{"time": 1694033974.1423037, "messages": [{"role": "system", "content": "You are a debugging assistant. You will be presented with a failing test, and tools (functions) to access the source code of the system under test (SUT). Your task is to provide a step-by-step explanation of how the bug occurred, based on the failing test and the information you retrieved using tests about the SUT. You will be given 9 chances to interact with functions to gather relevant information. An example answer would look like follows.\n\nTitle: Diagnosis of test `testGenerateURLFragment`\nDetails: The test `testGenerateURLFragment` checks whether HTML entities such as `&quot;` are correctly escaped to their corresponding character by the `StandardToolTipTagFragmentGenerator.generateToolTipFragment` method. However, the test failure indicates that this is not the case. Following the execution path, we find that `StandardToolTipTagFragmentGenerator.generateToolTipFragment` is not escaping any HTML code; instead, it is using its input `toolTipText` as is. Consequently, un-escaped strings are being returned, which leads to the error demonstrated by the test.\n\nAfter providing this diagnosis, you will be prompted to suggest which methods would be the best locations to be fixed. The answers should be in the form of `ClassName.MethodName(ArgType1, ArgType2, ...)` without commentary (one per line), as your answer will be automatically processed before finally being presented to the user."}, {"role": "user", "content": "The test `['test.test_utils.TestUtil.test_js_to_json_realworld(self)']` failed.\nThe test looks like:\n\n```python\n680 :     def test_js_to_json_realworld(self):\n681 :         inp = '''{\n682 :             'clip':{'provider':'pseudo'}\n683 :         }'''\n684 :         self.assertEqual(js_to_json(inp), '''{\n688 : \n689 :         inp = '''{\n690 :             'playlist':[{'controls':{'all':null}}]\n691 :         }'''\n692 :         self.assertEqual(js_to_json(inp), '''{\n696 :         inp = '''\"The CW\\\\'s \\\\'Crazy Ex-Girlfriend\\\\'\"'''\n697 :         self.assertEqual(js_to_json(inp), '''\"The CW's 'Crazy Ex-Girlfriend'\"''')\n699 :         inp = '\"SAND Number: SAND 2013-7800P\\\\nPresenter: Tom Russo\\\\nHabanero Software Training - Xyce Software\\\\nXyce, Sandia\\\\u0027s\"'\n700 :         json_code = js_to_json(inp)\n701 :         self.assertEqual(json.loads(json_code), json.loads(inp))\n703 :         inp = '''{\n704 :             0:{src:'skipped', type: 'application/dash+xml'},\n705 :             1:{src:'skipped', type: 'application/vnd.apple.mpegURL'},\n706 :         }'''\n707 :         self.assertEqual(js_to_json(inp), '''{\n712 :         inp = '''{\"foo\":101}'''\n713 :         self.assertEqual(js_to_json(inp), '''{\"foo\":101}''')\n715 :         inp = '''{\"duration\": \"00:01:07\"}'''\n716 :         self.assertEqual(js_to_json(inp), '''{\"duration\": \"00:01:07\"}''') # error occurred here\n```\n\nIt failed with the following error message and call stack:\n\n```\nAssertionError: '{\"duration\": 0}' != '{\"duration\": \"00:01:07\"}'\nTraceback (most recent call last):\n  File \"/home/user/BugsInPy/temp/projects/youtube-dl/test/test_utils.py\", line 716, in test_js_to_json_realworld\n    self.assertEqual(js_to_json(inp), '''{\"duration\": \"00:01:07\"}''')\n```\n\nStart by calling the `get_covered_packages` function."}, {"role": "assistant", "content": null, "function_call": {"name": "get_covered_packages", "arguments": "{}"}}, {"role": "function", "name": "get_covered_packages", "content": "[\"youtube_dl.extractor.tvc\", \"youtube_dl.YoutubeDL\", \"youtube_dl.extractor.lynda\", \"youtube_dl.extractor.appletrailers\", \"youtube_dl.extractor.facebook\", \"youtube_dl.extractor.bokecc\", \"youtube_dl.extractor.generic\", \"youtube_dl.extractor.viki\", \"youtube_dl.extractor.microsoftvirtualacademy\", \"youtube_dl.extractor.leeco\", \"youtube_dl.extractor.dbtv\", \"youtube_dl.extractor.animeondemand\", \"youtube_dl.extractor.dailymotion\", \"youtube_dl.extractor.arkena\", \"youtube_dl.postprocessor.ffmpeg\", \"youtube_dl.extractor.aenetworks\", \"youtube_dl.extractor.pbs\", \"youtube_dl.extractor\", \"youtube_dl.extractor.iqiyi\", \"youtube_dl.extractor.abc7news\", \"youtube_dl.extractor.br\", \"youtube_dl.extractor.mtv\", \"youtube_dl.jsinterp\", \"youtube_dl.extractor.twitch\", \"youtube_dl.extractor.tnaflix\", \"youtube_dl\", \"youtube_dl.extractor.nrk\", \"youtube_dl.extractor.udemy\", \"youtube_dl.extractor.instagram\", \"youtube_dl.extractor.kaltura\", \"youtube_dl.extractor.acast\", \"youtube_dl.extractor.npo\", \"youtube_dl.extractor.common\", \"youtube_dl.extractor.senateisvp\", \"youtube_dl.extractor.arte\", \"youtube_dl.extractor.pladform\", \"youtube_dl.extractor.svt\", \"youtube_dl.extractor.francetv\", \"youtube_dl.extractor.jwplatform\", \"youtube_dl.extractor.baidu\", \"youtube_dl.extractor.vimeo\", \"youtube_dl.extractor.daum\", \"youtube_dl.extractor.adultswim\", \"youtube_dl.extractor.xhamster\", \"youtube_dl.extractor.r7\", \"youtube_dl.extractor.youporn\", \"youtube_dl.extractor.tvplay\", \"youtube_dl.compat\", \"youtube_dl.extractor.tagesschau\", \"youtube_dl.extractor.democracynow\", \"youtube_dl.downloader.common\", \"youtube_dl.extractor.youtube\", \"youtube_dl.extractor.adobetv\", \"youtube_dl.extractor.rutv\", \"youtube_dl.extractor.bbc\", \"youtube_dl.extractor.theplatform\", \"youtube_dl.cache\", \"youtube_dl.utils\", \"youtube_dl.extractor.vimple\", \"youtube_dl.extractor.tunein\", \"youtube_dl.postprocessor.common\", \"youtube_dl.extractor.eagleplatform\", \"youtube_dl.extractor.walla\", \"youtube_dl.extractor.soundcloud\", \"youtube_dl.extractor.smotri\", \"youtube_dl.extractor.ceskatelevize\", \"youtube_dl.extractor.globo\", \"youtube_dl.extractor.ted\", \"youtube_dl.extractor.videomore\", \"youtube_dl.extractor.digiteka\", \"youtube_dl.extractor.washingtonpost\", \"youtube_dl.extractor.brightcove\", \"youtube_dl.extractor.abcnews\", \"youtube_dl.extractor.cbc\", \"youtube_dl.downloader.http\", \"youtube_dl.postprocessor.metadatafromtitle\", \"youtube_dl.aes\", \"youtube_dl.extractor.rai\", \"youtube_dl.downloader\", \"youtube_dl.extractor.abc\", \"youtube_dl.extractor.amp\", \"youtube_dl.extractor.anvato\", \"youtube_dl.extractor.nbc\"]"}, {"role": "assistant", "content": "The failing test `test_js_to_json_realworld` covers classes from various packages in the program under test. Here are the packages covered by the failing test:\n\n1. `youtube_dl.extractor.tvc`\n2. `youtube_dl.YoutubeDL`\n3. `youtube_dl.extractor.lynda`\n4. `youtube_dl.extractor.appletrailers`\n5. `youtube_dl.extractor.facebook`\n6. `youtube_dl.extractor.bokecc`\n7. `youtube_dl.extractor.generic`\n8. `youtube_dl.extractor.viki`\n9. `youtube_dl.extractor.microsoftvirtualacademy`\n10. `youtube_dl.extractor.leeco`\n11. `youtube_dl.extractor.dbtv`\n12. `youtube_dl.extractor.animeondemand`\n13. `youtube_dl.extractor.dailymotion`\n14. `youtube_dl.extractor.arkena`\n15. `youtube_dl.postprocessor.ffmpeg`\n16. `youtube_dl.extractor.aenetworks`\n17. `youtube_dl.extractor.pbs`\n18. `youtube_dl.extractor`\n19. `youtube_dl.extractor.iqiyi`\n20. `youtube_dl.extractor.abc7news`\n21. `youtube_dl.extractor.br`\n22. `youtube_dl.extractor.mtv`\n23. `youtube_dl.jsinterp`\n24. `youtube_dl.extractor.twitch`\n25. `youtube_dl.extractor.tnaflix`\n26. `youtube_dl`\n27. `youtube_dl.extractor.nrk`\n28. `youtube_dl.extractor.udemy`\n29. `youtube_dl.extractor.instagram`\n30. `youtube_dl.extractor.kaltura`\n31. `youtube_dl.extractor.acast`\n32. `youtube_dl.extractor.npo`\n33. `youtube_dl.extractor.common`\n34. `youtube_dl.extractor.senateisvp`\n35. `youtube_dl.extractor.arte`\n36. `youtube_dl.extractor.pladform`\n37. `youtube_dl.extractor.svt`\n38. `youtube_dl.extractor.francetv`\n39. `youtube_dl.extractor.jwplatform`\n40. `youtube_dl.extractor.baidu`\n41. `youtube_dl.extractor.vimeo`\n42. `youtube_dl.extractor.daum`\n43. `youtube_dl.extractor.adultswim`\n44. `youtube_dl.extractor.xhamster`\n45. `youtube_dl.extractor.r7`\n46. `youtube_dl.extractor.youporn`\n47. `youtube_dl.extractor.tvplay`\n48. `youtube_dl.compat`\n49. `youtube_dl.extractor.tagesschau`\n50. `youtube_dl.extractor.democracynow`\n51. `youtube_dl.downloader.common`\n52. `youtube_dl.extractor.youtube`\n53. `youtube_dl.extractor.adobetv`\n54. `youtube_dl.extractor.rutv`\n55. `youtube_dl.extractor.bbc`\n56. `youtube_dl.extractor.theplatform`\n57. `youtube_dl.cache`\n58. `youtube_dl.utils`\n59. `youtube_dl.extractor.vimple`\n60. `youtube_dl.extractor.tunein`\n61. `youtube_dl.postprocessor.common`\n62. `youtube_dl.extractor.eagleplatform`\n63. `youtube_dl.extractor.walla`\n64. `youtube_dl.extractor.soundcloud`\n65. `youtube_dl.extractor.smotri`\n66. `youtube_dl.extractor.ceskatelevize`\n67. `youtube_dl.extractor.globo`\n68. `youtube_dl.extractor.ted`\n69. `youtube_dl.extractor.videomore`\n70. `youtube_dl.extractor.digiteka`\n71. `youtube_dl.extractor.washingtonpost`\n72. `youtube_dl.extractor.brightcove`\n73. `youtube_dl.extractor.abcnews`\n74. `youtube_dl.extractor.cbc`\n75. `youtube_dl.downloader.http`\n76. `youtube_dl.postprocessor.metadatafromtitle`\n77. `youtube_dl.aes`\n78. `youtube_dl.extractor.rai`\n79. `youtube_dl.downloader`\n80. `youtube_dl.extractor.abc`\n81. `youtube_dl.extractor.amp`\n82. `youtube_dl.extractor.anvato`\n83. `youtube_dl.extractor.nbc`\n\nLet's continue investigating by retrieving the classes covered by failing tests for the package `youtube_dl.extractor.generic`.", "function_call": {"name": "get_failing_tests_covered_classes", "arguments": "{\n  \"package_name\": \"youtube_dl.extractor.generic\"\n}"}}, {"role": "function", "name": "get_failing_tests_covered_classes", "content": "[\"GenericIE\"]"}, {"role": "assistant", "content": "The failing test `test_js_to_json_realworld` covers the class `GenericIE` in the `youtube_dl.extractor.generic` package.\nLet's retrieve the methods covered by failing tests for this class.", "function_call": {"name": "get_failing_tests_covered_methods_for_class", "arguments": "{\n  \"class_name\": \"youtube_dl.extractor.generic.GenericIE\"\n}"}}, {"role": "function", "name": "get_failing_tests_covered_methods_for_class", "content": "[\".report_following_redirect\", \"._extract_rss\", \"._extract_camtasia\", \"._real_extract\", \"._playlist_from_matches\", \".check_video\", \".filter_video\"]"}, {"role": "assistant", "content": "The failing test `test_js_to_json_realworld` covers the following methods in the `GenericIE` class:\n\n1. `.report_following_redirect`\n2. `._extract_rss`\n3. `._extract_camtasia`\n4. `._real_extract`\n5. `._playlist_from_matches`\n6. `.check_video`\n7. `.filter_video`\n\nLet's retrieve the code snippets for these methods to analyze the implementation.", "function_call": {"name": "get_code_snippet", "arguments": "{\n  \"signature\": \"youtube_dl.extractor.generic.GenericIE.report_following_redirect\"\n}"}}, {"role": "function", "name": "get_code_snippet", "content": "\"1418 :     def report_following_redirect(self, new_url):\\n1419 :         \\\"\\\"\\\"Report information extraction.\\\"\\\"\\\"\\n1420 :         self._downloader.to_screen('[redirect] Following redirect to %s' % new_url)\""}, {"role": "assistant", "content": null, "function_call": {"name": "get_code_snippet", "arguments": "{\n  \"signature\": \"youtube_dl.extractor.generic.GenericIE._extract_rss\"\n}"}}, {"role": "function", "name": "get_code_snippet", "content": "\"1422 :     def _extract_rss(self, url, video_id, doc):\\n1423 :         playlist_title = doc.find('./channel/title').text\\n1424 :         playlist_desc_el = doc.find('./channel/description')\\n1425 :         playlist_desc = None if playlist_desc_el is None else playlist_desc_el.text\\n1426 : \\n1427 :         entries = []\\n1428 :         for it in doc.findall('./channel/item'):\\n1429 :             next_url = xpath_text(it, 'link', fatal=False)\\n1430 :             if not next_url:\\n1431 :                 enclosure_nodes = it.findall('./enclosure')\\n1432 :                 for e in enclosure_nodes:\\n1433 :                     next_url = e.attrib.get('url')\\n1434 :                     if next_url:\\n1435 :                         break\\n1436 : \\n1437 :             if not next_url:\\n1438 :                 continue\\n1439 : \\n1440 :             entries.append({\\n1441 :                 '_type': 'url',\\n1442 :                 'url': next_url,\\n1443 :                 'title': it.find('title').text,\\n1444 :             })\\n1445 : \\n1446 :         return {\\n1447 :             '_type': 'playlist',\\n1448 :             'id': url,\\n1449 :             'title': playlist_title,\\n1450 :             'description': playlist_desc,\\n1451 :             'entries': entries,\\n1452 :         }\""}, {"role": "assistant", "content": null, "function_call": {"name": "get_code_snippet", "arguments": "{\n  \"signature\": \"youtube_dl.extractor.generic.GenericIE._extract_camtasia\"\n}"}}, {"role": "function", "name": "get_code_snippet", "content": "\"1454 :     def _extract_camtasia(self, url, video_id, webpage):\\n1455 :         \\\"\\\"\\\" Returns None if no camtasia video can be found. \\\"\\\"\\\"\\n1456 : \\n1457 :         camtasia_cfg = self._search_regex(\\n1458 :             r'fo\\\\.addVariable\\\\(\\\\s*\\\"csConfigFile\\\",\\\\s*\\\"([^\\\"]+)\\\"\\\\s*\\\\);',\\n1459 :             webpage, 'camtasia configuration file', default=None)\\n1460 :         if camtasia_cfg is None:\\n1461 :             return None\\n1462 : \\n1463 :         title = self._html_search_meta('DC.title', webpage, fatal=True)\\n1464 : \\n1465 :         camtasia_url = compat_urlparse.urljoin(url, camtasia_cfg)\\n1466 :         camtasia_cfg = self._download_xml(\\n1467 :             camtasia_url, video_id,\\n1468 :             note='Downloading camtasia configuration',\\n1469 :             errnote='Failed to download camtasia configuration')\\n1470 :         fileset_node = camtasia_cfg.find('./playlist/array/fileset')\\n1471 : \\n1472 :         entries = []\\n1473 :         for n in fileset_node.getchildren():\\n1474 :             url_n = n.find('./uri')\\n1475 :             if url_n is None:\\n1476 :                 continue\\n1477 : \\n1478 :             entries.append({\\n1479 :                 'id': os.path.splitext(url_n.text.rpartition('/')[2])[0],\\n1480 :                 'title': '%s - %s' % (title, n.tag),\\n1481 :                 'url': compat_urlparse.urljoin(url, url_n.text),\\n1482 :                 'duration': float_or_none(n.find('./duration').text),\\n1483 :             })\\n1484 : \\n1485 :         return {\\n1486 :             '_type': 'playlist',\\n1487 :             'entries': entries,\\n1488 :             'title': title,\\n1489 :         }\""}, {"role": "assistant", "content": null, "function_call": {"name": "get_code_snippet", "arguments": "{\n  \"signature\": \"youtube_dl.extractor.generic.GenericIE._real_extract\"\n}"}}, {"role": "function", "name": "get_code_snippet", "content": "\"1491 :     def _real_extract(self, url):\\n1492 :         if url.startswith('//'):\\n1493 :             return {\\n1494 :                 '_type': 'url',\\n1495 :                 'url': self.http_scheme() + url,\\n1496 :             }\\n1497 : \\n1498 :         parsed_url = compat_urlparse.urlparse(url)\\n1499 :         if not parsed_url.scheme:\\n1500 :             default_search = self._downloader.params.get('default_search')\\n1501 :             if default_search is None:\\n1502 :                 default_search = 'fixup_error'\\n1503 : \\n1504 :             if default_search in ('auto', 'auto_warning', 'fixup_error'):\\n1505 :                 if '/' in url:\\n1506 :                     self._downloader.report_warning('The url doesn\\\\'t specify the protocol, trying with http')\\n1507 :                     return self.url_result('http://' + url)\\n1508 :                 elif default_search != 'fixup_error':\\n1509 :                     if default_search == 'auto_warning':\\n1510 :                         if re.match(r'^(?:url|URL)$', url):\\n1511 :                             raise ExtractorError(\\n1512 :                                 'Invalid URL:  %r . Call youtube-dl like this:  youtube-dl -v \\\"https://www.youtube.com/watch?v=BaW_jenozKc\\\"  ' % url,\\n1513 :                                 expected=True)\\n1514 :                         else:\\n1515 :                             self._downloader.report_warning(\\n1516 :                                 'Falling back to youtube search for  %s . Set --default-search \\\"auto\\\" to suppress this warning.' % url)\\n1517 :                     return self.url_result('ytsearch:' + url)\\n1518 : \\n1519 :             if default_search in ('error', 'fixup_error'):\\n1520 :                 raise ExtractorError(\\n1521 :                     '%r is not a valid URL. '\\n1522 :                     'Set --default-search \\\"ytsearch\\\" (or run  youtube-dl \\\"ytsearch:%s\\\" ) to search YouTube'\\n1523 :                     % (url, url), expected=True)\\n1524 :             else:\\n1525 :                 if ':' not in default_search:\\n1526 :                     default_search += ':'\\n1527 :                 return self.url_result(default_search + url)\\n1528 : \\n1529 :         url, smuggled_data = unsmuggle_url(url)\\n1530 :         force_videoid = None\\n1531 :         is_intentional = smuggled_data and smuggled_data.get('to_generic')\\n1532 :         if smuggled_data and 'force_videoid' in smuggled_data:\\n1533 :             force_videoid = smuggled_data['force_videoid']\\n1534 :             video_id = force_videoid\\n1535 :         else:\\n1536 :             video_id = compat_urllib_parse_unquote(os.path.splitext(url.rstrip('/').split('/')[-1])[0])\\n1537 : \\n1538 :         self.to_screen('%s: Requesting header' % video_id)\\n1539 : \\n1540 :         head_req = HEADRequest(url)\\n1541 :         head_response = self._request_webpage(\\n1542 :             head_req, video_id,\\n1543 :             note=False, errnote='Could not send HEAD request to %s' % url,\\n1544 :             fatal=False)\\n1545 : \\n1546 :         if head_response is not False:\\n1547 :             # Check for redirect\\n1548 :             new_url = head_response.geturl()\\n1549 :             if url != new_url:\\n1550 :                 self.report_following_redirect(new_url)\\n1551 :                 if force_videoid:\\n1552 :                     new_url = smuggle_url(\\n1553 :                         new_url, {'force_videoid': force_videoid})\\n1554 :                 return self.url_result(new_url)\\n1555 : \\n1556 :         full_response = None\\n1557 :         if head_response is False:\\n1558 :             request = sanitized_Request(url)\\n1559 :             request.add_header('Accept-Encoding', '*')\\n1560 :             full_response = self._request_webpage(request, video_id)\\n1561 :             head_response = full_response\\n1562 : \\n1563 :         info_dict = {\\n1564 :             'id': video_id,\\n1565 :             'title': compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0]),\\n1566 :             'upload_date': unified_strdate(head_response.headers.get('Last-Modified'))\\n1567 :         }\\n1568 : \\n1569 :         # Check for direct link to a video\\n1570 :         content_type = head_response.headers.get('Content-Type', '').lower()\\n1571 :         m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|(?:vnd\\\\.apple\\\\.|x-)?mpegurl)))/(?P<format_id>[^;\\\\s]+)', content_type)\\n1572 :         if m:\\n1573 :             format_id = m.group('format_id')\\n1574 :             if format_id.endswith('mpegurl'):\\n1575 :                 formats = self._extract_m3u8_formats(url, video_id, 'mp4')\\n1576 :             elif format_id == 'f4m':\\n1577 :                 formats = self._extract_f4m_formats(url, video_id)\\n1578 :             else:\\n1579 :                 formats = [{\\n1580 :                     'format_id': m.group('format_id'),\\n1581 :                     'url': url,\\n1582 :                     'vcodec': 'none' if m.group('type') == 'audio' else None\\n1583 :                 }]\\n1584 :                 info_dict['direct'] = True\\n1585 :             self._sort_formats(formats)\\n1586 :             info_dict['formats'] = formats\\n1587 :             return info_dict\\n1588 : \\n1589 :         if not self._downloader.params.get('test', False) and not is_intentional:\\n1590 :             force = self._downloader.params.get('force_generic_extractor', False)\\n1591 :             self._downloader.report_warning(\\n1592 :                 '%s on generic information extractor.' % ('Forcing' if force else 'Falling back'))\\n1593 : \\n1594 :         if not full_response:\\n1595 :             request = sanitized_Request(url)\\n1596 :             # Some webservers may serve compressed content of rather big size (e.g. gzipped flac)\\n1597 :             # making it impossible to download only chunk of the file (yet we need only 512kB to\\n1598 :             # test whether it's HTML or not). According to youtube-dl default Accept-Encoding\\n1599 :             # that will always result in downloading the whole file that is not desirable.\\n1600 :             # Therefore for extraction pass we have to override Accept-Encoding to any in order\\n1601 :             # to accept raw bytes and being able to download only a chunk.\\n1602 :             # It may probably better to solve this by checking Content-Type for application/octet-stream\\n1603 :             # after HEAD request finishes, but not sure if we can rely on this.\\n1604 :             request.add_header('Accept-Encoding', '*')\\n1605 :             full_response = self._request_webpage(request, video_id)\\n1606 : \\n1607 :         first_bytes = full_response.read(512)\\n1608 : \\n1609 :         # Is it an M3U playlist?\\n1610 :         if first_bytes.startswith(b'#EXTM3U'):\\n1611 :             info_dict['formats'] = self._extract_m3u8_formats(url, video_id, 'mp4')\\n1612 :             self._sort_formats(info_dict['formats'])\\n1613 :             return info_dict\\n1614 : \\n1615 :         # Maybe it's a direct link to a video?\\n1616 :         # Be careful not to download the whole thing!\\n1617 :         if not is_html(first_bytes):\\n1618 :             self._downloader.report_warning(\\n1619 :                 'URL could be a direct video link, returning it as such.')\\n1620 :             info_dict.update({\\n1621 :                 'direct': True,\\n1622 :                 'url': url,\\n1623 :             })\\n1624 :             return info_dict\\n1625 : \\n1626 :         webpage = self._webpage_read_content(\\n1627 :             full_response, url, video_id, prefix=first_bytes)\\n1628 : \\n1629 :         self.report_extraction(video_id)\\n1630 : \\n1631 :         # Is it an RSS feed, a SMIL file, an XSPF playlist or a MPD manifest?\\n1632 :         try:\\n1633 :             doc = compat_etree_fromstring(webpage.encode('utf-8'))\\n1634 :             if doc.tag == 'rss':\\n1635 :                 return self._extract_rss(url, video_id, doc)\\n1636 :             elif re.match(r'^(?:{[^}]+})?smil$', doc.tag):\\n1637 :                 smil = self._parse_smil(doc, url, video_id)\\n1638 :                 self._sort_formats(smil['formats'])\\n1639 :                 return smil\\n1640 :             elif doc.tag == '{http://xspf.org/ns/0/}playlist':\\n1641 :                 return self.playlist_result(self._parse_xspf(doc, video_id), video_id)\\n1642 :             elif re.match(r'(?i)^(?:{[^}]+})?MPD$', doc.tag):\\n1643 :                 info_dict['formats'] = self._parse_mpd_formats(\\n1644 :                     doc, video_id, mpd_base_url=url.rpartition('/')[0])\\n1645 :                 self._sort_formats(info_dict['formats'])\\n1646 :                 return info_dict\\n1647 :             elif re.match(r'^{http://ns\\\\.adobe\\\\.com/f4m/[12]\\\\.0}manifest$', doc.tag):\\n1648 :                 info_dict['formats'] = self._parse_f4m_formats(doc, url, video_id)\\n1649 :                 self._sort_formats(info_dict['formats'])\\n1650 :                 return info_dict\\n1651 :         except compat_xml_parse_error:\\n1652 :             pass\\n1653 : \\n1654 :         # Is it a Camtasia project?\\n1655 :         camtasia_res = self._extract_camtasia(url, video_id, webpage)\\n1656 :         if camtasia_res is not None:\\n1657 :             return camtasia_res\\n1658 : \\n1659 :         # Sometimes embedded video player is hidden behind percent encoding\\n1660 :         # (e.g. https://github.com/rg3/youtube-dl/issues/2448)\\n1661 :         # Unescaping the whole page allows to handle those cases in a generic way\\n1662 :         webpage = compat_urllib_parse_unquote(webpage)\\n1663 : \\n1664 :         # it's tempting to parse this further, but you would\\n1665 :         # have to take into account all the variations like\\n1666 :         #   Video Title - Site Name\\n1667 :         #   Site Name | Video Title\\n1668 :         #   Video Title - Tagline | Site Name\\n1669 :         # and so on and so forth; it's just not practical\\n1670 :         video_title = self._og_search_title(\\n1671 :             webpage, default=None) or self._html_search_regex(\\n1672 :             r'(?s)<title>(.*?)</title>', webpage, 'video title',\\n1673 :             default='video')\\n1674 : \\n1675 :         # Try to detect age limit automatically\\n1676 :         age_limit = self._rta_search(webpage)\\n1677 :         # And then there are the jokers who advertise that they use RTA,\\n1678 :         # but actually don't.\\n1679 :         AGE_LIMIT_MARKERS = [\\n1680 :             r'Proudly Labeled <a href=\\\"http://www.rtalabel.org/\\\" title=\\\"Restricted to Adults\\\">RTA</a>',\\n1681 :         ]\\n1682 :         if any(re.search(marker, webpage) for marker in AGE_LIMIT_MARKERS):\\n1683 :             age_limit = 18\\n1684 : \\n1685 :         # video uploader is domain name\\n1686 :         video_uploader = self._search_regex(\\n1687 :             r'^(?:https?://)?([^/]*)/.*', url, 'video uploader')\\n1688 : \\n1689 :         video_description = self._og_search_description(webpage, default=None)\\n1690 :         video_thumbnail = self._og_search_thumbnail(webpage, default=None)\\n1691 : \\n1692 :         # Helper method\\n1693 :         def _playlist_from_matches(matches, getter=None, ie=None):\\n1694 :             urlrs = orderedSet(\\n1695 :                 self.url_result(self._proto_relative_url(getter(m) if getter else m), ie)\\n1696 :                 for m in matches)\\n1697 :             return self.playlist_result(\\n1698 :                 urlrs, playlist_id=video_id, playlist_title=video_title)\\n1699 : \\n1700 :         # Look for Brightcove Legacy Studio embeds\\n1701 :         bc_urls = BrightcoveLegacyIE._extract_brightcove_urls(webpage)\\n1702 :         if bc_urls:\\n1703 :             self.to_screen('Brightcove video detected.')\\n1704 :             entries = [{\\n1705 :                 '_type': 'url',\\n1706 :                 'url': smuggle_url(bc_url, {'Referer': url}),\\n1707 :                 'ie_key': 'BrightcoveLegacy'\\n1708 :             } for bc_url in bc_urls]\\n1709 : \\n1710 :             return {\\n1711 :                 '_type': 'playlist',\\n1712 :                 'title': video_title,\\n1713 :                 'id': video_id,\\n1714 :                 'entries': entries,\\n1715 :             }\\n1716 : \\n1717 :         # Look for Brightcove New Studio embeds\\n1718 :         bc_urls = BrightcoveNewIE._extract_urls(webpage)\\n1719 :         if bc_urls:\\n1720 :             return _playlist_from_matches(bc_urls, ie='BrightcoveNew')\\n1721 : \\n1722 :         # Look for ThePlatform embeds\\n1723 :         tp_urls = ThePlatformIE._extract_urls(webpage)\\n1724 :         if tp_urls:\\n1725 :             return _playlist_from_matches(tp_urls, ie='ThePlatform')\\n1726 : \\n1727 :         # Look for Vessel embeds\\n1728 :         vessel_urls = VesselIE._extract_urls(webpage)\\n1729 :         if vessel_urls:\\n1730 :             return _playlist_from_matches(vessel_urls, ie=VesselIE.ie_key())\\n1731 : \\n1732 :         # Look for embedded rtl.nl player\\n1733 :         matches = re.findall(\\n1734 :             r'<iframe[^>]+?src=\\\"((?:https?:)?//(?:www\\\\.)?rtl\\\\.nl/system/videoplayer/[^\\\"]+(?:video_)?embed[^\\\"]+)\\\"',\\n1735 :             webpage)\\n1736 :         if matches:\\n1737 :             return _playlist_from_matches(matches, ie='RtlNl')\\n1738 : \\n1739 :         vimeo_url = VimeoIE._extract_vimeo_url(url, webpage)\\n1740 :         if vimeo_url is not None:\\n1741 :             return self.url_result(vimeo_url)\\n1742 : \\n1743 :         vid_me_embed_url = self._search_regex(\\n1744 :             r'src=[\\\\'\\\"](https?://vid\\\\.me/[^\\\\'\\\"]+)[\\\\'\\\"]',\\n1745 :             webpage, 'vid.me embed', default=None)\\n1746 :         if vid_me_embed_url is not None:\\n1747 :             return self.url_result(vid_me_embed_url, 'Vidme')\\n1748 : \\n1749 :         # Look for embedded YouTube player\\n1750 :         matches = re.findall(r'''(?x)\\n1751 :             (?:\\n1752 :                 <iframe[^>]+?src=|\\n1753 :                 data-video-url=|\\n1754 :                 <embed[^>]+?src=|\\n1755 :                 embedSWF\\\\(?:\\\\s*|\\n1756 :                 new\\\\s+SWFObject\\\\(\\n1757 :             )\\n1758 :             ([\\\"\\\\'])\\n1759 :                 (?P<url>(?:https?:)?//(?:www\\\\.)?youtube(?:-nocookie)?\\\\.com/\\n1760 :                 (?:embed|v|p)/.+?)\\n1761 :             \\\\1''', webpage)\\n1762 :         if matches:\\n1763 :             return _playlist_from_matches(\\n1764 :                 matches, lambda m: unescapeHTML(m[1]))\\n1765 : \\n1766 :         # Look for lazyYT YouTube embed\\n1767 :         matches = re.findall(\\n1768 :             r'class=\\\"lazyYT\\\" data-youtube-id=\\\"([^\\\"]+)\\\"', webpage)\\n1769 :         if matches:\\n1770 :             return _playlist_from_matches(matches, lambda m: unescapeHTML(m))\\n1771 : \\n1772 :         # Look for Wordpress \\\"YouTube Video Importer\\\" plugin\\n1773 :         matches = re.findall(r'''(?x)<div[^>]+\\n1774 :             class=(?P<q1>[\\\\'\\\"])[^\\\\'\\\"]*\\\\byvii_single_video_player\\\\b[^\\\\'\\\"]*(?P=q1)[^>]+\\n1775 :             data-video_id=(?P<q2>[\\\\'\\\"])([^\\\\'\\\"]+)(?P=q2)''', webpage)\\n1776 :         if matches:\\n1777 :             return _playlist_from_matches(matches, lambda m: m[-1])\\n1778 : \\n1779 :         matches = DailymotionIE._extract_urls(webpage)\\n1780 :         if matches:\\n1781 :             return _playlist_from_matches(matches)\\n1782 : \\n1783 :         # Look for embedded Dailymotion playlist player (#3822)\\n1784 :         m = re.search(\\n1785 :             r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>(?:https?:)?//(?:www\\\\.)?dailymotion\\\\.[a-z]{2,3}/widget/jukebox\\\\?.+?)\\\\1', webpage)\\n1786 :         if m:\\n1787 :             playlists = re.findall(\\n1788 :                 r'list\\\\[\\\\]=/playlist/([^/]+)/', unescapeHTML(m.group('url')))\\n1789 :             if playlists:\\n1790 :                 return _playlist_from_matches(\\n1791 :                     playlists, lambda p: '//dailymotion.com/playlist/%s' % p)\\n1792 : \\n1793 :         # Look for embedded Wistia player\\n1794 :         match = re.search(\\n1795 :             r'<(?:meta[^>]+?content|iframe[^>]+?src)=([\\\"\\\\'])(?P<url>(?:https?:)?//(?:fast\\\\.)?wistia\\\\.net/embed/iframe/.+?)\\\\1', webpage)\\n1796 :         if match:\\n1797 :             embed_url = self._proto_relative_url(\\n1798 :                 unescapeHTML(match.group('url')))\\n1799 :             return {\\n1800 :                 '_type': 'url_transparent',\\n1801 :                 'url': embed_url,\\n1802 :                 'ie_key': 'Wistia',\\n1803 :                 'uploader': video_uploader,\\n1804 :             }\\n1805 : \\n1806 :         match = re.search(r'(?:id=[\\\"\\\\']wistia_|data-wistia-?id=[\\\"\\\\']|Wistia\\\\.embed\\\\([\\\"\\\\'])(?P<id>[^\\\"\\\\']+)', webpage)\\n1807 :         if match:\\n1808 :             return {\\n1809 :                 '_type': 'url_transparent',\\n1810 :                 'url': 'wistia:%s' % match.group('id'),\\n1811 :                 'ie_key': 'Wistia',\\n1812 :                 'uploader': video_uploader,\\n1813 :             }\\n1814 : \\n1815 :         match = re.search(\\n1816 :             r'''(?sx)\\n1817 :                 <script[^>]+src=([\\\"'])(?:https?:)?//fast\\\\.wistia\\\\.com/assets/external/E-v1\\\\.js\\\\1[^>]*>.*?\\n1818 :                 <div[^>]+class=([\\\"']).*?\\\\bwistia_async_(?P<id>[a-z0-9]+)\\\\b.*?\\\\2\\n1819 :             ''', webpage)\\n1820 :         if match:\\n1821 :             return self.url_result(self._proto_relative_url(\\n1822 :                 'wistia:%s' % match.group('id')), 'Wistia')\\n1823 : \\n1824 :         # Look for SVT player\\n1825 :         svt_url = SVTIE._extract_url(webpage)\\n1826 :         if svt_url:\\n1827 :             return self.url_result(svt_url, 'SVT')\\n1828 : \\n1829 :         # Look for embedded condenast player\\n1830 :         matches = re.findall(\\n1831 :             r'<iframe\\\\s+(?:[a-zA-Z-]+=\\\"[^\\\"]+\\\"\\\\s+)*?src=\\\"(https?://player\\\\.cnevids\\\\.com/embed/[^\\\"]+\\\")',\\n1832 :             webpage)\\n1833 :         if matches:\\n1834 :             return {\\n1835 :                 '_type': 'playlist',\\n1836 :                 'entries': [{\\n1837 :                     '_type': 'url',\\n1838 :                     'ie_key': 'CondeNast',\\n1839 :                     'url': ma,\\n1840 :                 } for ma in matches],\\n1841 :                 'title': video_title,\\n1842 :                 'id': video_id,\\n1843 :             }\\n1844 : \\n1845 :         # Look for Bandcamp pages with custom domain\\n1846 :         mobj = re.search(r'<meta property=\\\"og:url\\\"[^>]*?content=\\\"(.*?bandcamp\\\\.com.*?)\\\"', webpage)\\n1847 :         if mobj is not None:\\n1848 :             burl = unescapeHTML(mobj.group(1))\\n1849 :             # Don't set the extractor because it can be a track url or an album\\n1850 :             return self.url_result(burl)\\n1851 : \\n1852 :         # Look for embedded Vevo player\\n1853 :         mobj = re.search(\\n1854 :             r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>(?:https?:)?//(?:cache\\\\.)?vevo\\\\.com/.+?)\\\\1', webpage)\\n1855 :         if mobj is not None:\\n1856 :             return self.url_result(mobj.group('url'))\\n1857 : \\n1858 :         # Look for embedded Viddler player\\n1859 :         mobj = re.search(\\n1860 :             r'<(?:iframe[^>]+?src|param[^>]+?value)=([\\\"\\\\'])(?P<url>(?:https?:)?//(?:www\\\\.)?viddler\\\\.com/(?:embed|player)/.+?)\\\\1',\\n1861 :             webpage)\\n1862 :         if mobj is not None:\\n1863 :             return self.url_result(mobj.group('url'))\\n1864 : \\n1865 :         # Look for NYTimes player\\n1866 :         mobj = re.search(\\n1867 :             r'<iframe[^>]+src=([\\\"\\\\'])(?P<url>(?:https?:)?//graphics8\\\\.nytimes\\\\.com/bcvideo/[^/]+/iframe/embed\\\\.html.+?)\\\\1>',\\n1868 :             webpage)\\n1869 :         if mobj is not None:\\n1870 :             return self.url_result(mobj.group('url'))\\n1871 : \\n1872 :         # Look for Libsyn player\\n1873 :         mobj = re.search(\\n1874 :             r'<iframe[^>]+src=([\\\"\\\\'])(?P<url>(?:https?:)?//html5-player\\\\.libsyn\\\\.com/embed/.+?)\\\\1', webpage)\\n1875 :         if mobj is not None:\\n1876 :             return self.url_result(mobj.group('url'))\\n1877 : \\n1878 :         # Look for Ooyala videos\\n1879 :         mobj = (re.search(r'player\\\\.ooyala\\\\.com/[^\\\"?]+[?#][^\\\"]*?(?:embedCode|ec)=(?P<ec>[^\\\"&]+)', webpage) or\\n1880 :                 re.search(r'OO\\\\.Player\\\\.create\\\\([\\\\'\\\"].*?[\\\\'\\\"],\\\\s*[\\\\'\\\"](?P<ec>.{32})[\\\\'\\\"]', webpage) or\\n1881 :                 re.search(r'SBN\\\\.VideoLinkset\\\\.ooyala\\\\([\\\\'\\\"](?P<ec>.{32})[\\\\'\\\"]\\\\)', webpage) or\\n1882 :                 re.search(r'data-ooyala-video-id\\\\s*=\\\\s*[\\\\'\\\"](?P<ec>.{32})[\\\\'\\\"]', webpage))\\n1883 :         if mobj is not None:\\n1884 :             return OoyalaIE._build_url_result(smuggle_url(mobj.group('ec'), {'domain': url}))\\n1885 : \\n1886 :         # Look for multiple Ooyala embeds on SBN network websites\\n1887 :         mobj = re.search(r'SBN\\\\.VideoLinkset\\\\.entryGroup\\\\((\\\\[.*?\\\\])', webpage)\\n1888 :         if mobj is not None:\\n1889 :             embeds = self._parse_json(mobj.group(1), video_id, fatal=False)\\n1890 :             if embeds:\\n1891 :                 return _playlist_from_matches(\\n1892 :                     embeds, getter=lambda v: OoyalaIE._url_for_embed_code(smuggle_url(v['provider_video_id'], {'domain': url})), ie='Ooyala')\\n1893 : \\n1894 :         # Look for Aparat videos\\n1895 :         mobj = re.search(r'<iframe .*?src=\\\"(http://www\\\\.aparat\\\\.com/video/[^\\\"]+)\\\"', webpage)\\n1896 :         if mobj is not None:\\n1897 :             return self.url_result(mobj.group(1), 'Aparat')\\n1898 : \\n1899 :         # Look for MPORA videos\\n1900 :         mobj = re.search(r'<iframe .*?src=\\\"(http://mpora\\\\.(?:com|de)/videos/[^\\\"]+)\\\"', webpage)\\n1901 :         if mobj is not None:\\n1902 :             return self.url_result(mobj.group(1), 'Mpora')\\n1903 : \\n1904 :         # Look for embedded NovaMov-based player\\n1905 :         mobj = re.search(\\n1906 :             r'''(?x)<(?:pagespeed_)?iframe[^>]+?src=([\\\"\\\\'])\\n1907 :                     (?P<url>http://(?:(?:embed|www)\\\\.)?\\n1908 :                         (?:novamov\\\\.com|\\n1909 :                            nowvideo\\\\.(?:ch|sx|eu|at|ag|co)|\\n1910 :                            videoweed\\\\.(?:es|com)|\\n1911 :                            movshare\\\\.(?:net|sx|ag)|\\n1912 :                            divxstage\\\\.(?:eu|net|ch|co|at|ag))\\n1913 :                         /embed\\\\.php.+?)\\\\1''', webpage)\\n1914 :         if mobj is not None:\\n1915 :             return self.url_result(mobj.group('url'))\\n1916 : \\n1917 :         # Look for embedded Facebook player\\n1918 :         facebook_url = FacebookIE._extract_url(webpage)\\n1919 :         if facebook_url is not None:\\n1920 :             return self.url_result(facebook_url, 'Facebook')\\n1921 : \\n1922 :         # Look for embedded VK player\\n1923 :         mobj = re.search(r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>https?://vk\\\\.com/video_ext\\\\.php.+?)\\\\1', webpage)\\n1924 :         if mobj is not None:\\n1925 :             return self.url_result(mobj.group('url'), 'VK')\\n1926 : \\n1927 :         # Look for embedded Odnoklassniki player\\n1928 :         mobj = re.search(r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>https?://(?:odnoklassniki|ok)\\\\.ru/videoembed/.+?)\\\\1', webpage)\\n1929 :         if mobj is not None:\\n1930 :             return self.url_result(mobj.group('url'), 'Odnoklassniki')\\n1931 : \\n1932 :         # Look for embedded ivi player\\n1933 :         mobj = re.search(r'<embed[^>]+?src=([\\\"\\\\'])(?P<url>https?://(?:www\\\\.)?ivi\\\\.ru/video/player.+?)\\\\1', webpage)\\n1934 :         if mobj is not None:\\n1935 :             return self.url_result(mobj.group('url'), 'Ivi')\\n1936 : \\n1937 :         # Look for embedded Huffington Post player\\n1938 :         mobj = re.search(\\n1939 :             r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>https?://embed\\\\.live\\\\.huffingtonpost\\\\.com/.+?)\\\\1', webpage)\\n1940 :         if mobj is not None:\\n1941 :             return self.url_result(mobj.group('url'), 'HuffPost')\\n1942 : \\n1943 :         # Look for embed.ly\\n1944 :         mobj = re.search(r'class=[\\\"\\\\']embedly-card[\\\"\\\\'][^>]href=[\\\"\\\\'](?P<url>[^\\\"\\\\']+)', webpage)\\n1945 :         if mobj is not None:\\n1946 :             return self.url_result(mobj.group('url'))\\n1947 :         mobj = re.search(r'class=[\\\"\\\\']embedly-embed[\\\"\\\\'][^>]src=[\\\"\\\\'][^\\\"\\\\']*url=(?P<url>[^&]+)', webpage)\\n1948 :         if mobj is not None:\\n1949 :             return self.url_result(compat_urllib_parse_unquote(mobj.group('url')))\\n1950 : \\n1951 :         # Look for funnyordie embed\\n1952 :         matches = re.findall(r'<iframe[^>]+?src=\\\"(https?://(?:www\\\\.)?funnyordie\\\\.com/embed/[^\\\"]+)\\\"', webpage)\\n1953 :         if matches:\\n1954 :             return _playlist_from_matches(\\n1955 :                 matches, getter=unescapeHTML, ie='FunnyOrDie')\\n1956 : \\n1957 :         # Look for BBC iPlayer embed\\n1958 :         matches = re.findall(r'setPlaylist\\\\(\\\"(https?://www\\\\.bbc\\\\.co\\\\.uk/iplayer/[^/]+/[\\\\da-z]{8})\\\"\\\\)', webpage)\\n1959 :         if matches:\\n1960 :             return _playlist_from_matches(matches, ie='BBCCoUk')\\n1961 : \\n1962 :         # Look for embedded RUTV player\\n1963 :         rutv_url = RUTVIE._extract_url(webpage)\\n1964 :         if rutv_url:\\n1965 :             return self.url_result(rutv_url, 'RUTV')\\n1966 : \\n1967 :         # Look for embedded TVC player\\n1968 :         tvc_url = TVCIE._extract_url(webpage)\\n1969 :         if tvc_url:\\n1970 :             return self.url_result(tvc_url, 'TVC')\\n1971 : \\n1972 :         # Look for embedded SportBox player\\n1973 :         sportbox_urls = SportBoxEmbedIE._extract_urls(webpage)\\n1974 :         if sportbox_urls:\\n1975 :             return _playlist_from_matches(sportbox_urls, ie='SportBoxEmbed')\\n1976 : \\n1977 :         # Look for embedded PornHub player\\n1978 :         pornhub_url = PornHubIE._extract_url(webpage)\\n1979 :         if pornhub_url:\\n1980 :             return self.url_result(pornhub_url, 'PornHub')\\n1981 : \\n1982 :         # Look for embedded XHamster player\\n1983 :         xhamster_urls = XHamsterEmbedIE._extract_urls(webpage)\\n1984 :         if xhamster_urls:\\n1985 :             return _playlist_from_matches(xhamster_urls, ie='XHamsterEmbed')\\n1986 : \\n1987 :         # Look for embedded TNAFlixNetwork player\\n1988 :         tnaflix_urls = TNAFlixNetworkEmbedIE._extract_urls(webpage)\\n1989 :         if tnaflix_urls:\\n1990 :             return _playlist_from_matches(tnaflix_urls, ie=TNAFlixNetworkEmbedIE.ie_key())\\n1991 : \\n1992 :         # Look for embedded Tvigle player\\n1993 :         mobj = re.search(\\n1994 :             r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>(?:https?:)?//cloud\\\\.tvigle\\\\.ru/video/.+?)\\\\1', webpage)\\n1995 :         if mobj is not None:\\n1996 :             return self.url_result(mobj.group('url'), 'Tvigle')\\n1997 : \\n1998 :         # Look for embedded TED player\\n1999 :         mobj = re.search(\\n2000 :             r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>https?://embed(?:-ssl)?\\\\.ted\\\\.com/.+?)\\\\1', webpage)\\n2001 :         if mobj is not None:\\n2002 :             return self.url_result(mobj.group('url'), 'TED')\\n2003 : \\n2004 :         # Look for embedded Ustream videos\\n2005 :         mobj = re.search(\\n2006 :             r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>http://www\\\\.ustream\\\\.tv/embed/.+?)\\\\1', webpage)\\n2007 :         if mobj is not None:\\n2008 :             return self.url_result(mobj.group('url'), 'Ustream')\\n2009 : \\n2010 :         # Look for embedded arte.tv player\\n2011 :         mobj = re.search(\\n2012 :             r'<(?:script|iframe) [^>]*?src=\\\"(?P<url>http://www\\\\.arte\\\\.tv/(?:playerv2/embed|arte_vp/index)[^\\\"]+)\\\"',\\n2013 :             webpage)\\n2014 :         if mobj is not None:\\n2015 :             return self.url_result(mobj.group('url'), 'ArteTVEmbed')\\n2016 : \\n2017 :         # Look for embedded francetv player\\n2018 :         mobj = re.search(\\n2019 :             r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>(?:https?://)?embed\\\\.francetv\\\\.fr/\\\\?ue=.+?)\\\\1',\\n2020 :             webpage)\\n2021 :         if mobj is not None:\\n2022 :             return self.url_result(mobj.group('url'))\\n2023 : \\n2024 :         # Look for embedded smotri.com player\\n2025 :         smotri_url = SmotriIE._extract_url(webpage)\\n2026 :         if smotri_url:\\n2027 :             return self.url_result(smotri_url, 'Smotri')\\n2028 : \\n2029 :         # Look for embedded Myvi.ru player\\n2030 :         myvi_url = MyviIE._extract_url(webpage)\\n2031 :         if myvi_url:\\n2032 :             return self.url_result(myvi_url)\\n2033 : \\n2034 :         # Look for embedded soundcloud player\\n2035 :         soundcloud_urls = SoundcloudIE._extract_urls(webpage)\\n2036 :         if soundcloud_urls:\\n2037 :             return _playlist_from_matches(soundcloud_urls, getter=unescapeHTML, ie=SoundcloudIE.ie_key())\\n2038 : \\n2039 :         # Look for embedded mtvservices player\\n2040 :         mtvservices_url = MTVServicesEmbeddedIE._extract_url(webpage)\\n2041 :         if mtvservices_url:\\n2042 :             return self.url_result(mtvservices_url, ie='MTVServicesEmbedded')\\n2043 : \\n2044 :         # Look for embedded yahoo player\\n2045 :         mobj = re.search(\\n2046 :             r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>https?://(?:screen|movies)\\\\.yahoo\\\\.com/.+?\\\\.html\\\\?format=embed)\\\\1',\\n2047 :             webpage)\\n2048 :         if mobj is not None:\\n2049 :             return self.url_result(mobj.group('url'), 'Yahoo')\\n2050 : \\n2051 :         # Look for embedded sbs.com.au player\\n2052 :         mobj = re.search(\\n2053 :             r'''(?x)\\n2054 :             (?:\\n2055 :                 <meta\\\\s+property=\\\"og:video\\\"\\\\s+content=|\\n2056 :                 <iframe[^>]+?src=\\n2057 :             )\\n2058 :             ([\\\"\\\\'])(?P<url>https?://(?:www\\\\.)?sbs\\\\.com\\\\.au/ondemand/video/.+?)\\\\1''',\\n2059 :             webpage)\\n2060 :         if mobj is not None:\\n2061 :             return self.url_result(mobj.group('url'), 'SBS')\\n2062 : \\n2063 :         # Look for embedded Cinchcast player\\n2064 :         mobj = re.search(\\n2065 :             r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>https?://player\\\\.cinchcast\\\\.com/.+?)\\\\1',\\n2066 :             webpage)\\n2067 :         if mobj is not None:\\n2068 :             return self.url_result(mobj.group('url'), 'Cinchcast')\\n2069 : \\n2070 :         mobj = re.search(\\n2071 :             r'<iframe[^>]+?src=([\\\"\\\\'])(?P<url>https?://m(?:lb)?\\\\.mlb\\\\.com/shared/video/embed/embed\\\\.html\\\\?.+?)\\\\1',\\n2072 :             webpage)\\n2073 :         if not mobj:\\n2074 :             mobj = re.search(\\n2075 :                 r'data-video-link=[\\\"\\\\'](?P<url>http://m.mlb.com/video/[^\\\"\\\\']+)',\\n2076 :                 webpage)\\n2077 :         if mobj is not None:\\n2078 :             return self.url_result(mobj.group('url'), 'MLB')\\n2079 : \\n2080 :         mobj = re.search(\\n2081 :             r'<(?:iframe|script)[^>]+?src=([\\\"\\\\'])(?P<url>%s)\\\\1' % CondeNastIE.EMBED_URL,\\n2082 :             webpage)\\n2083 :         if mobj is not None:\\n2084 :             return self.url_result(self._proto_relative_url(mobj.group('url'), scheme='http:'), 'CondeNast')\\n2085 : \\n2086 :         mobj = re.search(\\n2087 :             r'<iframe[^>]+src=\\\"(?P<url>https?://(?:new\\\\.)?livestream\\\\.com/[^\\\"]+/player[^\\\"]+)\\\"',\\n2088 :             webpage)\\n2089 :         if mobj is not None:\\n2090 :             return self.url_result(mobj.group('url'), 'Livestream')\\n2091 : \\n2092 :         # Look for Zapiks embed\\n2093 :         mobj = re.search(\\n2094 :             r'<iframe[^>]+src=\\\"(?P<url>https?://(?:www\\\\.)?zapiks\\\\.fr/index\\\\.php\\\\?.+?)\\\"', webpage)\\n2095 :         if mobj is not None:\\n2096 :             return self.url_result(mobj.group('url'), 'Zapiks')\\n2097 : \\n2098 :         # Look for Kaltura embeds\\n2099 :         kaltura_url = KalturaIE._extract_url(webpage)\\n2100 :         if kaltura_url:\\n2101 :             return self.url_result(smuggle_url(kaltura_url, {'source_url': url}), KalturaIE.ie_key())\\n2102 : \\n2103 :         # Look for Eagle.Platform embeds\\n2104 :         eagleplatform_url = EaglePlatformIE._extract_url(webpage)\\n2105 :         if eagleplatform_url:\\n2106 :             return self.url_result(eagleplatform_url, EaglePlatformIE.ie_key())\\n2107 : \\n2108 :         # Look for ClipYou (uses Eagle.Platform) embeds\\n2109 :         mobj = re.search(\\n2110 :             r'<iframe[^>]+src=\\\"https?://(?P<host>media\\\\.clipyou\\\\.ru)/index/player\\\\?.*\\\\brecord_id=(?P<id>\\\\d+).*\\\"', webpage)\\n2111 :         if mobj is not None:\\n2112 :             return self.url_result('eagleplatform:%(host)s:%(id)s' % mobj.groupdict(), 'EaglePlatform')\\n2113 : \\n2114 :         # Look for Pladform embeds\\n2115 :         pladform_url = PladformIE._extract_url(webpage)\\n2116 :         if pladform_url:\\n2117 :             return self.url_result(pladform_url)\\n2118 : \\n2119 :         # Look for Videomore embeds\\n2120 :         videomore_url = VideomoreIE._extract_url(webpage)\\n2121 :         if videomore_url:\\n2122 :             return self.url_result(videomore_url)\\n2123 : \\n2124 :         # Look for Playwire embeds\\n2125 :         mobj = re.search(\\n2126 :             r'<script[^>]+data-config=([\\\"\\\\'])(?P<url>(?:https?:)?//config\\\\.playwire\\\\.com/.+?)\\\\1', webpage)\\n2127 :         if mobj is not None:\\n2128 :             return self.url_result(mobj.group('url'))\\n2129 : \\n2130 :         # Look for 5min embeds\\n2131 :         mobj = re.search(\\n2132 :             r'<meta[^>]+property=\\\"og:video\\\"[^>]+content=\\\"https?://embed\\\\.5min\\\\.com/(?P<id>[0-9]+)/?', webpage)\\n2133 :         if mobj is not None:\\n2134 :             return self.url_result('5min:%s' % mobj.group('id'), 'FiveMin')\\n2135 : \\n2136 :         # Look for Crooks and Liars embeds\\n2137 :         mobj = re.search(\\n2138 :             r'<(?:iframe[^>]+src|param[^>]+value)=([\\\"\\\\'])(?P<url>(?:https?:)?//embed\\\\.crooksandliars\\\\.com/(?:embed|v)/.+?)\\\\1', webpage)\\n2139 :         if mobj is not None:\\n2140 :             return self.url_result(mobj.group('url'))\\n2141 : \\n2142 :         # Look for NBC Sports VPlayer embeds\\n2143 :         nbc_sports_url = NBCSportsVPlayerIE._extract_url(webpage)\\n2144 :         if nbc_sports_url:\\n2145 :             return self.url_result(nbc_sports_url, 'NBCSportsVPlayer')\\n2146 : \\n2147 :         # Look for NBC News embeds\\n2148 :         nbc_news_embed_url = re.search(\\n2149 :             r'<iframe[^>]+src=([\\\"\\\\'])(?P<url>(?:https?:)?//www\\\\.nbcnews\\\\.com/widget/video-embed/[^\\\"\\\\']+)\\\\1', webpage)\\n2150 :         if nbc_news_embed_url:\\n2151 :             return self.url_result(nbc_news_embed_url.group('url'), 'NBCNews')\\n2152 : \\n2153 :         # Look for Google Drive embeds\\n2154 :         google_drive_url = GoogleDriveIE._extract_url(webpage)\\n2155 :         if google_drive_url:\\n2156 :             return self.url_result(google_drive_url, 'GoogleDrive')\\n2157 : \\n2158 :         # Look for UDN embeds\\n2159 :         mobj = re.search(\\n2160 :             r'<iframe[^>]+src=\\\"(?P<url>%s)\\\"' % UDNEmbedIE._PROTOCOL_RELATIVE_VALID_URL, webpage)\\n2161 :         if mobj is not None:\\n2162 :             return self.url_result(\\n2163 :                 compat_urlparse.urljoin(url, mobj.group('url')), 'UDNEmbed')\\n2164 : \\n2165 :         # Look for Senate ISVP iframe\\n2166 :         senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)\\n2167 :         if senate_isvp_url:\\n2168 :             return self.url_result(senate_isvp_url, 'SenateISVP')\\n2169 : \\n2170 :         # Look for Dailymotion Cloud videos\\n2171 :         dmcloud_url = DailymotionCloudIE._extract_dmcloud_url(webpage)\\n2172 :         if dmcloud_url:\\n2173 :             return self.url_result(dmcloud_url, 'DailymotionCloud')\\n2174 : \\n2175 :         # Look for OnionStudios embeds\\n2176 :         onionstudios_url = OnionStudiosIE._extract_url(webpage)\\n2177 :         if onionstudios_url:\\n2178 :             return self.url_result(onionstudios_url)\\n2179 : \\n2180 :         # Look for ViewLift embeds\\n2181 :         viewlift_url = ViewLiftEmbedIE._extract_url(webpage)\\n2182 :         if viewlift_url:\\n2183 :             return self.url_result(viewlift_url)\\n2184 : \\n2185 :         # Look for JWPlatform embeds\\n2186 :         jwplatform_url = JWPlatformIE._extract_url(webpage)\\n2187 :         if jwplatform_url:\\n2188 :             return self.url_result(jwplatform_url, 'JWPlatform')\\n2189 : \\n2190 :         # Look for ScreenwaveMedia embeds\\n2191 :         mobj = re.search(ScreenwaveMediaIE.EMBED_PATTERN, webpage)\\n2192 :         if mobj is not None:\\n2193 :             return self.url_result(unescapeHTML(mobj.group('url')), 'ScreenwaveMedia')\\n2194 : \\n2195 :         # Look for Digiteka embeds\\n2196 :         digiteka_url = DigitekaIE._extract_url(webpage)\\n2197 :         if digiteka_url:\\n2198 :             return self.url_result(self._proto_relative_url(digiteka_url), DigitekaIE.ie_key())\\n2199 : \\n2200 :         # Look for Arkena embeds\\n2201 :         arkena_url = ArkenaIE._extract_url(webpage)\\n2202 :         if arkena_url:\\n2203 :             return self.url_result(arkena_url, ArkenaIE.ie_key())\\n2204 : \\n2205 :         # Look for Limelight embeds\\n2206 :         mobj = re.search(r'LimelightPlayer\\\\.doLoad(Media|Channel|ChannelList)\\\\([\\\"\\\\'](?P<id>[a-z0-9]{32})', webpage)\\n2207 :         if mobj:\\n2208 :             lm = {\\n2209 :                 'Media': 'media',\\n2210 :                 'Channel': 'channel',\\n2211 :                 'ChannelList': 'channel_list',\\n2212 :             }\\n2213 :             return self.url_result('limelight:%s:%s' % (\\n2214 :                 lm[mobj.group(1)], mobj.group(2)), 'Limelight%s' % mobj.group(1), mobj.group(2))\\n2215 : \\n2216 :         # Look for AdobeTVVideo embeds\\n2217 :         mobj = re.search(\\n2218 :             r'<iframe[^>]+src=[\\\\'\\\"]((?:https?:)?//video\\\\.tv\\\\.adobe\\\\.com/v/\\\\d+[^\\\"]+)[\\\\'\\\"]',\\n2219 :             webpage)\\n2220 :         if mobj is not None:\\n2221 :             return self.url_result(\\n2222 :                 self._proto_relative_url(unescapeHTML(mobj.group(1))),\\n2223 :                 'AdobeTVVideo')\\n2224 : \\n2225 :         # Look for Vine embeds\\n2226 :         mobj = re.search(\\n2227 :             r'<iframe[^>]+src=[\\\\'\\\"]((?:https?:)?//(?:www\\\\.)?vine\\\\.co/v/[^/]+/embed/(?:simple|postcard))',\\n2228 :             webpage)\\n2229 :         if mobj is not None:\\n2230 :             return self.url_result(\\n2231 :                 self._proto_relative_url(unescapeHTML(mobj.group(1))), 'Vine')\\n2232 : \\n2233 :         # Look for VODPlatform embeds\\n2234 :         mobj = re.search(\\n2235 :             r'<iframe[^>]+src=[\\\\'\\\"]((?:https?:)?//(?:www\\\\.)?vod-platform\\\\.net/embed/[^/?#]+)',\\n2236 :             webpage)\\n2237 :         if mobj is not None:\\n2238 :             return self.url_result(\\n2239 :                 self._proto_relative_url(unescapeHTML(mobj.group(1))), 'VODPlatform')\\n2240 : \\n2241 :         # Look for Instagram embeds\\n2242 :         instagram_embed_url = InstagramIE._extract_embed_url(webpage)\\n2243 :         if instagram_embed_url is not None:\\n2244 :             return self.url_result(\\n2245 :                 self._proto_relative_url(instagram_embed_url), InstagramIE.ie_key())\\n2246 : \\n2247 :         # Look for LiveLeak embeds\\n2248 :         liveleak_url = LiveLeakIE._extract_url(webpage)\\n2249 :         if liveleak_url:\\n2250 :             return self.url_result(liveleak_url, 'LiveLeak')\\n2251 : \\n2252 :         # Look for 3Q SDN embeds\\n2253 :         threeqsdn_url = ThreeQSDNIE._extract_url(webpage)\\n2254 :         if threeqsdn_url:\\n2255 :             return {\\n2256 :                 '_type': 'url_transparent',\\n2257 :                 'ie_key': ThreeQSDNIE.ie_key(),\\n2258 :                 'url': self._proto_relative_url(threeqsdn_url),\\n2259 :                 'title': video_title,\\n2260 :                 'description': video_description,\\n2261 :                 'thumbnail': video_thumbnail,\\n2262 :                 'uploader': video_uploader,\\n2263 :             }\\n2264 : \\n2265 :         # Look for VBOX7 embeds\\n2266 :         vbox7_url = Vbox7IE._extract_url(webpage)\\n2267 :         if vbox7_url:\\n2268 :             return self.url_result(vbox7_url, Vbox7IE.ie_key())\\n2269 : \\n2270 :         # Look for DBTV embeds\\n2271 :         dbtv_urls = DBTVIE._extract_urls(webpage)\\n2272 :         if dbtv_urls:\\n2273 :             return _playlist_from_matches(dbtv_urls, ie=DBTVIE.ie_key())\\n2274 : \\n2275 :         # Looking for http://schema.org/VideoObject\\n2276 :         json_ld = self._search_json_ld(\\n2277 :             webpage, video_id, default={}, expected_type='VideoObject')\\n2278 :         if json_ld.get('url'):\\n2279 :             info_dict.update({\\n2280 :                 'title': video_title or info_dict['title'],\\n2281 :                 'description': video_description,\\n2282 :                 'thumbnail': video_thumbnail,\\n2283 :                 'age_limit': age_limit\\n2284 :             })\\n2285 :             info_dict.update(json_ld)\\n2286 :             return info_dict\\n2287 : \\n2288 :         def check_video(vurl):\\n2289 :             if YoutubeIE.suitable(vurl):\\n2290 :                 return True\\n2291 :             vpath = compat_urlparse.urlparse(vurl).path\\n2292 :             vext = determine_ext(vpath)\\n2293 :             return '.' in vpath and vext not in ('swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml')\\n2294 : \\n2295 :         def filter_video(urls):\\n2296 :             return list(filter(check_video, urls))\\n2297 : \\n2298 :         # Start with something easy: JW Player in SWFObject\\n2299 :         found = filter_video(re.findall(r'flashvars: [\\\\'\\\"](?:.*&)?file=(http[^\\\\'\\\"&]*)', webpage))\\n2300 :         if not found:\\n2301 :             # Look for gorilla-vid style embedding\\n2302 :             found = filter_video(re.findall(r'''(?sx)\\n2303 :                 (?:\\n2304 :                     jw_plugins|\\n2305 :                     JWPlayerOptions|\\n2306 :                     jwplayer\\\\s*\\\\(\\\\s*[\\\"'][^'\\\"]+[\\\"']\\\\s*\\\\)\\\\s*\\\\.setup\\n2307 :                 )\\n2308 :                 .*?\\n2309 :                 ['\\\"]?file['\\\"]?\\\\s*:\\\\s*[\\\"\\\\'](.*?)[\\\"\\\\']''', webpage))\\n2310 :         if not found:\\n2311 :             # Broaden the search a little bit\\n2312 :             found = filter_video(re.findall(r'[^A-Za-z0-9]?(?:file|source)=(http[^\\\\'\\\"&]*)', webpage))\\n2313 :         if not found:\\n2314 :             # Broaden the findall a little bit: JWPlayer JS loader\\n2315 :             found = filter_video(re.findall(\\n2316 :                 r'[^A-Za-z0-9]?(?:file|video_url)[\\\"\\\\']?:\\\\s*[\\\"\\\\'](http(?![^\\\\'\\\"]+\\\\.[0-9]+[\\\\'\\\"])[^\\\\'\\\"]+)[\\\"\\\\']', webpage))\\n2317 :         if not found:\\n2318 :             # Flow player\\n2319 :             found = filter_video(re.findall(r'''(?xs)\\n2320 :                 flowplayer\\\\(\\\"[^\\\"]+\\\",\\\\s*\\n2321 :                     \\\\{[^}]+?\\\\}\\\\s*,\\n2322 :                     \\\\s*\\\\{[^}]+? [\\\"']?clip[\\\"']?\\\\s*:\\\\s*\\\\{\\\\s*\\n2323 :                         [\\\"']?url[\\\"']?\\\\s*:\\\\s*[\\\"']([^\\\"']+)[\\\"']\\n2324 :             ''', webpage))\\n2325 :         if not found:\\n2326 :             # Cinerama player\\n2327 :             found = re.findall(\\n2328 :                 r\\\"cinerama\\\\.embedPlayer\\\\(\\\\s*\\\\'[^']+\\\\',\\\\s*'([^']+)'\\\", webpage)\\n2329 :         if not found:\\n2330 :             # Try to find twitter cards info\\n2331 :             # twitter:player:stream should be checked before twitter:player since\\n2332 :             # it is expected to contain a raw stream (see\\n2333 :             # https://dev.twitter.com/cards/types/player#On_twitter.com_via_desktop_browser)\\n2334 :             found = filter_video(re.findall(\\n2335 :                 r'<meta (?:property|name)=\\\"twitter:player:stream\\\" (?:content|value)=\\\"(.+?)\\\"', webpage))\\n2336 :         if not found:\\n2337 :             # We look for Open Graph info:\\n2338 :             # We have to match any number spaces between elements, some sites try to align them (eg.: statigr.am)\\n2339 :             m_video_type = re.findall(r'<meta.*?property=\\\"og:video:type\\\".*?content=\\\"video/(.*?)\\\"', webpage)\\n2340 :             # We only look in og:video if the MIME type is a video, don't try if it's a Flash player:\\n2341 :             if m_video_type is not None:\\n2342 :                 found = filter_video(re.findall(r'<meta.*?property=\\\"og:video\\\".*?content=\\\"(.*?)\\\"', webpage))\\n2343 :         if not found:\\n2344 :             # HTML5 video\\n2345 :             found = re.findall(r'(?s)<(?:video|audio)[^<]*(?:>.*?<source[^>]*)?\\\\s+src=[\\\"\\\\'](.*?)[\\\"\\\\']', webpage)\\n2346 :         if not found:\\n2347 :             REDIRECT_REGEX = r'[0-9]{,2};\\\\s*(?:URL|url)=\\\\'?([^\\\\'\\\"]+)'\\n2348 :             found = re.search(\\n2349 :                 r'(?i)<meta\\\\s+(?=(?:[a-z-]+=\\\"[^\\\"]+\\\"\\\\s+)*http-equiv=\\\"refresh\\\")'\\n2350 :                 r'(?:[a-z-]+=\\\"[^\\\"]+\\\"\\\\s+)*?content=\\\"%s' % REDIRECT_REGEX,\\n2351 :                 webpage)\\n2352 :             if not found:\\n2353 :                 # Look also in Refresh HTTP header\\n2354 :                 refresh_header = head_response.headers.get('Refresh')\\n2355 :                 if refresh_header:\\n2356 :                     # In python 2 response HTTP headers are bytestrings\\n2357 :                     if sys.version_info < (3, 0) and isinstance(refresh_header, str):\\n2358 :                         refresh_header = refresh_header.decode('iso-8859-1')\\n2359 :                     found = re.search(REDIRECT_REGEX, refresh_header)\\n2360 :             if found:\\n2361 :                 new_url = compat_urlparse.urljoin(url, unescapeHTML(found.group(1)))\\n2362 :                 self.report_following_redirect(new_url)\\n2363 :                 return {\\n2364 :                     '_type': 'url',\\n2365 :                     'url': new_url,\\n2366 :                 }\\n2367 : \\n2368 :         if not found:\\n2369 :             # twitter:player is a https URL to iframe player that may or may not\\n2370 :             # be supported by youtube-dl thus this is checked the very last (see\\n2371 :             # https://dev.twitter.com/cards/types/player#On_twitter.com_via_desktop_browser)\\n2372 :             embed_url = self._html_search_meta('twitter:player', webpage, default=None)\\n2373 :             if embed_url:\\n2374 :                 return self.url_result(embed_url)\\n2375 : \\n2376 :         if not found:\\n2377 :             raise UnsupportedError(url)\\n2378 : \\n2379 :         entries = []\\n2380 :         for video_url in orderedSet(found):\\n2381 :             video_url = unescapeHTML(video_url)\\n2382 :             video_url = video_url.replace('\\\\\\\\/', '/')\\n2383 :             video_url = compat_urlparse.urljoin(url, video_url)\\n2384 :             video_id = compat_urllib_parse_unquote(os.path.basename(video_url))\\n2385 : \\n2386 :             # Sometimes, jwplayer extraction will result in a YouTube URL\\n2387 :             if YoutubeIE.suitable(video_url):\\n2388 :                 entries.append(self.url_result(video_url, 'Youtube'))\\n2389 :                 continue\\n2390 : \\n2391 :             # here's a fun little line of code for you:\\n2392 :             video_id = os.path.splitext(video_id)[0]\\n2393 : \\n2394 :             entry_info_dict = {\\n2395 :                 'id': video_id,\\n2396 :                 'uploader': video_uploader,\\n2397 :                 'title': video_title,\\n2398 :                 'age_limit': age_limit,\\n2399 :             }\\n2400 : \\n2401 :             ext = determine_ext(video_url)\\n2402 :             if ext == 'smil':\\n2403 :                 entry_info_dict['formats'] = self._extract_smil_formats(video_url, video_id)\\n2404 :             elif ext == 'xspf':\\n2405 :                 return self.playlist_result(self._extract_xspf_playlist(video_url, video_id), video_id)\\n2406 :             elif ext == 'm3u8':\\n2407 :                 entry_info_dict['formats'] = self._extract_m3u8_formats(video_url, video_id, ext='mp4')\\n2408 :             elif ext == 'mpd':\\n2409 :                 entry_info_dict['formats'] = self._extract_mpd_formats(video_url, video_id)\\n2410 :             elif ext == 'f4m':\\n2411 :                 entry_info_dict['formats'] = self._extract_f4m_formats(video_url, video_id)\\n2412 :             else:\\n2413 :                 entry_info_dict['url'] = video_url\\n2414 : \\n2415 :             if entry_info_dict.get('formats'):\\n2416 :                 self._sort_formats(entry_info_dict['formats'])\\n2417 : \\n2418 :             entries.append(entry_info_dict)\\n2419 : \\n2420 :         if len(entries) == 1:\\n2421 :             return entries[0]\\n2422 :         else:\\n2423 :             for num, e in enumerate(entries, start=1):\\n2424 :                 # 'url' results don't have a title\\n2425 :                 if e.get('title') is not None:\\n2426 :                     e['title'] = '%s (%d)' % (e['title'], num)\\n2427 :             return {\\n2428 :                 '_type': 'playlist',\\n2429 :                 'entries': entries,\\n2430 :             }\""}], "interaction_records": {"step_histories": [{"prompt_messages": ["m1", "m2", "m3", "m4"], "response_message": "m5"}, {"prompt_messages": ["m1", "m2", "m3", "m4", "m5", "m6"], "response_message": "m7"}, {"prompt_messages": ["m1", "m2", "m3", "m4", "m5", "m6", "m7", "m8"], "response_message": "m9"}, {"prompt_messages": ["m1", "m2", "m3", "m4", "m5", "m6", "m7", "m8", "m9", "m10"], "response_message": "m11"}, {"prompt_messages": ["m1", "m2", "m3", "m4", "m5", "m6", "m7", "m8", "m9", "m10", "m11", "m12"], "response_message": "m13"}, {"prompt_messages": ["m1", "m2", "m3", "m4", "m5", "m6", "m7", "m8", "m9", "m10", "m11", "m12", "m13", "m14"], "response_message": "m15"}], "mid_to_message": {"m1": {"role": "system", "content": "You are a debugging assistant. You will be presented with a failing test, and tools (functions) to access the source code of the system under test (SUT). Your task is to provide a step-by-step explanation of how the bug occurred, based on the failing test and the information you retrieved using tests about the SUT. You will be given 9 chances to interact with functions to gather relevant information. An example answer would look like follows.\n\nTitle: Diagnosis of test `testGenerateURLFragment`\nDetails: The test `testGenerateURLFragment` checks whether HTML entities such as `&quot;` are correctly escaped to their corresponding character by the `StandardToolTipTagFragmentGenerator.generateToolTipFragment` method. However, the test failure indicates that this is not the case. Following the execution path, we find that `StandardToolTipTagFragmentGenerator.generateToolTipFragment` is not escaping any HTML code; instead, it is using its input `toolTipText` as is. Consequently, un-escaped strings are being returned, which leads to the error demonstrated by the test.\n\nAfter providing this diagnosis, you will be prompted to suggest which methods would be the best locations to be fixed. The answers should be in the form of `ClassName.MethodName(ArgType1, ArgType2, ...)` without commentary (one per line), as your answer will be automatically processed before finally being presented to the user."}, "m2": {"role": "user", "content": "The test `['test.test_utils.TestUtil.test_js_to_json_realworld(self)']` failed.\nThe test looks like:\n\n```python\n680 :     def test_js_to_json_realworld(self):\n681 :         inp = '''{\n682 :             'clip':{'provider':'pseudo'}\n683 :         }'''\n684 :         self.assertEqual(js_to_json(inp), '''{\n688 : \n689 :         inp = '''{\n690 :             'playlist':[{'controls':{'all':null}}]\n691 :         }'''\n692 :         self.assertEqual(js_to_json(inp), '''{\n696 :         inp = '''\"The CW\\\\'s \\\\'Crazy Ex-Girlfriend\\\\'\"'''\n697 :         self.assertEqual(js_to_json(inp), '''\"The CW's 'Crazy Ex-Girlfriend'\"''')\n699 :         inp = '\"SAND Number: SAND 2013-7800P\\\\nPresenter: Tom Russo\\\\nHabanero Software Training - Xyce Software\\\\nXyce, Sandia\\\\u0027s\"'\n700 :         json_code = js_to_json(inp)\n701 :         self.assertEqual(json.loads(json_code), json.loads(inp))\n703 :         inp = '''{\n704 :             0:{src:'skipped', type: 'application/dash+xml'},\n705 :             1:{src:'skipped', type: 'application/vnd.apple.mpegURL'},\n706 :         }'''\n707 :         self.assertEqual(js_to_json(inp), '''{\n712 :         inp = '''{\"foo\":101}'''\n713 :         self.assertEqual(js_to_json(inp), '''{\"foo\":101}''')\n715 :         inp = '''{\"duration\": \"00:01:07\"}'''\n716 :         self.assertEqual(js_to_json(inp), '''{\"duration\": \"00:01:07\"}''') # error occurred here\n```\n\nIt failed with the following error message and call stack:\n\n```\nAssertionError: '{\"duration\": 0}' != '{\"duration\": \"00:01:07\"}'\nTraceback (most recent call last):\n  File \"/home/user/BugsInPy/temp/projects/youtube-dl/test/test_utils.py\", line 716, in test_js_to_json_realworld\n    self.assertEqual(js_to_json(inp), '''{\"duration\": \"00:01:07\"}''')\n```\n\nStart by calling the `get_covered_packages` function."}, "m3": {"role": "assistant", "content": null, "function_call": {"name": "get_covered_packages", "arguments": "{}"}}, "m4": {"role": "function", "name": "get_covered_packages", "content": "[\"youtube_dl.extractor.tvc\", \"youtube_dl.YoutubeDL\", \"youtube_dl.extractor.lynda\", \"youtube_dl.extractor.appletrailers\", \"youtube_dl.extractor.facebook\", \"youtube_dl.extractor.bokecc\", \"youtube_dl.extractor.generic\", \"youtube_dl.extractor.viki\", \"youtube_dl.extractor.microsoftvirtualacademy\", \"youtube_dl.extractor.leeco\", \"youtube_dl.extractor.dbtv\", \"youtube_dl.extractor.animeondemand\", \"youtube_dl.extractor.dailymotion\", \"youtube_dl.extractor.arkena\", \"youtube_dl.postprocessor.ffmpeg\", \"youtube_dl.extractor.aenetworks\", \"youtube_dl.extractor.pbs\", \"youtube_dl.extractor\", \"youtube_dl.extractor.iqiyi\", \"youtube_dl.extractor.abc7news\", \"youtube_dl.extractor.br\", \"youtube_dl.extractor.mtv\", \"youtube_dl.jsinterp\", \"youtube_dl.extractor.twitch\", \"youtube_dl.extractor.tnaflix\", \"youtube_dl\", \"youtube_dl.extractor.nrk\", \"youtube_dl.extractor.udemy\", \"youtube_dl.extractor.instagram\", \"youtube_dl.extractor.kaltura\", \"youtube_dl.extractor.acast\", \"youtube_dl.extractor.npo\", \"youtube_dl.extractor.common\", \"youtube_dl.extractor.senateisvp\", \"youtube_dl.extractor.arte\", \"youtube_dl.extractor.pladform\", \"youtube_dl.extractor.svt\", \"youtube_dl.extractor.francetv\", \"youtube_dl.extractor.jwplatform\", \"youtube_dl.extractor.baidu\", \"youtube_dl.extractor.vimeo\", \"youtube_dl.extractor.daum\", \"youtube_dl.extractor.adultswim\", \"youtube_dl.extractor.xhamster\", \"youtube_dl.extractor.r7\", \"youtube_dl.extractor.youporn\", \"youtube_dl.extractor.tvplay\", \"youtube_dl.compat\", \"youtube_dl.extractor.tagesschau\", \"youtube_dl.extractor.democracynow\", \"youtube_dl.downloader.common\", \"youtube_dl.extractor.youtube\", \"youtube_dl.extractor.adobetv\", \"youtube_dl.extractor.rutv\", \"youtube_dl.extractor.bbc\", \"youtube_dl.extractor.theplatform\", \"youtube_dl.cache\", \"youtube_dl.utils\", \"youtube_dl.extractor.vimple\", \"youtube_dl.extractor.tunein\", \"youtube_dl.postprocessor.common\", \"youtube_dl.extractor.eagleplatform\", \"youtube_dl.extractor.walla\", \"youtube_dl.extractor.soundcloud\", \"youtube_dl.extractor.smotri\", \"youtube_dl.extractor.ceskatelevize\", \"youtube_dl.extractor.globo\", \"youtube_dl.extractor.ted\", \"youtube_dl.extractor.videomore\", \"youtube_dl.extractor.digiteka\", \"youtube_dl.extractor.washingtonpost\", \"youtube_dl.extractor.brightcove\", \"youtube_dl.extractor.abcnews\", \"youtube_dl.extractor.cbc\", \"youtube_dl.downloader.http\", \"youtube_dl.postprocessor.metadatafromtitle\", \"youtube_dl.aes\", \"youtube_dl.extractor.rai\", \"youtube_dl.downloader\", \"youtube_dl.extractor.abc\", \"youtube_dl.extractor.amp\", \"youtube_dl.extractor.anvato\", \"youtube_dl.extractor.nbc\"]"}, "m5": {"role": "assistant", "content": "The failing test `test_js_to_json_realworld` covers classes from various packages in the program under test. Here are the packages covered by the failing test:\n\n1. `youtube_dl.extractor.tvc`\n2. `youtube_dl.YoutubeDL`\n3. `youtube_dl.extractor.lynda`\n4. `youtube_dl.extractor.appletrailers`\n5. `youtube_dl.extractor.facebook`\n6. `youtube_dl.extractor.bokecc`\n7. `youtube_dl.extractor.generic`\n8. `youtube_dl.extractor.viki`\n9. `youtube_dl.extractor.microsoftvirtualacademy`\n10. `youtube_dl.extractor.leeco`\n11. `youtube_dl.extractor.dbtv`\n12. `youtube_dl.extractor.animeondemand`\n13. `youtube_dl.extractor.dailymotion`\n14. `youtube_dl.extractor.arkena`\n15. `youtube_dl.postprocessor.ffmpeg`\n16. `youtube_dl.extractor.aenetworks`\n17. `youtube_dl.extractor.pbs`\n18. `youtube_dl.extractor`\n19. `youtube_dl.extractor.iqiyi`\n20. `youtube_dl.extractor.abc7news`\n21. `youtube_dl.extractor.br`\n22. `youtube_dl.extractor.mtv`\n23. `youtube_dl.jsinterp`\n24. `youtube_dl.extractor.twitch`\n25. `youtube_dl.extractor.tnaflix`\n26. `youtube_dl`\n27. `youtube_dl.extractor.nrk`\n28. `youtube_dl.extractor.udemy`\n29. `youtube_dl.extractor.instagram`\n30. `youtube_dl.extractor.kaltura`\n31. `youtube_dl.extractor.acast`\n32. `youtube_dl.extractor.npo`\n33. `youtube_dl.extractor.common`\n34. `youtube_dl.extractor.senateisvp`\n35. `youtube_dl.extractor.arte`\n36. `youtube_dl.extractor.pladform`\n37. `youtube_dl.extractor.svt`\n38. `youtube_dl.extractor.francetv`\n39. `youtube_dl.extractor.jwplatform`\n40. `youtube_dl.extractor.baidu`\n41. `youtube_dl.extractor.vimeo`\n42. `youtube_dl.extractor.daum`\n43. `youtube_dl.extractor.adultswim`\n44. `youtube_dl.extractor.xhamster`\n45. `youtube_dl.extractor.r7`\n46. `youtube_dl.extractor.youporn`\n47. `youtube_dl.extractor.tvplay`\n48. `youtube_dl.compat`\n49. `youtube_dl.extractor.tagesschau`\n50. `youtube_dl.extractor.democracynow`\n51. `youtube_dl.downloader.common`\n52. `youtube_dl.extractor.youtube`\n53. `youtube_dl.extractor.adobetv`\n54. `youtube_dl.extractor.rutv`\n55. `youtube_dl.extractor.bbc`\n56. `youtube_dl.extractor.theplatform`\n57. `youtube_dl.cache`\n58. `youtube_dl.utils`\n59. `youtube_dl.extractor.vimple`\n60. `youtube_dl.extractor.tunein`\n61. `youtube_dl.postprocessor.common`\n62. `youtube_dl.extractor.eagleplatform`\n63. `youtube_dl.extractor.walla`\n64. `youtube_dl.extractor.soundcloud`\n65. `youtube_dl.extractor.smotri`\n66. `youtube_dl.extractor.ceskatelevize`\n67. `youtube_dl.extractor.globo`\n68. `youtube_dl.extractor.ted`\n69. `youtube_dl.extractor.videomore`\n70. `youtube_dl.extractor.digiteka`\n71. `youtube_dl.extractor.washingtonpost`\n72. `youtube_dl.extractor.brightcove`\n73. `youtube_dl.extractor.abcnews`\n74. `youtube_dl.extractor.cbc`\n75. `youtube_dl.downloader.http`\n76. `youtube_dl.postprocessor.metadatafromtitle`\n77. `youtube_dl.aes`\n78. `youtube_dl.extractor.rai`\n79. `youtube_dl.downloader`\n80. `youtube_dl.extractor.abc`\n81. `youtube_dl.extractor.amp`\n82. `youtube_dl.extractor.anvato`\n83. `youtube_dl.extractor.nbc`\n\nLet's continue investigating by retrieving the classes covered by failing tests for the package `youtube_dl.extractor.generic`.", "function_call": {"name": "get_failing_tests_covered_classes", "arguments": "{\n  \"package_name\": \"youtube_dl.extractor.generic\"\n}"}}, "m6": {"role": "function", "name": "get_failing_tests_covered_classes", "content": "[\"GenericIE\"]"}, "m7": {"role": "assistant", "content": "The failing test `test_js_to_json_realworld` covers the class `GenericIE` in the `youtube_dl.extractor.generic` package.\nLet's retrieve the methods covered by failing tests for this class.", "function_call": {"name": "get_failing_tests_covered_methods_for_class", "arguments": "{\n  \"class_name\": \"youtube_dl.extractor.generic.GenericIE\"\n}"}}, "m8": {"role": "function", "name": "get_failing_tests_covered_methods_for_class", "content": "[\".report_following_redirect\", \"._extract_rss\", \"._extract_camtasia\", \"._real_extract\", \"._playlist_from_matches\", \".check_video\", \".filter_video\"]"}, "m9": {"role": "assistant", "content": "The failing test `test_js_to_json_realworld` covers the following methods in the `GenericIE` class:\n\n1. `.report_following_redirect`\n2. `._extract_rss`\n3. `._extract_camtasia`\n4. `._real_extract`\n5. `._playlist_from_matches`\n6. `.check_video`\n7. `.filter_video`\n\nLet's retrieve the code snippets for these methods to analyze the implementation.", "function_call": {"name": "get_code_snippet", "arguments": "{\n  \"signature\": \"youtube_dl.extractor.generic.GenericIE.report_following_redirect\"\n}"}}, "m10": {"role": "function", "name": "get_code_snippet", "content": "\"1418 :     def report_following_redirect(self, new_url):\\n1419 :         \\\"\\\"\\\"Report information extraction.\\\"\\\"\\\"\\n1420 :         self._downloader.to_screen('[redirect] Following redirect to %s' % new_url)\""}, "m11": {"role": "assistant", "content": null, "function_call": {"name": "get_code_snippet", "arguments": "{\n  \"signature\": \"youtube_dl.extractor.generic.GenericIE._extract_rss\"\n}"}}, "m12": {"role": "function", "name": "get_code_snippet", "content": "\"1422 :     def _extract_rss(self, url, video_id, doc):\\n1423 :         playlist_title = doc.find('./channel/title').text\\n1424 :         playlist_desc_el = doc.find('./channel/description')\\n1425 :         playlist_desc = None if playlist_desc_el is None else playlist_desc_el.text\\n1426 : \\n1427 :         entries = []\\n1428 :         for it in doc.findall('./channel/item'):\\n1429 :             next_url = xpath_text(it, 'link', fatal=False)\\n1430 :             if not next_url:\\n1431 :                 enclosure_nodes = it.findall('./enclosure')\\n1432 :                 for e in enclosure_nodes:\\n1433 :                     next_url = e.attrib.get('url')\\n1434 :                     if next_url:\\n1435 :                         break\\n1436 : \\n1437 :             if not next_url:\\n1438 :                 continue\\n1439 : \\n1440 :             entries.append({\\n1441 :                 '_type': 'url',\\n1442 :                 'url': next_url,\\n1443 :                 'title': it.find('title').text,\\n1444 :             })\\n1445 : \\n1446 :         return {\\n1447 :             '_type': 'playlist',\\n1448 :             'id': url,\\n1449 :             'title': playlist_title,\\n1450 :             'description': playlist_desc,\\n1451 :             'entries': entries,\\n1452 :         }\""}, "m13": {"role": "assistant", "content": null, "function_call": {"name": "get_code_snippet", "arguments": "{\n  \"signature\": \"youtube_dl.extractor.generic.GenericIE._extract_camtasia\"\n}"}}, "m14": {"role": "function", "name": "get_code_snippet", "content": "\"1454 :     def _extract_camtasia(self, url, video_id, webpage):\\n1455 :         \\\"\\\"\\\" Returns None if no camtasia video can be found. \\\"\\\"\\\"\\n1456 : \\n1457 :         camtasia_cfg = self._search_regex(\\n1458 :             r'fo\\\\.addVariable\\\\(\\\\s*\\\"csConfigFile\\\",\\\\s*\\\"([^\\\"]+)\\\"\\\\s*\\\\);',\\n1459 :             webpage, 'camtasia configuration file', default=None)\\n1460 :         if camtasia_cfg is None:\\n1461 :             return None\\n1462 : \\n1463 :         title = self._html_search_meta('DC.title', webpage, fatal=True)\\n1464 : \\n1465 :         camtasia_url = compat_urlparse.urljoin(url, camtasia_cfg)\\n1466 :         camtasia_cfg = self._download_xml(\\n1467 :             camtasia_url, video_id,\\n1468 :             note='Downloading camtasia configuration',\\n1469 :             errnote='Failed to download camtasia configuration')\\n1470 :         fileset_node = camtasia_cfg.find('./playlist/array/fileset')\\n1471 : \\n1472 :         entries = []\\n1473 :         for n in fileset_node.getchildren():\\n1474 :             url_n = n.find('./uri')\\n1475 :             if url_n is None:\\n1476 :                 continue\\n1477 : \\n1478 :             entries.append({\\n1479 :                 'id': os.path.splitext(url_n.text.rpartition('/')[2])[0],\\n1480 :                 'title': '%s - %s' % (title, n.tag),\\n1481 :                 'url': compat_urlparse.urljoin(url, url_n.text),\\n1482 :                 'duration': float_or_none(n.find('./duration').text),\\n1483 :             })\\n1484 : \\n1485 :         return {\\n1486 :             '_type': 'playlist',\\n1487 :             'entries': entries,\\n1488 :             'title': title,\\n1489 :         }\""}, "m15": {"role": "assistant", "content": null, "function_call": {"name": "get_code_snippet", "arguments": "{\n  \"signature\": \"youtube_dl.extractor.generic.GenericIE._real_extract\"\n}"}}}}, "buggy_methods": "Traceback (most recent call last):\n  File \"/HIDDEN_PATH/autofl.py\", line 254, in <module>\n    grade = ad.run(args.max_budget)\n  File \"/HIDDEN_PATH/autofl.py\", line 219, in run\n    done = self.step()\n  File \"/HIDDEN_PATH/autofl.py\", line 130, in step\n    response = self.get_LLM_response(\n  File \"/HIDDEN_PATH/llm_utils.py\", line 27, in get_LLM_response\n    raise save_err\n  File \"/HIDDEN_PATH/llm_utils.py\", line 17, in get_LLM_response\n    response = openai.ChatCompletion.create(**kwargs)\n  File \"/HIDDEN_PATH/chat_completion.py\", line 25, in create\n    return super().create(*args, **kwargs)\n  File \"/HIDDEN_PATH/engine_api_resource.py\", line 153, in create\n    response, _, api_key = requestor.request(\n  File \"/HIDDEN_PATH/api_requestor.py\", line 226, in request\n    resp, got_stream = self._interpret_response(result, stream)\n  File \"/HIDDEN_PATH/api_requestor.py\", line 619, in _interpret_response\n    self._interpret_response_line(\n  File \"/HIDDEN_PATH/api_requestor.py\", line 679, in _interpret_response_line\n    raise self.handle_error_response(\nopenai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 18357 tokens (18088 in the messages, 269 in the functions). Please reduce the length of the messages or functions."}