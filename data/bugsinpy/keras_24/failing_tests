coverage run -m pytest tests/keras/test_callbacks.py::test_TensorBoard_multi_input_output
============================= test session starts ==============================
platform linux -- Python 3.7.3, pytest-5.4.3, py-1.8.1, pluggy-0.13.1 -- /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/bin/python
cachedir: .pytest_cache
rootdir: /home/user/BugsInPy/temp/projects/keras, inifile: pytest.ini
plugins: forked-1.1.3, flaky-3.6.1, xdist-1.32.0, httpbin-1.0.0
gw0 I / gw1 I

[gw0] linux Python 3.7.3 cwd: /home/user/BugsInPy/temp/projects/keras

[gw1] linux Python 3.7.3 cwd: /home/user/BugsInPy/temp/projects/keras

[gw0] Python 3.7.3 (default, Mar 27 2019, 22:11:17)  -- [GCC 7.3.0]

[gw1] Python 3.7.3 (default, Mar 27 2019, 22:11:17)  -- [GCC 7.3.0]
gw0 [1] / gw1 [1]

scheduling tests via LoadScheduling

tests/keras/test_callbacks.py::test_TensorBoard_multi_input_output 
[gw0] [100%] FAILED tests/keras/test_callbacks.py::test_TensorBoard_multi_input_output 

=================================== FAILURES ===================================
_____________________ test_TensorBoard_multi_input_output ______________________
[gw0] linux -- Python 3.7.3 /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/bin/python

graph = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
node_def = name: "lambda_1_out/values_1"
op: "Pack"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "axis"
  value {
    i: 0
  }
}

inputs = [[<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]]
control_inputs = []

    def _create_c_op(graph, node_def, inputs, control_inputs):
      """Creates a TF_Operation.
    
      Args:
        graph: a `Graph`.
        node_def: `node_def_pb2.NodeDef` for the operation to create.
        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of
          `Tensor`s (corresponding to sequence inputs, e.g. "int64 * N",
          "list(int64)"). The length of the list should be equal to the number of
          inputs specified by this operation's op def.
        control_inputs: A list of `Operation`s to set as control dependencies.
    
      Returns:
        A wrapped TF_Operation*.
      """
      # pylint: disable=protected-access
      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),
                                      compat.as_str(node_def.name))
      if node_def.device:
        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))
      # Add inputs
      for op_input in inputs:
        if isinstance(op_input, (list, tuple)):
          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])
        else:
          c_api.TF_AddInput(op_desc, op_input._as_tf_output())
    
      # Add control inputs
      for control_input in control_inputs:
        c_api.TF_AddControlInput(op_desc, control_input._c_op)
      # pylint: enable=protected-access
    
      # Add attrs
      for name, attr_value in node_def.attr.items():
        serialized = attr_value.SerializeToString()
        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.
        # It might be worth creating a convenient way to re-use the same status.
        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)
    
      try:
>       c_op = c_api.TF_FinishOperation(op_desc)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 3 and 2
E       	From merging shape 0 with other shapes. for 'lambda_1_out/values_1' (op: 'Pack') with input shapes: [?,2,2], [?,2].

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1864: InvalidArgumentError

During handling of the above exception, another exception occurred:

self = <tensorflow.python.framework.op_def_library.OpDefLibrary object at 0x7f25bb016e10>
op_type_name = 'HistogramSummary', name = 'lambda_1_out/', keywords = {}
op_info = <tensorflow.python.framework.op_def_library._OpInfo object at 0x7f25bb0270b8>
op_def = name: "HistogramSummary"
input_arg {
  name: "tag"
  type: DT_STRING
}
input_arg {
  name: "values"
  type_attr: "T"
}...   type: DT_BFLOAT16
      type: DT_UINT16
      type: DT_HALF
      type: DT_UINT32
      type: DT_UINT64
    }
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
deprecation_version = 0, default_type_attr_map = {'T': tf.float32}

    def _apply_op_helper(self, op_type_name, name=None, **keywords):
      """Implementation of apply_op that returns output_structure, op."""
      op_info = self._ops.get(op_type_name, None)
      if op_info is None:
        raise RuntimeError("Unrecognized Op name " + op_type_name)
      op_def = op_info.op_def
    
      # Determine the graph context.
      try:
        # Need to flatten all the arguments into a list.
        # pylint: disable=protected-access
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
        # pylint: enable=protected-access
      except AssertionError as e:
        raise RuntimeError(
            "Cannot determine graph for Op '%s' due to: %s"
            % (op_type_name, e.message))
    
      # Default name if not specified.
      if name is None:
        name = op_type_name
    
      # Check for deprecation
      deprecation_version = op_def.deprecation.version
      if deprecation_version:
        producer = g.graph_def_versions.producer
        if producer >= deprecation_version:
          raise NotImplementedError(
              ("Op %s is not available in GraphDef version %d. "
               "It has been removed in version %d. %s.") %
              (op_type_name, producer, deprecation_version,
               op_def.deprecation.explanation))
    
      # Fill in the list of default types for all "type" attrs.  This
      # will be used to choose a preferred dtype to convert to in the
      # absence of input type information.
      #
      # TODO(b/31302892): Currently the defaults don't work in the right
      # way if you have two inputs, one of whose type resolution depends
      # on the other.  Handling this will require restructuring this code
      # significantly.
      default_type_attr_map = {}
      for attr_def in op_def.attr:
        if attr_def.type != "type":
          continue
        key = attr_def.name
        if attr_def.HasField("default_value"):
          default_type_attr_map[key] = dtypes.as_dtype(
              attr_def.default_value.type)
    
      # Requires that op_def has passed validation (using the C++
      # ValidateOpDef() from ../framework/op_def_util.h).
      attrs = {}
      inputs = []
      input_types = []
      with g.as_default(), ops.name_scope(name) as scope:
    
        # Perform input type inference
        inferred_from = {}
        for input_arg in op_def.input_arg:
          input_name = input_arg.name
          if input_name in keywords:
            values = keywords.pop(input_name)
          elif input_name + "_" in keywords:
            # Handle the case where the name is a keyword or built-in
            # for Python so we use the name + _ instead.
            input_name += "_"
            values = keywords.pop(input_name)
          else:
            raise TypeError("No argument for input " + input_name)
    
          # Goals:
          # * Convert values to Tensors if it contains constants.
          # * Verify that values is a list if that matches the input_arg's
          #   type.
          # * If the input_arg's type is determined by attrs, either set
          #   those attrs and validate those attr values are legal (if
          #   they have not yet been set) or validate the input matches
          #   the type indicated by the attrs (if they have already been
          #   inferred via an earlier input).
          # * If the input_arg has an explicit type, make sure the input
          #   conforms.
    
          if _IsListParameter(input_arg):
            if not _IsListValue(values):
              raise TypeError(
                  "Expected list for '%s' argument to '%s' Op, not %s." %
                  (input_name, op_type_name, values))
            # In cases where we expect all elements of the list to have the
            # same dtype, try to cast non-Tensor elements to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.number_attr:
              if input_arg.type_attr in attrs:
                dtype = attrs[input_arg.type_attr]
              else:
                for t in values:
                  if isinstance(t, ops.Tensor):
                    dtype = t.dtype
                    break
    
              # dtype still not found, prefer using the default dtype
              # from the attr.
              if dtype is None and input_arg.type_attr in default_type_attr_map:
                default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              if not input_arg.is_ref and dtype:
                dtype = dtypes.as_dtype(dtype).base_dtype
              values = ops.internal_convert_n_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype if dtype else None,
                  preferred_dtype=default_dtype,
                  as_ref=input_arg.is_ref)
              if input_arg.number_attr and len(
                  set(v.dtype.base_dtype for v in values)) > 1:
                raise TypeError()  # All types should match.
            except (TypeError, ValueError):
              # What types does the conversion function think values have?
              observed_types = []
              for value in values:
                try:
                  converted_value = ops.internal_convert_to_tensor(
                      value, as_ref=input_arg.is_ref)
                  observed_types.append(converted_value.dtype.base_dtype.name)
                except (TypeError, ValueError):
                  observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
              observed = ", ".join(observed_types)
    
              prefix = (
                  "Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                  (input_name, op_type_name, observed))
              if input_arg.number_attr:
                if input_arg.type != types_pb2.DT_INVALID:
                  raise TypeError("%s that do not match expected type %s." %
                                  (prefix, dtype.name))
                elif input_arg.type_attr in attrs:
                  raise TypeError("%s that do not match type %s inferred from "
                                  "earlier arguments." %
                                  (prefix, dtype.name))
                else:
                  raise TypeError("%s that don't all match." % prefix)
              else:
                raise TypeError(
                    "%s that are invalid. Tensors: %s" % (prefix, values))
    
            types = [x.dtype for x in values]
            inputs.extend(values)
          else:
            # In cases where we have an expected type, try to convert non-Tensor
            # arguments to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            elif input_arg.type_attr in default_type_attr_map:
              # The dtype could not be inferred solely from the inputs,
              # so we prefer the attr's default, so code that adds a new attr
              # with a default is backwards compatible.
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              values = ops.internal_convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
>                 preferred_dtype=default_dtype)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:527: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
dtype = None, name = 'values', as_ref = False, preferred_dtype = tf.float32
ctx = <tensorflow.python.eager.context.Context object at 0x7f25ae620f98>
accept_symbolic_tensors = True, accept_composite_tensors = False

    def internal_convert_to_tensor(value,
                                   dtype=None,
                                   name=None,
                                   as_ref=False,
                                   preferred_dtype=None,
                                   ctx=None,
                                   accept_symbolic_tensors=True,
                                   accept_composite_tensors=False):
      """Implementation of the public convert_to_tensor."""
      if ctx is None:
        ctx = context.context()
      if isinstance(value, EagerTensor):
        if ctx.executing_eagerly():
          if dtype is not None:
            dtype = dtypes.as_dtype(dtype)
            value = _TensorTensorConversionFunction(value, dtype=dtype)
          return value
        else:
          graph = get_default_graph()
          if not graph.building_function:
            raise RuntimeError("Attempting to capture an EagerTensor without "
                               "building a function.")
          return graph.capture(value, name=name)
      elif ((not accept_symbolic_tensors) and isinstance(value, Tensor) and
            ctx.executing_eagerly()):
        # Found a symbolic tensor in an eager context.
        # This happens when we use the Keras functional API (i.e. calling layers
        # on the output of `keras.Input()`, which is symbolic) while eager
        # execution is enabled.
        if _is_keras_symbolic_tensor(value):
          # If the graph of the tensor isn't the Keras graph, we should still
          # fail, for the time being. TODO(fchollet): consider allowing
          # all symbolic tensors to raise this exception in this case.
          raise core._SymbolicException(  # pylint: disable=protected-access
              "Using the symbolic output of a Keras layer during eager execution.")
    
      if dtype is not None:
        dtype = dtypes.as_dtype(dtype)
      unwrapped_type = type(value)
      conversion_func_list = _tensor_conversion_func_cache.get(unwrapped_type, None)
      if conversion_func_list is None:
        with _tensor_conversion_func_lock:
          conversion_func_list = []
          for _, funcs_at_priority in sorted(
              _tensor_conversion_func_registry.items()):
            for base_type, conversion_func in funcs_at_priority:
              if isinstance(value, base_type):
                conversion_func_list.append((base_type, conversion_func))
          _tensor_conversion_func_cache[unwrapped_type] = conversion_func_list
    
      for base_type, conversion_func in conversion_func_list:
        # If dtype is None but preferred_dtype is not None, we try to
        # cast to preferred_dtype first.
        ret = None
        if dtype is None and preferred_dtype is not None:
          try:
            ret = conversion_func(
                value, dtype=preferred_dtype, name=name, as_ref=as_ref)
          except (TypeError, ValueError, errors.UnimplementedError,
                  errors.InvalidArgumentError):
            # Could not coerce the conversion to use the preferred dtype.
            ret = None
    
          if ret is not None and ret is not NotImplemented:
            if (ret.dtype.base_dtype !=
                dtypes.as_dtype(preferred_dtype).base_dtype):
              raise TypeError("convert_to_tensor did not convert to "
                              "the preferred dtype: %s vs %s " %
                              (ret.dtype.base_dtype,
                               dtypes.as_dtype(preferred_dtype).base_dtype))
    
        if ret is None:
>         ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

v = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
dtype = tf.float32, name = 'values', as_ref = False

    def _autopacking_conversion_function(v, dtype=None, name=None, as_ref=False):
      """Tensor conversion function that automatically packs arguments."""
      if as_ref:
        return NotImplemented
      inferred_dtype = _get_dtype_from_nested_lists(v)
      if inferred_dtype is None:
        # We did not find any tensor-like objects in the nested lists, so defer to
        # other conversion functions.
        return NotImplemented
      if dtype is None:
        dtype = inferred_dtype
      elif dtype != inferred_dtype:
        v = nest.map_structure(_cast_nested_seqs_to_dtype(dtype), v)
>     return _autopacking_helper(v, dtype, name or "packed")

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

list_or_tuple = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
dtype = tf.float32, name = 'values'

    def _autopacking_helper(list_or_tuple, dtype, name):
      """Converts the given list or tuple to a tensor by packing.
    
      Args:
        list_or_tuple: A (possibly nested) list or tuple containing a tensor.
        dtype: The element type of the returned tensor.
        name: A name for the returned tensor.
    
      Returns:
        A `tf.Tensor` with value equivalent to `list_or_tuple`.
      """
      if context.executing_eagerly():
        # NOTE: Fast path when all the items are tensors, this doesn't do any type
        # checking.
        if all(ops.is_dense_tensor_like(elem) for elem in list_or_tuple):
          return gen_array_ops.pack(list_or_tuple, name=name)
      must_pack = False
      converted_elems = []
      with ops.name_scope(name) as scope:
        for i, elem in enumerate(list_or_tuple):
          if ops.is_dense_tensor_like(elem):
            if dtype is not None and elem.dtype.base_dtype != dtype:
              raise TypeError("Cannot convert a list containing a tensor of dtype "
                              "%s to %s (Tensor is: %r)" %
                              (elem.dtype, dtype, elem))
            converted_elems.append(elem)
            must_pack = True
          elif isinstance(elem, (list, tuple)):
            converted_elem = _autopacking_helper(elem, dtype, str(i))
            if ops.is_dense_tensor_like(converted_elem):
              must_pack = True
            converted_elems.append(converted_elem)
          else:
            converted_elems.append(elem)
        if must_pack:
          elems_as_tensors = []
          for i, elem in enumerate(converted_elems):
            if ops.is_dense_tensor_like(elem):
              elems_as_tensors.append(elem)
            else:
              # NOTE(mrry): This is inefficient, but it enables us to
              # handle the case where the list arguments are other
              # convertible-to-tensor types, such as numpy arrays.
              elems_as_tensors.append(
                  constant_op.constant(elem, dtype=dtype, name=str(i)))
>         return gen_array_ops.pack(elems_as_tensors, name=scope)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1095: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
axis = 0, name = 'lambda_1_out/values_1/'

    def pack(values, axis=0, name=None):
      r"""Packs a list of `N` rank-`R` tensors into one rank-`(R+1)` tensor.
    
      Packs the `N` tensors in `values` into a tensor with rank one higher than each
      tensor in `values`, by packing them along the `axis` dimension.
      Given a list of tensors of shape `(A, B, C)`;
    
      if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.
      if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.
      Etc.
    
      For example:
    
      ```
      # 'x' is [1, 4]
      # 'y' is [2, 5]
      # 'z' is [3, 6]
      pack([x, y, z]) => [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.
      pack([x, y, z], axis=1) => [[1, 2, 3], [4, 5, 6]]
      ```
    
      This is the opposite of `unpack`.
    
      Args:
        values: A list of at least 1 `Tensor` objects with the same type.
          Must be of same shape and type.
        axis: An optional `int`. Defaults to `0`.
          Dimension along which to pack.  Negative values wrap around, so the
          valid range is `[-(R+1), R+1)`.
        name: A name for the operation (optional).
    
      Returns:
        A `Tensor`. Has the same type as `values`.
      """
      _ctx = _context._context or _context.context()
      if _ctx is not None and _ctx._thread_local_data.is_eager:
        try:
          _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
            _ctx._context_handle, _ctx._thread_local_data.device_name, "Pack",
            name, _ctx._post_execution_callbacks, values, "axis", axis)
          return _result
        except _core._FallbackException:
          try:
            return pack_eager_fallback(
                values, axis=axis, name=name, ctx=_ctx)
          except _core._SymbolicException:
            pass  # Add nodes to the TensorFlow graph.
        except _core._NotOkStatusException as e:
          if name is not None:
            message = e.message + " name: " + name
          else:
            message = e.message
          _six.raise_from(_core._status_to_exception(e.code, message), None)
      # Add nodes to the TensorFlow graph.
      if not isinstance(values, (list, tuple)):
        raise TypeError(
            "Expected list for 'values' argument to "
            "'pack' Op, not %r." % values)
      _attr_N = len(values)
      if axis is None:
        axis = 0
      axis = _execute.make_int(axis, "axis")
      _, _, _op = _op_def_lib._apply_op_helper(
>           "Pack", values=values, axis=axis, name=name)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:5897: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tensorflow.python.framework.op_def_library.OpDefLibrary object at 0x7f25bb43d048>
op_type_name = 'Pack', name = 'lambda_1_out/values_1/', keywords = {}
op_info = <tensorflow.python.framework.op_def_library._OpInfo object at 0x7f25bb445588>
op_def = name: "Pack"
input_arg {
  name: "values"
  type_attr: "T"
  number_attr: "N"
}
output_arg {
  name: "output"
  type_a... minimum: 1
}
attr {
  name: "T"
  type: "type"
}
attr {
  name: "axis"
  type: "int"
  default_value {
    i: 0
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
deprecation_version = 0, default_type_attr_map = {}

    def _apply_op_helper(self, op_type_name, name=None, **keywords):
      """Implementation of apply_op that returns output_structure, op."""
      op_info = self._ops.get(op_type_name, None)
      if op_info is None:
        raise RuntimeError("Unrecognized Op name " + op_type_name)
      op_def = op_info.op_def
    
      # Determine the graph context.
      try:
        # Need to flatten all the arguments into a list.
        # pylint: disable=protected-access
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
        # pylint: enable=protected-access
      except AssertionError as e:
        raise RuntimeError(
            "Cannot determine graph for Op '%s' due to: %s"
            % (op_type_name, e.message))
    
      # Default name if not specified.
      if name is None:
        name = op_type_name
    
      # Check for deprecation
      deprecation_version = op_def.deprecation.version
      if deprecation_version:
        producer = g.graph_def_versions.producer
        if producer >= deprecation_version:
          raise NotImplementedError(
              ("Op %s is not available in GraphDef version %d. "
               "It has been removed in version %d. %s.") %
              (op_type_name, producer, deprecation_version,
               op_def.deprecation.explanation))
    
      # Fill in the list of default types for all "type" attrs.  This
      # will be used to choose a preferred dtype to convert to in the
      # absence of input type information.
      #
      # TODO(b/31302892): Currently the defaults don't work in the right
      # way if you have two inputs, one of whose type resolution depends
      # on the other.  Handling this will require restructuring this code
      # significantly.
      default_type_attr_map = {}
      for attr_def in op_def.attr:
        if attr_def.type != "type":
          continue
        key = attr_def.name
        if attr_def.HasField("default_value"):
          default_type_attr_map[key] = dtypes.as_dtype(
              attr_def.default_value.type)
    
      # Requires that op_def has passed validation (using the C++
      # ValidateOpDef() from ../framework/op_def_util.h).
      attrs = {}
      inputs = []
      input_types = []
      with g.as_default(), ops.name_scope(name) as scope:
    
        # Perform input type inference
        inferred_from = {}
        for input_arg in op_def.input_arg:
          input_name = input_arg.name
          if input_name in keywords:
            values = keywords.pop(input_name)
          elif input_name + "_" in keywords:
            # Handle the case where the name is a keyword or built-in
            # for Python so we use the name + _ instead.
            input_name += "_"
            values = keywords.pop(input_name)
          else:
            raise TypeError("No argument for input " + input_name)
    
          # Goals:
          # * Convert values to Tensors if it contains constants.
          # * Verify that values is a list if that matches the input_arg's
          #   type.
          # * If the input_arg's type is determined by attrs, either set
          #   those attrs and validate those attr values are legal (if
          #   they have not yet been set) or validate the input matches
          #   the type indicated by the attrs (if they have already been
          #   inferred via an earlier input).
          # * If the input_arg has an explicit type, make sure the input
          #   conforms.
    
          if _IsListParameter(input_arg):
            if not _IsListValue(values):
              raise TypeError(
                  "Expected list for '%s' argument to '%s' Op, not %s." %
                  (input_name, op_type_name, values))
            # In cases where we expect all elements of the list to have the
            # same dtype, try to cast non-Tensor elements to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.number_attr:
              if input_arg.type_attr in attrs:
                dtype = attrs[input_arg.type_attr]
              else:
                for t in values:
                  if isinstance(t, ops.Tensor):
                    dtype = t.dtype
                    break
    
              # dtype still not found, prefer using the default dtype
              # from the attr.
              if dtype is None and input_arg.type_attr in default_type_attr_map:
                default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              if not input_arg.is_ref and dtype:
                dtype = dtypes.as_dtype(dtype).base_dtype
              values = ops.internal_convert_n_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype if dtype else None,
                  preferred_dtype=default_dtype,
                  as_ref=input_arg.is_ref)
              if input_arg.number_attr and len(
                  set(v.dtype.base_dtype for v in values)) > 1:
                raise TypeError()  # All types should match.
            except (TypeError, ValueError):
              # What types does the conversion function think values have?
              observed_types = []
              for value in values:
                try:
                  converted_value = ops.internal_convert_to_tensor(
                      value, as_ref=input_arg.is_ref)
                  observed_types.append(converted_value.dtype.base_dtype.name)
                except (TypeError, ValueError):
                  observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
              observed = ", ".join(observed_types)
    
              prefix = (
                  "Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                  (input_name, op_type_name, observed))
              if input_arg.number_attr:
                if input_arg.type != types_pb2.DT_INVALID:
                  raise TypeError("%s that do not match expected type %s." %
                                  (prefix, dtype.name))
                elif input_arg.type_attr in attrs:
                  raise TypeError("%s that do not match type %s inferred from "
                                  "earlier arguments." %
                                  (prefix, dtype.name))
                else:
                  raise TypeError("%s that don't all match." % prefix)
              else:
                raise TypeError(
                    "%s that are invalid. Tensors: %s" % (prefix, values))
    
            types = [x.dtype for x in values]
            inputs.extend(values)
          else:
            # In cases where we have an expected type, try to convert non-Tensor
            # arguments to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            elif input_arg.type_attr in default_type_attr_map:
              # The dtype could not be inferred solely from the inputs,
              # so we prefer the attr's default, so code that adds a new attr
              # with a default is backwards compatible.
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              values = ops.internal_convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
            except TypeError as err:
              if dtype is None:
                raise err
              else:
                raise TypeError(
                    "Expected %s passed to parameter '%s' of op '%s', got %s of "
                    "type '%s' instead. Error: %s" %
                    (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,
                     repr(values), type(values).__name__, err))
            except ValueError:
              # What type does convert_to_tensor think it has?
              try:
                observed = ops.internal_convert_to_tensor(
                    values, as_ref=input_arg.is_ref).dtype.name
              except ValueError as err:
                raise ValueError(
                    "Tried to convert '%s' to a tensor and failed. Error: %s" %
                    (input_name, err))
              prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                        (input_name, op_type_name, observed))
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError("%s expected type of %s." %
                                (prefix, dtypes.as_dtype(input_arg.type).name))
              else:
                # Update the maps with the default, if needed.
                k = input_arg.type_attr
                if k in default_type_attr_map:
                  if k not in attrs:
                    attrs[k] = default_type_attr_map[k]
                    if k not in inferred_from:
                      inferred_from[k] = "Default in OpDef"
    
                raise TypeError(
                    "%s type %s of argument '%s'." %
                    (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
    
            types = [values.dtype]
            inputs.append(values)
          base_types = [x.base_dtype for x in types]
    
          if input_arg.number_attr:
            # <number-attr> * <type> or <number-attr> * <type-attr>
            if input_arg.number_attr in attrs:
              if len(values) != attrs[input_arg.number_attr]:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d must match "
                    "length %d of argument '%s'." %
                    (input_name, op_type_name, len(values),
                     attrs[input_arg.number_attr],
                     inferred_from[input_arg.number_attr]))
            else:
              attrs[input_arg.number_attr] = len(values)
              inferred_from[input_arg.number_attr] = input_name
              num_attr = _Attr(op_def, input_arg.number_attr)
              if num_attr.has_minimum and len(values) < num_attr.minimum:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d shorter "
                    "than minimum length %d." %
                    (input_name, op_type_name, len(values), num_attr.minimum))
            # All tensors must have the same base type.
            if any(bt != base_types[0] for bt in base_types):
              raise TypeError(
                  "All tensors passed to '%s' of '%s' Op "
                  "must have the same type." %
                  (input_name, op_type_name))
            if input_arg.type != types_pb2.DT_INVALID:
              # <number-attr> * <type> case
              if base_types and base_types[0] != input_arg.type:
                assert False, "Unreachable"
            elif input_arg.type_attr in attrs:
              # <number-attr> * <type-attr> case, where <type-attr> already
              # has an inferred value.
              if base_types and base_types[0] != attrs[input_arg.type_attr]:
                assert False, "Unreachable"
            else:
              # <number-attr> * <type-attr> case, where we are now setting
              # the <type-attr> based on this input
              if not base_types:
                raise TypeError(
                    "Don't know how to infer type variable from empty input "
                    "list passed to input '%s' of '%s' Op." %
                    (input_name, op_type_name))
              attrs[input_arg.type_attr] = base_types[0]
              inferred_from[input_arg.type_attr] = input_name
              type_attr = _Attr(op_def, input_arg.type_attr)
              _SatisfiesTypeConstraint(base_types[0], type_attr,
                                       param_name=input_name)
          elif input_arg.type_attr:
            # <type-attr>
            attr_value = base_types[0]
            if input_arg.type_attr in attrs:
              if attrs[input_arg.type_attr] != attr_value:
                assert False, "Unreachable"
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_attr),
                                         param_name=input_name)
              attrs[input_arg.type_attr] = attr_value
              inferred_from[input_arg.type_attr] = input_name
          elif input_arg.type_list_attr:
            # <type-list-attr>
            attr_value = base_types
            if input_arg.type_list_attr in attrs:
              if attrs[input_arg.type_list_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type list of %s that does not "
                    "match type list %s of argument '%s'." %
                    (input_name, op_type_name,
                     ", ".join(dtypes.as_dtype(x).name for x in attr_value),
                     ", ".join(dtypes.as_dtype(x).name
                               for x in attrs[input_arg.type_list_attr]),
                     inferred_from[input_arg.type_list_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_list_attr),
                                         param_name=input_name)
              attrs[input_arg.type_list_attr] = attr_value
              inferred_from[input_arg.type_list_attr] = input_name
          else:
            # single Tensor with specified type
            if base_types[0] != input_arg.type:
              assert False, "Unreachable"
    
          if input_arg.is_ref:
            if not all(x._is_ref_dtype for x in types):  # pylint: disable=protected-access
              raise TypeError(
                  ("'%s' Op requires that input '%s' be a mutable tensor "
                   "(e.g.: a tf.Variable)") % (op_type_name, input_name))
            input_types.extend(types)
          else:
            input_types.extend(base_types)
    
        # Process remaining attrs
        for attr in op_def.attr:
          # Skip attrs that have already had their values inferred
          if attr.name in attrs:
            if attr.name in keywords:
              raise TypeError(
                  "Should not specify value for inferred attr '%s'." % attr.name)
            continue
          if attr.name in keywords:
            attrs[attr.name] = keywords.pop(attr.name)
          elif attr.name + "_" in keywords:
            # Attrs whose names match Python keywords have an extra '_'
            # appended, so we must check for that as well.
            attrs[attr.name] = keywords.pop(attr.name + "_")
          else:
            raise TypeError("No argument for attr " + attr.name)
    
        # Convert attr values to AttrValue protos.
        attr_protos = {}
        for attr_def in op_def.attr:
          key = attr_def.name
          value = attrs[key]
          attr_value = attr_value_pb2.AttrValue()
          if attr_def.HasField("default_value") and value is None:
            attr_value.CopyFrom(attr_def.default_value)
            attr_protos[key] = attr_value
            continue
          if attr_def.type.startswith("list("):
            if not _IsListValue(value):
              raise TypeError("Expected list for attr " + key)
            if attr_def.has_minimum:
              if len(value) < attr_def.minimum:
                raise ValueError("Attr '%s' of '%s' Op passed list of length %d "
                                 "less than minimum %d." %
                                 (key, op_type_name, len(value),
                                  attr_def.minimum))
            attr_value.list.SetInParent()
          if attr_def.type == "string":
            attr_value.s = _MakeStr(value, key)
            if attr_def.HasField("allowed_values"):
              if attr_value.s not in attr_def.allowed_values.list.s:
                raise ValueError(
                    "Attr '%s' of '%s' Op passed string '%s' not in: \"%s\"." %
                    (key, op_type_name, compat.as_text(attr_value.s),
                     '", "'.join(map(compat.as_text,
                                     attr_def.allowed_values.list.s))))
          elif attr_def.type == "list(string)":
            attr_value.list.s.extend([_MakeStr(x, key) for x in value])
            if attr_def.HasField("allowed_values"):
              for x in attr_value.list.s:
                if x not in attr_def.allowed_values.list.s:
                  raise ValueError(
                      "Attr '%s' of '%s' Op passed string '%s' not in: \"%s\"." %
                      (key, op_type_name, compat.as_text(x),
                       '", "'.join(map(compat.as_text,
                                       attr_def.allowed_values.list.s))))
          elif attr_def.type == "int":
            attr_value.i = _MakeInt(value, key)
            if attr_def.has_minimum:
              if attr_value.i < attr_def.minimum:
                raise ValueError(
                    "Attr '%s' of '%s' Op passed %d less than minimum %d." %
                    (key, op_type_name, attr_value.i, attr_def.minimum))
          elif attr_def.type == "list(int)":
            attr_value.list.i.extend([_MakeInt(x, key) for x in value])
          elif attr_def.type == "float":
            attr_value.f = _MakeFloat(value, key)
          elif attr_def.type == "list(float)":
            attr_value.list.f.extend([_MakeFloat(x, key) for x in value])
          elif attr_def.type == "bool":
            attr_value.b = _MakeBool(value, key)
          elif attr_def.type == "list(bool)":
            attr_value.list.b.extend([_MakeBool(x, key) for x in value])
          elif attr_def.type == "type":
            attr_value.type = _MakeType(value, attr_def)
          elif attr_def.type == "list(type)":
            attr_value.list.type.extend(
                [_MakeType(x, attr_def) for x in value])
          elif attr_def.type == "shape":
            attr_value.shape.CopyFrom(_MakeShape(value, key))
          elif attr_def.type == "list(shape)":
            attr_value.list.shape.extend(
                [_MakeShape(x, key) for x in value])
          elif attr_def.type == "tensor":
            attr_value.tensor.CopyFrom(_MakeTensor(value, key))
          elif attr_def.type == "list(tensor)":
            attr_value.list.tensor.extend(
                [_MakeTensor(x, key) for x in value])
          elif attr_def.type == "func":
            attr_value.func.CopyFrom(_MakeFunc(value, key))
          elif attr_def.type == "list(func)":
            attr_value.list.func.extend([_MakeFunc(x, key) for x in value])
          else:
            raise TypeError("Unrecognized Attr type " + attr_def.type)
    
          attr_protos[key] = attr_value
        del attrs  # attrs is no longer authoritative, use attr_protos instead
    
        # Determine output types (possibly using attrs)
        output_structure = []
        for arg in op_def.output_arg:
          if arg.number_attr:
            n = _AttrValue(attr_protos, arg.number_attr).i
            output_structure.append(n)
          elif arg.type_attr:
            t = _AttrValue(attr_protos, arg.type_attr)
            output_structure.append(None)
          elif arg.type_list_attr:
            t = _AttrValue(attr_protos, arg.type_list_attr)
            output_structure.append(len(t.list.type))
          else:
            output_structure.append(None)
    
        if keywords:
          raise TypeError("apply_op() got unexpected keyword arguments: " +
                          ", ".join(sorted(keywords.keys())))
    
        # NOTE(mrry): We add an explicit colocation constraint between
        # the newly created op and any of its reference-typed inputs.
        must_colocate_inputs = [val for arg, val in zip(op_def.input_arg, inputs)
                                if arg.is_ref]
        with _MaybeColocateWith(must_colocate_inputs):
          # Add Op to graph
          op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,
                           input_types=input_types, attrs=attr_protos,
>                          op_def=op_def)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:788: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>, 'Pack', [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>])
kwargs = {'attrs': {'N': i: 2
, 'T': type: DT_FLOAT
, 'axis': i: 0
}, 'dtypes': None, 'input_types': [tf.float32, tf.float32], 'name': 'lambda_1_out/values_1/', ...}
invalid_args = []
named_args = {'attrs': {'N': i: 2
, 'T': type: DT_FLOAT
, 'axis': i: 0
}, 'compute_device': True, 'compute_shapes': True, 'dtypes': None, ...}
arg_name = 'compute_shapes'
spec = DeprecatedArgSpec(position=8, has_ok_value=False, ok_value=None)

    @functools.wraps(func)
    def new_func(*args, **kwargs):
      """Deprecation wrapper."""
      # TODO(apassos) figure out a way to have reasonable performance with
      # deprecation warnings and eager mode.
      if is_in_graph_mode.IS_IN_GRAPH_MODE() and _PRINT_DEPRECATION_WARNINGS:
        invalid_args = []
        named_args = tf_inspect.getcallargs(func, *args, **kwargs)
        for arg_name, spec in iter(deprecated_positions.items()):
          if (spec.position < len(args) and
              not (spec.has_ok_value and
                   _same_value(named_args[arg_name], spec.ok_value))):
            invalid_args.append(arg_name)
        if is_varargs_deprecated and len(args) > len(arg_spec.args):
          invalid_args.append(arg_spec.varargs)
        if is_kwargs_deprecated and kwargs:
          invalid_args.append(arg_spec.varkw)
        for arg_name in deprecated_arg_names:
          if (arg_name in kwargs and
              not (deprecated_positions[arg_name].has_ok_value and
                   _same_value(named_args[arg_name],
                               deprecated_positions[arg_name].ok_value))):
            invalid_args.append(arg_name)
        for arg_name in invalid_args:
          if (func, arg_name) not in _PRINTED_WARNING:
            if warn_once:
              _PRINTED_WARNING[(func, arg_name)] = True
            logging.warning(
                'From %s: calling %s (from %s) with %s is deprecated and will '
                'be removed %s.\nInstructions for updating:\n%s',
                _call_location(), decorator_utils.get_qualified_name(func),
                func.__module__, arg_name,
                'in a future version' if date is None else ('after %s' % date),
                instructions)
>     return func(*args, **kwargs)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
op_type = 'Pack'
inputs = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
dtypes = None, input_types = [tf.float32, tf.float32]
name = 'lambda_1_out/values_1'
attrs = {'N': i: 2
, 'T': type: DT_FLOAT
, 'axis': i: 0
}
op_def = name: "Pack"
input_arg {
  name: "values"
  type_attr: "T"
  number_attr: "N"
}
output_arg {
  name: "output"
  type_a... minimum: 1
}
attr {
  name: "T"
  type: "type"
}
attr {
  name: "axis"
  type: "int"
  default_value {
    i: 0
  }
}

compute_device = True

    @deprecated_args(None,
                     "Shapes are always computed; don't use the compute_shapes "
                     "as it has no effect.", "compute_shapes")
    def create_op(
        self,
        op_type,
        inputs,
        dtypes=None,  # pylint: disable=redefined-outer-name
        input_types=None,
        name=None,
        attrs=None,
        op_def=None,
        compute_shapes=True,
        compute_device=True):
      """Creates an `Operation` in this graph.
    
      This is a low-level interface for creating an `Operation`. Most
      programs will not call this method directly, and instead use the
      Python op constructors, such as `tf.constant()`, which add ops to
      the default graph.
    
      Args:
        op_type: The `Operation` type to create. This corresponds to the
          `OpDef.name` field for the proto that defines the operation.
        inputs: A list of `Tensor` objects that will be inputs to the `Operation`.
        dtypes: (Optional) A list of `DType` objects that will be the types of the
          tensors that the operation produces.
        input_types: (Optional.) A list of `DType`s that will be the types of the
          tensors that the operation consumes. By default, uses the base `DType`
          of each input in `inputs`. Operations that expect reference-typed inputs
          must specify `input_types` explicitly.
        name: (Optional.) A string name for the operation. If not specified, a
          name is generated based on `op_type`.
        attrs: (Optional.) A dictionary where the key is the attribute name (a
          string) and the value is the respective `attr` attribute of the
          `NodeDef` proto that will represent the operation (an `AttrValue`
          proto).
        op_def: (Optional.) The `OpDef` proto that describes the `op_type` that
          the operation will have.
        compute_shapes: (Optional.) Deprecated. Has no effect (shapes are always
          computed).
        compute_device: (Optional.) If True, device functions will be executed to
          compute the device property of the Operation.
    
      Raises:
        TypeError: if any of the inputs is not a `Tensor`.
        ValueError: if colocation conflicts with existing device assignment.
    
      Returns:
        An `Operation` object.
      """
      del compute_shapes
    
      self._check_not_finalized()
      for idx, a in enumerate(inputs):
        if not isinstance(a, Tensor):
          raise TypeError("Input #%d is not a tensor: %s" % (idx, a))
      if name is None:
        name = op_type
      # If a names ends with a '/' it is a "name scope" and we use it as-is,
      # after removing the trailing '/'.
      if name and name[-1] == "/":
        name = name_from_scope_name(name)
      else:
        name = self.unique_name(name)
    
      node_def = _NodeDef(op_type, name, device=None, attrs=attrs)
    
      input_ops = set([t.op for t in inputs])
      control_inputs = self._control_dependencies_for_inputs(input_ops)
      # _create_op_helper mutates the new Operation. `_mutation_lock` ensures a
      # Session.run call cannot occur between creating and mutating the op.
      with self._mutation_lock():
        ret = Operation(
            node_def,
            self,
            inputs=inputs,
            output_types=dtypes,
            control_inputs=control_inputs,
            input_types=input_types,
            original_op=self._default_original_op,
>           op_def=op_def)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'Operation' object has no attribute '_c_op'") raised in repr()] Operation object at 0x7f258c4aa9b0>
node_def = name: "lambda_1_out/values_1"
op: "Pack"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "axis"
  value {
    i: 0
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
inputs = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
output_types = None, control_inputs = [], input_types = [tf.float32, tf.float32]
original_op = None
op_def = name: "Pack"
input_arg {
  name: "values"
  type_attr: "T"
  number_attr: "N"
}
output_arg {
  name: "output"
  type_a... minimum: 1
}
attr {
  name: "T"
  type: "type"
}
attr {
  name: "axis"
  type: "int"
  default_value {
    i: 0
  }
}


    def __init__(self,
                 node_def,
                 g,
                 inputs=None,
                 output_types=None,
                 control_inputs=None,
                 input_types=None,
                 original_op=None,
                 op_def=None):
      r"""Creates an `Operation`.
    
      NOTE: This constructor validates the name of the `Operation` (passed
      as `node_def.name`). Valid `Operation` names match the following
      regular expression:
    
          [A-Za-z0-9.][A-Za-z0-9_.\\-/]*
    
      Args:
        node_def: `node_def_pb2.NodeDef`.  `NodeDef` for the `Operation`. Used for
          attributes of `node_def_pb2.NodeDef`, typically `name`, `op`, and
          `device`.  The `input` attribute is irrelevant here as it will be
          computed when generating the model.
        g: `Graph`. The parent graph.
        inputs: list of `Tensor` objects. The inputs to this `Operation`.
        output_types: list of `DType` objects.  List of the types of the `Tensors`
          computed by this operation.  The length of this list indicates the
          number of output endpoints of the `Operation`.
        control_inputs: list of operations or tensors from which to have a control
          dependency.
        input_types: List of `DType` objects representing the types of the tensors
          accepted by the `Operation`.  By default uses `[x.dtype.base_dtype for x
          in inputs]`.  Operations that expect reference-typed inputs must specify
          these explicitly.
        original_op: Optional. Used to associate the new `Operation` with an
          existing `Operation` (for example, a replica with the op that was
          replicated).
        op_def: Optional. The `op_def_pb2.OpDef` proto that describes the op type
          that this `Operation` represents.
    
      Raises:
        TypeError: if control inputs are not Operations or Tensors,
          or if `node_def` is not a `NodeDef`,
          or if `g` is not a `Graph`,
          or if `inputs` are not tensors,
          or if `inputs` and `input_types` are incompatible.
        ValueError: if the `node_def` name is not valid.
      """
      # For internal use only: `node_def` can be set to a TF_Operation to create
      # an Operation for that op. This is useful for creating Operations for ops
      # indirectly created by C API methods, e.g. the ops created by
      # TF_ImportGraphDef. When `node_def` is a TF_Operation, all optional fields
      # should be None.
    
      if isinstance(node_def, node_def_pb2.NodeDef):
        if node_def.ByteSize() >= (1 << 31) or node_def.ByteSize() < 0:
          raise ValueError(
              "Cannot create a tensor proto whose content is larger than 2GB.")
        if not _VALID_OP_NAME_REGEX.match(node_def.name):
          raise ValueError("'%s' is not a valid node name" % node_def.name)
        c_op = None
      elif type(node_def).__name__ == "SwigPyObject":
        assert inputs is None
        assert output_types is None
        assert control_inputs is None
        assert input_types is None
        assert original_op is None
        assert op_def is None
        c_op = node_def
      else:
        raise TypeError("node_def needs to be a NodeDef: %s" % node_def)
    
      if not isinstance(g, Graph):
        raise TypeError("g needs to be a Graph: %s" % g)
      self._graph = g
    
      if inputs is None:
        inputs = []
      elif not isinstance(inputs, list):
        raise TypeError("inputs needs to be a list of Tensors: %s" % inputs)
      for a in inputs:
        if not isinstance(a, Tensor):
          raise TypeError("input needs to be a Tensor: %s" % a)
      if input_types is None:
        input_types = [i.dtype.base_dtype for i in inputs]
      else:
        if not all(
            x.is_compatible_with(i.dtype) for i, x in zip(inputs, input_types)):
          raise TypeError("In op '%s', input types (%s) are not compatible "
                          "with expected types (%s)" %
                          (node_def.name, [i.dtype for i in inputs], input_types))
    
      # Build the list of control inputs.
      control_input_ops = []
      if control_inputs:
        for c in control_inputs:
          control_op = None
          if isinstance(c, Operation):
            control_op = c
          elif isinstance(c, (Tensor, IndexedSlices)):
            control_op = c.op
          else:
            raise TypeError("Control input must be an Operation, "
                            "a Tensor, or IndexedSlices: %s" % c)
          control_input_ops.append(control_op)
    
      # This will be set by self.inputs.
      self._inputs_val = None
    
      # pylint: disable=protected-access
      self._id_value = self._graph._next_id()
      self._original_op = original_op
      self._traceback = tf_stack.extract_stack()
    
      # List of _UserDevSpecs holding code location of device context manager
      # invocations and the users original argument to them.
      self._device_code_locations = None
      # Dict mapping op name to file and line information for op colocation
      # context managers.
      self._colocation_code_locations = None
      self._control_flow_context = self.graph._get_control_flow_context()
      # pylint: enable=protected-access
    
      # Initialize self._c_op.
      if c_op:
        self._c_op = c_op
      else:
        if op_def is None:
          op_def = self._graph._get_op_def(node_def.op)
        # TODO(skyewm): op_def_library.apply_op() flattens the incoming inputs.
        # Refactor so we don't have to do this here.
        grouped_inputs = self._reconstruct_sequence_inputs(
            op_def, inputs, node_def.attr)
        self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,
>                                 control_input_ops)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2027: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

graph = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
node_def = name: "lambda_1_out/values_1"
op: "Pack"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "axis"
  value {
    i: 0
  }
}

inputs = [[<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]]
control_inputs = []

    def _create_c_op(graph, node_def, inputs, control_inputs):
      """Creates a TF_Operation.
    
      Args:
        graph: a `Graph`.
        node_def: `node_def_pb2.NodeDef` for the operation to create.
        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of
          `Tensor`s (corresponding to sequence inputs, e.g. "int64 * N",
          "list(int64)"). The length of the list should be equal to the number of
          inputs specified by this operation's op def.
        control_inputs: A list of `Operation`s to set as control dependencies.
    
      Returns:
        A wrapped TF_Operation*.
      """
      # pylint: disable=protected-access
      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),
                                      compat.as_str(node_def.name))
      if node_def.device:
        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))
      # Add inputs
      for op_input in inputs:
        if isinstance(op_input, (list, tuple)):
          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])
        else:
          c_api.TF_AddInput(op_desc, op_input._as_tf_output())
    
      # Add control inputs
      for control_input in control_inputs:
        c_api.TF_AddControlInput(op_desc, control_input._c_op)
      # pylint: enable=protected-access
    
      # Add attrs
      for name, attr_value in node_def.attr.items():
        serialized = attr_value.SerializeToString()
        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.
        # It might be worth creating a convenient way to re-use the same status.
        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)
    
      try:
        c_op = c_api.TF_FinishOperation(op_desc)
      except errors.InvalidArgumentError as e:
        # Convert to ValueError for backwards compatibility.
>       raise ValueError(str(e))
E       ValueError: Shapes must be equal rank, but are 3 and 2
E       	From merging shape 0 with other shapes. for 'lambda_1_out/values_1' (op: 'Pack') with input shapes: [?,2,2], [?,2].

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1867: ValueError

During handling of the above exception, another exception occurred:

graph = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
node_def = name: "lambda_1_out/packed"
op: "Pack"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "axis"
  value {
    i: 0
  }
}

inputs = [[<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]]
control_inputs = []

    def _create_c_op(graph, node_def, inputs, control_inputs):
      """Creates a TF_Operation.
    
      Args:
        graph: a `Graph`.
        node_def: `node_def_pb2.NodeDef` for the operation to create.
        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of
          `Tensor`s (corresponding to sequence inputs, e.g. "int64 * N",
          "list(int64)"). The length of the list should be equal to the number of
          inputs specified by this operation's op def.
        control_inputs: A list of `Operation`s to set as control dependencies.
    
      Returns:
        A wrapped TF_Operation*.
      """
      # pylint: disable=protected-access
      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),
                                      compat.as_str(node_def.name))
      if node_def.device:
        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))
      # Add inputs
      for op_input in inputs:
        if isinstance(op_input, (list, tuple)):
          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])
        else:
          c_api.TF_AddInput(op_desc, op_input._as_tf_output())
    
      # Add control inputs
      for control_input in control_inputs:
        c_api.TF_AddControlInput(op_desc, control_input._c_op)
      # pylint: enable=protected-access
    
      # Add attrs
      for name, attr_value in node_def.attr.items():
        serialized = attr_value.SerializeToString()
        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.
        # It might be worth creating a convenient way to re-use the same status.
        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)
    
      try:
>       c_op = c_api.TF_FinishOperation(op_desc)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 3 and 2
E       	From merging shape 0 with other shapes. for 'lambda_1_out/packed' (op: 'Pack') with input shapes: [?,2,2], [?,2].

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1864: InvalidArgumentError

During handling of the above exception, another exception occurred:

self = <tensorflow.python.framework.op_def_library.OpDefLibrary object at 0x7f25bb016e10>
op_type_name = 'HistogramSummary', name = 'lambda_1_out/', keywords = {}
op_info = <tensorflow.python.framework.op_def_library._OpInfo object at 0x7f25bb0270b8>
op_def = name: "HistogramSummary"
input_arg {
  name: "tag"
  type: DT_STRING
}
input_arg {
  name: "values"
  type_attr: "T"
}...   type: DT_BFLOAT16
      type: DT_UINT16
      type: DT_HALF
      type: DT_UINT32
      type: DT_UINT64
    }
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
deprecation_version = 0, default_type_attr_map = {'T': tf.float32}

    def _apply_op_helper(self, op_type_name, name=None, **keywords):
      """Implementation of apply_op that returns output_structure, op."""
      op_info = self._ops.get(op_type_name, None)
      if op_info is None:
        raise RuntimeError("Unrecognized Op name " + op_type_name)
      op_def = op_info.op_def
    
      # Determine the graph context.
      try:
        # Need to flatten all the arguments into a list.
        # pylint: disable=protected-access
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
        # pylint: enable=protected-access
      except AssertionError as e:
        raise RuntimeError(
            "Cannot determine graph for Op '%s' due to: %s"
            % (op_type_name, e.message))
    
      # Default name if not specified.
      if name is None:
        name = op_type_name
    
      # Check for deprecation
      deprecation_version = op_def.deprecation.version
      if deprecation_version:
        producer = g.graph_def_versions.producer
        if producer >= deprecation_version:
          raise NotImplementedError(
              ("Op %s is not available in GraphDef version %d. "
               "It has been removed in version %d. %s.") %
              (op_type_name, producer, deprecation_version,
               op_def.deprecation.explanation))
    
      # Fill in the list of default types for all "type" attrs.  This
      # will be used to choose a preferred dtype to convert to in the
      # absence of input type information.
      #
      # TODO(b/31302892): Currently the defaults don't work in the right
      # way if you have two inputs, one of whose type resolution depends
      # on the other.  Handling this will require restructuring this code
      # significantly.
      default_type_attr_map = {}
      for attr_def in op_def.attr:
        if attr_def.type != "type":
          continue
        key = attr_def.name
        if attr_def.HasField("default_value"):
          default_type_attr_map[key] = dtypes.as_dtype(
              attr_def.default_value.type)
    
      # Requires that op_def has passed validation (using the C++
      # ValidateOpDef() from ../framework/op_def_util.h).
      attrs = {}
      inputs = []
      input_types = []
      with g.as_default(), ops.name_scope(name) as scope:
    
        # Perform input type inference
        inferred_from = {}
        for input_arg in op_def.input_arg:
          input_name = input_arg.name
          if input_name in keywords:
            values = keywords.pop(input_name)
          elif input_name + "_" in keywords:
            # Handle the case where the name is a keyword or built-in
            # for Python so we use the name + _ instead.
            input_name += "_"
            values = keywords.pop(input_name)
          else:
            raise TypeError("No argument for input " + input_name)
    
          # Goals:
          # * Convert values to Tensors if it contains constants.
          # * Verify that values is a list if that matches the input_arg's
          #   type.
          # * If the input_arg's type is determined by attrs, either set
          #   those attrs and validate those attr values are legal (if
          #   they have not yet been set) or validate the input matches
          #   the type indicated by the attrs (if they have already been
          #   inferred via an earlier input).
          # * If the input_arg has an explicit type, make sure the input
          #   conforms.
    
          if _IsListParameter(input_arg):
            if not _IsListValue(values):
              raise TypeError(
                  "Expected list for '%s' argument to '%s' Op, not %s." %
                  (input_name, op_type_name, values))
            # In cases where we expect all elements of the list to have the
            # same dtype, try to cast non-Tensor elements to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.number_attr:
              if input_arg.type_attr in attrs:
                dtype = attrs[input_arg.type_attr]
              else:
                for t in values:
                  if isinstance(t, ops.Tensor):
                    dtype = t.dtype
                    break
    
              # dtype still not found, prefer using the default dtype
              # from the attr.
              if dtype is None and input_arg.type_attr in default_type_attr_map:
                default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              if not input_arg.is_ref and dtype:
                dtype = dtypes.as_dtype(dtype).base_dtype
              values = ops.internal_convert_n_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype if dtype else None,
                  preferred_dtype=default_dtype,
                  as_ref=input_arg.is_ref)
              if input_arg.number_attr and len(
                  set(v.dtype.base_dtype for v in values)) > 1:
                raise TypeError()  # All types should match.
            except (TypeError, ValueError):
              # What types does the conversion function think values have?
              observed_types = []
              for value in values:
                try:
                  converted_value = ops.internal_convert_to_tensor(
                      value, as_ref=input_arg.is_ref)
                  observed_types.append(converted_value.dtype.base_dtype.name)
                except (TypeError, ValueError):
                  observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
              observed = ", ".join(observed_types)
    
              prefix = (
                  "Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                  (input_name, op_type_name, observed))
              if input_arg.number_attr:
                if input_arg.type != types_pb2.DT_INVALID:
                  raise TypeError("%s that do not match expected type %s." %
                                  (prefix, dtype.name))
                elif input_arg.type_attr in attrs:
                  raise TypeError("%s that do not match type %s inferred from "
                                  "earlier arguments." %
                                  (prefix, dtype.name))
                else:
                  raise TypeError("%s that don't all match." % prefix)
              else:
                raise TypeError(
                    "%s that are invalid. Tensors: %s" % (prefix, values))
    
            types = [x.dtype for x in values]
            inputs.extend(values)
          else:
            # In cases where we have an expected type, try to convert non-Tensor
            # arguments to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            elif input_arg.type_attr in default_type_attr_map:
              # The dtype could not be inferred solely from the inputs,
              # so we prefer the attr's default, so code that adds a new attr
              # with a default is backwards compatible.
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              values = ops.internal_convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
            except TypeError as err:
              if dtype is None:
                raise err
              else:
                raise TypeError(
                    "Expected %s passed to parameter '%s' of op '%s', got %s of "
                    "type '%s' instead. Error: %s" %
                    (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,
                     repr(values), type(values).__name__, err))
            except ValueError:
              # What type does convert_to_tensor think it has?
              try:
                observed = ops.internal_convert_to_tensor(
>                   values, as_ref=input_arg.is_ref).dtype.name

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:541: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
dtype = None, name = None, as_ref = False, preferred_dtype = None
ctx = <tensorflow.python.eager.context.Context object at 0x7f25ae620f98>
accept_symbolic_tensors = True, accept_composite_tensors = False

    def internal_convert_to_tensor(value,
                                   dtype=None,
                                   name=None,
                                   as_ref=False,
                                   preferred_dtype=None,
                                   ctx=None,
                                   accept_symbolic_tensors=True,
                                   accept_composite_tensors=False):
      """Implementation of the public convert_to_tensor."""
      if ctx is None:
        ctx = context.context()
      if isinstance(value, EagerTensor):
        if ctx.executing_eagerly():
          if dtype is not None:
            dtype = dtypes.as_dtype(dtype)
            value = _TensorTensorConversionFunction(value, dtype=dtype)
          return value
        else:
          graph = get_default_graph()
          if not graph.building_function:
            raise RuntimeError("Attempting to capture an EagerTensor without "
                               "building a function.")
          return graph.capture(value, name=name)
      elif ((not accept_symbolic_tensors) and isinstance(value, Tensor) and
            ctx.executing_eagerly()):
        # Found a symbolic tensor in an eager context.
        # This happens when we use the Keras functional API (i.e. calling layers
        # on the output of `keras.Input()`, which is symbolic) while eager
        # execution is enabled.
        if _is_keras_symbolic_tensor(value):
          # If the graph of the tensor isn't the Keras graph, we should still
          # fail, for the time being. TODO(fchollet): consider allowing
          # all symbolic tensors to raise this exception in this case.
          raise core._SymbolicException(  # pylint: disable=protected-access
              "Using the symbolic output of a Keras layer during eager execution.")
    
      if dtype is not None:
        dtype = dtypes.as_dtype(dtype)
      unwrapped_type = type(value)
      conversion_func_list = _tensor_conversion_func_cache.get(unwrapped_type, None)
      if conversion_func_list is None:
        with _tensor_conversion_func_lock:
          conversion_func_list = []
          for _, funcs_at_priority in sorted(
              _tensor_conversion_func_registry.items()):
            for base_type, conversion_func in funcs_at_priority:
              if isinstance(value, base_type):
                conversion_func_list.append((base_type, conversion_func))
          _tensor_conversion_func_cache[unwrapped_type] = conversion_func_list
    
      for base_type, conversion_func in conversion_func_list:
        # If dtype is None but preferred_dtype is not None, we try to
        # cast to preferred_dtype first.
        ret = None
        if dtype is None and preferred_dtype is not None:
          try:
            ret = conversion_func(
                value, dtype=preferred_dtype, name=name, as_ref=as_ref)
          except (TypeError, ValueError, errors.UnimplementedError,
                  errors.InvalidArgumentError):
            # Could not coerce the conversion to use the preferred dtype.
            ret = None
    
          if ret is not None and ret is not NotImplemented:
            if (ret.dtype.base_dtype !=
                dtypes.as_dtype(preferred_dtype).base_dtype):
              raise TypeError("convert_to_tensor did not convert to "
                              "the preferred dtype: %s vs %s " %
                              (ret.dtype.base_dtype,
                               dtypes.as_dtype(preferred_dtype).base_dtype))
    
        if ret is None:
>         ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

v = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
dtype = tf.float32, name = None, as_ref = False

    def _autopacking_conversion_function(v, dtype=None, name=None, as_ref=False):
      """Tensor conversion function that automatically packs arguments."""
      if as_ref:
        return NotImplemented
      inferred_dtype = _get_dtype_from_nested_lists(v)
      if inferred_dtype is None:
        # We did not find any tensor-like objects in the nested lists, so defer to
        # other conversion functions.
        return NotImplemented
      if dtype is None:
        dtype = inferred_dtype
      elif dtype != inferred_dtype:
        v = nest.map_structure(_cast_nested_seqs_to_dtype(dtype), v)
>     return _autopacking_helper(v, dtype, name or "packed")

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

list_or_tuple = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
dtype = tf.float32, name = 'packed'

    def _autopacking_helper(list_or_tuple, dtype, name):
      """Converts the given list or tuple to a tensor by packing.
    
      Args:
        list_or_tuple: A (possibly nested) list or tuple containing a tensor.
        dtype: The element type of the returned tensor.
        name: A name for the returned tensor.
    
      Returns:
        A `tf.Tensor` with value equivalent to `list_or_tuple`.
      """
      if context.executing_eagerly():
        # NOTE: Fast path when all the items are tensors, this doesn't do any type
        # checking.
        if all(ops.is_dense_tensor_like(elem) for elem in list_or_tuple):
          return gen_array_ops.pack(list_or_tuple, name=name)
      must_pack = False
      converted_elems = []
      with ops.name_scope(name) as scope:
        for i, elem in enumerate(list_or_tuple):
          if ops.is_dense_tensor_like(elem):
            if dtype is not None and elem.dtype.base_dtype != dtype:
              raise TypeError("Cannot convert a list containing a tensor of dtype "
                              "%s to %s (Tensor is: %r)" %
                              (elem.dtype, dtype, elem))
            converted_elems.append(elem)
            must_pack = True
          elif isinstance(elem, (list, tuple)):
            converted_elem = _autopacking_helper(elem, dtype, str(i))
            if ops.is_dense_tensor_like(converted_elem):
              must_pack = True
            converted_elems.append(converted_elem)
          else:
            converted_elems.append(elem)
        if must_pack:
          elems_as_tensors = []
          for i, elem in enumerate(converted_elems):
            if ops.is_dense_tensor_like(elem):
              elems_as_tensors.append(elem)
            else:
              # NOTE(mrry): This is inefficient, but it enables us to
              # handle the case where the list arguments are other
              # convertible-to-tensor types, such as numpy arrays.
              elems_as_tensors.append(
                  constant_op.constant(elem, dtype=dtype, name=str(i)))
>         return gen_array_ops.pack(elems_as_tensors, name=scope)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1095: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
axis = 0, name = 'lambda_1_out/packed/'

    def pack(values, axis=0, name=None):
      r"""Packs a list of `N` rank-`R` tensors into one rank-`(R+1)` tensor.
    
      Packs the `N` tensors in `values` into a tensor with rank one higher than each
      tensor in `values`, by packing them along the `axis` dimension.
      Given a list of tensors of shape `(A, B, C)`;
    
      if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.
      if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.
      Etc.
    
      For example:
    
      ```
      # 'x' is [1, 4]
      # 'y' is [2, 5]
      # 'z' is [3, 6]
      pack([x, y, z]) => [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.
      pack([x, y, z], axis=1) => [[1, 2, 3], [4, 5, 6]]
      ```
    
      This is the opposite of `unpack`.
    
      Args:
        values: A list of at least 1 `Tensor` objects with the same type.
          Must be of same shape and type.
        axis: An optional `int`. Defaults to `0`.
          Dimension along which to pack.  Negative values wrap around, so the
          valid range is `[-(R+1), R+1)`.
        name: A name for the operation (optional).
    
      Returns:
        A `Tensor`. Has the same type as `values`.
      """
      _ctx = _context._context or _context.context()
      if _ctx is not None and _ctx._thread_local_data.is_eager:
        try:
          _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
            _ctx._context_handle, _ctx._thread_local_data.device_name, "Pack",
            name, _ctx._post_execution_callbacks, values, "axis", axis)
          return _result
        except _core._FallbackException:
          try:
            return pack_eager_fallback(
                values, axis=axis, name=name, ctx=_ctx)
          except _core._SymbolicException:
            pass  # Add nodes to the TensorFlow graph.
        except _core._NotOkStatusException as e:
          if name is not None:
            message = e.message + " name: " + name
          else:
            message = e.message
          _six.raise_from(_core._status_to_exception(e.code, message), None)
      # Add nodes to the TensorFlow graph.
      if not isinstance(values, (list, tuple)):
        raise TypeError(
            "Expected list for 'values' argument to "
            "'pack' Op, not %r." % values)
      _attr_N = len(values)
      if axis is None:
        axis = 0
      axis = _execute.make_int(axis, "axis")
      _, _, _op = _op_def_lib._apply_op_helper(
>           "Pack", values=values, axis=axis, name=name)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:5897: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tensorflow.python.framework.op_def_library.OpDefLibrary object at 0x7f25bb43d048>
op_type_name = 'Pack', name = 'lambda_1_out/packed/', keywords = {}
op_info = <tensorflow.python.framework.op_def_library._OpInfo object at 0x7f25bb445588>
op_def = name: "Pack"
input_arg {
  name: "values"
  type_attr: "T"
  number_attr: "N"
}
output_arg {
  name: "output"
  type_a... minimum: 1
}
attr {
  name: "T"
  type: "type"
}
attr {
  name: "axis"
  type: "int"
  default_value {
    i: 0
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
deprecation_version = 0, default_type_attr_map = {}

    def _apply_op_helper(self, op_type_name, name=None, **keywords):
      """Implementation of apply_op that returns output_structure, op."""
      op_info = self._ops.get(op_type_name, None)
      if op_info is None:
        raise RuntimeError("Unrecognized Op name " + op_type_name)
      op_def = op_info.op_def
    
      # Determine the graph context.
      try:
        # Need to flatten all the arguments into a list.
        # pylint: disable=protected-access
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
        # pylint: enable=protected-access
      except AssertionError as e:
        raise RuntimeError(
            "Cannot determine graph for Op '%s' due to: %s"
            % (op_type_name, e.message))
    
      # Default name if not specified.
      if name is None:
        name = op_type_name
    
      # Check for deprecation
      deprecation_version = op_def.deprecation.version
      if deprecation_version:
        producer = g.graph_def_versions.producer
        if producer >= deprecation_version:
          raise NotImplementedError(
              ("Op %s is not available in GraphDef version %d. "
               "It has been removed in version %d. %s.") %
              (op_type_name, producer, deprecation_version,
               op_def.deprecation.explanation))
    
      # Fill in the list of default types for all "type" attrs.  This
      # will be used to choose a preferred dtype to convert to in the
      # absence of input type information.
      #
      # TODO(b/31302892): Currently the defaults don't work in the right
      # way if you have two inputs, one of whose type resolution depends
      # on the other.  Handling this will require restructuring this code
      # significantly.
      default_type_attr_map = {}
      for attr_def in op_def.attr:
        if attr_def.type != "type":
          continue
        key = attr_def.name
        if attr_def.HasField("default_value"):
          default_type_attr_map[key] = dtypes.as_dtype(
              attr_def.default_value.type)
    
      # Requires that op_def has passed validation (using the C++
      # ValidateOpDef() from ../framework/op_def_util.h).
      attrs = {}
      inputs = []
      input_types = []
      with g.as_default(), ops.name_scope(name) as scope:
    
        # Perform input type inference
        inferred_from = {}
        for input_arg in op_def.input_arg:
          input_name = input_arg.name
          if input_name in keywords:
            values = keywords.pop(input_name)
          elif input_name + "_" in keywords:
            # Handle the case where the name is a keyword or built-in
            # for Python so we use the name + _ instead.
            input_name += "_"
            values = keywords.pop(input_name)
          else:
            raise TypeError("No argument for input " + input_name)
    
          # Goals:
          # * Convert values to Tensors if it contains constants.
          # * Verify that values is a list if that matches the input_arg's
          #   type.
          # * If the input_arg's type is determined by attrs, either set
          #   those attrs and validate those attr values are legal (if
          #   they have not yet been set) or validate the input matches
          #   the type indicated by the attrs (if they have already been
          #   inferred via an earlier input).
          # * If the input_arg has an explicit type, make sure the input
          #   conforms.
    
          if _IsListParameter(input_arg):
            if not _IsListValue(values):
              raise TypeError(
                  "Expected list for '%s' argument to '%s' Op, not %s." %
                  (input_name, op_type_name, values))
            # In cases where we expect all elements of the list to have the
            # same dtype, try to cast non-Tensor elements to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.number_attr:
              if input_arg.type_attr in attrs:
                dtype = attrs[input_arg.type_attr]
              else:
                for t in values:
                  if isinstance(t, ops.Tensor):
                    dtype = t.dtype
                    break
    
              # dtype still not found, prefer using the default dtype
              # from the attr.
              if dtype is None and input_arg.type_attr in default_type_attr_map:
                default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              if not input_arg.is_ref and dtype:
                dtype = dtypes.as_dtype(dtype).base_dtype
              values = ops.internal_convert_n_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype if dtype else None,
                  preferred_dtype=default_dtype,
                  as_ref=input_arg.is_ref)
              if input_arg.number_attr and len(
                  set(v.dtype.base_dtype for v in values)) > 1:
                raise TypeError()  # All types should match.
            except (TypeError, ValueError):
              # What types does the conversion function think values have?
              observed_types = []
              for value in values:
                try:
                  converted_value = ops.internal_convert_to_tensor(
                      value, as_ref=input_arg.is_ref)
                  observed_types.append(converted_value.dtype.base_dtype.name)
                except (TypeError, ValueError):
                  observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
              observed = ", ".join(observed_types)
    
              prefix = (
                  "Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                  (input_name, op_type_name, observed))
              if input_arg.number_attr:
                if input_arg.type != types_pb2.DT_INVALID:
                  raise TypeError("%s that do not match expected type %s." %
                                  (prefix, dtype.name))
                elif input_arg.type_attr in attrs:
                  raise TypeError("%s that do not match type %s inferred from "
                                  "earlier arguments." %
                                  (prefix, dtype.name))
                else:
                  raise TypeError("%s that don't all match." % prefix)
              else:
                raise TypeError(
                    "%s that are invalid. Tensors: %s" % (prefix, values))
    
            types = [x.dtype for x in values]
            inputs.extend(values)
          else:
            # In cases where we have an expected type, try to convert non-Tensor
            # arguments to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            elif input_arg.type_attr in default_type_attr_map:
              # The dtype could not be inferred solely from the inputs,
              # so we prefer the attr's default, so code that adds a new attr
              # with a default is backwards compatible.
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              values = ops.internal_convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
            except TypeError as err:
              if dtype is None:
                raise err
              else:
                raise TypeError(
                    "Expected %s passed to parameter '%s' of op '%s', got %s of "
                    "type '%s' instead. Error: %s" %
                    (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,
                     repr(values), type(values).__name__, err))
            except ValueError:
              # What type does convert_to_tensor think it has?
              try:
                observed = ops.internal_convert_to_tensor(
                    values, as_ref=input_arg.is_ref).dtype.name
              except ValueError as err:
                raise ValueError(
                    "Tried to convert '%s' to a tensor and failed. Error: %s" %
                    (input_name, err))
              prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                        (input_name, op_type_name, observed))
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError("%s expected type of %s." %
                                (prefix, dtypes.as_dtype(input_arg.type).name))
              else:
                # Update the maps with the default, if needed.
                k = input_arg.type_attr
                if k in default_type_attr_map:
                  if k not in attrs:
                    attrs[k] = default_type_attr_map[k]
                    if k not in inferred_from:
                      inferred_from[k] = "Default in OpDef"
    
                raise TypeError(
                    "%s type %s of argument '%s'." %
                    (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
    
            types = [values.dtype]
            inputs.append(values)
          base_types = [x.base_dtype for x in types]
    
          if input_arg.number_attr:
            # <number-attr> * <type> or <number-attr> * <type-attr>
            if input_arg.number_attr in attrs:
              if len(values) != attrs[input_arg.number_attr]:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d must match "
                    "length %d of argument '%s'." %
                    (input_name, op_type_name, len(values),
                     attrs[input_arg.number_attr],
                     inferred_from[input_arg.number_attr]))
            else:
              attrs[input_arg.number_attr] = len(values)
              inferred_from[input_arg.number_attr] = input_name
              num_attr = _Attr(op_def, input_arg.number_attr)
              if num_attr.has_minimum and len(values) < num_attr.minimum:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d shorter "
                    "than minimum length %d." %
                    (input_name, op_type_name, len(values), num_attr.minimum))
            # All tensors must have the same base type.
            if any(bt != base_types[0] for bt in base_types):
              raise TypeError(
                  "All tensors passed to '%s' of '%s' Op "
                  "must have the same type." %
                  (input_name, op_type_name))
            if input_arg.type != types_pb2.DT_INVALID:
              # <number-attr> * <type> case
              if base_types and base_types[0] != input_arg.type:
                assert False, "Unreachable"
            elif input_arg.type_attr in attrs:
              # <number-attr> * <type-attr> case, where <type-attr> already
              # has an inferred value.
              if base_types and base_types[0] != attrs[input_arg.type_attr]:
                assert False, "Unreachable"
            else:
              # <number-attr> * <type-attr> case, where we are now setting
              # the <type-attr> based on this input
              if not base_types:
                raise TypeError(
                    "Don't know how to infer type variable from empty input "
                    "list passed to input '%s' of '%s' Op." %
                    (input_name, op_type_name))
              attrs[input_arg.type_attr] = base_types[0]
              inferred_from[input_arg.type_attr] = input_name
              type_attr = _Attr(op_def, input_arg.type_attr)
              _SatisfiesTypeConstraint(base_types[0], type_attr,
                                       param_name=input_name)
          elif input_arg.type_attr:
            # <type-attr>
            attr_value = base_types[0]
            if input_arg.type_attr in attrs:
              if attrs[input_arg.type_attr] != attr_value:
                assert False, "Unreachable"
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_attr),
                                         param_name=input_name)
              attrs[input_arg.type_attr] = attr_value
              inferred_from[input_arg.type_attr] = input_name
          elif input_arg.type_list_attr:
            # <type-list-attr>
            attr_value = base_types
            if input_arg.type_list_attr in attrs:
              if attrs[input_arg.type_list_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type list of %s that does not "
                    "match type list %s of argument '%s'." %
                    (input_name, op_type_name,
                     ", ".join(dtypes.as_dtype(x).name for x in attr_value),
                     ", ".join(dtypes.as_dtype(x).name
                               for x in attrs[input_arg.type_list_attr]),
                     inferred_from[input_arg.type_list_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_list_attr),
                                         param_name=input_name)
              attrs[input_arg.type_list_attr] = attr_value
              inferred_from[input_arg.type_list_attr] = input_name
          else:
            # single Tensor with specified type
            if base_types[0] != input_arg.type:
              assert False, "Unreachable"
    
          if input_arg.is_ref:
            if not all(x._is_ref_dtype for x in types):  # pylint: disable=protected-access
              raise TypeError(
                  ("'%s' Op requires that input '%s' be a mutable tensor "
                   "(e.g.: a tf.Variable)") % (op_type_name, input_name))
            input_types.extend(types)
          else:
            input_types.extend(base_types)
    
        # Process remaining attrs
        for attr in op_def.attr:
          # Skip attrs that have already had their values inferred
          if attr.name in attrs:
            if attr.name in keywords:
              raise TypeError(
                  "Should not specify value for inferred attr '%s'." % attr.name)
            continue
          if attr.name in keywords:
            attrs[attr.name] = keywords.pop(attr.name)
          elif attr.name + "_" in keywords:
            # Attrs whose names match Python keywords have an extra '_'
            # appended, so we must check for that as well.
            attrs[attr.name] = keywords.pop(attr.name + "_")
          else:
            raise TypeError("No argument for attr " + attr.name)
    
        # Convert attr values to AttrValue protos.
        attr_protos = {}
        for attr_def in op_def.attr:
          key = attr_def.name
          value = attrs[key]
          attr_value = attr_value_pb2.AttrValue()
          if attr_def.HasField("default_value") and value is None:
            attr_value.CopyFrom(attr_def.default_value)
            attr_protos[key] = attr_value
            continue
          if attr_def.type.startswith("list("):
            if not _IsListValue(value):
              raise TypeError("Expected list for attr " + key)
            if attr_def.has_minimum:
              if len(value) < attr_def.minimum:
                raise ValueError("Attr '%s' of '%s' Op passed list of length %d "
                                 "less than minimum %d." %
                                 (key, op_type_name, len(value),
                                  attr_def.minimum))
            attr_value.list.SetInParent()
          if attr_def.type == "string":
            attr_value.s = _MakeStr(value, key)
            if attr_def.HasField("allowed_values"):
              if attr_value.s not in attr_def.allowed_values.list.s:
                raise ValueError(
                    "Attr '%s' of '%s' Op passed string '%s' not in: \"%s\"." %
                    (key, op_type_name, compat.as_text(attr_value.s),
                     '", "'.join(map(compat.as_text,
                                     attr_def.allowed_values.list.s))))
          elif attr_def.type == "list(string)":
            attr_value.list.s.extend([_MakeStr(x, key) for x in value])
            if attr_def.HasField("allowed_values"):
              for x in attr_value.list.s:
                if x not in attr_def.allowed_values.list.s:
                  raise ValueError(
                      "Attr '%s' of '%s' Op passed string '%s' not in: \"%s\"." %
                      (key, op_type_name, compat.as_text(x),
                       '", "'.join(map(compat.as_text,
                                       attr_def.allowed_values.list.s))))
          elif attr_def.type == "int":
            attr_value.i = _MakeInt(value, key)
            if attr_def.has_minimum:
              if attr_value.i < attr_def.minimum:
                raise ValueError(
                    "Attr '%s' of '%s' Op passed %d less than minimum %d." %
                    (key, op_type_name, attr_value.i, attr_def.minimum))
          elif attr_def.type == "list(int)":
            attr_value.list.i.extend([_MakeInt(x, key) for x in value])
          elif attr_def.type == "float":
            attr_value.f = _MakeFloat(value, key)
          elif attr_def.type == "list(float)":
            attr_value.list.f.extend([_MakeFloat(x, key) for x in value])
          elif attr_def.type == "bool":
            attr_value.b = _MakeBool(value, key)
          elif attr_def.type == "list(bool)":
            attr_value.list.b.extend([_MakeBool(x, key) for x in value])
          elif attr_def.type == "type":
            attr_value.type = _MakeType(value, attr_def)
          elif attr_def.type == "list(type)":
            attr_value.list.type.extend(
                [_MakeType(x, attr_def) for x in value])
          elif attr_def.type == "shape":
            attr_value.shape.CopyFrom(_MakeShape(value, key))
          elif attr_def.type == "list(shape)":
            attr_value.list.shape.extend(
                [_MakeShape(x, key) for x in value])
          elif attr_def.type == "tensor":
            attr_value.tensor.CopyFrom(_MakeTensor(value, key))
          elif attr_def.type == "list(tensor)":
            attr_value.list.tensor.extend(
                [_MakeTensor(x, key) for x in value])
          elif attr_def.type == "func":
            attr_value.func.CopyFrom(_MakeFunc(value, key))
          elif attr_def.type == "list(func)":
            attr_value.list.func.extend([_MakeFunc(x, key) for x in value])
          else:
            raise TypeError("Unrecognized Attr type " + attr_def.type)
    
          attr_protos[key] = attr_value
        del attrs  # attrs is no longer authoritative, use attr_protos instead
    
        # Determine output types (possibly using attrs)
        output_structure = []
        for arg in op_def.output_arg:
          if arg.number_attr:
            n = _AttrValue(attr_protos, arg.number_attr).i
            output_structure.append(n)
          elif arg.type_attr:
            t = _AttrValue(attr_protos, arg.type_attr)
            output_structure.append(None)
          elif arg.type_list_attr:
            t = _AttrValue(attr_protos, arg.type_list_attr)
            output_structure.append(len(t.list.type))
          else:
            output_structure.append(None)
    
        if keywords:
          raise TypeError("apply_op() got unexpected keyword arguments: " +
                          ", ".join(sorted(keywords.keys())))
    
        # NOTE(mrry): We add an explicit colocation constraint between
        # the newly created op and any of its reference-typed inputs.
        must_colocate_inputs = [val for arg, val in zip(op_def.input_arg, inputs)
                                if arg.is_ref]
        with _MaybeColocateWith(must_colocate_inputs):
          # Add Op to graph
          op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,
                           input_types=input_types, attrs=attr_protos,
>                          op_def=op_def)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:788: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>, 'Pack', [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>])
kwargs = {'attrs': {'N': i: 2
, 'T': type: DT_FLOAT
, 'axis': i: 0
}, 'dtypes': None, 'input_types': [tf.float32, tf.float32], 'name': 'lambda_1_out/packed/', ...}
invalid_args = []
named_args = {'attrs': {'N': i: 2
, 'T': type: DT_FLOAT
, 'axis': i: 0
}, 'compute_device': True, 'compute_shapes': True, 'dtypes': None, ...}
arg_name = 'compute_shapes'
spec = DeprecatedArgSpec(position=8, has_ok_value=False, ok_value=None)

    @functools.wraps(func)
    def new_func(*args, **kwargs):
      """Deprecation wrapper."""
      # TODO(apassos) figure out a way to have reasonable performance with
      # deprecation warnings and eager mode.
      if is_in_graph_mode.IS_IN_GRAPH_MODE() and _PRINT_DEPRECATION_WARNINGS:
        invalid_args = []
        named_args = tf_inspect.getcallargs(func, *args, **kwargs)
        for arg_name, spec in iter(deprecated_positions.items()):
          if (spec.position < len(args) and
              not (spec.has_ok_value and
                   _same_value(named_args[arg_name], spec.ok_value))):
            invalid_args.append(arg_name)
        if is_varargs_deprecated and len(args) > len(arg_spec.args):
          invalid_args.append(arg_spec.varargs)
        if is_kwargs_deprecated and kwargs:
          invalid_args.append(arg_spec.varkw)
        for arg_name in deprecated_arg_names:
          if (arg_name in kwargs and
              not (deprecated_positions[arg_name].has_ok_value and
                   _same_value(named_args[arg_name],
                               deprecated_positions[arg_name].ok_value))):
            invalid_args.append(arg_name)
        for arg_name in invalid_args:
          if (func, arg_name) not in _PRINTED_WARNING:
            if warn_once:
              _PRINTED_WARNING[(func, arg_name)] = True
            logging.warning(
                'From %s: calling %s (from %s) with %s is deprecated and will '
                'be removed %s.\nInstructions for updating:\n%s',
                _call_location(), decorator_utils.get_qualified_name(func),
                func.__module__, arg_name,
                'in a future version' if date is None else ('after %s' % date),
                instructions)
>     return func(*args, **kwargs)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
op_type = 'Pack'
inputs = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
dtypes = None, input_types = [tf.float32, tf.float32]
name = 'lambda_1_out/packed'
attrs = {'N': i: 2
, 'T': type: DT_FLOAT
, 'axis': i: 0
}
op_def = name: "Pack"
input_arg {
  name: "values"
  type_attr: "T"
  number_attr: "N"
}
output_arg {
  name: "output"
  type_a... minimum: 1
}
attr {
  name: "T"
  type: "type"
}
attr {
  name: "axis"
  type: "int"
  default_value {
    i: 0
  }
}

compute_device = True

    @deprecated_args(None,
                     "Shapes are always computed; don't use the compute_shapes "
                     "as it has no effect.", "compute_shapes")
    def create_op(
        self,
        op_type,
        inputs,
        dtypes=None,  # pylint: disable=redefined-outer-name
        input_types=None,
        name=None,
        attrs=None,
        op_def=None,
        compute_shapes=True,
        compute_device=True):
      """Creates an `Operation` in this graph.
    
      This is a low-level interface for creating an `Operation`. Most
      programs will not call this method directly, and instead use the
      Python op constructors, such as `tf.constant()`, which add ops to
      the default graph.
    
      Args:
        op_type: The `Operation` type to create. This corresponds to the
          `OpDef.name` field for the proto that defines the operation.
        inputs: A list of `Tensor` objects that will be inputs to the `Operation`.
        dtypes: (Optional) A list of `DType` objects that will be the types of the
          tensors that the operation produces.
        input_types: (Optional.) A list of `DType`s that will be the types of the
          tensors that the operation consumes. By default, uses the base `DType`
          of each input in `inputs`. Operations that expect reference-typed inputs
          must specify `input_types` explicitly.
        name: (Optional.) A string name for the operation. If not specified, a
          name is generated based on `op_type`.
        attrs: (Optional.) A dictionary where the key is the attribute name (a
          string) and the value is the respective `attr` attribute of the
          `NodeDef` proto that will represent the operation (an `AttrValue`
          proto).
        op_def: (Optional.) The `OpDef` proto that describes the `op_type` that
          the operation will have.
        compute_shapes: (Optional.) Deprecated. Has no effect (shapes are always
          computed).
        compute_device: (Optional.) If True, device functions will be executed to
          compute the device property of the Operation.
    
      Raises:
        TypeError: if any of the inputs is not a `Tensor`.
        ValueError: if colocation conflicts with existing device assignment.
    
      Returns:
        An `Operation` object.
      """
      del compute_shapes
    
      self._check_not_finalized()
      for idx, a in enumerate(inputs):
        if not isinstance(a, Tensor):
          raise TypeError("Input #%d is not a tensor: %s" % (idx, a))
      if name is None:
        name = op_type
      # If a names ends with a '/' it is a "name scope" and we use it as-is,
      # after removing the trailing '/'.
      if name and name[-1] == "/":
        name = name_from_scope_name(name)
      else:
        name = self.unique_name(name)
    
      node_def = _NodeDef(op_type, name, device=None, attrs=attrs)
    
      input_ops = set([t.op for t in inputs])
      control_inputs = self._control_dependencies_for_inputs(input_ops)
      # _create_op_helper mutates the new Operation. `_mutation_lock` ensures a
      # Session.run call cannot occur between creating and mutating the op.
      with self._mutation_lock():
        ret = Operation(
            node_def,
            self,
            inputs=inputs,
            output_types=dtypes,
            control_inputs=control_inputs,
            input_types=input_types,
            original_op=self._default_original_op,
>           op_def=op_def)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'Operation' object has no attribute '_c_op'") raised in repr()] Operation object at 0x7f258c4aaa90>
node_def = name: "lambda_1_out/packed"
op: "Pack"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "axis"
  value {
    i: 0
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
inputs = [<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]
output_types = None, control_inputs = [], input_types = [tf.float32, tf.float32]
original_op = None
op_def = name: "Pack"
input_arg {
  name: "values"
  type_attr: "T"
  number_attr: "N"
}
output_arg {
  name: "output"
  type_a... minimum: 1
}
attr {
  name: "T"
  type: "type"
}
attr {
  name: "axis"
  type: "int"
  default_value {
    i: 0
  }
}


    def __init__(self,
                 node_def,
                 g,
                 inputs=None,
                 output_types=None,
                 control_inputs=None,
                 input_types=None,
                 original_op=None,
                 op_def=None):
      r"""Creates an `Operation`.
    
      NOTE: This constructor validates the name of the `Operation` (passed
      as `node_def.name`). Valid `Operation` names match the following
      regular expression:
    
          [A-Za-z0-9.][A-Za-z0-9_.\\-/]*
    
      Args:
        node_def: `node_def_pb2.NodeDef`.  `NodeDef` for the `Operation`. Used for
          attributes of `node_def_pb2.NodeDef`, typically `name`, `op`, and
          `device`.  The `input` attribute is irrelevant here as it will be
          computed when generating the model.
        g: `Graph`. The parent graph.
        inputs: list of `Tensor` objects. The inputs to this `Operation`.
        output_types: list of `DType` objects.  List of the types of the `Tensors`
          computed by this operation.  The length of this list indicates the
          number of output endpoints of the `Operation`.
        control_inputs: list of operations or tensors from which to have a control
          dependency.
        input_types: List of `DType` objects representing the types of the tensors
          accepted by the `Operation`.  By default uses `[x.dtype.base_dtype for x
          in inputs]`.  Operations that expect reference-typed inputs must specify
          these explicitly.
        original_op: Optional. Used to associate the new `Operation` with an
          existing `Operation` (for example, a replica with the op that was
          replicated).
        op_def: Optional. The `op_def_pb2.OpDef` proto that describes the op type
          that this `Operation` represents.
    
      Raises:
        TypeError: if control inputs are not Operations or Tensors,
          or if `node_def` is not a `NodeDef`,
          or if `g` is not a `Graph`,
          or if `inputs` are not tensors,
          or if `inputs` and `input_types` are incompatible.
        ValueError: if the `node_def` name is not valid.
      """
      # For internal use only: `node_def` can be set to a TF_Operation to create
      # an Operation for that op. This is useful for creating Operations for ops
      # indirectly created by C API methods, e.g. the ops created by
      # TF_ImportGraphDef. When `node_def` is a TF_Operation, all optional fields
      # should be None.
    
      if isinstance(node_def, node_def_pb2.NodeDef):
        if node_def.ByteSize() >= (1 << 31) or node_def.ByteSize() < 0:
          raise ValueError(
              "Cannot create a tensor proto whose content is larger than 2GB.")
        if not _VALID_OP_NAME_REGEX.match(node_def.name):
          raise ValueError("'%s' is not a valid node name" % node_def.name)
        c_op = None
      elif type(node_def).__name__ == "SwigPyObject":
        assert inputs is None
        assert output_types is None
        assert control_inputs is None
        assert input_types is None
        assert original_op is None
        assert op_def is None
        c_op = node_def
      else:
        raise TypeError("node_def needs to be a NodeDef: %s" % node_def)
    
      if not isinstance(g, Graph):
        raise TypeError("g needs to be a Graph: %s" % g)
      self._graph = g
    
      if inputs is None:
        inputs = []
      elif not isinstance(inputs, list):
        raise TypeError("inputs needs to be a list of Tensors: %s" % inputs)
      for a in inputs:
        if not isinstance(a, Tensor):
          raise TypeError("input needs to be a Tensor: %s" % a)
      if input_types is None:
        input_types = [i.dtype.base_dtype for i in inputs]
      else:
        if not all(
            x.is_compatible_with(i.dtype) for i, x in zip(inputs, input_types)):
          raise TypeError("In op '%s', input types (%s) are not compatible "
                          "with expected types (%s)" %
                          (node_def.name, [i.dtype for i in inputs], input_types))
    
      # Build the list of control inputs.
      control_input_ops = []
      if control_inputs:
        for c in control_inputs:
          control_op = None
          if isinstance(c, Operation):
            control_op = c
          elif isinstance(c, (Tensor, IndexedSlices)):
            control_op = c.op
          else:
            raise TypeError("Control input must be an Operation, "
                            "a Tensor, or IndexedSlices: %s" % c)
          control_input_ops.append(control_op)
    
      # This will be set by self.inputs.
      self._inputs_val = None
    
      # pylint: disable=protected-access
      self._id_value = self._graph._next_id()
      self._original_op = original_op
      self._traceback = tf_stack.extract_stack()
    
      # List of _UserDevSpecs holding code location of device context manager
      # invocations and the users original argument to them.
      self._device_code_locations = None
      # Dict mapping op name to file and line information for op colocation
      # context managers.
      self._colocation_code_locations = None
      self._control_flow_context = self.graph._get_control_flow_context()
      # pylint: enable=protected-access
    
      # Initialize self._c_op.
      if c_op:
        self._c_op = c_op
      else:
        if op_def is None:
          op_def = self._graph._get_op_def(node_def.op)
        # TODO(skyewm): op_def_library.apply_op() flattens the incoming inputs.
        # Refactor so we don't have to do this here.
        grouped_inputs = self._reconstruct_sequence_inputs(
            op_def, inputs, node_def.attr)
        self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,
>                                 control_input_ops)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2027: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

graph = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
node_def = name: "lambda_1_out/packed"
op: "Pack"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "axis"
  value {
    i: 0
  }
}

inputs = [[<tf.Tensor 'lambda_1/Identity:0' shape=(?, 2, 2) dtype=float32>, <tf.Tensor 'lambda_1/Identity_1:0' shape=(?, 2) dtype=float32>]]
control_inputs = []

    def _create_c_op(graph, node_def, inputs, control_inputs):
      """Creates a TF_Operation.
    
      Args:
        graph: a `Graph`.
        node_def: `node_def_pb2.NodeDef` for the operation to create.
        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of
          `Tensor`s (corresponding to sequence inputs, e.g. "int64 * N",
          "list(int64)"). The length of the list should be equal to the number of
          inputs specified by this operation's op def.
        control_inputs: A list of `Operation`s to set as control dependencies.
    
      Returns:
        A wrapped TF_Operation*.
      """
      # pylint: disable=protected-access
      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),
                                      compat.as_str(node_def.name))
      if node_def.device:
        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))
      # Add inputs
      for op_input in inputs:
        if isinstance(op_input, (list, tuple)):
          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])
        else:
          c_api.TF_AddInput(op_desc, op_input._as_tf_output())
    
      # Add control inputs
      for control_input in control_inputs:
        c_api.TF_AddControlInput(op_desc, control_input._c_op)
      # pylint: enable=protected-access
    
      # Add attrs
      for name, attr_value in node_def.attr.items():
        serialized = attr_value.SerializeToString()
        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.
        # It might be worth creating a convenient way to re-use the same status.
        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)
    
      try:
        c_op = c_api.TF_FinishOperation(op_desc)
      except errors.InvalidArgumentError as e:
        # Convert to ValueError for backwards compatibility.
>       raise ValueError(str(e))
E       ValueError: Shapes must be equal rank, but are 3 and 2
E       	From merging shape 0 with other shapes. for 'lambda_1_out/packed' (op: 'Pack') with input shapes: [?,2,2], [?,2].

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1867: ValueError

During handling of the above exception, another exception occurred:

tmpdir = local('/tmp/pytest-of-root/pytest-77/popen-gw0/test_TensorBoard_multi_input_o0')

    @keras_test
    def test_TensorBoard_multi_input_output(tmpdir):
        np.random.seed(np.random.randint(1, 1e7))
        filepath = str(tmpdir / 'logs')
    
        (X_train, y_train), (X_test, y_test) = get_test_data(
            num_train=train_samples,
            num_test=test_samples,
            input_shape=(input_dim, input_dim),
            classification=True,
            num_classes=num_classes)
        y_test = np_utils.to_categorical(y_test)
        y_train = np_utils.to_categorical(y_train)
    
        def data_generator(train):
            if train:
                max_batch_index = len(X_train) // batch_size
            else:
                max_batch_index = len(X_test) // batch_size
            i = 0
            while 1:
                if train:
                    # simulate multi-input/output models
                    yield ([X_train[i * batch_size: (i + 1) * batch_size]] * 2,
                           [y_train[i * batch_size: (i + 1) * batch_size]] * 2)
                else:
                    yield ([X_test[i * batch_size: (i + 1) * batch_size]] * 2,
                           [y_test[i * batch_size: (i + 1) * batch_size]] * 2)
                i += 1
                i = i % max_batch_index
    
        inp1 = Input((input_dim, input_dim))
        inp2 = Input((input_dim, input_dim))
        inp_3d = add([inp1, inp2])
        inp_2d = GlobalAveragePooling1D()(inp_3d)
        inp_pair = Lambda(lambda x: x)([inp_3d, inp_2d])  # test a layer with a list of output tensors
        hidden = dot(inp_pair, axes=-1)
        hidden = Dense(num_hidden, activation='relu')(hidden)
        hidden = Dropout(0.1)(hidden)
        output1 = Dense(num_classes, activation='softmax')(hidden)
        output2 = Dense(num_classes, activation='softmax')(hidden)
        model = Model(inputs=[inp1, inp2], outputs=[output1, output2])
        model.compile(loss='categorical_crossentropy',
                      optimizer='sgd',
                      metrics=['accuracy'])
    
        # we must generate new callbacks for each test, as they aren't stateless
        def callbacks_factory(histogram_freq):
            return [callbacks.TensorBoard(log_dir=filepath,
                                          histogram_freq=histogram_freq,
                                          write_images=True, write_grads=True,
                                          embeddings_freq=1,
                                          embeddings_layer_names=['dense_1'],
                                          batch_size=5)]
    
        # fit without validation data
        model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,
                  callbacks=callbacks_factory(histogram_freq=0), epochs=3)
    
        # fit with validation data and accuracy
        model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,
                  validation_data=([X_test] * 2, [y_test] * 2),
>                 callbacks=callbacks_factory(histogram_freq=1), epochs=2)

tests/keras/test_callbacks.py:680: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
keras/engine/training.py:1037: in fit
    validation_steps=validation_steps)
keras/engine/training_arrays.py:115: in fit_loop
    callbacks.set_model(callback_model)
keras/callbacks.py:51: in set_model
    callback.set_model(model)
keras/callbacks.py:790: in set_model
    layer.output)
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/summary/summary.py:179: in histogram
    tag=tag, values=values, name=scope)
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/ops/gen_logging_ops.py:329: in histogram_summary
    "HistogramSummary", tag=tag, values=values, name=name)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tensorflow.python.framework.op_def_library.OpDefLibrary object at 0x7f25bb016e10>
op_type_name = 'HistogramSummary', name = 'lambda_1_out/', keywords = {}
op_info = <tensorflow.python.framework.op_def_library._OpInfo object at 0x7f25bb0270b8>
op_def = name: "HistogramSummary"
input_arg {
  name: "tag"
  type: DT_STRING
}
input_arg {
  name: "values"
  type_attr: "T"
}...   type: DT_BFLOAT16
      type: DT_UINT16
      type: DT_HALF
      type: DT_UINT32
      type: DT_UINT64
    }
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x7f25ae620e48>
deprecation_version = 0, default_type_attr_map = {'T': tf.float32}

    def _apply_op_helper(self, op_type_name, name=None, **keywords):
      """Implementation of apply_op that returns output_structure, op."""
      op_info = self._ops.get(op_type_name, None)
      if op_info is None:
        raise RuntimeError("Unrecognized Op name " + op_type_name)
      op_def = op_info.op_def
    
      # Determine the graph context.
      try:
        # Need to flatten all the arguments into a list.
        # pylint: disable=protected-access
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
        # pylint: enable=protected-access
      except AssertionError as e:
        raise RuntimeError(
            "Cannot determine graph for Op '%s' due to: %s"
            % (op_type_name, e.message))
    
      # Default name if not specified.
      if name is None:
        name = op_type_name
    
      # Check for deprecation
      deprecation_version = op_def.deprecation.version
      if deprecation_version:
        producer = g.graph_def_versions.producer
        if producer >= deprecation_version:
          raise NotImplementedError(
              ("Op %s is not available in GraphDef version %d. "
               "It has been removed in version %d. %s.") %
              (op_type_name, producer, deprecation_version,
               op_def.deprecation.explanation))
    
      # Fill in the list of default types for all "type" attrs.  This
      # will be used to choose a preferred dtype to convert to in the
      # absence of input type information.
      #
      # TODO(b/31302892): Currently the defaults don't work in the right
      # way if you have two inputs, one of whose type resolution depends
      # on the other.  Handling this will require restructuring this code
      # significantly.
      default_type_attr_map = {}
      for attr_def in op_def.attr:
        if attr_def.type != "type":
          continue
        key = attr_def.name
        if attr_def.HasField("default_value"):
          default_type_attr_map[key] = dtypes.as_dtype(
              attr_def.default_value.type)
    
      # Requires that op_def has passed validation (using the C++
      # ValidateOpDef() from ../framework/op_def_util.h).
      attrs = {}
      inputs = []
      input_types = []
      with g.as_default(), ops.name_scope(name) as scope:
    
        # Perform input type inference
        inferred_from = {}
        for input_arg in op_def.input_arg:
          input_name = input_arg.name
          if input_name in keywords:
            values = keywords.pop(input_name)
          elif input_name + "_" in keywords:
            # Handle the case where the name is a keyword or built-in
            # for Python so we use the name + _ instead.
            input_name += "_"
            values = keywords.pop(input_name)
          else:
            raise TypeError("No argument for input " + input_name)
    
          # Goals:
          # * Convert values to Tensors if it contains constants.
          # * Verify that values is a list if that matches the input_arg's
          #   type.
          # * If the input_arg's type is determined by attrs, either set
          #   those attrs and validate those attr values are legal (if
          #   they have not yet been set) or validate the input matches
          #   the type indicated by the attrs (if they have already been
          #   inferred via an earlier input).
          # * If the input_arg has an explicit type, make sure the input
          #   conforms.
    
          if _IsListParameter(input_arg):
            if not _IsListValue(values):
              raise TypeError(
                  "Expected list for '%s' argument to '%s' Op, not %s." %
                  (input_name, op_type_name, values))
            # In cases where we expect all elements of the list to have the
            # same dtype, try to cast non-Tensor elements to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.number_attr:
              if input_arg.type_attr in attrs:
                dtype = attrs[input_arg.type_attr]
              else:
                for t in values:
                  if isinstance(t, ops.Tensor):
                    dtype = t.dtype
                    break
    
              # dtype still not found, prefer using the default dtype
              # from the attr.
              if dtype is None and input_arg.type_attr in default_type_attr_map:
                default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              if not input_arg.is_ref and dtype:
                dtype = dtypes.as_dtype(dtype).base_dtype
              values = ops.internal_convert_n_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype if dtype else None,
                  preferred_dtype=default_dtype,
                  as_ref=input_arg.is_ref)
              if input_arg.number_attr and len(
                  set(v.dtype.base_dtype for v in values)) > 1:
                raise TypeError()  # All types should match.
            except (TypeError, ValueError):
              # What types does the conversion function think values have?
              observed_types = []
              for value in values:
                try:
                  converted_value = ops.internal_convert_to_tensor(
                      value, as_ref=input_arg.is_ref)
                  observed_types.append(converted_value.dtype.base_dtype.name)
                except (TypeError, ValueError):
                  observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
              observed = ", ".join(observed_types)
    
              prefix = (
                  "Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                  (input_name, op_type_name, observed))
              if input_arg.number_attr:
                if input_arg.type != types_pb2.DT_INVALID:
                  raise TypeError("%s that do not match expected type %s." %
                                  (prefix, dtype.name))
                elif input_arg.type_attr in attrs:
                  raise TypeError("%s that do not match type %s inferred from "
                                  "earlier arguments." %
                                  (prefix, dtype.name))
                else:
                  raise TypeError("%s that don't all match." % prefix)
              else:
                raise TypeError(
                    "%s that are invalid. Tensors: %s" % (prefix, values))
    
            types = [x.dtype for x in values]
            inputs.extend(values)
          else:
            # In cases where we have an expected type, try to convert non-Tensor
            # arguments to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            elif input_arg.type_attr in default_type_attr_map:
              # The dtype could not be inferred solely from the inputs,
              # so we prefer the attr's default, so code that adds a new attr
              # with a default is backwards compatible.
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              values = ops.internal_convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
            except TypeError as err:
              if dtype is None:
                raise err
              else:
                raise TypeError(
                    "Expected %s passed to parameter '%s' of op '%s', got %s of "
                    "type '%s' instead. Error: %s" %
                    (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,
                     repr(values), type(values).__name__, err))
            except ValueError:
              # What type does convert_to_tensor think it has?
              try:
                observed = ops.internal_convert_to_tensor(
                    values, as_ref=input_arg.is_ref).dtype.name
              except ValueError as err:
                raise ValueError(
                    "Tried to convert '%s' to a tensor and failed. Error: %s" %
>                   (input_name, err))
E               ValueError: Tried to convert 'values' to a tensor and failed. Error: Shapes must be equal rank, but are 3 and 2
E               	From merging shape 0 with other shapes. for 'lambda_1_out/packed' (op: 'Pack') with input shapes: [?,2,2], [?,2].

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:545: ValueError
----------------------------- Captured stdout call -----------------------------
Epoch 1/3

 5/20 [======>.......................] - ETA: 0s - loss: 1.4488 - dense_2_loss: 1.2744 - dense_3_loss: 0.1744 - dense_2_acc: 0.4000 - dense_3_acc: 0.8000
20/20 [==============================] - 0s 6ms/step - loss: 1.8103 - dense_2_loss: 0.9196 - dense_3_loss: 0.8907 - dense_2_acc: 0.4000 - dense_3_acc: 0.6000
Epoch 2/3

 5/20 [======>.......................] - ETA: 0s - loss: 1.3363 - dense_2_loss: 0.8539 - dense_3_loss: 0.4824 - dense_2_acc: 0.4000 - dense_3_acc: 0.6000
20/20 [==============================] - 0s 157us/step - loss: 1.4188 - dense_2_loss: 0.7156 - dense_3_loss: 0.7032 - dense_2_acc: 0.4500 - dense_3_acc: 0.6000
Epoch 3/3

 5/20 [======>.......................] - ETA: 0s - loss: 0.8567 - dense_2_loss: 0.4854 - dense_3_loss: 0.3713 - dense_2_acc: 0.8000 - dense_3_acc: 0.8000
20/20 [==============================] - 0s 221us/step - loss: 1.5025 - dense_2_loss: 0.6396 - dense_3_loss: 0.8630 - dense_2_acc: 0.5000 - dense_3_acc: 0.6000
Train on 20 samples, validate on 20 samples
----------------------------- Captured stderr call -----------------------------
WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:70: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:513: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:3994: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:129: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:3281: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:3151: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2023-09-01 18:49:28.200747: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2023-09-01 18:49:28.220945: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3399905000 Hz
2023-09-01 18:49:28.221392: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f536632860 executing computations on platform Host. Devices:
2023-09-01 18:49:28.221423: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-09-01 18:49:28.274984: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/callbacks.py:791: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/callbacks.py:794: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/callbacks.py:810: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/callbacks.py:789: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

------------------------------ Captured log call -------------------------------
WARNING  tensorflow:deprecation_wrapper.py:119 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:70: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING  tensorflow:deprecation_wrapper.py:119 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:513: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING  tensorflow:deprecation_wrapper.py:119 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:3994: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING  tensorflow:deprecation_wrapper.py:119 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:129: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING  tensorflow:deprecation.py:506 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:3281: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING  tensorflow:deprecation_wrapper.py:119 From /home/user/BugsInPy/temp/projects/keras/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING  tensorflow:deprecation_wrapper.py:119 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:3151: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING  tensorflow:deprecation.py:323 From /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING  tensorflow:deprecation_wrapper.py:119 From /home/user/BugsInPy/temp/projects/keras/keras/callbacks.py:791: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING  tensorflow:deprecation_wrapper.py:119 From /home/user/BugsInPy/temp/projects/keras/keras/callbacks.py:794: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING  tensorflow:deprecation_wrapper.py:119 From /home/user/BugsInPy/temp/projects/keras/keras/callbacks.py:810: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING  tensorflow:deprecation_wrapper.py:119 From /home/user/BugsInPy/temp/projects/keras/keras/callbacks.py:789: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.
=============================== warnings summary ===============================
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/h5py/__init__.py:46
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/h5py/__init__.py:46
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/h5py/__init__.py:46: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.
    from ._conv import register_converters as _register_converters

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
    import imp

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1286
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1286
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1286: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    _pywrap_tensorflow.RegisterType("Mapping", _collections.Mapping)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1287
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1287
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1287: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    _pywrap_tensorflow.RegisterType("Sequence", _collections.Sequence)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_qint8 = np.dtype([("qint8", np.int8, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_quint8 = np.dtype([("quint8", np.uint8, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_qint16 = np.dtype([("qint16", np.int16, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_quint16 = np.dtype([("quint16", np.uint16, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_qint32 = np.dtype([("qint32", np.int32, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    np_resource = np.dtype([("resource", np.ubyte, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:593
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:593
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:593: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.object,

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:601
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:601
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:601: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.bool,

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:635
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:635
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:635: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.object,

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:645
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:645
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:645: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.bool,

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:106
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:106
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:106: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.object:

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:108
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:108
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:108: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.bool:

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:61
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:61
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:61: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    class ObjectIdentityDictionary(collections.MutableMapping):

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:112
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:112
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:112: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    class ObjectIdentitySet(collections.MutableSet):

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/training/tracking/data_structures.py:374
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/training/tracking/data_structures.py:374
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/training/tracking/data_structures.py:374: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    class _ListWrapper(List, collections.MutableSequence,

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:10
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:10
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:10: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _nlv = LooseVersion(_np_version)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:11
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:11
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p14 = _nlv < LooseVersion("1.14")

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:12
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:12
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:12: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p15 = _nlv < LooseVersion("1.15")

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:13
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:13
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:13: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p16 = _nlv < LooseVersion("1.16")

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:14
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:14
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:14: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p17 = _nlv < LooseVersion("1.17")

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:15
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:15
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:15: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p18 = _nlv < LooseVersion("1.18")

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/setuptools/_distutils/version.py:346
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/setuptools/_distutils/version.py:346
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    other = LooseVersion(other)

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/function.py:114
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/function.py:114
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/function.py:114
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/function.py:114
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/compat/numpy/function.py:114: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(_np_version) >= LooseVersion("1.17.0"):

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/_testing.py:24
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/_testing.py:24
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/pandas/_testing.py:24: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    import pandas._libs.testing as _testing

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_qint8 = np.dtype([("qint8", np.int8, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_quint8 = np.dtype([("quint8", np.uint8, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_qint16 = np.dtype([("qint16", np.int16, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_quint16 = np.dtype([("quint16", np.uint16, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_qint32 = np.dtype([("qint32", np.int32, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    np_resource = np.dtype([("resource", np.ubyte, 1)])

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:568
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:568
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:568: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    (np.object, string),

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:569
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:569
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:569: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    (np.bool, bool),

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:593
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:593
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:593: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    types_pb2.DT_STRING: np.object,

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:597
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:597
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:597: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    types_pb2.DT_BOOL: np.bool,

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:614
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:614
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:614: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    types_pb2.DT_STRING_REF: np.object,

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:619
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:619
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:619: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    types_pb2.DT_BOOL_REF: np.bool,

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/util/tensor_util.py:100
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/util/tensor_util.py:100
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/util/tensor_util.py:100: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.object: SlowAppendObjectArrayToTensorProto,

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/util/tensor_util.py:101
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/util/tensor_util.py:101
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorboard/util/tensor_util.py:101: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.bool: SlowAppendBoolArrayToTensorProto,

keras/callbacks.py:18
keras/callbacks.py:18
  /home/user/BugsInPy/temp/projects/keras/keras/callbacks.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    from collections import Iterable

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:538
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:538
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:538
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
    tensor_proto.tensor_content = nparray.tostring()

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/generator_io.py:26
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/generator_io.py:26: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    from collections import Container

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/contrib/labeled_tensor/python/ops/core.py:722
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/contrib/labeled_tensor/python/ops/core.py:722: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    tc.Tuple(string_types, collections.Hashable))),

/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/contrib/labeled_tensor/python/ops/core.py:1058
  /opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/tensorflow/contrib/labeled_tensor/python/ops/core.py:1058: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    @tc.accepts(string_types, collections.Callable)

-- Docs: https://docs.pytest.org/en/latest/warnings.html
========================== slowest 20 test durations ===========================
1.04s call     tests/keras/test_callbacks.py::test_TensorBoard_multi_input_output

(0.00 durations hidden.  Use -vv to show these durations.)
=========================== short test summary info ============================
FAILED tests/keras/test_callbacks.py::test_TensorBoard_multi_input_output - V...
======================== 1 failed, 94 warnings in 4.86s ========================
/opt/conda/envs/70d512a17e79e7668f22d8292a6a3870/lib/python3.7/site-packages/coverage/control.py:793: CoverageWarning: No data was collected. (no-data-collected)
  self._warn("No data was collected.", slug="no-data-collected")
