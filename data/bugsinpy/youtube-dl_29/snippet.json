[
    {
        "name": "youtube_dl.extractor.crooksandliars.CrooksAndLiarsIE._real_extract#30",
        "src_path": "youtube_dl/extractor/crooksandliars.py",
        "class_name": "youtube_dl.extractor.crooksandliars.CrooksAndLiarsIE",
        "signature": "youtube_dl.extractor.crooksandliars.CrooksAndLiarsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://embed.crooksandliars.com/embed/%s' % video_id, video_id)\n\n        manifest = self._parse_json(\n            self._search_regex(\n                r'var\\s+manifest\\s*=\\s*({.+?})\\n', webpage, 'manifest JSON'),\n            video_id)\n\n        quality = qualities(('webm_low', 'mp4_low', 'webm_high', 'mp4_high'))\n\n        formats = [{\n            'url': item['url'],\n            'format_id': item['type'],\n            'quality': quality(item['type']),\n        } for item in manifest['flavors'] if item['mime'].startswith('video/')]\n        self._sort_formats(formats)\n\n        return {\n            'url': url,\n            'id': video_id,\n            'title': manifest['title'],\n            'description': manifest.get('description'),\n            'thumbnail': self._proto_relative_url(manifest.get('poster')),\n            'timestamp': int_or_none(manifest.get('created')),\n            'uploader': manifest.get('author'),\n            'duration': int_or_none(manifest.get('duration')),\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.playtvak.PlaytvakIE._real_extract#92",
        "src_path": "youtube_dl/extractor/playtvak.py",
        "class_name": "youtube_dl.extractor.playtvak.PlaytvakIE",
        "signature": "youtube_dl.extractor.playtvak.PlaytvakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        info_url = self._html_search_regex(\n            r'Misc\\.videoFLV\\(\\s*{\\s*data\\s*:\\s*\"([^\"]+)\"', webpage, 'info url')\n\n        parsed_url = compat_urlparse.urlparse(info_url)\n\n        qs = compat_urlparse.parse_qs(parsed_url.query)\n        qs.update({\n            'reklama': ['0'],\n            'type': ['js'],\n        })\n\n        info_url = compat_urlparse.urlunparse(\n            parsed_url._replace(query=compat_urllib_parse.urlencode(qs, True)))\n\n        json_info = self._download_json(\n            info_url, video_id,\n            transform_source=lambda s: s[s.index('{'):s.rindex('}') + 1])\n\n        item = None\n        for i in json_info['items']:\n            if i.get('type') == 'video' or i.get('type') == 'stream':\n                item = i\n                break\n        if not item:\n            raise ExtractorError('No suitable stream found')\n\n        quality = qualities(('low', 'middle', 'high'))\n\n        formats = []\n        for fmt in item['video']:\n            video_url = fmt.get('file')\n            if not video_url:\n                continue\n\n            format_ = fmt['format']\n            format_id = '%s_%s' % (format_, fmt['quality'])\n            preference = None\n\n            if format_ in ('mp4', 'webm'):\n                ext = format_\n            elif format_ == 'rtmp':\n                ext = 'flv'\n            elif format_ == 'apple':\n                ext = 'mp4'\n                # Some streams have mp3 audio which does not play\n                # well with ffmpeg filter aac_adtstoasc\n                preference = -1\n            elif format_ == 'adobe':  # f4m manifest fails with 404 in 80% of requests\n                continue\n            else:  # Other formats not supported yet\n                continue\n\n            formats.append({\n                'url': video_url,\n                'ext': ext,\n                'format_id': format_id,\n                'quality': quality(fmt.get('quality')),\n                'preference': preference,\n            })\n        self._sort_formats(formats)\n\n        title = item['title']\n        is_live = item['type'] == 'stream'\n        if is_live:\n            title = self._live_title(title)\n        description = self._og_search_description(webpage, default=None) or self._html_search_meta(\n            'description', webpage, 'description')\n        timestamp = None\n        duration = None\n        if not is_live:\n            duration = int_or_none(item.get('length'))\n            timestamp = item.get('published')\n            if timestamp:\n                timestamp = parse_iso8601(timestamp[:-5])\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': item.get('image'),\n            'duration': duration,\n            'timestamp': timestamp,\n            'is_live': is_live,\n            'formats': formats,\n        }",
        "begin_line": 92,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cbsnews.CBSNewsIE._real_extract#45",
        "src_path": "youtube_dl/extractor/cbsnews.py",
        "class_name": "youtube_dl.extractor.cbsnews.CBSNewsIE",
        "signature": "youtube_dl.extractor.cbsnews.CBSNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_info = json.loads(self._html_search_regex(\n            r'(?:<ul class=\"media-list items\" id=\"media-related-items\"><li data-video-info|<div id=\"cbsNewsVideoPlayer\" data-video-player-options)=\\'({.+?})\\'',\n            webpage, 'video JSON info'))\n\n        item = video_info['item'] if 'item' in video_info else video_info\n        title = item.get('articleTitle') or item.get('hed')\n        duration = item.get('duration')\n        thumbnail = item.get('mediaImage') or item.get('thumbnail')\n\n        formats = []\n        for format_id in ['RtmpMobileLow', 'RtmpMobileHigh', 'Hls', 'RtmpDesktop']:\n            uri = item.get('media' + format_id + 'URI')\n            if not uri:\n                continue\n            fmt = {\n                'url': uri,\n                'format_id': format_id,\n            }\n            if uri.startswith('rtmp'):\n                fmt.update({\n                    'app': 'ondemand?auth=cbs',\n                    'play_path': 'mp4:' + uri.split('<break>')[-1],\n                    'player_url': 'http://www.cbsnews.com/[[IMPORT]]/vidtech.cbsinteractive.com/player/3_3_0/CBSI_PLAYER_HD.swf',\n                    'page_url': 'http://www.cbsnews.com',\n                    'ext': 'flv',\n                })\n            elif uri.endswith('.m3u8'):\n                fmt['ext'] = 'mp4'\n            formats.append(fmt)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cbs.CBSIE._real_extract#47",
        "src_path": "youtube_dl/extractor/cbs.py",
        "class_name": "youtube_dl.extractor.cbs.CBSIE",
        "signature": "youtube_dl.extractor.cbs.CBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        real_id = self._search_regex(\n            [r\"video\\.settings\\.pid\\s*=\\s*'([^']+)';\", r\"cbsplayer\\.pid\\s*=\\s*'([^']+)';\"],\n            webpage, 'real video ID')\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'ThePlatform',\n            'url': 'theplatform:%s' % real_id,\n            'display_id': display_id,\n        }",
        "begin_line": 47,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.foxgay.FoxgayIE._real_extract#21",
        "src_path": "youtube_dl/extractor/foxgay.py",
        "class_name": "youtube_dl.extractor.foxgay.FoxgayIE",
        "signature": "youtube_dl.extractor.foxgay.FoxgayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<title>(?P<title>.*?)</title>',\n            webpage, 'title', fatal=False)\n        description = self._html_search_regex(\n            r'<div class=\"ico_desc\"><h2>(?P<description>.*?)</h2>',\n            webpage, 'description', fatal=False)\n\n        # Find the URL for the iFrame which contains the actual video.\n        iframe = self._download_webpage(\n            self._html_search_regex(r'iframe src=\"(?P<frame>.*?)\"', webpage, 'video frame'),\n            video_id)\n        video_url = self._html_search_regex(\n            r\"v_path = '(?P<vid>http://.*?)'\", iframe, 'url')\n        thumb_url = self._html_search_regex(\n            r\"t_path = '(?P<thumb>http://.*?)'\", iframe, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'description': description,\n            'thumbnail': thumb_url,\n            'age_limit': 18,\n        }",
        "begin_line": 21,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gamekings.GamekingsIE._real_extract#40",
        "src_path": "youtube_dl/extractor/gamekings.py",
        "class_name": "youtube_dl.extractor.gamekings.GamekingsIE",
        "signature": "youtube_dl.extractor.gamekings.GamekingsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        playlist_id = self._search_regex(\n            r'gogoVideo\\(\\s*\\d+\\s*,\\s*\"([^\"]+)', webpage, 'playlist id')\n\n        playlist = self._download_xml(\n            'http://www.gamekings.tv/wp-content/themes/gk2010/rss_playlist.php?id=%s' % playlist_id,\n            video_id)\n\n        NS_MAP = {\n            'jwplayer': 'http://rss.jwpcdn.com/'\n        }\n\n        item = playlist.find('./channel/item')\n\n        thumbnail = xpath_text(item, xpath_with_ns('./jwplayer:image', NS_MAP), 'thumbnail')\n        video_url = item.find(xpath_with_ns('./jwplayer:source', NS_MAP)).get('file')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 40,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightBaseIE._call_playlist_service#18",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightBaseIE",
        "signature": "youtube_dl.extractor.limelight.LimelightBaseIE._call_playlist_service(self, item_id, method, fatal=True)",
        "snippet": "    def _call_playlist_service(self, item_id, method, fatal=True):\n        return self._download_json(\n            self._PLAYLIST_SERVICE_URL % (self._PLAYLIST_SERVICE_PATH, item_id, method),\n            item_id, 'Downloading PlaylistService %s JSON' % method, fatal=fatal)",
        "begin_line": 18,
        "end_line": 21,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightBaseIE._call_api#23",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightBaseIE",
        "signature": "youtube_dl.extractor.limelight.LimelightBaseIE._call_api(self, organization_id, item_id, method)",
        "snippet": "    def _call_api(self, organization_id, item_id, method):\n        return self._download_json(\n            self._API_URL % (organization_id, self._API_PATH, item_id, method),\n            item_id, 'Downloading API %s JSON' % method)",
        "begin_line": 23,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightBaseIE._extract#28",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightBaseIE",
        "signature": "youtube_dl.extractor.limelight.LimelightBaseIE._extract(self, item_id, pc_method, mobile_method, meta_method)",
        "snippet": "    def _extract(self, item_id, pc_method, mobile_method, meta_method):\n        pc = self._call_playlist_service(item_id, pc_method)\n        metadata = self._call_api(pc['orgId'], item_id, meta_method)\n        mobile = self._call_playlist_service(item_id, mobile_method, fatal=False)\n        return pc, mobile, metadata",
        "begin_line": 28,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightBaseIE._extract_info#34",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightBaseIE",
        "signature": "youtube_dl.extractor.limelight.LimelightBaseIE._extract_info(self, streams, mobile_urls, properties)",
        "snippet": "    def _extract_info(self, streams, mobile_urls, properties):\n        video_id = properties['media_id']\n        formats = []\n\n        for stream in streams:\n            stream_url = stream.get('url')\n            if not stream_url:\n                continue\n            if '.f4m' in stream_url:\n                formats.extend(self._extract_f4m_formats(stream_url, video_id))\n            else:\n                fmt = {\n                    'url': stream_url,\n                    'abr': float_or_none(stream.get('audioBitRate')),\n                    'vbr': float_or_none(stream.get('videoBitRate')),\n                    'fps': float_or_none(stream.get('videoFrameRate')),\n                    'width': int_or_none(stream.get('videoWidthInPixels')),\n                    'height': int_or_none(stream.get('videoHeightInPixels')),\n                    'ext': determine_ext(stream_url)\n                }\n                rtmp = re.search(r'^(?P<url>rtmpe?://[^/]+/(?P<app>.+))/(?P<playpath>mp4:.+)$', stream_url)\n                if rtmp:\n                    format_id = 'rtmp'\n                    if stream.get('videoBitRate'):\n                        format_id += '-%d' % int_or_none(stream['videoBitRate'])\n                    fmt.update({\n                        'url': rtmp.group('url'),\n                        'play_path': rtmp.group('playpath'),\n                        'app': rtmp.group('app'),\n                        'ext': 'flv',\n                        'format_id': format_id,\n                    })\n                formats.append(fmt)\n\n        for mobile_url in mobile_urls:\n            media_url = mobile_url.get('mobileUrl')\n            if not media_url:\n                continue\n            format_id = mobile_url.get('targetMediaPlatform')\n            if determine_ext(media_url) == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    media_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    preference=-1, m3u8_id=format_id))\n            else:\n                formats.append({\n                    'url': media_url,\n                    'format_id': format_id,\n                    'preference': -1,\n                })\n\n        self._sort_formats(formats)\n\n        title = properties['title']\n        description = properties.get('description')\n        timestamp = int_or_none(properties.get('publish_date') or properties.get('create_date'))\n        duration = float_or_none(properties.get('duration_in_milliseconds'), 1000)\n        filesize = int_or_none(properties.get('total_storage_in_bytes'))\n        categories = [properties.get('category')]\n        tags = properties.get('tags', [])\n        thumbnails = [{\n            'url': thumbnail['url'],\n            'width': int_or_none(thumbnail.get('width')),\n            'height': int_or_none(thumbnail.get('height')),\n        } for thumbnail in properties.get('thumbnails', []) if thumbnail.get('url')]\n\n        subtitles = {}\n        for caption in properties.get('captions', {}):\n            lang = caption.get('language_code')\n            subtitles_url = caption.get('url')\n            if lang and subtitles_url:\n                subtitles[lang] = [{\n                    'url': subtitles_url,\n                }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n            'timestamp': timestamp,\n            'duration': duration,\n            'filesize': filesize,\n            'categories': categories,\n            'tags': tags,\n            'thumbnails': thumbnails,\n            'subtitles': subtitles,\n        }",
        "begin_line": 34,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightMediaIE._real_extract#164",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightMediaIE",
        "signature": "youtube_dl.extractor.limelight.LimelightMediaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        pc, mobile, metadata = self._extract(\n            video_id, 'getPlaylistByMediaId', 'getMobilePlaylistByMediaId', 'properties')\n\n        return self._extract_info(\n            pc['playlistItems'][0].get('streams', []),\n            mobile['mediaList'][0].get('mobileUrls', []) if mobile else [],\n            metadata)",
        "begin_line": 164,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightChannelIE._real_extract#190",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightChannelIE",
        "signature": "youtube_dl.extractor.limelight.LimelightChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        pc, mobile, medias = self._extract(\n            channel_id, 'getPlaylistByChannelId',\n            'getMobilePlaylistWithNItemsByChannelId?begin=0&count=-1', 'media')\n\n        entries = [\n            self._extract_info(\n                pc['playlistItems'][i].get('streams', []),\n                mobile['mediaList'][i].get('mobileUrls', []) if mobile else [],\n                medias['media_list'][i])\n            for i in range(len(medias['media_list']))]\n\n        return self.playlist_result(entries, channel_id, pc['title'])",
        "begin_line": 190,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightChannelListIE._real_extract#220",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightChannelListIE",
        "signature": "youtube_dl.extractor.limelight.LimelightChannelListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_list_id = self._match_id(url)\n\n        channel_list = self._call_playlist_service(channel_list_id, 'getMobileChannelListById')\n\n        entries = [\n            self.url_result('limelight:channel:%s' % channel['id'], 'LimelightChannel')\n            for channel in channel_list['channelList']]\n\n        return self.playlist_result(entries, channel_list_id, channel_list['title'])",
        "begin_line": 220,
        "end_line": 229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.viewster.ViewsterIE._download_json#78",
        "src_path": "youtube_dl/extractor/viewster.py",
        "class_name": "youtube_dl.extractor.viewster.ViewsterIE",
        "signature": "youtube_dl.extractor.viewster.ViewsterIE._download_json(self, url, video_id, note='Downloading JSON metadata', fatal=True)",
        "snippet": "    def _download_json(self, url, video_id, note='Downloading JSON metadata', fatal=True):\n        request = compat_urllib_request.Request(url)\n        request.add_header('Accept', self._ACCEPT_HEADER)\n        request.add_header('Auth-token', self._AUTH_TOKEN)\n        return super(ViewsterIE, self)._download_json(request, video_id, note, fatal=fatal)",
        "begin_line": 78,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.viewster.ViewsterIE._real_extract#84",
        "src_path": "youtube_dl/extractor/viewster.py",
        "class_name": "youtube_dl.extractor.viewster.ViewsterIE",
        "signature": "youtube_dl.extractor.viewster.ViewsterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        # Get 'api_token' cookie\n        self._request_webpage(HEADRequest('http://www.viewster.com/'), video_id)\n        cookies = self._get_cookies('http://www.viewster.com/')\n        self._AUTH_TOKEN = compat_urllib_parse_unquote(cookies['api_token'].value)\n\n        info = self._download_json(\n            'https://public-api.viewster.com/search/%s' % video_id,\n            video_id, 'Downloading entry JSON')\n\n        entry_id = info.get('Id') or info['id']\n\n        # unfinished serie has no Type\n        if info.get('Type') in ('Serie', None):\n            try:\n                episodes = self._download_json(\n                    'https://public-api.viewster.com/series/%s/episodes' % entry_id,\n                    video_id, 'Downloading series JSON')\n            except ExtractorError as e:\n                if isinstance(e.cause, compat_HTTPError) and e.cause.code == 404:\n                    self.raise_geo_restricted()\n                else:\n                    raise\n            entries = [\n                self.url_result(\n                    'http://www.viewster.com/movie/%s' % episode['OriginId'], 'Viewster')\n                for episode in episodes]\n            title = (info.get('Title') or info['Synopsis']['Title']).strip()\n            description = info.get('Synopsis', {}).get('Detailed')\n            return self.playlist_result(entries, video_id, title, description)\n\n        formats = []\n        for media_type in ('application/f4m+xml', 'application/x-mpegURL', 'video/mp4'):\n            media = self._download_json(\n                'https://public-api.viewster.com/movies/%s/video?mediaType=%s'\n                % (entry_id, compat_urllib_parse.quote(media_type)),\n                video_id, 'Downloading %s JSON' % media_type, fatal=False)\n            if not media:\n                continue\n            video_url = media.get('Uri')\n            if not video_url:\n                continue\n            ext = determine_ext(video_url)\n            if ext == 'f4m':\n                video_url += '&' if '?' in video_url else '?'\n                video_url += 'hdcore=3.2.0&plugin=flowplayer-3.2.0.1'\n                formats.extend(self._extract_f4m_formats(\n                    video_url, video_id, f4m_id='hds'))\n            elif ext == 'm3u8':\n                m3u8_formats = self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4', m3u8_id='hls',\n                    fatal=False)  # m3u8 sometimes fail\n                if m3u8_formats:\n                    formats.extend(m3u8_formats)\n            else:\n                format_id = media.get('Bitrate')\n                f = {\n                    'url': video_url,\n                    'format_id': 'mp4-%s' % format_id,\n                    'height': int_or_none(media.get('Height')),\n                    'width': int_or_none(media.get('Width')),\n                    'preference': 1,\n                }\n                if format_id and not f['height']:\n                    f['height'] = int_or_none(self._search_regex(\n                        r'^(\\d+)[pP]$', format_id, 'height', default=None))\n                formats.append(f)\n\n        if not formats and not info.get('LanguageSets') and not info.get('VODSettings'):\n            self.raise_geo_restricted()\n\n        self._sort_formats(formats)\n\n        synopsis = info.get('Synopsis', {})\n        # Prefer title outside synopsis since it's less messy\n        title = (info.get('Title') or synopsis['Title']).strip()\n        description = synopsis.get('Detailed') or info.get('Synopsis', {}).get('Short')\n        duration = int_or_none(info.get('Duration'))\n        timestamp = parse_iso8601(info.get('ReleaseDate'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 84,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeIE._real_extract#41",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeIE",
        "signature": "youtube_dl.extractor.rutube.RutubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video = self._download_json(\n            'http://rutube.ru/api/video/%s/?format=json' % video_id,\n            video_id, 'Downloading video JSON')\n\n        # Some videos don't have the author field\n        author = video.get('author') or {}\n\n        options = self._download_json(\n            'http://rutube.ru/api/play/options/%s/?format=json' % video_id,\n            video_id, 'Downloading options JSON')\n\n        m3u8_url = options['video_balancer'].get('m3u8')\n        if m3u8_url is None:\n            raise ExtractorError('Couldn\\'t find m3u8 manifest url')\n        formats = self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4')\n\n        return {\n            'id': video['id'],\n            'title': video['title'],\n            'description': video['description'],\n            'duration': video['duration'],\n            'view_count': video['hits'],\n            'formats': formats,\n            'thumbnail': video['thumbnail_url'],\n            'uploader': author.get('name'),\n            'uploader_id': compat_str(author['id']) if author else None,\n            'upload_date': unified_strdate(video['created_ts']),\n            'age_limit': 18 if video['is_adult'] else 0,\n        }",
        "begin_line": 41,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeEmbedIE._real_extract#95",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeEmbedIE",
        "signature": "youtube_dl.extractor.rutube.RutubeEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        embed_id = self._match_id(url)\n        webpage = self._download_webpage(url, embed_id)\n\n        canonical_url = self._html_search_regex(\n            r'<link\\s+rel=\"canonical\"\\s+href=\"([^\"]+?)\"', webpage,\n            'Canonical URL')\n        return self.url_result(canonical_url, 'Rutube')",
        "begin_line": 95,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeChannelIE._extract_videos#119",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeChannelIE",
        "signature": "youtube_dl.extractor.rutube.RutubeChannelIE._extract_videos(self, channel_id, channel_title=None)",
        "snippet": "    def _extract_videos(self, channel_id, channel_title=None):\n        entries = []\n        for pagenum in itertools.count(1):\n            page = self._download_json(\n                self._PAGE_TEMPLATE % (channel_id, pagenum),\n                channel_id, 'Downloading page %s' % pagenum)\n            results = page['results']\n            if not results:\n                break\n            entries.extend(self.url_result(result['video_url'], 'Rutube') for result in results)\n            if not page['has_next']:\n                break\n        return self.playlist_result(entries, channel_id, channel_title)",
        "begin_line": 119,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeChannelIE._real_extract#133",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeChannelIE",
        "signature": "youtube_dl.extractor.rutube.RutubeChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id = mobj.group('id')\n        return self._extract_videos(channel_id)",
        "begin_line": 133,
        "end_line": 136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeMovieIE._real_extract#148",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeMovieIE",
        "signature": "youtube_dl.extractor.rutube.RutubeMovieIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        movie_id = self._match_id(url)\n        movie = self._download_json(\n            self._MOVIE_TEMPLATE % movie_id, movie_id,\n            'Downloading movie JSON')\n        movie_name = movie['name']\n        return self._extract_videos(movie_id, movie_name)",
        "begin_line": 148,
        "end_line": 154,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.srf.SrfIE._real_extract#46",
        "src_path": "youtube_dl/extractor/srf.py",
        "class_name": "youtube_dl.extractor.srf.SrfIE",
        "signature": "youtube_dl.extractor.srf.SrfIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        display_id = re.match(self._VALID_URL, url).group('display_id') or video_id\n\n        video_data = self._download_xml(\n            'http://il.srgssr.ch/integrationlayer/1.0/ue/srf/video/play/%s.xml' % video_id,\n            display_id)\n\n        title = xpath_text(\n            video_data, './AssetMetadatas/AssetMetadata/title', fatal=True)\n        thumbnails = [{\n            'url': s.text\n        } for s in video_data.findall('.//ImageRepresentation/url')]\n        timestamp = parse_iso8601(xpath_text(video_data, './createdDate'))\n        # The <duration> field in XML is different from the exact duration, skipping\n\n        formats = []\n        for item in video_data.findall('./Playlists/Playlist') + video_data.findall('./Downloads/Download'):\n            for url_node in item.findall('url'):\n                quality = url_node.attrib['quality']\n                full_url = url_node.text\n                original_ext = determine_ext(full_url)\n                format_id = '%s-%s' % (quality, item.attrib['protocol'])\n                if original_ext == 'f4m':\n                    formats.extend(self._extract_f4m_formats(\n                        full_url + '?hdcore=3.4.0', display_id, f4m_id=format_id))\n                elif original_ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        full_url, display_id, 'mp4', m3u8_id=format_id))\n                else:\n                    formats.append({\n                        'url': full_url,\n                        'ext': original_ext,\n                        'format_id': format_id,\n                        'quality': 0 if 'HD' in quality else -1,\n                        'preference': 1,\n                    })\n\n        self._sort_formats(formats)\n\n        subtitles = {}\n        subtitles_data = video_data.find('Subtitles')\n        if subtitles_data is not None:\n            subtitles_list = [{\n                'url': sub.text,\n                'ext': determine_ext(sub.text),\n            } for sub in subtitles_data]\n            if subtitles_list:\n                subtitles['de'] = subtitles_list\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'formats': formats,\n            'title': title,\n            'thumbnails': thumbnails,\n            'timestamp': timestamp,\n            'subtitles': subtitles,\n        }",
        "begin_line": 46,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.zdf.extract_from_xml_url#16",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf",
        "signature": "youtube_dl.extractor.zdf.extract_from_xml_url(ie, video_id, xml_url)",
        "snippet": "def extract_from_xml_url(ie, video_id, xml_url):\n    doc = ie._download_xml(\n        xml_url, video_id,\n        note='Downloading video info',\n        errnote='Failed to download video info')\n\n    title = doc.find('.//information/title').text\n    description = xpath_text(doc, './/information/detail', 'description')\n    duration = int_or_none(xpath_text(doc, './/details/lengthSec', 'duration'))\n    uploader = xpath_text(doc, './/details/originChannelTitle', 'uploader')\n    uploader_id = xpath_text(doc, './/details/originChannelId', 'uploader id')\n    upload_date = unified_strdate(xpath_text(doc, './/details/airtime', 'upload date'))\n\n    def xml_to_format(fnode):\n        video_url = fnode.find('url').text\n        is_available = 'http://www.metafilegenerator' not in video_url\n\n        format_id = fnode.attrib['basetype']\n        format_m = re.match(r'''(?x)\n            (?P<vcodec>[^_]+)_(?P<acodec>[^_]+)_(?P<container>[^_]+)_\n            (?P<proto>[^_]+)_(?P<index>[^_]+)_(?P<indexproto>[^_]+)\n        ''', format_id)\n\n        ext = format_m.group('container')\n        proto = format_m.group('proto').lower()\n\n        quality = xpath_text(fnode, './quality', 'quality')\n        abr = int_or_none(xpath_text(fnode, './audioBitrate', 'abr'), 1000)\n        vbr = int_or_none(xpath_text(fnode, './videoBitrate', 'vbr'), 1000)\n\n        width = int_or_none(xpath_text(fnode, './width', 'width'))\n        height = int_or_none(xpath_text(fnode, './height', 'height'))\n\n        filesize = int_or_none(xpath_text(fnode, './filesize', 'filesize'))\n\n        format_note = ''\n        if not format_note:\n            format_note = None\n\n        return {\n            'format_id': format_id + '-' + quality,\n            'url': video_url,\n            'ext': ext,\n            'acodec': format_m.group('acodec'),\n            'vcodec': format_m.group('vcodec'),\n            'abr': abr,\n            'vbr': vbr,\n            'width': width,\n            'height': height,\n            'filesize': filesize,\n            'format_note': format_note,\n            'protocol': proto,\n            '_available': is_available,\n        }\n\n    def xml_to_thumbnails(fnode):\n        thumbnails = []\n        for node in fnode:\n            thumbnail_url = node.text\n            if not thumbnail_url:\n                continue\n            thumbnail = {\n                'url': thumbnail_url,\n            }\n            if 'key' in node.attrib:\n                m = re.match('^([0-9]+)x([0-9]+)$', node.attrib['key'])\n                if m:\n                    thumbnail['width'] = int(m.group(1))\n                    thumbnail['height'] = int(m.group(2))\n            thumbnails.append(thumbnail)\n        return thumbnails\n\n    thumbnails = xml_to_thumbnails(doc.findall('.//teaserimages/teaserimage'))\n\n    format_nodes = doc.findall('.//formitaeten/formitaet')\n    formats = list(filter(\n        lambda f: f['_available'],\n        map(xml_to_format, format_nodes)))\n    ie._sort_formats(formats)\n\n    return {\n        'id': video_id,\n        'title': title,\n        'description': description,\n        'duration': duration,\n        'thumbnails': thumbnails,\n        'uploader': uploader,\n        'uploader_id': uploader_id,\n        'upload_date': upload_date,\n        'formats': formats,\n    }",
        "begin_line": 16,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFIE._real_extract#127",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFIE",
        "signature": "youtube_dl.extractor.zdf.ZDFIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        xml_url = 'http://www.zdf.de/ZDFmediathek/xmlservice/web/beitragsDetails?ak=web&id=%s' % video_id\n        return extract_from_xml_url(self, video_id, xml_url)",
        "begin_line": 127,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFChannelIE._fetch_page#144",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFChannelIE",
        "signature": "youtube_dl.extractor.zdf.ZDFChannelIE._fetch_page(self, channel_id, page)",
        "snippet": "    def _fetch_page(self, channel_id, page):\n        offset = page * self._PAGE_SIZE\n        xml_url = (\n            'http://www.zdf.de/ZDFmediathek/xmlservice/web/aktuellste?ak=web&offset=%d&maxLength=%d&id=%s'\n            % (offset, self._PAGE_SIZE, channel_id))\n        doc = self._download_xml(\n            xml_url, channel_id,\n            note='Downloading channel info',\n            errnote='Failed to download channel info')\n\n        title = doc.find('.//information/title').text\n        description = doc.find('.//information/detail').text\n        for asset in doc.findall('.//teasers/teaser'):\n            a_type = asset.find('./type').text\n            a_id = asset.find('./details/assetId').text\n            if a_type not in ('video', 'topic'):\n                continue\n            yield {\n                '_type': 'url',\n                'playlist_title': title,\n                'playlist_description': description,\n                'url': 'zdf:%s:%s' % (a_type, a_id),\n            }",
        "begin_line": 144,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFChannelIE._real_extract#168",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFChannelIE",
        "signature": "youtube_dl.extractor.zdf.ZDFChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n        entries = OnDemandPagedList(\n            functools.partial(self._fetch_page, channel_id), self._PAGE_SIZE)\n\n        return {\n            '_type': 'playlist',\n            'id': channel_id,\n            'entries': entries,\n        }",
        "begin_line": 168,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.atresplayer.AtresPlayerIE._real_initialize#53",
        "src_path": "youtube_dl/extractor/atresplayer.py",
        "class_name": "youtube_dl.extractor.atresplayer.AtresPlayerIE",
        "signature": "youtube_dl.extractor.atresplayer.AtresPlayerIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.atresplayer.AtresPlayerIE._login#56",
        "src_path": "youtube_dl/extractor/atresplayer.py",
        "class_name": "youtube_dl.extractor.atresplayer.AtresPlayerIE",
        "signature": "youtube_dl.extractor.atresplayer.AtresPlayerIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'j_username': username,\n            'j_password': password,\n        }\n\n        request = compat_urllib_request.Request(\n            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        response = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        error = self._html_search_regex(\n            r'(?s)<ul class=\"list_error\">(.+?)</ul>', response, 'error', default=None)\n        if error:\n            raise ExtractorError(\n                'Unable to login: %s' % error, expected=True)",
        "begin_line": 56,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.atresplayer.AtresPlayerIE._real_extract#78",
        "src_path": "youtube_dl/extractor/atresplayer.py",
        "class_name": "youtube_dl.extractor.atresplayer.AtresPlayerIE",
        "signature": "youtube_dl.extractor.atresplayer.AtresPlayerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        episode_id = self._search_regex(\n            r'episode=\"([^\"]+)\"', webpage, 'episode id')\n\n        timestamp = int_or_none(self._download_webpage(\n            self._TIME_API_URL,\n            video_id, 'Downloading timestamp', fatal=False), 1000, time.time())\n        timestamp_shifted = compat_str(timestamp + self._TIMESTAMP_SHIFT)\n        token = hmac.new(\n            self._MAGIC.encode('ascii'),\n            (episode_id + timestamp_shifted).encode('utf-8')\n        ).hexdigest()\n\n        formats = []\n        for fmt in ['windows', 'android_tablet']:\n            request = compat_urllib_request.Request(\n                self._URL_VIDEO_TEMPLATE.format(fmt, episode_id, timestamp_shifted, token))\n            request.add_header('User-Agent', self._USER_AGENT)\n\n            fmt_json = self._download_json(\n                request, video_id, 'Downloading %s video JSON' % fmt)\n\n            result = fmt_json.get('resultDes')\n            if result.lower() != 'ok':\n                raise ExtractorError(\n                    '%s returned error: %s' % (self.IE_NAME, result), expected=True)\n\n            for format_id, video_url in fmt_json['resultObject'].items():\n                if format_id == 'token' or not video_url.startswith('http'):\n                    continue\n                if video_url.endswith('/Manifest'):\n                    if 'geodeswowsmpra3player' in video_url:\n                        f4m_path = video_url.split('smil:', 1)[-1].split('free_', 1)[0]\n                        f4m_url = 'http://drg.antena3.com/{0}hds/es/sd.f4m'.format(f4m_path)\n                        # this videos are protected by DRM, the f4m downloader doesn't support them\n                        continue\n                    else:\n                        f4m_url = video_url[:-9] + '/manifest.f4m'\n                    formats.extend(self._extract_f4m_formats(f4m_url, video_id))\n                else:\n                    formats.append({\n                        'url': video_url,\n                        'format_id': 'android-%s' % format_id,\n                        'preference': 1,\n                    })\n        self._sort_formats(formats)\n\n        player = self._download_json(\n            self._PLAYER_URL_TEMPLATE % episode_id,\n            episode_id)\n\n        path_data = player.get('pathData')\n\n        episode = self._download_xml(\n            self._EPISODE_URL_TEMPLATE % path_data,\n            video_id, 'Downloading episode XML')\n\n        duration = float_or_none(xpath_text(\n            episode, './media/asset/info/technical/contentDuration', 'duration'))\n\n        art = episode.find('./media/asset/info/art')\n        title = xpath_text(art, './name', 'title')\n        description = xpath_text(art, './description', 'description')\n        thumbnail = xpath_text(episode, './media/asset/files/background', 'thumbnail')\n\n        subtitles = {}\n        subtitle_url = xpath_text(episode, './media/asset/files/subtitle', 'subtitle')\n        if subtitle_url:\n            subtitles['es'] = [{\n                'ext': 'srt',\n                'url': subtitle_url,\n            }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 78,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ehow.EHowIE._real_extract#22",
        "src_path": "youtube_dl/extractor/ehow.py",
        "class_name": "youtube_dl.extractor.ehow.EHowIE",
        "signature": "youtube_dl.extractor.ehow.EHowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(\n            r'(?:file|source)=(http[^\\'\"&]*)', webpage, 'video URL')\n        final_url = compat_urllib_parse_unquote(video_url)\n        uploader = self._html_search_meta('uploader', webpage)\n        title = self._og_search_title(webpage).replace(' | eHow', '')\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n            'uploader': uploader,\n        }",
        "begin_line": 22,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._real_initialize#63",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 63,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._login#66",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'a': 'login',\n            'cookie': '1',\n            'username': username,\n            'password': password,\n        }\n        request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded; charset=UTF-8')\n\n        login = self._download_json(request, None, 'Logging in as %s' % username)\n\n        if 'erreur' in login:\n            raise ExtractorError('Unable to login: %s' % clean_html(login['erreur']), expected=True)",
        "begin_line": 66,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._call_api#85",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._call_api(self, path, video_id, note, sub_lang=None)",
        "snippet": "    def _call_api(self, path, video_id, note, sub_lang=None):\n        ts = compat_str(int(time.time() * 1000))\n        tk = hashlib.md5((hashlib.md5(ts.encode('ascii')).hexdigest() + '#8S?uCraTedap6a').encode('ascii')).hexdigest()\n        url = self._API_URL_TEMPLATE % (path, ts, tk)\n        if sub_lang:\n            url += self._SUB_LANG_TEMPLATE % sub_lang\n\n        resp = self._download_json(url, video_id, note)\n\n        if isinstance(resp, dict) and resp.get('error'):\n            self._raise_error(resp['error'], resp['description'])\n\n        return resp",
        "begin_line": 85,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._raise_error#99",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._raise_error(self, error, description)",
        "snippet": "    def _raise_error(self, error, description):\n        raise ExtractorError(\n            '%s returned error: %s - %s' % (self.IE_NAME, error, description),\n            expected=True)",
        "begin_line": 99,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._real_extract#104",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        medias = self._call_api(\n            'shows/%s/medias' % video_id,\n            video_id, 'Downloading video JSON')\n\n        show = self._call_api(\n            'shows/by_id/%s' % video_id,\n            video_id, 'Downloading show JSON')[0]\n\n        options = self._call_api(\n            'users/init', video_id,\n            'Downloading user options JSON')['options']\n        audio_lang_pref = options.get('audio_language') or options.get('language', 'fr')\n\n        if audio_lang_pref == 'original':\n            audio_lang_pref = show['original_lang']\n        if len(medias) == 1:\n            audio_lang_pref = list(medias.keys())[0]\n        elif audio_lang_pref not in medias:\n            audio_lang_pref = 'fr'\n\n        qualities = self._call_api(\n            'qualities',\n            video_id, 'Downloading qualities JSON')\n\n        formats = []\n\n        for audio_lang, audio_lang_dict in medias.items():\n            preference = 1 if audio_lang == audio_lang_pref else 0\n            for sub_lang, lang_dict in audio_lang_dict['video_list'].items():\n                for format_id, fmt in lang_dict['quality_list'].items():\n                    format_id_extended = 'audio-%s_sub-%s_%s' % (audio_lang, sub_lang, format_id)\n\n                    video = self._call_api(\n                        'shows/%s/video/%s/%s' % (video_id, format_id.lower(), audio_lang),\n                        video_id, 'Downloading %s video JSON' % format_id_extended,\n                        sub_lang if sub_lang != 'none' else None)\n\n                    file_url = video['file']\n                    if not file_url:\n                        continue\n\n                    if file_url in ['forbidden', 'not found']:\n                        popmessage = video['popmessage']\n                        self._raise_error(popmessage['title'], popmessage['message'])\n\n                    formats.append({\n                        'url': file_url,\n                        'format_id': format_id_extended,\n                        'width': int_or_none(fmt.get('res_width')),\n                        'height': int_or_none(fmt.get('res_lines')),\n                        'abr': int_or_none(fmt.get('audiobitrate')),\n                        'vbr': int_or_none(fmt.get('videobitrate')),\n                        'filesize': int_or_none(fmt.get('filesize')),\n                        'format_note': qualities[format_id].get('quality_name'),\n                        'quality': qualities[format_id].get('priority'),\n                        'preference': preference,\n                    })\n\n        self._sort_formats(formats)\n\n        timestamp = parse_iso8601(show.get('online_date_start_utc'), ' ')\n\n        if timestamp is not None and timestamp < 0:\n            timestamp = None\n\n        uploader = show.get('partner_name')\n        uploader_id = show.get('partner_key')\n        duration = float_or_none(show.get('duration_ms'), 1000)\n\n        thumbnails = []\n        for thumbnail_key, thumbnail_url in show.items():\n            m = re.search(r'^screenshot_(?P<width>\\d+)x(?P<height>\\d+)$', thumbnail_key)\n            if not m:\n                continue\n            thumbnails.append({\n                'url': thumbnail_url,\n                'width': int(m.group('width')),\n                'height': int(m.group('height')),\n            })\n\n        episode = show.get('show_TT') or show.get('show_OT')\n        family = show.get('family_TT') or show.get('family_OT')\n        episode_number = show.get('episode_number')\n\n        title = ''\n        if family:\n            title += family\n        if episode_number:\n            title += ' #' + compat_str(episode_number)\n        if episode:\n            title += ' - ' + compat_str(episode)\n\n        description = show.get('show_resume') or show.get('family_resume')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 104,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yam.YamIE._real_extract#74",
        "src_path": "youtube_dl/extractor/yam.py",
        "class_name": "youtube_dl.extractor.yam.YamIE",
        "signature": "youtube_dl.extractor.yam.YamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        page = self._download_webpage(url, video_id)\n\n        # Check for errors\n        system_msg = self._html_search_regex(\n            r'\u7cfb\u7d71\u8a0a\u606f(?:<br>|\\n|\\r)*([^<>]+)<br>', page, 'system message',\n            default=None)\n        if system_msg:\n            raise ExtractorError(system_msg, expected=True)\n\n        # Is it hosted externally on YouTube?\n        youtube_url = self._html_search_regex(\n            r'<embed src=\"(http://www.youtube.com/[^\"]+)\"',\n            page, 'YouTube url', default=None)\n        if youtube_url:\n            return self.url_result(youtube_url, 'Youtube')\n\n        title = self._html_search_regex(\n            r'<h1[^>]+class=\"heading\"[^>]*>\\s*(.+)\\s*</h1>', page, 'title')\n\n        api_page = self._download_webpage(\n            'http://mymedia.yam.com/api/a/?pID=' + video_id, video_id,\n            note='Downloading API page')\n        api_result_obj = compat_urlparse.parse_qs(api_page)\n\n        info_table = get_element_by_attribute('class', 'info', page)\n        uploader_id = self._html_search_regex(\n            r'<!-- \u767c\u8868\u4f5c\u8005 -->\uff1a[\\n ]+<a href=\"/([a-z0-9]+)\"',\n            info_table, 'uploader id', fatal=False)\n        mobj = re.search(r'<!-- \u767c\u8868\u65bc -->(?P<mon>[A-Z][a-z]{2})\\s+' +\n                         r'(?P<day>\\d{1,2}), (?P<year>\\d{4})', page)\n        if mobj:\n            upload_date = '%s%02d%02d' % (\n                mobj.group('year'),\n                month_by_abbreviation(mobj.group('mon')),\n                int(mobj.group('day')))\n        else:\n            upload_date = None\n        duration = float_or_none(api_result_obj['totaltime'][0], scale=1000)\n\n        return {\n            'id': video_id,\n            'url': api_result_obj['mp3file'][0],\n            'title': title,\n            'description': self._html_search_meta('description', page),\n            'duration': duration,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n        }",
        "begin_line": 74,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaBaseIE._extract_result#17",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaBaseIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaBaseIE._extract_result(self, info, more_info)",
        "snippet": "    def _extract_result(self, info, more_info):\n        embedCode = info['embedCode']\n        video_url = info.get('ipad_url') or info['url']\n\n        if determine_ext(video_url) == 'm3u8':\n            formats = self._extract_m3u8_formats(video_url, embedCode, ext='mp4')\n        else:\n            formats = [{\n                'url': video_url,\n                'ext': 'mp4',\n            }]\n\n        return {\n            'id': embedCode,\n            'title': unescapeHTML(info['title']),\n            'formats': formats,\n            'description': unescapeHTML(more_info['description']),\n            'thumbnail': more_info['promo'],\n        }",
        "begin_line": 17,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaBaseIE._extract#37",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaBaseIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaBaseIE._extract(self, player_url, video_id)",
        "snippet": "    def _extract(self, player_url, video_id):\n        player = self._download_webpage(player_url, video_id)\n        mobile_url = self._search_regex(r'mobile_player_url=\"(.+?)&device=\"',\n                                        player, 'mobile player url')\n        # Looks like some videos are only available for particular devices\n        # (e.g. http://player.ooyala.com/player.js?embedCode=x1b3lqZDq9y_7kMyC2Op5qo-p077tXD0\n        # is only available for ipad)\n        # Working around with fetching URLs for all the devices found starting with 'unknown'\n        # until we succeed or eventually fail for each device.\n        devices = re.findall(r'device\\s*=\\s*\"([^\"]+)\";', player)\n        devices.remove('unknown')\n        devices.insert(0, 'unknown')\n        for device in devices:\n            mobile_player = self._download_webpage(\n                '%s&device=%s' % (mobile_url, device), video_id,\n                'Downloading mobile player JS for %s device' % device)\n            videos_info = self._search_regex(\n                r'var streams=window.oo_testEnv\\?\\[\\]:eval\\(\"\\((\\[{.*?}\\])\\)\"\\);',\n                mobile_player, 'info', fatal=False, default=None)\n            if videos_info:\n                break\n\n        if not videos_info:\n            formats = []\n            auth_data = self._download_json(\n                'http://player.ooyala.com/sas/player_api/v1/authorization/embed_code/%s/%s?domain=www.example.org&supportedFormats=mp4,webm' % (video_id, video_id),\n                video_id)\n\n            cur_auth_data = auth_data['authorization_data'][video_id]\n\n            for stream in cur_auth_data['streams']:\n                formats.append({\n                    'url': base64.b64decode(stream['url']['data'].encode('ascii')).decode('utf-8'),\n                    'ext': stream.get('delivery_type'),\n                    'format': stream.get('video_codec'),\n                    'format_id': stream.get('profile'),\n                    'width': int_or_none(stream.get('width')),\n                    'height': int_or_none(stream.get('height')),\n                    'abr': int_or_none(stream.get('audio_bitrate')),\n                    'vbr': int_or_none(stream.get('video_bitrate')),\n                })\n            if formats:\n                return {\n                    'id': video_id,\n                    'formats': formats,\n                    'title': 'Ooyala video',\n                }\n\n            if not cur_auth_data['authorized']:\n                raise ExtractorError(cur_auth_data['message'], expected=True)\n\n        if not videos_info:\n            raise ExtractorError('Unable to extract info')\n        videos_info = videos_info.replace('\\\\\"', '\"')\n        videos_more_info = self._search_regex(\n            r'eval\\(\"\\(({.*?\\\\\"promo\\\\\".*?})\\)\"', mobile_player, 'more info').replace('\\\\\"', '\"')\n        videos_info = json.loads(videos_info)\n        videos_more_info = json.loads(videos_more_info)\n\n        if videos_more_info.get('lineup'):\n            videos = [self._extract_result(info, more_info) for (info, more_info) in zip(videos_info, videos_more_info['lineup'])]\n            return {\n                '_type': 'playlist',\n                'id': video_id,\n                'title': unescapeHTML(videos_more_info['title']),\n                'entries': videos,\n            }\n        else:\n            return self._extract_result(videos_info[0], videos_more_info)",
        "begin_line": 37,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaIE._url_for_embed_code#145",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaIE._url_for_embed_code(embed_code)",
        "snippet": "    def _url_for_embed_code(embed_code):\n        return 'http://player.ooyala.com/player.js?embedCode=%s' % embed_code",
        "begin_line": 145,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaIE._build_url_result#149",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaIE._build_url_result(cls, embed_code)",
        "snippet": "    def _build_url_result(cls, embed_code):\n        return cls.url_result(cls._url_for_embed_code(embed_code),\n                              ie=cls.ie_key())",
        "begin_line": 149,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaIE._real_extract#153",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        embed_code = self._match_id(url)\n        player_url = 'http://player.ooyala.com/player.js?embedCode=%s' % embed_code\n        return self._extract(player_url, embed_code)",
        "begin_line": 153,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaExternalIE._real_extract#190",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaExternalIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaExternalIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        partner_id = mobj.group('partner_id')\n        video_id = mobj.group('id')\n        pcode = mobj.group('pcode')\n        player_url = 'http://player.ooyala.com/player.js?externalId=%s:%s&pcode=%s' % (partner_id, video_id, pcode)\n        return self._extract(player_url, video_id)",
        "begin_line": 190,
        "end_line": 196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._extract_series#73",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._extract_series(self, url, webpage)",
        "snippet": "    def _extract_series(self, url, webpage):\n        title = self._html_search_regex(r'<div class=\"cne-series-info\">.*?<h1>(.+?)</h1>',\n                                        webpage, 'series title', flags=re.DOTALL)\n        url_object = compat_urllib_parse_urlparse(url)\n        base_url = '%s://%s' % (url_object.scheme, url_object.netloc)\n        m_paths = re.finditer(r'<p class=\"cne-thumb-title\">.*?<a href=\"(/watch/.+?)[\"\\?]',\n                              webpage, flags=re.DOTALL)\n        paths = orderedSet(m.group(1) for m in m_paths)\n        build_url = lambda path: compat_urlparse.urljoin(base_url, path)\n        entries = [self.url_result(build_url(path), 'CondeNast') for path in paths]\n        return self.playlist_result(entries, playlist_title=title)",
        "begin_line": 73,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._extract_video#85",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._extract_video(self, webpage, url_type)",
        "snippet": "    def _extract_video(self, webpage, url_type):\n        if url_type != 'embed':\n            description = self._html_search_regex(\n                [\n                    r'<div class=\"cne-video-description\">(.+?)</div>',\n                    r'<div class=\"video-post-content\">(.+?)</div>',\n                ],\n                webpage, 'description', fatal=False, flags=re.DOTALL)\n        else:\n            description = None\n        params = self._search_regex(r'var params = {(.+?)}[;,]', webpage,\n                                    'player params', flags=re.DOTALL)\n        video_id = self._search_regex(r'videoId: [\\'\"](.+?)[\\'\"]', params, 'video id')\n        player_id = self._search_regex(r'playerId: [\\'\"](.+?)[\\'\"]', params, 'player id')\n        target = self._search_regex(r'target: [\\'\"](.+?)[\\'\"]', params, 'target')\n        data = compat_urllib_parse.urlencode({'videoId': video_id,\n                                              'playerId': player_id,\n                                              'target': target,\n                                              })\n        base_info_url = self._search_regex(r'url = [\\'\"](.+?)[\\'\"][,;]',\n                                           webpage, 'base info url',\n                                           default='http://player.cnevids.com/player/loader.js?')\n        info_url = base_info_url + data\n        info_page = self._download_webpage(info_url, video_id,\n                                           'Downloading video info')\n        video_info = self._search_regex(r'var\\s+video\\s*=\\s*({.+?});', info_page, 'video info')\n        video_info = self._parse_json(video_info, video_id)\n\n        formats = [{\n            'format_id': '%s-%s' % (fdata['type'].split('/')[-1], fdata['quality']),\n            'url': fdata['src'],\n            'ext': fdata['type'].split('/')[-1],\n            'quality': 1 if fdata['quality'] == 'high' else 0,\n        } for fdata in video_info['sources'][0]]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_info['title'],\n            'thumbnail': video_info['poster_frame'],\n            'description': description,\n        }",
        "begin_line": 85,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._real_extract#129",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        site = mobj.group('site')\n        url_type = mobj.group('type')\n        item_id = mobj.group('id')\n\n        # Convert JS embed to regular embed\n        if url_type == 'embedjs':\n            parsed_url = compat_urlparse.urlparse(url)\n            url = compat_urlparse.urlunparse(parsed_url._replace(\n                path=remove_end(parsed_url.path, '.js').replace('/embedjs/', '/embed/')))\n            url_type = 'embed'\n\n        self.to_screen('Extracting from %s with the Cond\u00e9 Nast extractor' % self._SITES[site])\n        webpage = self._download_webpage(url, item_id)\n\n        if url_type == 'series':\n            return self._extract_series(url, webpage)\n        else:\n            return self._extract_video(webpage, url_type)",
        "begin_line": 129,
        "end_line": 148,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vbox7.Vbox7IE._real_extract#27",
        "src_path": "youtube_dl/extractor/vbox7.py",
        "class_name": "youtube_dl.extractor.vbox7.Vbox7IE",
        "signature": "youtube_dl.extractor.vbox7.Vbox7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # need to get the page 3 times for the correct jsSecretToken cookie\n        # which is necessary for the correct title\n        def get_session_id():\n            redirect_page = self._download_webpage(url, video_id)\n            session_id_url = self._search_regex(\n                r'var\\s*url\\s*=\\s*\\'([^\\']+)\\';', redirect_page,\n                'session id url')\n            self._download_webpage(\n                compat_urlparse.urljoin(url, session_id_url), video_id,\n                'Getting session id')\n\n        get_session_id()\n        get_session_id()\n\n        webpage = self._download_webpage(url, video_id,\n                                         'Downloading redirect page')\n\n        title = self._html_search_regex(r'<title>(.*)</title>',\n                                        webpage, 'title').split('/')[0].strip()\n\n        info_url = \"http://vbox7.com/play/magare.do\"\n        data = compat_urllib_parse.urlencode({'as3': '1', 'vid': video_id})\n        info_request = compat_urllib_request.Request(info_url, data)\n        info_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        info_response = self._download_webpage(info_request, video_id, 'Downloading info webpage')\n        if info_response is None:\n            raise ExtractorError('Unable to extract the media url')\n        (final_url, thumbnail_url) = map(lambda x: x.split('=')[1], info_response.split('&'))\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': thumbnail_url,\n        }",
        "begin_line": 27,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudIE._check_url#46",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudIE._check_url(self, url, track_id, ext)",
        "snippet": "    def _check_url(self, url, track_id, ext):\n        try:\n            # We only want to know if the request succeed\n            # don't download the whole file\n            self._request_webpage(\n                HEADRequest(url), track_id,\n                'Trying %s URL' % ext)\n            return True\n        except ExtractorError:\n            return False",
        "begin_line": 46,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudIE._real_extract#57",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader = mobj.group(1)\n        cloudcast_name = mobj.group(2)\n        track_id = compat_urllib_parse_unquote('-'.join((uploader, cloudcast_name)))\n\n        webpage = self._download_webpage(url, track_id)\n\n        preview_url = self._search_regex(\n            r'\\s(?:data-preview-url|m-preview)=\"([^\"]+)\"', webpage, 'preview url')\n        song_url = preview_url.replace('/previews/', '/c/originals/')\n        if not self._check_url(song_url, track_id, 'mp3'):\n            song_url = song_url.replace('.mp3', '.m4a').replace('originals/', 'm4a/64/')\n            if not self._check_url(song_url, track_id, 'm4a'):\n                raise ExtractorError('Unable to extract track url')\n\n        PREFIX = (\n            r'm-play-on-spacebar[^>]+'\n            r'(?:\\s+[a-zA-Z0-9-]+(?:=\"[^\"]+\")?)*?\\s+')\n        title = self._html_search_regex(\n            PREFIX + r'm-title=\"([^\"]+)\"', webpage, 'title')\n        thumbnail = self._proto_relative_url(self._html_search_regex(\n            PREFIX + r'm-thumbnail-url=\"([^\"]+)\"', webpage, 'thumbnail',\n            fatal=False))\n        uploader = self._html_search_regex(\n            PREFIX + r'm-owner-name=\"([^\"]+)\"',\n            webpage, 'uploader', fatal=False)\n        uploader_id = self._search_regex(\n            r'\\s+\"profile\": \"([^\"]+)\",', webpage, 'uploader id', fatal=False)\n        description = self._og_search_description(webpage)\n        like_count = str_to_int(self._search_regex(\n            r'\\bbutton-favorite\\b[^>]+m-ajax-toggle-count=\"([^\"]+)\"',\n            webpage, 'like count', fatal=False))\n        view_count = str_to_int(self._search_regex(\n            [r'<meta itemprop=\"interactionCount\" content=\"UserPlays:([0-9]+)\"',\n             r'/listeners/?\">([0-9,.]+)</a>'],\n            webpage, 'play count', fatal=False))\n\n        return {\n            'id': track_id,\n            'title': title,\n            'url': song_url,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n            'like_count': like_count,\n        }",
        "begin_line": 57,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.keezmovies.KeezMoviesIE._real_extract#26",
        "src_path": "youtube_dl/extractor/keezmovies.py",
        "class_name": "youtube_dl.extractor.keezmovies.KeezMoviesIE",
        "signature": "youtube_dl.extractor.keezmovies.KeezMoviesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        # embedded video\n        mobj = re.search(r'href=\"([^\"]+)\"></iframe>', webpage)\n        if mobj:\n            embedded_url = mobj.group(1)\n            return self.url_result(embedded_url)\n\n        video_title = self._html_search_regex(\n            r'<h1 [^>]*>([^<]+)', webpage, 'title')\n        video_url = self._html_search_regex(\n            r'(?s)html5VideoPlayer = .*?src=\"([^\"]+)\"', webpage, 'video URL')\n        path = compat_urllib_parse_urlparse(video_url).path\n        extension = os.path.splitext(path)[1][1:]\n        format = path.split('/')[4].split('_')[:2]\n        format = \"-\".join(format)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'url': video_url,\n            'ext': extension,\n            'format': format,\n            'format_id': format,\n            'age_limit': age_limit,\n        }",
        "begin_line": 26,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dctp.DctpTvIE._real_extract#24",
        "src_path": "youtube_dl/extractor/dctp.py",
        "class_name": "youtube_dl.extractor.dctp.DctpTvIE",
        "signature": "youtube_dl.extractor.dctp.DctpTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        base_url = 'http://dctp-ivms2-restapi.s3.amazonaws.com/'\n        version_json = self._download_json(\n            base_url + 'version.json',\n            video_id, note='Determining file version')\n        version = version_json['version_name']\n        info_json = self._download_json(\n            '{0}{1}/restapi/slugs/{2}.json'.format(base_url, version, video_id),\n            video_id, note='Fetching object ID')\n        object_id = compat_str(info_json['object_id'])\n        meta_json = self._download_json(\n            '{0}{1}/restapi/media/{2}.json'.format(base_url, version, object_id),\n            video_id, note='Downloading metadata')\n        uuid = meta_json['uuid']\n        title = meta_json['title']\n        wide = meta_json['is_wide']\n        if wide:\n            ratio = '16x9'\n        else:\n            ratio = '4x3'\n        play_path = 'mp4:{0}_dctp_0500_{1}.m4v'.format(uuid, ratio)\n\n        servers_json = self._download_json(\n            'http://www.dctp.tv/streaming_servers/',\n            video_id, note='Downloading server list')\n        url = servers_json[0]['endpoint']\n\n        return {\n            'id': object_id,\n            'title': title,\n            'format': 'rtmp',\n            'url': url,\n            'play_path': play_path,\n            'rtmp_real_time': True,\n            'ext': 'flv',\n            'display_id': video_id\n        }",
        "begin_line": 24,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._build_url#30",
        "src_path": "youtube_dl/extractor/internetvideoarchive.py",
        "class_name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE",
        "signature": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._build_url(query)",
        "snippet": "    def _build_url(query):\n        return 'http://video.internetvideoarchive.net/flash/players/flashconfiguration.aspx?' + query",
        "begin_line": 30,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._clean_query#34",
        "src_path": "youtube_dl/extractor/internetvideoarchive.py",
        "class_name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE",
        "signature": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._clean_query(query)",
        "snippet": "    def _clean_query(query):\n        NEEDED_ARGS = ['publishedid', 'customerid']\n        query_dic = compat_urlparse.parse_qs(query)\n        cleaned_dic = dict((k, v[0]) for (k, v) in query_dic.items() if k in NEEDED_ARGS)\n        # Other player ids return m3u8 urls\n        cleaned_dic['playerid'] = '247'\n        cleaned_dic['videokbrate'] = '100000'\n        return compat_urllib_parse.urlencode(cleaned_dic)",
        "begin_line": 34,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._real_extract#43",
        "src_path": "youtube_dl/extractor/internetvideoarchive.py",
        "class_name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE",
        "signature": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        query = compat_urlparse.urlparse(url).query\n        query_dic = compat_urlparse.parse_qs(query)\n        video_id = query_dic['publishedid'][0]\n        url = self._build_url(query)\n\n        flashconfiguration = self._download_xml(url, video_id,\n                                                'Downloading flash configuration')\n        file_url = flashconfiguration.find('file').text\n        file_url = file_url.replace('/playlist.aspx', '/mrssplaylist.aspx')\n        # Replace some of the parameters in the query to get the best quality\n        # and http links (no m3u8 manifests)\n        file_url = re.sub(r'(?<=\\?)(.+)$',\n                          lambda m: self._clean_query(m.group()),\n                          file_url)\n        info = self._download_xml(file_url, video_id,\n                                  'Downloading video info')\n        item = info.find('channel/item')\n\n        def _bp(p):\n            return xpath_with_ns(\n                p,\n                {\n                    'media': 'http://search.yahoo.com/mrss/',\n                    'jwplayer': 'http://developer.longtailvideo.com/trac/wiki/FlashFormats',\n                }\n            )\n        formats = []\n        for content in item.findall(_bp('media:group/media:content')):\n            attr = content.attrib\n            f_url = attr['url']\n            width = int(attr['width'])\n            bitrate = int(attr['bitrate'])\n            format_id = '%d-%dk' % (width, bitrate)\n            formats.append({\n                'format_id': format_id,\n                'url': f_url,\n                'width': width,\n                'tbr': bitrate,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': item.find('title').text,\n            'formats': formats,\n            'thumbnail': item.find(_bp('media:thumbnail')).attrib['url'],\n            'description': item.find('description').text,\n            'duration': int(attr['duration']),\n        }",
        "begin_line": 43,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.huffpost.HuffPostIE._real_extract#35",
        "src_path": "youtube_dl/extractor/huffpost.py",
        "class_name": "youtube_dl.extractor.huffpost.HuffPostIE",
        "signature": "youtube_dl.extractor.huffpost.HuffPostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        api_url = 'http://embed.live.huffingtonpost.com/api/segments/%s.json' % video_id\n        data = self._download_json(api_url, video_id)['data']\n\n        video_title = data['title']\n        duration = parse_duration(data.get('running_time'))\n        upload_date = unified_strdate(\n            data.get('schedule', {}).get('starts_at') or data.get('segment_start_date_time'))\n        description = data.get('description')\n\n        thumbnails = []\n        for url in data['images'].values():\n            m = re.match('.*-([0-9]+x[0-9]+)\\.', url)\n            if not m:\n                continue\n            thumbnails.append({\n                'url': url,\n                'resolution': m.group(1),\n            })\n\n        formats = [{\n            'format': key,\n            'format_id': key.replace('/', '.'),\n            'ext': 'mp4',\n            'url': url,\n            'vcodec': 'none' if key.startswith('audio/') else None,\n        } for key, url in data.get('sources', {}).get('live', {}).items()]\n\n        if not formats and data.get('fivemin_id'):\n            return self.url_result('5min:%s' % data['fivemin_id'])\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': description,\n            'formats': formats,\n            'duration': duration,\n            'upload_date': upload_date,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 35,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoBaseIE._get_formats#26",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoBaseIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoBaseIE._get_formats(self, song_id)",
        "snippet": "    def _get_formats(self, song_id):\n        formats = []\n        for file_format in self._FORMATS:\n            song_url = self._download_webpage(\n                'http://antiserver.kuwo.cn/anti.s?format=%s&br=%s&rid=MUSIC_%s&type=convert_url&response=url' %\n                (file_format['ext'], file_format.get('br', ''), song_id),\n                song_id, note='Download %s url info' % file_format['format'],\n            )\n            if song_url.startswith('http://') or song_url.startswith('https://'):\n                formats.append({\n                    'url': song_url,\n                    'format_id': file_format['format'],\n                    'format': file_format['format'],\n                    'preference': file_format['preference'],\n                    'abr': file_format.get('abr'),\n                })\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 26,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoIE._real_extract#75",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, song_id, note='Download song detail info',\n            errnote='Unable to get song detail info')\n        if '\u5bf9\u4e0d\u8d77\uff0c\u8be5\u6b4c\u66f2\u7531\u4e8e\u7248\u6743\u95ee\u9898\u5df2\u88ab\u4e0b\u7ebf\uff0c\u5c06\u8fd4\u56de\u7f51\u7ad9\u9996\u9875' in webpage:\n            raise ExtractorError('this song has been offline because of copyright issues', expected=True)\n\n        song_name = self._html_search_regex(\n            r'(?s)class=\"(?:[^\"\\s]+\\s+)*title(?:\\s+[^\"\\s]+)*\".*?<h1[^>]+title=\"([^\"]+)\"', webpage, 'song name')\n        singer_name = self._html_search_regex(\n            r'<div[^>]+class=\"s_img\">\\s*<a[^>]+title=\"([^>]+)\"',\n            webpage, 'singer name', fatal=False)\n        lrc_content = clean_html(get_element_by_id('lrcContent', webpage))\n        if lrc_content == '\u6682\u65e0':     # indicates no lyrics\n            lrc_content = None\n\n        formats = self._get_formats(song_id)\n\n        album_id = self._html_search_regex(\n            r'<p[^>]+class=\"album\"[^<]+<a[^>]+href=\"http://www\\.kuwo\\.cn/album/(\\d+)/\"',\n            webpage, 'album id', fatal=False)\n\n        publish_time = None\n        if album_id is not None:\n            album_info_page = self._download_webpage(\n                'http://www.kuwo.cn/album/%s/' % album_id, song_id,\n                note='Download album detail info',\n                errnote='Unable to get album detail info')\n\n            publish_time = self._html_search_regex(\n                r'\u53d1\u884c\u65f6\u95f4\uff1a(\\d{4}-\\d{2}-\\d{2})', album_info_page,\n                'publish time', fatal=False)\n            if publish_time:\n                publish_time = publish_time.replace('-', '')\n\n        return {\n            'id': song_id,\n            'title': song_name,\n            'creator': singer_name,\n            'upload_date': publish_time,\n            'description': lrc_content,\n            'formats': formats,\n        }",
        "begin_line": 75,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoAlbumIE._real_extract#135",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoAlbumIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        album_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            url, album_id, note='Download album info',\n            errnote='Unable to get album info')\n\n        album_name = self._html_search_regex(\n            r'<div[^>]+class=\"comm\"[^<]+<h1[^>]+title=\"([^\"]+)\"', webpage,\n            'album name')\n        album_intro = remove_start(\n            clean_html(get_element_by_id('intro', webpage)),\n            '%s\u7b80\u4ecb\uff1a' % album_name)\n\n        entries = [\n            self.url_result(song_url, 'Kuwo') for song_url in re.findall(\n                r'<p[^>]+class=\"listen\"><a[^>]+href=\"(http://www\\.kuwo\\.cn/yinyue/\\d+/)\"',\n                webpage)\n        ]\n        return self.playlist_result(entries, album_id, album_name, album_intro)",
        "begin_line": 135,
        "end_line": 154,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoChartIE._real_extract#171",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoChartIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoChartIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        chart_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, chart_id, note='Download chart info',\n            errnote='Unable to get chart info')\n\n        chart_name = self._html_search_regex(\n            r'<h1[^>]+class=\"unDis\">([^<]+)</h1>', webpage, 'chart name')\n\n        chart_desc = self._html_search_regex(\n            r'<p[^>]+class=\"tabDef\">(\\d{4}\u7b2c\\d{2}\u671f)</p>', webpage, 'chart desc')\n\n        entries = [\n            self.url_result(song_url, 'Kuwo') for song_url in re.findall(\n                r'<a[^>]+href=\"(http://www\\.kuwo\\.cn/yinyue/\\d+)/\"', webpage)\n        ]\n        return self.playlist_result(entries, chart_id, chart_name, chart_desc)",
        "begin_line": 171,
        "end_line": 187,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoSingerIE._real_extract#211",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoSingerIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoSingerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        singer_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, singer_id, note='Download singer info',\n            errnote='Unable to get singer info')\n\n        singer_name = self._html_search_regex(\n            r'<div class=\"title clearfix\">\\s*<h1>([^<]+)<span', webpage, 'singer name'\n        )\n\n        entries = []\n        first_page_only = False if re.search(r'/music(?:_\\d+)?\\.htm', url) else True\n        for page_num in itertools.count(1):\n            webpage = self._download_webpage(\n                'http://www.kuwo.cn/mingxing/%s/music_%d.htm' % (singer_id, page_num),\n                singer_id, note='Download song list page #%d' % page_num,\n                errnote='Unable to get song list page #%d' % page_num)\n\n            entries.extend([\n                self.url_result(song_url, 'Kuwo') for song_url in re.findall(\n                    r'<p[^>]+class=\"m_name\"><a[^>]+href=\"(http://www\\.kuwo\\.cn/yinyue/\\d+)/',\n                    webpage)\n            ][:10 if first_page_only else None])\n\n            if first_page_only or not re.search(r'<a[^>]+href=\"[^\"]+\">\u4e0b\u4e00\u9875</a>', webpage):\n                break\n\n        return self.playlist_result(entries, singer_id, singer_name)",
        "begin_line": 211,
        "end_line": 238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoCategoryIE._real_extract#255",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoCategoryIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoCategoryIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        category_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, category_id, note='Download category info',\n            errnote='Unable to get category info')\n\n        category_name = self._html_search_regex(\n            r'<h1[^>]+title=\"([^<>]+?)\">[^<>]+?</h1>', webpage, 'category name')\n\n        category_desc = remove_start(\n            get_element_by_id('intro', webpage).strip(),\n            '%s\u7b80\u4ecb\uff1a' % category_name)\n\n        jsonm = self._parse_json(self._html_search_regex(\n            r'var\\s+jsonm\\s*=\\s*([^;]+);', webpage, 'category songs'), category_id)\n\n        entries = [\n            self.url_result('http://www.kuwo.cn/yinyue/%s/' % song['musicrid'], 'Kuwo')\n            for song in jsonm['musiclist']\n        ]\n        return self.playlist_result(entries, category_id, category_name, category_desc)",
        "begin_line": 255,
        "end_line": 275,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoMvIE._real_extract#296",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoMvIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoMvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, song_id, note='Download mv detail info: %s' % song_id,\n            errnote='Unable to get mv detail info: %s' % song_id)\n\n        mobj = re.search(\n            r'<h1[^>]+title=\"(?P<song>[^\"]+)\">[^<]+<span[^>]+title=\"(?P<singer>[^\"]+)\"',\n            webpage)\n        if mobj:\n            song_name = mobj.group('song')\n            singer_name = mobj.group('singer')\n        else:\n            raise ExtractorError('Unable to find song or singer names')\n\n        formats = self._get_formats(song_id)\n\n        return {\n            'id': song_id,\n            'title': song_name,\n            'creator': singer_name,\n            'formats': formats,\n        }",
        "begin_line": 296,
        "end_line": 318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.keek.KeekIE._real_extract#22",
        "src_path": "youtube_dl/extractor/keek.py",
        "class_name": "youtube_dl.extractor.keek.KeekIE",
        "signature": "youtube_dl.extractor.keek.KeekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        return {\n            'id': video_id,\n            'url': self._og_search_video_url(webpage),\n            'ext': 'mp4',\n            'title': self._og_search_description(webpage).strip(),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader': self._search_regex(\n                r'data-username=([\"\\'])(?P<uploader>.+?)\\1', webpage,\n                'uploader', fatal=False, group='uploader'),\n            'uploader_id': self._search_regex(\n                r'data-user-id=([\"\\'])(?P<uploader_id>.+?)\\1', webpage,\n                'uploader id', fatal=False, group='uploader_id'),\n        }",
        "begin_line": 22,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mojvideo.MojvideoIE._real_extract#28",
        "src_path": "youtube_dl/extractor/mojvideo.py",
        "class_name": "youtube_dl.extractor.mojvideo.MojvideoIE",
        "signature": "youtube_dl.extractor.mojvideo.MojvideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        # XML is malformed\n        playerapi = self._download_webpage(\n            'http://www.mojvideo.com/playerapi.php?v=%s&t=1' % video_id, display_id)\n\n        if '<error>true</error>' in playerapi:\n            error_desc = self._html_search_regex(\n                r'<errordesc>([^<]*)</errordesc>', playerapi, 'error description', fatal=False)\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, error_desc), expected=True)\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)</title>', playerapi, 'title')\n        video_url = self._html_search_regex(\n            r'<file>([^<]+)</file>', playerapi, 'video URL')\n        thumbnail = self._html_search_regex(\n            r'<preview>([^<]+)</preview>', playerapi, 'thumbnail', fatal=False)\n        duration = parse_duration(self._html_search_regex(\n            r'<duration>([^<]+)</duration>', playerapi, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 28,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.__init__#30",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.__init__(self, code, objects=None)",
        "snippet": "    def __init__(self, code, objects=None):\n        if objects is None:\n            objects = {}\n        self.code = code\n        self._functions = {}\n        self._objects = objects",
        "begin_line": 30,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.8470416249903824e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.interpret_statement#37",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.interpret_statement(self, stmt, local_vars, allow_recursion=100)",
        "snippet": "    def interpret_statement(self, stmt, local_vars, allow_recursion=100):\n        if allow_recursion < 0:\n            raise ExtractorError('Recursion limit reached')\n\n        should_abort = False\n        stmt = stmt.lstrip()\n        stmt_m = re.match(r'var\\s', stmt)\n        if stmt_m:\n            expr = stmt[len(stmt_m.group(0)):]\n        else:\n            return_m = re.match(r'return(?:\\s+|$)', stmt)\n            if return_m:\n                expr = stmt[len(return_m.group(0)):]\n                should_abort = True\n            else:\n                # Try interpreting it as an expression\n                expr = stmt\n\n        v = self.interpret_expression(expr, local_vars, allow_recursion)\n        return v, should_abort",
        "begin_line": 37,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.865630677645058e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.interpret_expression#58",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.interpret_expression(self, expr, local_vars, allow_recursion)",
        "snippet": "    def interpret_expression(self, expr, local_vars, allow_recursion):\n        expr = expr.strip()\n\n        if expr == '':  # Empty expression\n            return None\n\n        if expr.startswith('('):\n            parens_count = 0\n            for m in re.finditer(r'[()]', expr):\n                if m.group(0) == '(':\n                    parens_count += 1\n                else:\n                    parens_count -= 1\n                    if parens_count == 0:\n                        sub_expr = expr[1:m.start()]\n                        sub_result = self.interpret_expression(\n                            sub_expr, local_vars, allow_recursion)\n                        remaining_expr = expr[m.end():].strip()\n                        if not remaining_expr:\n                            return sub_result\n                        else:\n                            expr = json.dumps(sub_result) + remaining_expr\n                        break\n            else:\n                raise ExtractorError('Premature end of parens in %r' % expr)\n\n        for op, opfunc in _ASSIGN_OPERATORS:\n            m = re.match(r'''(?x)\n                (?P<out>%s)(?:\\[(?P<index>[^\\]]+?)\\])?\n                \\s*%s\n                (?P<expr>.*)$''' % (_NAME_RE, re.escape(op)), expr)\n            if not m:\n                continue\n            right_val = self.interpret_expression(\n                m.group('expr'), local_vars, allow_recursion - 1)\n\n            if m.groupdict().get('index'):\n                lvar = local_vars[m.group('out')]\n                idx = self.interpret_expression(\n                    m.group('index'), local_vars, allow_recursion)\n                assert isinstance(idx, int)\n                cur = lvar[idx]\n                val = opfunc(cur, right_val)\n                lvar[idx] = val\n                return val\n            else:\n                cur = local_vars.get(m.group('out'))\n                val = opfunc(cur, right_val)\n                local_vars[m.group('out')] = val\n                return val\n\n        if expr.isdigit():\n            return int(expr)\n\n        var_m = re.match(\n            r'(?!if|return|true|false)(?P<name>%s)$' % _NAME_RE,\n            expr)\n        if var_m:\n            return local_vars[var_m.group('name')]\n\n        try:\n            return json.loads(expr)\n        except ValueError:\n            pass\n\n        m = re.match(\n            r'(?P<var>%s)\\.(?P<member>[^(]+)(?:\\(+(?P<args>[^()]*)\\))?$' % _NAME_RE,\n            expr)\n        if m:\n            variable = m.group('var')\n            member = m.group('member')\n            arg_str = m.group('args')\n\n            if variable in local_vars:\n                obj = local_vars[variable]\n            else:\n                if variable not in self._objects:\n                    self._objects[variable] = self.extract_object(variable)\n                obj = self._objects[variable]\n\n            if arg_str is None:\n                # Member access\n                if member == 'length':\n                    return len(obj)\n                return obj[member]\n\n            assert expr.endswith(')')\n            # Function call\n            if arg_str == '':\n                argvals = tuple()\n            else:\n                argvals = tuple([\n                    self.interpret_expression(v, local_vars, allow_recursion)\n                    for v in arg_str.split(',')])\n\n            if member == 'split':\n                assert argvals == ('',)\n                return list(obj)\n            if member == 'join':\n                assert len(argvals) == 1\n                return argvals[0].join(obj)\n            if member == 'reverse':\n                assert len(argvals) == 0\n                obj.reverse()\n                return obj\n            if member == 'slice':\n                assert len(argvals) == 1\n                return obj[argvals[0]:]\n            if member == 'splice':\n                assert isinstance(obj, list)\n                index, howMany = argvals\n                res = []\n                for i in range(index, min(index + howMany, len(obj))):\n                    res.append(obj.pop(index))\n                return res\n\n            return obj[member](argvals)\n\n        m = re.match(\n            r'(?P<in>%s)\\[(?P<idx>.+)\\]$' % _NAME_RE, expr)\n        if m:\n            val = local_vars[m.group('in')]\n            idx = self.interpret_expression(\n                m.group('idx'), local_vars, allow_recursion - 1)\n            return val[idx]\n\n        for op, opfunc in _OPERATORS:\n            m = re.match(r'(?P<x>.+?)%s(?P<y>.+)' % re.escape(op), expr)\n            if not m:\n                continue\n            x, abort = self.interpret_statement(\n                m.group('x'), local_vars, allow_recursion - 1)\n            if abort:\n                raise ExtractorError(\n                    'Premature left-side return of %s in %r' % (op, expr))\n            y, abort = self.interpret_statement(\n                m.group('y'), local_vars, allow_recursion - 1)\n            if abort:\n                raise ExtractorError(\n                    'Premature right-side return of %s in %r' % (op, expr))\n            return opfunc(x, y)\n\n        m = re.match(\n            r'^(?P<func>%s)\\((?P<args>[a-zA-Z0-9_$,]+)\\)$' % _NAME_RE, expr)\n        if m:\n            fname = m.group('func')\n            argvals = tuple([\n                int(v) if v.isdigit() else local_vars[v]\n                for v in m.group('args').split(',')])\n            if fname not in self._functions:\n                self._functions[fname] = self.extract_function(fname)\n            return self._functions[fname](argvals)\n\n        raise ExtractorError('Unsupported JS expression %r' % expr)",
        "begin_line": 58,
        "end_line": 211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.extract_object#213",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.extract_object(self, objname)",
        "snippet": "    def extract_object(self, objname):\n        obj = {}\n        obj_m = re.search(\n            (r'(?:var\\s+)?%s\\s*=\\s*\\{' % re.escape(objname)) +\n            r'\\s*(?P<fields>([a-zA-Z$0-9]+\\s*:\\s*function\\(.*?\\)\\s*\\{.*?\\})*)' +\n            r'\\}\\s*;',\n            self.code)\n        fields = obj_m.group('fields')\n        # Currently, it only supports function definitions\n        fields_m = re.finditer(\n            r'(?P<key>[a-zA-Z$0-9]+)\\s*:\\s*function'\n            r'\\((?P<args>[a-z,]+)\\){(?P<code>[^}]+)}',\n            fields)\n        for f in fields_m:\n            argnames = f.group('args').split(',')\n            obj[f.group('key')] = self.build_function(argnames, f.group('code'))\n\n        return obj",
        "begin_line": 213,
        "end_line": 230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 4.1353072533289225e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.extract_function#232",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.extract_function(self, funcname)",
        "snippet": "    def extract_function(self, funcname):\n        func_m = re.search(\n            r'''(?x)\n                (?:function\\s+%s|[{;]%s\\s*=\\s*function)\\s*\n                \\((?P<args>[^)]*)\\)\\s*\n                \\{(?P<code>[^}]+)\\}''' % (\n                re.escape(funcname), re.escape(funcname)),\n            self.code)\n        if func_m is None:\n            raise ExtractorError('Could not find JS function %r' % funcname)\n        argnames = func_m.group('args').split(',')\n\n        return self.build_function(argnames, func_m.group('code'))",
        "begin_line": 232,
        "end_line": 244,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.8470416249903824e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.call_function#246",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.call_function(self, funcname, *args)",
        "snippet": "    def call_function(self, funcname, *args):\n        f = self.extract_function(funcname)\n        return f(args)",
        "begin_line": 246,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.8824397251232675e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.build_function#250",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.build_function(self, argnames, code)",
        "snippet": "    def build_function(self, argnames, code):\n        def resf(args):\n            local_vars = dict(zip(argnames, args))\n            for stmt in code.split(';'):\n                res, abort = self.interpret_statement(stmt, local_vars)\n                if abort:\n                    break\n            return res\n        return resf",
        "begin_line": 250,
        "end_line": 258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.8470416249903824e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.resf#251",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.resf(args)",
        "snippet": "        def resf(args):\n            local_vars = dict(zip(argnames, args))\n            for stmt in code.split(';'):\n                res, abort = self.interpret_statement(stmt, local_vars)\n                if abort:\n                    break\n            return res",
        "begin_line": 251,
        "end_line": 257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.8470416249903824e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.drbonanza.DRBonanzaIE._real_extract#46",
        "src_path": "youtube_dl/extractor/drbonanza.py",
        "class_name": "youtube_dl.extractor.drbonanza.DRBonanzaIE",
        "signature": "youtube_dl.extractor.drbonanza.DRBonanzaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url_id = self._match_id(url)\n        webpage = self._download_webpage(url, url_id)\n\n        if url_id:\n            info = json.loads(self._html_search_regex(r'({.*?%s.*})' % url_id, webpage, 'json'))\n        else:\n            # Just fetch the first video on that page\n            info = json.loads(self._html_search_regex(r'bonanzaFunctions.newPlaylist\\(({.*})\\)', webpage, 'json'))\n\n        asset_id = str(info['AssetId'])\n        title = info['Title'].rstrip(' \\'\\\"-,.:;!?')\n        duration = int_or_none(info.get('Duration'), scale=1000)\n        # First published online. \"FirstPublished\" contains the date for original airing.\n        timestamp = parse_iso8601(\n            re.sub(r'\\.\\d+$', '', info['Created']))\n\n        def parse_filename_info(url):\n            match = re.search(r'/\\d+_(?P<width>\\d+)x(?P<height>\\d+)x(?P<bitrate>\\d+)K\\.(?P<ext>\\w+)$', url)\n            if match:\n                return {\n                    'width': int(match.group('width')),\n                    'height': int(match.group('height')),\n                    'vbr': int(match.group('bitrate')),\n                    'ext': match.group('ext')\n                }\n            match = re.search(r'/\\d+_(?P<bitrate>\\d+)K\\.(?P<ext>\\w+)$', url)\n            if match:\n                return {\n                    'vbr': int(match.group('bitrate')),\n                    'ext': match.group(2)\n                }\n            return {}\n\n        video_types = ['VideoHigh', 'VideoMid', 'VideoLow']\n        preferencemap = {\n            'VideoHigh': -1,\n            'VideoMid': -2,\n            'VideoLow': -3,\n            'Audio': -4,\n        }\n\n        formats = []\n        for file in info['Files']:\n            if info['Type'] == \"Video\":\n                if file['Type'] in video_types:\n                    format = parse_filename_info(file['Location'])\n                    format.update({\n                        'url': file['Location'],\n                        'format_id': file['Type'].replace('Video', ''),\n                        'preference': preferencemap.get(file['Type'], -10),\n                    })\n                    if format['url'].startswith('rtmp'):\n                        rtmp_url = format['url']\n                        format['rtmp_live'] = True  # --resume does not work\n                        if '/bonanza/' in rtmp_url:\n                            format['play_path'] = rtmp_url.split('/bonanza/')[1]\n                    formats.append(format)\n                elif file['Type'] == \"Thumb\":\n                    thumbnail = file['Location']\n            elif info['Type'] == \"Audio\":\n                if file['Type'] == \"Audio\":\n                    format = parse_filename_info(file['Location'])\n                    format.update({\n                        'url': file['Location'],\n                        'format_id': file['Type'],\n                        'vcodec': 'none',\n                    })\n                    formats.append(format)\n                elif file['Type'] == \"Thumb\":\n                    thumbnail = file['Location']\n\n        description = '%s\\n%s\\n%s\\n' % (\n            info['Description'], info['Actors'], info['Colophon'])\n\n        self._sort_formats(formats)\n\n        display_id = re.sub(r'[^\\w\\d-]', '', re.sub(r' ', '-', title.lower())) + '-' + asset_id\n        display_id = re.sub(r'-+', '-', display_id)\n\n        return {\n            'id': asset_id,\n            'display_id': display_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n        }",
        "begin_line": 46,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.screencastomatic.ScreencastOMaticIE._real_extract#26",
        "src_path": "youtube_dl/extractor/screencastomatic.py",
        "class_name": "youtube_dl.extractor.screencastomatic.ScreencastOMaticIE",
        "signature": "youtube_dl.extractor.screencastomatic.ScreencastOMaticIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        setup_js = self._search_regex(\n            r\"(?s)jwplayer\\('mp4Player'\\).setup\\((\\{.*?\\})\\);\",\n            webpage, 'setup code')\n        data = self._parse_json(setup_js, video_id, transform_source=js_to_json)\n        try:\n            video_data = next(\n                m for m in data['modes'] if m.get('type') == 'html5')\n        except StopIteration:\n            raise ExtractorError('Could not find any video entries!')\n        video_url = compat_urlparse.urljoin(url, video_data['config']['file'])\n        thumbnail = data.get('image')\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'url': video_url,\n            'ext': 'mp4',\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 26,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kontrtube.KontrTubeIE._real_extract#32",
        "src_path": "youtube_dl/extractor/kontrtube.py",
        "class_name": "youtube_dl.extractor.kontrtube.KontrTubeIE",
        "signature": "youtube_dl.extractor.kontrtube.KontrTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(\n            url, display_id, 'Downloading page')\n\n        video_url = self._search_regex(\n            r\"video_url\\s*:\\s*'(.+?)/?',\", webpage, 'video URL')\n        thumbnail = self._search_regex(\n            r\"preview_url\\s*:\\s*'(.+?)/?',\", webpage, 'thumbnail', fatal=False)\n        title = self._html_search_regex(\n            r'(?s)<h2>(.+?)</h2>', webpage, 'title')\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n\n        duration = self._search_regex(\n            r'\u0414\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c: <em>([^<]+)</em>', webpage, 'duration', fatal=False)\n        if duration:\n            duration = parse_duration(duration.replace('\u043c\u0438\u043d', 'min').replace('\u0441\u0435\u043a', 'sec'))\n\n        view_count = self._search_regex(\n            r'\u041f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u043e\u0432: <em>([^<]+)</em>',\n            webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = int_or_none(view_count.replace(' ', ''))\n\n        comment_count = int_or_none(self._search_regex(\n            r'\u041a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438 \\((\\d+)\\)<', webpage, ' comment count', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'view_count': int_or_none(view_count),\n            'comment_count': int_or_none(comment_count),\n        }",
        "begin_line": 32,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mooshare.MooshareIE._real_extract#46",
        "src_path": "youtube_dl/extractor/mooshare.py",
        "class_name": "youtube_dl.extractor.mooshare.MooshareIE",
        "signature": "youtube_dl.extractor.mooshare.MooshareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        if re.search(r'>Video Not Found or Deleted<', page) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        hash_key = self._html_search_regex(r'<input type=\"hidden\" name=\"hash\" value=\"([^\"]+)\">', page, 'hash')\n        title = self._html_search_regex(r'(?m)<div class=\"blockTitle\">\\s*<h2>Watch ([^<]+)</h2>', page, 'title')\n\n        download_form = {\n            'op': 'download1',\n            'id': video_id,\n            'hash': hash_key,\n        }\n\n        request = compat_urllib_request.Request(\n            'http://mooshare.biz/%s' % video_id, compat_urllib_parse.urlencode(download_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n\n        self._sleep(5, video_id)\n\n        video_page = self._download_webpage(request, video_id, 'Downloading video page')\n\n        thumbnail = self._html_search_regex(r'image:\\s*\"([^\"]+)\",', video_page, 'thumbnail', fatal=False)\n        duration_str = self._html_search_regex(r'duration:\\s*\"(\\d+)\",', video_page, 'duration', fatal=False)\n        duration = int(duration_str) if duration_str is not None else None\n\n        formats = []\n\n        # SD video\n        mobj = re.search(r'(?m)file:\\s*\"(?P<url>[^\"]+)\",\\s*provider:', video_page)\n        if mobj is not None:\n            formats.append({\n                'url': mobj.group('url'),\n                'format_id': 'sd',\n                'format': 'SD',\n            })\n\n        # HD video\n        mobj = re.search(r'\\'hd-2\\': { file: \\'(?P<url>[^\\']+)\\' },', video_page)\n        if mobj is not None:\n            formats.append({\n                'url': mobj.group('url'),\n                'format_id': 'hd',\n                'format': 'HD',\n            })\n\n        # rtmp video\n        mobj = re.search(r'(?m)file: \"(?P<playpath>[^\"]+)\",\\s*streamer: \"(?P<rtmpurl>rtmp://[^\"]+)\",', video_page)\n        if mobj is not None:\n            formats.append({\n                'url': mobj.group('rtmpurl'),\n                'play_path': mobj.group('playpath'),\n                'rtmp_live': False,\n                'ext': 'mp4',\n                'format_id': 'rtmp',\n                'format': 'HD',\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 46,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.srmediathek.SRMediathekIE._real_extract#25",
        "src_path": "youtube_dl/extractor/srmediathek.py",
        "class_name": "youtube_dl.extractor.srmediathek.SRMediathekIE",
        "signature": "youtube_dl.extractor.srmediathek.SRMediathekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        murls = json.loads(js_to_json(self._search_regex(\n            r'var mediaURLs\\s*=\\s*(.*?);\\n', webpage, 'video URLs')))\n        formats = [{'url': murl} for murl in murls]\n        self._sort_formats(formats)\n\n        title = json.loads(js_to_json(self._search_regex(\n            r'var mediaTitles\\s*=\\s*(.*?);\\n', webpage, 'title')))[0]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 25,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.appleconnect.AppleConnectIE._real_extract#27",
        "src_path": "youtube_dl/extractor/appleconnect.py",
        "class_name": "youtube_dl.extractor.appleconnect.AppleConnectIE",
        "signature": "youtube_dl.extractor.appleconnect.AppleConnectIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        try:\n            video_json = self._html_search_regex(\n                r'class=\"auc-video-data\">(\\{.*?\\})', webpage, 'json')\n        except ExtractorError:\n            raise ExtractorError('This post doesn\\'t contain a video', expected=True)\n\n        video_data = self._parse_json(video_json, video_id)\n        timestamp = str_to_int(self._html_search_regex(r'data-timestamp=\"(\\d+)\"', webpage, 'timestamp'))\n        like_count = str_to_int(self._html_search_regex(r'(\\d+) Loves', webpage, 'like count'))\n\n        return {\n            'id': video_id,\n            'url': video_data['sslSrc'],\n            'title': video_data['title'],\n            'description': video_data['description'],\n            'uploader': video_data['artistName'],\n            'thumbnail': video_data['artworkUrl'],\n            'timestamp': timestamp,\n            'like_count': like_count,\n        }",
        "begin_line": 27,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tube8.Tube8IE._real_extract#40",
        "src_path": "youtube_dl/extractor/tube8.py",
        "class_name": "youtube_dl.extractor.tube8.Tube8IE",
        "signature": "youtube_dl.extractor.tube8.Tube8IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, display_id)\n\n        flashvars = json.loads(self._html_search_regex(\n            r'flashvars\\s*=\\s*({.+?});\\r?\\n', webpage, 'flashvars'))\n\n        video_url = flashvars['video_url']\n        if flashvars.get('encrypted') is True:\n            video_url = aes_decrypt_text(video_url, flashvars['video_title'], 32).decode('utf-8')\n        path = compat_urllib_parse_urlparse(video_url).path\n        format_id = '-'.join(path.split('/')[4].split('_')[:2])\n\n        thumbnail = flashvars.get('image_url')\n\n        title = self._html_search_regex(\n            r'videoTitle\\s*=\\s*\"([^\"]+)', webpage, 'title')\n        description = self._html_search_regex(\n            r'>Description:</strong>\\s*(.+?)\\s*<', webpage, 'description', fatal=False)\n        uploader = self._html_search_regex(\n            r'<span class=\"username\">\\s*(.+?)\\s*<',\n            webpage, 'uploader', fatal=False)\n\n        like_count = int_or_none(self._html_search_regex(\n            r'rupVar\\s*=\\s*\"(\\d+)\"', webpage, 'like count', fatal=False))\n        dislike_count = int_or_none(self._html_search_regex(\n            r'rdownVar\\s*=\\s*\"(\\d+)\"', webpage, 'dislike count', fatal=False))\n        view_count = self._html_search_regex(\n            r'<strong>Views: </strong>([\\d,\\.]+)\\s*</li>', webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = str_to_int(view_count)\n        comment_count = self._html_search_regex(\n            r'<span id=\"allCommentsCount\">(\\d+)</span>', webpage, 'comment count', fatal=False)\n        if comment_count:\n            comment_count = str_to_int(comment_count)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'format_id': format_id,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'age_limit': 18,\n        }",
        "begin_line": 40,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soundgasm.SoundgasmIE._real_extract#23",
        "src_path": "youtube_dl/extractor/soundgasm.py",
        "class_name": "youtube_dl.extractor.soundgasm.SoundgasmIE",
        "signature": "youtube_dl.extractor.soundgasm.SoundgasmIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('title')\n        audio_title = mobj.group('user') + '_' + mobj.group('title')\n        webpage = self._download_webpage(url, display_id)\n        audio_url = self._html_search_regex(\n            r'(?s)m4a\\:\\s\"([^\"]+)\"', webpage, 'audio URL')\n        audio_id = re.split('\\/|\\.', audio_url)[-2]\n        description = self._html_search_regex(\n            r'(?s)<li>Description:\\s(.*?)<\\/li>', webpage, 'description',\n            fatal=False)\n\n        return {\n            'id': audio_id,\n            'display_id': display_id,\n            'url': audio_url,\n            'title': audio_title,\n            'description': description\n        }",
        "begin_line": 23,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soundgasm.SoundgasmProfileIE._real_extract#55",
        "src_path": "youtube_dl/extractor/soundgasm.py",
        "class_name": "youtube_dl.extractor.soundgasm.SoundgasmProfileIE",
        "signature": "youtube_dl.extractor.soundgasm.SoundgasmProfileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        profile_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, profile_id)\n\n        entries = [\n            self.url_result(audio_url, 'Soundgasm')\n            for audio_url in re.findall(r'href=\"([^\"]+/u/%s/[^\"]+)' % profile_id, webpage)]\n\n        return self.playlist_result(entries, profile_id)",
        "begin_line": 55,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviIE._extract_description#57",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviIE",
        "signature": "youtube_dl.extractor.ivi.IviIE._extract_description(self, html)",
        "snippet": "    def _extract_description(self, html):\n        m = re.search(r'<meta name=\"description\" content=\"(?P<description>[^\"]+)\"/>', html)\n        return m.group('description') if m is not None else None",
        "begin_line": 57,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviIE._extract_comment_count#61",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviIE",
        "signature": "youtube_dl.extractor.ivi.IviIE._extract_comment_count(self, html)",
        "snippet": "    def _extract_comment_count(self, html):\n        m = re.search('(?s)<a href=\"#\" id=\"view-comments\" class=\"action-button dim gradient\">\\s*\u041a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438:\\s*(?P<commentcount>\\d+)\\s*</a>', html)\n        return int(m.group('commentcount')) if m is not None else 0",
        "begin_line": 61,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviIE._real_extract#65",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviIE",
        "signature": "youtube_dl.extractor.ivi.IviIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        api_url = 'http://api.digitalaccess.ru/api/json/'\n\n        data = {\n            'method': 'da.content.get',\n            'params': [\n                video_id, {\n                    'site': 's183',\n                    'referrer': 'http://www.ivi.ru/watch/%s' % video_id,\n                    'contentid': video_id\n                }\n            ]\n        }\n\n        request = compat_urllib_request.Request(api_url, json.dumps(data))\n\n        video_json_page = self._download_webpage(\n            request, video_id, 'Downloading video JSON')\n        video_json = json.loads(video_json_page)\n\n        if 'error' in video_json:\n            error = video_json['error']\n            if error['origin'] == 'NoRedisValidData':\n                raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n            raise ExtractorError(\n                'Unable to download video %s: %s' % (video_id, error['message']),\n                expected=True)\n\n        result = video_json['result']\n\n        formats = [{\n            'url': x['url'],\n            'format_id': x['content_format'],\n            'preference': self._known_formats.index(x['content_format']),\n        } for x in result['files'] if x['content_format'] in self._known_formats]\n\n        self._sort_formats(formats)\n\n        if not formats:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        duration = result['duration']\n        compilation = result['compilation']\n        title = result['title']\n\n        title = '%s - %s' % (compilation, title) if compilation is not None else title\n\n        previews = result['preview']\n        previews.sort(key=lambda fmt: self._known_thumbnails.index(fmt['content_format']))\n        thumbnail = previews[-1]['url'] if len(previews) > 0 else None\n\n        video_page = self._download_webpage(url, video_id, 'Downloading video page')\n        description = self._extract_description(video_page)\n        comment_count = self._extract_comment_count(video_page)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n            'comment_count': comment_count,\n            'formats': formats,\n        }",
        "begin_line": 65,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviCompilationIE._extract_entries#153",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviCompilationIE",
        "signature": "youtube_dl.extractor.ivi.IviCompilationIE._extract_entries(self, html, compilation_id)",
        "snippet": "    def _extract_entries(self, html, compilation_id):\n        return [self.url_result('http://www.ivi.ru/watch/%s/%s' % (compilation_id, serie), 'Ivi')\n                for serie in re.findall(r'<strong><a href=\"/watch/%s/(\\d+)\">(?:[^<]+)</a></strong>' % compilation_id, html)]",
        "begin_line": 153,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviCompilationIE._real_extract#157",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviCompilationIE",
        "signature": "youtube_dl.extractor.ivi.IviCompilationIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        compilation_id = mobj.group('compilationid')\n        season_id = mobj.group('seasonid')\n\n        if season_id is not None:  # Season link\n            season_page = self._download_webpage(url, compilation_id, 'Downloading season %s web page' % season_id)\n            playlist_id = '%s/season%s' % (compilation_id, season_id)\n            playlist_title = self._html_search_meta('title', season_page, 'title')\n            entries = self._extract_entries(season_page, compilation_id)\n        else:  # Compilation link\n            compilation_page = self._download_webpage(url, compilation_id, 'Downloading compilation web page')\n            playlist_id = compilation_id\n            playlist_title = self._html_search_meta('title', compilation_page, 'title')\n            seasons = re.findall(r'<a href=\"/watch/%s/season(\\d+)\">[^<]+</a>' % compilation_id, compilation_page)\n            if len(seasons) == 0:  # No seasons in this compilation\n                entries = self._extract_entries(compilation_page, compilation_id)\n            else:\n                entries = []\n                for season_id in seasons:\n                    season_page = self._download_webpage(\n                        'http://www.ivi.ru/watch/%s/season%s' % (compilation_id, season_id),\n                        compilation_id, 'Downloading season %s web page' % season_id)\n                    entries.extend(self._extract_entries(season_page, compilation_id))\n\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 157,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ynet.YnetIE._real_extract#33",
        "src_path": "youtube_dl/extractor/ynet.py",
        "class_name": "youtube_dl.extractor.ynet.YnetIE",
        "signature": "youtube_dl.extractor.ynet.YnetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        content = compat_urllib_parse_unquote_plus(self._og_search_video_url(webpage))\n        config = json.loads(self._search_regex(r'config=({.+?})$', content, 'video config'))\n        f4m_url = config['clip']['url']\n        title = self._og_search_title(webpage)\n        m = re.search(r'ynet - HOT -- ([\"\\']+)(?P<title>.+?)\\1', title)\n        if m:\n            title = m.group('title')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': self._extract_f4m_formats(f4m_url, video_id),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 33,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVIE._real_extract#31",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        player = self._parse_json(\n            self._search_regex(r'html5player:\\s*({.+?})\\s*\\n', webpage, 'player'),\n            video_id)\n\n        title = player.get('title') or self._search_regex(\n            r'data-title=\"([^\"]+)\"', webpage, 'title')\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        upload_date = unified_strdate(\n            self._html_search_meta('datepublished', webpage, 'upload date'))\n\n        duration = parse_duration(\n            self._html_search_meta('duration', webpage, 'duration') or\n            self._search_regex(\n                r'Runtime:\\s*(\\d{2}:\\d{2}:\\d{2})',\n                webpage, 'duration', fatal=False))\n\n        view_count = str_to_int(self._search_regex(\n            r'<div class=\"views\">\\s*Views?:\\s*([\\d,.]+)\\s*</div>',\n            webpage, 'view count'))\n\n        formats = [{\n            'url': source['src'],\n            'format_id': source.get('quality') or source['src'].split('-')[-1].split('.')[0] or None,\n            'tbr': source.get('bitrate'),\n        } for source in player['sources']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVVideoIE._real_extract#92",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVVideoIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        player_params = self._parse_json(self._search_regex(\n            r'var\\s+bridge\\s*=\\s*([^;]+);', webpage, 'player parameters'),\n            video_id)\n\n        formats = [{\n            'url': source['src'],\n            'width': source.get('width'),\n            'height': source.get('height'),\n            'tbr': source.get('bitrate'),\n        } for source in player_params['sources']]\n\n        # For both metadata and downloaded files the duration varies among\n        # formats. I just pick the max one\n        duration = max(filter(None, [\n            float_or_none(source.get('duration'), scale=1000)\n            for source in player_params['sources']]))\n\n        subtitles = {}\n        for translation in player_params.get('translations', []):\n            lang_id = translation.get('language_w3c') or ISO639Utils.long2short(translation['language_medium'])\n            if lang_id not in subtitles:\n                subtitles[lang_id] = []\n            subtitles[lang_id].append({\n                'url': translation['vttPath'],\n                'ext': 'vtt',\n            })\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': player_params['title'],\n            'description': self._og_search_description(webpage),\n            'duration': duration,\n            'subtitles': subtitles,\n        }",
        "begin_line": 92,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sztvhu.SztvHuIE._real_extract#20",
        "src_path": "youtube_dl/extractor/sztvhu.py",
        "class_name": "youtube_dl.extractor.sztvhu.SztvHuIE",
        "signature": "youtube_dl.extractor.sztvhu.SztvHuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video_file = self._search_regex(\n            r'file: \"...:(.*?)\",', webpage, 'video file')\n        title = self._html_search_regex(\n            r'<meta name=\"title\" content=\"([^\"]*?) - [^-]*? - [^-]*?\"',\n            webpage, 'video title')\n        description = self._html_search_regex(\n            r'<meta name=\"description\" content=\"([^\"]*)\"/>',\n            webpage, 'video description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        video_url = 'http://media.sztv.hu/vod/' + video_file\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 20,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nba.NBAIE._real_extract#39",
        "src_path": "youtube_dl/extractor/nba.py",
        "class_name": "youtube_dl.extractor.nba.NBAIE",
        "signature": "youtube_dl.extractor.nba.NBAIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = 'http://ht-mobile.cdn.turner.com/nba/big' + video_id + '_nba_1280x720.mp4'\n\n        shortened_video_id = video_id.rpartition('/')[2]\n        title = remove_end(\n            self._og_search_title(webpage, default=shortened_video_id), ' : NBA.com')\n\n        description = self._og_search_description(webpage)\n        duration_str = self._html_search_meta(\n            'duration', webpage, 'duration', default=None)\n        if not duration_str:\n            duration_str = self._html_search_regex(\n                r'Duration:</b>\\s*(\\d+:\\d+)', webpage, 'duration', fatal=False)\n        duration = parse_duration(duration_str)\n\n        return {\n            'id': shortened_video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'duration': duration,\n        }",
        "begin_line": 39,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.howstuffworks.HowStuffWorksIE._real_extract#55",
        "src_path": "youtube_dl/extractor/howstuffworks.py",
        "class_name": "youtube_dl.extractor.howstuffworks.HowStuffWorksIE",
        "signature": "youtube_dl.extractor.howstuffworks.HowStuffWorksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        clip_js = self._search_regex(\n            r'(?s)var clip = ({.*?});', webpage, 'clip info')\n        clip_info = self._parse_json(\n            clip_js, display_id, transform_source=js_to_json)\n\n        video_id = clip_info['content_id']\n        formats = []\n        m3u8_url = clip_info.get('m3u8')\n        if m3u8_url:\n            formats += self._extract_m3u8_formats(m3u8_url, video_id, 'mp4')\n        for video in clip_info.get('mp4', []):\n            formats.append({\n                'url': video['src'],\n                'format_id': video['bitrate'],\n                'vbr': int(video['bitrate'].rstrip('k')),\n            })\n\n        if not formats:\n            smil = self._download_xml(\n                'http://services.media.howstuffworks.com/videos/%s/smil-service.smil' % video_id,\n                video_id, 'Downloading video SMIL')\n\n            http_base = find_xpath_attr(\n                smil,\n                './{0}head/{0}meta'.format('{http://www.w3.org/2001/SMIL20/Language}'),\n                'name',\n                'httpBase').get('content')\n\n            URL_SUFFIX = '?v=2.11.3&fp=LNX 11,2,202,356&r=A&g=A'\n\n            for video in smil.findall(\n                    './{0}body/{0}switch/{0}video'.format('{http://www.w3.org/2001/SMIL20/Language}')):\n                vbr = int_or_none(video.attrib['system-bitrate'], scale=1000)\n                formats.append({\n                    'url': '%s/%s%s' % (http_base, video.attrib['src'], URL_SUFFIX),\n                    'format_id': '%dk' % vbr,\n                    'vbr': vbr,\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': '%s' % video_id,\n            'display_id': display_id,\n            'title': unescapeHTML(clip_info['clip_title']),\n            'description': unescapeHTML(clip_info.get('caption')),\n            'thumbnail': clip_info.get('video_still_url'),\n            'duration': clip_info.get('duration'),\n            'formats': formats,\n        }",
        "begin_line": 55,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xxxymovies.XXXYMoviesIE._real_extract#31",
        "src_path": "youtube_dl/extractor/xxxymovies.py",
        "class_name": "youtube_dl.extractor.xxxymovies.XXXYMoviesIE",
        "signature": "youtube_dl.extractor.xxxymovies.XXXYMoviesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._search_regex(\n            r\"video_url\\s*:\\s*'([^']+)'\", webpage, 'video URL')\n\n        title = self._html_search_regex(\n            [r'<div class=\"block_header\">\\s*<h1>([^<]+)</h1>',\n             r'<title>(.*?)\\s*-\\s*XXXYMovies\\.com</title>'],\n            webpage, 'title')\n\n        thumbnail = self._search_regex(\n            r\"preview_url\\s*:\\s*'([^']+)'\",\n            webpage, 'thumbnail', fatal=False)\n\n        categories = self._html_search_meta(\n            'keywords', webpage, 'categories', default='').split(',')\n\n        duration = parse_duration(self._search_regex(\n            r'<span>Duration:</span>\\s*(\\d+:\\d+)',\n            webpage, 'duration', fatal=False))\n\n        view_count = int_or_none(self._html_search_regex(\n            r'<div class=\"video_views\">\\s*(\\d+)',\n            webpage, 'view count', fatal=False))\n        like_count = int_or_none(self._search_regex(\n            r'>\\s*Likes? <b>\\((\\d+)\\)',\n            webpage, 'like count', fatal=False))\n        dislike_count = int_or_none(self._search_regex(\n            r'>\\s*Dislike <b>\\((\\d+)\\)</b>',\n            webpage, 'dislike count', fatal=False))\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'age_limit': age_limit,\n        }",
        "begin_line": 31,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mofosex.MofosexIE._real_extract#27",
        "src_path": "youtube_dl/extractor/mofosex.py",
        "class_name": "youtube_dl.extractor.mofosex.MofosexIE",
        "signature": "youtube_dl.extractor.mofosex.MofosexIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(r'<h1>(.+?)<', webpage, 'title')\n        video_url = compat_urllib_parse_unquote(self._html_search_regex(r'flashvars.video_url = \\'([^\\']+)', webpage, 'video_url'))\n        path = compat_urllib_parse_urlparse(video_url).path\n        extension = os.path.splitext(path)[1][1:]\n        format = path.split('/')[5].split('_')[:2]\n        format = \"-\".join(format)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'url': video_url,\n            'ext': extension,\n            'format': format,\n            'format_id': format,\n            'age_limit': age_limit,\n        }",
        "begin_line": 27,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._extract_info#110",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._extract_info(self, webpage)",
        "snippet": "    def _extract_info(self, webpage):\n        info_json = self._search_regex(r'q\\(\"\\w+.init\",({.+})\\)</script>',\n                                       webpage, 'info json')\n        return json.loads(info_json)",
        "begin_line": 110,
        "end_line": 113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._real_extract#115",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url, re.VERBOSE)\n        if m.group('type').startswith('embed'):\n            desktop_url = m.group('proto') + 'www' + m.group('urlmain')\n            return self.url_result(desktop_url, 'TED')\n        name = m.group('name')\n        if m.group('type_talk'):\n            return self._talk_info(url, name)\n        elif m.group('type_watch'):\n            return self._watch_info(url, name)\n        else:\n            return self._playlist_videos_info(url, name)",
        "begin_line": 115,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._playlist_videos_info#128",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._playlist_videos_info(self, url, name)",
        "snippet": "    def _playlist_videos_info(self, url, name):\n        '''Returns the videos of the playlist'''\n\n        webpage = self._download_webpage(url, name,\n                                         'Downloading playlist webpage')\n        info = self._extract_info(webpage)\n        playlist_info = info['playlist']\n\n        playlist_entries = [\n            self.url_result('http://www.ted.com/talks/' + talk['slug'], self.ie_key())\n            for talk in info['talks']\n        ]\n        return self.playlist_result(\n            playlist_entries,\n            playlist_id=compat_str(playlist_info['id']),\n            playlist_title=playlist_info['title'])",
        "begin_line": 128,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._talk_info#145",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._talk_info(self, url, video_name)",
        "snippet": "    def _talk_info(self, url, video_name):\n        webpage = self._download_webpage(url, video_name)\n        self.report_extraction(video_name)\n\n        talk_info = self._extract_info(webpage)['talks'][0]\n\n        external = talk_info.get('external')\n        if external:\n            service = external['service']\n            self.to_screen('Found video from %s' % service)\n            ext_url = None\n            if service.lower() == 'youtube':\n                ext_url = external.get('code')\n            return {\n                '_type': 'url',\n                'url': ext_url or external['uri'],\n            }\n\n        formats = [{\n            'url': format_url,\n            'format_id': format_id,\n            'format': format_id,\n        } for (format_id, format_url) in talk_info['nativeDownloads'].items() if format_url is not None]\n        if formats:\n            for f in formats:\n                finfo = self._NATIVE_FORMATS.get(f['format_id'])\n                if finfo:\n                    f.update(finfo)\n\n        for format_id, resources in talk_info['resources'].items():\n            if format_id == 'h264':\n                for resource in resources:\n                    bitrate = int_or_none(resource.get('bitrate'))\n                    formats.append({\n                        'url': resource['file'],\n                        'format_id': '%s-%sk' % (format_id, bitrate),\n                        'tbr': bitrate,\n                    })\n            elif format_id == 'rtmp':\n                streamer = talk_info.get('streamer')\n                if not streamer:\n                    continue\n                for resource in resources:\n                    formats.append({\n                        'format_id': '%s-%s' % (format_id, resource.get('name')),\n                        'url': streamer,\n                        'play_path': resource['file'],\n                        'ext': 'flv',\n                        'width': int_or_none(resource.get('width')),\n                        'height': int_or_none(resource.get('height')),\n                        'tbr': int_or_none(resource.get('bitrate')),\n                    })\n            elif format_id == 'hls':\n                hls_formats = self._extract_m3u8_formats(\n                    resources.get('stream'), video_name, 'mp4', m3u8_id=format_id)\n                for f in hls_formats:\n                    if f.get('format_id') == 'hls-meta':\n                        continue\n                    if not f.get('height'):\n                        f['vcodec'] = 'none'\n                    else:\n                        f['acodec'] = 'none'\n                formats.extend(hls_formats)\n\n        audio_download = talk_info.get('audioDownload')\n        if audio_download:\n            formats.append({\n                'url': audio_download,\n                'format_id': 'audio',\n                'vcodec': 'none',\n                'preference': -0.5,\n            })\n\n        self._sort_formats(formats)\n\n        video_id = compat_str(talk_info['id'])\n\n        thumbnail = talk_info['thumb']\n        if not thumbnail.startswith('http'):\n            thumbnail = 'http://' + thumbnail\n        return {\n            'id': video_id,\n            'title': talk_info['title'].strip(),\n            'uploader': talk_info['speaker'],\n            'thumbnail': thumbnail,\n            'description': self._og_search_description(webpage),\n            'subtitles': self._get_subtitles(video_id, talk_info),\n            'formats': formats,\n            'duration': talk_info.get('duration'),\n        }",
        "begin_line": 145,
        "end_line": 234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._get_subtitles#236",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._get_subtitles(self, video_id, talk_info)",
        "snippet": "    def _get_subtitles(self, video_id, talk_info):\n        languages = [lang['languageCode'] for lang in talk_info.get('languages', [])]\n        if languages:\n            sub_lang_list = {}\n            for l in languages:\n                sub_lang_list[l] = [\n                    {\n                        'url': 'http://www.ted.com/talks/subtitles/id/%s/lang/%s/format/%s' % (video_id, l, ext),\n                        'ext': ext,\n                    }\n                    for ext in ['ted', 'srt']\n                ]\n            return sub_lang_list\n        else:\n            return {}",
        "begin_line": 236,
        "end_line": 250,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._watch_info#252",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._watch_info(self, url, name)",
        "snippet": "    def _watch_info(self, url, name):\n        webpage = self._download_webpage(url, name)\n\n        config_json = self._html_search_regex(\n            r'\"pages\\.jwplayer\"\\s*,\\s*({.+?})\\s*\\)\\s*</script>',\n            webpage, 'config')\n        config = json.loads(config_json)['config']\n        video_url = config['video']['url']\n        thumbnail = config.get('image', {}).get('url')\n\n        title = self._html_search_regex(\n            r\"(?s)<h1(?:\\s+class='[^']+')?>(.+?)</h1>\", webpage, 'title')\n        description = self._html_search_regex(\n            [\n                r'(?s)<h4 class=\"[^\"]+\" id=\"h3--about-this-talk\">.*?</h4>(.*?)</div>',\n                r'(?s)<p><strong>About this talk:</strong>\\s+(.*?)</p>',\n            ],\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': name,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 252,
        "end_line": 277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gamersyde.GamersydeIE._real_extract#27",
        "src_path": "youtube_dl/extractor/gamersyde.py",
        "class_name": "youtube_dl.extractor.gamersyde.GamersydeIE",
        "signature": "youtube_dl.extractor.gamersyde.GamersydeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        playlist = self._parse_json(\n            self._search_regex(\n                r'(?s)playlist: \\[({.+?})\\]\\s*}\\);', webpage, 'files'),\n            display_id, transform_source=js_to_json)\n\n        formats = []\n        for source in playlist['sources']:\n            video_url = source.get('file')\n            if not video_url:\n                continue\n            format_id = source.get('label')\n            f = {\n                'url': video_url,\n                'format_id': format_id,\n            }\n            m = re.search(r'^(?P<height>\\d+)[pP](?P<fps>\\d+)fps', format_id)\n            if m:\n                f.update({\n                    'height': int(m.group('height')),\n                    'fps': int(m.group('fps')),\n                })\n            formats.append(f)\n        self._sort_formats(formats)\n\n        title = remove_start(playlist['title'], '%s - ' % video_id)\n        thumbnail = playlist.get('image')\n        duration = parse_duration(self._search_regex(\n            r'Length:</label>([^<]+)<', webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dcn.DCNIE._real_extract#36",
        "src_path": "youtube_dl/extractor/dcn.py",
        "class_name": "youtube_dl.extractor.dcn.DCNIE",
        "signature": "youtube_dl.extractor.dcn.DCNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        request = compat_urllib_request.Request(\n            'http://admin.mangomolo.com/analytics/index.php/plus/video?id=%s' % video_id,\n            headers={'Origin': 'http://www.dcndigital.ae'})\n\n        video = self._download_json(request, video_id)\n        title = video.get('title_en') or video['title_ar']\n\n        webpage = self._download_webpage(\n            'http://admin.mangomolo.com/analytics/index.php/customers/embed/video?' +\n            compat_urllib_parse.urlencode({\n                'id': video['id'],\n                'user_id': video['user_id'],\n                'signature': video['signature'],\n                'countries': 'Q0M=',\n                'filter': 'DENY',\n            }), video_id)\n\n        m3u8_url = self._html_search_regex(r'file:\\s*\"([^\"]+)', webpage, 'm3u8 url')\n        formats = self._extract_m3u8_formats(\n            m3u8_url, video_id, 'mp4', entry_protocol='m3u8_native', m3u8_id='hls')\n\n        rtsp_url = self._search_regex(\n            r'<a[^>]+href=\"(rtsp://[^\"]+)\"', webpage, 'rtsp url', fatal=False)\n        if rtsp_url:\n            formats.append({\n                'url': rtsp_url,\n                'format_id': 'rtsp',\n            })\n\n        self._sort_formats(formats)\n\n        img = video.get('img')\n        thumbnail = 'http://admin.mangomolo.com/analytics/%s' % img if img else None\n        duration = int_or_none(video.get('duration'))\n        description = video.get('description_en') or video.get('description_ar')\n        timestamp = parse_iso8601(video.get('create_time') or video.get('update_time'), ' ')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n        }",
        "begin_line": 36,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.philharmoniedeparis.PhilharmonieDeParisIE._real_extract#38",
        "src_path": "youtube_dl/extractor/philharmoniedeparis.py",
        "class_name": "youtube_dl.extractor.philharmoniedeparis.PhilharmonieDeParisIE",
        "signature": "youtube_dl.extractor.philharmoniedeparis.PhilharmonieDeParisIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        concert = self._download_xml(\n            'http://live.philharmoniedeparis.fr/misc/Playlist.ashx?id=%s' % video_id,\n            video_id).find('./concert')\n\n        formats = []\n        info_dict = {\n            'id': video_id,\n            'title': xpath_text(concert, './titre', 'title', fatal=True),\n            'formats': formats,\n        }\n\n        fichiers = concert.find('./fichiers')\n        stream = fichiers.attrib['serveurstream']\n        for fichier in fichiers.findall('./fichier'):\n            info_dict['duration'] = float_or_none(fichier.get('timecodefin'))\n            for quality, (format_id, suffix) in enumerate([('lq', ''), ('hq', '_hd')]):\n                format_url = fichier.get('url%s' % suffix)\n                if not format_url:\n                    continue\n                formats.append({\n                    'url': stream,\n                    'play_path': format_url,\n                    'ext': 'flv',\n                    'format_id': format_id,\n                    'width': int_or_none(concert.get('largeur%s' % suffix)),\n                    'height': int_or_none(concert.get('hauteur%s' % suffix)),\n                    'quality': quality,\n                })\n        self._sort_formats(formats)\n\n        date, hour = concert.get('date'), concert.get('heure')\n        if date and hour:\n            info_dict['timestamp'] = parse_iso8601(\n                '%s-%s-%sT%s:00' % (date[0:4], date[4:6], date[6:8], hour))\n        elif date:\n            info_dict['upload_date'] = date\n\n        return info_dict",
        "begin_line": 38,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cspan.CSpanIE._real_extract#59",
        "src_path": "youtube_dl/extractor/cspan.py",
        "class_name": "youtube_dl.extractor.cspan.CSpanIE",
        "signature": "youtube_dl.extractor.cspan.CSpanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_id = mobj.group('id')\n        webpage = self._download_webpage(url, page_id)\n        video_id = self._search_regex(r'progid=\\'?([0-9]+)\\'?>', webpage, 'video id')\n\n        description = self._html_search_regex(\n            [\n                # The full description\n                r'<div class=\\'expandable\\'>(.*?)<a href=\\'#\\'',\n                # If the description is small enough the other div is not\n                # present, otherwise this is a stripped version\n                r'<p class=\\'initial\\'>(.*?)</p>'\n            ],\n            webpage, 'description', flags=re.DOTALL, default=None)\n\n        info_url = 'http://c-spanvideo.org/videoLibrary/assets/player/ajax-player.php?os=android&html5=program&id=' + video_id\n        data = self._download_json(info_url, video_id)\n\n        doc = self._download_xml(\n            'http://www.c-span.org/common/services/flashXml.php?programid=' + video_id,\n            video_id)\n\n        title = find_xpath_attr(doc, './/string', 'name', 'title').text\n        thumbnail = find_xpath_attr(doc, './/string', 'name', 'poster').text\n\n        senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)\n        if senate_isvp_url:\n            surl = smuggle_url(senate_isvp_url, {'force_title': title})\n            return self.url_result(surl, 'SenateISVP', video_id, title)\n\n        files = data['video']['files']\n        try:\n            capfile = data['video']['capfile']['#text']\n        except KeyError:\n            capfile = None\n\n        entries = [{\n            'id': '%s_%d' % (video_id, partnum + 1),\n            'title': (\n                title if len(files) == 1 else\n                '%s part %d' % (title, partnum + 1)),\n            'url': unescapeHTML(f['path']['#text']),\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': int_or_none(f.get('length', {}).get('#text')),\n            'subtitles': {\n                'en': [{\n                    'url': capfile,\n                    'ext': determine_ext(capfile, 'dfxp')\n                }],\n            } if capfile else None,\n        } for partnum, f in enumerate(files)]\n\n        if len(entries) == 1:\n            entry = dict(entries[0])\n            entry['id'] = video_id\n            return entry\n        else:\n            return {\n                '_type': 'playlist',\n                'entries': entries,\n                'title': title,\n                'id': video_id,\n            }",
        "begin_line": 59,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.turbo.TurboIE._real_extract#31",
        "src_path": "youtube_dl/extractor/turbo.py",
        "class_name": "youtube_dl.extractor.turbo.TurboIE",
        "signature": "youtube_dl.extractor.turbo.TurboIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        playlist = self._download_xml(self._API_URL.format(video_id), video_id)\n        item = playlist.find('./channel/item')\n        if item is None:\n            raise ExtractorError('Playlist item was not found', expected=True)\n\n        title = xpath_text(item, './title', 'title')\n        duration = int_or_none(xpath_text(item, './durate', 'duration'))\n        thumbnail = xpath_text(item, './visuel_clip', 'thumbnail')\n        description = self._html_search_meta('description', webpage)\n\n        formats = []\n        get_quality = qualities(['3g', 'sd', 'hq'])\n        for child in item:\n            m = re.search(r'url_video_(?P<quality>.+)', child.tag)\n            if m:\n                quality = m.group('quality')\n                formats.append({\n                    'format_id': quality,\n                    'url': child.text,\n                    'quality': get_quality(quality),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'description': description,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.hark.HarkIE._real_extract#21",
        "src_path": "youtube_dl/extractor/hark.py",
        "class_name": "youtube_dl.extractor.hark.HarkIE",
        "signature": "youtube_dl.extractor.hark.HarkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        data = self._download_json(\n            'http://www.hark.com/clips/%s.json' % video_id, video_id)\n\n        return {\n            'id': video_id,\n            'url': data['url'],\n            'title': data['name'],\n            'description': data.get('description'),\n            'thumbnail': data.get('image_original'),\n            'duration': data.get('duration'),\n        }",
        "begin_line": 21,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.videodetective.VideoDetectiveIE._real_extract#22",
        "src_path": "youtube_dl/extractor/videodetective.py",
        "class_name": "youtube_dl.extractor.videodetective.VideoDetectiveIE",
        "signature": "youtube_dl.extractor.videodetective.VideoDetectiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        og_video = self._og_search_video_url(webpage)\n        query = compat_urlparse.urlparse(og_video).query\n        return self.url_result(InternetVideoArchiveIE._build_url(query), ie=InternetVideoArchiveIE.ie_key())",
        "begin_line": 22,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nova.NovaIE._real_extract#99",
        "src_path": "youtube_dl/extractor/nova.py",
        "class_name": "youtube_dl.extractor.nova.NovaIE",
        "signature": "youtube_dl.extractor.nova.NovaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n        site = mobj.group('site')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            [r\"(?:media|video_id)\\s*:\\s*'(\\d+)'\",\n             r'media=(\\d+)',\n             r'id=\"article_video_(\\d+)\"',\n             r'id=\"player_(\\d+)\"'],\n            webpage, 'video id')\n\n        config_url = self._search_regex(\n            r'src=\"(http://tn\\.nova\\.cz/bin/player/videojs/config\\.php\\?[^\"]+)\"',\n            webpage, 'config url', default=None)\n\n        if not config_url:\n            DEFAULT_SITE_ID = '23000'\n            SITES = {\n                'tvnoviny': DEFAULT_SITE_ID,\n                'novaplus': DEFAULT_SITE_ID,\n                'vymena': DEFAULT_SITE_ID,\n                'krasna': DEFAULT_SITE_ID,\n                'fanda': '30',\n                'tn': '30',\n                'doma': '30',\n            }\n\n            site_id = self._search_regex(\n                r'site=(\\d+)', webpage, 'site id', default=None) or SITES.get(site, DEFAULT_SITE_ID)\n\n            config_url = ('http://tn.nova.cz/bin/player/videojs/config.php?site=%s&media=%s&jsVar=vjsconfig'\n                          % (site_id, video_id))\n\n        config = self._download_json(\n            config_url, display_id,\n            'Downloading config JSON',\n            transform_source=lambda s: s[s.index('{'):s.rindex('}') + 1])\n\n        mediafile = config['mediafile']\n        video_url = mediafile['src']\n\n        m = re.search(r'^(?P<url>rtmpe?://[^/]+/(?P<app>[^/]+?))/&*(?P<playpath>.+)$', video_url)\n        if m:\n            formats = [{\n                'url': m.group('url'),\n                'app': m.group('app'),\n                'play_path': m.group('playpath'),\n                'player_path': 'http://tvnoviny.nova.cz/static/shared/app/videojs/video-js.swf',\n                'ext': 'flv',\n            }]\n        else:\n            formats = [{\n                'url': video_url,\n            }]\n        self._sort_formats(formats)\n\n        title = mediafile.get('meta', {}).get('title') or self._og_search_title(webpage)\n        description = clean_html(self._og_search_description(webpage, default=None))\n        thumbnail = config.get('poster')\n\n        if site == 'novaplus':\n            upload_date = unified_strdate(self._search_regex(\n                r'(\\d{1,2}-\\d{1,2}-\\d{4})$', display_id, 'upload date', default=None))\n        elif site == 'fanda':\n            upload_date = unified_strdate(self._search_regex(\n                r'<span class=\"date_time\">(\\d{1,2}\\.\\d{1,2}\\.\\d{4})', webpage, 'upload date', default=None))\n        else:\n            upload_date = None\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'upload_date': upload_date,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 99,
        "end_line": 179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPOBaseIE._get_token#16",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOBaseIE",
        "signature": "youtube_dl.extractor.npo.NPOBaseIE._get_token(self, video_id)",
        "snippet": "    def _get_token(self, video_id):\n        token_page = self._download_webpage(\n            'http://ida.omroep.nl/npoplayer/i.js',\n            video_id, note='Downloading token')\n        token = self._search_regex(\n            r'npoplayer\\.token = \"(.+?)\"', token_page, 'token')\n        # Decryption algorithm extracted from http://npoplayer.omroep.nl/csjs/npoplayer-min.js\n        token_l = list(token)\n        first = second = None\n        for i in range(5, len(token_l) - 4):\n            if token_l[i].isdigit():\n                if first is None:\n                    first = i\n                elif second is None:\n                    second = i\n        if first is None or second is None:\n            first = 12\n            second = 13\n\n        token_l[first], token_l[second] = token_l[second], token_l[first]\n\n        return ''.join(token_l)",
        "begin_line": 16,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPOIE._real_extract#143",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOIE",
        "signature": "youtube_dl.extractor.npo.NPOIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self._get_info(video_id)",
        "begin_line": 143,
        "end_line": 145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPOIE._get_info#147",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOIE",
        "signature": "youtube_dl.extractor.npo.NPOIE._get_info(self, video_id)",
        "snippet": "    def _get_info(self, video_id):\n        metadata = self._download_json(\n            'http://e.omroep.nl/metadata/%s' % video_id,\n            video_id,\n            # We have to remove the javascript callback\n            transform_source=strip_jsonp,\n        )\n\n        # For some videos actual video id (prid) is different (e.g. for\n        # http://www.omroepwnl.nl/video/fragment/vandaag-de-dag-verkiezingen__POMS_WNL_853698\n        # video id is POMS_WNL_853698 but prid is POW_00996502)\n        video_id = metadata.get('prid') or video_id\n\n        # titel is too generic in some cases so utilize aflevering_titel as well\n        # when available (e.g. http://tegenlicht.vpro.nl/afleveringen/2014-2015/access-to-africa.html)\n        title = metadata['titel']\n        sub_title = metadata.get('aflevering_titel')\n        if sub_title and sub_title != title:\n            title += ': %s' % sub_title\n\n        token = self._get_token(video_id)\n\n        formats = []\n\n        pubopties = metadata.get('pubopties')\n        if pubopties:\n            quality = qualities(['adaptive', 'wmv_sb', 'h264_sb', 'wmv_bb', 'h264_bb', 'wvc1_std', 'h264_std'])\n            for format_id in pubopties:\n                format_info = self._download_json(\n                    'http://ida.omroep.nl/odi/?prid=%s&puboptions=%s&adaptive=yes&token=%s'\n                    % (video_id, format_id, token),\n                    video_id, 'Downloading %s JSON' % format_id)\n                if format_info.get('error_code', 0) or format_info.get('errorcode', 0):\n                    continue\n                streams = format_info.get('streams')\n                if streams:\n                    video_info = self._download_json(\n                        streams[0] + '&type=json',\n                        video_id, 'Downloading %s stream JSON' % format_id)\n                else:\n                    video_info = format_info\n                video_url = video_info.get('url')\n                if not video_url:\n                    continue\n                if format_id == 'adaptive':\n                    formats.extend(self._extract_m3u8_formats(video_url, video_id))\n                else:\n                    formats.append({\n                        'url': video_url,\n                        'format_id': format_id,\n                        'quality': quality(format_id),\n                    })\n\n        streams = metadata.get('streams')\n        if streams:\n            for i, stream in enumerate(streams):\n                stream_url = stream.get('url')\n                if not stream_url:\n                    continue\n                if '.asf' not in stream_url:\n                    formats.append({\n                        'url': stream_url,\n                        'quality': stream.get('kwaliteit'),\n                    })\n                    continue\n                asx = self._download_xml(\n                    stream_url, video_id,\n                    'Downloading stream %d ASX playlist' % i,\n                    transform_source=fix_xml_ampersands)\n                ref = asx.find('./ENTRY/Ref')\n                if ref is None:\n                    continue\n                video_url = ref.get('href')\n                if not video_url:\n                    continue\n                formats.append({\n                    'url': video_url,\n                    'ext': stream.get('formaat', 'asf'),\n                    'quality': stream.get('kwaliteit'),\n                })\n\n        self._sort_formats(formats)\n\n        subtitles = {}\n        if metadata.get('tt888') == 'ja':\n            subtitles['nl'] = [{\n                'ext': 'vtt',\n                'url': 'http://e.omroep.nl/tt888/%s' % video_id,\n            }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': metadata.get('info'),\n            'thumbnail': metadata.get('images', [{'url': None}])[-1]['url'],\n            'upload_date': unified_strdate(metadata.get('gidsdatum')),\n            'duration': parse_duration(metadata.get('tijdsduur')),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 147,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPOLiveIE._real_extract#268",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOLiveIE",
        "signature": "youtube_dl.extractor.npo.NPOLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        live_id = self._search_regex(\n            r'data-prid=\"([^\"]+)\"', webpage, 'live id')\n\n        metadata = self._download_json(\n            'http://e.omroep.nl/metadata/%s' % live_id,\n            display_id, transform_source=strip_jsonp)\n\n        token = self._get_token(display_id)\n\n        formats = []\n\n        streams = metadata.get('streams')\n        if streams:\n            for stream in streams:\n                stream_type = stream.get('type').lower()\n                # smooth streaming is not supported\n                if stream_type in ['ss', 'ms']:\n                    continue\n                stream_info = self._download_json(\n                    'http://ida.omroep.nl/aapi/?stream=%s&token=%s&type=jsonp'\n                    % (stream.get('url'), token),\n                    display_id, 'Downloading %s JSON' % stream_type)\n                if stream_info.get('error_code', 0) or stream_info.get('errorcode', 0):\n                    continue\n                stream_url = self._download_json(\n                    stream_info['stream'], display_id,\n                    'Downloading %s URL' % stream_type,\n                    'Unable to download %s URL' % stream_type,\n                    transform_source=strip_jsonp, fatal=False)\n                if not stream_url:\n                    continue\n                if stream_type == 'hds':\n                    f4m_formats = self._extract_f4m_formats(stream_url, display_id)\n                    # f4m downloader downloads only piece of live stream\n                    for f4m_format in f4m_formats:\n                        f4m_format['preference'] = -1\n                    formats.extend(f4m_formats)\n                elif stream_type == 'hls':\n                    formats.extend(self._extract_m3u8_formats(stream_url, display_id, 'mp4'))\n                else:\n                    formats.append({\n                        'url': stream_url,\n                        'preference': -10,\n                    })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': live_id,\n            'display_id': display_id,\n            'title': self._live_title(metadata['titel']),\n            'description': metadata['info'],\n            'thumbnail': metadata.get('images', [{'url': None}])[-1]['url'],\n            'formats': formats,\n            'is_live': True,\n        }",
        "begin_line": 268,
        "end_line": 328,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPORadioIE._html_get_attribute_regex#349",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPORadioIE",
        "signature": "youtube_dl.extractor.npo.NPORadioIE._html_get_attribute_regex(attribute)",
        "snippet": "    def _html_get_attribute_regex(attribute):\n        return r'{0}\\s*=\\s*\\'([^\\']+)\\''.format(attribute)",
        "begin_line": 349,
        "end_line": 350,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPORadioIE._real_extract#352",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPORadioIE",
        "signature": "youtube_dl.extractor.npo.NPORadioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            self._html_get_attribute_regex('data-channel'), webpage, 'title')\n\n        stream = self._parse_json(\n            self._html_search_regex(self._html_get_attribute_regex('data-streams'), webpage, 'data-streams'),\n            video_id)\n\n        codec = stream.get('codec')\n\n        return {\n            'id': video_id,\n            'url': stream['url'],\n            'title': self._live_title(title),\n            'acodec': codec,\n            'ext': codec,\n            'is_live': True,\n        }",
        "begin_line": 352,
        "end_line": 373,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPORadioFragmentIE._real_extract#390",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPORadioFragmentIE",
        "signature": "youtube_dl.extractor.npo.NPORadioFragmentIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        audio_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, audio_id)\n\n        title = self._html_search_regex(\n            r'href=\"/radio/[^/]+/fragment/%s\" title=\"([^\"]+)\"' % audio_id,\n            webpage, 'title')\n\n        audio_url = self._search_regex(\n            r\"data-streams='([^']+)'\", webpage, 'audio url')\n\n        return {\n            'id': audio_id,\n            'url': audio_url,\n            'title': title,\n        }",
        "begin_line": 390,
        "end_line": 406,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.npo.VPROIE._real_extract#444",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.VPROIE",
        "signature": "youtube_dl.extractor.npo.VPROIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = [\n            self.url_result('npo:%s' % video_id if not video_id.startswith('http') else video_id)\n            for video_id in re.findall(r'data-media-id=\"([^\"]+)\"', webpage)\n        ]\n\n        playlist_title = self._search_regex(\n            r'<title>\\s*([^>]+?)\\s*-\\s*Teledoc\\s*-\\s*VPRO\\s*</title>',\n            webpage, 'playlist title', default=None) or self._og_search_title(webpage)\n\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 444,
        "end_line": 458,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.npo.WNLIE._real_extract#473",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.WNLIE",
        "signature": "youtube_dl.extractor.npo.WNLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = [\n            self.url_result('npo:%s' % video_id, 'NPO')\n            for video_id, part in re.findall(\n                r'<a[^>]+href=\"([^\"]+)\"[^>]+class=\"js-mid\"[^>]*>(Deel \\d+)', webpage)\n        ]\n\n        playlist_title = self._html_search_regex(\n            r'(?s)<h1[^>]+class=\"subject\"[^>]*>(.+?)</h1>',\n            webpage, 'playlist title')\n\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 473,
        "end_line": 488,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCIE._real_extract#59",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCIE",
        "signature": "youtube_dl.extractor.nbc.NBCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        theplatform_url = unescapeHTML(lowercase_escape(self._html_search_regex(\n            [\n                r'(?:class=\"video-player video-player-full\" data-mpx-url|class=\"player\" src)=\"(.*?)\"',\n                r'\"embedURL\"\\s*:\\s*\"([^\"]+)\"'\n            ],\n            webpage, 'theplatform url').replace('_no_endcard', '').replace('\\\\/', '/')))\n        if theplatform_url.startswith('//'):\n            theplatform_url = 'http:' + theplatform_url\n        return self.url_result(theplatform_url)",
        "begin_line": 59,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE._extract_url#90",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE",
        "signature": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        iframe_m = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://vplayer\\.nbcsports\\.com/[^\"]+)\"', webpage)\n        if iframe_m:\n            return iframe_m.group('url')",
        "begin_line": 90,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE._real_extract#96",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE",
        "signature": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        theplatform_url = self._og_search_video_url(webpage)\n        return self.url_result(theplatform_url, 'ThePlatform')",
        "begin_line": 96,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCSportsIE._real_extract#117",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCSportsIE",
        "signature": "youtube_dl.extractor.nbc.NBCSportsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        return self.url_result(\n            NBCSportsVPlayerIE._extract_url(webpage), 'NBCSportsVPlayer')",
        "begin_line": 117,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCNewsIE._real_extract#178",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCNewsIE",
        "signature": "youtube_dl.extractor.nbc.NBCNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        if video_id is not None:\n            all_info = self._download_xml('http://www.nbcnews.com/id/%s/displaymode/1219' % video_id, video_id)\n            info = all_info.find('video')\n\n            return {\n                'id': video_id,\n                'title': info.find('headline').text,\n                'ext': 'flv',\n                'url': find_xpath_attr(info, 'media', 'type', 'flashVideo').text,\n                'description': compat_str(info.find('caption').text),\n                'thumbnail': find_xpath_attr(info, 'media', 'type', 'thumbnail').text,\n            }\n        else:\n            # \"feature\" and \"nightly-news\" pages use theplatform.com\n            title = mobj.group('title')\n            webpage = self._download_webpage(url, title)\n            bootstrap_json = self._search_regex(\n                r'var\\s+(?:bootstrapJson|playlistData)\\s*=\\s*({.+});?\\s*$',\n                webpage, 'bootstrap json', flags=re.MULTILINE)\n            bootstrap = self._parse_json(bootstrap_json, video_id)\n            info = bootstrap['results'][0]['video']\n            mpxid = info['mpxId']\n\n            base_urls = [\n                info['fallbackPlaylistUrl'],\n                info['associatedPlaylistUrl'],\n            ]\n\n            for base_url in base_urls:\n                if not base_url:\n                    continue\n                playlist_url = base_url + '?form=MPXNBCNewsAPI'\n\n                try:\n                    all_videos = self._download_json(playlist_url, title)\n                except ExtractorError as ee:\n                    if isinstance(ee.cause, compat_HTTPError):\n                        continue\n                    raise\n\n                if not all_videos or 'videos' not in all_videos:\n                    continue\n\n                try:\n                    info = next(v for v in all_videos['videos'] if v['mpxId'] == mpxid)\n                    break\n                except StopIteration:\n                    continue\n\n            if info is None:\n                raise ExtractorError('Could not find video in playlists')\n\n            return {\n                '_type': 'url',\n                # We get the best quality video\n                'url': info['videoAssets'][-1]['publicUrl'],\n                'ie_key': 'ThePlatform',\n            }",
        "begin_line": 178,
        "end_line": 238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.MSNBCIE._real_extract#259",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.MSNBCIE",
        "signature": "youtube_dl.extractor.nbc.MSNBCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        embed_url = self._html_search_meta('embedURL', webpage)\n        return self.url_result(embed_url)",
        "begin_line": 259,
        "end_line": 263,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.funnyordie.FunnyOrDieIE._real_extract#36",
        "src_path": "youtube_dl/extractor/funnyordie.py",
        "class_name": "youtube_dl.extractor.funnyordie.FunnyOrDieIE",
        "signature": "youtube_dl.extractor.funnyordie.FunnyOrDieIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        links = re.findall(r'<source src=\"([^\"]+/v)[^\"]+\\.([^\"]+)\" type=\\'video', webpage)\n        if not links:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        links.sort(key=lambda link: 1 if link[1] == 'mp4' else 0)\n\n        bitrates = self._html_search_regex(r'<source src=\"[^\"]+/v,((?:\\d+,)+)\\.mp4\\.csmil', webpage, 'video bitrates')\n        bitrates = [int(b) for b in bitrates.rstrip(',').split(',')]\n        bitrates.sort()\n\n        formats = []\n        for bitrate in bitrates:\n            for link in links:\n                formats.append({\n                    'url': self._proto_relative_url('%s%d.%s' % (link[0], bitrate, link[1])),\n                    'format_id': '%s-%d' % (link[1], bitrate),\n                    'vbr': bitrate,\n                })\n\n        subtitles = {}\n        for src, src_lang in re.findall(r'<track kind=\"captions\" src=\"([^\"]+)\" srclang=\"([^\"]+)\"', webpage):\n            subtitles[src_lang] = [{\n                'ext': src.split('/')[-1],\n                'url': 'http://www.funnyordie.com%s' % src,\n            }]\n\n        post_json = self._search_regex(\n            r'fb_post\\s*=\\s*(\\{.*?\\});', webpage, 'post details')\n        post = json.loads(post_json)\n\n        return {\n            'id': video_id,\n            'title': post['name'],\n            'description': post.get('description'),\n            'thumbnail': post.get('picture'),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 36,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._get_track_url#36",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._get_track_url(self, storage_dir, track_id)",
        "snippet": "    def _get_track_url(self, storage_dir, track_id):\n        data = self._download_json(\n            'http://music.yandex.ru/api/v1.5/handlers/api-jsonp.jsx?action=getTrackSrc&p=download-info/%s'\n            % storage_dir,\n            track_id, 'Downloading track location JSON')\n\n        key = hashlib.md5(('XGRlBW9FXlekgbPrRHuSiA' + data['path'][1:] + data['s']).encode('utf-8')).hexdigest()\n        storage = storage_dir.split('.')\n\n        return ('http://%s/get-mp3/%s/%s?track-id=%s&from=service-10-track&similarities-experiment=default'\n                % (data['host'], key, data['ts'] + data['path'], storage[1]))",
        "begin_line": 36,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._get_track_info#48",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._get_track_info(self, track)",
        "snippet": "    def _get_track_info(self, track):\n        thumbnail = None\n        cover_uri = track.get('albums', [{}])[0].get('coverUri')\n        if cover_uri:\n            thumbnail = cover_uri.replace('%%', 'orig')\n            if not thumbnail.startswith('http'):\n                thumbnail = 'http://' + thumbnail\n        return {\n            'id': track['id'],\n            'ext': 'mp3',\n            'url': self._get_track_url(track['storageDir'], track['id']),\n            'title': '%s - %s' % (track['artists'][0]['name'], track['title']),\n            'filesize': int_or_none(track.get('fileSize')),\n            'duration': float_or_none(track.get('durationMs'), 1000),\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 48,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._real_extract#65",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        album_id, track_id = mobj.group('album_id'), mobj.group('id')\n\n        track = self._download_json(\n            'http://music.yandex.ru/handlers/track.jsx?track=%s:%s' % (track_id, album_id),\n            track_id, 'Downloading track JSON')['track']\n\n        return self._get_track_info(track)",
        "begin_line": 65,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistBaseIE._build_playlist#77",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistBaseIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistBaseIE._build_playlist(self, tracks)",
        "snippet": "    def _build_playlist(self, tracks):\n        return [\n            self.url_result(\n                'http://music.yandex.ru/album/%s/track/%s' % (track['albums'][0]['id'], track['id']))\n            for track in tracks if track.get('albums') and isinstance(track.get('albums'), list)]",
        "begin_line": 77,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicAlbumIE._real_extract#98",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicAlbumIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        album_id = self._match_id(url)\n\n        album = self._download_json(\n            'http://music.yandex.ru/handlers/album.jsx?album=%s' % album_id,\n            album_id, 'Downloading album JSON')\n\n        entries = self._build_playlist(album['volumes'][0])\n\n        title = '%s - %s' % (album['artists'][0]['name'], album['title'])\n        year = album.get('year')\n        if year:\n            title += ' (%s)' % year\n\n        return self.playlist_result(entries, compat_str(album['id']), title)",
        "begin_line": 98,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistIE._real_extract#139",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        mu = self._parse_json(\n            self._search_regex(\n                r'var\\s+Mu\\s*=\\s*({.+?});\\s*</script>', webpage, 'player'),\n            playlist_id)\n\n        playlist = mu['pageData']['playlist']\n        tracks, track_ids = playlist['tracks'], playlist['trackIds']\n\n        # tracks dictionary shipped with webpage is limited to 150 tracks,\n        # missing tracks should be retrieved manually.\n        if len(tracks) < len(track_ids):\n            present_track_ids = set([compat_str(track['id']) for track in tracks if track.get('id')])\n            missing_track_ids = set(map(compat_str, track_ids)) - set(present_track_ids)\n            request = compat_urllib_request.Request(\n                'https://music.yandex.ru/handlers/track-entries.jsx',\n                compat_urllib_parse.urlencode({\n                    'entries': ','.join(missing_track_ids),\n                    'lang': mu.get('settings', {}).get('lang', 'en'),\n                    'external-domain': 'music.yandex.ru',\n                    'overembed': 'false',\n                    'sign': mu.get('authData', {}).get('user', {}).get('sign'),\n                    'strict': 'true',\n                }).encode('utf-8'))\n            request.add_header('Referer', url)\n            request.add_header('X-Requested-With', 'XMLHttpRequest')\n\n            missing_tracks = self._download_json(\n                request, playlist_id, 'Downloading missing tracks JSON', fatal=False)\n            if missing_tracks:\n                tracks.extend(missing_tracks)\n\n        return self.playlist_result(\n            self._build_playlist(tracks),\n            compat_str(playlist_id),\n            playlist['title'], playlist.get('description'))",
        "begin_line": 139,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE._real_extract#21",
        "src_path": "youtube_dl/extractor/academicearth.py",
        "class_name": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE",
        "signature": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n        title = self._html_search_regex(\n            r'<h1 class=\"playlist-name\"[^>]*?>(.*?)</h1>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<p class=\"excerpt\"[^>]*?>(.*?)</p>',\n            webpage, 'description', fatal=False)\n        urls = re.findall(\n            r'<li class=\"lecture-preview\">\\s*?<a target=\"_blank\" href=\"([^\"]+)\">',\n            webpage)\n        entries = [self.url_result(u) for u in urls]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': title,\n            'description': description,\n            'entries': entries,\n        }",
        "begin_line": 21,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.appletrailers.AppleTrailersIE._real_extract#73",
        "src_path": "youtube_dl/extractor/appletrailers.py",
        "class_name": "youtube_dl.extractor.appletrailers.AppleTrailersIE",
        "signature": "youtube_dl.extractor.appletrailers.AppleTrailersIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        movie = mobj.group('movie')\n        uploader_id = mobj.group('company')\n\n        playlist_url = compat_urlparse.urljoin(url, 'includes/playlists/itunes.inc')\n\n        def fix_html(s):\n            s = re.sub(r'(?s)<script[^<]*?>.*?</script>', '', s)\n            s = re.sub(r'<img ([^<]*?)>', r'<img \\1/>', s)\n            # The ' in the onClick attributes are not escaped, it couldn't be parsed\n            # like: http://trailers.apple.com/trailers/wb/gravity/\n\n            def _clean_json(m):\n                return 'iTunes.playURL(%s);' % m.group(1).replace('\\'', '&#39;')\n            s = re.sub(self._JSON_RE, _clean_json, s)\n            s = '<html>%s</html>' % s\n            return s\n        doc = self._download_xml(playlist_url, movie, transform_source=fix_html)\n\n        playlist = []\n        for li in doc.findall('./div/ul/li'):\n            on_click = li.find('.//a').attrib['onClick']\n            trailer_info_json = self._search_regex(self._JSON_RE,\n                                                   on_click, 'trailer info')\n            trailer_info = json.loads(trailer_info_json)\n            title = trailer_info['title']\n            video_id = movie + '-' + re.sub(r'[^a-zA-Z0-9]', '', title).lower()\n            thumbnail = li.find('.//img').attrib['src']\n            upload_date = trailer_info['posted'].replace('-', '')\n\n            runtime = trailer_info['runtime']\n            m = re.search(r'(?P<minutes>[0-9]+):(?P<seconds>[0-9]{1,2})', runtime)\n            duration = None\n            if m:\n                duration = 60 * int(m.group('minutes')) + int(m.group('seconds'))\n\n            first_url = trailer_info['url']\n            trailer_id = first_url.split('/')[-1].rpartition('_')[0].lower()\n            settings_json_url = compat_urlparse.urljoin(url, 'includes/settings/%s.json' % trailer_id)\n            settings = self._download_json(settings_json_url, trailer_id, 'Downloading settings json')\n\n            formats = []\n            for format in settings['metadata']['sizes']:\n                # The src is a file pointing to the real video file\n                format_url = re.sub(r'_(\\d*p.mov)', r'_h\\1', format['src'])\n                formats.append({\n                    'url': format_url,\n                    'format': format['type'],\n                    'width': int_or_none(format['width']),\n                    'height': int_or_none(format['height']),\n                })\n\n            self._sort_formats(formats)\n\n            playlist.append({\n                '_type': 'video',\n                'id': video_id,\n                'formats': formats,\n                'title': title,\n                'duration': duration,\n                'thumbnail': thumbnail,\n                'upload_date': upload_date,\n                'uploader_id': uploader_id,\n                'http_headers': {\n                    'User-Agent': 'QuickTime compatible (youtube-dl)',\n                },\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': movie,\n            'entries': playlist,\n        }",
        "begin_line": 73,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.audiomack.AudiomackIE._real_extract#45",
        "src_path": "youtube_dl/extractor/audiomack.py",
        "class_name": "youtube_dl.extractor.audiomack.AudiomackIE",
        "signature": "youtube_dl.extractor.audiomack.AudiomackIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # URLs end with [uploader name]/[uploader title]\n        # this title is whatever the user types in, and is rarely\n        # the proper song title.  Real metadata is in the api response\n        album_url_tag = self._match_id(url)\n\n        # Request the extended version of the api for extra fields like artist and title\n        api_response = self._download_json(\n            'http://www.audiomack.com/api/music/url/song/%s?extended=1&_=%d' % (\n                album_url_tag, time.time()),\n            album_url_tag)\n\n        # API is inconsistent with errors\n        if 'url' not in api_response or not api_response['url'] or 'error' in api_response:\n            raise ExtractorError('Invalid url %s', url)\n\n        # Audiomack wraps a lot of soundcloud tracks in their branded wrapper\n        # if so, pass the work off to the soundcloud extractor\n        if SoundcloudIE.suitable(api_response['url']):\n            return {'_type': 'url', 'url': api_response['url'], 'ie_key': 'Soundcloud'}\n\n        return {\n            'id': api_response.get('id', album_url_tag),\n            'uploader': api_response.get('artist'),\n            'title': api_response.get('title'),\n            'url': api_response['url'],\n        }",
        "begin_line": 45,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.audiomack.AudiomackAlbumIE._real_extract#110",
        "src_path": "youtube_dl/extractor/audiomack.py",
        "class_name": "youtube_dl.extractor.audiomack.AudiomackAlbumIE",
        "signature": "youtube_dl.extractor.audiomack.AudiomackAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # URLs end with [uploader name]/[uploader title]\n        # this title is whatever the user types in, and is rarely\n        # the proper song title.  Real metadata is in the api response\n        album_url_tag = self._match_id(url)\n        result = {'_type': 'playlist', 'entries': []}\n        # There is no one endpoint for album metadata - instead it is included/repeated in each song's metadata\n        # Therefore we don't know how many songs the album has and must infi-loop until failure\n        for track_no in itertools.count():\n            # Get song's metadata\n            api_response = self._download_json(\n                'http://www.audiomack.com/api/music/url/album/%s/%d?extended=1&_=%d'\n                % (album_url_tag, track_no, time.time()), album_url_tag,\n                note='Querying song information (%d)' % (track_no + 1))\n\n            # Total failure, only occurs when url is totally wrong\n            # Won't happen in middle of valid playlist (next case)\n            if 'url' not in api_response or 'error' in api_response:\n                raise ExtractorError('Invalid url for track %d of album url %s' % (track_no, url))\n            # URL is good but song id doesn't exist - usually means end of playlist\n            elif not api_response['url']:\n                break\n            else:\n                # Pull out the album metadata and add to result (if it exists)\n                for resultkey, apikey in [('id', 'album_id'), ('title', 'album_title')]:\n                    if apikey in api_response and resultkey not in result:\n                        result[resultkey] = api_response[apikey]\n                song_id = url_basename(api_response['url']).rpartition('.')[0]\n                result['entries'].append({\n                    'id': api_response.get('id', song_id),\n                    'uploader': api_response.get('artist'),\n                    'title': api_response.get('title', song_id),\n                    'url': api_response['url'],\n                })\n        return result",
        "begin_line": 110,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.space.SpaceIE._real_extract#24",
        "src_path": "youtube_dl/extractor/space.py",
        "class_name": "youtube_dl.extractor.space.SpaceIE",
        "signature": "youtube_dl.extractor.space.SpaceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        try:\n            # Some videos require the playerKey field, which isn't define in\n            # the BrightcoveExperience object\n            brightcove_url = self._og_search_video_url(webpage)\n        except RegexNotFoundError:\n            # Other videos works fine with the info from the object\n            brightcove_url = BrightcoveIE._extract_brightcove_url(webpage)\n        if brightcove_url is None:\n            raise ExtractorError(\n                'The webpage does not contain a video', expected=True)\n        return self.url_result(brightcove_url, BrightcoveIE.ie_key())",
        "begin_line": 24,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.stitcher.StitcherIE._real_extract#50",
        "src_path": "youtube_dl/extractor/stitcher.py",
        "class_name": "youtube_dl.extractor.stitcher.StitcherIE",
        "signature": "youtube_dl.extractor.stitcher.StitcherIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        audio_id = mobj.group('id')\n        display_id = mobj.group('display_id') or audio_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        episode = self._parse_json(\n            js_to_json(self._search_regex(\n                r'(?s)var\\s+stitcher\\s*=\\s*({.+?});\\n', webpage, 'episode config')),\n            display_id)['config']['episode']\n\n        title = unescapeHTML(episode['title'])\n        formats = [{\n            'url': episode[episode_key],\n            'ext': determine_ext(episode[episode_key]) or 'mp3',\n            'vcodec': 'none',\n        } for episode_key in ('episodeURL',) if episode.get(episode_key)]\n        description = self._search_regex(\n            r'Episode Info:\\s*</span>([^<]+)<', webpage, 'description', fatal=False)\n        duration = int_or_none(episode.get('duration'))\n        thumbnail = episode.get('episodeImage')\n\n        return {\n            'id': audio_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 50,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE.report_resolve#119",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE.report_resolve(self, video_id)",
        "snippet": "    def report_resolve(self, video_id):\n        \"\"\"Report information extraction.\"\"\"\n        self.to_screen('%s: Resolving id' % video_id)",
        "begin_line": 119,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._resolv_url#124",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._resolv_url(cls, url)",
        "snippet": "    def _resolv_url(cls, url):\n        return 'http://api.soundcloud.com/resolve.json?url=' + url + '&client_id=' + cls._CLIENT_ID",
        "begin_line": 124,
        "end_line": 125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._extract_info_dict#127",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._extract_info_dict(self, info, full_title=None, quiet=False, secret_token=None)",
        "snippet": "    def _extract_info_dict(self, info, full_title=None, quiet=False, secret_token=None):\n        track_id = compat_str(info['id'])\n        name = full_title or track_id\n        if quiet:\n            self.report_extraction(name)\n\n        thumbnail = info['artwork_url']\n        if thumbnail is not None:\n            thumbnail = thumbnail.replace('-large', '-t500x500')\n        ext = 'mp3'\n        result = {\n            'id': track_id,\n            'uploader': info['user']['username'],\n            'upload_date': unified_strdate(info['created_at']),\n            'title': info['title'],\n            'description': info['description'],\n            'thumbnail': thumbnail,\n            'duration': int_or_none(info.get('duration'), 1000),\n            'webpage_url': info.get('permalink_url'),\n        }\n        formats = []\n        if info.get('downloadable', False):\n            # We can build a direct link to the song\n            format_url = (\n                'https://api.soundcloud.com/tracks/{0}/download?client_id={1}'.format(\n                    track_id, self._CLIENT_ID))\n            formats.append({\n                'format_id': 'download',\n                'ext': info.get('original_format', 'mp3'),\n                'url': format_url,\n                'vcodec': 'none',\n                'preference': 10,\n            })\n\n        # We have to retrieve the url\n        streams_url = ('http://api.soundcloud.com/i1/tracks/{0}/streams?'\n                       'client_id={1}&secret_token={2}'.format(track_id, self._IPHONE_CLIENT_ID, secret_token))\n        format_dict = self._download_json(\n            streams_url,\n            track_id, 'Downloading track url')\n\n        for key, stream_url in format_dict.items():\n            if key.startswith('http'):\n                formats.append({\n                    'format_id': key,\n                    'ext': ext,\n                    'url': stream_url,\n                    'vcodec': 'none',\n                })\n            elif key.startswith('rtmp'):\n                # The url doesn't have an rtmp app, we have to extract the playpath\n                url, path = stream_url.split('mp3:', 1)\n                formats.append({\n                    'format_id': key,\n                    'url': url,\n                    'play_path': 'mp3:' + path,\n                    'ext': 'flv',\n                    'vcodec': 'none',\n                })\n\n            if not formats:\n                # We fallback to the stream_url in the original info, this\n                # cannot be always used, sometimes it can give an HTTP 404 error\n                formats.append({\n                    'format_id': 'fallback',\n                    'url': info['stream_url'] + '?client_id=' + self._CLIENT_ID,\n                    'ext': ext,\n                    'vcodec': 'none',\n                })\n\n            for f in formats:\n                if f['format_id'].startswith('http'):\n                    f['protocol'] = 'http'\n                if f['format_id'].startswith('rtmp'):\n                    f['protocol'] = 'rtmp'\n\n        self._check_formats(formats, track_id)\n        self._sort_formats(formats)\n        result['formats'] = formats\n\n        return result",
        "begin_line": 127,
        "end_line": 207,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._real_extract#209",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n\n        track_id = mobj.group('track_id')\n        token = None\n        if track_id is not None:\n            info_json_url = 'http://api.soundcloud.com/tracks/' + track_id + '.json?client_id=' + self._CLIENT_ID\n            full_title = track_id\n            token = mobj.group('secret_token')\n            if token:\n                info_json_url += \"&secret_token=\" + token\n        elif mobj.group('player'):\n            query = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n            real_url = query['url'][0]\n            # If the token is in the query of the original url we have to\n            # manually add it\n            if 'secret_token' in query:\n                real_url += '?secret_token=' + query['secret_token'][0]\n            return self.url_result(real_url)\n        else:\n            # extract uploader (which is in the url)\n            uploader = mobj.group('uploader')\n            # extract simple title (uploader + slug of song title)\n            slug_title = mobj.group('title')\n            token = mobj.group('token')\n            full_title = resolve_title = '%s/%s' % (uploader, slug_title)\n            if token:\n                resolve_title += '/%s' % token\n\n            self.report_resolve(full_title)\n\n            url = 'http://soundcloud.com/%s' % resolve_title\n            info_json_url = self._resolv_url(url)\n        info = self._download_json(info_json_url, full_title, 'Downloading info JSON')\n\n        return self._extract_info_dict(info, full_title, secret_token=token)",
        "begin_line": 209,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudSetIE._real_extract#261",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudSetIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudSetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        # extract uploader (which is in the url)\n        uploader = mobj.group('uploader')\n        # extract simple title (uploader + slug of song title)\n        slug_title = mobj.group('slug_title')\n        full_title = '%s/sets/%s' % (uploader, slug_title)\n        url = 'http://soundcloud.com/%s/sets/%s' % (uploader, slug_title)\n\n        token = mobj.group('token')\n        if token:\n            full_title += '/' + token\n            url += '/' + token\n\n        self.report_resolve(full_title)\n\n        resolv_url = self._resolv_url(url)\n        info = self._download_json(resolv_url, full_title)\n\n        if 'errors' in info:\n            msgs = (compat_str(err['error_message']) for err in info['errors'])\n            raise ExtractorError('unable to download video webpage: %s' % ','.join(msgs))\n\n        entries = [self.url_result(track['permalink_url'], 'Soundcloud') for track in info['tracks']]\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': '%s' % info['id'],\n            'title': info['title'],\n        }",
        "begin_line": 261,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudUserIE._real_extract#371",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudUserIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader = mobj.group('user')\n\n        url = 'http://soundcloud.com/%s/' % uploader\n        resolv_url = self._resolv_url(url)\n        user = self._download_json(\n            resolv_url, uploader, 'Downloading user info')\n\n        resource = mobj.group('rsrc') or 'all'\n        base_url = self._BASE_URL_MAP[resource] % user['id']\n\n        next_href = None\n\n        entries = []\n        for i in itertools.count():\n            if not next_href:\n                data = compat_urllib_parse.urlencode({\n                    'offset': i * 50,\n                    'limit': 50,\n                    'client_id': self._CLIENT_ID,\n                    'linked_partitioning': '1',\n                    'representation': 'speedy',\n                })\n                next_href = base_url + '?' + data\n\n            response = self._download_json(\n                next_href, uploader, 'Downloading track page %s' % (i + 1))\n\n            collection = response['collection']\n\n            if not collection:\n                self.to_screen('%s: End page received' % uploader)\n                break\n\n            def resolve_permalink_url(candidates):\n                for cand in candidates:\n                    if isinstance(cand, dict):\n                        permalink_url = cand.get('permalink_url')\n                        if permalink_url and permalink_url.startswith('http'):\n                            return permalink_url\n\n            for e in collection:\n                permalink_url = resolve_permalink_url((e, e.get('track'), e.get('playlist')))\n                if permalink_url:\n                    entries.append(self.url_result(permalink_url))\n\n            if 'next_href' in response:\n                next_href = response['next_href']\n                if not next_href:\n                    break\n            else:\n                next_href = None\n\n        return {\n            '_type': 'playlist',\n            'id': compat_str(user['id']),\n            'title': '%s (%s)' % (user['username'], self._TITLE_MAP[resource]),\n            'entries': entries,\n        }",
        "begin_line": 371,
        "end_line": 430,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE._real_extract#446",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        base_url = '%s//api.soundcloud.com/playlists/%s.json?' % (self.http_scheme(), playlist_id)\n\n        data_dict = {\n            'client_id': self._CLIENT_ID,\n        }\n        token = mobj.group('token')\n\n        if token:\n            data_dict['secret_token'] = token\n\n        data = compat_urllib_parse.urlencode(data_dict)\n        data = self._download_json(\n            base_url + data, playlist_id, 'Downloading playlist')\n\n        entries = [self.url_result(track['permalink_url'], 'Soundcloud') for track in data['tracks']]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': data.get('title'),\n            'description': data.get('description'),\n            'entries': entries,\n        }",
        "begin_line": 446,
        "end_line": 471,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._prepare_call#33",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._prepare_call(self, path, timestamp=None, post_data=None)",
        "snippet": "    def _prepare_call(self, path, timestamp=None, post_data=None):\n        path += '?' if '?' not in path else '&'\n        if not timestamp:\n            timestamp = int(time.time())\n        query = self._API_QUERY_TEMPLATE % (path, self._APP, timestamp)\n        if self._token:\n            query += '&token=%s' % self._token\n        sig = hmac.new(\n            self._APP_SECRET.encode('ascii'),\n            query.encode('ascii'),\n            hashlib.sha1\n        ).hexdigest()\n        url = self._API_URL_TEMPLATE % (query, sig)\n        return compat_urllib_request.Request(\n            url, json.dumps(post_data).encode('utf-8')) if post_data else url",
        "begin_line": 33,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._call_api#49",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._call_api(self, path, video_id, note, timestamp=None, post_data=None)",
        "snippet": "    def _call_api(self, path, video_id, note, timestamp=None, post_data=None):\n        resp = self._download_json(\n            self._prepare_call(path, timestamp, post_data), video_id, note)\n\n        error = resp.get('error')\n        if error:\n            if error == 'invalid timestamp':\n                resp = self._download_json(\n                    self._prepare_call(path, int(resp['current_timestamp']), post_data),\n                    video_id, '%s (retry)' % note)\n                error = resp.get('error')\n            if error:\n                self._raise_error(resp['error'])\n\n        return resp",
        "begin_line": 49,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._raise_error#65",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._raise_error(self, error)",
        "snippet": "    def _raise_error(self, error):\n        raise ExtractorError(\n            '%s returned error: %s' % (self.IE_NAME, error),\n            expected=True)",
        "begin_line": 65,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._real_initialize#70",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 70,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._login#73",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'login_id': username,\n            'password': password,\n        }\n\n        login = self._call_api(\n            'sessions.json', None,\n            'Logging in as %s' % username, post_data=login_form)\n\n        self._token = login.get('token')\n        if not self._token:\n            self.report_warning('Unable to get session token, login has probably failed')",
        "begin_line": 73,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE.dict_selection#92",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE.dict_selection(dict_obj, preferred_key)",
        "snippet": "    def dict_selection(dict_obj, preferred_key):\n        if preferred_key in dict_obj:\n            return dict_obj.get(preferred_key)\n\n        filtered_dict = list(filter(None, [dict_obj.get(k) for k in dict_obj.keys()]))\n        return filtered_dict[0] if filtered_dict else None",
        "begin_line": 92,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiIE._real_extract#199",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiIE",
        "signature": "youtube_dl.extractor.viki.VikiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._call_api(\n            'videos/%s.json' % video_id, video_id, 'Downloading video JSON')\n\n        title = self.dict_selection(video.get('titles', {}), 'en')\n        if not title:\n            title = 'Episode %d' % video.get('number') if video.get('type') == 'episode' else video.get('id') or video_id\n            container_titles = video.get('container', {}).get('titles', {})\n            container_title = self.dict_selection(container_titles, 'en')\n            title = '%s - %s' % (container_title, title)\n\n        description = self.dict_selection(video.get('descriptions', {}), 'en')\n\n        duration = int_or_none(video.get('duration'))\n        timestamp = parse_iso8601(video.get('created_at'))\n        uploader = video.get('author')\n        like_count = int_or_none(video.get('likes', {}).get('count'))\n        age_limit = parse_age_limit(video.get('rating'))\n\n        thumbnails = []\n        for thumbnail_id, thumbnail in video.get('images', {}).items():\n            thumbnails.append({\n                'id': thumbnail_id,\n                'url': thumbnail.get('url'),\n            })\n\n        subtitles = {}\n        for subtitle_lang, _ in video.get('subtitle_completions', {}).items():\n            subtitles[subtitle_lang] = [{\n                'ext': subtitles_format,\n                'url': self._prepare_call(\n                    'videos/%s/subtitles/%s.%s' % (video_id, subtitle_lang, subtitles_format)),\n            } for subtitles_format in ('srt', 'vtt')]\n\n        result = {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'like_count': like_count,\n            'age_limit': age_limit,\n            'thumbnails': thumbnails,\n            'subtitles': subtitles,\n        }\n\n        streams = self._call_api(\n            'videos/%s/streams.json' % video_id, video_id,\n            'Downloading video streams JSON')\n\n        if 'external' in streams:\n            result.update({\n                '_type': 'url_transparent',\n                'url': streams['external']['url'],\n            })\n            return result\n\n        formats = []\n        for format_id, stream_dict in streams.items():\n            height = int_or_none(self._search_regex(\n                r'^(\\d+)[pP]$', format_id, 'height', default=None))\n            for protocol, format_dict in stream_dict.items():\n                if format_id == 'm3u8':\n                    formats = self._extract_m3u8_formats(\n                        format_dict['url'], video_id, 'mp4', m3u8_id='m3u8-%s' % protocol)\n                else:\n                    formats.append({\n                        'url': format_dict['url'],\n                        'format_id': '%s-%s' % (format_id, protocol),\n                        'height': height,\n                    })\n        self._sort_formats(formats)\n\n        result['formats'] = formats\n        return result",
        "begin_line": 199,
        "end_line": 276,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiChannelIE._real_extract#311",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiChannelIE",
        "signature": "youtube_dl.extractor.viki.VikiChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        channel = self._call_api(\n            'containers/%s.json' % channel_id, channel_id,\n            'Downloading channel JSON')\n\n        title = self.dict_selection(channel['titles'], 'en')\n\n        description = self.dict_selection(channel['descriptions'], 'en')\n\n        entries = []\n        for video_type in ('episodes', 'clips', 'movies'):\n            for page_num in itertools.count(1):\n                page = self._call_api(\n                    'containers/%s/%s.json?per_page=%d&sort=number&direction=asc&with_paging=true&page=%d'\n                    % (channel_id, video_type, self._PER_PAGE, page_num), channel_id,\n                    'Downloading %s JSON page #%d' % (video_type, page_num))\n                for video in page['response']:\n                    video_id = video['id']\n                    entries.append(self.url_result(\n                        'http://www.viki.com/videos/%s' % video_id, 'Viki'))\n                if not page['pagination']['next']:\n                    break\n\n        return self.playlist_result(entries, channel_id, title, description)",
        "begin_line": 311,
        "end_line": 336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.footyroom.FootyRoomIE._real_extract#25",
        "src_path": "youtube_dl/extractor/footyroom.py",
        "class_name": "youtube_dl.extractor.footyroom.FootyRoomIE",
        "signature": "youtube_dl.extractor.footyroom.FootyRoomIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        playlist = self._parse_json(\n            self._search_regex(\n                r'VideoSelector\\.load\\((\\[.+?\\])\\);', webpage, 'video selector'),\n            playlist_id)\n\n        playlist_title = self._og_search_title(webpage)\n\n        entries = []\n        for video in playlist:\n            payload = video.get('payload')\n            if not payload:\n                continue\n            playwire_url = self._search_regex(\n                r'data-config=\"([^\"]+)\"', payload,\n                'playwire url', default=None)\n            if playwire_url:\n                entries.append(self.url_result(self._proto_relative_url(\n                    playwire_url, 'http:'), 'Playwire'))\n\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 25,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.clipfish.ClipfishIE._real_extract#30",
        "src_path": "youtube_dl/extractor/clipfish.py",
        "class_name": "youtube_dl.extractor.clipfish.ClipfishIE",
        "signature": "youtube_dl.extractor.clipfish.ClipfishIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_info = self._parse_json(\n            js_to_json(self._html_search_regex(\n                '(?s)videoObject\\s*=\\s*({.+?});', webpage, 'video object')),\n            video_id)\n\n        formats = []\n        for video_url in re.findall(r'var\\s+videourl\\s*=\\s*\"([^\"]+)\"', webpage):\n            ext = determine_ext(video_url)\n            if ext == 'm3u8':\n                formats.append({\n                    'url': video_url.replace('de.hls.fra.clipfish.de', 'hls.fra.clipfish.de'),\n                    'ext': 'mp4',\n                    'format_id': 'hls',\n                })\n            else:\n                formats.append({\n                    'url': video_url,\n                    'format_id': ext,\n                })\n        self._sort_formats(formats)\n\n        title = remove_end(self._og_search_title(webpage), ' - Video')\n        thumbnail = self._og_search_thumbnail(webpage)\n        duration = int_or_none(video_info.get('length'))\n        timestamp = parse_iso8601(self._html_search_meta('uploadDate', webpage, 'upload date'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n        }",
        "begin_line": 30,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.telebruxelles.TeleBruxellesIE._real_extract#37",
        "src_path": "youtube_dl/extractor/telebruxelles.py",
        "class_name": "youtube_dl.extractor.telebruxelles.TeleBruxellesIE",
        "signature": "youtube_dl.extractor.telebruxelles.TeleBruxellesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        article_id = self._html_search_regex(\n            r\"<article id=\\\"post-(\\d+)\\\"\", webpage, 'article ID')\n        title = self._html_search_regex(\n            r'<h1 class=\\\"entry-title\\\">(.*?)</h1>', webpage, 'title')\n        description = self._og_search_description(webpage)\n\n        rtmp_url = self._html_search_regex(\n            r\"file: \\\"(rtmp://\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}:\\d{1,5}/vod/mp4:\\\" \\+ \\\"\\w+\\\" \\+ \\\".mp4)\\\"\",\n            webpage, 'RTMP url')\n        rtmp_url = rtmp_url.replace(\"\\\" + \\\"\", \"\")\n\n        return {\n            'id': article_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'url': rtmp_url,\n            'ext': 'flv',\n            'rtmp_live': True  # if rtmpdump is not called with \"--live\" argument, the download is blocked and can be completed\n        }",
        "begin_line": 37,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.jpopsukitv.JpopsukiIE._real_extract#30",
        "src_path": "youtube_dl/extractor/jpopsukitv.py",
        "class_name": "youtube_dl.extractor.jpopsukitv.JpopsukiIE",
        "signature": "youtube_dl.extractor.jpopsukitv.JpopsukiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = 'http://www.jpopsuki.tv' + self._html_search_regex(\n            r'<source src=\"(.*?)\" type', webpage, 'video url')\n\n        video_title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        uploader = self._html_search_regex(\n            r'<li>from: <a href=\"/user/view/user/(.*?)/uid/',\n            webpage, 'video uploader', fatal=False)\n        uploader_id = self._html_search_regex(\n            r'<li>from: <a href=\"/user/view/user/\\S*?/uid/(\\d*)',\n            webpage, 'video uploader_id', fatal=False)\n        upload_date = unified_strdate(self._html_search_regex(\n            r'<li>uploaded: (.*?)</li>', webpage, 'video upload_date',\n            fatal=False))\n        view_count_str = self._html_search_regex(\n            r'<li>Hits: ([0-9]+?)</li>', webpage, 'video view_count',\n            fatal=False)\n        comment_count_str = self._html_search_regex(\n            r'<h2>([0-9]+?) comments</h2>', webpage, 'video comment_count',\n            fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'view_count': int_or_none(view_count_str),\n            'comment_count': int_or_none(comment_count_str),\n        }",
        "begin_line": 30,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.minhateca.MinhatecaIE._real_extract#31",
        "src_path": "youtube_dl/extractor/minhateca.py",
        "class_name": "youtube_dl.extractor.minhateca.MinhatecaIE",
        "signature": "youtube_dl.extractor.minhateca.MinhatecaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        token = self._html_search_regex(\n            r'<input name=\"__RequestVerificationToken\".*?value=\"([^\"]+)\"',\n            webpage, 'request token')\n        token_data = [\n            ('fileId', video_id),\n            ('__RequestVerificationToken', token),\n        ]\n        req = compat_urllib_request.Request(\n            'http://minhateca.com.br/action/License/Download',\n            data=compat_urllib_parse.urlencode(token_data))\n        req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        data = self._download_json(\n            req, video_id, note='Downloading metadata')\n\n        video_url = data['redirectUrl']\n        title_str = self._html_search_regex(\n            r'<h1.*?>(.*?)</h1>', webpage, 'title')\n        title, _, ext = title_str.rpartition('.')\n        filesize_approx = parse_filesize(self._html_search_regex(\n            r'<p class=\"fileSize\">(.*?)</p>',\n            webpage, 'file size approximation', fatal=False))\n        duration = parse_duration(self._html_search_regex(\n            r'(?s)<p class=\"fileLeng[ht][th]\">.*?class=\"bold\">(.*?)<',\n            webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'<p class=\"downloadsCounter\">([0-9]+)</p>',\n            webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'ext': ext,\n            'filesize_approx': filesize_approx,\n            'duration': duration,\n            'view_count': view_count,\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 31,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gameone.GameOneIE._real_extract#59",
        "src_path": "youtube_dl/extractor/gameone.py",
        "class_name": "youtube_dl.extractor.gameone.GameOneIE",
        "signature": "youtube_dl.extractor.gameone.GameOneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        og_video = self._og_search_video_url(webpage, secure=False)\n        description = self._html_search_meta('description', webpage)\n        age_limit = int(\n            self._search_regex(\n                r'age=(\\d+)',\n                self._html_search_meta(\n                    'age-de-meta-label',\n                    webpage),\n                'age_limit',\n                '0'))\n        mrss_url = self._search_regex(r'mrss=([^&]+)', og_video, 'mrss')\n\n        mrss = self._download_xml(mrss_url, video_id, 'Downloading mrss')\n        title = mrss.find('.//item/title').text\n        thumbnail = mrss.find('.//item/image').get('url')\n        timestamp = parse_iso8601(mrss.find('.//pubDate').text, delimiter=' ')\n        content = mrss.find(xpath_with_ns('.//media:content', NAMESPACE_MAP))\n        content_url = content.get('url')\n\n        content = self._download_xml(\n            content_url,\n            video_id,\n            'Downloading media:content')\n        rendition_items = content.findall('.//rendition')\n        duration = float_or_none(rendition_items[0].get('duration'))\n        formats = [\n            {\n                'url': re.sub(r'.*/(r2)', RAW_MP4_URL + r'\\1', r.find('./src').text),\n                'width': int_or_none(r.get('width')),\n                'height': int_or_none(r.get('height')),\n                'tbr': int_or_none(r.get('bitrate')),\n            }\n            for r in rendition_items\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'description': description,\n            'age_limit': age_limit,\n            'timestamp': timestamp,\n        }",
        "begin_line": 59,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gameone.GameOnePlaylistIE._real_extract#122",
        "src_path": "youtube_dl/extractor/gameone.py",
        "class_name": "youtube_dl.extractor.gameone.GameOnePlaylistIE",
        "signature": "youtube_dl.extractor.gameone.GameOnePlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage('http://www.gameone.de/tv', 'TV')\n        max_id = max(map(int, re.findall(r'<a href=\"/tv/(\\d+)\"', webpage)))\n        entries = [\n            self.url_result('http://www.gameone.de/tv/%d' %\n                            video_id, 'GameOne')\n            for video_id in range(max_id, 0, -1)]\n\n        return {\n            '_type': 'playlist',\n            'title': 'GameOne',\n            'entries': entries,\n        }",
        "begin_line": 122,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tvplay.TVPlayIE._real_extract#196",
        "src_path": "youtube_dl/extractor/tvplay.py",
        "class_name": "youtube_dl.extractor.tvplay.TVPlayIE",
        "signature": "youtube_dl.extractor.tvplay.TVPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://playapi.mtgx.tv/v1/videos/%s' % video_id, video_id, 'Downloading video JSON')\n\n        if video['is_geo_blocked']:\n            self.report_warning(\n                'This content might not be available in your country due to copyright reasons')\n\n        streams = self._download_json(\n            'http://playapi.mtgx.tv/v1/videos/stream/%s' % video_id, video_id, 'Downloading streams JSON')\n\n        quality = qualities(['hls', 'medium', 'high'])\n        formats = []\n        for format_id, video_url in streams['streams'].items():\n            if not video_url or not isinstance(video_url, compat_str):\n                continue\n            fmt = {\n                'format_id': format_id,\n                'preference': quality(format_id),\n            }\n            if video_url.startswith('rtmp'):\n                m = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', video_url)\n                if not m:\n                    continue\n                fmt.update({\n                    'ext': 'flv',\n                    'url': m.group('url'),\n                    'app': m.group('app'),\n                    'play_path': m.group('playpath'),\n                })\n            elif video_url.endswith('.f4m'):\n                formats.extend(self._extract_f4m_formats(\n                    video_url + '?hdcore=3.5.0&plugin=aasp-3.5.0.151.81', video_id))\n                continue\n            else:\n                fmt.update({\n                    'url': video_url,\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video['title'],\n            'description': video['description'],\n            'duration': video['duration'],\n            'timestamp': parse_iso8601(video['created_at']),\n            'view_count': video['views']['total'],\n            'age_limit': video.get('age_limit', 0),\n            'formats': formats,\n        }",
        "begin_line": 196,
        "end_line": 249,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.teachingchannel.TeachingChannelIE._real_extract#26",
        "src_path": "youtube_dl/extractor/teachingchannel.py",
        "class_name": "youtube_dl.extractor.teachingchannel.TeachingChannelIE",
        "signature": "youtube_dl.extractor.teachingchannel.TeachingChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        ooyala_code = self._search_regex(\n            r'data-embed-code=\\'(.+?)\\'', webpage, 'ooyala code')\n\n        return OoyalaIE._build_url_result(ooyala_code)",
        "begin_line": 26,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.drtuber.DrTuberIE._real_extract#28",
        "src_path": "youtube_dl/extractor/drtuber.py",
        "class_name": "youtube_dl.extractor.drtuber.DrTuberIE",
        "signature": "youtube_dl.extractor.drtuber.DrTuberIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._html_search_regex(\n            r'<source src=\"([^\"]+)\"', webpage, 'video URL')\n\n        title = self._html_search_regex(\n            [r'<p[^>]+class=\"title_substrate\">([^<]+)</p>', r'<title>([^<]+) - \\d+'],\n            webpage, 'title')\n\n        thumbnail = self._html_search_regex(\n            r'poster=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        def extract_count(id_, name):\n            return str_to_int(self._html_search_regex(\n                r'<span[^>]+(?:class|id)=\"%s\"[^>]*>([\\d,\\.]+)</span>' % id_,\n                webpage, '%s count' % name, fatal=False))\n\n        like_count = extract_count('rate_likes', 'like')\n        dislike_count = extract_count('rate_dislikes', 'dislike')\n        comment_count = extract_count('comments_count', 'comment')\n\n        cats_str = self._search_regex(\n            r'<div[^>]+class=\"categories_list\">(.+?)</div>', webpage, 'categories', fatal=False)\n        categories = [] if not cats_str else re.findall(r'<a title=\"([^\"]+)\"', cats_str)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'categories': categories,\n            'age_limit': self._rta_search(webpage),\n        }",
        "begin_line": 28,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dvtv.DVTVIE._parse_video_metadata#76",
        "src_path": "youtube_dl/extractor/dvtv.py",
        "class_name": "youtube_dl.extractor.dvtv.DVTVIE",
        "signature": "youtube_dl.extractor.dvtv.DVTVIE._parse_video_metadata(self, js, video_id)",
        "snippet": "    def _parse_video_metadata(self, js, video_id):\n        metadata = self._parse_json(js, video_id, transform_source=js_to_json)\n\n        formats = []\n        for video in metadata['sources']:\n            ext = video['type'][6:]\n            formats.append({\n                'url': video['file'],\n                'ext': ext,\n                'format_id': '%s-%s' % (ext, video['label']),\n                'height': int(video['label'].rstrip('p')),\n                'fps': 25,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': metadata['mediaid'],\n            'title': unescapeHTML(metadata['title']),\n            'thumbnail': self._proto_relative_url(metadata['image'], 'http:'),\n            'formats': formats\n        }",
        "begin_line": 76,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dvtv.DVTVIE._real_extract#99",
        "src_path": "youtube_dl/extractor/dvtv.py",
        "class_name": "youtube_dl.extractor.dvtv.DVTVIE",
        "signature": "youtube_dl.extractor.dvtv.DVTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        # single video\n        item = self._search_regex(\n            r\"(?s)embedData[0-9a-f]{32}\\['asset'\\]\\s*=\\s*(\\{.+?\\});\",\n            webpage, 'video', default=None, fatal=False)\n\n        if item:\n            return self._parse_video_metadata(item, video_id)\n\n        # playlist\n        items = re.findall(\n            r\"(?s)BBX\\.context\\.assets\\['[0-9a-f]{32}'\\]\\.push\\(({.+?})\\);\",\n            webpage)\n\n        if items:\n            return {\n                '_type': 'playlist',\n                'id': video_id,\n                'title': self._og_search_title(webpage),\n                'entries': [self._parse_video_metadata(i, video_id) for i in items]\n            }\n\n        raise ExtractorError('Could not find neither video nor playlist')",
        "begin_line": 99,
        "end_line": 125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.embedly.EmbedlyIE._real_extract#15",
        "src_path": "youtube_dl/extractor/embedly.py",
        "class_name": "youtube_dl.extractor.embedly.EmbedlyIE",
        "signature": "youtube_dl.extractor.embedly.EmbedlyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self.url_result(compat_urllib_parse_unquote(self._match_id(url)))",
        "begin_line": 15,
        "end_line": 16,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.traileraddict.TrailerAddictIE._real_extract#22",
        "src_path": "youtube_dl/extractor/traileraddict.py",
        "class_name": "youtube_dl.extractor.traileraddict.TrailerAddictIE",
        "signature": "youtube_dl.extractor.traileraddict.TrailerAddictIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('movie') + '/' + mobj.group('trailer_name')\n        webpage = self._download_webpage(url, name)\n\n        title = self._search_regex(r'<title>(.+?)</title>',\n                                   webpage, 'video title').replace(' - Trailer Addict', '')\n        view_count_str = self._search_regex(\n            r'<span class=\"views_n\">([0-9,.]+)</span>',\n            webpage, 'view count', fatal=False)\n        view_count = (\n            None if view_count_str is None\n            else int(view_count_str.replace(',', '')))\n        video_id = self._search_regex(\n            r'<param\\s+name=\"movie\"\\s+value=\"/emb/([0-9]+)\"\\s*/>',\n            webpage, 'video id')\n\n        # Presence of (no)watchplus function indicates HD quality is available\n        if re.search(r'function (no)?watchplus()', webpage):\n            fvar = \"fvarhd\"\n        else:\n            fvar = \"fvar\"\n\n        info_url = \"http://www.traileraddict.com/%s.php?tid=%s\" % (fvar, str(video_id))\n        info_webpage = self._download_webpage(info_url, video_id, \"Downloading the info webpage\")\n\n        final_url = self._search_regex(r'&fileurl=(.+)',\n                                       info_webpage, 'Download url').replace('%3F', '?')\n        thumbnail_url = self._search_regex(r'&image=(.+?)&',\n                                           info_webpage, 'thumbnail url')\n\n        description = self._html_search_regex(\n            r'(?s)<div class=\"synopsis\">.*?<div class=\"movie_label_info\"[^>]*>(.*?)</div>',\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': thumbnail_url,\n            'description': description,\n            'view_count': view_count,\n        }",
        "begin_line": 22,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nfl.NFLIE.prepend_host#133",
        "src_path": "youtube_dl/extractor/nfl.py",
        "class_name": "youtube_dl.extractor.nfl.NFLIE",
        "signature": "youtube_dl.extractor.nfl.NFLIE.prepend_host(host, url)",
        "snippet": "    def prepend_host(host, url):\n        if not url.startswith('http'):\n            if not url.startswith('/'):\n                url = '/%s' % url\n            url = 'http://{0:}{1:}'.format(host, url)\n        return url",
        "begin_line": 133,
        "end_line": 138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nfl.NFLIE.format_from_stream#141",
        "src_path": "youtube_dl/extractor/nfl.py",
        "class_name": "youtube_dl.extractor.nfl.NFLIE",
        "signature": "youtube_dl.extractor.nfl.NFLIE.format_from_stream(stream, protocol, host, path_prefix='', preference=0, note=None)",
        "snippet": "    def format_from_stream(stream, protocol, host, path_prefix='',\n                           preference=0, note=None):\n        url = '{protocol:}://{host:}/{prefix:}{path:}'.format(\n            protocol=protocol,\n            host=host,\n            prefix=path_prefix,\n            path=stream.get('path'),\n        )\n        return {\n            'url': url,\n            'vbr': int_or_none(stream.get('rate', 0), 1000),\n            'preference': preference,\n            'format_note': note,\n        }",
        "begin_line": 141,
        "end_line": 154,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nfl.NFLIE._real_extract#156",
        "src_path": "youtube_dl/extractor/nfl.py",
        "class_name": "youtube_dl.extractor.nfl.NFLIE",
        "signature": "youtube_dl.extractor.nfl.NFLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id, host = mobj.group('id'), mobj.group('host')\n\n        webpage = self._download_webpage(url, video_id)\n\n        config_url = NFLIE.prepend_host(host, self._search_regex(\n            r'(?:(?:config|configURL)\\s*:\\s*|<nflcs:avplayer[^>]+data-config\\s*=\\s*)([\"\\'])(?P<config>.+?)\\1',\n            webpage, 'config URL', default='static/content/static/config/video/config.json',\n            group='config'))\n        # For articles, the id in the url is not the video id\n        video_id = self._search_regex(\n            r'(?:<nflcs:avplayer[^>]+data-content[Ii]d\\s*=\\s*|content[Ii]d\\s*:\\s*)([\"\\'])(?P<id>.+?)\\1',\n            webpage, 'video id', default=video_id, group='id')\n        config = self._download_json(config_url, video_id, 'Downloading player config')\n        url_template = NFLIE.prepend_host(\n            host, '{contentURLTemplate:}'.format(**config))\n        video_data = self._download_json(\n            url_template.format(id=video_id), video_id)\n\n        formats = []\n        cdn_data = video_data.get('cdnData', {})\n        streams = cdn_data.get('bitrateInfo', [])\n        if cdn_data.get('format') == 'EXTERNAL_HTTP_STREAM':\n            parts = compat_urllib_parse_urlparse(cdn_data.get('uri'))\n            protocol, host = parts.scheme, parts.netloc\n            for stream in streams:\n                formats.append(\n                    NFLIE.format_from_stream(stream, protocol, host))\n        else:\n            cdns = config.get('cdns')\n            if not cdns:\n                raise ExtractorError('Failed to get CDN data', expected=True)\n\n            for name, cdn in cdns.items():\n                # LimeLight streams don't seem to work\n                if cdn.get('name') == 'LIMELIGHT':\n                    continue\n\n                protocol = cdn.get('protocol')\n                host = remove_end(cdn.get('host', ''), '/')\n                if not (protocol and host):\n                    continue\n\n                prefix = cdn.get('pathprefix', '')\n                if prefix and not prefix.endswith('/'):\n                    prefix = '%s/' % prefix\n\n                preference = 0\n                if protocol == 'rtmp':\n                    preference = -2\n                elif 'prog' in name.lower():\n                    preference = 1\n\n                for stream in streams:\n                    formats.append(\n                        NFLIE.format_from_stream(stream, protocol, host,\n                                                 prefix, preference, name))\n\n        self._sort_formats(formats)\n\n        thumbnail = None\n        for q in ('xl', 'l', 'm', 's', 'xs'):\n            thumbnail = video_data.get('imagePaths', {}).get(q)\n            if thumbnail:\n                break\n\n        return {\n            'id': video_id,\n            'title': video_data.get('headline'),\n            'formats': formats,\n            'description': video_data.get('caption'),\n            'duration': video_data.get('duration'),\n            'thumbnail': thumbnail,\n            'timestamp': int_or_none(video_data.get('posted'), 1000),\n        }",
        "begin_line": 156,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tvc.TVCIE._extract_url#28",
        "src_path": "youtube_dl/extractor/tvc.py",
        "class_name": "youtube_dl.extractor.tvc.TVCIE",
        "signature": "youtube_dl.extractor.tvc.TVCIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:http:)?//(?:www\\.)?tvc\\.ru/video/iframe/id/[^\"]+)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 28,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tvc.TVCIE._real_extract#34",
        "src_path": "youtube_dl/extractor/tvc.py",
        "class_name": "youtube_dl.extractor.tvc.TVCIE",
        "signature": "youtube_dl.extractor.tvc.TVCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://www.tvc.ru/video/json/id/%s' % video_id, video_id)\n\n        formats = []\n        for info in video.get('path', {}).get('quality', []):\n            video_url = info.get('url')\n            if not video_url:\n                continue\n            format_id = self._search_regex(\n                r'cdnvideo/([^/]+?)(?:-[^/]+?)?/', video_url,\n                'format id', default=None)\n            formats.append({\n                'url': video_url,\n                'format_id': format_id,\n                'width': int_or_none(info.get('width')),\n                'height': int_or_none(info.get('height')),\n                'tbr': int_or_none(info.get('bitrate')),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video['title'],\n            'thumbnail': video.get('picture'),\n            'duration': int_or_none(video.get('duration')),\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tvc.TVCArticleIE._real_extract#100",
        "src_path": "youtube_dl/extractor/tvc.py",
        "class_name": "youtube_dl.extractor.tvc.TVCArticleIE",
        "signature": "youtube_dl.extractor.tvc.TVCArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, self._match_id(url))\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'TVC',\n            'url': self._og_search_video_url(webpage),\n            'title': clean_html(self._og_search_title(webpage)),\n            'description': clean_html(self._og_search_description(webpage)),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 100,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE.report_disclaimer#107",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE.report_disclaimer(self)",
        "snippet": "    def report_disclaimer(self):\n        self.to_screen('Retrieving disclaimer')",
        "begin_line": 107,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE._real_initialize#110",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        # Retrieve disclaimer\n        self.report_disclaimer()\n        self._download_webpage(self._DISCLAIMER, None, False, 'Unable to retrieve disclaimer')\n\n        # Confirm age\n        disclaimer_form = {\n            'filters': '0',\n            'submit': \"Continue - I'm over 18\",\n        }\n        request = compat_urllib_request.Request(self._FILTER_POST, compat_urllib_parse.urlencode(disclaimer_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        self.report_age_confirmation()\n        self._download_webpage(request, None, False, 'Unable to confirm age')",
        "begin_line": 110,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE._real_extract#125",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract id and simplified title from URL\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n\n        video_id = mobj.group(1)\n\n        # the video may come from an external site\n        m_external = re.match('^(\\w{2})-(.*)$', video_id)\n        if m_external is not None:\n            prefix, ext_id = m_external.groups()\n            # Check if video comes from YouTube\n            if prefix == 'yt':\n                return self.url_result('http://www.youtube.com/watch?v=%s' % ext_id, 'Youtube')\n            # CBS videos use theplatform.com\n            if prefix == 'cb':\n                return self.url_result('theplatform:%s' % ext_id, 'ThePlatform')\n\n        # Retrieve video webpage to extract further information\n        req = compat_urllib_request.Request('http://www.metacafe.com/watch/%s/' % video_id)\n\n        # AnyClip videos require the flashversion cookie so that we get the link\n        # to the mp4 file\n        mobj_an = re.match(r'^an-(.*?)$', video_id)\n        if mobj_an:\n            req.headers['Cookie'] = 'flashVersion=0;'\n        webpage = self._download_webpage(req, video_id)\n\n        # Extract URL, uploader and title from webpage\n        self.report_extraction(video_id)\n        video_url = None\n        mobj = re.search(r'(?m)&mediaURL=([^&]+)', webpage)\n        if mobj is not None:\n            mediaURL = compat_urllib_parse_unquote(mobj.group(1))\n            video_ext = mediaURL[-3:]\n\n            # Extract gdaKey if available\n            mobj = re.search(r'(?m)&gdaKey=(.*?)&', webpage)\n            if mobj is None:\n                video_url = mediaURL\n            else:\n                gdaKey = mobj.group(1)\n                video_url = '%s?__gda__=%s' % (mediaURL, gdaKey)\n        if video_url is None:\n            mobj = re.search(r'<video src=\"([^\"]+)\"', webpage)\n            if mobj:\n                video_url = mobj.group(1)\n                video_ext = 'mp4'\n        if video_url is None:\n            flashvars = self._search_regex(\n                r' name=\"flashvars\" value=\"(.*?)\"', webpage, 'flashvars',\n                default=None)\n            if flashvars:\n                vardict = compat_parse_qs(flashvars)\n                if 'mediaData' not in vardict:\n                    raise ExtractorError('Unable to extract media URL')\n                mobj = re.search(\n                    r'\"mediaURL\":\"(?P<mediaURL>http.*?)\",(.*?)\"key\":\"(?P<key>.*?)\"', vardict['mediaData'][0])\n                if mobj is None:\n                    raise ExtractorError('Unable to extract media URL')\n                mediaURL = mobj.group('mediaURL').replace('\\\\/', '/')\n                video_url = '%s?__gda__=%s' % (mediaURL, mobj.group('key'))\n                video_ext = determine_ext(video_url)\n        if video_url is None:\n            player_url = self._search_regex(\n                r\"swfobject\\.embedSWF\\('([^']+)'\",\n                webpage, 'config URL', default=None)\n            if player_url:\n                config_url = self._search_regex(\n                    r'config=(.+)$', player_url, 'config URL')\n                config_doc = self._download_xml(\n                    config_url, video_id,\n                    note='Downloading video config')\n                smil_url = config_doc.find('.//properties').attrib['smil_file']\n                smil_doc = self._download_xml(\n                    smil_url, video_id,\n                    note='Downloading SMIL document')\n                base_url = smil_doc.find('./head/meta').attrib['base']\n                video_url = []\n                for vn in smil_doc.findall('.//video'):\n                    br = int(vn.attrib['system-bitrate'])\n                    play_path = vn.attrib['src']\n                    video_url.append({\n                        'format_id': 'smil-%d' % br,\n                        'url': base_url,\n                        'play_path': play_path,\n                        'page_url': url,\n                        'player_url': player_url,\n                        'ext': play_path.partition(':')[0],\n                    })\n\n        if video_url is None:\n            raise ExtractorError('Unsupported video type')\n\n        video_title = self._html_search_regex(\n            r'(?im)<title>(.*) - Video</title>', webpage, 'title')\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        video_uploader = self._html_search_regex(\n            r'submitter=(.*?);|googletag\\.pubads\\(\\)\\.setTargeting\\(\"(?:channel|submiter)\",\"([^\"]+)\"\\);',\n            webpage, 'uploader nickname', fatal=False)\n        duration = int_or_none(\n            self._html_search_meta('video:duration', webpage))\n\n        age_limit = (\n            18\n            if re.search(r'\"contentRating\":\"restricted\"', webpage)\n            else 0)\n\n        if isinstance(video_url, list):\n            formats = video_url\n        else:\n            formats = [{\n                'url': video_url,\n                'ext': video_ext,\n            }]\n\n        self._sort_formats(formats)\n        return {\n            'id': video_id,\n            'description': description,\n            'uploader': video_uploader,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'age_limit': age_limit,\n            'formats': formats,\n            'duration': duration,\n        }",
        "begin_line": 125,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.discovery.DiscoveryIE._real_extract#39",
        "src_path": "youtube_dl/extractor/discovery.py",
        "class_name": "youtube_dl.extractor.discovery.DiscoveryIE",
        "signature": "youtube_dl.extractor.discovery.DiscoveryIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        info = self._download_json(url + '?flat=1', video_id)\n\n        video_title = info.get('playlist_title') or info.get('video_title')\n\n        entries = [{\n            'id': compat_str(video_info['id']),\n            'formats': self._extract_m3u8_formats(\n                video_info['src'], video_id, ext='mp4',\n                note='Download m3u8 information for video %d' % (idx + 1)),\n            'title': video_info['title'],\n            'description': video_info.get('description'),\n            'duration': parse_duration(video_info.get('video_length')),\n            'webpage_url': video_info.get('href'),\n            'thumbnail': video_info.get('thumbnailURL'),\n            'alt_title': video_info.get('secondary_title'),\n            'timestamp': parse_iso8601(video_info.get('publishedDate')),\n        } for idx, video_info in enumerate(info['playlist'])]\n\n        return self.playlist_result(entries, video_id, video_title)",
        "begin_line": 39,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._login#34",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor",
        "signature": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return\n        self.report_login()\n        webpage = self._download_webpage(self._LOGIN_URL, None, False)\n        token, vuid = self._extract_xsrft_and_vuid(webpage)\n        data = urlencode_postdata({\n            'action': 'login',\n            'email': username,\n            'password': password,\n            'service': 'vimeo',\n            'token': token,\n        })\n        login_request = compat_urllib_request.Request(self._LOGIN_URL, data)\n        login_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        login_request.add_header('Cookie', 'vuid=%s' % vuid)\n        login_request.add_header('Referer', self._LOGIN_URL)\n        self._download_webpage(login_request, None, False, 'Wrong login info')",
        "begin_line": 34,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._extract_xsrft_and_vuid#56",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor",
        "signature": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._extract_xsrft_and_vuid(self, webpage)",
        "snippet": "    def _extract_xsrft_and_vuid(self, webpage):\n        xsrft = self._search_regex(\n            r'xsrft\\s*[=:]\\s*(?P<q>[\"\\'])(?P<xsrft>.+?)(?P=q)',\n            webpage, 'login token', group='xsrft')\n        vuid = self._search_regex(\n            r'[\"\\']vuid[\"\\']\\s*:\\s*([\"\\'])(?P<vuid>.+?)\\1',\n            webpage, 'vuid', group='vuid')\n        return xsrft, vuid",
        "begin_line": 56,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._extract_vimeo_url#192",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._extract_vimeo_url(url, webpage)",
        "snippet": "    def _extract_vimeo_url(url, webpage):\n        # Look for embedded (iframe) Vimeo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//player\\.vimeo\\.com/video/.+?)\\1', webpage)\n        if mobj:\n            player_url = unescapeHTML(mobj.group('url'))\n            surl = smuggle_url(player_url, {'Referer': url})\n            return surl\n        # Look for embedded (swf embed) Vimeo player\n        mobj = re.search(\n            r'<embed[^>]+?src=\"((?:https?:)?//(?:www\\.)?vimeo\\.com/moogaloop\\.swf.+?)\"', webpage)\n        if mobj:\n            return mobj.group(1)",
        "begin_line": 192,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._verify_video_password#206",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._verify_video_password(self, url, video_id, webpage)",
        "snippet": "    def _verify_video_password(self, url, video_id, webpage):\n        password = self._downloader.params.get('videopassword', None)\n        if password is None:\n            raise ExtractorError('This video is protected by a password, use the --video-password option', expected=True)\n        token, vuid = self._extract_xsrft_and_vuid(webpage)\n        data = urlencode_postdata({\n            'password': password,\n            'token': token,\n        })\n        if url.startswith('http://'):\n            # vimeo only supports https now, but the user can give an http url\n            url = url.replace('http://', 'https://')\n        password_request = compat_urllib_request.Request(url + '/password', data)\n        password_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        password_request.add_header('Cookie', 'clip_test2=1; vuid=%s' % vuid)\n        password_request.add_header('Referer', url)\n        return self._download_webpage(\n            password_request, video_id,\n            'Verifying the password', 'Wrong password')",
        "begin_line": 206,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._verify_player_video_password#226",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._verify_player_video_password(self, url, video_id)",
        "snippet": "    def _verify_player_video_password(self, url, video_id):\n        password = self._downloader.params.get('videopassword', None)\n        if password is None:\n            raise ExtractorError('This video is protected by a password, use the --video-password option')\n        data = compat_urllib_parse.urlencode({'password': password})\n        pass_url = url + '/check-password'\n        password_request = compat_urllib_request.Request(pass_url, data)\n        password_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        return self._download_json(\n            password_request, video_id,\n            'Verifying the password',\n            'Wrong password')",
        "begin_line": 226,
        "end_line": 237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._real_initialize#239",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 239,
        "end_line": 240,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._real_extract#242",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, data = unsmuggle_url(url)\n        headers = std_headers\n        if data is not None:\n            headers = headers.copy()\n            headers.update(data)\n        if 'Referer' not in headers:\n            headers['Referer'] = url\n\n        # Extract ID from URL\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        orig_url = url\n        if mobj.group('pro') or mobj.group('player'):\n            url = 'https://player.vimeo.com/video/' + video_id\n        else:\n            url = 'https://vimeo.com/' + video_id\n\n        # Retrieve video webpage to extract further information\n        request = compat_urllib_request.Request(url, None, headers)\n        try:\n            webpage = self._download_webpage(request, video_id)\n        except ExtractorError as ee:\n            if isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 403:\n                errmsg = ee.cause.read()\n                if b'Because of its privacy settings, this video cannot be played here' in errmsg:\n                    raise ExtractorError(\n                        'Cannot download embed-only video without embedding '\n                        'URL. Please call youtube-dl with the URL of the page '\n                        'that embeds this video.',\n                        expected=True)\n            raise\n\n        # Now we begin extracting as much information as we can from what we\n        # retrieved. First we extract the information common to all extractors,\n        # and latter we extract those that are Vimeo specific.\n        self.report_extraction(video_id)\n\n        vimeo_config = self._search_regex(\n            r'vimeo\\.config\\s*=\\s*(?:({.+?})|_extend\\([^,]+,\\s+({.+?})\\));', webpage,\n            'vimeo config', default=None)\n        if vimeo_config:\n            seed_status = self._parse_json(vimeo_config, video_id).get('seed_status', {})\n            if seed_status.get('state') == 'failed':\n                raise ExtractorError(\n                    '%s said: %s' % (self.IE_NAME, seed_status['title']),\n                    expected=True)\n\n        # Extract the config JSON\n        try:\n            try:\n                config_url = self._html_search_regex(\n                    r' data-config-url=\"(.+?)\"', webpage,\n                    'config URL', default=None)\n                if not config_url:\n                    # Sometimes new react-based page is served instead of old one that require\n                    # different config URL extraction approach (see\n                    # https://github.com/rg3/youtube-dl/pull/7209)\n                    vimeo_clip_page_config = self._search_regex(\n                        r'vimeo\\.clip_page_config\\s*=\\s*({.+?});', webpage,\n                        'vimeo clip page config')\n                    config_url = self._parse_json(\n                        vimeo_clip_page_config, video_id)['player']['config_url']\n                config_json = self._download_webpage(config_url, video_id)\n                config = json.loads(config_json)\n            except RegexNotFoundError:\n                # For pro videos or player.vimeo.com urls\n                # We try to find out to which variable is assigned the config dic\n                m_variable_name = re.search('(\\w)\\.video\\.id', webpage)\n                if m_variable_name is not None:\n                    config_re = r'%s=({[^}].+?});' % re.escape(m_variable_name.group(1))\n                else:\n                    config_re = [r' = {config:({.+?}),assets:', r'(?:[abc])=({.+?});']\n                config = self._search_regex(config_re, webpage, 'info section',\n                                            flags=re.DOTALL)\n                config = json.loads(config)\n        except Exception as e:\n            if re.search('The creator of this video has not given you permission to embed it on this domain.', webpage):\n                raise ExtractorError('The author has restricted the access to this video, try with the \"--referer\" option')\n\n            if re.search(r'<form[^>]+?id=\"pw_form\"', webpage) is not None:\n                if data and '_video_password_verified' in data:\n                    raise ExtractorError('video password verification failed!')\n                self._verify_video_password(url, video_id, webpage)\n                return self._real_extract(\n                    smuggle_url(url, {'_video_password_verified': 'verified'}))\n            else:\n                raise ExtractorError('Unable to extract info section',\n                                     cause=e)\n        else:\n            if config.get('view') == 4:\n                config = self._verify_player_video_password(url, video_id)\n\n        # Extract title\n        video_title = config[\"video\"][\"title\"]\n\n        # Extract uploader and uploader_id\n        video_uploader = config[\"video\"][\"owner\"][\"name\"]\n        video_uploader_id = config[\"video\"][\"owner\"][\"url\"].split('/')[-1] if config[\"video\"][\"owner\"][\"url\"] else None\n\n        # Extract video thumbnail\n        video_thumbnail = config[\"video\"].get(\"thumbnail\")\n        if video_thumbnail is None:\n            video_thumbs = config[\"video\"].get(\"thumbs\")\n            if video_thumbs and isinstance(video_thumbs, dict):\n                _, video_thumbnail = sorted((int(width if width.isdigit() else 0), t_url) for (width, t_url) in video_thumbs.items())[-1]\n\n        # Extract video description\n\n        video_description = self._html_search_regex(\n            r'(?s)<div\\s+class=\"[^\"]*description[^\"]*\"[^>]*>(.*?)</div>',\n            webpage, 'description', default=None)\n        if not video_description:\n            video_description = self._html_search_meta(\n                'description', webpage, default=None)\n        if not video_description and mobj.group('pro'):\n            orig_webpage = self._download_webpage(\n                orig_url, video_id,\n                note='Downloading webpage for description',\n                fatal=False)\n            if orig_webpage:\n                video_description = self._html_search_meta(\n                    'description', orig_webpage, default=None)\n        if not video_description and not mobj.group('player'):\n            self._downloader.report_warning('Cannot find video description')\n\n        # Extract video duration\n        video_duration = int_or_none(config[\"video\"].get(\"duration\"))\n\n        # Extract upload date\n        video_upload_date = None\n        mobj = re.search(r'<time[^>]+datetime=\"([^\"]+)\"', webpage)\n        if mobj is not None:\n            video_upload_date = unified_strdate(mobj.group(1))\n\n        try:\n            view_count = int(self._search_regex(r'UserPlays:(\\d+)', webpage, 'view count'))\n            like_count = int(self._search_regex(r'UserLikes:(\\d+)', webpage, 'like count'))\n            comment_count = int(self._search_regex(r'UserComments:(\\d+)', webpage, 'comment count'))\n        except RegexNotFoundError:\n            # This info is only available in vimeo.com/{id} urls\n            view_count = None\n            like_count = None\n            comment_count = None\n\n        # Vimeo specific: extract request signature and timestamp\n        sig = config['request']['signature']\n        timestamp = config['request']['timestamp']\n\n        # Vimeo specific: extract video codec and quality information\n        # First consider quality, then codecs, then take everything\n        codecs = [('vp6', 'flv'), ('vp8', 'flv'), ('h264', 'mp4')]\n        files = {'hd': [], 'sd': [], 'other': []}\n        config_files = config[\"video\"].get(\"files\") or config[\"request\"].get(\"files\")\n        for codec_name, codec_extension in codecs:\n            for quality in config_files.get(codec_name, []):\n                format_id = '-'.join((codec_name, quality)).lower()\n                key = quality if quality in files else 'other'\n                video_url = None\n                if isinstance(config_files[codec_name], dict):\n                    file_info = config_files[codec_name][quality]\n                    video_url = file_info.get('url')\n                else:\n                    file_info = {}\n                if video_url is None:\n                    video_url = \"http://player.vimeo.com/play_redirect?clip_id=%s&sig=%s&time=%s&quality=%s&codecs=%s&type=moogaloop_local&embed_location=\" \\\n                        % (video_id, sig, timestamp, quality, codec_name.upper())\n\n                files[key].append({\n                    'ext': codec_extension,\n                    'url': video_url,\n                    'format_id': format_id,\n                    'width': int_or_none(file_info.get('width')),\n                    'height': int_or_none(file_info.get('height')),\n                    'tbr': int_or_none(file_info.get('bitrate')),\n                })\n        formats = []\n        m3u8_url = config_files.get('hls', {}).get('all')\n        if m3u8_url:\n            m3u8_formats = self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', 'm3u8_native', 0, 'hls', fatal=False)\n            if m3u8_formats:\n                formats.extend(m3u8_formats)\n        for key in ('other', 'sd', 'hd'):\n            formats += files[key]\n        self._sort_formats(formats)\n\n        subtitles = {}\n        text_tracks = config['request'].get('text_tracks')\n        if text_tracks:\n            for tt in text_tracks:\n                subtitles[tt['lang']] = [{\n                    'ext': 'vtt',\n                    'url': 'https://vimeo.com' + tt['url'],\n                }]\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'uploader_id': video_uploader_id,\n            'upload_date': video_upload_date,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'duration': video_duration,\n            'formats': formats,\n            'webpage_url': url,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'subtitles': subtitles,\n        }",
        "begin_line": 242,
        "end_line": 453,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002564102564102564,
            "pseudo_dstar_susp": 0.0024813895781637717,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0024813895781637717,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._page_url#471",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        return '%s/videos/page:%d/' % (base_url, pagenum)",
        "begin_line": 471,
        "end_line": 472,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_list_title#474",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_list_title(self, webpage)",
        "snippet": "    def _extract_list_title(self, webpage):\n        return self._TITLE or self._html_search_regex(self._TITLE_RE, webpage, 'list title')",
        "begin_line": 474,
        "end_line": 475,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._login_list_password#477",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._login_list_password(self, page_url, list_id, webpage)",
        "snippet": "    def _login_list_password(self, page_url, list_id, webpage):\n        login_form = self._search_regex(\n            r'(?s)<form[^>]+?id=\"pw_form\"(.*?)</form>',\n            webpage, 'login form', default=None)\n        if not login_form:\n            return webpage\n\n        password = self._downloader.params.get('videopassword', None)\n        if password is None:\n            raise ExtractorError('This album is protected by a password, use the --video-password option', expected=True)\n        fields = self._hidden_inputs(login_form)\n        token, vuid = self._extract_xsrft_and_vuid(webpage)\n        fields['token'] = token\n        fields['password'] = password\n        post = urlencode_postdata(fields)\n        password_path = self._search_regex(\n            r'action=\"([^\"]+)\"', login_form, 'password URL')\n        password_url = compat_urlparse.urljoin(page_url, password_path)\n        password_request = compat_urllib_request.Request(password_url, post)\n        password_request.add_header('Content-type', 'application/x-www-form-urlencoded')\n        password_request.add_header('Cookie', 'vuid=%s' % vuid)\n        self._set_cookie('vimeo.com', 'xsrft', token)\n\n        return self._download_webpage(\n            password_request, list_id,\n            'Verifying the password', 'Wrong password')",
        "begin_line": 477,
        "end_line": 502,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_videos#504",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_videos(self, list_id, base_url)",
        "snippet": "    def _extract_videos(self, list_id, base_url):\n        video_ids = []\n        for pagenum in itertools.count(1):\n            page_url = self._page_url(base_url, pagenum)\n            webpage = self._download_webpage(\n                page_url, list_id,\n                'Downloading page %s' % pagenum)\n\n            if pagenum == 1:\n                webpage = self._login_list_password(page_url, list_id, webpage)\n\n            video_ids.extend(re.findall(r'id=\"clip_(\\d+?)\"', webpage))\n            if re.search(self._MORE_PAGES_INDICATOR, webpage, re.DOTALL) is None:\n                break\n\n        entries = [self.url_result('https://vimeo.com/%s' % video_id, 'Vimeo')\n                   for video_id in video_ids]\n        return {'_type': 'playlist',\n                'id': list_id,\n                'title': self._extract_list_title(webpage),\n                'entries': entries,\n                }",
        "begin_line": 504,
        "end_line": 525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._real_extract#527",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id = mobj.group('id')\n        return self._extract_videos(channel_id, 'https://vimeo.com/channels/%s' % channel_id)",
        "begin_line": 527,
        "end_line": 530,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoUserIE._real_extract#546",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoUserIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        return self._extract_videos(name, 'https://vimeo.com/%s' % name)",
        "begin_line": 546,
        "end_line": 549,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoAlbumIE._page_url#576",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoAlbumIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoAlbumIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        return '%s/page:%d/' % (base_url, pagenum)",
        "begin_line": 576,
        "end_line": 577,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoAlbumIE._real_extract#579",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoAlbumIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        album_id = self._match_id(url)\n        return self._extract_videos(album_id, 'https://vimeo.com/album/%s' % album_id)",
        "begin_line": 579,
        "end_line": 581,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoGroupsIE._extract_list_title#596",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoGroupsIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoGroupsIE._extract_list_title(self, webpage)",
        "snippet": "    def _extract_list_title(self, webpage):\n        return self._og_search_title(webpage)",
        "begin_line": 596,
        "end_line": 597,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoGroupsIE._real_extract#599",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoGroupsIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoGroupsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        return self._extract_videos(name, 'https://vimeo.com/groups/%s' % name)",
        "begin_line": 599,
        "end_line": 602,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_extract#632",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoReviewIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        player_url = 'https://player.vimeo.com/player/' + video_id\n        return self.url_result(player_url, 'Vimeo', video_id)",
        "begin_line": 632,
        "end_line": 636,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_initialize#650",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 650,
        "end_line": 651,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._page_url#653",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        url = '%s/page:%d/' % (base_url, pagenum)\n        request = compat_urllib_request.Request(url)\n        # Set the header to get a partial html page with the ids,\n        # the normal page doesn't contain them.\n        request.add_header('X-Requested-With', 'XMLHttpRequest')\n        return request",
        "begin_line": 653,
        "end_line": 659,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_extract#661",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_videos('watchlater', 'https://vimeo.com/watchlater')",
        "begin_line": 661,
        "end_line": 662,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoLikesIE._real_extract#679",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoLikesIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoLikesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        user_id = self._match_id(url)\n        webpage = self._download_webpage(url, user_id)\n        page_count = self._int(\n            self._search_regex(\n                r'''(?x)<li><a\\s+href=\"[^\"]+\"\\s+data-page=\"([0-9]+)\">\n                    .*?</a></li>\\s*<li\\s+class=\"pagination_next\">\n                ''', webpage, 'page count'),\n            'page count', fatal=True)\n        PAGE_SIZE = 12\n        title = self._html_search_regex(\n            r'(?s)<h1>(.+?)</h1>', webpage, 'title', fatal=False)\n        description = self._html_search_meta('description', webpage)\n\n        def _get_page(idx):\n            page_url = 'https://vimeo.com/user%s/likes/page:%d/sort:date' % (\n                user_id, idx + 1)\n            webpage = self._download_webpage(\n                page_url, user_id,\n                note='Downloading page %d/%d' % (idx + 1, page_count))\n            video_list = self._search_regex(\n                r'(?s)<ol class=\"js-browse_list[^\"]+\"[^>]*>(.*?)</ol>',\n                webpage, 'video content')\n            paths = re.findall(\n                r'<li[^>]*>\\s*<a\\s+href=\"([^\"]+)\"', video_list)\n            for path in paths:\n                yield {\n                    '_type': 'url',\n                    'url': compat_urlparse.urljoin(page_url, path),\n                }\n\n        pl = InAdvancePagedList(_get_page, page_count, PAGE_SIZE)\n\n        return {\n            '_type': 'playlist',\n            'id': 'user%s_likes' % user_id,\n            'title': title,\n            'description': description,\n            'entries': pl,\n        }",
        "begin_line": 679,
        "end_line": 718,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gorillavid.GorillaVidIE._real_extract#81",
        "src_path": "youtube_dl/extractor/gorillavid.py",
        "class_name": "youtube_dl.extractor.gorillavid.GorillaVidIE",
        "signature": "youtube_dl.extractor.gorillavid.GorillaVidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        url = 'http://%s/%s' % (mobj.group('host'), video_id)\n        webpage = self._download_webpage(url, video_id)\n\n        if re.search(self._FILE_NOT_FOUND_REGEX, webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        fields = self._hidden_inputs(webpage)\n\n        if fields['op'] == 'download1':\n            countdown = int_or_none(self._search_regex(\n                r'<span id=\"countdown_str\">(?:[Ww]ait)?\\s*<span id=\"cxc\">(\\d+)</span>\\s*(?:seconds?)?</span>',\n                webpage, 'countdown', default=None))\n            if countdown:\n                self._sleep(countdown, video_id)\n\n            post = compat_urllib_parse.urlencode(encode_dict(fields))\n\n            req = compat_urllib_request.Request(url, post)\n            req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n            webpage = self._download_webpage(req, video_id, 'Downloading video page')\n\n        title = self._search_regex(\n            [r'style=\"z-index: [0-9]+;\">([^<]+)</span>', r'<td nowrap>([^<]+)</td>', r'>Watch (.+) '],\n            webpage, 'title', default=None) or self._og_search_title(webpage)\n        video_url = self._search_regex(\n            r'file\\s*:\\s*[\"\\'](http[^\"\\']+)[\"\\'],', webpage, 'file url')\n        thumbnail = self._search_regex(\n            r'image\\s*:\\s*[\"\\'](http[^\"\\']+)[\"\\'],', webpage, 'thumbnail', fatal=False)\n\n        formats = [{\n            'format_id': 'sd',\n            'url': video_url,\n            'quality': 1,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 81,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv._media_xml_tag#22",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv",
        "signature": "youtube_dl.extractor.mtv._media_xml_tag(tag)",
        "snippet": "def _media_xml_tag(tag):\n    return '{http://search.yahoo.com/mrss/}%s' % tag",
        "begin_line": 22,
        "end_line": 23,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._id_from_uri#31",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._id_from_uri(uri)",
        "snippet": "    def _id_from_uri(uri):\n        return uri.split(':')[-1]",
        "begin_line": 31,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._transform_rtmp_url#36",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._transform_rtmp_url(rtmp_video_url)",
        "snippet": "    def _transform_rtmp_url(rtmp_video_url):\n        m = re.match(r'^rtmpe?://.*?/(?P<finalid>gsp\\..+?/.*)$', rtmp_video_url)\n        if not m:\n            return rtmp_video_url\n        base = 'http://viacommtvstrmfs.fplive.net/'\n        return base + m.group('finalid')",
        "begin_line": 36,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_feed_url#43",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_feed_url(self, uri)",
        "snippet": "    def _get_feed_url(self, uri):\n        return self._FEED_URL",
        "begin_line": 43,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_thumbnail_url#46",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_thumbnail_url(self, uri, itemdoc)",
        "snippet": "    def _get_thumbnail_url(self, uri, itemdoc):\n        search_path = '%s/%s' % (_media_xml_tag('group'), _media_xml_tag('thumbnail'))\n        thumb_node = itemdoc.find(search_path)\n        if thumb_node is None:\n            return None\n        else:\n            return thumb_node.attrib['url']",
        "begin_line": 46,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_mobile_video_formats#54",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_mobile_video_formats(self, mtvn_id)",
        "snippet": "    def _extract_mobile_video_formats(self, mtvn_id):\n        webpage_url = self._MOBILE_TEMPLATE % mtvn_id\n        req = compat_urllib_request.Request(webpage_url)\n        # Otherwise we get a webpage that would execute some javascript\n        req.add_header('User-Agent', 'curl/7')\n        webpage = self._download_webpage(req, mtvn_id,\n                                         'Downloading mobile page')\n        metrics_url = unescapeHTML(self._search_regex(r'<a href=\"(http://metrics.+?)\"', webpage, 'url'))\n        req = HEADRequest(metrics_url)\n        response = self._request_webpage(req, mtvn_id, 'Resolving url')\n        url = response.geturl()\n        # Transform the url to get the best quality:\n        url = re.sub(r'.+pxE=mp4', 'http://mtvnmobile.vo.llnwd.net/kip0/_pxn=0+_pxK=18639+_pxE=mp4', url, 1)\n        return [{'url': url, 'ext': 'mp4'}]",
        "begin_line": 54,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_video_formats#69",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_video_formats(self, mdoc, mtvn_id)",
        "snippet": "    def _extract_video_formats(self, mdoc, mtvn_id):\n        if re.match(r'.*/(error_country_block\\.swf|geoblock\\.mp4|copyright_error\\.flv(?:\\?geo\\b.+?)?)$', mdoc.find('.//src').text) is not None:\n            if mtvn_id is not None and self._MOBILE_TEMPLATE is not None:\n                self.to_screen('The normal version is not available from your '\n                               'country, trying with the mobile version')\n                return self._extract_mobile_video_formats(mtvn_id)\n            raise ExtractorError('This video is not available from your country.',\n                                 expected=True)\n\n        formats = []\n        for rendition in mdoc.findall('.//rendition'):\n            try:\n                _, _, ext = rendition.attrib['type'].partition('/')\n                rtmp_video_url = rendition.find('./src').text\n                if rtmp_video_url.endswith('siteunavail.png'):\n                    continue\n                formats.append({\n                    'ext': ext,\n                    'url': self._transform_rtmp_url(rtmp_video_url),\n                    'format_id': rendition.get('bitrate'),\n                    'width': int(rendition.get('width')),\n                    'height': int(rendition.get('height')),\n                })\n            except (KeyError, TypeError):\n                raise ExtractorError('Invalid rendition field.')\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 69,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_subtitles#97",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_subtitles(self, mdoc, mtvn_id)",
        "snippet": "    def _extract_subtitles(self, mdoc, mtvn_id):\n        subtitles = {}\n        for transcript in mdoc.findall('.//transcript'):\n            if transcript.get('kind') != 'captions':\n                continue\n            lang = transcript.get('srclang')\n            subtitles[lang] = [{\n                'url': compat_str(typographic.get('src')),\n                'ext': typographic.get('format')\n            } for typographic in transcript.findall('./typographic')]\n        return subtitles",
        "begin_line": 97,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_video_info#109",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_video_info(self, itemdoc)",
        "snippet": "    def _get_video_info(self, itemdoc):\n        uri = itemdoc.find('guid').text\n        video_id = self._id_from_uri(uri)\n        self.report_extraction(video_id)\n        mediagen_url = itemdoc.find('%s/%s' % (_media_xml_tag('group'), _media_xml_tag('content'))).attrib['url']\n        # Remove the templates, like &device={device}\n        mediagen_url = re.sub(r'&[^=]*?={.*?}(?=(&|$))', '', mediagen_url)\n        if 'acceptMethods' not in mediagen_url:\n            mediagen_url += '&' if '?' in mediagen_url else '?'\n            mediagen_url += 'acceptMethods=fms'\n\n        mediagen_doc = self._download_xml(mediagen_url, video_id,\n                                          'Downloading video urls')\n\n        item = mediagen_doc.find('./video/item')\n        if item is not None and item.get('type') == 'text':\n            message = '%s returned error: ' % self.IE_NAME\n            if item.get('code') is not None:\n                message += '%s - ' % item.get('code')\n            message += item.text\n            raise ExtractorError(message, expected=True)\n\n        description_node = itemdoc.find('description')\n        if description_node is not None:\n            description = description_node.text.strip()\n        else:\n            description = None\n\n        title_el = None\n        if title_el is None:\n            title_el = find_xpath_attr(\n                itemdoc, './/{http://search.yahoo.com/mrss/}category',\n                'scheme', 'urn:mtvn:video_title')\n        if title_el is None:\n            title_el = itemdoc.find('.//{http://search.yahoo.com/mrss/}title')\n        if title_el is None:\n            title_el = itemdoc.find('.//title') or itemdoc.find('./title')\n            if title_el.text is None:\n                title_el = None\n\n        title = title_el.text\n        if title is None:\n            raise ExtractorError('Could not find video title')\n        title = title.strip()\n\n        # This a short id that's used in the webpage urls\n        mtvn_id = None\n        mtvn_id_node = find_xpath_attr(itemdoc, './/{http://search.yahoo.com/mrss/}category',\n                                       'scheme', 'urn:mtvn:id')\n        if mtvn_id_node is not None:\n            mtvn_id = mtvn_id_node.text\n\n        return {\n            'title': title,\n            'formats': self._extract_video_formats(mediagen_doc, mtvn_id),\n            'subtitles': self._extract_subtitles(mediagen_doc, mtvn_id),\n            'id': video_id,\n            'thumbnail': self._get_thumbnail_url(uri, itemdoc),\n            'description': description,\n        }",
        "begin_line": 109,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info#170",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info(self, uri)",
        "snippet": "    def _get_videos_info(self, uri):\n        video_id = self._id_from_uri(uri)\n        feed_url = self._get_feed_url(uri)\n        data = compat_urllib_parse.urlencode({'uri': uri})\n        info_url = feed_url + '?'\n        if self._LANG:\n            info_url += 'lang=%s&' % self._LANG\n        info_url += data\n        return self._get_videos_info_from_url(info_url, video_id)",
        "begin_line": 170,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info_from_url#180",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info_from_url(self, url, video_id)",
        "snippet": "    def _get_videos_info_from_url(self, url, video_id):\n        idoc = self._download_xml(\n            url, video_id,\n            'Downloading info', transform_source=fix_xml_ampersands)\n        return self.playlist_result(\n            [self._get_video_info(item) for item in idoc.findall('.//item')])",
        "begin_line": 180,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._real_extract#187",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = url_basename(url)\n        webpage = self._download_webpage(url, title)\n        try:\n            # the url can be http://media.mtvnservices.com/fb/{mgid}.swf\n            # or http://media.mtvnservices.com/{mgid}\n            og_url = self._og_search_video_url(webpage)\n            mgid = url_basename(og_url)\n            if mgid.endswith('.swf'):\n                mgid = mgid[:-4]\n        except RegexNotFoundError:\n            mgid = None\n\n        if mgid is None or ':' not in mgid:\n            mgid = self._search_regex(\n                [r'data-mgid=\"(.*?)\"', r'swfobject.embedSWF\\(\".*?(mgid:.*?)\"'],\n                webpage, 'mgid', default=None)\n\n        if not mgid:\n            sm4_embed = self._html_search_meta(\n                'sm4:video:embed', webpage, 'sm4 embed', default='')\n            mgid = self._search_regex(\n                r'embed/(mgid:.+?)[\"\\'&?/]', sm4_embed, 'mgid')\n\n        videos_info = self._get_videos_info(mgid)\n        return videos_info",
        "begin_line": 187,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._extract_url#232",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE",
        "signature": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//media.mtvnservices.com/embed/.+?)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 232,
        "end_line": 236,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._get_feed_url#238",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE",
        "signature": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._get_feed_url(self, uri)",
        "snippet": "    def _get_feed_url(self, uri):\n        video_id = self._id_from_uri(uri)\n        site_id = uri.replace(video_id, '')\n        config_url = ('http://media.mtvnservices.com/pmt/e1/players/{0}/'\n                      'context4/context5/config.xml'.format(site_id))\n        config_doc = self._download_xml(config_url, video_id)\n        feed_node = config_doc.find('.//feed')\n        feed_url = feed_node.text.strip().split('?')[0]\n        return feed_url",
        "begin_line": 238,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._real_extract#248",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE",
        "signature": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        mgid = mobj.group('mgid')\n        return self._get_videos_info(mgid)",
        "begin_line": 248,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVIE._get_thumbnail_url#274",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVIE",
        "signature": "youtube_dl.extractor.mtv.MTVIE._get_thumbnail_url(self, uri, itemdoc)",
        "snippet": "    def _get_thumbnail_url(self, uri, itemdoc):\n        return 'http://mtv.mtvnimages.com/uri/' + uri",
        "begin_line": 274,
        "end_line": 275,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVIE._real_extract#277",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVIE",
        "signature": "youtube_dl.extractor.mtv.MTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        uri = mobj.groupdict().get('mgid')\n        if uri is None:\n            webpage = self._download_webpage(url, video_id)\n\n            # Some videos come from Vevo.com\n            m_vevo = re.search(\n                r'(?s)isVevoVideo = true;.*?vevoVideoId = \"(.*?)\";', webpage)\n            if m_vevo:\n                vevo_id = m_vevo.group(1)\n                self.to_screen('Vevo video detected: %s' % vevo_id)\n                return self.url_result('vevo:%s' % vevo_id, ie='Vevo')\n\n            uri = self._html_search_regex(r'/uri/(.*?)\\?', webpage, 'uri')\n        return self._get_videos_info(uri)",
        "begin_line": 277,
        "end_line": 293,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVDEIE._real_extract#352",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVDEIE",
        "signature": "youtube_dl.extractor.mtv.MTVDEIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        playlist = self._parse_json(\n            self._search_regex(\n                r'window\\.pagePlaylist\\s*=\\s*(\\[.+?\\]);\\n', webpage, 'page playlist'),\n            video_id)\n\n        # news pages contain single video in playlist with different id\n        if len(playlist) == 1:\n            return self._get_videos_info_from_url(playlist[0]['mrss'], video_id)\n\n        for item in playlist:\n            item_id = item.get('id')\n            if item_id and compat_str(item_id) == video_id:\n                return self._get_videos_info_from_url(item['mrss'], video_id)",
        "begin_line": 352,
        "end_line": 369,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.myvidster.MyVidsterIE._real_extract#23",
        "src_path": "youtube_dl/extractor/myvidster.py",
        "class_name": "youtube_dl.extractor.myvidster.MyVidsterIE",
        "signature": "youtube_dl.extractor.myvidster.MyVidsterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        return self.url_result(self._html_search_regex(\n            r'rel=\"videolink\" href=\"(?P<real_url>.*)\">',\n            webpage, 'real video url'))",
        "begin_line": 23,
        "end_line": 29,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.moevideo.MoeVideoIE._real_extract#60",
        "src_path": "youtube_dl/extractor/moevideo.py",
        "class_name": "youtube_dl.extractor.moevideo.MoeVideoIE",
        "signature": "youtube_dl.extractor.moevideo.MoeVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(\n            'http://%s/video/%s' % (mobj.group('host'), video_id),\n            video_id, 'Downloading webpage')\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage)\n\n        r = [\n            self._API_KEY,\n            [\n                'preview/flv_link',\n                {\n                    'uid': video_id,\n                },\n            ],\n        ]\n        r_json = json.dumps(r)\n        post = compat_urllib_parse.urlencode({'r': r_json})\n        req = compat_urllib_request.Request(self._API_URL, post)\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n        response = self._download_json(req, video_id)\n        if response['status'] != 'OK':\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, response['data']),\n                expected=True\n            )\n        item = response['data'][0]\n        video_url = item['link']\n        duration = int_or_none(item['length'])\n        width = int_or_none(item['width'])\n        height = int_or_none(item['height'])\n        filesize = int_or_none(item['convert_size'])\n\n        formats = [{\n            'format_id': 'sd',\n            'http_headers': {'Range': 'bytes=0-'},  # Required to download\n            'url': video_url,\n            'width': width,\n            'height': height,\n            'filesize': filesize,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 60,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dumpert.DumpertIE._real_extract#28",
        "src_path": "youtube_dl/extractor/dumpert.py",
        "class_name": "youtube_dl.extractor.dumpert.DumpertIE",
        "signature": "youtube_dl.extractor.dumpert.DumpertIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        url = 'https://www.dumpert.nl/mediabase/' + video_id\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'nsfw=1; cpc=10')\n        webpage = self._download_webpage(req, video_id)\n\n        files_base64 = self._search_regex(\n            r'data-files=\"([^\"]+)\"', webpage, 'data files')\n\n        files = self._parse_json(\n            base64.b64decode(files_base64.encode('utf-8')).decode('utf-8'),\n            video_id)\n\n        quality = qualities(['flv', 'mobile', 'tablet', '720p'])\n\n        formats = [{\n            'url': video_url,\n            'format_id': format_id,\n            'quality': quality(format_id),\n        } for format_id, video_url in files.items() if format_id != 'still']\n        self._sort_formats(formats)\n\n        title = self._html_search_meta(\n            'title', webpage) or self._og_search_title(webpage)\n        description = self._html_search_meta(\n            'description', webpage) or self._og_search_description(webpage)\n        thumbnail = files.get('still') or self._og_search_thumbnail(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats\n        }",
        "begin_line": 28,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ntvru.NTVRuIE._real_extract#85",
        "src_path": "youtube_dl/extractor/ntvru.py",
        "class_name": "youtube_dl.extractor.ntvru.NTVRuIE",
        "signature": "youtube_dl.extractor.ntvru.NTVRuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_id = self._html_search_regex(self._VIDEO_ID_REGEXES, webpage, 'video id')\n\n        player = self._download_xml(\n            'http://www.ntv.ru/vi%s/' % video_id,\n            video_id, 'Downloading video XML')\n        title = clean_html(xpath_text(player, './data/title', 'title', fatal=True))\n        description = clean_html(xpath_text(player, './data/description', 'description'))\n\n        video = player.find('./data/video')\n        video_id = xpath_text(video, './id', 'video id')\n        thumbnail = xpath_text(video, './splash', 'thumbnail')\n        duration = int_or_none(xpath_text(video, './totaltime', 'duration'))\n        view_count = int_or_none(xpath_text(video, './views', 'view count'))\n\n        token = self._download_webpage(\n            'http://stat.ntv.ru/services/access/token',\n            video_id, 'Downloading access token')\n\n        formats = []\n        for format_id in ['', 'hi', 'webm']:\n            file_ = video.find('./%sfile' % format_id)\n            if file_ is None:\n                continue\n            size = video.find('./%ssize' % format_id)\n            formats.append({\n                'url': 'http://media2.ntv.ru/vod/%s&tok=%s' % (file_.text, token),\n                'filesize': int_or_none(size.text if size is not None else None),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 85,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rai.RaiIE._extract_relinker_url#91",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiIE",
        "signature": "youtube_dl.extractor.rai.RaiIE._extract_relinker_url(self, webpage)",
        "snippet": "    def _extract_relinker_url(self, webpage):\n        return self._proto_relative_url(self._search_regex(\n            [r'name=\"videourl\" content=\"([^\"]+)\"', r'var\\s+videoURL(?:_MP4)?\\s*=\\s*\"([^\"]+)\"'],\n            webpage, 'relinker url', default=None))",
        "begin_line": 91,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.rai.RaiIE._real_extract#96",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiIE",
        "signature": "youtube_dl.extractor.rai.RaiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        host = mobj.group('host')\n\n        webpage = self._download_webpage(url, video_id)\n\n        relinker_url = self._extract_relinker_url(webpage)\n\n        if not relinker_url:\n            iframe_url = self._search_regex(\n                [r'<iframe[^>]+src=\"([^\"]*/dl/[^\"]+\\?iframe\\b[^\"]*)\"',\n                 r'drawMediaRaiTV\\([\"\\'](.+?)[\"\\']'],\n                webpage, 'iframe')\n            if not iframe_url.startswith('http'):\n                iframe_url = compat_urlparse.urljoin(url, iframe_url)\n            webpage = self._download_webpage(\n                iframe_url, video_id)\n            relinker_url = self._extract_relinker_url(webpage)\n\n        relinker = self._download_json(\n            '%s&output=47' % relinker_url, video_id)\n\n        media_url = relinker['video'][0]\n        ct = relinker.get('ct')\n        if ct == 'f4m':\n            formats = self._extract_f4m_formats(\n                media_url + '&hdcore=3.7.0&plugin=aasp-3.7.0.39.44', video_id)\n        else:\n            formats = [{\n                'url': media_url,\n                'format_id': ct,\n            }]\n\n        json_link = self._html_search_meta(\n            'jsonlink', webpage, 'JSON link', default=None)\n        if json_link:\n            media = self._download_json(\n                host + json_link, video_id, 'Downloading video JSON')\n            title = media.get('name')\n            description = media.get('desc')\n            thumbnail = media.get('image_300') or media.get('image_medium') or media.get('image')\n            duration = parse_duration(media.get('length'))\n            uploader = media.get('author')\n            upload_date = unified_strdate(media.get('date'))\n        else:\n            title = (self._search_regex(\n                r'var\\s+videoTitolo\\s*=\\s*\"(.+?)\";',\n                webpage, 'title', default=None) or self._og_search_title(webpage)).replace('\\\\\"', '\"')\n            description = self._og_search_description(webpage)\n            thumbnail = self._og_search_thumbnail(webpage)\n            duration = None\n            uploader = self._html_search_meta('Editore', webpage, 'uploader')\n            upload_date = unified_strdate(self._html_search_meta(\n                'item-date', webpage, 'upload date', default=None))\n\n        subtitles = self.extract_subtitles(video_id, webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 96,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.rai.RaiIE._get_subtitles#166",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiIE",
        "signature": "youtube_dl.extractor.rai.RaiIE._get_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_subtitles(self, video_id, webpage):\n        subtitles = {}\n        m = re.search(r'<meta name=\"closedcaption\" content=\"(?P<captions>[^\"]+)\"', webpage)\n        if m:\n            captions = m.group('captions')\n            STL_EXT = '.stl'\n            SRT_EXT = '.srt'\n            if captions.endswith(STL_EXT):\n                captions = captions[:-len(STL_EXT)] + SRT_EXT\n            subtitles['it'] = [{\n                'ext': 'srt',\n                'url': 'http://www.rai.tv%s' % compat_urllib_parse.quote(captions),\n            }]\n        return subtitles",
        "begin_line": 166,
        "end_line": 179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.fragment.HttpQuietDownloader.to_screen#15",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.HttpQuietDownloader",
        "signature": "youtube_dl.downloader.fragment.HttpQuietDownloader.to_screen(self, *args, **kargs)",
        "snippet": "    def to_screen(self, *args, **kargs):\n        pass",
        "begin_line": 15,
        "end_line": 16,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._prepare_and_start_frag_download#24",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._prepare_and_start_frag_download(self, ctx)",
        "snippet": "    def _prepare_and_start_frag_download(self, ctx):\n        self._prepare_frag_download(ctx)\n        self._start_frag_download(ctx)",
        "begin_line": 24,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._prepare_frag_download#28",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._prepare_frag_download(self, ctx)",
        "snippet": "    def _prepare_frag_download(self, ctx):\n        self.to_screen('[%s] Total fragments: %d' % (self.FD_NAME, ctx['total_frags']))\n        self.report_destination(ctx['filename'])\n        dl = HttpQuietDownloader(\n            self.ydl,\n            {\n                'continuedl': True,\n                'quiet': True,\n                'noprogress': True,\n                'ratelimit': self.params.get('ratelimit', None),\n                'retries': self.params.get('retries', 0),\n                'test': self.params.get('test', False),\n            }\n        )\n        tmpfilename = self.temp_name(ctx['filename'])\n        dest_stream, tmpfilename = sanitize_open(tmpfilename, 'wb')\n        ctx.update({\n            'dl': dl,\n            'dest_stream': dest_stream,\n            'tmpfilename': tmpfilename,\n        })",
        "begin_line": 28,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._start_frag_download#50",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._start_frag_download(self, ctx)",
        "snippet": "    def _start_frag_download(self, ctx):\n        total_frags = ctx['total_frags']\n        # This dict stores the download progress, it's updated by the progress\n        # hook\n        state = {\n            'status': 'downloading',\n            'downloaded_bytes': 0,\n            'frag_index': 0,\n            'frag_count': total_frags,\n            'filename': ctx['filename'],\n            'tmpfilename': ctx['tmpfilename'],\n        }\n        start = time.time()\n        ctx['started'] = start\n\n        def frag_progress_hook(s):\n            if s['status'] not in ('downloading', 'finished'):\n                return\n\n            frag_total_bytes = s.get('total_bytes', 0)\n            if s['status'] == 'finished':\n                state['downloaded_bytes'] += frag_total_bytes\n                state['frag_index'] += 1\n\n            estimated_size = (\n                (state['downloaded_bytes'] + frag_total_bytes) /\n                (state['frag_index'] + 1) * total_frags)\n            time_now = time.time()\n            state['total_bytes_estimate'] = estimated_size\n            state['elapsed'] = time_now - start\n\n            if s['status'] == 'finished':\n                progress = self.calc_percent(state['frag_index'], total_frags)\n            else:\n                frag_downloaded_bytes = s['downloaded_bytes']\n                frag_progress = self.calc_percent(frag_downloaded_bytes,\n                                                  frag_total_bytes)\n                progress = self.calc_percent(state['frag_index'], total_frags)\n                progress += frag_progress / float(total_frags)\n\n                state['eta'] = self.calc_eta(\n                    start, time_now, estimated_size, state['downloaded_bytes'] + frag_downloaded_bytes)\n                state['speed'] = s.get('speed')\n            self._hook_progress(state)\n\n        ctx['dl'].add_progress_hook(frag_progress_hook)\n\n        return start",
        "begin_line": 50,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._finish_frag_download#99",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._finish_frag_download(self, ctx)",
        "snippet": "    def _finish_frag_download(self, ctx):\n        ctx['dest_stream'].close()\n        elapsed = time.time() - ctx['started']\n        self.try_rename(ctx['tmpfilename'], ctx['filename'])\n        fsize = os.path.getsize(encodeFilename(ctx['filename']))\n\n        self._hook_progress({\n            'downloaded_bytes': fsize,\n            'total_bytes': fsize,\n            'filename': ctx['filename'],\n            'status': 'finished',\n            'elapsed': elapsed,\n        })",
        "begin_line": 99,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampIE._real_extract#41",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        m_download = re.search(r'freeDownloadPage: \"(.*?)\"', webpage)\n        if not m_download:\n            m_trackinfo = re.search(r'trackinfo: (.+),\\s*?\\n', webpage)\n            if m_trackinfo:\n                json_code = m_trackinfo.group(1)\n                data = json.loads(json_code)[0]\n\n                formats = []\n                for format_id, format_url in data['file'].items():\n                    ext, abr_str = format_id.split('-', 1)\n                    formats.append({\n                        'format_id': format_id,\n                        'url': self._proto_relative_url(format_url, 'http:'),\n                        'ext': ext,\n                        'vcodec': 'none',\n                        'acodec': ext,\n                        'abr': int_or_none(abr_str),\n                    })\n\n                self._sort_formats(formats)\n\n                return {\n                    'id': compat_str(data['id']),\n                    'title': data['title'],\n                    'formats': formats,\n                    'duration': float_or_none(data.get('duration')),\n                }\n            else:\n                raise ExtractorError('No free songs found')\n\n        download_link = m_download.group(1)\n        video_id = self._search_regex(\n            r'(?ms)var TralbumData = .*?[{,]\\s*id: (?P<id>\\d+),?$',\n            webpage, 'video id')\n\n        download_webpage = self._download_webpage(download_link, video_id, 'Downloading free downloads page')\n        # We get the dictionary of the track from some javascript code\n        all_info = self._parse_json(self._search_regex(\n            r'(?sm)items: (.*?),$', download_webpage, 'items'), video_id)\n        info = all_info[0]\n        # We pick mp3-320 for now, until format selection can be easily implemented.\n        mp3_info = info['downloads']['mp3-320']\n        # If we try to use this url it says the link has expired\n        initial_url = mp3_info['url']\n        m_url = re.match(\n            r'(?P<server>http://(.*?)\\.bandcamp\\.com)/download/track\\?enc=mp3-320&fsig=(?P<fsig>.*?)&id=(?P<id>.*?)&ts=(?P<ts>.*)$',\n            initial_url)\n        # We build the url we will use to get the final track url\n        # This url is build in Bandcamp in the script download_bunde_*.js\n        request_url = '%s/statdownload/track?enc=mp3-320&fsig=%s&id=%s&ts=%s&.rand=665028774616&.vrs=1' % (m_url.group('server'), m_url.group('fsig'), video_id, m_url.group('ts'))\n        final_url_webpage = self._download_webpage(request_url, video_id, 'Requesting download url')\n        # If we could correctly generate the .rand field the url would be\n        # in the \"download_url\" key\n        final_url = self._proto_relative_url(self._search_regex(\n            r'\"retry_url\":\"(.+?)\"', final_url_webpage, 'final video URL'), 'http:')\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'ext': 'mp3',\n            'vcodec': 'none',\n            'url': final_url,\n            'thumbnail': info.get('thumb_url'),\n            'uploader': info.get('artist'),\n        }",
        "begin_line": 41,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE._real_extract#163",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader_id = mobj.group('subdomain')\n        album_id = mobj.group('album_id')\n        playlist_id = album_id or uploader_id\n        webpage = self._download_webpage(url, playlist_id)\n        tracks_paths = re.findall(r'<a href=\"(.*?)\" itemprop=\"url\">', webpage)\n        if not tracks_paths:\n            raise ExtractorError('The page doesn\\'t contain any tracks')\n        entries = [\n            self.url_result(compat_urlparse.urljoin(url, t_path), ie=BandcampIE.ie_key())\n            for t_path in tracks_paths]\n        title = self._search_regex(\n            r'album_title\\s*:\\s*\"(.*?)\"', webpage, 'title', fatal=False)\n        return {\n            '_type': 'playlist',\n            'uploader_id': uploader_id,\n            'id': playlist_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 163,
        "end_line": 183,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ninegag.NineGagIE._real_extract#69",
        "src_path": "youtube_dl/extractor/ninegag.py",
        "class_name": "youtube_dl.extractor.ninegag.NineGagIE",
        "signature": "youtube_dl.extractor.ninegag.NineGagIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        post_view = self._parse_json(\n            self._search_regex(\n                r'var\\s+postView\\s*=\\s*new\\s+app\\.PostView\\({\\s*post:\\s*({.+?})\\s*,\\s*posts:\\s*prefetchedCurrentPost',\n                webpage, 'post view'),\n            display_id)\n\n        ie_key = None\n        source_url = post_view.get('sourceUrl')\n        if not source_url:\n            external_video_id = post_view['videoExternalId']\n            external_video_provider = post_view['videoExternalProvider']\n            source_url = self._EXTERNAL_VIDEO_PROVIDER[external_video_provider]['url'] % external_video_id\n            ie_key = self._EXTERNAL_VIDEO_PROVIDER[external_video_provider]['ie_key']\n        title = post_view['title']\n        description = post_view.get('description')\n        view_count = str_to_int(post_view.get('externalView'))\n        thumbnail = post_view.get('thumbnail_700w') or post_view.get('ogImageUrl') or post_view.get('thumbnail_300w')\n\n        return {\n            '_type': 'url_transparent',\n            'url': source_url,\n            'ie_key': ie_key,\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'view_count': view_count,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 69,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gamestar.GameStarIE._real_extract#31",
        "src_path": "youtube_dl/extractor/gamestar.py",
        "class_name": "youtube_dl.extractor.gamestar.GameStarIE",
        "signature": "youtube_dl.extractor.gamestar.GameStarIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        og_title = self._og_search_title(webpage)\n        title = re.sub(r'\\s*- Video (bei|-) GameStar\\.de$', '', og_title)\n\n        url = 'http://gamestar.de/_misc/videos/portal/getVideoUrl.cfm?premium=0&videoId=' + video_id\n\n        description = self._og_search_description(webpage).strip()\n\n        thumbnail = self._proto_relative_url(\n            self._og_search_thumbnail(webpage), scheme='http:')\n\n        upload_date = unified_strdate(self._html_search_regex(\n            r'<span style=\"float:left;font-size:11px;\">Datum: ([0-9]+\\.[0-9]+\\.[0-9]+)&nbsp;&nbsp;',\n            webpage, 'upload_date', fatal=False))\n\n        duration = parse_duration(self._html_search_regex(\n            r'&nbsp;&nbsp;L\u00e4nge: ([0-9]+:[0-9]+)</span>', webpage, 'duration',\n            fatal=False))\n\n        view_count = str_to_int(self._html_search_regex(\n            r'&nbsp;&nbsp;Zuschauer: ([0-9\\.]+)&nbsp;&nbsp;', webpage,\n            'view_count', fatal=False))\n\n        comment_count = int_or_none(self._html_search_regex(\n            r'>Kommentieren \\(([0-9]+)\\)</a>', webpage, 'comment_count',\n            fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': url,\n            'ext': 'mp4',\n            'thumbnail': thumbnail,\n            'description': description,\n            'upload_date': upload_date,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count\n        }",
        "begin_line": 31,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sandia.SandiaIE._real_extract#37",
        "src_path": "youtube_dl/extractor/sandia.py",
        "class_name": "youtube_dl.extractor.sandia.SandiaIE",
        "signature": "youtube_dl.extractor.sandia.SandiaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'MediasitePlayerCaps=ClientPlugins=4')\n        webpage = self._download_webpage(req, video_id)\n\n        js_path = self._search_regex(\n            r'<script type=\"text/javascript\" src=\"(/Mediasite/FileServer/Presentation/[^\"]+)\"',\n            webpage, 'JS code URL')\n        js_url = compat_urlparse.urljoin(url, js_path)\n\n        js_code = self._download_webpage(\n            js_url, video_id, note='Downloading player')\n\n        def extract_str(key, **args):\n            return self._search_regex(\n                r'Mediasite\\.PlaybackManifest\\.%s\\s*=\\s*(.+);\\s*?\\n' % re.escape(key),\n                js_code, key, **args)\n\n        def extract_data(key, **args):\n            data_json = extract_str(key, **args)\n            if data_json is None:\n                return data_json\n            return self._parse_json(\n                data_json, video_id, transform_source=js_to_json)\n\n        formats = []\n        for i in itertools.count():\n            fd = extract_data('VideoUrls[%d]' % i, default=None)\n            if fd is None:\n                break\n            formats.append({\n                'format_id': '%s' % i,\n                'format_note': fd['MimeType'].partition('/')[2],\n                'ext': mimetype2ext(fd['MimeType']),\n                'url': fd['Location'],\n                'protocol': 'f4m' if fd['MimeType'] == 'video/x-mp4-fragmented' else None,\n            })\n        self._sort_formats(formats)\n\n        slide_baseurl = compat_urlparse.urljoin(\n            url, extract_data('SlideBaseUrl'))\n        slide_template = slide_baseurl + re.sub(\n            r'\\{0:D?([0-9+])\\}', r'%0\\1d', extract_data('SlideImageFileNameTemplate'))\n        slides = []\n        last_slide_time = 0\n        for i in itertools.count(1):\n            sd = extract_str('Slides[%d]' % i, default=None)\n            if sd is None:\n                break\n            timestamp = int_or_none(self._search_regex(\n                r'^Mediasite\\.PlaybackManifest\\.CreateSlide\\(\"[^\"]*\"\\s*,\\s*([0-9]+),',\n                sd, 'slide %s timestamp' % i, fatal=False))\n            slides.append({\n                'url': slide_template % i,\n                'duration': timestamp - last_slide_time,\n            })\n            last_slide_time = timestamp\n        formats.append({\n            'format_id': 'slides',\n            'protocol': 'slideshow',\n            'url': json.dumps(slides),\n            'preference': -10000,  # Downloader not yet written\n        })\n        self._sort_formats(formats)\n\n        title = extract_data('Title')\n        description = extract_data('Description', fatal=False)\n        duration = int_or_none(extract_data(\n            'Duration', fatal=False), scale=1000)\n        upload_date = unified_strdate(extract_data('AirDate', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n            'upload_date': upload_date,\n            'duration': duration,\n        }",
        "begin_line": 37,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.senateisvp.SenateISVPIE._search_iframe_url#82",
        "src_path": "youtube_dl/extractor/senateisvp.py",
        "class_name": "youtube_dl.extractor.senateisvp.SenateISVPIE",
        "signature": "youtube_dl.extractor.senateisvp.SenateISVPIE._search_iframe_url(webpage)",
        "snippet": "    def _search_iframe_url(webpage):\n        mobj = re.search(\n            r\"<iframe[^>]+src=['\\\"](?P<url>http://www\\.senate\\.gov/isvp/?\\?[^'\\\"]+)['\\\"]\",\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 82,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.senateisvp.SenateISVPIE._get_info_for_comm#89",
        "src_path": "youtube_dl/extractor/senateisvp.py",
        "class_name": "youtube_dl.extractor.senateisvp.SenateISVPIE",
        "signature": "youtube_dl.extractor.senateisvp.SenateISVPIE._get_info_for_comm(self, committee)",
        "snippet": "    def _get_info_for_comm(self, committee):\n        for entry in self._COMM_MAP:\n            if entry[0] == committee:\n                return entry[1:]",
        "begin_line": 89,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.senateisvp.SenateISVPIE._real_extract#94",
        "src_path": "youtube_dl/extractor/senateisvp.py",
        "class_name": "youtube_dl.extractor.senateisvp.SenateISVPIE",
        "signature": "youtube_dl.extractor.senateisvp.SenateISVPIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        qs = compat_parse_qs(re.match(self._VALID_URL, url).group('qs'))\n        if not qs.get('filename') or not qs.get('type') or not qs.get('comm'):\n            raise ExtractorError('Invalid URL', expected=True)\n\n        video_id = re.sub(r'.mp4$', '', qs['filename'][0])\n\n        webpage = self._download_webpage(url, video_id)\n\n        if smuggled_data.get('force_title'):\n            title = smuggled_data['force_title']\n        else:\n            title = self._html_search_regex(r'<title>([^<]+)</title>', webpage, video_id)\n        poster = qs.get('poster')\n        thumbnail = poster[0] if poster else None\n\n        video_type = qs['type'][0]\n        committee = video_type if video_type == 'arch' else qs['comm'][0]\n        stream_num, domain = self._get_info_for_comm(committee)\n\n        formats = []\n        if video_type == 'arch':\n            filename = video_id if '.' in video_id else video_id + '.mp4'\n            formats = [{\n                # All parameters in the query string are necessary to prevent a 403 error\n                'url': compat_urlparse.urljoin(domain, filename) + '?v=3.1.0&fp=&r=&g=',\n            }]\n        else:\n            hdcore_sign = 'hdcore=3.1.0'\n            url_params = (domain, video_id, stream_num)\n            f4m_url = '%s/z/%s_1@%s/manifest.f4m?' % url_params + hdcore_sign\n            m3u8_url = '%s/i/%s_1@%s/master.m3u8' % url_params\n            for entry in self._extract_f4m_formats(f4m_url, video_id, f4m_id='f4m'):\n                # URLs without the extra param induce an 404 error\n                entry.update({'extra_param_to_segment_url': hdcore_sign})\n                formats.append(entry)\n            for entry in self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4', m3u8_id='m3u8'):\n                mobj = re.search(r'(?P<tag>(?:-p|-b)).m3u8', entry['url'])\n                if mobj:\n                    entry['format_id'] += mobj.group('tag')\n                formats.append(entry)\n\n            self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 94,
        "end_line": 145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.promptfile.PromptFileIE._real_extract#30",
        "src_path": "youtube_dl/extractor/promptfile.py",
        "class_name": "youtube_dl.extractor.promptfile.PromptFileIE",
        "signature": "youtube_dl.extractor.promptfile.PromptFileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        if re.search(r'<div.+id=\"not_found_msg\".+>(?!We are).+</div>[^-]', webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id,\n                                 expected=True)\n\n        fields = self._hidden_inputs(webpage)\n        post = compat_urllib_parse.urlencode(fields)\n        req = compat_urllib_request.Request(url, post)\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n        webpage = self._download_webpage(\n            req, video_id, 'Downloading video page')\n\n        url = self._html_search_regex(r'url:\\s*\\'([^\\']+)\\'', webpage, 'URL')\n        title = self._html_search_regex(\n            r'<span.+title=\"([^\"]+)\">', webpage, 'title')\n        thumbnail = self._html_search_regex(\n            r'<div id=\"player_overlay\">.*button>.*?<img src=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False, flags=re.DOTALL)\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n            'ext': determine_ext(title),\n        }]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yinyuetai.YinYueTaiIE._real_extract#28",
        "src_path": "youtube_dl/extractor/yinyuetai.py",
        "class_name": "youtube_dl.extractor.yinyuetai.YinYueTaiIE",
        "signature": "youtube_dl.extractor.yinyuetai.YinYueTaiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_json(\n            'http://ext.yinyuetai.com/main/get-h-mv-info?json=true&videoId=%s' % video_id, video_id,\n            'Downloading mv info')['videoInfo']['coreVideoInfo']\n\n        if info['error']:\n            raise ExtractorError(info['errorMsg'], expected=True)\n\n        formats = [{\n            'url': format_info['videoUrl'],\n            'format_id': format_info['qualityLevel'],\n            'format': format_info.get('qualityLevelName'),\n            'filesize': format_info.get('fileSize'),\n            # though URLs ends with .flv, the downloaded files are in fact mp4\n            'ext': 'mp4',\n            'tbr': format_info.get('bitrate'),\n        } for format_info in info['videoUrlModels']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info['videoName'],\n            'thumbnail': info.get('bigHeadImage'),\n            'creator': info.get('artistNames'),\n            'duration': info.get('duration'),\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.videolecturesnet.VideoLecturesNetIE._real_extract#56",
        "src_path": "youtube_dl/extractor/videolecturesnet.py",
        "class_name": "youtube_dl.extractor.videolecturesnet.VideoLecturesNetIE",
        "signature": "youtube_dl.extractor.videolecturesnet.VideoLecturesNetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        smil_url = 'http://videolectures.net/%s/video/1/smil.xml' % video_id\n\n        try:\n            smil = self._download_smil(smil_url, video_id)\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 404:\n                # Probably a playlist\n                webpage = self._download_webpage(url, video_id)\n                entries = [\n                    self.url_result(compat_urlparse.urljoin(url, video_url), 'VideoLecturesNet')\n                    for _, video_url in re.findall(r'<a[^>]+href=([\"\\'])(.+?)\\1[^>]+id=[\"\\']lec=\\d+', webpage)]\n                playlist_title = self._html_search_meta('title', webpage, 'title', fatal=True)\n                playlist_description = self._html_search_meta('description', webpage, 'description')\n                return self.playlist_result(entries, video_id, playlist_title, playlist_description)\n\n        info = self._parse_smil(smil, smil_url, video_id)\n\n        info['id'] = video_id\n\n        switch = smil.find('.//switch')\n        if switch is not None:\n            info['duration'] = parse_duration(switch.attrib.get('dur'))\n\n        return info",
        "begin_line": 56,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.imgur.ImgurIE._real_extract#36",
        "src_path": "youtube_dl/extractor/imgur.py",
        "class_name": "youtube_dl.extractor.imgur.ImgurIE",
        "signature": "youtube_dl.extractor.imgur.ImgurIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            compat_urlparse.urljoin(url, video_id), video_id)\n\n        width = int_or_none(self._search_regex(\n            r'<param name=\"width\" value=\"([0-9]+)\"',\n            webpage, 'width', fatal=False))\n        height = int_or_none(self._search_regex(\n            r'<param name=\"height\" value=\"([0-9]+)\"',\n            webpage, 'height', fatal=False))\n\n        video_elements = self._search_regex(\n            r'(?s)<div class=\"video-elements\">(.*?)</div>',\n            webpage, 'video elements', default=None)\n        if not video_elements:\n            raise ExtractorError(\n                'No sources found for video %s. Maybe an image?' % video_id,\n                expected=True)\n\n        formats = []\n        for m in re.finditer(r'<source\\s+src=\"(?P<src>[^\"]+)\"\\s+type=\"(?P<type>[^\"]+)\"', video_elements):\n            formats.append({\n                'format_id': m.group('type').partition('/')[2],\n                'url': self._proto_relative_url(m.group('src')),\n                'ext': mimetype2ext(m.group('type')),\n                'acodec': 'none',\n                'width': width,\n                'height': height,\n                'http_headers': {\n                    'User-Agent': 'youtube-dl (like wget)',\n                },\n            })\n\n        gif_json = self._search_regex(\n            r'(?s)var\\s+videoItem\\s*=\\s*(\\{.*?\\})',\n            webpage, 'GIF code', fatal=False)\n        if gif_json:\n            gifd = self._parse_json(\n                gif_json, video_id, transform_source=js_to_json)\n            formats.append({\n                'format_id': 'gif',\n                'preference': -10,\n                'width': width,\n                'height': height,\n                'ext': 'gif',\n                'acodec': 'none',\n                'vcodec': 'gif',\n                'container': 'gif',\n                'url': self._proto_relative_url(gifd['gifUrl']),\n                'filesize': gifd.get('size'),\n                'http_headers': {\n                    'User-Agent': 'youtube-dl (like wget)',\n                },\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'title': self._og_search_title(webpage),\n        }",
        "begin_line": 36,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.imgur.ImgurAlbumIE._real_extract#113",
        "src_path": "youtube_dl/extractor/imgur.py",
        "class_name": "youtube_dl.extractor.imgur.ImgurAlbumIE",
        "signature": "youtube_dl.extractor.imgur.ImgurAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        album_id = self._match_id(url)\n\n        album_images = self._download_json(\n            'http://imgur.com/gallery/%s/album_images/hit.json?all=true' % album_id,\n            album_id)['data']['images']\n\n        entries = [\n            self.url_result('http://imgur.com/%s' % image['hash'])\n            for image in album_images if image.get('hash')]\n\n        return self.playlist_result(entries, album_id)",
        "begin_line": 113,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.playvid.PlayvidIE._real_extract#30",
        "src_path": "youtube_dl/extractor/playvid.py",
        "class_name": "youtube_dl.extractor.playvid.PlayvidIE",
        "signature": "youtube_dl.extractor.playvid.PlayvidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        m_error = re.search(\n            r'<div class=\"block-error\">\\s*<div class=\"heading\">\\s*<div>(?P<msg>.+?)</div>\\s*</div>', webpage)\n        if m_error:\n            raise ExtractorError(clean_html(m_error.group('msg')), expected=True)\n\n        video_title = None\n        duration = None\n        video_thumbnail = None\n        formats = []\n\n        # most of the information is stored in the flashvars\n        flashvars = self._html_search_regex(\n            r'flashvars=\"(.+?)\"', webpage, 'flashvars')\n\n        infos = compat_urllib_parse_unquote(flashvars).split(r'&')\n        for info in infos:\n            videovars_match = re.match(r'^video_vars\\[(.+?)\\]=(.+?)$', info)\n            if videovars_match:\n                key = videovars_match.group(1)\n                val = videovars_match.group(2)\n\n                if key == 'title':\n                    video_title = compat_urllib_parse_unquote_plus(val)\n                if key == 'duration':\n                    try:\n                        duration = int(val)\n                    except ValueError:\n                        pass\n                if key == 'big_thumb':\n                    video_thumbnail = val\n\n                videourl_match = re.match(\n                    r'^video_urls\\]\\[(?P<resolution>[0-9]+)p', key)\n                if videourl_match:\n                    height = int(videourl_match.group('resolution'))\n                    formats.append({\n                        'height': height,\n                        'url': val,\n                    })\n        self._sort_formats(formats)\n\n        # Extract title - should be in the flashvars; if not, look elsewhere\n        if video_title is None:\n            video_title = self._html_search_regex(\n                r'<title>(.*?)</title', webpage, 'title')\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'duration': duration,\n            'description': None,\n            'age_limit': 18\n        }",
        "begin_line": 30,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nerdist.NerdistIE._real_extract#31",
        "src_path": "youtube_dl/extractor/nerdist.py",
        "class_name": "youtube_dl.extractor.nerdist.NerdistIE",
        "signature": "youtube_dl.extractor.nerdist.NerdistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            r'''(?x)<script\\s+(?:type=\"text/javascript\"\\s+)?\n                src=\"https?://content\\.nerdist\\.com/players/([a-zA-Z0-9_]+)-''',\n            webpage, 'video ID')\n        timestamp = parse_iso8601(self._html_search_meta(\n            'shareaholic:article_published_time', webpage, 'upload date'))\n        uploader = self._html_search_meta(\n            'shareaholic:article_author_name', webpage, 'article author')\n\n        doc = self._download_xml(\n            'http://content.nerdist.com/jw6/%s.xml' % video_id, video_id)\n        video_info = doc.find('.//item')\n        title = xpath_text(video_info, './title', fatal=True)\n        description = xpath_text(video_info, './description')\n        thumbnail = xpath_text(\n            video_info, './{http://rss.jwpcdn.com/}image', 'thumbnail')\n\n        formats = []\n        for source in video_info.findall('./{http://rss.jwpcdn.com/}source'):\n            vurl = source.attrib['file']\n            ext = determine_ext(vurl)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    vurl, video_id, entry_protocol='m3u8_native', ext='mp4',\n                    preference=0))\n            elif ext == 'smil':\n                formats.extend(self._extract_smil_formats(\n                    vurl, video_id, fatal=False\n                ))\n            else:\n                formats.append({\n                    'format_id': ext,\n                    'url': vurl,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'formats': formats,\n            'uploader': uploader,\n        }",
        "begin_line": 31,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.streamcloud.StreamcloudIE._real_extract#28",
        "src_path": "youtube_dl/extractor/streamcloud.py",
        "class_name": "youtube_dl.extractor.streamcloud.StreamcloudIE",
        "signature": "youtube_dl.extractor.streamcloud.StreamcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        url = 'http://streamcloud.eu/%s' % video_id\n\n        orig_webpage = self._download_webpage(url, video_id)\n\n        fields = re.findall(r'''(?x)<input\\s+\n            type=\"(?:hidden|submit)\"\\s+\n            name=\"([^\"]+)\"\\s+\n            (?:id=\"[^\"]+\"\\s+)?\n            value=\"([^\"]*)\"\n            ''', orig_webpage)\n        post = compat_urllib_parse.urlencode(fields)\n\n        self._sleep(12, video_id)\n        headers = {\n            b'Content-Type': b'application/x-www-form-urlencoded',\n        }\n        req = compat_urllib_request.Request(url, post, headers)\n\n        webpage = self._download_webpage(\n            req, video_id, note='Downloading video page ...')\n        title = self._html_search_regex(\n            r'<h1[^>]*>([^<]+)<', webpage, 'title')\n        video_url = self._search_regex(\n            r'file:\\s*\"([^\"]+)\"', webpage, 'video URL')\n        thumbnail = self._search_regex(\n            r'image:\\s*\"([^\"]+)\"', webpage, 'thumbnail URL', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 28,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.comcarcoff.ComCarCoffIE._real_extract#28",
        "src_path": "youtube_dl/extractor/comcarcoff.py",
        "class_name": "youtube_dl.extractor.comcarcoff.ComCarCoffIE",
        "signature": "youtube_dl.extractor.comcarcoff.ComCarCoffIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        if not display_id:\n            display_id = 'comediansincarsgettingcoffee.com'\n        webpage = self._download_webpage(url, display_id)\n\n        full_data = json.loads(self._search_regex(\n            r'<script type=\"application/json\" id=\"videoData\">(?P<json>.+?)</script>',\n            webpage, 'full data json'))\n\n        video_id = full_data['activeVideo']['video']\n        video_data = full_data.get('videos', {}).get(video_id) or full_data['singleshots'][video_id]\n        thumbnails = [{\n            'url': video_data['images']['thumb'],\n        }, {\n            'url': video_data['images']['poster'],\n        }]\n        formats = self._extract_m3u8_formats(\n            video_data['mediaUrl'], video_id, ext='mp4')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': video_data['title'],\n            'description': video_data.get('description'),\n            'timestamp': parse_iso8601(video_data.get('pubDate')),\n            'thumbnails': thumbnails,\n            'formats': formats,\n            'webpage_url': 'http://comediansincarsgettingcoffee.com/%s' % (video_data.get('urlSlug', video_data.get('slug'))),\n        }",
        "begin_line": 28,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.reverbnation.ReverbNationIE._real_extract#24",
        "src_path": "youtube_dl/extractor/reverbnation.py",
        "class_name": "youtube_dl.extractor.reverbnation.ReverbNationIE",
        "signature": "youtube_dl.extractor.reverbnation.ReverbNationIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        song_id = mobj.group('id')\n\n        api_res = self._download_json(\n            'https://api.reverbnation.com/song/%s' % song_id,\n            song_id,\n            note='Downloading information of song %s' % song_id\n        )\n\n        return {\n            'id': song_id,\n            'title': api_res.get('name'),\n            'url': api_res.get('url'),\n            'uploader': api_res.get('artist', {}).get('name'),\n            'uploader_id': str_or_none(api_res.get('artist', {}).get('id')),\n            'thumbnail': self._proto_relative_url(\n                api_res.get('image', api_res.get('thumbnail'))),\n            'ext': 'mp3',\n            'vcodec': 'none',\n        }",
        "begin_line": 24,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.udn.UDNEmbedIE._real_extract#34",
        "src_path": "youtube_dl/extractor/udn.py",
        "class_name": "youtube_dl.extractor.udn.UDNEmbedIE",
        "signature": "youtube_dl.extractor.udn.UDNEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        page = self._download_webpage(url, video_id)\n\n        options = json.loads(js_to_json(self._html_search_regex(\n            r'var options\\s*=\\s*([^;]+);', page, 'video urls dictionary')))\n\n        video_urls = options['video']\n\n        if video_urls.get('youtube'):\n            return self.url_result(video_urls.get('youtube'), 'Youtube')\n\n        try:\n            del video_urls['youtube']\n        except KeyError:\n            pass\n\n        formats = [{\n            'url': self._download_webpage(\n                compat_urlparse.urljoin(url, api_url), video_id,\n                'retrieve url for %s video' % video_type),\n            'format_id': video_type,\n            'preference': 0 if video_type == 'mp4' else -1,\n        } for video_type, api_url in video_urls.items() if api_url]\n\n        if not formats:\n            raise ExtractorError('No videos found', expected=True)\n\n        self._sort_formats(formats)\n\n        thumbnail = None\n\n        if options.get('gallery') and len(options['gallery']):\n            thumbnail = options['gallery'][0].get('original')\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': options['title'],\n            'thumbnail': thumbnail\n        }",
        "begin_line": 34,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.odnoklassniki.OdnoklassnikiIE._real_extract#74",
        "src_path": "youtube_dl/extractor/odnoklassniki.py",
        "class_name": "youtube_dl.extractor.odnoklassniki.OdnoklassnikiIE",
        "signature": "youtube_dl.extractor.odnoklassniki.OdnoklassnikiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://ok.ru/video/%s' % video_id, video_id)\n\n        error = self._search_regex(\n            r'[^>]+class=\"vp_video_stub_txt\"[^>]*>([^<]+)<',\n            webpage, 'error', default=None)\n        if error:\n            raise ExtractorError(error, expected=True)\n\n        player = self._parse_json(\n            unescapeHTML(self._search_regex(\n                r'data-options=(?P<quote>[\"\\'])(?P<player>{.+?%s.+?})(?P=quote)' % video_id,\n                webpage, 'player', group='player')),\n            video_id)\n\n        flashvars = player['flashvars']\n\n        metadata = flashvars.get('metadata')\n        if metadata:\n            metadata = self._parse_json(metadata, video_id)\n        else:\n            metadata = self._download_json(\n                compat_urllib_parse_unquote(flashvars['metadataUrl']),\n                video_id, 'Downloading metadata JSON')\n\n        movie = metadata['movie']\n        title = movie['title']\n        thumbnail = movie.get('poster')\n        duration = int_or_none(movie.get('duration'))\n\n        author = metadata.get('author', {})\n        uploader_id = author.get('id')\n        uploader = author.get('name')\n\n        upload_date = unified_strdate(self._html_search_meta(\n            'ya:ovs:upload_date', webpage, 'upload date', default=None))\n\n        age_limit = None\n        adult = self._html_search_meta(\n            'ya:ovs:adult', webpage, 'age limit', default=None)\n        if adult:\n            age_limit = 18 if adult == 'true' else 0\n\n        like_count = int_or_none(metadata.get('likeCount'))\n\n        info = {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'upload_date': upload_date,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'like_count': like_count,\n            'age_limit': age_limit,\n        }\n\n        if metadata.get('provider') == 'USER_YOUTUBE':\n            info.update({\n                '_type': 'url_transparent',\n                'url': movie['contentId'],\n            })\n            return info\n\n        quality = qualities(('mobile', 'lowest', 'low', 'sd', 'hd'))\n\n        formats = [{\n            'url': f['url'],\n            'ext': 'mp4',\n            'format_id': f['name'],\n            'quality': quality(f['name']),\n        } for f in metadata['videos']]\n        self._sort_formats(formats)\n\n        info['formats'] = formats\n        return info",
        "begin_line": 74,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.esri.EsriVideoIE._real_extract#31",
        "src_path": "youtube_dl/extractor/esri.py",
        "class_name": "youtube_dl.extractor.esri.EsriVideoIE",
        "signature": "youtube_dl.extractor.esri.EsriVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        formats = []\n        for width, height, content in re.findall(\n                r'(?s)<li><strong>(\\d+)x(\\d+):</strong>(.+?)</li>', webpage):\n            for video_url, ext, filesize in re.findall(\n                    r'<a[^>]+href=\"([^\"]+)\">([^<]+)&nbsp;\\(([^<]+)\\)</a>', content):\n                formats.append({\n                    'url': compat_urlparse.urljoin(url, video_url),\n                    'ext': ext.lower(),\n                    'format_id': '%s-%s' % (ext.lower(), height),\n                    'width': int(width),\n                    'height': int(height),\n                    'filesize_approx': parse_filesize(filesize),\n                })\n        self._sort_formats(formats)\n\n        title = self._html_search_meta('title', webpage, 'title')\n        description = self._html_search_meta(\n            'description', webpage, 'description', fatal=False)\n\n        thumbnail = self._html_search_meta('thumbnail', webpage, 'thumbnail', fatal=False)\n        if thumbnail:\n            thumbnail = re.sub(r'_[st]\\.jpg$', '_x.jpg', thumbnail)\n\n        duration = int_or_none(self._search_regex(\n            [r'var\\s+videoSeconds\\s*=\\s*(\\d+)', r\"'duration'\\s*:\\s*(\\d+)\"],\n            webpage, 'duration', fatal=False))\n\n        upload_date = unified_strdate(self._html_search_meta(\n            'last-modified', webpage, 'upload date', fatal=None))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'upload_date': upload_date,\n            'formats': formats\n        }",
        "begin_line": 31,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.lrt.LRTIE._real_extract#32",
        "src_path": "youtube_dl/extractor/lrt.py",
        "class_name": "youtube_dl.extractor.lrt.LRTIE",
        "signature": "youtube_dl.extractor.lrt.LRTIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = remove_end(self._og_search_title(webpage), ' - LRT')\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage)\n        duration = parse_duration(self._search_regex(\n            r\"'duration':\\s*'([^']+)',\", webpage,\n            'duration', fatal=False, default=None))\n\n        formats = []\n        for js in re.findall(r'(?s)config:\\s*(\\{.*?\\})', webpage):\n            data = self._parse_json(js, video_id, transform_source=js_to_json)\n            if 'provider' not in data:\n                continue\n            if data['provider'] == 'rtmp':\n                formats.append({\n                    'format_id': 'rtmp',\n                    'ext': determine_ext(data['file']),\n                    'url': data['streamer'],\n                    'play_path': 'mp4:%s' % data['file'],\n                    'preference': -1,\n                    'rtmp_real_time': True,\n                })\n            else:\n                formats.extend(\n                    self._extract_m3u8_formats(data['file'], video_id, 'mp4'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n        }",
        "begin_line": 32,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rutv.RUTVIE._extract_url#105",
        "src_path": "youtube_dl/extractor/rutv.py",
        "class_name": "youtube_dl.extractor.rutv.RUTVIE",
        "signature": "youtube_dl.extractor.rutv.RUTVIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://player\\.(?:rutv\\.ru|vgtrk\\.com)/(?:iframe/(?:swf|video|live)/id|index/iframe/cast_id)/.+?)\\1', webpage)\n        if mobj:\n            return mobj.group('url')\n\n        mobj = re.search(\n            r'<meta[^>]+?property=([\"\\'])og:video\\1[^>]+?content=([\"\\'])(?P<url>https?://player\\.(?:rutv\\.ru|vgtrk\\.com)/flash2v/container\\.swf\\?id=.+?\\2)',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 105,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rutv.RUTVIE._real_extract#117",
        "src_path": "youtube_dl/extractor/rutv.py",
        "class_name": "youtube_dl.extractor.rutv.RUTVIE",
        "signature": "youtube_dl.extractor.rutv.RUTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        video_path = mobj.group('path')\n\n        if video_path.startswith('flash2v'):\n            video_type = 'video'\n        elif video_path.startswith('iframe'):\n            video_type = mobj.group('type')\n            if video_type == 'swf':\n                video_type = 'video'\n        elif video_path.startswith('index/iframe/cast_id'):\n            video_type = 'live'\n\n        is_live = video_type == 'live'\n\n        json_data = self._download_json(\n            'http://player.rutv.ru/iframe/%splay/id/%s' % ('live-' if is_live else '', video_id),\n            video_id, 'Downloading JSON')\n\n        if json_data['errors']:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, json_data['errors']), expected=True)\n\n        playlist = json_data['data']['playlist']\n        medialist = playlist['medialist']\n        media = medialist[0]\n\n        if media['errors']:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, media['errors']), expected=True)\n\n        view_count = playlist.get('count_views')\n        priority_transport = playlist['priority_transport']\n\n        thumbnail = media['picture']\n        width = int_or_none(media['width'])\n        height = int_or_none(media['height'])\n        description = media['anons']\n        title = media['title']\n        duration = int_or_none(media.get('duration'))\n\n        formats = []\n\n        for transport, links in media['sources'].items():\n            for quality, url in links.items():\n                preference = -1 if priority_transport == transport else -2\n                if transport == 'rtmp':\n                    mobj = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+))/(?P<playpath>.+)$', url)\n                    if not mobj:\n                        continue\n                    fmt = {\n                        'url': mobj.group('url'),\n                        'play_path': mobj.group('playpath'),\n                        'app': mobj.group('app'),\n                        'page_url': 'http://player.rutv.ru',\n                        'player_url': 'http://player.rutv.ru/flash2v/osmf.swf?i=22',\n                        'rtmp_live': True,\n                        'ext': 'flv',\n                        'vbr': int(quality),\n                        'preference': preference,\n                    }\n                elif transport == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        url, video_id, 'mp4', preference=preference, m3u8_id='hls'))\n                    continue\n                else:\n                    fmt = {\n                        'url': url\n                    }\n                fmt.update({\n                    'width': width,\n                    'height': height,\n                    'format_id': '%s-%s' % (transport, quality),\n                })\n                formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._live_title(title) if is_live else title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'view_count': view_count,\n            'duration': duration,\n            'formats': formats,\n            'is_live': is_live,\n        }",
        "begin_line": 117,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.la7.LA7IE._real_extract#32",
        "src_path": "youtube_dl/extractor/la7.py",
        "class_name": "youtube_dl.extractor.la7.LA7IE",
        "signature": "youtube_dl.extractor.la7.LA7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        xml_url = 'http://www.la7.tv/repliche/content/index.php?contentId=%s' % video_id\n        doc = self._download_xml(xml_url, video_id)\n\n        video_title = doc.find('title').text\n        description = doc.find('description').text\n        duration = parse_duration(doc.find('duration').text)\n        thumbnail = doc.find('img').text\n        view_count = int(doc.find('views').text)\n\n        prefix = doc.find('.//fqdn').text.strip().replace('auto:', 'http:')\n\n        formats = [{\n            'format': vnode.find('quality').text,\n            'tbr': int(vnode.find('quality').text),\n            'url': vnode.find('fms').text.strip().replace('mp4:', prefix),\n        } for vnode in doc.findall('.//videos/video')]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'view_count': view_count,\n        }",
        "begin_line": 32,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.jukebox.JukeboxIE._real_extract#25",
        "src_path": "youtube_dl/extractor/jukebox.py",
        "class_name": "youtube_dl.extractor.jukebox.JukeboxIE",
        "signature": "youtube_dl.extractor.jukebox.JukeboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        html = self._download_webpage(url, video_id)\n        iframe_url = unescapeHTML(self._search_regex(r'<iframe .*src=\"([^\"]*)\"', html, 'iframe url'))\n\n        iframe_html = self._download_webpage(iframe_url, video_id, 'Downloading iframe')\n        if re.search(r'class=\"jkb_waiting\"', iframe_html) is not None:\n            raise ExtractorError('Video is not available(in your country?)!')\n\n        self.report_extraction(video_id)\n\n        try:\n            video_url = self._search_regex(r'\"config\":{\"file\":\"(?P<video_url>http:[^\"]+\\?mdtk=[0-9]+)\"',\n                                           iframe_html, 'video url')\n            video_url = unescapeHTML(video_url).replace('\\/', '/')\n        except RegexNotFoundError:\n            youtube_url = self._search_regex(\n                r'config\":{\"file\":\"(http:\\\\/\\\\/www\\.youtube\\.com\\\\/watch\\?v=[^\"]+)\"',\n                iframe_html, 'youtube url')\n            youtube_url = unescapeHTML(youtube_url).replace('\\/', '/')\n            self.to_screen('Youtube video detected')\n            return self.url_result(youtube_url, ie='Youtube')\n\n        title = self._html_search_regex(r'<h1 class=\"inline\">([^<]+)</h1>',\n                                        html, 'title')\n        artist = self._html_search_regex(r'<span id=\"infos_article_artist\">([^<]+)</span>',\n                                         html, 'artist')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': artist + '-' + title,\n            'uploader': artist,\n        }",
        "begin_line": 25,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cnet.CNETIE._real_extract#43",
        "src_path": "youtube_dl/extractor/cnet.py",
        "class_name": "youtube_dl.extractor.cnet.CNETIE",
        "signature": "youtube_dl.extractor.cnet.CNETIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        data_json = self._html_search_regex(\n            r\"<div class=\\\"cnetVideoPlayer\\\"\\s+.*?data-cnet-video-options='([^']+)'\",\n            webpage, 'data json')\n        data = json.loads(data_json)\n        vdata = data['video']\n        if not vdata:\n            vdata = data['videos'][0]\n        if not vdata:\n            raise ExtractorError('Cannot find video data')\n\n        mpx_account = data['config']['players']['default']['mpx_account']\n        vid = vdata['files'].get('rtmp', vdata['files']['hds'])\n        tp_link = 'http://link.theplatform.com/s/%s/%s' % (mpx_account, vid)\n\n        video_id = vdata['id']\n        title = vdata.get('headline')\n        if title is None:\n            title = vdata.get('title')\n        if title is None:\n            raise ExtractorError('Cannot find title!')\n        thumbnail = vdata.get('image', {}).get('path')\n        author = vdata.get('author')\n        if author:\n            uploader = '%s %s' % (author['firstName'], author['lastName'])\n            uploader_id = author.get('id')\n        else:\n            uploader = None\n            uploader_id = None\n\n        return {\n            '_type': 'url_transparent',\n            'url': tp_link,\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 43,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.photobucket.PhotobucketIE._real_extract#25",
        "src_path": "youtube_dl/extractor/photobucket.py",
        "class_name": "youtube_dl.extractor.photobucket.PhotobucketIE",
        "signature": "youtube_dl.extractor.photobucket.PhotobucketIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        video_extension = mobj.group('ext')\n\n        webpage = self._download_webpage(url, video_id)\n\n        # Extract URL, uploader, and title from webpage\n        self.report_extraction(video_id)\n        info_json = self._search_regex(r'Pb\\.Data\\.Shared\\.put\\(Pb\\.Data\\.Shared\\.MEDIA, (.*?)\\);',\n                                       webpage, 'info json')\n        info = json.loads(info_json)\n        url = compat_urllib_parse_unquote(self._html_search_regex(r'file=(.+\\.mp4)', info['linkcodes']['html'], 'url'))\n        return {\n            'id': video_id,\n            'url': url,\n            'uploader': info['username'],\n            'timestamp': info['creationDate'],\n            'title': info['title'],\n            'ext': video_extension,\n            'thumbnail': info['thumbUrl'],\n        }",
        "begin_line": 25,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.muenchentv.MuenchenTVIE._real_extract#32",
        "src_path": "youtube_dl/extractor/muenchentv.py",
        "class_name": "youtube_dl.extractor.muenchentv.MuenchenTVIE",
        "signature": "youtube_dl.extractor.muenchentv.MuenchenTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = 'live'\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._live_title(self._og_search_title(webpage))\n\n        data_js = self._search_regex(\n            r'(?s)\\nplaylist:\\s*(\\[.*?}\\]),related:',\n            webpage, 'playlist configuration')\n        data_json = js_to_json(data_js)\n        data = json.loads(data_json)[0]\n\n        video_id = data['mediaid']\n        thumbnail = data.get('image')\n\n        formats = []\n        for format_num, s in enumerate(data['sources']):\n            ext = determine_ext(s['file'], None)\n            label_str = s.get('label')\n            if label_str is None:\n                label_str = '_%d' % format_num\n\n            if ext is None:\n                format_id = label_str\n            else:\n                format_id = '%s-%s' % (ext, label_str)\n\n            formats.append({\n                'url': s['file'],\n                'tbr': int_or_none(s.get('label')),\n                'ext': 'mp4',\n                'format_id': format_id,\n                'preference': -100 if '.smil' in s['file'] else 0,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'formats': formats,\n            'is_live': True,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 32,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.varzesh3.Varzesh3IE._real_extract#21",
        "src_path": "youtube_dl/extractor/varzesh3.py",
        "class_name": "youtube_dl.extractor.varzesh3.Varzesh3IE",
        "signature": "youtube_dl.extractor.varzesh3.Varzesh3IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._search_regex(\n            r'<source[^>]+src=\"([^\"]+)\"', webpage, 'video url')\n\n        title = self._og_search_title(webpage)\n        description = self._html_search_regex(\n            r'(?s)<div class=\"matn\">(.+?)</div>',\n            webpage, 'description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        video_id = self._search_regex(\n            r\"<link[^>]+rel='(?:canonical|shortlink)'[^>]+href='/\\?p=([^']+)'\",\n            webpage, display_id, default=display_id)\n\n        return {\n            'url': video_url,\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 21,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vodlocker.VodlockerIE._real_extract#25",
        "src_path": "youtube_dl/extractor/vodlocker.py",
        "class_name": "youtube_dl.extractor.vodlocker.VodlockerIE",
        "signature": "youtube_dl.extractor.vodlocker.VodlockerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        fields = self._hidden_inputs(webpage)\n\n        if fields['op'] == 'download1':\n            self._sleep(3, video_id)  # they do detect when requests happen too fast!\n            post = compat_urllib_parse.urlencode(fields)\n            req = compat_urllib_request.Request(url, post)\n            req.add_header('Content-type', 'application/x-www-form-urlencoded')\n            webpage = self._download_webpage(\n                req, video_id, 'Downloading video page')\n\n        title = self._search_regex(\n            r'id=\"file_title\".*?>\\s*(.*?)\\s*<(?:br|span)', webpage, 'title')\n        thumbnail = self._search_regex(\n            r'image:\\s*\"(http[^\\\"]+)\",', webpage, 'thumbnail')\n        url = self._search_regex(\n            r'file:\\s*\"(http[^\\\"]+)\",', webpage, 'file url')\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.goldenmoustache.GoldenMoustacheIE._real_extract#30",
        "src_path": "youtube_dl/extractor/goldenmoustache.py",
        "class_name": "youtube_dl.extractor.goldenmoustache.GoldenMoustacheIE",
        "signature": "youtube_dl.extractor.goldenmoustache.GoldenMoustacheIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'data-src-type=\"mp4\" data-src=\"([^\"]+)\"', webpage, 'video URL')\n        title = self._html_search_regex(\n            r'<title>(.*?)(?: - Golden Moustache)?</title>', webpage, 'title')\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 30,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.trilulilu.TriluliluIE._real_extract#23",
        "src_path": "youtube_dl/extractor/trilulilu.py",
        "class_name": "youtube_dl.extractor.trilulilu.TriluliluIE",
        "signature": "youtube_dl.extractor.trilulilu.TriluliluIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        if re.search(r'Fi\u015fierul nu este disponibil pentru vizionare \u00een \u0163ara dumneavoastr\u0103', webpage):\n            raise ExtractorError(\n                'This video is not available in your country.', expected=True)\n        elif re.search('Fi\u015fierul poate fi accesat doar de c\u0103tre prietenii lui', webpage):\n            raise ExtractorError('This video is private.', expected=True)\n\n        flashvars_str = self._search_regex(\n            r'block_flash_vars\\s*=\\s*(\\{[^\\}]+\\})', webpage, 'flashvars', fatal=False, default=None)\n\n        if flashvars_str:\n            flashvars = self._parse_json(flashvars_str, display_id)\n        else:\n            raise ExtractorError(\n                'This page does not contain videos', expected=True)\n\n        if flashvars['isMP3'] == 'true':\n            raise ExtractorError(\n                'Audio downloads are currently not supported', expected=True)\n\n        video_id = flashvars['hash']\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage, default=None)\n\n        format_url = ('http://fs%(server)s.trilulilu.ro/%(hash)s/'\n                      'video-formats2' % flashvars)\n        format_doc = self._download_xml(\n            format_url, video_id,\n            note='Downloading formats',\n            errnote='Error while downloading formats')\n\n        video_url_template = (\n            'http://fs%(server)s.trilulilu.ro/stream.php?type=video'\n            '&source=site&hash=%(hash)s&username=%(userid)s&'\n            'key=ministhebest&format=%%s&sig=&exp=' %\n            flashvars)\n        formats = [\n            {\n                'format_id': fnode.text.partition('-')[2],\n                'url': video_url_template % fnode.text,\n                'ext': fnode.text.partition('-')[0]\n            }\n\n            for fnode in format_doc.findall('./formats/format')\n        ]\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 23,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.douyutv.DouyuTVIE._real_extract#48",
        "src_path": "youtube_dl/extractor/douyutv.py",
        "class_name": "youtube_dl.extractor.douyutv.DouyuTVIE",
        "signature": "youtube_dl.extractor.douyutv.DouyuTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        if video_id.isdigit():\n            room_id = video_id\n        else:\n            page = self._download_webpage(url, video_id)\n            room_id = self._html_search_regex(\n                r'\"room_id\"\\s*:\\s*(\\d+),', page, 'room id')\n\n        prefix = 'room/%s?aid=android&client_sys=android&time=%d' % (\n            room_id, int(time.time()))\n\n        auth = hashlib.md5((prefix + '1231').encode('ascii')).hexdigest()\n        config = self._download_json(\n            'http://www.douyutv.com/api/v1/%s&auth=%s' % (prefix, auth),\n            video_id)\n\n        data = config['data']\n\n        error_code = config.get('error', 0)\n        if error_code is not 0:\n            error_desc = 'Server reported error %i' % error_code\n            if isinstance(data, (compat_str, compat_basestring)):\n                error_desc += ': ' + data\n            raise ExtractorError(error_desc, expected=True)\n\n        show_status = data.get('show_status')\n        # 1 = live, 2 = offline\n        if show_status == '2':\n            raise ExtractorError(\n                'Live stream is offline', expected=True)\n\n        base_url = data['rtmp_url']\n        live_path = data['rtmp_live']\n\n        title = self._live_title(unescapeHTML(data['room_name']))\n        description = data.get('show_details')\n        thumbnail = data.get('room_src')\n\n        uploader = data.get('nickname')\n        uploader_id = data.get('owner_uid')\n\n        multi_formats = data.get('rtmp_multi_bitrate')\n        if not isinstance(multi_formats, dict):\n            multi_formats = {}\n        multi_formats['live'] = live_path\n\n        formats = [{\n            'url': '%s/%s' % (base_url, format_path),\n            'format_id': format_id,\n            'preference': 1 if format_id == 'live' else 0,\n        } for format_id, format_path in multi_formats.items()]\n        self._sort_formats(formats)\n\n        return {\n            'id': room_id,\n            'display_id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'formats': formats,\n            'is_live': True,\n        }",
        "begin_line": 48,
        "end_line": 113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserIE._login#48",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'form_id': 'user_login',\n            'op': 'Log in',\n            'name': username,\n            'pass': password,\n        }\n\n        request = compat_urllib_request.Request(\n            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))\n        request.add_header('Referer', self._LOGIN_URL)\n        response = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        login_error = self._html_search_regex(\n            r'(?s)<div class=\"messages error\">(.+?)</div>',\n            response, 'login error', default=None)\n        if login_error:\n            raise ExtractorError(\n                'Unable to login: %s' % login_error, expected=True)",
        "begin_line": 48,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserIE._real_initialize#73",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 73,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserIE._real_extract#76",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_json(\n            'http://player-c.api.bambuser.com/getVideo.json?api_key=%s&vid=%s'\n            % (self._API_KEY, video_id), video_id)\n\n        error = info.get('error')\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error), expected=True)\n\n        result = info['result']\n\n        return {\n            'id': video_id,\n            'title': result['title'],\n            'url': result['url'],\n            'thumbnail': result.get('preview'),\n            'duration': int_or_none(result.get('length')),\n            'uploader': result.get('username'),\n            'uploader_id': compat_str(result.get('owner', {}).get('uid')),\n            'timestamp': int_or_none(result.get('created')),\n            'fps': float_or_none(result.get('framerate')),\n            'view_count': int_or_none(result.get('views_total')),\n            'comment_count': int_or_none(result.get('comment_count')),\n        }",
        "begin_line": 76,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserChannelIE._real_extract#118",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserChannelIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        urls = []\n        last_id = ''\n        for i in itertools.count(1):\n            req_url = (\n                'http://bambuser.com/xhr-api/index.php?username={user}'\n                '&sort=created&access_mode=0%2C1%2C2&limit={count}'\n                '&method=broadcast&format=json&vid_older_than={last}'\n            ).format(user=user, count=self._STEP, last=last_id)\n            req = compat_urllib_request.Request(req_url)\n            # Without setting this header, we wouldn't get any result\n            req.add_header('Referer', 'http://bambuser.com/channel/%s' % user)\n            data = self._download_json(\n                req, user, 'Downloading page %d' % i)\n            results = data['result']\n            if not results:\n                break\n            last_id = results[-1]['vid']\n            urls.extend(self.url_result(v['page'], 'Bambuser') for v in results)\n\n        return {\n            '_type': 'playlist',\n            'title': user,\n            'entries': urls,\n        }",
        "begin_line": 118,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dotsub.DotsubIE._real_extract#29",
        "src_path": "youtube_dl/extractor/dotsub.py",
        "class_name": "youtube_dl.extractor.dotsub.DotsubIE",
        "signature": "youtube_dl.extractor.dotsub.DotsubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_json(\n            'https://dotsub.com/api/media/%s/metadata' % video_id, video_id)\n        video_url = info.get('mediaURI')\n\n        if not video_url:\n            webpage = self._download_webpage(url, video_id)\n            video_url = self._search_regex(\n                [r'<source[^>]+src=\"([^\"]+)\"', r'\"file\"\\s*:\\s*\\'([^\\']+)'],\n                webpage, 'video url')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'flv',\n            'title': info['title'],\n            'description': info.get('description'),\n            'thumbnail': info.get('screenshotURI'),\n            'duration': int_or_none(info.get('duration'), 1000),\n            'uploader': info.get('user'),\n            'timestamp': float_or_none(info.get('dateCreated'), 1000),\n            'view_count': int_or_none(info.get('numberOfViews')),\n        }",
        "begin_line": 29,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ministrygrid.MinistryGridIE._real_extract#28",
        "src_path": "youtube_dl/extractor/ministrygrid.py",
        "class_name": "youtube_dl.extractor.ministrygrid.MinistryGridIE",
        "signature": "youtube_dl.extractor.ministrygrid.MinistryGridIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        portlets_json = self._search_regex(\n            r'Liferay\\.Portlet\\.list=(\\[.+?\\])', webpage, 'portlet list')\n        portlets = json.loads(portlets_json)\n        pl_id = self._search_regex(\n            r'<!--\\s*p_l_id - ([0-9]+)<br>', webpage, 'p_l_id')\n\n        for i, portlet in enumerate(portlets):\n            portlet_url = 'http://www.ministrygrid.com/c/portal/render_portlet?p_l_id=%s&p_p_id=%s' % (pl_id, portlet)\n            portlet_code = self._download_webpage(\n                portlet_url, video_id,\n                note='Looking in portlet %s (%d/%d)' % (portlet, i + 1, len(portlets)),\n                fatal=False)\n            video_iframe_url = self._search_regex(\n                r'<iframe.*?src=\"([^\"]+)\"', portlet_code, 'video iframe',\n                default=None)\n            if video_iframe_url:\n                surl = smuggle_url(\n                    video_iframe_url, {'force_videoid': video_id})\n                return {\n                    '_type': 'url',\n                    'id': video_id,\n                    'url': surl,\n                }\n\n        raise ExtractorError('Could not find video iframe in any portlets')",
        "begin_line": 28,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.videomega.VideoMegaIE._real_extract#29",
        "src_path": "youtube_dl/extractor/videomega.py",
        "class_name": "youtube_dl.extractor.videomega.VideoMegaIE",
        "signature": "youtube_dl.extractor.videomega.VideoMegaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        iframe_url = 'http://videomega.tv/cdn.php?ref=%s' % video_id\n        req = compat_urllib_request.Request(iframe_url)\n        req.add_header('Referer', url)\n        req.add_header('Cookie', 'noadvtday=0')\n        webpage = self._download_webpage(req, video_id)\n\n        title = self._html_search_regex(\n            r'<title>(.+?)</title>', webpage, 'title')\n        title = re.sub(\n            r'(?:^[Vv]ideo[Mm]ega\\.tv\\s-\\s*|\\s*-\\svideomega\\.tv$)', '', title)\n        thumbnail = self._search_regex(\n            r'<video[^>]+?poster=\"([^\"]+)\"', webpage, 'thumbnail', fatal=False)\n        video_url = self._search_regex(\n            r'<source[^>]+?src=\"([^\"]+)\"', webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'http_headers': {\n                'Referer': iframe_url,\n            },\n        }",
        "begin_line": 29,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sunporno.SunPornoIE._real_extract#30",
        "src_path": "youtube_dl/extractor/sunporno.py",
        "class_name": "youtube_dl.extractor.sunporno.SunPornoIE",
        "signature": "youtube_dl.extractor.sunporno.SunPornoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title')\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n        thumbnail = self._html_search_regex(\n            r'poster=\"([^\"]+)\"', webpage, 'thumbnail', fatal=False)\n\n        duration = parse_duration(self._search_regex(\n            r'itemprop=\"duration\">\\s*(\\d+:\\d+)\\s*<',\n            webpage, 'duration', fatal=False))\n\n        view_count = int_or_none(self._html_search_regex(\n            r'class=\"views\">(?:<noscript>)?\\s*(\\d+)\\s*<',\n            webpage, 'view count', fatal=False))\n        comment_count = int_or_none(self._html_search_regex(\n            r'(\\d+)</b> Comments?',\n            webpage, 'comment count', fatal=False))\n\n        formats = []\n        quality = qualities(['mp4', 'flv'])\n        for video_url in re.findall(r'<(?:source|video) src=\"([^\"]+)\"', webpage):\n            video_ext = determine_ext(video_url)\n            formats.append({\n                'url': video_url,\n                'format_id': video_ext,\n                'quality': quality(video_ext),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 30,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.videofyme.VideofyMeIE._real_extract#32",
        "src_path": "youtube_dl/extractor/videofyme.py",
        "class_name": "youtube_dl.extractor.videofyme.VideofyMeIE",
        "signature": "youtube_dl.extractor.videofyme.VideofyMeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        config = self._download_json('http://vf-player-info-loader.herokuapp.com/%s.json' % video_id, video_id)['videoinfo']\n\n        video = config.get('video')\n        blog = config.get('blog', {})\n\n        return {\n            'id': video_id,\n            'title': video['title'],\n            'url': video['sources']['source']['url'],\n            'thumbnail': video.get('thumb'),\n            'description': video.get('description'),\n            'timestamp': parse_iso8601(video.get('date')),\n            'uploader': blog.get('name'),\n            'uploader_id': blog.get('identifier'),\n            'view_count': int_or_none(self._search_regex(r'([0-9]+)', video.get('views'), 'view count', fatal=False)),\n            'likes': int_or_none(video.get('likes')),\n            'comment_count': int_or_none(video.get('nrOfComments')),\n        }",
        "begin_line": 32,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.collegerama.CollegeRamaIE._real_extract#45",
        "src_path": "youtube_dl/extractor/collegerama.py",
        "class_name": "youtube_dl.extractor.collegerama.CollegeRamaIE",
        "signature": "youtube_dl.extractor.collegerama.CollegeRamaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        player_options_request = {\n            \"getPlayerOptionsRequest\": {\n                \"ResourceId\": video_id,\n                \"QueryString\": \"\",\n            }\n        }\n\n        request = compat_urllib_request.Request(\n            'http://collegerama.tudelft.nl/Mediasite/PlayerService/PlayerService.svc/json/GetPlayerOptions',\n            json.dumps(player_options_request))\n        request.add_header('Content-Type', 'application/json')\n\n        player_options = self._download_json(request, video_id)\n\n        presentation = player_options['d']['Presentation']\n        title = presentation['Title']\n        description = presentation.get('Description')\n        thumbnail = None\n        duration = float_or_none(presentation.get('Duration'), 1000)\n        timestamp = int_or_none(presentation.get('UnixTime'), 1000)\n\n        formats = []\n        for stream in presentation['Streams']:\n            for video in stream['VideoUrls']:\n                thumbnail_url = stream.get('ThumbnailUrl')\n                if thumbnail_url:\n                    thumbnail = 'http://collegerama.tudelft.nl' + thumbnail_url\n                format_id = video['MediaType']\n                if format_id == 'SS':\n                    continue\n                formats.append({\n                    'url': video['Location'],\n                    'format_id': format_id,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kickstarter.KickStarterIE._real_extract#41",
        "src_path": "youtube_dl/extractor/kickstarter.py",
        "class_name": "youtube_dl.extractor.kickstarter.KickStarterIE",
        "signature": "youtube_dl.extractor.kickstarter.KickStarterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<title>\\s*(.*?)(?:\\s*&mdash; Kickstarter)?\\s*</title>',\n            webpage, 'title')\n        video_url = self._search_regex(\n            r'data-video-url=\"(.*?)\"',\n            webpage, 'video URL', default=None)\n        if video_url is None:  # No native kickstarter, look for embedded videos\n            return {\n                '_type': 'url_transparent',\n                'ie_key': 'Generic',\n                'url': url,\n                'title': title,\n            }\n\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n        if thumbnail is None:\n            thumbnail = self._html_search_regex(\n                r'<img[^>]+class=\"[^\"]+\\s*poster\\s*[^\"]+\"[^>]+src=\"([^\"]+)\"',\n                webpage, 'thumbnail image', fatal=False)\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 41,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.__init__._real_main#47",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__._real_main(argv=None)",
        "snippet": "def _real_main(argv=None):\n    # Compatibility fixes for Windows\n    if sys.platform == 'win32':\n        # https://github.com/rg3/youtube-dl/issues/820\n        codecs.register(lambda name: codecs.lookup('utf-8') if name == 'cp65001' else None)\n\n    workaround_optparse_bug9161()\n\n    setproctitle('youtube-dl')\n\n    parser, opts, args = parseOpts(argv)\n\n    # Set user agent\n    if opts.user_agent is not None:\n        std_headers['User-Agent'] = opts.user_agent\n\n    # Set referer\n    if opts.referer is not None:\n        std_headers['Referer'] = opts.referer\n\n    # Custom HTTP headers\n    if opts.headers is not None:\n        for h in opts.headers:\n            if h.find(':', 1) < 0:\n                parser.error('wrong header formatting, it should be key:value, not \"%s\"' % h)\n            key, value = h.split(':', 2)\n            if opts.verbose:\n                write_string('[debug] Adding header from command line option %s:%s\\n' % (key, value))\n            std_headers[key] = value\n\n    # Dump user agent\n    if opts.dump_user_agent:\n        compat_print(std_headers['User-Agent'])\n        sys.exit(0)\n\n    # Batch file verification\n    batch_urls = []\n    if opts.batchfile is not None:\n        try:\n            if opts.batchfile == '-':\n                batchfd = sys.stdin\n            else:\n                batchfd = io.open(opts.batchfile, 'r', encoding='utf-8', errors='ignore')\n            batch_urls = read_batch_urls(batchfd)\n            if opts.verbose:\n                write_string('[debug] Batch file urls: ' + repr(batch_urls) + '\\n')\n        except IOError:\n            sys.exit('ERROR: batch file could not be read')\n    all_urls = batch_urls + args\n    all_urls = [url.strip() for url in all_urls]\n    _enc = preferredencoding()\n    all_urls = [url.decode(_enc, 'ignore') if isinstance(url, bytes) else url for url in all_urls]\n\n    if opts.list_extractors:\n        for ie in list_extractors(opts.age_limit):\n            compat_print(ie.IE_NAME + (' (CURRENTLY BROKEN)' if not ie._WORKING else ''))\n            matchedUrls = [url for url in all_urls if ie.suitable(url)]\n            for mu in matchedUrls:\n                compat_print('  ' + mu)\n        sys.exit(0)\n    if opts.list_extractor_descriptions:\n        for ie in list_extractors(opts.age_limit):\n            if not ie._WORKING:\n                continue\n            desc = getattr(ie, 'IE_DESC', ie.IE_NAME)\n            if desc is False:\n                continue\n            if hasattr(ie, 'SEARCH_KEY'):\n                _SEARCHES = ('cute kittens', 'slithering pythons', 'falling cat', 'angry poodle', 'purple fish', 'running tortoise', 'sleeping bunny', 'burping cow')\n                _COUNTS = ('', '5', '10', 'all')\n                desc += ' (Example: \"%s%s:%s\" )' % (ie.SEARCH_KEY, random.choice(_COUNTS), random.choice(_SEARCHES))\n            compat_print(desc)\n        sys.exit(0)\n\n    # Conflicting, missing and erroneous options\n    if opts.usenetrc and (opts.username is not None or opts.password is not None):\n        parser.error('using .netrc conflicts with giving username/password')\n    if opts.password is not None and opts.username is None:\n        parser.error('account username missing\\n')\n    if opts.outtmpl is not None and (opts.usetitle or opts.autonumber or opts.useid):\n        parser.error('using output template conflicts with using title, video ID or auto number')\n    if opts.usetitle and opts.useid:\n        parser.error('using title conflicts with using video ID')\n    if opts.username is not None and opts.password is None:\n        opts.password = compat_getpass('Type account password and press [Return]: ')\n    if opts.ratelimit is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.ratelimit)\n        if numeric_limit is None:\n            parser.error('invalid rate limit specified')\n        opts.ratelimit = numeric_limit\n    if opts.min_filesize is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.min_filesize)\n        if numeric_limit is None:\n            parser.error('invalid min_filesize specified')\n        opts.min_filesize = numeric_limit\n    if opts.max_filesize is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.max_filesize)\n        if numeric_limit is None:\n            parser.error('invalid max_filesize specified')\n        opts.max_filesize = numeric_limit\n    if opts.retries is not None:\n        if opts.retries in ('inf', 'infinite'):\n            opts_retries = float('inf')\n        else:\n            try:\n                opts_retries = int(opts.retries)\n            except (TypeError, ValueError):\n                parser.error('invalid retry count specified')\n    if opts.buffersize is not None:\n        numeric_buffersize = FileDownloader.parse_bytes(opts.buffersize)\n        if numeric_buffersize is None:\n            parser.error('invalid buffer size specified')\n        opts.buffersize = numeric_buffersize\n    if opts.playliststart <= 0:\n        raise ValueError('Playlist start must be positive')\n    if opts.playlistend not in (-1, None) and opts.playlistend < opts.playliststart:\n        raise ValueError('Playlist end must be greater than playlist start')\n    if opts.extractaudio:\n        if opts.audioformat not in ['best', 'aac', 'mp3', 'm4a', 'opus', 'vorbis', 'wav']:\n            parser.error('invalid audio format specified')\n    if opts.audioquality:\n        opts.audioquality = opts.audioquality.strip('k').strip('K')\n        if not opts.audioquality.isdigit():\n            parser.error('invalid audio quality specified')\n    if opts.recodevideo is not None:\n        if opts.recodevideo not in ['mp4', 'flv', 'webm', 'ogg', 'mkv', 'avi']:\n            parser.error('invalid video recode format specified')\n    if opts.convertsubtitles is not None:\n        if opts.convertsubtitles not in ['srt', 'vtt', 'ass']:\n            parser.error('invalid subtitle format specified')\n\n    if opts.date is not None:\n        date = DateRange.day(opts.date)\n    else:\n        date = DateRange(opts.dateafter, opts.datebefore)\n\n    # Do not download videos when there are audio-only formats\n    if opts.extractaudio and not opts.keepvideo and opts.format is None:\n        opts.format = 'bestaudio/best'\n\n    # --all-sub automatically sets --write-sub if --write-auto-sub is not given\n    # this was the old behaviour if only --all-sub was given.\n    if opts.allsubtitles and not opts.writeautomaticsub:\n        opts.writesubtitles = True\n\n    outtmpl = ((opts.outtmpl is not None and opts.outtmpl) or\n               (opts.format == '-1' and opts.usetitle and '%(title)s-%(id)s-%(format)s.%(ext)s') or\n               (opts.format == '-1' and '%(id)s-%(format)s.%(ext)s') or\n               (opts.usetitle and opts.autonumber and '%(autonumber)s-%(title)s-%(id)s.%(ext)s') or\n               (opts.usetitle and '%(title)s-%(id)s.%(ext)s') or\n               (opts.useid and '%(id)s.%(ext)s') or\n               (opts.autonumber and '%(autonumber)s-%(id)s.%(ext)s') or\n               DEFAULT_OUTTMPL)\n    if not os.path.splitext(outtmpl)[1] and opts.extractaudio:\n        parser.error('Cannot download a video and extract audio into the same'\n                     ' file! Use \"{0}.%(ext)s\" instead of \"{0}\" as the output'\n                     ' template'.format(outtmpl))\n\n    any_getting = opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.getduration or opts.dumpjson or opts.dump_single_json\n    any_printing = opts.print_json\n    download_archive_fn = compat_expanduser(opts.download_archive) if opts.download_archive is not None else opts.download_archive\n\n    # PostProcessors\n    postprocessors = []\n    # Add the metadata pp first, the other pps will copy it\n    if opts.metafromtitle:\n        postprocessors.append({\n            'key': 'MetadataFromTitle',\n            'titleformat': opts.metafromtitle\n        })\n    if opts.addmetadata:\n        postprocessors.append({'key': 'FFmpegMetadata'})\n    if opts.extractaudio:\n        postprocessors.append({\n            'key': 'FFmpegExtractAudio',\n            'preferredcodec': opts.audioformat,\n            'preferredquality': opts.audioquality,\n            'nopostoverwrites': opts.nopostoverwrites,\n        })\n    if opts.recodevideo:\n        postprocessors.append({\n            'key': 'FFmpegVideoConvertor',\n            'preferedformat': opts.recodevideo,\n        })\n    if opts.convertsubtitles:\n        postprocessors.append({\n            'key': 'FFmpegSubtitlesConvertor',\n            'format': opts.convertsubtitles,\n        })\n    if opts.embedsubtitles:\n        postprocessors.append({\n            'key': 'FFmpegEmbedSubtitle',\n        })\n    if opts.xattrs:\n        postprocessors.append({'key': 'XAttrMetadata'})\n    if opts.embedthumbnail:\n        already_have_thumbnail = opts.writethumbnail or opts.write_all_thumbnails\n        postprocessors.append({\n            'key': 'EmbedThumbnail',\n            'already_have_thumbnail': already_have_thumbnail\n        })\n        if not already_have_thumbnail:\n            opts.writethumbnail = True\n    # Please keep ExecAfterDownload towards the bottom as it allows the user to modify the final file in any way.\n    # So if the user is able to remove the file before your postprocessor runs it might cause a few problems.\n    if opts.exec_cmd:\n        postprocessors.append({\n            'key': 'ExecAfterDownload',\n            'exec_cmd': opts.exec_cmd,\n        })\n    if opts.xattr_set_filesize:\n        try:\n            import xattr\n            xattr  # Confuse flake8\n        except ImportError:\n            parser.error('setting filesize xattr requested but python-xattr is not available')\n    external_downloader_args = None\n    if opts.external_downloader_args:\n        external_downloader_args = compat_shlex_split(opts.external_downloader_args)\n    postprocessor_args = None\n    if opts.postprocessor_args:\n        postprocessor_args = compat_shlex_split(opts.postprocessor_args)\n    match_filter = (\n        None if opts.match_filter is None\n        else match_filter_func(opts.match_filter))\n\n    ydl_opts = {\n        'usenetrc': opts.usenetrc,\n        'username': opts.username,\n        'password': opts.password,\n        'twofactor': opts.twofactor,\n        'videopassword': opts.videopassword,\n        'quiet': (opts.quiet or any_getting or any_printing),\n        'no_warnings': opts.no_warnings,\n        'forceurl': opts.geturl,\n        'forcetitle': opts.gettitle,\n        'forceid': opts.getid,\n        'forcethumbnail': opts.getthumbnail,\n        'forcedescription': opts.getdescription,\n        'forceduration': opts.getduration,\n        'forcefilename': opts.getfilename,\n        'forceformat': opts.getformat,\n        'forcejson': opts.dumpjson or opts.print_json,\n        'dump_single_json': opts.dump_single_json,\n        'simulate': opts.simulate or any_getting,\n        'skip_download': opts.skip_download,\n        'format': opts.format,\n        'listformats': opts.listformats,\n        'outtmpl': outtmpl,\n        'autonumber_size': opts.autonumber_size,\n        'restrictfilenames': opts.restrictfilenames,\n        'ignoreerrors': opts.ignoreerrors,\n        'force_generic_extractor': opts.force_generic_extractor,\n        'ratelimit': opts.ratelimit,\n        'nooverwrites': opts.nooverwrites,\n        'retries': opts_retries,\n        'buffersize': opts.buffersize,\n        'noresizebuffer': opts.noresizebuffer,\n        'continuedl': opts.continue_dl,\n        'noprogress': opts.noprogress,\n        'progress_with_newline': opts.progress_with_newline,\n        'playliststart': opts.playliststart,\n        'playlistend': opts.playlistend,\n        'playlistreverse': opts.playlist_reverse,\n        'noplaylist': opts.noplaylist,\n        'logtostderr': opts.outtmpl == '-',\n        'consoletitle': opts.consoletitle,\n        'nopart': opts.nopart,\n        'updatetime': opts.updatetime,\n        'writedescription': opts.writedescription,\n        'writeannotations': opts.writeannotations,\n        'writeinfojson': opts.writeinfojson,\n        'writethumbnail': opts.writethumbnail,\n        'write_all_thumbnails': opts.write_all_thumbnails,\n        'writesubtitles': opts.writesubtitles,\n        'writeautomaticsub': opts.writeautomaticsub,\n        'allsubtitles': opts.allsubtitles,\n        'listsubtitles': opts.listsubtitles,\n        'subtitlesformat': opts.subtitlesformat,\n        'subtitleslangs': opts.subtitleslangs,\n        'matchtitle': decodeOption(opts.matchtitle),\n        'rejecttitle': decodeOption(opts.rejecttitle),\n        'max_downloads': opts.max_downloads,\n        'prefer_free_formats': opts.prefer_free_formats,\n        'verbose': opts.verbose,\n        'dump_intermediate_pages': opts.dump_intermediate_pages,\n        'write_pages': opts.write_pages,\n        'test': opts.test,\n        'keepvideo': opts.keepvideo,\n        'min_filesize': opts.min_filesize,\n        'max_filesize': opts.max_filesize,\n        'min_views': opts.min_views,\n        'max_views': opts.max_views,\n        'daterange': date,\n        'cachedir': opts.cachedir,\n        'youtube_print_sig_code': opts.youtube_print_sig_code,\n        'age_limit': opts.age_limit,\n        'download_archive': download_archive_fn,\n        'cookiefile': opts.cookiefile,\n        'nocheckcertificate': opts.no_check_certificate,\n        'prefer_insecure': opts.prefer_insecure,\n        'proxy': opts.proxy,\n        'socket_timeout': opts.socket_timeout,\n        'bidi_workaround': opts.bidi_workaround,\n        'debug_printtraffic': opts.debug_printtraffic,\n        'prefer_ffmpeg': opts.prefer_ffmpeg,\n        'include_ads': opts.include_ads,\n        'default_search': opts.default_search,\n        'youtube_include_dash_manifest': opts.youtube_include_dash_manifest,\n        'encoding': opts.encoding,\n        'extract_flat': opts.extract_flat,\n        'merge_output_format': opts.merge_output_format,\n        'postprocessors': postprocessors,\n        'fixup': opts.fixup,\n        'source_address': opts.source_address,\n        'call_home': opts.call_home,\n        'sleep_interval': opts.sleep_interval,\n        'external_downloader': opts.external_downloader,\n        'list_thumbnails': opts.list_thumbnails,\n        'playlist_items': opts.playlist_items,\n        'xattr_set_filesize': opts.xattr_set_filesize,\n        'match_filter': match_filter,\n        'no_color': opts.no_color,\n        'ffmpeg_location': opts.ffmpeg_location,\n        'hls_prefer_native': opts.hls_prefer_native,\n        'external_downloader_args': external_downloader_args,\n        'postprocessor_args': postprocessor_args,\n        'cn_verification_proxy': opts.cn_verification_proxy,\n    }\n\n    with YoutubeDL(ydl_opts) as ydl:\n        # Update version\n        if opts.update_self:\n            update_self(ydl.to_screen, opts.verbose)\n\n        # Remove cache dir\n        if opts.rm_cachedir:\n            ydl.cache.remove()\n\n        # Maybe do nothing\n        if (len(all_urls) < 1) and (opts.load_info_filename is None):\n            if opts.update_self or opts.rm_cachedir:\n                sys.exit()\n\n            ydl.warn_if_short_id(sys.argv[1:] if argv is None else argv)\n            parser.error(\n                'You must provide at least one URL.\\n'\n                'Type youtube-dl --help to see a list of all options.')\n\n        try:\n            if opts.load_info_filename is not None:\n                retcode = ydl.download_with_info_file(opts.load_info_filename)\n            else:\n                retcode = ydl.download(all_urls)\n        except MaxDownloadsReached:\n            ydl.to_screen('--max-download limit reached, aborting.')\n            retcode = 101\n\n    sys.exit(retcode)",
        "begin_line": 47,
        "end_line": 405,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.__init__.main#408",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__.main(argv=None)",
        "snippet": "def main(argv=None):\n    try:\n        _real_main(argv)\n    except DownloadError:\n        sys.exit(1)\n    except SameFileError:\n        sys.exit('ERROR: fixed output name but more than one file to download')\n    except KeyboardInterrupt:\n        sys.exit('\\nERROR: Interrupted by user')",
        "begin_line": 408,
        "end_line": 416,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sexykarma.SexyKarmaIE._real_extract#70",
        "src_path": "youtube_dl/extractor/sexykarma.py",
        "class_name": "youtube_dl.extractor.sexykarma.SexyKarmaIE",
        "signature": "youtube_dl.extractor.sexykarma.SexyKarmaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._html_search_regex(\n            r\"url: escape\\('([^']+)'\\)\", webpage, 'url')\n\n        title = self._html_search_regex(\n            r'<h2 class=\"he2\"><span>(.*?)</span>',\n            webpage, 'title')\n        thumbnail = self._html_search_regex(\n            r'<span id=\"container\"><img\\s+src=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        uploader = self._html_search_regex(\n            r'class=\"aupa\">\\s*(.*?)</a>',\n            webpage, 'uploader')\n        upload_date = unified_strdate(self._html_search_regex(\n            r'Added: <strong>(.+?)</strong>', webpage, 'upload date', fatal=False))\n\n        duration = parse_duration(self._search_regex(\n            r'<td>Time:\\s*</td>\\s*<td align=\"right\"><span>\\s*(.+?)\\s*</span>',\n            webpage, 'duration', fatal=False))\n\n        view_count = int_or_none(self._search_regex(\n            r'<td>Views:\\s*</td>\\s*<td align=\"right\"><span>\\s*(\\d+)\\s*</span>',\n            webpage, 'view count', fatal=False))\n        comment_count = int_or_none(self._search_regex(\n            r'<td>Comments:\\s*</td>\\s*<td align=\"right\"><span>\\s*(\\d+)\\s*</span>',\n            webpage, 'comment count', fatal=False))\n\n        categories = re.findall(\n            r'<a href=\"[^\"]+/search/video/desi\"><span>([^<]+)</span></a>',\n            webpage)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'categories': categories,\n            'age_limit': 18,\n        }",
        "begin_line": 70,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.rtsp.RtspFD.real_download#14",
        "src_path": "youtube_dl/downloader/rtsp.py",
        "class_name": "youtube_dl.downloader.rtsp.RtspFD",
        "signature": "youtube_dl.downloader.rtsp.RtspFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n\n        if check_executable('mplayer', ['-h']):\n            args = [\n                'mplayer', '-really-quiet', '-vo', 'null', '-vc', 'dummy',\n                '-dumpstream', '-dumpfile', tmpfilename, url]\n        elif check_executable('mpv', ['-h']):\n            args = [\n                'mpv', '-really-quiet', '--vo=null', '--stream-dump=' + tmpfilename, url]\n        else:\n            self.report_error('MMS or RTSP download detected but neither \"mplayer\" nor \"mpv\" could be run. Please install any.')\n            return False\n\n        retval = subprocess.call(args)\n        if retval == 0:\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('\\r[%s] %s bytes' % (args[0], fsize))\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr('\\n')\n            self.report_error('%s exited with code %d' % (args[0], retval))\n            return False",
        "begin_line": 14,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.aftenposten.AftenpostenIE._real_extract#22",
        "src_path": "youtube_dl/extractor/aftenposten.py",
        "class_name": "youtube_dl.extractor.aftenposten.AftenpostenIE",
        "signature": "youtube_dl.extractor.aftenposten.AftenpostenIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self.url_result('xstream:ap:%s' % self._match_id(url), 'Xstream')",
        "begin_line": 22,
        "end_line": 23,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._extract_url#145",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<embed[^>]src=([\"\\'])(?P<url>http://pics\\.smotri\\.com/(?:player|scrubber_custom8)\\.swf\\?file=v.+?\\1)',\n            webpage)\n        if mobj is not None:\n            return mobj.group('url')\n\n        mobj = re.search(\n            r'''(?x)<div\\s+class=\"video_file\">http://smotri\\.com/video/download/file/[^<]+</div>\\s*\n                    <div\\s+class=\"video_image\">[^<]+</div>\\s*\n                    <div\\s+class=\"video_id\">(?P<id>[^<]+)</div>''', webpage)\n        if mobj is not None:\n            return 'http://smotri.com/video/view/?id=%s' % mobj.group('id')",
        "begin_line": 145,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._search_meta#159",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._search_meta(self, name, html, display_name=None)",
        "snippet": "    def _search_meta(self, name, html, display_name=None):\n        if display_name is None:\n            display_name = name\n        return self._html_search_meta(name, html, display_name)",
        "begin_line": 159,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._real_extract#164",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_form = {\n            'ticket': video_id,\n            'video_url': '1',\n            'frame_url': '1',\n            'devid': 'LoadupFlashPlayer',\n            'getvideoinfo': '1',\n        }\n\n        video_password = self._downloader.params.get('videopassword', None)\n        if video_password:\n            video_form['pass'] = hashlib.md5(video_password.encode('utf-8')).hexdigest()\n\n        request = compat_urllib_request.Request(\n            'http://smotri.com/video/view/url/bot/', compat_urllib_parse.urlencode(video_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n\n        video = self._download_json(request, video_id, 'Downloading video JSON')\n\n        video_url = video.get('_vidURL') or video.get('_vidURL_mp4')\n\n        if not video_url:\n            if video.get('_moderate_no'):\n                raise ExtractorError(\n                    'Video %s has not been approved by moderator' % video_id, expected=True)\n\n            if video.get('error'):\n                raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n            if video.get('_pass_protected') == 1:\n                msg = ('Invalid video password' if video_password\n                       else 'This video is protected by a password, use the --video-password option')\n                raise ExtractorError(msg, expected=True)\n\n        title = video['title']\n        thumbnail = video['_imgURL']\n        upload_date = unified_strdate(video['added'])\n        uploader = video['userNick']\n        uploader_id = video['userLogin']\n        duration = int_or_none(video['duration'])\n\n        # Video JSON does not provide enough meta data\n        # We will extract some from the video web page instead\n        webpage_url = 'http://smotri.com/video/view/?id=%s' % video_id\n        webpage = self._download_webpage(webpage_url, video_id, 'Downloading video page')\n\n        # Warning if video is unavailable\n        warning = self._html_search_regex(\n            r'<div class=\"videoUnModer\">(.*?)</div>', webpage,\n            'warning message', default=None)\n        if warning is not None:\n            self._downloader.report_warning(\n                'Video %s may not be available; smotri said: %s ' %\n                (video_id, warning))\n\n        # Adult content\n        if re.search('EroConfirmText\">', webpage) is not None:\n            self.report_age_confirmation()\n            confirm_string = self._html_search_regex(\n                r'<a href=\"/video/view/\\?id=%s&confirm=([^\"]+)\" title=\"[^\"]+\">' % video_id,\n                webpage, 'confirm string')\n            confirm_url = webpage_url + '&confirm=%s' % confirm_string\n            webpage = self._download_webpage(confirm_url, video_id, 'Downloading video page (age confirmed)')\n            adult_content = True\n        else:\n            adult_content = False\n\n        view_count = self._html_search_regex(\n            '\u041e\u0431\u0449\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u043e\u0432.*?<span class=\"Number\">(\\\\d+)</span>',\n            webpage, 'view count', fatal=False, flags=re.MULTILINE | re.DOTALL)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'view_count': int_or_none(view_count),\n            'age_limit': 18 if adult_content else 0,\n        }",
        "begin_line": 164,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriCommunityIE._real_extract#264",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriCommunityIE",
        "signature": "youtube_dl.extractor.smotri.SmotriCommunityIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        community_id = mobj.group('communityid')\n\n        url = 'http://smotri.com/export/rss/video/by/community/-/%s/video.xml' % community_id\n        rss = self._download_xml(url, community_id, 'Downloading community RSS')\n\n        entries = [self.url_result(video_url.text, 'Smotri')\n                   for video_url in rss.findall('./channel/item/link')]\n\n        description_text = rss.find('./channel/description').text\n        community_title = self._html_search_regex(\n            '^\u0412\u0438\u0434\u0435\u043e \u0441\u043e\u043e\u0431\u0449\u0435\u0441\u0442\u0432\u0430 \"([^\"]+)\"$', description_text, 'community title')\n\n        return self.playlist_result(entries, community_id, community_title)",
        "begin_line": 264,
        "end_line": 278,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriUserIE._real_extract#294",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriUserIE",
        "signature": "youtube_dl.extractor.smotri.SmotriUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('userid')\n\n        url = 'http://smotri.com/export/rss/user/video/-/%s/video.xml' % user_id\n        rss = self._download_xml(url, user_id, 'Downloading user RSS')\n\n        entries = [self.url_result(video_url.text, 'Smotri')\n                   for video_url in rss.findall('./channel/item/link')]\n\n        description_text = rss.find('./channel/description').text\n        user_nickname = self._html_search_regex(\n            '^\u0412\u0438\u0434\u0435\u043e \u0440\u0435\u0436\u0438\u0441\u0441\u0435\u0440\u0430 (.*)$', description_text,\n            'user nickname')\n\n        return self.playlist_result(entries, user_id, user_nickname)",
        "begin_line": 294,
        "end_line": 309,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriBroadcastIE._real_extract#317",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriBroadcastIE",
        "signature": "youtube_dl.extractor.smotri.SmotriBroadcastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        broadcast_id = mobj.group('broadcastid')\n\n        broadcast_url = 'http://' + mobj.group('url')\n        broadcast_page = self._download_webpage(broadcast_url, broadcast_id, 'Downloading broadcast page')\n\n        if re.search('>\u0420\u0435\u0436\u0438\u0441\u0441\u0435\u0440 \u0441 \u043b\u043e\u0433\u0438\u043d\u043e\u043c <br/>\"%s\"<br/> <span>\u043d\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442<' % broadcast_id, broadcast_page) is not None:\n            raise ExtractorError(\n                'Broadcast %s does not exist' % broadcast_id, expected=True)\n\n        # Adult content\n        if re.search('EroConfirmText\">', broadcast_page) is not None:\n\n            (username, password) = self._get_login_info()\n            if username is None:\n                self.raise_login_required('Erotic broadcasts allowed only for registered users')\n\n            login_form = {\n                'login-hint53': '1',\n                'confirm_erotic': '1',\n                'login': username,\n                'password': password,\n            }\n\n            request = compat_urllib_request.Request(\n                broadcast_url + '/?no_redirect=1', compat_urllib_parse.urlencode(login_form))\n            request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            broadcast_page = self._download_webpage(\n                request, broadcast_id, 'Logging in and confirming age')\n\n            if re.search('>\u041d\u0435\u0432\u0435\u0440\u043d\u044b\u0439 \u043b\u043e\u0433\u0438\u043d \u0438\u043b\u0438 \u043f\u0430\u0440\u043e\u043b\u044c<', broadcast_page) is not None:\n                raise ExtractorError('Unable to log in: bad username or password', expected=True)\n\n            adult_content = True\n        else:\n            adult_content = False\n\n        ticket = self._html_search_regex(\n            r\"window\\.broadcast_control\\.addFlashVar\\('file'\\s*,\\s*'([^']+)'\\)\",\n            broadcast_page, 'broadcast ticket')\n\n        url = 'http://smotri.com/broadcast/view/url/?ticket=%s' % ticket\n\n        broadcast_password = self._downloader.params.get('videopassword', None)\n        if broadcast_password:\n            url += '&pass=%s' % hashlib.md5(broadcast_password.encode('utf-8')).hexdigest()\n\n        broadcast_json_page = self._download_webpage(\n            url, broadcast_id, 'Downloading broadcast JSON')\n\n        try:\n            broadcast_json = json.loads(broadcast_json_page)\n\n            protected_broadcast = broadcast_json['_pass_protected'] == 1\n            if protected_broadcast and not broadcast_password:\n                raise ExtractorError(\n                    'This broadcast is protected by a password, use the --video-password option',\n                    expected=True)\n\n            broadcast_offline = broadcast_json['is_play'] == 0\n            if broadcast_offline:\n                raise ExtractorError('Broadcast %s is offline' % broadcast_id, expected=True)\n\n            rtmp_url = broadcast_json['_server']\n            mobj = re.search(r'^rtmp://[^/]+/(?P<app>.+)/?$', rtmp_url)\n            if not mobj:\n                raise ExtractorError('Unexpected broadcast rtmp URL')\n\n            broadcast_playpath = broadcast_json['_streamName']\n            broadcast_app = '%s/%s' % (mobj.group('app'), broadcast_json['_vidURL'])\n            broadcast_thumbnail = broadcast_json['_imgURL']\n            broadcast_title = self._live_title(broadcast_json['title'])\n            broadcast_description = broadcast_json['description']\n            broadcaster_nick = broadcast_json['nick']\n            broadcaster_login = broadcast_json['login']\n            rtmp_conn = 'S:%s' % uuid.uuid4().hex\n        except KeyError:\n            if protected_broadcast:\n                raise ExtractorError('Bad broadcast password', expected=True)\n            raise ExtractorError('Unexpected broadcast JSON')\n\n        return {\n            'id': broadcast_id,\n            'url': rtmp_url,\n            'title': broadcast_title,\n            'thumbnail': broadcast_thumbnail,\n            'description': broadcast_description,\n            'uploader': broadcaster_nick,\n            'uploader_id': broadcaster_login,\n            'age_limit': 18 if adult_content else 0,\n            'ext': 'flv',\n            'play_path': broadcast_playpath,\n            'player_url': 'http://pics.smotri.com/broadcast_play.swf',\n            'app': broadcast_app,\n            'rtmp_live': True,\n            'rtmp_conn': rtmp_conn,\n            'is_live': True,\n        }",
        "begin_line": 317,
        "end_line": 415,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.patreon.PatreonIE._real_extract#81",
        "src_path": "youtube_dl/extractor/patreon.py",
        "class_name": "youtube_dl.extractor.patreon.PatreonIE",
        "signature": "youtube_dl.extractor.patreon.PatreonIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage).strip()\n\n        attach_fn = self._html_search_regex(\n            r'<div class=\"attach\"><a target=\"_blank\" href=\"([^\"]+)\">',\n            webpage, 'attachment URL', default=None)\n        embed = self._html_search_regex(\n            r'<div[^>]+id=\"watchCreation\"[^>]*>\\s*<iframe[^>]+src=\"([^\"]+)\"',\n            webpage, 'embedded URL', default=None)\n\n        if attach_fn is not None:\n            video_url = 'http://www.patreon.com' + attach_fn\n            thumbnail = self._og_search_thumbnail(webpage)\n            uploader = self._html_search_regex(\n                r'<strong>(.*?)</strong> is creating', webpage, 'uploader')\n        elif embed is not None:\n            return self.url_result(embed)\n        else:\n            playlist = self._parse_json(self._search_regex(\n                r'(?s)new\\s+jPlayerPlaylist\\(\\s*\\{\\s*[^}]*},\\s*(\\[.*?,?\\s*\\])',\n                webpage, 'playlist JSON'),\n                video_id, transform_source=js_to_json)\n            data = playlist[0]\n            video_url = self._proto_relative_url(data['mp3'])\n            thumbnail = self._proto_relative_url(data.get('cover'))\n            uploader = data.get('artist')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp3',\n            'title': title,\n            'uploader': uploader,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 81,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.options.parseOpts#22",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options.parseOpts(overrideArguments=None)",
        "snippet": "def parseOpts(overrideArguments=None):\n    def _readOptions(filename_bytes, default=[]):\n        try:\n            optionf = open(filename_bytes)\n        except IOError:\n            return default  # silently skip if file is not present\n        try:\n            res = []\n            for l in optionf:\n                res += compat_shlex_split(l, comments=True)\n        finally:\n            optionf.close()\n        return res\n\n    def _readUserConf():\n        xdg_config_home = compat_getenv('XDG_CONFIG_HOME')\n        if xdg_config_home:\n            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')\n        else:\n            userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl.conf')\n        userConf = _readOptions(userConfFile, None)\n\n        if userConf is None:\n            appdata_dir = compat_getenv('appdata')\n            if appdata_dir:\n                userConf = _readOptions(\n                    os.path.join(appdata_dir, 'youtube-dl', 'config'),\n                    default=None)\n                if userConf is None:\n                    userConf = _readOptions(\n                        os.path.join(appdata_dir, 'youtube-dl', 'config.txt'),\n                        default=None)\n\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(compat_expanduser('~'), 'youtube-dl.conf'),\n                default=None)\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(compat_expanduser('~'), 'youtube-dl.conf.txt'),\n                default=None)\n\n        if userConf is None:\n            userConf = []\n\n        return userConf\n\n    def _format_option_string(option):\n        ''' ('-o', '--option') -> -o, --format METAVAR'''\n\n        opts = []\n\n        if option._short_opts:\n            opts.append(option._short_opts[0])\n        if option._long_opts:\n            opts.append(option._long_opts[0])\n        if len(opts) > 1:\n            opts.insert(1, ', ')\n\n        if option.takes_value():\n            opts.append(' %s' % option.metavar)\n\n        return \"\".join(opts)\n\n    def _comma_separated_values_options_callback(option, opt_str, value, parser):\n        setattr(parser.values, option.dest, value.split(','))\n\n    def _hide_login_info(opts):\n        opts = list(opts)\n        for private_opt in ['-p', '--password', '-u', '--username', '--video-password']:\n            try:\n                i = opts.index(private_opt)\n                opts[i + 1] = 'PRIVATE'\n            except ValueError:\n                pass\n        return opts\n\n    # No need to wrap help messages if we're on a wide console\n    columns = compat_get_terminal_size().columns\n    max_width = columns if columns else 80\n    max_help_position = 80\n\n    fmt = optparse.IndentedHelpFormatter(width=max_width, max_help_position=max_help_position)\n    fmt.format_option_strings = _format_option_string\n\n    kw = {\n        'version': __version__,\n        'formatter': fmt,\n        'usage': '%prog [OPTIONS] URL [URL...]',\n        'conflict_handler': 'resolve',\n    }\n\n    parser = optparse.OptionParser(**compat_kwargs(kw))\n\n    general = optparse.OptionGroup(parser, 'General Options')\n    general.add_option(\n        '-h', '--help',\n        action='help',\n        help='Print this help text and exit')\n    general.add_option(\n        '-v', '--version',\n        action='version',\n        help='Print program version and exit')\n    general.add_option(\n        '-U', '--update',\n        action='store_true', dest='update_self',\n        help='Update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')\n    general.add_option(\n        '-i', '--ignore-errors',\n        action='store_true', dest='ignoreerrors', default=False,\n        help='Continue on download errors, for example to skip unavailable videos in a playlist')\n    general.add_option(\n        '--abort-on-error',\n        action='store_false', dest='ignoreerrors',\n        help='Abort downloading of further videos (in the playlist or the command line) if an error occurs')\n    general.add_option(\n        '--dump-user-agent',\n        action='store_true', dest='dump_user_agent', default=False,\n        help='Display the current browser identification')\n    general.add_option(\n        '--list-extractors',\n        action='store_true', dest='list_extractors', default=False,\n        help='List all supported extractors')\n    general.add_option(\n        '--extractor-descriptions',\n        action='store_true', dest='list_extractor_descriptions', default=False,\n        help='Output descriptions of all supported extractors')\n    general.add_option(\n        '--force-generic-extractor',\n        action='store_true', dest='force_generic_extractor', default=False,\n        help='Force extraction to use the generic extractor')\n    general.add_option(\n        '--default-search',\n        dest='default_search', metavar='PREFIX',\n        help='Use this prefix for unqualified URLs. For example \"gvsearch2:\" downloads two videos from google videos for youtube-dl \"large apple\". Use the value \"auto\" to let youtube-dl guess (\"auto_warning\" to emit a warning when guessing). \"error\" just throws an error. The default value \"fixup_error\" repairs broken URLs, but emits an error if this is not possible instead of searching.')\n    general.add_option(\n        '--ignore-config',\n        action='store_true',\n        help='Do not read configuration files. '\n        'When given in the global configuration file /etc/youtube-dl.conf: '\n        'Do not read the user configuration in ~/.config/youtube-dl/config '\n        '(%APPDATA%/youtube-dl/config.txt on Windows)')\n    general.add_option(\n        '--flat-playlist',\n        action='store_const', dest='extract_flat', const='in_playlist',\n        default=False,\n        help='Do not extract the videos of a playlist, only list them.')\n    general.add_option(\n        '--no-color', '--no-colors',\n        action='store_true', dest='no_color',\n        default=False,\n        help='Do not emit color codes in output')\n\n    network = optparse.OptionGroup(parser, 'Network Options')\n    network.add_option(\n        '--proxy', dest='proxy',\n        default=None, metavar='URL',\n        help='Use the specified HTTP/HTTPS proxy. Pass in an empty string (--proxy \"\") for direct connection')\n    network.add_option(\n        '--socket-timeout',\n        dest='socket_timeout', type=float, default=None, metavar='SECONDS',\n        help='Time to wait before giving up, in seconds')\n    network.add_option(\n        '--source-address',\n        metavar='IP', dest='source_address', default=None,\n        help='Client-side IP address to bind to (experimental)',\n    )\n    network.add_option(\n        '-4', '--force-ipv4',\n        action='store_const', const='0.0.0.0', dest='source_address',\n        help='Make all connections via IPv4 (experimental)',\n    )\n    network.add_option(\n        '-6', '--force-ipv6',\n        action='store_const', const='::', dest='source_address',\n        help='Make all connections via IPv6 (experimental)',\n    )\n    network.add_option(\n        '--cn-verification-proxy',\n        dest='cn_verification_proxy', default=None, metavar='URL',\n        help='Use this proxy to verify the IP address for some Chinese sites. '\n        'The default proxy specified by --proxy (or none, if the options is not present) is used for the actual downloading. (experimental)'\n    )\n\n    selection = optparse.OptionGroup(parser, 'Video Selection')\n    selection.add_option(\n        '--playlist-start',\n        dest='playliststart', metavar='NUMBER', default=1, type=int,\n        help='Playlist video to start at (default is %default)')\n    selection.add_option(\n        '--playlist-end',\n        dest='playlistend', metavar='NUMBER', default=None, type=int,\n        help='Playlist video to end at (default is last)')\n    selection.add_option(\n        '--playlist-items',\n        dest='playlist_items', metavar='ITEM_SPEC', default=None,\n        help='Playlist video items to download. Specify indices of the videos in the playlist separated by commas like: \"--playlist-items 1,2,5,8\" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: \"--playlist-items 1-3,7,10-13\", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')\n    selection.add_option(\n        '--match-title',\n        dest='matchtitle', metavar='REGEX',\n        help='Download only matching titles (regex or caseless sub-string)')\n    selection.add_option(\n        '--reject-title',\n        dest='rejecttitle', metavar='REGEX',\n        help='Skip download for matching titles (regex or caseless sub-string)')\n    selection.add_option(\n        '--max-downloads',\n        dest='max_downloads', metavar='NUMBER', type=int, default=None,\n        help='Abort after downloading NUMBER files')\n    selection.add_option(\n        '--min-filesize',\n        metavar='SIZE', dest='min_filesize', default=None,\n        help='Do not download any videos smaller than SIZE (e.g. 50k or 44.6m)')\n    selection.add_option(\n        '--max-filesize',\n        metavar='SIZE', dest='max_filesize', default=None,\n        help='Do not download any videos larger than SIZE (e.g. 50k or 44.6m)')\n    selection.add_option(\n        '--date',\n        metavar='DATE', dest='date', default=None,\n        help='Download only videos uploaded in this date')\n    selection.add_option(\n        '--datebefore',\n        metavar='DATE', dest='datebefore', default=None,\n        help='Download only videos uploaded on or before this date (i.e. inclusive)')\n    selection.add_option(\n        '--dateafter',\n        metavar='DATE', dest='dateafter', default=None,\n        help='Download only videos uploaded on or after this date (i.e. inclusive)')\n    selection.add_option(\n        '--min-views',\n        metavar='COUNT', dest='min_views', default=None, type=int,\n        help='Do not download any videos with less than COUNT views')\n    selection.add_option(\n        '--max-views',\n        metavar='COUNT', dest='max_views', default=None, type=int,\n        help='Do not download any videos with more than COUNT views')\n    selection.add_option(\n        '--match-filter',\n        metavar='FILTER', dest='match_filter', default=None,\n        help=(\n            'Generic video filter (experimental). '\n            'Specify any key (see help for -o for a list of available keys) to'\n            ' match if the key is present, '\n            '!key to check if the key is not present,'\n            'key > NUMBER (like \"comment_count > 12\", also works with '\n            '>=, <, <=, !=, =) to compare against a number, and '\n            '& to require multiple matches. '\n            'Values which are not known are excluded unless you'\n            ' put a question mark (?) after the operator.'\n            'For example, to only match videos that have been liked more than '\n            '100 times and disliked less than 50 times (or the dislike '\n            'functionality is not available at the given service), but who '\n            'also have a description, use --match-filter '\n            '\"like_count > 100 & dislike_count <? 50 & description\" .'\n        ))\n    selection.add_option(\n        '--no-playlist',\n        action='store_true', dest='noplaylist', default=False,\n        help='Download only the video, if the URL refers to a video and a playlist.')\n    selection.add_option(\n        '--yes-playlist',\n        action='store_false', dest='noplaylist', default=False,\n        help='Download the playlist, if the URL refers to a video and a playlist.')\n    selection.add_option(\n        '--age-limit',\n        metavar='YEARS', dest='age_limit', default=None, type=int,\n        help='Download only videos suitable for the given age')\n    selection.add_option(\n        '--download-archive', metavar='FILE',\n        dest='download_archive',\n        help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')\n    selection.add_option(\n        '--include-ads',\n        dest='include_ads', action='store_true',\n        help='Download advertisements as well (experimental)')\n\n    authentication = optparse.OptionGroup(parser, 'Authentication Options')\n    authentication.add_option(\n        '-u', '--username',\n        dest='username', metavar='USERNAME',\n        help='Login with this account ID')\n    authentication.add_option(\n        '-p', '--password',\n        dest='password', metavar='PASSWORD',\n        help='Account password. If this option is left out, youtube-dl will ask interactively.')\n    authentication.add_option(\n        '-2', '--twofactor',\n        dest='twofactor', metavar='TWOFACTOR',\n        help='Two-factor auth code')\n    authentication.add_option(\n        '-n', '--netrc',\n        action='store_true', dest='usenetrc', default=False,\n        help='Use .netrc authentication data')\n    authentication.add_option(\n        '--video-password',\n        dest='videopassword', metavar='PASSWORD',\n        help='Video password (vimeo, smotri, youku)')\n\n    video_format = optparse.OptionGroup(parser, 'Video Format Options')\n    video_format.add_option(\n        '-f', '--format',\n        action='store', dest='format', metavar='FORMAT', default=None,\n        help='Video format code, see the \"FORMAT SELECTION\" for all the info')\n    video_format.add_option(\n        '--all-formats',\n        action='store_const', dest='format', const='all',\n        help='Download all available video formats')\n    video_format.add_option(\n        '--prefer-free-formats',\n        action='store_true', dest='prefer_free_formats', default=False,\n        help='Prefer free video formats unless a specific one is requested')\n    video_format.add_option(\n        '-F', '--list-formats',\n        action='store_true', dest='listformats',\n        help='List all available formats')\n    video_format.add_option(\n        '--youtube-include-dash-manifest',\n        action='store_true', dest='youtube_include_dash_manifest', default=True,\n        help=optparse.SUPPRESS_HELP)\n    video_format.add_option(\n        '--youtube-skip-dash-manifest',\n        action='store_false', dest='youtube_include_dash_manifest',\n        help='Do not download the DASH manifests and related data on YouTube videos')\n    video_format.add_option(\n        '--merge-output-format',\n        action='store', dest='merge_output_format', metavar='FORMAT', default=None,\n        help=(\n            'If a merge is required (e.g. bestvideo+bestaudio), '\n            'output to given container format. One of mkv, mp4, ogg, webm, flv. '\n            'Ignored if no merge is required'))\n\n    subtitles = optparse.OptionGroup(parser, 'Subtitle Options')\n    subtitles.add_option(\n        '--write-sub', '--write-srt',\n        action='store_true', dest='writesubtitles', default=False,\n        help='Write subtitle file')\n    subtitles.add_option(\n        '--write-auto-sub', '--write-automatic-sub',\n        action='store_true', dest='writeautomaticsub', default=False,\n        help='Write automatic subtitle file (YouTube only)')\n    subtitles.add_option(\n        '--all-subs',\n        action='store_true', dest='allsubtitles', default=False,\n        help='Download all the available subtitles of the video')\n    subtitles.add_option(\n        '--list-subs',\n        action='store_true', dest='listsubtitles', default=False,\n        help='List all available subtitles for the video')\n    subtitles.add_option(\n        '--sub-format',\n        action='store', dest='subtitlesformat', metavar='FORMAT', default='best',\n        help='Subtitle format, accepts formats preference, for example: \"srt\" or \"ass/srt/best\"')\n    subtitles.add_option(\n        '--sub-lang', '--sub-langs', '--srt-lang',\n        action='callback', dest='subtitleslangs', metavar='LANGS', type='str',\n        default=[], callback=_comma_separated_values_options_callback,\n        help='Languages of the subtitles to download (optional) separated by commas, use IETF language tags like \\'en,pt\\'')\n\n    downloader = optparse.OptionGroup(parser, 'Download Options')\n    downloader.add_option(\n        '-r', '--rate-limit',\n        dest='ratelimit', metavar='LIMIT',\n        help='Maximum download rate in bytes per second (e.g. 50K or 4.2M)')\n    downloader.add_option(\n        '-R', '--retries',\n        dest='retries', metavar='RETRIES', default=10,\n        help='Number of retries (default is %default), or \"infinite\".')\n    downloader.add_option(\n        '--buffer-size',\n        dest='buffersize', metavar='SIZE', default='1024',\n        help='Size of download buffer (e.g. 1024 or 16K) (default is %default)')\n    downloader.add_option(\n        '--no-resize-buffer',\n        action='store_true', dest='noresizebuffer', default=False,\n        help='Do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.')\n    downloader.add_option(\n        '--test',\n        action='store_true', dest='test', default=False,\n        help=optparse.SUPPRESS_HELP)\n    downloader.add_option(\n        '--playlist-reverse',\n        action='store_true',\n        help='Download playlist videos in reverse order')\n    downloader.add_option(\n        '--xattr-set-filesize',\n        dest='xattr_set_filesize', action='store_true',\n        help='Set file xattribute ytdl.filesize with expected filesize (experimental)')\n    downloader.add_option(\n        '--hls-prefer-native',\n        dest='hls_prefer_native', action='store_true',\n        help='Use the native HLS downloader instead of ffmpeg (experimental)')\n    downloader.add_option(\n        '--external-downloader',\n        dest='external_downloader', metavar='COMMAND',\n        help='Use the specified external downloader. '\n             'Currently supports %s' % ','.join(list_external_downloaders()))\n    downloader.add_option(\n        '--external-downloader-args',\n        dest='external_downloader_args', metavar='ARGS',\n        help='Give these arguments to the external downloader')\n\n    workarounds = optparse.OptionGroup(parser, 'Workarounds')\n    workarounds.add_option(\n        '--encoding',\n        dest='encoding', metavar='ENCODING',\n        help='Force the specified encoding (experimental)')\n    workarounds.add_option(\n        '--no-check-certificate',\n        action='store_true', dest='no_check_certificate', default=False,\n        help='Suppress HTTPS certificate validation')\n    workarounds.add_option(\n        '--prefer-insecure',\n        '--prefer-unsecure', action='store_true', dest='prefer_insecure',\n        help='Use an unencrypted connection to retrieve information about the video. (Currently supported only for YouTube)')\n    workarounds.add_option(\n        '--user-agent',\n        metavar='UA', dest='user_agent',\n        help='Specify a custom user agent')\n    workarounds.add_option(\n        '--referer',\n        metavar='URL', dest='referer', default=None,\n        help='Specify a custom referer, use if the video access is restricted to one domain',\n    )\n    workarounds.add_option(\n        '--add-header',\n        metavar='FIELD:VALUE', dest='headers', action='append',\n        help='Specify a custom HTTP header and its value, separated by a colon \\':\\'. You can use this option multiple times',\n    )\n    workarounds.add_option(\n        '--bidi-workaround',\n        dest='bidi_workaround', action='store_true',\n        help='Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')\n    workarounds.add_option(\n        '--sleep-interval', metavar='SECONDS',\n        dest='sleep_interval', type=float,\n        help='Number of seconds to sleep before each download.')\n\n    verbosity = optparse.OptionGroup(parser, 'Verbosity / Simulation Options')\n    verbosity.add_option(\n        '-q', '--quiet',\n        action='store_true', dest='quiet', default=False,\n        help='Activate quiet mode')\n    verbosity.add_option(\n        '--no-warnings',\n        dest='no_warnings', action='store_true', default=False,\n        help='Ignore warnings')\n    verbosity.add_option(\n        '-s', '--simulate',\n        action='store_true', dest='simulate', default=False,\n        help='Do not download the video and do not write anything to disk')\n    verbosity.add_option(\n        '--skip-download',\n        action='store_true', dest='skip_download', default=False,\n        help='Do not download the video')\n    verbosity.add_option(\n        '-g', '--get-url',\n        action='store_true', dest='geturl', default=False,\n        help='Simulate, quiet but print URL')\n    verbosity.add_option(\n        '-e', '--get-title',\n        action='store_true', dest='gettitle', default=False,\n        help='Simulate, quiet but print title')\n    verbosity.add_option(\n        '--get-id',\n        action='store_true', dest='getid', default=False,\n        help='Simulate, quiet but print id')\n    verbosity.add_option(\n        '--get-thumbnail',\n        action='store_true', dest='getthumbnail', default=False,\n        help='Simulate, quiet but print thumbnail URL')\n    verbosity.add_option(\n        '--get-description',\n        action='store_true', dest='getdescription', default=False,\n        help='Simulate, quiet but print video description')\n    verbosity.add_option(\n        '--get-duration',\n        action='store_true', dest='getduration', default=False,\n        help='Simulate, quiet but print video length')\n    verbosity.add_option(\n        '--get-filename',\n        action='store_true', dest='getfilename', default=False,\n        help='Simulate, quiet but print output filename')\n    verbosity.add_option(\n        '--get-format',\n        action='store_true', dest='getformat', default=False,\n        help='Simulate, quiet but print output format')\n    verbosity.add_option(\n        '-j', '--dump-json',\n        action='store_true', dest='dumpjson', default=False,\n        help='Simulate, quiet but print JSON information. See --output for a description of available keys.')\n    verbosity.add_option(\n        '-J', '--dump-single-json',\n        action='store_true', dest='dump_single_json', default=False,\n        help='Simulate, quiet but print JSON information for each command-line argument. If the URL refers to a playlist, dump the whole playlist information in a single line.')\n    verbosity.add_option(\n        '--print-json',\n        action='store_true', dest='print_json', default=False,\n        help='Be quiet and print the video information as JSON (video is still being downloaded).',\n    )\n    verbosity.add_option(\n        '--newline',\n        action='store_true', dest='progress_with_newline', default=False,\n        help='Output progress bar as new lines')\n    verbosity.add_option(\n        '--no-progress',\n        action='store_true', dest='noprogress', default=False,\n        help='Do not print progress bar')\n    verbosity.add_option(\n        '--console-title',\n        action='store_true', dest='consoletitle', default=False,\n        help='Display progress in console titlebar')\n    verbosity.add_option(\n        '-v', '--verbose',\n        action='store_true', dest='verbose', default=False,\n        help='Print various debugging information')\n    verbosity.add_option(\n        '--dump-pages', '--dump-intermediate-pages',\n        action='store_true', dest='dump_intermediate_pages', default=False,\n        help='Print downloaded pages encoded using base64 to debug problems (very verbose)')\n    verbosity.add_option(\n        '--write-pages',\n        action='store_true', dest='write_pages', default=False,\n        help='Write downloaded intermediary pages to files in the current directory to debug problems')\n    verbosity.add_option(\n        '--youtube-print-sig-code',\n        action='store_true', dest='youtube_print_sig_code', default=False,\n        help=optparse.SUPPRESS_HELP)\n    verbosity.add_option(\n        '--print-traffic', '--dump-headers',\n        dest='debug_printtraffic', action='store_true', default=False,\n        help='Display sent and read HTTP traffic')\n    verbosity.add_option(\n        '-C', '--call-home',\n        dest='call_home', action='store_true', default=False,\n        help='Contact the youtube-dl server for debugging')\n    verbosity.add_option(\n        '--no-call-home',\n        dest='call_home', action='store_false', default=False,\n        help='Do NOT contact the youtube-dl server for debugging')\n\n    filesystem = optparse.OptionGroup(parser, 'Filesystem Options')\n    filesystem.add_option(\n        '-a', '--batch-file',\n        dest='batchfile', metavar='FILE',\n        help='File containing URLs to download (\\'-\\' for stdin)')\n    filesystem.add_option(\n        '--id', default=False,\n        action='store_true', dest='useid', help='Use only video ID in file name')\n    filesystem.add_option(\n        '-o', '--output',\n        dest='outtmpl', metavar='TEMPLATE',\n        help=('Output filename template. Use %(title)s to get the title, '\n              '%(uploader)s for the uploader name, %(uploader_id)s for the uploader nickname if different, '\n              '%(autonumber)s to get an automatically incremented number, '\n              '%(ext)s for the filename extension, '\n              '%(format)s for the format description (like \"22 - 1280x720\" or \"HD\"), '\n              '%(format_id)s for the unique id of the format (like YouTube\\'s itags: \"137\"), '\n              '%(upload_date)s for the upload date (YYYYMMDD), '\n              '%(extractor)s for the provider (youtube, metacafe, etc), '\n              '%(id)s for the video id, '\n              '%(playlist_title)s, %(playlist_id)s, or %(playlist)s (=title if present, ID otherwise) for the playlist the video is in, '\n              '%(playlist_index)s for the position in the playlist. '\n              '%(height)s and %(width)s for the width and height of the video format. '\n              '%(resolution)s for a textual description of the resolution of the video format. '\n              '%% for a literal percent. '\n              'Use - to output to stdout. Can also be used to download to a different directory, '\n              'for example with -o \\'/my/downloads/%(uploader)s/%(title)s-%(id)s.%(ext)s\\' .'))\n    filesystem.add_option(\n        '--autonumber-size',\n        dest='autonumber_size', metavar='NUMBER',\n        help='Specify the number of digits in %(autonumber)s when it is present in output filename template or --auto-number option is given')\n    filesystem.add_option(\n        '--restrict-filenames',\n        action='store_true', dest='restrictfilenames', default=False,\n        help='Restrict filenames to only ASCII characters, and avoid \"&\" and spaces in filenames')\n    filesystem.add_option(\n        '-A', '--auto-number',\n        action='store_true', dest='autonumber', default=False,\n        help='[deprecated; use -o \"%(autonumber)s-%(title)s.%(ext)s\" ] Number downloaded files starting from 00000')\n    filesystem.add_option(\n        '-t', '--title',\n        action='store_true', dest='usetitle', default=False,\n        help='[deprecated] Use title in file name (default)')\n    filesystem.add_option(\n        '-l', '--literal', default=False,\n        action='store_true', dest='usetitle',\n        help='[deprecated] Alias of --title')\n    filesystem.add_option(\n        '-w', '--no-overwrites',\n        action='store_true', dest='nooverwrites', default=False,\n        help='Do not overwrite files')\n    filesystem.add_option(\n        '-c', '--continue',\n        action='store_true', dest='continue_dl', default=True,\n        help='Force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.')\n    filesystem.add_option(\n        '--no-continue',\n        action='store_false', dest='continue_dl',\n        help='Do not resume partially downloaded files (restart from beginning)')\n    filesystem.add_option(\n        '--no-part',\n        action='store_true', dest='nopart', default=False,\n        help='Do not use .part files - write directly into output file')\n    filesystem.add_option(\n        '--no-mtime',\n        action='store_false', dest='updatetime', default=True,\n        help='Do not use the Last-modified header to set the file modification time')\n    filesystem.add_option(\n        '--write-description',\n        action='store_true', dest='writedescription', default=False,\n        help='Write video description to a .description file')\n    filesystem.add_option(\n        '--write-info-json',\n        action='store_true', dest='writeinfojson', default=False,\n        help='Write video metadata to a .info.json file')\n    filesystem.add_option(\n        '--write-annotations',\n        action='store_true', dest='writeannotations', default=False,\n        help='Write video annotations to a .annotations.xml file')\n    filesystem.add_option(\n        '--load-info',\n        dest='load_info_filename', metavar='FILE',\n        help='JSON file containing the video information (created with the \"--write-info-json\" option)')\n    filesystem.add_option(\n        '--cookies',\n        dest='cookiefile', metavar='FILE',\n        help='File to read cookies from and dump cookie jar in')\n    filesystem.add_option(\n        '--cache-dir', dest='cachedir', default=None, metavar='DIR',\n        help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl . At the moment, only YouTube player files (for videos with obfuscated signatures) are cached, but that may change.')\n    filesystem.add_option(\n        '--no-cache-dir', action='store_const', const=False, dest='cachedir',\n        help='Disable filesystem caching')\n    filesystem.add_option(\n        '--rm-cache-dir',\n        action='store_true', dest='rm_cachedir',\n        help='Delete all filesystem cache files')\n\n    thumbnail = optparse.OptionGroup(parser, 'Thumbnail images')\n    thumbnail.add_option(\n        '--write-thumbnail',\n        action='store_true', dest='writethumbnail', default=False,\n        help='Write thumbnail image to disk')\n    thumbnail.add_option(\n        '--write-all-thumbnails',\n        action='store_true', dest='write_all_thumbnails', default=False,\n        help='Write all thumbnail image formats to disk')\n    thumbnail.add_option(\n        '--list-thumbnails',\n        action='store_true', dest='list_thumbnails', default=False,\n        help='Simulate and list all available thumbnail formats')\n\n    postproc = optparse.OptionGroup(parser, 'Post-processing Options')\n    postproc.add_option(\n        '-x', '--extract-audio',\n        action='store_true', dest='extractaudio', default=False,\n        help='Convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')\n    postproc.add_option(\n        '--audio-format', metavar='FORMAT', dest='audioformat', default='best',\n        help='Specify audio format: \"best\", \"aac\", \"vorbis\", \"mp3\", \"m4a\", \"opus\", or \"wav\"; \"%default\" by default')\n    postproc.add_option(\n        '--audio-quality', metavar='QUALITY',\n        dest='audioquality', default='5',\n        help='Specify ffmpeg/avconv audio quality, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default %default)')\n    postproc.add_option(\n        '--recode-video',\n        metavar='FORMAT', dest='recodevideo', default=None,\n        help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv|avi)')\n    postproc.add_option(\n        '--postprocessor-args',\n        dest='postprocessor_args', metavar='ARGS',\n        help='Give these arguments to the postprocessor')\n    postproc.add_option(\n        '-k', '--keep-video',\n        action='store_true', dest='keepvideo', default=False,\n        help='Keep the video file on disk after the post-processing; the video is erased by default')\n    postproc.add_option(\n        '--no-post-overwrites',\n        action='store_true', dest='nopostoverwrites', default=False,\n        help='Do not overwrite post-processed files; the post-processed files are overwritten by default')\n    postproc.add_option(\n        '--embed-subs',\n        action='store_true', dest='embedsubtitles', default=False,\n        help='Embed subtitles in the video (only for mkv and mp4 videos)')\n    postproc.add_option(\n        '--embed-thumbnail',\n        action='store_true', dest='embedthumbnail', default=False,\n        help='Embed thumbnail in the audio as cover art')\n    postproc.add_option(\n        '--add-metadata',\n        action='store_true', dest='addmetadata', default=False,\n        help='Write metadata to the video file')\n    postproc.add_option(\n        '--metadata-from-title',\n        metavar='FORMAT', dest='metafromtitle',\n        help='Parse additional metadata like song title / artist from the video title. '\n             'The format syntax is the same as --output, '\n             'the parsed parameters replace existing values. '\n             'Additional templates: %(album)s, %(artist)s. '\n             'Example: --metadata-from-title \"%(artist)s - %(title)s\" matches a title like '\n             '\"Coldplay - Paradise\"')\n    postproc.add_option(\n        '--xattrs',\n        action='store_true', dest='xattrs', default=False,\n        help='Write metadata to the video file\\'s xattrs (using dublin core and xdg standards)')\n    postproc.add_option(\n        '--fixup',\n        metavar='POLICY', dest='fixup', default='detect_or_warn',\n        help='Automatically correct known faults of the file. '\n             'One of never (do nothing), warn (only emit a warning), '\n             'detect_or_warn (the default; fix file if we can, warn otherwise)')\n    postproc.add_option(\n        '--prefer-avconv',\n        action='store_false', dest='prefer_ffmpeg',\n        help='Prefer avconv over ffmpeg for running the postprocessors (default)')\n    postproc.add_option(\n        '--prefer-ffmpeg',\n        action='store_true', dest='prefer_ffmpeg',\n        help='Prefer ffmpeg over avconv for running the postprocessors')\n    postproc.add_option(\n        '--ffmpeg-location', '--avconv-location', metavar='PATH',\n        dest='ffmpeg_location',\n        help='Location of the ffmpeg/avconv binary; either the path to the binary or its containing directory.')\n    postproc.add_option(\n        '--exec',\n        metavar='CMD', dest='exec_cmd',\n        help='Execute a command on the file after downloading, similar to find\\'s -exec syntax. Example: --exec \\'adb push {} /sdcard/Music/ && rm {}\\'')\n    postproc.add_option(\n        '--convert-subtitles', '--convert-subs',\n        metavar='FORMAT', dest='convertsubtitles', default=None,\n        help='Convert the subtitles to other format (currently supported: srt|ass|vtt)')\n\n    parser.add_option_group(general)\n    parser.add_option_group(network)\n    parser.add_option_group(selection)\n    parser.add_option_group(downloader)\n    parser.add_option_group(filesystem)\n    parser.add_option_group(thumbnail)\n    parser.add_option_group(verbosity)\n    parser.add_option_group(workarounds)\n    parser.add_option_group(video_format)\n    parser.add_option_group(subtitles)\n    parser.add_option_group(authentication)\n    parser.add_option_group(postproc)\n\n    if overrideArguments is not None:\n        opts, args = parser.parse_args(overrideArguments)\n        if opts.verbose:\n            write_string('[debug] Override config: ' + repr(overrideArguments) + '\\n')\n    else:\n        def compat_conf(conf):\n            if sys.version_info < (3,):\n                return [a.decode(preferredencoding(), 'replace') for a in conf]\n            return conf\n\n        command_line_conf = compat_conf(sys.argv[1:])\n\n        if '--ignore-config' in command_line_conf:\n            system_conf = []\n            user_conf = []\n        else:\n            system_conf = compat_conf(_readOptions('/etc/youtube-dl.conf'))\n            if '--ignore-config' in system_conf:\n                user_conf = []\n            else:\n                user_conf = compat_conf(_readUserConf())\n        argv = system_conf + user_conf + command_line_conf\n\n        opts, args = parser.parse_args(argv)\n        if opts.verbose:\n            write_string('[debug] System config: ' + repr(_hide_login_info(system_conf)) + '\\n')\n            write_string('[debug] User config: ' + repr(_hide_login_info(user_conf)) + '\\n')\n            write_string('[debug] Command-line args: ' + repr(_hide_login_info(command_line_conf)) + '\\n')\n\n    return parser, opts, args",
        "begin_line": 22,
        "end_line": 801,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.options._readOptions#23",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._readOptions(filename_bytes, default=[])",
        "snippet": "    def _readOptions(filename_bytes, default=[]):\n        try:\n            optionf = open(filename_bytes)\n        except IOError:\n            return default  # silently skip if file is not present\n        try:\n            res = []\n            for l in optionf:\n                res += compat_shlex_split(l, comments=True)\n        finally:\n            optionf.close()\n        return res",
        "begin_line": 23,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.options._readUserConf#36",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._readUserConf()",
        "snippet": "    def _readUserConf():\n        xdg_config_home = compat_getenv('XDG_CONFIG_HOME')\n        if xdg_config_home:\n            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')\n        else:\n            userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl.conf')\n        userConf = _readOptions(userConfFile, None)\n\n        if userConf is None:\n            appdata_dir = compat_getenv('appdata')\n            if appdata_dir:\n                userConf = _readOptions(\n                    os.path.join(appdata_dir, 'youtube-dl', 'config'),\n                    default=None)\n                if userConf is None:\n                    userConf = _readOptions(\n                        os.path.join(appdata_dir, 'youtube-dl', 'config.txt'),\n                        default=None)\n\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(compat_expanduser('~'), 'youtube-dl.conf'),\n                default=None)\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(compat_expanduser('~'), 'youtube-dl.conf.txt'),\n                default=None)\n\n        if userConf is None:\n            userConf = []\n\n        return userConf",
        "begin_line": 36,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.options._format_option_string#73",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._format_option_string(option)",
        "snippet": "    def _format_option_string(option):\n        ''' ('-o', '--option') -> -o, --format METAVAR'''\n\n        opts = []\n\n        if option._short_opts:\n            opts.append(option._short_opts[0])\n        if option._long_opts:\n            opts.append(option._long_opts[0])\n        if len(opts) > 1:\n            opts.insert(1, ', ')\n\n        if option.takes_value():\n            opts.append(' %s' % option.metavar)\n\n        return \"\".join(opts)",
        "begin_line": 73,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.options._comma_separated_values_options_callback#90",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._comma_separated_values_options_callback(option, opt_str, value, parser)",
        "snippet": "    def _comma_separated_values_options_callback(option, opt_str, value, parser):\n        setattr(parser.values, option.dest, value.split(','))",
        "begin_line": 90,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.options._hide_login_info#93",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._hide_login_info(opts)",
        "snippet": "    def _hide_login_info(opts):\n        opts = list(opts)\n        for private_opt in ['-p', '--password', '-u', '--username', '--video-password']:\n            try:\n                i = opts.index(private_opt)\n                opts[i + 1] = 'PRIVATE'\n            except ValueError:\n                pass\n        return opts",
        "begin_line": 93,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.options.compat_conf#777",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options.compat_conf(conf)",
        "snippet": "        def compat_conf(conf):\n            if sys.version_info < (3,):\n                return [a.decode(preferredencoding(), 'replace') for a in conf]\n            return conf",
        "begin_line": 777,
        "end_line": 780,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.videott.VideoTtIE._real_extract#34",
        "src_path": "youtube_dl/extractor/videott.py",
        "class_name": "youtube_dl.extractor.videott.VideoTtIE",
        "signature": "youtube_dl.extractor.videott.VideoTtIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        settings = self._download_json(\n            'http://www.video.tt/player_control/settings.php?v=%s' % video_id, video_id,\n            'Downloading video JSON')['settings']\n\n        video = settings['video_details']['video']\n\n        formats = [\n            {\n                'url': base64.b64decode(res['u'].encode('utf-8')).decode('utf-8'),\n                'ext': 'flv',\n                'format_id': res['l'],\n            } for res in settings['res'] if res['u']\n        ]\n\n        return {\n            'id': video_id,\n            'title': video['title'],\n            'description': video['description'],\n            'thumbnail': settings['config']['thumbnail'],\n            'upload_date': unified_strdate(video['added']),\n            'uploader': video['owner'],\n            'view_count': int_or_none(video['view_count']),\n            'comment_count': None if video.get('comment_count') == '--' else int_or_none(video['comment_count']),\n            'like_count': int_or_none(video['liked']),\n            'dislike_count': int_or_none(video['disliked']),\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.servingsys.ServingSysIE._real_extract#47",
        "src_path": "youtube_dl/extractor/servingsys.py",
        "class_name": "youtube_dl.extractor.servingsys.ServingSysIE",
        "signature": "youtube_dl.extractor.servingsys.ServingSysIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        pl_id = self._match_id(url)\n        vast_doc = self._download_xml(url, pl_id)\n\n        title = vast_doc.find('.//AdTitle').text\n        media = vast_doc.find('.//MediaFile').text\n        info_url = self._search_regex(r'&adData=([^&]+)&', media, 'info URL')\n\n        doc = self._download_xml(info_url, pl_id, 'Downloading video info')\n        entries = [{\n            '_type': 'video',\n            'id': a.attrib['id'],\n            'title': '%s (%s)' % (title, a.attrib['assetID']),\n            'url': a.attrib['URL'],\n            'duration': int_or_none(a.attrib.get('length')),\n            'tbr': int_or_none(a.attrib.get('bitrate')),\n            'height': int_or_none(a.attrib.get('height')),\n            'width': int_or_none(a.attrib.get('width')),\n        } for a in doc.findall('.//AdditionalAssets/asset')]\n\n        return {\n            '_type': 'playlist',\n            'id': pl_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 47,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kanalplay.KanalPlayIE._fix_subtitles#38",
        "src_path": "youtube_dl/extractor/kanalplay.py",
        "class_name": "youtube_dl.extractor.kanalplay.KanalPlayIE",
        "signature": "youtube_dl.extractor.kanalplay.KanalPlayIE._fix_subtitles(self, subs)",
        "snippet": "    def _fix_subtitles(self, subs):\n        return '\\r\\n\\r\\n'.join(\n            '%s\\r\\n%s --> %s\\r\\n%s'\n            % (\n                num,\n                srt_subtitles_timecode(item['startMillis'] / 1000.0),\n                srt_subtitles_timecode(item['endMillis'] / 1000.0),\n                item['text'],\n            ) for num, item in enumerate(subs, 1))",
        "begin_line": 38,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kanalplay.KanalPlayIE._get_subtitles#48",
        "src_path": "youtube_dl/extractor/kanalplay.py",
        "class_name": "youtube_dl.extractor.kanalplay.KanalPlayIE",
        "signature": "youtube_dl.extractor.kanalplay.KanalPlayIE._get_subtitles(self, channel_id, video_id)",
        "snippet": "    def _get_subtitles(self, channel_id, video_id):\n        subs = self._download_json(\n            'http://www.kanal%splay.se/api/subtitles/%s' % (channel_id, video_id),\n            video_id, 'Downloading subtitles JSON', fatal=False)\n        return {'se': [{'ext': 'srt', 'data': self._fix_subtitles(subs)}]} if subs else {}",
        "begin_line": 48,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kanalplay.KanalPlayIE._real_extract#54",
        "src_path": "youtube_dl/extractor/kanalplay.py",
        "class_name": "youtube_dl.extractor.kanalplay.KanalPlayIE",
        "signature": "youtube_dl.extractor.kanalplay.KanalPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        channel_id = mobj.group('channel_id')\n\n        video = self._download_json(\n            'http://www.kanal%splay.se/api/getVideo?format=FLASH&videoId=%s' % (channel_id, video_id),\n            video_id)\n\n        reasons_for_no_streams = video.get('reasonsForNoStreams')\n        if reasons_for_no_streams:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, '\\n'.join(reasons_for_no_streams)),\n                expected=True)\n\n        title = video['title']\n        description = video.get('description')\n        duration = float_or_none(video.get('length'), 1000)\n        thumbnail = video.get('posterUrl')\n\n        stream_base_url = video['streamBaseUrl']\n\n        formats = [{\n            'url': stream_base_url,\n            'play_path': stream['source'],\n            'ext': 'flv',\n            'tbr': float_or_none(stream.get('bitrate'), 1000),\n            'rtmp_real_time': True,\n        } for stream in video['streams']]\n        self._sort_formats(formats)\n\n        subtitles = {}\n        if video.get('hasSubtitle'):\n            subtitles = self.extract_subtitles(channel_id, video_id)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 54,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nfb.NFBIE._real_extract#32",
        "src_path": "youtube_dl/extractor/nfb.py",
        "class_name": "youtube_dl.extractor.nfb.NFBIE",
        "signature": "youtube_dl.extractor.nfb.NFBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        page = self._download_webpage(\n            'https://www.nfb.ca/film/%s' % video_id, video_id,\n            'Downloading film page')\n\n        uploader_id = self._html_search_regex(r'<a class=\"director-link\" href=\"/explore-all-directors/([^/]+)/\"',\n                                              page, 'director id', fatal=False)\n        uploader = self._html_search_regex(r'<em class=\"director-name\" itemprop=\"name\">([^<]+)</em>',\n                                           page, 'director name', fatal=False)\n\n        request = compat_urllib_request.Request('https://www.nfb.ca/film/%s/player_config' % video_id,\n                                                compat_urllib_parse.urlencode({'getConfig': 'true'}).encode('ascii'))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        request.add_header('X-NFB-Referer', 'http://www.nfb.ca/medias/flash/NFBVideoPlayer.swf')\n\n        config = self._download_xml(request, video_id, 'Downloading player config XML')\n\n        title = None\n        description = None\n        thumbnail = None\n        duration = None\n        formats = []\n\n        def extract_thumbnail(media):\n            thumbnails = {}\n            for asset in media.findall('assets/asset'):\n                thumbnails[asset.get('quality')] = asset.find('default/url').text\n            if not thumbnails:\n                return None\n            if 'high' in thumbnails:\n                return thumbnails['high']\n            return list(thumbnails.values())[0]\n\n        for media in config.findall('./player/stream/media'):\n            if media.get('type') == 'posterImage':\n                thumbnail = extract_thumbnail(media)\n            elif media.get('type') == 'video':\n                duration = int(media.get('duration'))\n                title = media.find('title').text\n                description = media.find('description').text\n                # It seems assets always go from lower to better quality, so no need to sort\n                for asset in media.findall('assets/asset'):\n                    for x in asset:\n                        formats.append({\n                            'url': x.find('streamerURI').text,\n                            'app': x.find('streamerURI').text.split('/', 3)[3],\n                            'play_path': x.find('url').text,\n                            'rtmp_live': False,\n                            'ext': 'mp4',\n                            'format_id': '%s-%s' % (x.tag, asset.get('quality')),\n                        })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.heise.HeiseIE._real_extract#36",
        "src_path": "youtube_dl/extractor/heise.py",
        "class_name": "youtube_dl.extractor.heise.HeiseIE",
        "signature": "youtube_dl.extractor.heise.HeiseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        container_id = self._search_regex(\n            r'<div class=\"videoplayerjw\".*?data-container=\"([0-9]+)\"',\n            webpage, 'container ID')\n        sequenz_id = self._search_regex(\n            r'<div class=\"videoplayerjw\".*?data-sequenz=\"([0-9]+)\"',\n            webpage, 'sequenz ID')\n        data_url = 'http://www.heise.de/videout/feed?container=%s&sequenz=%s' % (container_id, sequenz_id)\n        doc = self._download_xml(data_url, video_id)\n\n        info = {\n            'id': video_id,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'timestamp': parse_iso8601(\n                self._html_search_meta('date', webpage)),\n            'description': self._og_search_description(webpage),\n        }\n\n        title = self._html_search_meta('fulltitle', webpage)\n        if title:\n            info['title'] = title\n        else:\n            info['title'] = self._og_search_title(webpage)\n\n        formats = []\n        for source_node in doc.findall('.//{http://rss.jwpcdn.com/}source'):\n            label = source_node.attrib['label']\n            height = int_or_none(self._search_regex(\n                r'^(.*?_)?([0-9]+)p$', label, 'height', default=None))\n            video_url = source_node.attrib['file']\n            ext = determine_ext(video_url, '')\n            formats.append({\n                'url': video_url,\n                'format_note': label,\n                'format_id': '%s_%s' % (ext, label),\n                'height': height,\n            })\n        self._sort_formats(formats)\n        info['formats'] = formats\n\n        return info",
        "begin_line": 36,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE._real_extract#28",
        "src_path": "youtube_dl/extractor/worldstarhiphop.py",
        "class_name": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE",
        "signature": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        m_vevo_id = re.search(r'videoId=(.*?)&amp?', webpage)\n        if m_vevo_id is not None:\n            return self.url_result('vevo:%s' % m_vevo_id.group(1), ie='Vevo')\n\n        video_url = self._search_regex(\n            [r'so\\.addVariable\\(\"file\",\"(.*?)\"\\)',\n             r'<div class=\"artlist\">\\s*<a[^>]+href=\"([^\"]+)\">'],\n            webpage, 'video URL')\n\n        if 'youtube' in video_url:\n            return self.url_result(video_url, ie='Youtube')\n\n        video_title = self._html_search_regex(\n            [r'(?s)<div class=\"content-heading\">\\s*<h1>(.*?)</h1>',\n             r'<span[^>]+class=\"tc-sp-pinned-title\">(.*)</span>'],\n            webpage, 'title')\n\n        # Getting thumbnail and if not thumbnail sets correct title for WSHH candy video.\n        thumbnail = self._html_search_regex(\n            r'rel=\"image_src\" href=\"(.*)\" />', webpage, 'thumbnail',\n            default=None)\n        if not thumbnail:\n            _title = r'candytitles.*>(.*)</span>'\n            mobj = re.search(_title, webpage)\n            if mobj is not None:\n                video_title = mobj.group(1)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 28,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.groupon.GrouponIE._real_extract#28",
        "src_path": "youtube_dl/extractor/groupon.py",
        "class_name": "youtube_dl.extractor.groupon.GrouponIE",
        "signature": "youtube_dl.extractor.groupon.GrouponIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n\n        payload = self._parse_json(self._search_regex(\n            r'var\\s+payload\\s*=\\s*(.*?);\\n', webpage, 'payload'), playlist_id)\n        videos = payload['carousel'].get('dealVideos', [])\n        entries = []\n        for v in videos:\n            if v.get('provider') != 'OOYALA':\n                self.report_warning(\n                    '%s: Unsupported video provider %s, skipping video' %\n                    (playlist_id, v.get('provider')))\n                continue\n            entries.append(self.url_result('ooyala:%s' % v['media']))\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'entries': entries,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 28,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vlive.VLiveIE._real_extract#33",
        "src_path": "youtube_dl/extractor/vlive.py",
        "class_name": "youtube_dl.extractor.vlive.VLiveIE",
        "signature": "youtube_dl.extractor.vlive.VLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://m.vlive.tv/video/%s' % video_id,\n            video_id, note='Download video page')\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        creator = self._html_search_regex(\n            r'<span[^>]+class=\"name\">([^<>]+)</span>', webpage, 'creator')\n\n        url = 'http://global.apis.naver.com/globalV/globalV/vod/%s/playinfo?' % video_id\n        msgpad = '%.0f' % (time() * 1000)\n        md = b64encode(\n            hmac.new(self._SECRET.encode('ascii'),\n                     (url[:255] + msgpad).encode('ascii'), sha1).digest()\n        )\n        url += '&' + compat_urllib_parse.urlencode({'msgpad': msgpad, 'md': md})\n        playinfo = self._download_json(url, video_id, 'Downloading video json')\n\n        if playinfo.get('message', '') != 'success':\n            raise ExtractorError(playinfo.get('message', 'JSON request unsuccessful'))\n\n        if not playinfo.get('result'):\n            raise ExtractorError('No videos found.')\n\n        formats = []\n        for vid in playinfo['result'].get('videos', {}).get('list', []):\n            formats.append({\n                'url': vid['source'],\n                'ext': 'mp4',\n                'abr': vid.get('bitrate', {}).get('audio'),\n                'vbr': vid.get('bitrate', {}).get('video'),\n                'format_id': vid['encodingOption']['name'],\n                'height': vid.get('height'),\n                'width': vid.get('width'),\n            })\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for caption in playinfo['result'].get('captions', {}).get('list', []):\n            subtitles[caption['language']] = [\n                {'ext': determine_ext(caption['source'], default_ext='vtt'),\n                 'url': caption['source']}]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'creator': creator,\n            'thumbnail': thumbnail,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 33,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.firsttv.FirstTVIE._real_extract#41",
        "src_path": "youtube_dl/extractor/firsttv.py",
        "class_name": "youtube_dl.extractor.firsttv.FirstTVIE",
        "signature": "youtube_dl.extractor.firsttv.FirstTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id, 'Downloading page')\n\n        video_url = self._html_search_regex(\n            r'''(?s)(?:jwplayer\\('flashvideoportal_1'\\)\\.setup\\({|var\\s+playlistObj\\s*=).*?'file'\\s*:\\s*'([^']+)'.*?}\\);''',\n            webpage, 'video URL')\n\n        title = self._html_search_regex(\n            [r'<div class=\"tv_translation\">\\s*<h1><a href=\"[^\"]+\">([^<]*)</a>',\n             r\"'title'\\s*:\\s*'([^']+)'\"], webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"descr\">\\s*<div>&nbsp;</div>\\s*<p>([^<]*)</p></div>',\n            webpage, 'description', default=None) or self._html_search_meta(\n                'description', webpage, 'description')\n\n        thumbnail = self._og_search_thumbnail(webpage)\n        duration = self._og_search_property(\n            'video:duration', webpage,\n            'video duration', fatal=False)\n\n        like_count = self._html_search_regex(\n            r'title=\"\u041f\u043e\u043d\u0440\u0430\u0432\u0438\u043b\u043e\u0441\u044c\".*?/></label> \\[(\\d+)\\]',\n            webpage, 'like count', default=None)\n        dislike_count = self._html_search_regex(\n            r'title=\"\u041d\u0435 \u043f\u043e\u043d\u0440\u0430\u0432\u0438\u043b\u043e\u0441\u044c\".*?/></label> \\[(\\d+)\\]',\n            webpage, 'dislike count', default=None)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title,\n            'description': description,\n            'duration': int_or_none(duration),\n            'like_count': int_or_none(like_count),\n            'dislike_count': int_or_none(dislike_count),\n        }",
        "begin_line": 41,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooIE._real_extract#161",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooIE",
        "signature": "youtube_dl.extractor.yahoo.YahooIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id') or self._match_id(url)\n        page_id = mobj.group('id')\n        url = mobj.group('url')\n        host = mobj.group('host')\n        webpage = self._download_webpage(url, display_id)\n\n        # Look for iframed media first\n        iframe_m = re.search(r'<iframe[^>]+src=\"(/video/.+?-\\d+\\.html\\?format=embed.*?)\"', webpage)\n        if iframe_m:\n            iframepage = self._download_webpage(\n                host + iframe_m.group(1), display_id, 'Downloading iframe webpage')\n            items_json = self._search_regex(\n                r'mediaItems: (\\[.+?\\])$', iframepage, 'items', flags=re.MULTILINE, default=None)\n            if items_json:\n                items = json.loads(items_json)\n                video_id = items[0]['id']\n                return self._get_info(video_id, display_id, webpage)\n        # Look for NBCSports iframes\n        nbc_sports_url = NBCSportsVPlayerIE._extract_url(webpage)\n        if nbc_sports_url:\n            return self.url_result(nbc_sports_url, 'NBCSportsVPlayer')\n\n        # Query result is often embedded in webpage as JSON. Sometimes explicit requests\n        # to video API results in a failure with geo restriction reason therefore using\n        # embedded query result when present sounds reasonable.\n        config_json = self._search_regex(\n            r'window\\.Af\\.bootstrap\\[[^\\]]+\\]\\s*=\\s*({.*?\"applet_type\"\\s*:\\s*\"td-applet-videoplayer\".*?});(?:</script>|$)',\n            webpage, 'videoplayer applet', default=None)\n        if config_json:\n            config = self._parse_json(config_json, display_id, fatal=False)\n            if config:\n                sapi = config.get('models', {}).get('applet_model', {}).get('data', {}).get('sapi')\n                if sapi:\n                    return self._extract_info(display_id, sapi, webpage)\n\n        items_json = self._search_regex(\n            r'mediaItems: ({.*?})$', webpage, 'items', flags=re.MULTILINE,\n            default=None)\n        if items_json is None:\n            CONTENT_ID_REGEXES = [\n                r'YUI\\.namespace\\(\"Media\"\\)\\.CONTENT_ID\\s*=\\s*\"([^\"]+)\"',\n                r'root\\.App\\.Cache\\.context\\.videoCache\\.curVideo = \\{\"([^\"]+)\"',\n                r'\"first_videoid\"\\s*:\\s*\"([^\"]+)\"',\n                r'%s[^}]*\"ccm_id\"\\s*:\\s*\"([^\"]+)\"' % re.escape(page_id),\n            ]\n            video_id = self._search_regex(CONTENT_ID_REGEXES, webpage, 'content ID')\n        else:\n            items = json.loads(items_json)\n            info = items['mediaItems']['query']['results']['mediaObj'][0]\n            # The 'meta' field is not always in the video webpage, we request it\n            # from another page\n            video_id = info['id']\n        return self._get_info(video_id, display_id, webpage)",
        "begin_line": 161,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooIE._extract_info#217",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooIE",
        "signature": "youtube_dl.extractor.yahoo.YahooIE._extract_info(self, display_id, query, webpage)",
        "snippet": "    def _extract_info(self, display_id, query, webpage):\n        info = query['query']['results']['mediaObj'][0]\n        meta = info.get('meta')\n        video_id = info.get('id')\n\n        if not meta:\n            msg = info['status'].get('msg')\n            if msg:\n                raise ExtractorError(\n                    '%s returned error: %s' % (self.IE_NAME, msg), expected=True)\n            raise ExtractorError('Unable to extract media object meta')\n\n        formats = []\n        for s in info['streams']:\n            format_info = {\n                'width': int_or_none(s.get('width')),\n                'height': int_or_none(s.get('height')),\n                'tbr': int_or_none(s.get('bitrate')),\n            }\n\n            host = s['host']\n            path = s['path']\n            if host.startswith('rtmp'):\n                format_info.update({\n                    'url': host,\n                    'play_path': path,\n                    'ext': 'flv',\n                })\n            else:\n                if s.get('format') == 'm3u8_playlist':\n                    format_info['protocol'] = 'm3u8_native'\n                    format_info['ext'] = 'mp4'\n                format_url = compat_urlparse.urljoin(host, path)\n                format_info['url'] = format_url\n            formats.append(format_info)\n\n        self._sort_formats(formats)\n\n        closed_captions = self._html_search_regex(\n            r'\"closedcaptions\":(\\[[^\\]]+\\])', webpage, 'closed captions',\n            default='[]')\n\n        cc_json = self._parse_json(closed_captions, video_id, fatal=False)\n        subtitles = {}\n        if cc_json:\n            for closed_caption in cc_json:\n                lang = closed_caption['lang']\n                if lang not in subtitles:\n                    subtitles[lang] = []\n                subtitles[lang].append({\n                    'url': closed_caption['url'],\n                    'ext': mimetype2ext(closed_caption['content_type']),\n                })\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': unescapeHTML(meta['title']),\n            'formats': formats,\n            'description': clean_html(meta['description']),\n            'thumbnail': meta['thumbnail'] if meta.get('thumbnail') else self._og_search_thumbnail(webpage),\n            'duration': int_or_none(meta.get('duration')),\n            'subtitles': subtitles,\n        }",
        "begin_line": 217,
        "end_line": 280,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooIE._get_info#282",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooIE",
        "signature": "youtube_dl.extractor.yahoo.YahooIE._get_info(self, video_id, display_id, webpage)",
        "snippet": "    def _get_info(self, video_id, display_id, webpage):\n        region = self._search_regex(\n            r'\\\\?\"region\\\\?\"\\s*:\\s*\\\\?\"([^\"]+?)\\\\?\"',\n            webpage, 'region', fatal=False, default='US')\n        data = compat_urllib_parse.urlencode({\n            'protocol': 'http',\n            'region': region,\n        })\n        query_url = (\n            'https://video.media.yql.yahoo.com/v1/video/sapi/streams/'\n            '{id}?{data}'.format(id=video_id, data=data))\n        query_result = self._download_json(\n            query_url, display_id, 'Downloading video info')\n        return self._extract_info(display_id, query_result, webpage)",
        "begin_line": 282,
        "end_line": 295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooSearchIE._get_n_results#304",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooSearchIE",
        "signature": "youtube_dl.extractor.yahoo.YahooSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n        entries = []\n        for pagenum in itertools.count(0):\n            result_url = 'http://video.search.yahoo.com/search/?p=%s&fr=screen&o=js&gs=0&b=%d' % (compat_urllib_parse.quote_plus(query), pagenum * 30)\n            info = self._download_json(result_url, query,\n                                       note='Downloading results page ' + str(pagenum + 1))\n            m = info['m']\n            results = info['results']\n\n            for (i, r) in enumerate(results):\n                if (pagenum * 30) + i >= n:\n                    break\n                mobj = re.search(r'(?P<url>screen\\.yahoo\\.com/.*?-\\d*?\\.html)\"', r)\n                e = self.url_result('http://' + mobj.group('url'), 'Yahoo')\n                entries.append(e)\n            if (pagenum * 30 + i >= n) or (m['last'] >= (m['total'] - 1)):\n                break\n\n        return {\n            '_type': 'playlist',\n            'id': query,\n            'entries': entries,\n        }",
        "begin_line": 304,
        "end_line": 327,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xminus.XMinusIE._real_extract#34",
        "src_path": "youtube_dl/extractor/xminus.py",
        "class_name": "youtube_dl.extractor.xminus.XMinusIE",
        "signature": "youtube_dl.extractor.xminus.XMinusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        artist = self._html_search_regex(\n            r'minus_track\\.artist=\"(.+?)\"', webpage, 'artist')\n        title = artist + '-' + self._html_search_regex(\n            r'minus_track\\.title=\"(.+?)\"', webpage, 'title')\n        duration = int_or_none(self._html_search_regex(\n            r'minus_track\\.dur_sec=\\'([0-9]*?)\\'',\n            webpage, 'duration', fatal=False))\n        filesize_approx = parse_filesize(self._html_search_regex(\n            r'<div id=\"finfo\"[^>]*>\\s*\u2193\\s*([0-9.]+\\s*[a-zA-Z][bB])',\n            webpage, 'approximate filesize', fatal=False))\n        tbr = int_or_none(self._html_search_regex(\n            r'<div class=\"quality[^\"]*\"></div>\\s*([0-9]+)\\s*kbps',\n            webpage, 'bitrate', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'<div class=\"quality.*?\u25ba ([0-9]+)',\n            webpage, 'view count', fatal=False))\n        description = self._html_search_regex(\n            r'(?s)<div id=\"song_texts\">(.*?)</div><br',\n            webpage, 'song lyrics', fatal=False)\n        if description:\n            description = re.sub(' *\\r *', '\\n', description)\n\n        enc_token = self._html_search_regex(\n            r'minus_track\\.s?tkn=\"(.+?)\"', webpage, 'enc_token')\n        token = ''.join(\n            c if pos == 3 else compat_chr(compat_ord(c) - 1)\n            for pos, c in enumerate(reversed(enc_token)))\n        video_url = 'http://x-minus.org/dwlf/%s/%s.mp3' % (video_id, token)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'duration': duration,\n            'filesize_approx': filesize_approx,\n            'tbr': tbr,\n            'view_count': view_count,\n            'description': description,\n        }",
        "begin_line": 34,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.newstube.NewstubeIE._real_extract#27",
        "src_path": "youtube_dl/extractor/newstube.py",
        "class_name": "youtube_dl.extractor.newstube.NewstubeIE",
        "signature": "youtube_dl.extractor.newstube.NewstubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        video_guid = self._html_search_regex(\n            r'<meta property=\"og:video:url\" content=\"https?://(?:www\\.)?newstube\\.ru/freshplayer\\.swf\\?guid=(?P<guid>[\\da-f]{8}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{12})',\n            page, 'video GUID')\n\n        player = self._download_xml(\n            'http://p.newstube.ru/v2/player.asmx/GetAutoPlayInfo6?state=&url=%s&sessionId=&id=%s&placement=profile&location=n2' % (url, video_guid),\n            video_guid, 'Downloading player XML')\n\n        def ns(s):\n            return s.replace('/', '/%(ns)s') % {'ns': '{http://app1.newstube.ru/N2SiteWS/player.asmx}'}\n\n        error_message = player.find(ns('./ErrorMessage'))\n        if error_message is not None:\n            raise ExtractorError('%s returned error: %s' % (self.IE_NAME, error_message.text), expected=True)\n\n        session_id = player.find(ns('./SessionId')).text\n        media_info = player.find(ns('./Medias/MediaInfo'))\n        title = media_info.find(ns('./Name')).text\n        description = self._og_search_description(page)\n        thumbnail = media_info.find(ns('./KeyFrame')).text\n        duration = int(media_info.find(ns('./Duration')).text) / 1000.0\n\n        formats = []\n\n        for stream_info in media_info.findall(ns('./Streams/StreamInfo')):\n            media_location = stream_info.find(ns('./MediaLocation'))\n            if media_location is None:\n                continue\n\n            server = media_location.find(ns('./Server')).text\n            app = media_location.find(ns('./App')).text\n            media_id = stream_info.find(ns('./Id')).text\n            quality_id = stream_info.find(ns('./QualityId')).text\n            name = stream_info.find(ns('./Name')).text\n            width = int(stream_info.find(ns('./Width')).text)\n            height = int(stream_info.find(ns('./Height')).text)\n\n            formats.append({\n                'url': 'rtmp://%s/%s' % (server, app),\n                'app': app,\n                'play_path': '01/%s' % video_guid.upper(),\n                'rtmp_conn': ['S:%s' % session_id, 'S:%s' % media_id, 'S:n2'],\n                'page_url': url,\n                'ext': 'flv',\n                'format_id': quality_id,\n                'format_note': name,\n                'width': width,\n                'height': height,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_guid,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNIE._real_extract#56",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNIE",
        "signature": "youtube_dl.extractor.cnn.CNNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        path = mobj.group('path')\n        page_title = mobj.group('title')\n        info_url = 'http://edition.cnn.com/video/data/3.0/%s/index.xml' % path\n        info = self._download_xml(info_url, page_title)\n\n        formats = []\n        rex = re.compile(r'''(?x)\n            (?P<width>[0-9]+)x(?P<height>[0-9]+)\n            (?:_(?P<bitrate>[0-9]+)k)?\n        ''')\n        for f in info.findall('files/file'):\n            video_url = 'http://ht.cdn.turner.com/cnn/big%s' % (f.text.strip())\n            fdct = {\n                'format_id': f.attrib['bitrate'],\n                'url': video_url,\n            }\n\n            mf = rex.match(f.attrib['bitrate'])\n            if mf:\n                fdct['width'] = int(mf.group('width'))\n                fdct['height'] = int(mf.group('height'))\n                fdct['tbr'] = int_or_none(mf.group('bitrate'))\n            else:\n                mf = rex.search(f.text)\n                if mf:\n                    fdct['width'] = int(mf.group('width'))\n                    fdct['height'] = int(mf.group('height'))\n                    fdct['tbr'] = int_or_none(mf.group('bitrate'))\n                else:\n                    mi = re.match(r'ios_(audio|[0-9]+)$', f.attrib['bitrate'])\n                    if mi:\n                        if mi.group(1) == 'audio':\n                            fdct['vcodec'] = 'none'\n                            fdct['ext'] = 'm4a'\n                        else:\n                            fdct['tbr'] = int(mi.group(1))\n\n            formats.append(fdct)\n\n        self._sort_formats(formats)\n\n        thumbnails = [{\n            'height': int(t.attrib['height']),\n            'width': int(t.attrib['width']),\n            'url': t.text,\n        } for t in info.findall('images/image')]\n\n        metas_el = info.find('metas')\n        upload_date = (\n            metas_el.attrib.get('version') if metas_el is not None else None)\n\n        duration_el = info.find('length')\n        duration = parse_duration(duration_el.text)\n\n        return {\n            'id': info.attrib['id'],\n            'title': info.find('headline').text,\n            'formats': formats,\n            'thumbnails': thumbnails,\n            'description': info.find('description').text,\n            'duration': duration,\n            'upload_date': upload_date,\n        }",
        "begin_line": 56,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNBlogsIE._real_extract#138",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNBlogsIE",
        "signature": "youtube_dl.extractor.cnn.CNNBlogsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, url_basename(url))\n        cnn_url = self._html_search_regex(r'data-url=\"(.+?)\"', webpage, 'cnn url')\n        return {\n            '_type': 'url',\n            'url': cnn_url,\n            'ie_key': CNNIE.ie_key(),\n        }",
        "begin_line": 138,
        "end_line": 145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNArticleIE._real_extract#163",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNArticleIE",
        "signature": "youtube_dl.extractor.cnn.CNNArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, url_basename(url))\n        cnn_url = self._html_search_regex(r\"video:\\s*'([^']+)'\", webpage, 'cnn url')\n        return {\n            '_type': 'url',\n            'url': 'http://cnn.com/video/?/video/' + cnn_url,\n            'ie_key': CNNIE.ie_key(),\n        }",
        "begin_line": 163,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.history.HistoryIE._real_extract#22",
        "src_path": "youtube_dl/extractor/history.py",
        "class_name": "youtube_dl.extractor.history.HistoryIE",
        "signature": "youtube_dl.extractor.history.HistoryIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(\n            r'data-href=\"[^\"]*/%s\"[^>]+data-release-url=\"([^\"]+)\"' % video_id,\n            webpage, 'video url')\n\n        return self.url_result(smuggle_url(video_url, {'sig': {'key': 'crazyjava', 'secret': 's3cr3t'}}))",
        "begin_line": 22,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.porn91.Porn91IE._real_extract#29",
        "src_path": "youtube_dl/extractor/porn91.py",
        "class_name": "youtube_dl.extractor.porn91.Porn91IE",
        "signature": "youtube_dl.extractor.porn91.Porn91IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        url = 'http://91porn.com/view_video.php?viewkey=%s' % video_id\n        self._set_cookie('91porn.com', 'language', 'cn_CN')\n        webpage = self._download_webpage(url, video_id, 'get HTML content')\n\n        if '\u4f5c\u4e3a\u6e38\u5ba2\uff0c\u4f60\u6bcf\u5929\u53ea\u53ef\u89c2\u770b10\u4e2a\u89c6\u9891' in webpage:\n            raise ExtractorError('91 Porn says: Daily limit 10 videos exceeded', expected=True)\n\n        title = self._search_regex(\n            r'<div id=\"viewvideo-title\">([^<]+)</div>', webpage, 'title')\n        title = title.replace('\\n', '')\n\n        # get real url\n        file_id = self._search_regex(\n            r'so.addVariable\\(\\'file\\',\\'(\\d+)\\'', webpage, 'file id')\n        sec_code = self._search_regex(\n            r'so.addVariable\\(\\'seccode\\',\\'([^\\']+)\\'', webpage, 'sec code')\n        max_vid = self._search_regex(\n            r'so.addVariable\\(\\'max_vid\\',\\'(\\d+)\\'', webpage, 'max vid')\n        url_params = compat_urllib_parse.urlencode({\n            'VID': file_id,\n            'mp4': '1',\n            'seccode': sec_code,\n            'max_vid': max_vid,\n        })\n        info_cn = self._download_webpage(\n            'http://91porn.com/getfile.php?' + url_params, video_id,\n            'get real video url')\n        video_url = self._search_regex(r'file=([^&]+)&', info_cn, 'url')\n\n        duration = parse_duration(self._search_regex(\n            r'\u65f6\u957f:\\s*</span>\\s*(\\d+:\\d+)', webpage, 'duration', fatal=False))\n\n        comment_count = int_or_none(self._search_regex(\n            r'\u7559\u8a00:\\s*</span>\\s*(\\d+)', webpage, 'comment count', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'duration': duration,\n            'comment_count': comment_count,\n            'age_limit': self._rta_search(webpage),\n        }",
        "begin_line": 29,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.report_following_redirect#1037",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.report_following_redirect(self, new_url)",
        "snippet": "    def report_following_redirect(self, new_url):\n        \"\"\"Report information extraction.\"\"\"\n        self._downloader.to_screen('[redirect] Following redirect to %s' % new_url)",
        "begin_line": 1037,
        "end_line": 1039,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._extract_rss#1041",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._extract_rss(self, url, video_id, doc)",
        "snippet": "    def _extract_rss(self, url, video_id, doc):\n        playlist_title = doc.find('./channel/title').text\n        playlist_desc_el = doc.find('./channel/description')\n        playlist_desc = None if playlist_desc_el is None else playlist_desc_el.text\n\n        entries = []\n        for it in doc.findall('./channel/item'):\n            next_url = xpath_text(it, 'link', fatal=False)\n            if not next_url:\n                enclosure_nodes = it.findall('./enclosure')\n                for e in enclosure_nodes:\n                    next_url = e.attrib.get('url')\n                    if next_url:\n                        break\n\n            if not next_url:\n                continue\n\n            entries.append({\n                '_type': 'url',\n                'url': next_url,\n                'title': it.find('title').text,\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': url,\n            'title': playlist_title,\n            'description': playlist_desc,\n            'entries': entries,\n        }",
        "begin_line": 1041,
        "end_line": 1071,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._extract_camtasia#1073",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._extract_camtasia(self, url, video_id, webpage)",
        "snippet": "    def _extract_camtasia(self, url, video_id, webpage):\n        \"\"\" Returns None if no camtasia video can be found. \"\"\"\n\n        camtasia_cfg = self._search_regex(\n            r'fo\\.addVariable\\(\\s*\"csConfigFile\",\\s*\"([^\"]+)\"\\s*\\);',\n            webpage, 'camtasia configuration file', default=None)\n        if camtasia_cfg is None:\n            return None\n\n        title = self._html_search_meta('DC.title', webpage, fatal=True)\n\n        camtasia_url = compat_urlparse.urljoin(url, camtasia_cfg)\n        camtasia_cfg = self._download_xml(\n            camtasia_url, video_id,\n            note='Downloading camtasia configuration',\n            errnote='Failed to download camtasia configuration')\n        fileset_node = camtasia_cfg.find('./playlist/array/fileset')\n\n        entries = []\n        for n in fileset_node.getchildren():\n            url_n = n.find('./uri')\n            if url_n is None:\n                continue\n\n            entries.append({\n                'id': os.path.splitext(url_n.text.rpartition('/')[2])[0],\n                'title': '%s - %s' % (title, n.tag),\n                'url': compat_urlparse.urljoin(url, url_n.text),\n                'duration': float_or_none(n.find('./duration').text),\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'title': title,\n        }",
        "begin_line": 1073,
        "end_line": 1108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._real_extract#1110",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        if url.startswith('//'):\n            return {\n                '_type': 'url',\n                'url': self.http_scheme() + url,\n            }\n\n        parsed_url = compat_urlparse.urlparse(url)\n        if not parsed_url.scheme:\n            default_search = self._downloader.params.get('default_search')\n            if default_search is None:\n                default_search = 'fixup_error'\n\n            if default_search in ('auto', 'auto_warning', 'fixup_error'):\n                if '/' in url:\n                    self._downloader.report_warning('The url doesn\\'t specify the protocol, trying with http')\n                    return self.url_result('http://' + url)\n                elif default_search != 'fixup_error':\n                    if default_search == 'auto_warning':\n                        if re.match(r'^(?:url|URL)$', url):\n                            raise ExtractorError(\n                                'Invalid URL:  %r . Call youtube-dl like this:  youtube-dl -v \"https://www.youtube.com/watch?v=BaW_jenozKc\"  ' % url,\n                                expected=True)\n                        else:\n                            self._downloader.report_warning(\n                                'Falling back to youtube search for  %s . Set --default-search \"auto\" to suppress this warning.' % url)\n                    return self.url_result('ytsearch:' + url)\n\n            if default_search in ('error', 'fixup_error'):\n                raise ExtractorError(\n                    '%r is not a valid URL. '\n                    'Set --default-search \"ytsearch\" (or run  youtube-dl \"ytsearch:%s\" ) to search YouTube'\n                    % (url, url), expected=True)\n            else:\n                if ':' not in default_search:\n                    default_search += ':'\n                return self.url_result(default_search + url)\n\n        url, smuggled_data = unsmuggle_url(url)\n        force_videoid = None\n        is_intentional = smuggled_data and smuggled_data.get('to_generic')\n        if smuggled_data and 'force_videoid' in smuggled_data:\n            force_videoid = smuggled_data['force_videoid']\n            video_id = force_videoid\n        else:\n            video_id = compat_urllib_parse_unquote(os.path.splitext(url.rstrip('/').split('/')[-1])[0])\n\n        self.to_screen('%s: Requesting header' % video_id)\n\n        head_req = HEADRequest(url)\n        head_response = self._request_webpage(\n            head_req, video_id,\n            note=False, errnote='Could not send HEAD request to %s' % url,\n            fatal=False)\n\n        if head_response is not False:\n            # Check for redirect\n            new_url = head_response.geturl()\n            if url != new_url:\n                self.report_following_redirect(new_url)\n                if force_videoid:\n                    new_url = smuggle_url(\n                        new_url, {'force_videoid': force_videoid})\n                return self.url_result(new_url)\n\n        full_response = None\n        if head_response is False:\n            request = compat_urllib_request.Request(url)\n            request.add_header('Accept-Encoding', '*')\n            full_response = self._request_webpage(request, video_id)\n            head_response = full_response\n\n        # Check for direct link to a video\n        content_type = head_response.headers.get('Content-Type', '')\n        m = re.match(r'^(?P<type>audio|video|application(?=/ogg$))/(?P<format_id>.+)$', content_type)\n        if m:\n            upload_date = unified_strdate(\n                head_response.headers.get('Last-Modified'))\n            return {\n                'id': video_id,\n                'title': compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0]),\n                'direct': True,\n                'formats': [{\n                    'format_id': m.group('format_id'),\n                    'url': url,\n                    'vcodec': 'none' if m.group('type') == 'audio' else None\n                }],\n                'upload_date': upload_date,\n            }\n\n        if not self._downloader.params.get('test', False) and not is_intentional:\n            force = self._downloader.params.get('force_generic_extractor', False)\n            self._downloader.report_warning(\n                '%s on generic information extractor.' % ('Forcing' if force else 'Falling back'))\n\n        if not full_response:\n            request = compat_urllib_request.Request(url)\n            # Some webservers may serve compressed content of rather big size (e.g. gzipped flac)\n            # making it impossible to download only chunk of the file (yet we need only 512kB to\n            # test whether it's HTML or not). According to youtube-dl default Accept-Encoding\n            # that will always result in downloading the whole file that is not desirable.\n            # Therefore for extraction pass we have to override Accept-Encoding to any in order\n            # to accept raw bytes and being able to download only a chunk.\n            # It may probably better to solve this by checking Content-Type for application/octet-stream\n            # after HEAD request finishes, but not sure if we can rely on this.\n            request.add_header('Accept-Encoding', '*')\n            full_response = self._request_webpage(request, video_id)\n\n        # Maybe it's a direct link to a video?\n        # Be careful not to download the whole thing!\n        first_bytes = full_response.read(512)\n        if not is_html(first_bytes):\n            self._downloader.report_warning(\n                'URL could be a direct video link, returning it as such.')\n            upload_date = unified_strdate(\n                head_response.headers.get('Last-Modified'))\n            return {\n                'id': video_id,\n                'title': compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0]),\n                'direct': True,\n                'url': url,\n                'upload_date': upload_date,\n            }\n\n        webpage = self._webpage_read_content(\n            full_response, url, video_id, prefix=first_bytes)\n\n        self.report_extraction(video_id)\n\n        # Is it an RSS feed, a SMIL file or a XSPF playlist?\n        try:\n            doc = compat_etree_fromstring(webpage.encode('utf-8'))\n            if doc.tag == 'rss':\n                return self._extract_rss(url, video_id, doc)\n            elif re.match(r'^(?:{[^}]+})?smil$', doc.tag):\n                return self._parse_smil(doc, url, video_id)\n            elif doc.tag == '{http://xspf.org/ns/0/}playlist':\n                return self.playlist_result(self._parse_xspf(doc, video_id), video_id)\n        except compat_xml_parse_error:\n            pass\n\n        # Is it a Camtasia project?\n        camtasia_res = self._extract_camtasia(url, video_id, webpage)\n        if camtasia_res is not None:\n            return camtasia_res\n\n        # Sometimes embedded video player is hidden behind percent encoding\n        # (e.g. https://github.com/rg3/youtube-dl/issues/2448)\n        # Unescaping the whole page allows to handle those cases in a generic way\n        webpage = compat_urllib_parse_unquote(webpage)\n\n        # it's tempting to parse this further, but you would\n        # have to take into account all the variations like\n        #   Video Title - Site Name\n        #   Site Name | Video Title\n        #   Video Title - Tagline | Site Name\n        # and so on and so forth; it's just not practical\n        video_title = self._html_search_regex(\n            r'(?s)<title>(.*?)</title>', webpage, 'video title',\n            default='video')\n\n        # Try to detect age limit automatically\n        age_limit = self._rta_search(webpage)\n        # And then there are the jokers who advertise that they use RTA,\n        # but actually don't.\n        AGE_LIMIT_MARKERS = [\n            r'Proudly Labeled <a href=\"http://www.rtalabel.org/\" title=\"Restricted to Adults\">RTA</a>',\n        ]\n        if any(re.search(marker, webpage) for marker in AGE_LIMIT_MARKERS):\n            age_limit = 18\n\n        # video uploader is domain name\n        video_uploader = self._search_regex(\n            r'^(?:https?://)?([^/]*)/.*', url, 'video uploader')\n\n        # Helper method\n        def _playlist_from_matches(matches, getter=None, ie=None):\n            urlrs = orderedSet(\n                self.url_result(self._proto_relative_url(getter(m) if getter else m), ie)\n                for m in matches)\n            return self.playlist_result(\n                urlrs, playlist_id=video_id, playlist_title=video_title)\n\n        # Look for BrightCove:\n        bc_urls = BrightcoveIE._extract_brightcove_urls(webpage)\n        if bc_urls:\n            self.to_screen('Brightcove video detected.')\n            entries = [{\n                '_type': 'url',\n                'url': smuggle_url(bc_url, {'Referer': url}),\n                'ie_key': 'Brightcove'\n            } for bc_url in bc_urls]\n\n            return {\n                '_type': 'playlist',\n                'title': video_title,\n                'id': video_id,\n                'entries': entries,\n            }\n\n        # Look for embedded rtl.nl player\n        matches = re.findall(\n            r'<iframe[^>]+?src=\"((?:https?:)?//(?:www\\.)?rtl\\.nl/system/videoplayer/[^\"]+(?:video_)?embed[^\"]+)\"',\n            webpage)\n        if matches:\n            return _playlist_from_matches(matches, ie='RtlNl')\n\n        vimeo_url = VimeoIE._extract_vimeo_url(url, webpage)\n        if vimeo_url is not None:\n            return self.url_result(vimeo_url)\n\n        vid_me_embed_url = self._search_regex(\n            r'src=[\\'\"](https?://vid\\.me/[^\\'\"]+)[\\'\"]',\n            webpage, 'vid.me embed', default=None)\n        if vid_me_embed_url is not None:\n            return self.url_result(vid_me_embed_url, 'Vidme')\n\n        # Look for embedded YouTube player\n        matches = re.findall(r'''(?x)\n            (?:\n                <iframe[^>]+?src=|\n                data-video-url=|\n                <embed[^>]+?src=|\n                embedSWF\\(?:\\s*|\n                new\\s+SWFObject\\(\n            )\n            ([\"\\'])\n                (?P<url>(?:https?:)?//(?:www\\.)?youtube(?:-nocookie)?\\.com/\n                (?:embed|v|p)/.+?)\n            \\1''', webpage)\n        if matches:\n            return _playlist_from_matches(\n                matches, lambda m: unescapeHTML(m[1]))\n\n        # Look for lazyYT YouTube embed\n        matches = re.findall(\n            r'class=\"lazyYT\" data-youtube-id=\"([^\"]+)\"', webpage)\n        if matches:\n            return _playlist_from_matches(matches, lambda m: unescapeHTML(m))\n\n        # Look for embedded Dailymotion player\n        matches = re.findall(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?dailymotion\\.com/embed/video/.+?)\\1', webpage)\n        if matches:\n            return _playlist_from_matches(\n                matches, lambda m: unescapeHTML(m[1]))\n\n        # Look for embedded Dailymotion playlist player (#3822)\n        m = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?dailymotion\\.[a-z]{2,3}/widget/jukebox\\?.+?)\\1', webpage)\n        if m:\n            playlists = re.findall(\n                r'list\\[\\]=/playlist/([^/]+)/', unescapeHTML(m.group('url')))\n            if playlists:\n                return _playlist_from_matches(\n                    playlists, lambda p: '//dailymotion.com/playlist/%s' % p)\n\n        # Look for embedded Wistia player\n        match = re.search(\n            r'<(?:meta[^>]+?content|iframe[^>]+?src)=([\"\\'])(?P<url>(?:https?:)?//(?:fast\\.)?wistia\\.net/embed/iframe/.+?)\\1', webpage)\n        if match:\n            embed_url = self._proto_relative_url(\n                unescapeHTML(match.group('url')))\n            return {\n                '_type': 'url_transparent',\n                'url': embed_url,\n                'ie_key': 'Wistia',\n                'uploader': video_uploader,\n                'title': video_title,\n                'id': video_id,\n            }\n\n        match = re.search(r'(?:id=[\"\\']wistia_|data-wistia-?id=[\"\\']|Wistia\\.embed\\([\"\\'])(?P<id>[^\"\\']+)', webpage)\n        if match:\n            return {\n                '_type': 'url_transparent',\n                'url': 'http://fast.wistia.net/embed/iframe/{0:}'.format(match.group('id')),\n                'ie_key': 'Wistia',\n                'uploader': video_uploader,\n                'title': video_title,\n                'id': match.group('id')\n            }\n\n        # Look for embedded blip.tv player\n        bliptv_url = BlipTVIE._extract_url(webpage)\n        if bliptv_url:\n            return self.url_result(bliptv_url, 'BlipTV')\n\n        # Look for SVT player\n        svt_url = SVTIE._extract_url(webpage)\n        if svt_url:\n            return self.url_result(svt_url, 'SVT')\n\n        # Look for embedded condenast player\n        matches = re.findall(\n            r'<iframe\\s+(?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?src=\"(https?://player\\.cnevids\\.com/embed/[^\"]+\")',\n            webpage)\n        if matches:\n            return {\n                '_type': 'playlist',\n                'entries': [{\n                    '_type': 'url',\n                    'ie_key': 'CondeNast',\n                    'url': ma,\n                } for ma in matches],\n                'title': video_title,\n                'id': video_id,\n            }\n\n        # Look for Bandcamp pages with custom domain\n        mobj = re.search(r'<meta property=\"og:url\"[^>]*?content=\"(.*?bandcamp\\.com.*?)\"', webpage)\n        if mobj is not None:\n            burl = unescapeHTML(mobj.group(1))\n            # Don't set the extractor because it can be a track url or an album\n            return self.url_result(burl)\n\n        # Look for embedded Vevo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:cache\\.)?vevo\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for embedded Viddler player\n        mobj = re.search(\n            r'<(?:iframe[^>]+?src|param[^>]+?value)=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?viddler\\.com/(?:embed|player)/.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for NYTimes player\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//graphics8\\.nytimes\\.com/bcvideo/[^/]+/iframe/embed\\.html.+?)\\1>',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for Libsyn player\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//html5-player\\.libsyn\\.com/embed/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for Ooyala videos\n        mobj = (re.search(r'player\\.ooyala\\.com/[^\"?]+[?#][^\"]*?(?:embedCode|ec)=(?P<ec>[^\"&]+)', webpage) or\n                re.search(r'OO\\.Player\\.create\\([\\'\"].*?[\\'\"],\\s*[\\'\"](?P<ec>.{32})[\\'\"]', webpage) or\n                re.search(r'SBN\\.VideoLinkset\\.ooyala\\([\\'\"](?P<ec>.{32})[\\'\"]\\)', webpage) or\n                re.search(r'data-ooyala-video-id\\s*=\\s*[\\'\"](?P<ec>.{32})[\\'\"]', webpage))\n        if mobj is not None:\n            return OoyalaIE._build_url_result(mobj.group('ec'))\n\n        # Look for multiple Ooyala embeds on SBN network websites\n        mobj = re.search(r'SBN\\.VideoLinkset\\.entryGroup\\((\\[.*?\\])', webpage)\n        if mobj is not None:\n            embeds = self._parse_json(mobj.group(1), video_id, fatal=False)\n            if embeds:\n                return _playlist_from_matches(\n                    embeds, getter=lambda v: OoyalaIE._url_for_embed_code(v['provider_video_id']), ie='Ooyala')\n\n        # Look for Aparat videos\n        mobj = re.search(r'<iframe .*?src=\"(http://www\\.aparat\\.com/video/[^\"]+)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group(1), 'Aparat')\n\n        # Look for MPORA videos\n        mobj = re.search(r'<iframe .*?src=\"(http://mpora\\.(?:com|de)/videos/[^\"]+)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group(1), 'Mpora')\n\n        # Look for embedded NovaMov-based player\n        mobj = re.search(\n            r'''(?x)<(?:pagespeed_)?iframe[^>]+?src=([\"\\'])\n                    (?P<url>http://(?:(?:embed|www)\\.)?\n                        (?:novamov\\.com|\n                           nowvideo\\.(?:ch|sx|eu|at|ag|co)|\n                           videoweed\\.(?:es|com)|\n                           movshare\\.(?:net|sx|ag)|\n                           divxstage\\.(?:eu|net|ch|co|at|ag))\n                        /embed\\.php.+?)\\1''', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for embedded Facebook player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https://www\\.facebook\\.com/video/embed.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Facebook')\n\n        # Look for embedded VK player\n        mobj = re.search(r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://vk\\.com/video_ext\\.php.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'VK')\n\n        # Look for embedded ivi player\n        mobj = re.search(r'<embed[^>]+?src=([\"\\'])(?P<url>https?://(?:www\\.)?ivi\\.ru/video/player.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Ivi')\n\n        # Look for embedded Huffington Post player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://embed\\.live\\.huffingtonpost\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'HuffPost')\n\n        # Look for embed.ly\n        mobj = re.search(r'class=[\"\\']embedly-card[\"\\'][^>]href=[\"\\'](?P<url>[^\"\\']+)', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n        mobj = re.search(r'class=[\"\\']embedly-embed[\"\\'][^>]src=[\"\\'][^\"\\']*url=(?P<url>[^&]+)', webpage)\n        if mobj is not None:\n            return self.url_result(compat_urllib_parse_unquote(mobj.group('url')))\n\n        # Look for funnyordie embed\n        matches = re.findall(r'<iframe[^>]+?src=\"(https?://(?:www\\.)?funnyordie\\.com/embed/[^\"]+)\"', webpage)\n        if matches:\n            return _playlist_from_matches(\n                matches, getter=unescapeHTML, ie='FunnyOrDie')\n\n        # Look for BBC iPlayer embed\n        matches = re.findall(r'setPlaylist\\(\"(https?://www\\.bbc\\.co\\.uk/iplayer/[^/]+/[\\da-z]{8})\"\\)', webpage)\n        if matches:\n            return _playlist_from_matches(matches, ie='BBCCoUk')\n\n        # Look for embedded RUTV player\n        rutv_url = RUTVIE._extract_url(webpage)\n        if rutv_url:\n            return self.url_result(rutv_url, 'RUTV')\n\n        # Look for embedded TVC player\n        tvc_url = TVCIE._extract_url(webpage)\n        if tvc_url:\n            return self.url_result(tvc_url, 'TVC')\n\n        # Look for embedded SportBox player\n        sportbox_urls = SportBoxEmbedIE._extract_urls(webpage)\n        if sportbox_urls:\n            return _playlist_from_matches(sportbox_urls, ie='SportBoxEmbed')\n\n        # Look for embedded PornHub player\n        pornhub_url = PornHubIE._extract_url(webpage)\n        if pornhub_url:\n            return self.url_result(pornhub_url, 'PornHub')\n\n        # Look for embedded XHamster player\n        xhamster_urls = XHamsterEmbedIE._extract_urls(webpage)\n        if xhamster_urls:\n            return _playlist_from_matches(xhamster_urls, ie='XHamsterEmbed')\n\n        # Look for embedded Tvigle player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//cloud\\.tvigle\\.ru/video/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Tvigle')\n\n        # Look for embedded TED player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://embed(?:-ssl)?\\.ted\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'TED')\n\n        # Look for embedded Ustream videos\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>http://www\\.ustream\\.tv/embed/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Ustream')\n\n        # Look for embedded arte.tv player\n        mobj = re.search(\n            r'<script [^>]*?src=\"(?P<url>http://www\\.arte\\.tv/playerv2/embed[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'ArteTVEmbed')\n\n        # Look for embedded francetv player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?://)?embed\\.francetv\\.fr/\\?ue=.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for embedded smotri.com player\n        smotri_url = SmotriIE._extract_url(webpage)\n        if smotri_url:\n            return self.url_result(smotri_url, 'Smotri')\n\n        # Look for embedded Myvi.ru player\n        myvi_url = MyviIE._extract_url(webpage)\n        if myvi_url:\n            return self.url_result(myvi_url)\n\n        # Look for embeded soundcloud player\n        mobj = re.search(\n            r'<iframe\\s+(?:[a-zA-Z0-9_-]+=\"[^\"]+\"\\s+)*src=\"(?P<url>https?://(?:w\\.)?soundcloud\\.com/player[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            url = unescapeHTML(mobj.group('url'))\n            return self.url_result(url)\n\n        # Look for embedded vulture.com player\n        mobj = re.search(\n            r'<iframe src=\"(?P<url>https?://video\\.vulture\\.com/[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            url = unescapeHTML(mobj.group('url'))\n            return self.url_result(url, ie='Vulture')\n\n        # Look for embedded mtvservices player\n        mtvservices_url = MTVServicesEmbeddedIE._extract_url(webpage)\n        if mtvservices_url:\n            return self.url_result(mtvservices_url, ie='MTVServicesEmbedded')\n\n        # Look for embedded yahoo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://(?:screen|movies)\\.yahoo\\.com/.+?\\.html\\?format=embed)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Yahoo')\n\n        # Look for embedded sbs.com.au player\n        mobj = re.search(\n            r'''(?x)\n            (?:\n                <meta\\s+property=\"og:video\"\\s+content=|\n                <iframe[^>]+?src=\n            )\n            ([\"\\'])(?P<url>https?://(?:www\\.)?sbs\\.com\\.au/ondemand/video/.+?)\\1''',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'SBS')\n\n        # Look for embedded Cinchcast player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://player\\.cinchcast\\.com/.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Cinchcast')\n\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://m(?:lb)?\\.mlb\\.com/shared/video/embed/embed\\.html\\?.+?)\\1',\n            webpage)\n        if not mobj:\n            mobj = re.search(\n                r'data-video-link=[\"\\'](?P<url>http://m.mlb.com/video/[^\"\\']+)',\n                webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'MLB')\n\n        mobj = re.search(\n            r'<(?:iframe|script)[^>]+?src=([\"\\'])(?P<url>%s)\\1' % CondeNastIE.EMBED_URL,\n            webpage)\n        if mobj is not None:\n            return self.url_result(self._proto_relative_url(mobj.group('url'), scheme='http:'), 'CondeNast')\n\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://new\\.livestream\\.com/[^\"]+/player[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Livestream')\n\n        # Look for Zapiks embed\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://(?:www\\.)?zapiks\\.fr/index\\.php\\?.+?)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Zapiks')\n\n        # Look for Kaltura embeds\n        mobj = (re.search(r\"(?s)kWidget\\.(?:thumb)?[Ee]mbed\\(\\{.*?'wid'\\s*:\\s*'_?(?P<partner_id>[^']+)',.*?'entry_id'\\s*:\\s*'(?P<id>[^']+)',\", webpage) or\n                re.search(r'(?s)([\"\\'])(?:https?:)?//cdnapisec\\.kaltura\\.com/.*?(?:p|partner_id)/(?P<partner_id>\\d+).*?\\1.*?entry_id\\s*:\\s*([\"\\'])(?P<id>[^\\2]+?)\\2', webpage))\n        if mobj is not None:\n            return self.url_result('kaltura:%(partner_id)s:%(id)s' % mobj.groupdict(), 'Kaltura')\n\n        # Look for Eagle.Platform embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://.+?\\.media\\.eagleplatform\\.com/index/player\\?.+?)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'EaglePlatform')\n\n        # Look for ClipYou (uses Eagle.Platform) embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=\"https?://(?P<host>media\\.clipyou\\.ru)/index/player\\?.*\\brecord_id=(?P<id>\\d+).*\"', webpage)\n        if mobj is not None:\n            return self.url_result('eagleplatform:%(host)s:%(id)s' % mobj.groupdict(), 'EaglePlatform')\n\n        # Look for Pladform embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://out\\.pladform\\.ru/player\\?.+?)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Pladform')\n\n        # Look for Playwire embeds\n        mobj = re.search(\n            r'<script[^>]+data-config=([\"\\'])(?P<url>(?:https?:)?//config\\.playwire\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for 5min embeds\n        mobj = re.search(\n            r'<meta[^>]+property=\"og:video\"[^>]+content=\"https?://embed\\.5min\\.com/(?P<id>[0-9]+)/?', webpage)\n        if mobj is not None:\n            return self.url_result('5min:%s' % mobj.group('id'), 'FiveMin')\n\n        # Look for Crooks and Liars embeds\n        mobj = re.search(\n            r'<(?:iframe[^>]+src|param[^>]+value)=([\"\\'])(?P<url>(?:https?:)?//embed\\.crooksandliars\\.com/(?:embed|v)/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for NBC Sports VPlayer embeds\n        nbc_sports_url = NBCSportsVPlayerIE._extract_url(webpage)\n        if nbc_sports_url:\n            return self.url_result(nbc_sports_url, 'NBCSportsVPlayer')\n\n        # Look for UDN embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>%s)\"' % UDNEmbedIE._VALID_URL, webpage)\n        if mobj is not None:\n            return self.url_result(\n                compat_urlparse.urljoin(url, mobj.group('url')), 'UDNEmbed')\n\n        # Look for Senate ISVP iframe\n        senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)\n        if senate_isvp_url:\n            return self.url_result(senate_isvp_url, 'SenateISVP')\n\n        # Look for Dailymotion Cloud videos\n        dmcloud_url = DailymotionCloudIE._extract_dmcloud_url(webpage)\n        if dmcloud_url:\n            return self.url_result(dmcloud_url, 'DailymotionCloud')\n\n        # Look for OnionStudios embeds\n        onionstudios_url = OnionStudiosIE._extract_url(webpage)\n        if onionstudios_url:\n            return self.url_result(onionstudios_url)\n\n        # Look for SnagFilms embeds\n        snagfilms_url = SnagFilmsEmbedIE._extract_url(webpage)\n        if snagfilms_url:\n            return self.url_result(snagfilms_url)\n\n        # Look for ScreenwaveMedia embeds\n        mobj = re.search(ScreenwaveMediaIE.EMBED_PATTERN, webpage)\n        if mobj is not None:\n            return self.url_result(unescapeHTML(mobj.group('url')), 'ScreenwaveMedia')\n\n        # Look for AdobeTVVideo embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=[\\'\"]((?:https?:)?//video\\.tv\\.adobe\\.com/v/\\d+[^\"]+)[\\'\"]',\n            webpage)\n        if mobj is not None:\n            return self.url_result(\n                self._proto_relative_url(unescapeHTML(mobj.group(1))),\n                'AdobeTVVideo')\n\n        def check_video(vurl):\n            if YoutubeIE.suitable(vurl):\n                return True\n            vpath = compat_urlparse.urlparse(vurl).path\n            vext = determine_ext(vpath)\n            return '.' in vpath and vext not in ('swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml')\n\n        def filter_video(urls):\n            return list(filter(check_video, urls))\n\n        # Start with something easy: JW Player in SWFObject\n        found = filter_video(re.findall(r'flashvars: [\\'\"](?:.*&)?file=(http[^\\'\"&]*)', webpage))\n        if not found:\n            # Look for gorilla-vid style embedding\n            found = filter_video(re.findall(r'''(?sx)\n                (?:\n                    jw_plugins|\n                    JWPlayerOptions|\n                    jwplayer\\s*\\(\\s*[\"'][^'\"]+[\"']\\s*\\)\\s*\\.setup\n                )\n                .*?\n                ['\"]?file['\"]?\\s*:\\s*[\"\\'](.*?)[\"\\']''', webpage))\n        if not found:\n            # Broaden the search a little bit\n            found = filter_video(re.findall(r'[^A-Za-z0-9]?(?:file|source)=(http[^\\'\"&]*)', webpage))\n        if not found:\n            # Broaden the findall a little bit: JWPlayer JS loader\n            found = filter_video(re.findall(\n                r'[^A-Za-z0-9]?(?:file|video_url)[\"\\']?:\\s*[\"\\'](http(?![^\\'\"]+\\.[0-9]+[\\'\"])[^\\'\"]+)[\"\\']', webpage))\n        if not found:\n            # Flow player\n            found = filter_video(re.findall(r'''(?xs)\n                flowplayer\\(\"[^\"]+\",\\s*\n                    \\{[^}]+?\\}\\s*,\n                    \\s*\\{[^}]+? [\"']?clip[\"']?\\s*:\\s*\\{\\s*\n                        [\"']?url[\"']?\\s*:\\s*[\"']([^\"']+)[\"']\n            ''', webpage))\n        if not found:\n            # Cinerama player\n            found = re.findall(\n                r\"cinerama\\.embedPlayer\\(\\s*\\'[^']+\\',\\s*'([^']+)'\", webpage)\n        if not found:\n            # Try to find twitter cards info\n            found = filter_video(re.findall(\n                r'<meta (?:property|name)=\"twitter:player:stream\" (?:content|value)=\"(.+?)\"', webpage))\n        if not found:\n            # We look for Open Graph info:\n            # We have to match any number spaces between elements, some sites try to align them (eg.: statigr.am)\n            m_video_type = re.findall(r'<meta.*?property=\"og:video:type\".*?content=\"video/(.*?)\"', webpage)\n            # We only look in og:video if the MIME type is a video, don't try if it's a Flash player:\n            if m_video_type is not None:\n                found = filter_video(re.findall(r'<meta.*?property=\"og:video\".*?content=\"(.*?)\"', webpage))\n        if not found:\n            # HTML5 video\n            found = re.findall(r'(?s)<(?:video|audio)[^<]*(?:>.*?<source[^>]*)?\\s+src=[\"\\'](.*?)[\"\\']', webpage)\n        if not found:\n            REDIRECT_REGEX = r'[0-9]{,2};\\s*(?:URL|url)=\\'?([^\\'\"]+)'\n            found = re.search(\n                r'(?i)<meta\\s+(?=(?:[a-z-]+=\"[^\"]+\"\\s+)*http-equiv=\"refresh\")'\n                r'(?:[a-z-]+=\"[^\"]+\"\\s+)*?content=\"%s' % REDIRECT_REGEX,\n                webpage)\n            if not found:\n                # Look also in Refresh HTTP header\n                refresh_header = head_response.headers.get('Refresh')\n                if refresh_header:\n                    # In python 2 response HTTP headers are bytestrings\n                    if sys.version_info < (3, 0) and isinstance(refresh_header, str):\n                        refresh_header = refresh_header.decode('iso-8859-1')\n                    found = re.search(REDIRECT_REGEX, refresh_header)\n            if found:\n                new_url = compat_urlparse.urljoin(url, unescapeHTML(found.group(1)))\n                self.report_following_redirect(new_url)\n                return {\n                    '_type': 'url',\n                    'url': new_url,\n                }\n        if not found:\n            raise UnsupportedError(url)\n\n        entries = []\n        for video_url in found:\n            video_url = compat_urlparse.urljoin(url, video_url)\n            video_id = compat_urllib_parse_unquote(os.path.basename(video_url))\n\n            # Sometimes, jwplayer extraction will result in a YouTube URL\n            if YoutubeIE.suitable(video_url):\n                entries.append(self.url_result(video_url, 'Youtube'))\n                continue\n\n            # here's a fun little line of code for you:\n            video_id = os.path.splitext(video_id)[0]\n\n            ext = determine_ext(video_url)\n            if ext == 'smil':\n                entries.append({\n                    'id': video_id,\n                    'formats': self._extract_smil_formats(video_url, video_id),\n                    'uploader': video_uploader,\n                    'title': video_title,\n                    'age_limit': age_limit,\n                })\n            elif ext == 'xspf':\n                return self.playlist_result(self._extract_xspf_playlist(video_url, video_id), video_id)\n            else:\n                entries.append({\n                    'id': video_id,\n                    'url': video_url,\n                    'uploader': video_uploader,\n                    'title': video_title,\n                    'age_limit': age_limit,\n                })\n\n        if len(entries) == 1:\n            return entries[0]\n        else:\n            for num, e in enumerate(entries, start=1):\n                # 'url' results don't have a title\n                if e.get('title') is not None:\n                    e['title'] = '%s (%d)' % (e['title'], num)\n            return {\n                '_type': 'playlist',\n                'entries': entries,\n            }",
        "begin_line": 1110,
        "end_line": 1884,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._playlist_from_matches#1286",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._playlist_from_matches(matches, getter=None, ie=None)",
        "snippet": "        def _playlist_from_matches(matches, getter=None, ie=None):\n            urlrs = orderedSet(\n                self.url_result(self._proto_relative_url(getter(m) if getter else m), ie)\n                for m in matches)\n            return self.playlist_result(\n                urlrs, playlist_id=video_id, playlist_title=video_title)",
        "begin_line": 1286,
        "end_line": 1291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.check_video#1762",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.check_video(vurl)",
        "snippet": "        def check_video(vurl):\n            if YoutubeIE.suitable(vurl):\n                return True\n            vpath = compat_urlparse.urlparse(vurl).path\n            vext = determine_ext(vpath)\n            return '.' in vpath and vext not in ('swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml')",
        "begin_line": 1762,
        "end_line": 1767,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.filter_video#1769",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.filter_video(urls)",
        "snippet": "        def filter_video(urls):\n            return list(filter(check_video, urls))",
        "begin_line": 1769,
        "end_line": 1770,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._build_request#26",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._build_request(url)",
        "snippet": "    def _build_request(url):\n        \"\"\"Build a request with the family filter disabled\"\"\"\n        request = compat_urllib_request.Request(url)\n        request.add_header('Cookie', 'family_filter=off; ff=off')\n        return request",
        "begin_line": 26,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._download_webpage_handle_no_ff#32",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._download_webpage_handle_no_ff(self, url, *args, **kwargs)",
        "snippet": "    def _download_webpage_handle_no_ff(self, url, *args, **kwargs):\n        request = self._build_request(url)\n        return self._download_webpage_handle(request, *args, **kwargs)",
        "begin_line": 32,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._download_webpage_no_ff#36",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._download_webpage_no_ff(self, url, *args, **kwargs)",
        "snippet": "    def _download_webpage_no_ff(self, url, *args, **kwargs):\n        request = self._build_request(url)\n        return self._download_webpage(request, *args, **kwargs)",
        "begin_line": 36,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._real_extract#107",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage_no_ff(\n            'https://www.dailymotion.com/video/%s' % video_id, video_id)\n\n        age_limit = self._rta_search(webpage)\n\n        description = self._og_search_description(webpage) or self._html_search_meta(\n            'description', webpage, 'description')\n\n        view_count = str_to_int(self._search_regex(\n            [r'<meta[^>]+itemprop=\"interactionCount\"[^>]+content=\"UserPlays:(\\d+)\"',\n             r'video_views_count[^>]+>\\s+([\\d\\.,]+)'],\n            webpage, 'view count', fatal=False))\n        comment_count = int_or_none(self._search_regex(\n            r'<meta[^>]+itemprop=\"interactionCount\"[^>]+content=\"UserComments:(\\d+)\"',\n            webpage, 'comment count', fatal=False))\n\n        player_v5 = self._search_regex(\n            [r'buildPlayer\\(({.+?})\\);', r'playerV5\\s*=\\s*dmp\\.create\\([^,]+?,\\s*({.+?})\\);'],\n            webpage, 'player v5', default=None)\n        if player_v5:\n            player = self._parse_json(player_v5, video_id)\n            metadata = player['metadata']\n\n            self._check_error(metadata)\n\n            formats = []\n            for quality, media_list in metadata['qualities'].items():\n                for media in media_list:\n                    media_url = media.get('url')\n                    if not media_url:\n                        continue\n                    type_ = media.get('type')\n                    if type_ == 'application/vnd.lumberjack.manifest':\n                        continue\n                    ext = determine_ext(media_url)\n                    if type_ == 'application/x-mpegURL' or ext == 'm3u8':\n                        m3u8_formats = self._extract_m3u8_formats(\n                            media_url, video_id, 'mp4', m3u8_id='hls', fatal=False)\n                        if m3u8_formats:\n                            formats.extend(m3u8_formats)\n                    elif type_ == 'application/f4m' or ext == 'f4m':\n                        f4m_formats = self._extract_f4m_formats(\n                            media_url, video_id, preference=-1, f4m_id='hds', fatal=False)\n                        if f4m_formats:\n                            formats.extend(f4m_formats)\n                    else:\n                        f = {\n                            'url': media_url,\n                            'format_id': quality,\n                        }\n                        m = re.search(r'H264-(?P<width>\\d+)x(?P<height>\\d+)', media_url)\n                        if m:\n                            f.update({\n                                'width': int(m.group('width')),\n                                'height': int(m.group('height')),\n                            })\n                        formats.append(f)\n            self._sort_formats(formats)\n\n            title = metadata['title']\n            duration = int_or_none(metadata.get('duration'))\n            timestamp = int_or_none(metadata.get('created_time'))\n            thumbnail = metadata.get('poster_url')\n            uploader = metadata.get('owner', {}).get('screenname')\n            uploader_id = metadata.get('owner', {}).get('id')\n\n            subtitles = {}\n            for subtitle_lang, subtitle in metadata.get('subtitles', {}).get('data', {}).items():\n                subtitles[subtitle_lang] = [{\n                    'ext': determine_ext(subtitle_url),\n                    'url': subtitle_url,\n                } for subtitle_url in subtitle.get('urls', [])]\n\n            return {\n                'id': video_id,\n                'title': title,\n                'description': description,\n                'thumbnail': thumbnail,\n                'duration': duration,\n                'timestamp': timestamp,\n                'uploader': uploader,\n                'uploader_id': uploader_id,\n                'age_limit': age_limit,\n                'view_count': view_count,\n                'comment_count': comment_count,\n                'formats': formats,\n                'subtitles': subtitles,\n            }\n\n        # vevo embed\n        vevo_id = self._search_regex(\n            r'<link rel=\"video_src\" href=\"[^\"]*?vevo.com[^\"]*?video=(?P<id>[\\w]*)',\n            webpage, 'vevo embed', default=None)\n        if vevo_id:\n            return self.url_result('vevo:%s' % vevo_id, 'Vevo')\n\n        # fallback old player\n        embed_page = self._download_webpage_no_ff(\n            'https://www.dailymotion.com/embed/video/%s' % video_id,\n            video_id, 'Downloading embed page')\n\n        timestamp = parse_iso8601(self._html_search_meta(\n            'video:release_date', webpage, 'upload date'))\n\n        info = self._parse_json(\n            self._search_regex(\n                r'var info = ({.*?}),$', embed_page,\n                'video info', flags=re.MULTILINE),\n            video_id)\n\n        self._check_error(info)\n\n        formats = []\n        for (key, format_id) in self._FORMATS:\n            video_url = info.get(key)\n            if video_url is not None:\n                m_size = re.search(r'H264-(\\d+)x(\\d+)', video_url)\n                if m_size is not None:\n                    width, height = map(int_or_none, (m_size.group(1), m_size.group(2)))\n                else:\n                    width, height = None, None\n                formats.append({\n                    'url': video_url,\n                    'ext': 'mp4',\n                    'format_id': format_id,\n                    'width': width,\n                    'height': height,\n                })\n        self._sort_formats(formats)\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, webpage)\n\n        title = self._og_search_title(webpage, default=None)\n        if title is None:\n            title = self._html_search_regex(\n                r'(?s)<span\\s+id=\"video_title\"[^>]*>(.*?)</span>', webpage,\n                'title')\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'uploader': info['owner.screenname'],\n            'timestamp': timestamp,\n            'title': title,\n            'description': description,\n            'subtitles': video_subtitles,\n            'thumbnail': info['thumbnail_url'],\n            'age_limit': age_limit,\n            'view_count': view_count,\n            'duration': info['duration']\n        }",
        "begin_line": 107,
        "end_line": 261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._check_error#263",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._check_error(self, info)",
        "snippet": "    def _check_error(self, info):\n        if info.get('error') is not None:\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, info['error']['title']), expected=True)",
        "begin_line": 263,
        "end_line": 266,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._get_subtitles#268",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._get_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_subtitles(self, video_id, webpage):\n        try:\n            sub_list = self._download_webpage(\n                'https://api.dailymotion.com/video/%s/subtitles?fields=id,language,url' % video_id,\n                video_id, note=False)\n        except ExtractorError as err:\n            self._downloader.report_warning('unable to download video subtitles: %s' % compat_str(err))\n            return {}\n        info = json.loads(sub_list)\n        if (info['total'] > 0):\n            sub_lang_list = dict((l['language'], [{'url': l['url'], 'ext': 'srt'}]) for l in info['list'])\n            return sub_lang_list\n        self._downloader.report_warning('video doesn\\'t have subtitles')\n        return {}",
        "begin_line": 268,
        "end_line": 281,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._extract_entries#298",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._extract_entries(self, id)",
        "snippet": "    def _extract_entries(self, id):\n        video_ids = set()\n        processed_urls = set()\n        for pagenum in itertools.count(1):\n            page_url = self._PAGE_TEMPLATE % (id, pagenum)\n            webpage, urlh = self._download_webpage_handle_no_ff(\n                page_url, id, 'Downloading page %s' % pagenum)\n            if urlh.geturl() in processed_urls:\n                self.report_warning('Stopped at duplicated page %s, which is the same as %s' % (\n                    page_url, urlh.geturl()), id)\n                break\n\n            processed_urls.add(urlh.geturl())\n\n            for video_id in re.findall(r'data-xid=\"(.+?)\"', webpage):\n                if video_id not in video_ids:\n                    yield self.url_result('http://www.dailymotion.com/video/%s' % video_id, 'Dailymotion')\n                    video_ids.add(video_id)\n\n            if re.search(self._MORE_PAGES_INDICATOR, webpage) is None:\n                break",
        "begin_line": 298,
        "end_line": 318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._real_extract#320",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        webpage = self._download_webpage(url, playlist_id)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': self._og_search_title(webpage),\n            'entries': self._extract_entries(playlist_id),\n        }",
        "begin_line": 320,
        "end_line": 330,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionUserIE._real_extract#357",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionUserIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        webpage = self._download_webpage(\n            'https://www.dailymotion.com/user/%s' % user, user)\n        full_user = unescapeHTML(self._html_search_regex(\n            r'<a class=\"nav-image\" title=\"([^\"]+)\" href=\"/%s\">' % re.escape(user),\n            webpage, 'user'))\n\n        return {\n            '_type': 'playlist',\n            'id': user,\n            'title': full_user,\n            'entries': self._extract_entries(user),\n        }",
        "begin_line": 357,
        "end_line": 371,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionCloudIE._extract_dmcloud_url#391",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionCloudIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionCloudIE._extract_dmcloud_url(self, webpage)",
        "snippet": "    def _extract_dmcloud_url(self, webpage):\n        mobj = re.search(r'<iframe[^>]+src=[\\'\"](%s)[\\'\"]' % self._VALID_EMBED_URL, webpage)\n        if mobj:\n            return mobj.group(1)\n\n        mobj = re.search(\n            r'<input[^>]+id=[\\'\"]dmcloudUrlEmissionSelect[\\'\"][^>]+value=[\\'\"](%s)[\\'\"]' % self._VALID_EMBED_URL,\n            webpage)\n        if mobj:\n            return mobj.group(1)",
        "begin_line": 391,
        "end_line": 400,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionCloudIE._real_extract#402",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionCloudIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionCloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage_no_ff(url, video_id)\n\n        title = self._html_search_regex(r'<title>([^>]+)</title>', webpage, 'title')\n\n        video_info = self._parse_json(self._search_regex(\n            r'var\\s+info\\s*=\\s*([^;]+);', webpage, 'video info'), video_id)\n\n        # TODO: parse ios_url, which is in fact a manifest\n        video_url = video_info['mp4_url']\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': video_info.get('thumbnail_url'),\n        }",
        "begin_line": 402,
        "end_line": 420,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tlc.TlcDeIE._real_extract#51",
        "src_path": "youtube_dl/extractor/tlc.py",
        "class_name": "youtube_dl.extractor.tlc.TlcDeIE",
        "signature": "youtube_dl.extractor.tlc.TlcDeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        iframe_url = self._search_regex(\n            '<iframe src=\"(http://www\\.tlc\\.de/wp-content/.+?)\"', webpage,\n            'iframe url')\n        # Otherwise we don't get the correct 'BrightcoveExperience' element,\n        # example: http://www.tlc.de/sendungen/cake-boss/videos/cake-boss-cannoli-drama/\n        iframe_url = iframe_url.replace('.htm?', '.php?')\n        url_fragment = compat_urlparse.urlparse(url).fragment\n        if url_fragment:\n            # Since the fragment is not send to the server, we always get the same iframe\n            iframe_url = re.sub(r'playlist=(\\d+)', 'playlist=%s' % url_fragment, iframe_url)\n        iframe = self._download_webpage(iframe_url, title)\n\n        return {\n            '_type': 'url',\n            'url': BrightcoveIE._extract_brightcove_url(iframe),\n            'ie': BrightcoveIE.ie_key(),\n        }",
        "begin_line": 51,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.malemotion.MalemotionIE._real_extract#21",
        "src_path": "youtube_dl/extractor/malemotion.py",
        "class_name": "youtube_dl.extractor.malemotion.MalemotionIE",
        "signature": "youtube_dl.extractor.malemotion.MalemotionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = compat_urllib_parse_unquote(self._search_regex(\n            r'<source type=\"video/mp4\" src=\"(.+?)\"', webpage, 'video URL'))\n        video_title = self._html_search_regex(\n            r'<title>(.*?)</title', webpage, 'title')\n        video_thumbnail = self._search_regex(\n            r'<video .+?poster=\"(.+?)\"', webpage, 'thumbnail', fatal=False)\n\n        formats = [{\n            'url': video_url,\n            'ext': 'mp4',\n            'format_id': 'mp4',\n            'preference': 1,\n        }]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 21,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.savefrom.SaveFromIE._real_extract#30",
        "src_path": "youtube_dl/extractor/savefrom.py",
        "class_name": "youtube_dl.extractor.savefrom.SaveFromIE",
        "signature": "youtube_dl.extractor.savefrom.SaveFromIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = os.path.splitext(url.split('/')[-1])[0]\n        return {\n            '_type': 'url',\n            'id': video_id,\n            'url': mobj.group('url'),\n        }",
        "begin_line": 30,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaBaseIE._real_initialize#24",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaBaseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 24,
        "end_line": 25,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaBaseIE._login#27",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaBaseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'username': username.encode('utf-8'),\n            'password': password.encode('utf-8'),\n            'remember': 'false',\n            'stayPut': 'false'\n        }\n        request = compat_urllib_request.Request(\n            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))\n        login_page = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        # Not (yet) logged in\n        m = re.search(r'loginResultJson\\s*=\\s*\\'(?P<json>[^\\']+)\\';', login_page)\n        if m is not None:\n            response = m.group('json')\n            response_json = json.loads(response)\n            state = response_json['state']\n\n            if state == 'notlogged':\n                raise ExtractorError(\n                    'Unable to login, incorrect username and/or password',\n                    expected=True)\n\n            # This is when we get popup:\n            # > You're already logged in to lynda.com on two devices.\n            # > If you log in here, we'll log you out of another device.\n            # So, we need to confirm this.\n            if state == 'conflicted':\n                confirm_form = {\n                    'username': '',\n                    'password': '',\n                    'resolve': 'true',\n                    'remember': 'false',\n                    'stayPut': 'false',\n                }\n                request = compat_urllib_request.Request(\n                    self._LOGIN_URL, compat_urllib_parse.urlencode(confirm_form).encode('utf-8'))\n                login_page = self._download_webpage(\n                    request, None,\n                    'Confirming log in and log out from another device')\n\n        if all(not re.search(p, login_page) for p in ('isLoggedIn\\s*:\\s*true', r'logout\\.aspx', r'>Log out<')):\n            if 'login error' in login_page:\n                mobj = re.search(\n                    r'(?s)<h1[^>]+class=\"topmost\">(?P<title>[^<]+)</h1>\\s*<div>(?P<description>.+?)</div>',\n                    login_page)\n                if mobj:\n                    raise ExtractorError(\n                        'lynda returned error: %s - %s'\n                        % (mobj.group('title'), clean_html(mobj.group('description'))),\n                        expected=True)\n            raise ExtractorError('Unable to log in')",
        "begin_line": 27,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._real_extract#108",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        page = self._download_webpage(\n            'http://www.lynda.com/ajax/player?videoId=%s&type=video' % video_id,\n            video_id, 'Downloading video JSON')\n        video_json = json.loads(page)\n\n        if 'Status' in video_json:\n            raise ExtractorError(\n                'lynda returned error: %s' % video_json['Message'], expected=True)\n\n        if video_json['HasAccess'] is False:\n            self.raise_login_required('Video %s is only available for members' % video_id)\n\n        video_id = compat_str(video_json['ID'])\n        duration = video_json['DurationInSeconds']\n        title = video_json['Title']\n\n        formats = []\n\n        fmts = video_json.get('Formats')\n        if fmts:\n            formats.extend([\n                {\n                    'url': fmt['Url'],\n                    'ext': fmt['Extension'],\n                    'width': fmt['Width'],\n                    'height': fmt['Height'],\n                    'filesize': fmt['FileSize'],\n                    'format_id': str(fmt['Resolution'])\n                } for fmt in fmts])\n\n        prioritized_streams = video_json.get('PrioritizedStreams')\n        if prioritized_streams:\n            for prioritized_stream_id, prioritized_stream in prioritized_streams.items():\n                formats.extend([\n                    {\n                        'url': video_url,\n                        'width': int_or_none(format_id),\n                        'format_id': '%s-%s' % (prioritized_stream_id, format_id),\n                    } for format_id, video_url in prioritized_stream.items()\n                ])\n\n        self._check_formats(formats, video_id)\n        self._sort_formats(formats)\n\n        subtitles = self.extract_subtitles(video_id, page)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'subtitles': subtitles,\n            'formats': formats\n        }",
        "begin_line": 108,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._fix_subtitles#165",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._fix_subtitles(self, subs)",
        "snippet": "    def _fix_subtitles(self, subs):\n        srt = ''\n        seq_counter = 0\n        for pos in range(0, len(subs) - 1):\n            seq_current = subs[pos]\n            m_current = re.match(self._TIMECODE_REGEX, seq_current['Timecode'])\n            if m_current is None:\n                continue\n            seq_next = subs[pos + 1]\n            m_next = re.match(self._TIMECODE_REGEX, seq_next['Timecode'])\n            if m_next is None:\n                continue\n            appear_time = m_current.group('timecode')\n            disappear_time = m_next.group('timecode')\n            text = seq_current['Caption'].strip()\n            if text:\n                seq_counter += 1\n                srt += '%s\\r\\n%s --> %s\\r\\n%s\\r\\n\\r\\n' % (seq_counter, appear_time, disappear_time, text)\n        if srt:\n            return srt",
        "begin_line": 165,
        "end_line": 184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._get_subtitles#186",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._get_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_subtitles(self, video_id, webpage):\n        url = 'http://www.lynda.com/ajax/player?videoId=%s&type=transcript' % video_id\n        subs = self._download_json(url, None, False)\n        if subs:\n            return {'en': [{'ext': 'srt', 'data': self._fix_subtitles(subs)}]}\n        else:\n            return {}",
        "begin_line": 186,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaCourseIE._real_extract#203",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaCourseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_path = mobj.group('coursepath')\n        course_id = mobj.group('courseid')\n\n        page = self._download_webpage(\n            'http://www.lynda.com/ajax/player?courseId=%s&type=course' % course_id,\n            course_id, 'Downloading course JSON')\n        course_json = json.loads(page)\n\n        if 'Status' in course_json and course_json['Status'] == 'NotFound':\n            raise ExtractorError(\n                'Course %s does not exist' % course_id, expected=True)\n\n        unaccessible_videos = 0\n        videos = []\n\n        # Might want to extract videos right here from video['Formats'] as it seems 'Formats' is not provided\n        # by single video API anymore\n\n        for chapter in course_json['Chapters']:\n            for video in chapter['Videos']:\n                if video['HasAccess'] is False:\n                    unaccessible_videos += 1\n                    continue\n                videos.append(video['ID'])\n\n        if unaccessible_videos > 0:\n            self._downloader.report_warning(\n                '%s videos are only available for members (or paid members) and will not be downloaded. '\n                % unaccessible_videos + self._ACCOUNT_CREDENTIALS_HINT)\n\n        entries = [\n            self.url_result(\n                'http://www.lynda.com/%s/%s-4.html' % (course_path, video_id),\n                'Lynda')\n            for video_id in videos]\n\n        course_title = course_json['Title']\n\n        return self.playlist_result(entries, course_id, course_title)",
        "begin_line": 203,
        "end_line": 243,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.criterion.CriterionIE._real_extract#22",
        "src_path": "youtube_dl/extractor/criterion.py",
        "class_name": "youtube_dl.extractor.criterion.CriterionIE",
        "signature": "youtube_dl.extractor.criterion.CriterionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        final_url = self._search_regex(\n            r'so.addVariable\\(\"videoURL\", \"(.+?)\"\\)\\;', webpage, 'video url')\n        title = self._og_search_title(webpage)\n        description = self._html_search_meta('description', webpage)\n        thumbnail = self._search_regex(\n            r'so.addVariable\\(\"thumbnailURL\", \"(.+?)\"\\)\\;',\n            webpage, 'thumbnail url')\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 22,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP.__init__#25",
        "src_path": "youtube_dl/postprocessor/embedthumbnail.py",
        "class_name": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP",
        "signature": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP.__init__(self, downloader=None, already_have_thumbnail=False)",
        "snippet": "    def __init__(self, downloader=None, already_have_thumbnail=False):\n        super(EmbedThumbnailPP, self).__init__(downloader)\n        self._already_have_thumbnail = already_have_thumbnail",
        "begin_line": 25,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP.run#29",
        "src_path": "youtube_dl/postprocessor/embedthumbnail.py",
        "class_name": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP",
        "signature": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP.run(self, info)",
        "snippet": "    def run(self, info):\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        if not info.get('thumbnails'):\n            raise EmbedThumbnailPPError('Thumbnail was not found. Nothing to do.')\n\n        thumbnail_filename = info['thumbnails'][-1]['filename']\n\n        if not os.path.exists(encodeFilename(thumbnail_filename)):\n            self._downloader.report_warning(\n                'Skipping embedding the thumbnail because the file is missing.')\n            return [], info\n\n        if info['ext'] == 'mp3':\n            options = [\n                '-c', 'copy', '-map', '0', '-map', '1',\n                '-metadata:s:v', 'title=\"Album cover\"', '-metadata:s:v', 'comment=\"Cover (Front)\"']\n\n            self._downloader.to_screen('[ffmpeg] Adding thumbnail to \"%s\"' % filename)\n\n            self.run_ffmpeg_multiple_files([filename, thumbnail_filename], temp_filename, options)\n\n            if not self._already_have_thumbnail:\n                os.remove(encodeFilename(thumbnail_filename))\n            os.remove(encodeFilename(filename))\n            os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        elif info['ext'] in ['m4a', 'mp4']:\n            if not check_executable('AtomicParsley', ['-v']):\n                raise EmbedThumbnailPPError('AtomicParsley was not found. Please install.')\n\n            cmd = [encodeFilename('AtomicParsley', True),\n                   encodeFilename(filename, True),\n                   encodeArgument('--artwork'),\n                   encodeFilename(thumbnail_filename, True),\n                   encodeArgument('-o'),\n                   encodeFilename(temp_filename, True)]\n\n            self._downloader.to_screen('[atomicparsley] Adding thumbnail to \"%s\"' % filename)\n\n            if self._downloader.params.get('verbose', False):\n                self._downloader.to_screen('[debug] AtomicParsley command line: %s' % shell_quote(cmd))\n\n            p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            stdout, stderr = p.communicate()\n\n            if p.returncode != 0:\n                msg = stderr.decode('utf-8', 'replace').strip()\n                raise EmbedThumbnailPPError(msg)\n\n            if not self._already_have_thumbnail:\n                os.remove(encodeFilename(thumbnail_filename))\n            # for formats that don't support thumbnails (like 3gp) AtomicParsley\n            # won't create to the temporary file\n            if b'No changes' in stdout:\n                self._downloader.report_warning('The file format doesn\\'t support embedding a thumbnail')\n            else:\n                os.remove(encodeFilename(filename))\n                os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n        else:\n            raise EmbedThumbnailPPError('Only mp3 and m4a/mp4 are supported for thumbnail embedding for now.')\n\n        return [], info",
        "begin_line": 29,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pornotube.PornotubeIE._real_extract#33",
        "src_path": "youtube_dl/extractor/pornotube.py",
        "class_name": "youtube_dl.extractor.pornotube.PornotubeIE",
        "signature": "youtube_dl.extractor.pornotube.PornotubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Fetch origin token\n        js_config = self._download_webpage(\n            'http://www.pornotube.com/assets/src/app/config.js', video_id,\n            note='Download JS config')\n        originAuthenticationSpaceKey = self._search_regex(\n            r\"constant\\('originAuthenticationSpaceKey',\\s*'([^']+)'\",\n            js_config, 'originAuthenticationSpaceKey')\n\n        # Fetch actual token\n        token_req_data = {\n            'authenticationSpaceKey': originAuthenticationSpaceKey,\n            'credentials': 'Clip Application',\n        }\n        token_req = compat_urllib_request.Request(\n            'https://api.aebn.net/auth/v1/token/primal',\n            data=json.dumps(token_req_data).encode('utf-8'))\n        token_req.add_header('Content-Type', 'application/json')\n        token_req.add_header('Origin', 'http://www.pornotube.com')\n        token_answer = self._download_json(\n            token_req, video_id, note='Requesting primal token')\n        token = token_answer['tokenKey']\n\n        # Get video URL\n        delivery_req = compat_urllib_request.Request(\n            'https://api.aebn.net/delivery/v1/clips/%s/MP4' % video_id)\n        delivery_req.add_header('Authorization', token)\n        delivery_info = self._download_json(\n            delivery_req, video_id, note='Downloading delivery information')\n        video_url = delivery_info['mediaUrl']\n\n        # Get additional info (title etc.)\n        info_req = compat_urllib_request.Request(\n            'https://api.aebn.net/content/v1/clips/%s?expand='\n            'title,description,primaryImageNumber,startSecond,endSecond,'\n            'movie.title,movie.MovieId,movie.boxCoverFront,movie.stars,'\n            'movie.studios,stars.name,studios.name,categories.name,'\n            'clipActive,movieActive,publishDate,orientations' % video_id)\n        info_req.add_header('Authorization', token)\n        info = self._download_json(\n            info_req, video_id, note='Downloading metadata')\n\n        timestamp = int_or_none(info.get('publishDate'), scale=1000)\n        uploader = info.get('studios', [{}])[0].get('name')\n        movie_id = info['movie']['movieId']\n        thumbnail = 'http://pic.aebn.net/dis/t/%s/%s_%08d.jpg' % (\n            movie_id, movie_id, info['primaryImageNumber'])\n        categories = [c['name'] for c in info.get('categories')]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': info['title'],\n            'description': info.get('description'),\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'age_limit': 18,\n        }",
        "begin_line": 33,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.wimp.WimpIE._real_extract#29",
        "src_path": "youtube_dl/extractor/wimp.py",
        "class_name": "youtube_dl.extractor.wimp.WimpIE",
        "signature": "youtube_dl.extractor.wimp.WimpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(\n            [r\"[\\\"']file[\\\"']\\s*[:,]\\s*[\\\"'](.+?)[\\\"']\", r\"videoId\\s*:\\s*[\\\"']([^\\\"']+)[\\\"']\"],\n            webpage, 'video URL')\n        if YoutubeIE.suitable(video_url):\n            self.to_screen('Found YouTube video')\n            return {\n                '_type': 'url',\n                'url': video_url,\n                'ie_key': YoutubeIE.ie_key(),\n            }\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 29,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tutv.TutvIE._real_extract#21",
        "src_path": "youtube_dl/extractor/tutv.py",
        "class_name": "youtube_dl.extractor.tutv.TutvIE",
        "signature": "youtube_dl.extractor.tutv.TutvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        internal_id = self._search_regex(r'codVideo=([0-9]+)', webpage, 'internal video ID')\n\n        data_content = self._download_webpage(\n            'http://tu.tv/flvurl.php?codVideo=%s' % internal_id, video_id, 'Downloading video info')\n        video_url = base64.b64decode(compat_parse_qs(data_content)['kpt'][0].encode('utf-8')).decode('utf-8')\n\n        return {\n            'id': internal_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n        }",
        "begin_line": 21,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.myspace.MySpaceIE._real_extract#74",
        "src_path": "youtube_dl/extractor/myspace.py",
        "class_name": "youtube_dl.extractor.myspace.MySpaceIE",
        "signature": "youtube_dl.extractor.myspace.MySpaceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        player_url = self._search_regex(\n            r'playerSwf\":\"([^\"?]*)', webpage, 'player URL')\n\n        if mobj.group('mediatype').startswith('music/song'):\n            # songs don't store any useful info in the 'context' variable\n            song_data = self._search_regex(\n                r'''<button.*data-song-id=([\"\\'])%s\\1.*''' % video_id,\n                webpage, 'song_data', default=None, group=0)\n            if song_data is None:\n                # some songs in an album are not playable\n                self.report_warning(\n                    '%s: No downloadable song on this page' % video_id)\n                return\n\n            def search_data(name):\n                return self._search_regex(\n                    r'''data-%s=([\\'\"])(?P<data>.*?)\\1''' % name,\n                    song_data, name, default='', group='data')\n            streamUrl = search_data('stream-url')\n            if not streamUrl:\n                vevo_id = search_data('vevo-id')\n                youtube_id = search_data('youtube-id')\n                if vevo_id:\n                    self.to_screen('Vevo video detected: %s' % vevo_id)\n                    return self.url_result('vevo:%s' % vevo_id, ie='Vevo')\n                elif youtube_id:\n                    self.to_screen('Youtube video detected: %s' % youtube_id)\n                    return self.url_result(youtube_id, ie='Youtube')\n                else:\n                    raise ExtractorError(\n                        'Found song but don\\'t know how to download it')\n            info = {\n                'id': video_id,\n                'title': self._og_search_title(webpage),\n                'uploader': search_data('artist-name'),\n                'uploader_id': search_data('artist-username'),\n                'thumbnail': self._og_search_thumbnail(webpage),\n            }\n        else:\n            context = json.loads(self._search_regex(\n                r'context = ({.*?});', webpage, 'context'))\n            video = context['video']\n            streamUrl = video['streamUrl']\n            info = {\n                'id': compat_str(video['mediaId']),\n                'title': video['title'],\n                'description': video['description'],\n                'thumbnail': video['imageUrl'],\n                'uploader': video['artistName'],\n                'uploader_id': video['artistUsername'],\n            }\n\n        rtmp_url, play_path = streamUrl.split(';', 1)\n        info.update({\n            'url': rtmp_url,\n            'play_path': play_path,\n            'player_url': player_url,\n            'ext': 'flv',\n        })\n        return info",
        "begin_line": 74,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.myspace.MySpaceAlbumIE._real_extract#161",
        "src_path": "youtube_dl/extractor/myspace.py",
        "class_name": "youtube_dl.extractor.myspace.MySpaceAlbumIE",
        "signature": "youtube_dl.extractor.myspace.MySpaceAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        display_id = mobj.group('title') + playlist_id\n        webpage = self._download_webpage(url, display_id)\n        tracks_paths = re.findall(r'\"music:song\" content=\"(.*?)\"', webpage)\n        if not tracks_paths:\n            raise ExtractorError(\n                '%s: No songs found, try using proxy' % display_id,\n                expected=True)\n        entries = [\n            self.url_result(t_path, ie=MySpaceIE.ie_key())\n            for t_path in tracks_paths]\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'display_id': display_id,\n            'title': self._og_search_title(webpage),\n            'entries': entries,\n        }",
        "begin_line": 161,
        "end_line": 180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._real_initialize#90",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 90,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._login#93",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        # No authentication to be performed\n        if not username:\n            return True\n\n        # Log in\n        login_form_strs = {\n            'mail': username,\n            'password': password,\n        }\n        login_data = compat_urllib_parse.urlencode(encode_dict(login_form_strs)).encode('utf-8')\n        request = compat_urllib_request.Request(\n            'https://secure.nicovideo.jp/secure/login', login_data)\n        login_results = self._download_webpage(\n            request, None, note='Logging in', errnote='Unable to log in')\n        if re.search(r'(?i)<h1 class=\"mb8p4\">Log in error</h1>', login_results) is not None:\n            self._downloader.report_warning('unable to log in: bad username or password')\n            return False\n        # Successful login\n        self._AUTHENTICATED = True\n        return True",
        "begin_line": 93,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._real_extract#116",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Get video webpage. We are not actually interested in it for normal\n        # cases, but need the cookies in order to be able to download the\n        # info webpage\n        webpage, handle = self._download_webpage_handle(\n            'http://www.nicovideo.jp/watch/' + video_id, video_id)\n        if video_id.startswith('so'):\n            video_id = self._match_id(handle.geturl())\n\n        video_info = self._download_xml(\n            'http://ext.nicovideo.jp/api/getthumbinfo/' + video_id, video_id,\n            note='Downloading video info page')\n\n        if self._AUTHENTICATED:\n            # Get flv info\n            flv_info_webpage = self._download_webpage(\n                'http://flapi.nicovideo.jp/api/getflv/' + video_id + '?as3=1',\n                video_id, 'Downloading flv info')\n        else:\n            # Get external player info\n            ext_player_info = self._download_webpage(\n                'http://ext.nicovideo.jp/thumb_watch/' + video_id, video_id)\n            thumb_play_key = self._search_regex(\n                r'\\'thumbPlayKey\\'\\s*:\\s*\\'(.*?)\\'', ext_player_info, 'thumbPlayKey')\n\n            # Get flv info\n            flv_info_data = compat_urllib_parse.urlencode({\n                'k': thumb_play_key,\n                'v': video_id\n            })\n            flv_info_request = compat_urllib_request.Request(\n                'http://ext.nicovideo.jp/thumb_watch', flv_info_data,\n                {'Content-Type': 'application/x-www-form-urlencoded'})\n            flv_info_webpage = self._download_webpage(\n                flv_info_request, video_id,\n                note='Downloading flv info', errnote='Unable to download flv info')\n\n        flv_info = compat_urlparse.parse_qs(flv_info_webpage)\n        if 'url' not in flv_info:\n            if 'deleted' in flv_info:\n                raise ExtractorError('The video has been deleted.',\n                                     expected=True)\n            else:\n                raise ExtractorError('Unable to find video URL')\n\n        video_real_url = flv_info['url'][0]\n\n        # Start extracting information\n        title = xpath_text(video_info, './/title')\n        if not title:\n            title = self._og_search_title(webpage, default=None)\n        if not title:\n            title = self._html_search_regex(\n                r'<span[^>]+class=\"videoHeaderTitle\"[^>]*>([^<]+)</span>',\n                webpage, 'video title')\n\n        watch_api_data_string = self._html_search_regex(\n            r'<div[^>]+id=\"watchAPIDataContainer\"[^>]+>([^<]+)</div>',\n            webpage, 'watch api data', default=None)\n        watch_api_data = self._parse_json(watch_api_data_string, video_id) if watch_api_data_string else {}\n        video_detail = watch_api_data.get('videoDetail', {})\n\n        extension = xpath_text(video_info, './/movie_type')\n        if not extension:\n            extension = determine_ext(video_real_url)\n\n        thumbnail = (\n            xpath_text(video_info, './/thumbnail_url') or\n            self._html_search_meta('image', webpage, 'thumbnail', default=None) or\n            video_detail.get('thumbnail'))\n\n        description = xpath_text(video_info, './/description')\n\n        timestamp = parse_iso8601(xpath_text(video_info, './/first_retrieve'))\n        if not timestamp:\n            match = self._html_search_meta('datePublished', webpage, 'date published', default=None)\n            if match:\n                timestamp = parse_iso8601(match.replace('+', ':00+'))\n        if not timestamp and video_detail.get('postedAt'):\n            timestamp = parse_iso8601(\n                video_detail['postedAt'].replace('/', '-'),\n                delimiter=' ', timezone=datetime.timedelta(hours=9))\n\n        view_count = int_or_none(xpath_text(video_info, './/view_counter'))\n        if not view_count:\n            match = self._html_search_regex(\n                r'>Views: <strong[^>]*>([^<]+)</strong>',\n                webpage, 'view count', default=None)\n            if match:\n                view_count = int_or_none(match.replace(',', ''))\n        view_count = view_count or video_detail.get('viewCount')\n\n        comment_count = int_or_none(xpath_text(video_info, './/comment_num'))\n        if not comment_count:\n            match = self._html_search_regex(\n                r'>Comments: <strong[^>]*>([^<]+)</strong>',\n                webpage, 'comment count', default=None)\n            if match:\n                comment_count = int_or_none(match.replace(',', ''))\n        comment_count = comment_count or video_detail.get('commentCount')\n\n        duration = (parse_duration(\n            xpath_text(video_info, './/length') or\n            self._html_search_meta(\n                'video:duration', webpage, 'video duration', default=None)) or\n            video_detail.get('length'))\n\n        webpage_url = xpath_text(video_info, './/watch_url') or url\n\n        if video_info.find('.//ch_id') is not None:\n            uploader_id = video_info.find('.//ch_id').text\n            uploader = video_info.find('.//ch_name').text\n        elif video_info.find('.//user_id') is not None:\n            uploader_id = video_info.find('.//user_id').text\n            uploader = video_info.find('.//user_nickname').text\n        else:\n            uploader_id = uploader = None\n\n        return {\n            'id': video_id,\n            'url': video_real_url,\n            'title': title,\n            'ext': extension,\n            'format_id': 'economy' if video_real_url.endswith('low') else 'normal',\n            'thumbnail': thumbnail,\n            'description': description,\n            'uploader': uploader,\n            'timestamp': timestamp,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'duration': duration,\n            'webpage_url': webpage_url,\n        }",
        "begin_line": 116,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoPlaylistIE._real_extract#266",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoPlaylistIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n        webpage = self._download_webpage(url, list_id)\n\n        entries_json = self._search_regex(r'Mylist\\.preload\\(\\d+, (\\[.*\\])\\);',\n                                          webpage, 'entries')\n        entries = json.loads(entries_json)\n        entries = [{\n            '_type': 'url',\n            'ie_key': NiconicoIE.ie_key(),\n            'url': ('http://www.nicovideo.jp/watch/%s' %\n                    entry['item_data']['video_id']),\n        } for entry in entries]\n\n        return {\n            '_type': 'playlist',\n            'title': self._search_regex(r'\\s+name: \"(.*?)\"', webpage, 'title'),\n            'id': list_id,\n            'entries': entries,\n        }",
        "begin_line": 266,
        "end_line": 285,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.swrmediathek.SWRMediathekIE._real_extract#57",
        "src_path": "youtube_dl/extractor/swrmediathek.py",
        "class_name": "youtube_dl.extractor.swrmediathek.SWRMediathekIE",
        "signature": "youtube_dl.extractor.swrmediathek.SWRMediathekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video = self._download_json(\n            'http://swrmediathek.de/AjaxEntry?ekey=%s' % video_id, video_id, 'Downloading video JSON')\n\n        attr = video['attr']\n        media_type = attr['entry_etype']\n\n        formats = []\n        for entry in video['sub']:\n            if entry['name'] != 'entry_media':\n                continue\n\n            entry_attr = entry['attr']\n            codec = entry_attr['val0']\n            quality = int(entry_attr['val1'])\n\n            fmt = {\n                'url': entry_attr['val2'],\n                'quality': quality,\n            }\n\n            if media_type == 'Video':\n                fmt.update({\n                    'format_note': ['144p', '288p', '544p', '720p'][quality - 1],\n                    'vcodec': codec,\n                })\n            elif media_type == 'Audio':\n                fmt.update({\n                    'acodec': codec,\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': attr['entry_title'],\n            'description': attr['entry_descl'],\n            'thumbnail': attr['entry_image_16_9'],\n            'duration': parse_duration(attr['entry_durat']),\n            'upload_date': attr['entry_pdatet'][:-4],\n            'uploader': attr['channel_title'],\n            'uploader_id': attr['channel_idkey'],\n            'formats': formats,\n        }",
        "begin_line": 57,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._handle_error#34",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._handle_error(self, response)",
        "snippet": "    def _handle_error(self, response):\n        if not isinstance(response, dict):\n            return\n        error = response.get('error')\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s - %s' % (self.IE_NAME, error, response.get('message')),\n                expected=True)",
        "begin_line": 34,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._download_json#43",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._download_json(self, url, video_id, note='Downloading JSON metadata')",
        "snippet": "    def _download_json(self, url, video_id, note='Downloading JSON metadata'):\n        headers = {\n            'Referer': 'http://api.twitch.tv/crossdomain/receiver.html?v=2',\n            'X-Requested-With': 'XMLHttpRequest',\n        }\n        for cookie in self._downloader.cookiejar:\n            if cookie.name == 'api_token':\n                headers['Twitch-Api-Token'] = cookie.value\n        request = compat_urllib_request.Request(url, headers=headers)\n        response = super(TwitchBaseIE, self)._download_json(request, video_id, note)\n        self._handle_error(response)\n        return response",
        "begin_line": 43,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._real_initialize#56",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._login#59",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_page, handle = self._download_webpage_handle(\n            self._LOGIN_URL, None, 'Downloading login page')\n\n        login_form = self._hidden_inputs(login_page)\n\n        login_form.update({\n            'username': username,\n            'password': password,\n        })\n\n        redirect_url = handle.geturl()\n\n        post_url = self._search_regex(\n            r'<form[^>]+action=([\"\\'])(?P<url>.+?)\\1', login_page,\n            'post url', default=redirect_url, group='url')\n\n        if not post_url.startswith('http'):\n            post_url = compat_urlparse.urljoin(redirect_url, post_url)\n\n        request = compat_urllib_request.Request(\n            post_url, compat_urllib_parse.urlencode(encode_dict(login_form)).encode('utf-8'))\n        request.add_header('Referer', redirect_url)\n        response = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        error_message = self._search_regex(\n            r'<div[^>]+class=\"subwindow_notice\"[^>]*>([^<]+)</div>',\n            response, 'error message', default=None)\n        if error_message:\n            raise ExtractorError(\n                'Unable to login. Twitch said: %s' % error_message, expected=True)\n\n        if '>Reset your password<' in response:\n            self.report_warning('Twitch asks you to reset your password, go to https://secure.twitch.tv/reset/submit')",
        "begin_line": 59,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._prefer_source#99",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._prefer_source(self, formats)",
        "snippet": "    def _prefer_source(self, formats):\n        try:\n            source = next(f for f in formats if f['format_id'] == 'Source')\n            source['preference'] = 10\n        except StopIteration:\n            pass  # No Source stream present\n        self._sort_formats(formats)",
        "begin_line": 99,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._download_info#109",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._download_info(self, item, item_id)",
        "snippet": "    def _download_info(self, item, item_id):\n        return self._extract_info(self._download_json(\n            '%s/kraken/videos/%s%s' % (self._API_BASE, item, item_id), item_id,\n            'Downloading %s info JSON' % self._ITEM_TYPE))",
        "begin_line": 109,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_media#114",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_media(self, item_id)",
        "snippet": "    def _extract_media(self, item_id):\n        info = self._download_info(self._ITEM_SHORTCUT, item_id)\n        response = self._download_json(\n            '%s/api/videos/%s%s' % (self._API_BASE, self._ITEM_SHORTCUT, item_id), item_id,\n            'Downloading %s playlist JSON' % self._ITEM_TYPE)\n        entries = []\n        chunks = response['chunks']\n        qualities = list(chunks.keys())\n        for num, fragment in enumerate(zip(*chunks.values()), start=1):\n            formats = []\n            for fmt_num, fragment_fmt in enumerate(fragment):\n                format_id = qualities[fmt_num]\n                fmt = {\n                    'url': fragment_fmt['url'],\n                    'format_id': format_id,\n                    'quality': 1 if format_id == 'live' else 0,\n                }\n                m = re.search(r'^(?P<height>\\d+)[Pp]', format_id)\n                if m:\n                    fmt['height'] = int(m.group('height'))\n                formats.append(fmt)\n            self._sort_formats(formats)\n            entry = dict(info)\n            entry['id'] = '%s_%d' % (entry['id'], num)\n            entry['title'] = '%s part %d' % (entry['title'], num)\n            entry['formats'] = formats\n            entries.append(entry)\n        return self.playlist_result(entries, info['id'], info['title'])",
        "begin_line": 114,
        "end_line": 141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_info#143",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_info(self, info)",
        "snippet": "    def _extract_info(self, info):\n        return {\n            'id': info['_id'],\n            'title': info.get('title') or 'Untitled Broadcast',\n            'description': info.get('description'),\n            'duration': int_or_none(info.get('length')),\n            'thumbnail': info.get('preview'),\n            'uploader': info.get('channel', {}).get('display_name'),\n            'uploader_id': info.get('channel', {}).get('name'),\n            'timestamp': parse_iso8601(info.get('recorded_at')),\n            'view_count': int_or_none(info.get('views')),\n        }",
        "begin_line": 143,
        "end_line": 154,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._real_extract#156",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_media(self._match_id(url))",
        "begin_line": 156,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchVodIE._real_extract#241",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchVodIE",
        "signature": "youtube_dl.extractor.twitch.TwitchVodIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        item_id = self._match_id(url)\n\n        info = self._download_info(self._ITEM_SHORTCUT, item_id)\n        access_token = self._download_json(\n            '%s/api/vods/%s/access_token' % (self._API_BASE, item_id), item_id,\n            'Downloading %s access token' % self._ITEM_TYPE)\n\n        formats = self._extract_m3u8_formats(\n            '%s/vod/%s?%s' % (\n                self._USHER_BASE, item_id,\n                compat_urllib_parse.urlencode({\n                    'allow_source': 'true',\n                    'allow_spectre': 'true',\n                    'player': 'twitchweb',\n                    'nauth': access_token['token'],\n                    'nauthsig': access_token['sig'],\n                })),\n            item_id, 'mp4')\n\n        self._prefer_source(formats)\n        info['formats'] = formats\n\n        parsed_url = compat_urllib_parse_urlparse(url)\n        query = compat_parse_qs(parsed_url.query)\n        if 't' in query:\n            info['start_time'] = parse_duration(query['t'][0])\n\n        return info",
        "begin_line": 241,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist#276",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist(self, channel_id)",
        "snippet": "    def _extract_playlist(self, channel_id):\n        info = self._download_json(\n            '%s/kraken/channels/%s' % (self._API_BASE, channel_id),\n            channel_id, 'Downloading channel info JSON')\n        channel_name = info.get('display_name') or info.get('name')\n        entries = []\n        offset = 0\n        limit = self._PAGE_LIMIT\n        for counter in itertools.count(1):\n            response = self._download_json(\n                self._PLAYLIST_URL % (channel_id, offset, limit),\n                channel_id, 'Downloading %s videos JSON page %d' % (self._PLAYLIST_TYPE, counter))\n            page_entries = self._extract_playlist_page(response)\n            if not page_entries:\n                break\n            entries.extend(page_entries)\n            offset += limit\n        return self.playlist_result(\n            [self.url_result(entry) for entry in set(entries)],\n            channel_id, channel_name)",
        "begin_line": 276,
        "end_line": 295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist_page#297",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist_page(self, response)",
        "snippet": "    def _extract_playlist_page(self, response):\n        videos = response.get('videos')\n        return [video['url'] for video in videos] if videos else []",
        "begin_line": 297,
        "end_line": 299,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._real_extract#301",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_playlist(self._match_id(url))",
        "begin_line": 301,
        "end_line": 302,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBookmarksIE._extract_playlist_page#351",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBookmarksIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBookmarksIE._extract_playlist_page(self, response)",
        "snippet": "    def _extract_playlist_page(self, response):\n        entries = []\n        for bookmark in response.get('bookmarks', []):\n            video = bookmark.get('video')\n            if not video:\n                continue\n            entries.append(video['url'])\n        return entries",
        "begin_line": 351,
        "end_line": 358,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchStreamIE._real_extract#389",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchStreamIE",
        "signature": "youtube_dl.extractor.twitch.TwitchStreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        stream = self._download_json(\n            '%s/kraken/streams/%s' % (self._API_BASE, channel_id), channel_id,\n            'Downloading stream JSON').get('stream')\n\n        # Fallback on profile extraction if stream is offline\n        if not stream:\n            return self.url_result(\n                'http://www.twitch.tv/%s/profile' % channel_id,\n                'TwitchProfile', channel_id)\n\n        # Channel name may be typed if different case than the original channel name\n        # (e.g. http://www.twitch.tv/TWITCHPLAYSPOKEMON) that will lead to constructing\n        # an invalid m3u8 URL. Working around by use of original channel name from stream\n        # JSON and fallback to lowercase if it's not available.\n        channel_id = stream.get('channel', {}).get('name') or channel_id.lower()\n\n        access_token = self._download_json(\n            '%s/api/channels/%s/access_token' % (self._API_BASE, channel_id), channel_id,\n            'Downloading channel access token')\n\n        query = {\n            'allow_source': 'true',\n            'p': random.randint(1000000, 10000000),\n            'player': 'twitchweb',\n            'segment_preference': '4',\n            'sig': access_token['sig'].encode('utf-8'),\n            'token': access_token['token'].encode('utf-8'),\n        }\n        formats = self._extract_m3u8_formats(\n            '%s/api/channel/hls/%s.m3u8?%s'\n            % (self._USHER_BASE, channel_id, compat_urllib_parse.urlencode(query)),\n            channel_id, 'mp4')\n        self._prefer_source(formats)\n\n        view_count = stream.get('viewers')\n        timestamp = parse_iso8601(stream.get('created_at'))\n\n        channel = stream['channel']\n        title = self._live_title(channel.get('display_name') or channel.get('name'))\n        description = channel.get('status')\n\n        thumbnails = []\n        for thumbnail_key, thumbnail_url in stream['preview'].items():\n            m = re.search(r'(?P<width>\\d+)x(?P<height>\\d+)\\.jpg$', thumbnail_key)\n            if not m:\n                continue\n            thumbnails.append({\n                'url': thumbnail_url,\n                'width': int(m.group('width')),\n                'height': int(m.group('height')),\n            })\n\n        return {\n            'id': compat_str(stream['_id']),\n            'display_id': channel_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'uploader': channel.get('display_name'),\n            'uploader_id': channel.get('name'),\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'formats': formats,\n            'is_live': True,\n        }",
        "begin_line": 389,
        "end_line": 456,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE.md5_text#99",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE.md5_text(text)",
        "snippet": "    def md5_text(text):\n        return hashlib.md5(text.encode('utf-8')).hexdigest()",
        "begin_line": 99,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE.construct_video_urls#102",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE.construct_video_urls(self, data, video_id, _uuid)",
        "snippet": "    def construct_video_urls(self, data, video_id, _uuid):\n        def do_xor(x, y):\n            a = y % 3\n            if a == 1:\n                return x ^ 121\n            if a == 2:\n                return x ^ 72\n            return x ^ 103\n\n        def get_encode_code(l):\n            a = 0\n            b = l.split('-')\n            c = len(b)\n            s = ''\n            for i in range(c - 1, -1, -1):\n                a = do_xor(int(b[c - i - 1], 16), i)\n                s += chr(a)\n            return s[::-1]\n\n        def get_path_key(x, format_id, segment_index):\n            mg = ')(*&^flash@#$%a'\n            tm = self._download_json(\n                'http://data.video.qiyi.com/t?tn=' + str(random.random()), video_id,\n                note='Download path key of segment %d for format %s' % (segment_index + 1, format_id)\n            )['t']\n            t = str(int(math.floor(int(tm) / (600.0))))\n            return self.md5_text(t + mg + x)\n\n        video_urls_dict = {}\n        for format_item in data['vp']['tkl'][0]['vs']:\n            if 0 < int(format_item['bid']) <= 10:\n                format_id = self.get_format(format_item['bid'])\n            else:\n                continue\n\n            video_urls = []\n\n            video_urls_info = format_item['fs']\n            if not format_item['fs'][0]['l'].startswith('/'):\n                t = get_encode_code(format_item['fs'][0]['l'])\n                if t.endswith('mp4'):\n                    video_urls_info = format_item['flvs']\n\n            for segment_index, segment in enumerate(video_urls_info):\n                vl = segment['l']\n                if not vl.startswith('/'):\n                    vl = get_encode_code(vl)\n                key = get_path_key(\n                    vl.split('/')[-1].split('.')[0], format_id, segment_index)\n                filesize = segment['b']\n                base_url = data['vp']['du'].split('/')\n                base_url.insert(-1, key)\n                base_url = '/'.join(base_url)\n                param = {\n                    'su': _uuid,\n                    'qyid': uuid.uuid4().hex,\n                    'client': '',\n                    'z': '',\n                    'bt': '',\n                    'ct': '',\n                    'tn': str(int(time.time()))\n                }\n                api_video_url = base_url + vl + '?' + \\\n                    compat_urllib_parse.urlencode(param)\n                js = self._download_json(\n                    api_video_url, video_id,\n                    note='Download video info of segment %d for format %s' % (segment_index + 1, format_id))\n                video_url = js['l']\n                video_urls.append(\n                    (video_url, filesize))\n\n            video_urls_dict[format_id] = video_urls\n        return video_urls_dict",
        "begin_line": 102,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE.get_format#176",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE.get_format(self, bid)",
        "snippet": "    def get_format(self, bid):\n        matched_format_ids = [_format_id for _bid, _format_id in self._FORMATS_MAP if _bid == str(bid)]\n        return matched_format_ids[0] if len(matched_format_ids) else None",
        "begin_line": 176,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE.get_bid#180",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE.get_bid(self, format_id)",
        "snippet": "    def get_bid(self, format_id):\n        matched_bids = [_bid for _bid, _format_id in self._FORMATS_MAP if _format_id == format_id]\n        return matched_bids[0] if len(matched_bids) else None",
        "begin_line": 180,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE.get_raw_data#184",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE.get_raw_data(self, tvid, video_id, enc_key, _uuid)",
        "snippet": "    def get_raw_data(self, tvid, video_id, enc_key, _uuid):\n        tm = str(int(time.time()))\n        tail = tm + tvid\n        param = {\n            'key': 'fvip',\n            'src': self.md5_text('youtube-dl'),\n            'tvId': tvid,\n            'vid': video_id,\n            'vinfo': 1,\n            'tm': tm,\n            'enc': self.md5_text(enc_key + tail),\n            'qyid': _uuid,\n            'tn': random.random(),\n            'um': 0,\n            'authkey': self.md5_text(self.md5_text('') + tail),\n        }\n\n        api_url = 'http://cache.video.qiyi.com/vms' + '?' + \\\n            compat_urllib_parse.urlencode(param)\n        raw_data = self._download_json(api_url, video_id)\n        return raw_data",
        "begin_line": 184,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE.get_enc_key#206",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE.get_enc_key(self, swf_url, video_id)",
        "snippet": "    def get_enc_key(self, swf_url, video_id):\n        # TODO: automatic key extraction\n        # last update at 2015-10-22 for Zombie::bite\n        # '7223c67061dbea1259d0ceb44f44b6d62288f4f80c972170de5201d2321060270e05'[2:66][0::2]\n        enc_key = '2c76de15dcb44bd28ff0927d50d31620'\n        return enc_key",
        "begin_line": 206,
        "end_line": 211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE._real_extract#213",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(\n            url, 'temp_id', note='download video page')\n        tvid = self._search_regex(\n            r'data-player-tvid\\s*=\\s*[\\'\"](\\d+)', webpage, 'tvid')\n        video_id = self._search_regex(\n            r'data-player-videoid\\s*=\\s*[\\'\"]([a-f\\d]+)', webpage, 'video_id')\n        swf_url = self._search_regex(\n            r'(http://[^\\'\"]+MainPlayer[^.]+\\.swf)', webpage, 'swf player URL')\n        _uuid = uuid.uuid4().hex\n\n        enc_key = self.get_enc_key(swf_url, video_id)\n\n        raw_data = self.get_raw_data(tvid, video_id, enc_key, _uuid)\n\n        if raw_data['code'] != 'A000000':\n            raise ExtractorError('Unable to load data. Error code: ' + raw_data['code'])\n\n        if not raw_data['data']['vp']['tkl']:\n            raise ExtractorError('No support iQiqy VIP video')\n\n        data = raw_data['data']\n\n        title = data['vi']['vn']\n\n        # generate video_urls_dict\n        video_urls_dict = self.construct_video_urls(\n            data, video_id, _uuid)\n\n        # construct info\n        entries = []\n        for format_id in video_urls_dict:\n            video_urls = video_urls_dict[format_id]\n            for i, video_url_info in enumerate(video_urls):\n                if len(entries) < i + 1:\n                    entries.append({'formats': []})\n                entries[i]['formats'].append(\n                    {\n                        'url': video_url_info[0],\n                        'filesize': video_url_info[-1],\n                        'format_id': format_id,\n                        'preference': int(self.get_bid(format_id))\n                    }\n                )\n\n        for i in range(len(entries)):\n            self._sort_formats(entries[i]['formats'])\n            entries[i].update(\n                {\n                    'id': '%s_part%d' % (video_id, i + 1),\n                    'title': title,\n                }\n            )\n\n        if len(entries) > 1:\n            info = {\n                '_type': 'multi_video',\n                'id': video_id,\n                'title': title,\n                'entries': entries,\n            }\n        else:\n            info = entries[0]\n            info['id'] = video_id\n            info['title'] = title\n\n        return info",
        "begin_line": 213,
        "end_line": 279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vine.VineIE._real_extract#83",
        "src_path": "youtube_dl/extractor/vine.py",
        "class_name": "youtube_dl.extractor.vine.VineIE",
        "signature": "youtube_dl.extractor.vine.VineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage('https://vine.co/v/' + video_id, video_id)\n\n        data = self._parse_json(\n            self._search_regex(\n                r'window\\.POST_DATA\\s*=\\s*{\\s*%s\\s*:\\s*({.+?})\\s*};\\s*</script>' % video_id,\n                webpage, 'vine data'),\n            video_id)\n\n        formats = [{\n            'format_id': '%(format)s-%(rate)s' % f,\n            'vcodec': f.get('format'),\n            'quality': f.get('rate'),\n            'url': f['videoUrl'],\n        } for f in data['videoUrls'] if f.get('videoUrl')]\n\n        self._sort_formats(formats)\n\n        username = data.get('username')\n\n        return {\n            'id': video_id,\n            'title': data.get('description') or self._og_search_title(webpage),\n            'alt_title': 'Vine by %s' % username if username else self._og_search_description(webpage, default=None),\n            'thumbnail': data.get('thumbnailUrl'),\n            'upload_date': unified_strdate(data.get('created')),\n            'uploader': username,\n            'uploader_id': data.get('userIdStr'),\n            'like_count': int_or_none(data.get('likes', {}).get('count')),\n            'comment_count': int_or_none(data.get('comments', {}).get('count')),\n            'repost_count': int_or_none(data.get('reposts', {}).get('count')),\n            'formats': formats,\n        }",
        "begin_line": 83,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vine.VineUserIE._real_extract#137",
        "src_path": "youtube_dl/extractor/vine.py",
        "class_name": "youtube_dl.extractor.vine.VineUserIE",
        "signature": "youtube_dl.extractor.vine.VineUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        u = mobj.group('u')\n\n        profile_url = \"%sapi/users/profiles/%s%s\" % (\n            self._VINE_BASE_URL, 'vanity/' if not u else '', user)\n        profile_data = self._download_json(\n            profile_url, user, note='Downloading user profile data')\n\n        user_id = profile_data['data']['userId']\n        timeline_data = []\n        for pagenum in itertools.count(1):\n            timeline_url = \"%sapi/timelines/users/%s?page=%s&size=100\" % (\n                self._VINE_BASE_URL, user_id, pagenum)\n            timeline_page = self._download_json(\n                timeline_url, user, note='Downloading page %d' % pagenum)\n            timeline_data.extend(timeline_page['data']['records'])\n            if timeline_page['data']['nextPage'] is None:\n                break\n\n        entries = [\n            self.url_result(e['permalinkUrl'], 'Vine') for e in timeline_data]\n        return self.playlist_result(entries, user)",
        "begin_line": 137,
        "end_line": 160,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.naver.NaverIE._real_extract#41",
        "src_path": "youtube_dl/extractor/naver.py",
        "class_name": "youtube_dl.extractor.naver.NaverIE",
        "signature": "youtube_dl.extractor.naver.NaverIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        m_id = re.search(r'var rmcPlayer = new nhn.rmcnmv.RMCVideoPlayer\\(\"(.+?)\", \"(.+?)\"',\n                         webpage)\n        if m_id is None:\n            error = self._html_search_regex(\n                r'(?s)<div class=\"(?:nation_error|nation_box|error_box)\">\\s*(?:<!--.*?-->)?\\s*<p class=\"[^\"]+\">(?P<msg>.+?)</p>\\s*</div>',\n                webpage, 'error', default=None)\n            if error:\n                raise ExtractorError(error, expected=True)\n            raise ExtractorError('couldn\\'t extract vid and key')\n        vid = m_id.group(1)\n        key = m_id.group(2)\n        query = compat_urllib_parse.urlencode({'vid': vid, 'inKey': key, })\n        query_urls = compat_urllib_parse.urlencode({\n            'masterVid': vid,\n            'protocol': 'p2p',\n            'inKey': key,\n        })\n        info = self._download_xml(\n            'http://serviceapi.rmcnmv.naver.com/flash/videoInfo.nhn?' + query,\n            video_id, 'Downloading video info')\n        urls = self._download_xml(\n            'http://serviceapi.rmcnmv.naver.com/flash/playableEncodingOption.nhn?' + query_urls,\n            video_id, 'Downloading video formats info')\n\n        formats = []\n        for format_el in urls.findall('EncodingOptions/EncodingOption'):\n            domain = format_el.find('Domain').text\n            uri = format_el.find('uri').text\n            f = {\n                'url': compat_urlparse.urljoin(domain, uri),\n                'ext': 'mp4',\n                'width': int(format_el.find('width').text),\n                'height': int(format_el.find('height').text),\n            }\n            if domain.startswith('rtmp'):\n                # urlparse does not support custom schemes\n                # https://bugs.python.org/issue18828\n                f.update({\n                    'url': domain + uri,\n                    'ext': 'flv',\n                    'rtmp_protocol': '1',  # rtmpt\n                })\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info.find('Subject').text,\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'upload_date': info.find('WriteDate').text.replace('.', ''),\n            'view_count': int(info.find('PlayCount').text),\n        }",
        "begin_line": 41,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.safari.SafariBaseIE._real_initialize#30",
        "src_path": "youtube_dl/extractor/safari.py",
        "class_name": "youtube_dl.extractor.safari.SafariBaseIE",
        "signature": "youtube_dl.extractor.safari.SafariBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        # We only need to log in once for courses or individual videos\n        if not self.LOGGED_IN:\n            self._login()\n            SafariBaseIE.LOGGED_IN = True",
        "begin_line": 30,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.safari.SafariBaseIE._login#36",
        "src_path": "youtube_dl/extractor/safari.py",
        "class_name": "youtube_dl.extractor.safari.SafariBaseIE",
        "signature": "youtube_dl.extractor.safari.SafariBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            self.raise_login_required('safaribooksonline.com account is required')\n\n        headers = std_headers\n        if 'Referer' not in headers:\n            headers['Referer'] = self._LOGIN_URL\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None,\n            'Downloading login form')\n\n        csrf = self._html_search_regex(\n            r\"name='csrfmiddlewaretoken'\\s+value='([^']+)'\",\n            login_page, 'csrf token')\n\n        login_form = {\n            'csrfmiddlewaretoken': csrf,\n            'email': username,\n            'password1': password,\n            'login': 'Sign In',\n            'next': '',\n        }\n\n        request = compat_urllib_request.Request(\n            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form), headers=headers)\n        login_page = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        if re.search(self._SUCCESSFUL_LOGIN_REGEX, login_page) is None:\n            raise ExtractorError(\n                'Login failed; make sure your credentials are correct and try again.',\n                expected=True)\n\n        self.to_screen('Login successful')",
        "begin_line": 36,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.safari.SafariIE._real_extract#106",
        "src_path": "youtube_dl/extractor/safari.py",
        "class_name": "youtube_dl.extractor.safari.SafariIE",
        "signature": "youtube_dl.extractor.safari.SafariIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_id = mobj.group('course_id')\n        part = mobj.group('part')\n\n        webpage = self._download_webpage(\n            '%s/%s/chapter-content/%s.html' % (self._API_BASE, course_id, part),\n            part)\n\n        bc_url = BrightcoveIE._extract_brightcove_url(webpage)\n        if not bc_url:\n            raise ExtractorError('Could not extract Brightcove URL from %s' % url, expected=True)\n\n        return self.url_result(smuggle_url(bc_url, {'Referer': url}), 'Brightcove')",
        "begin_line": 106,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.safari.SafariCourseIE._real_extract#141",
        "src_path": "youtube_dl/extractor/safari.py",
        "class_name": "youtube_dl.extractor.safari.SafariCourseIE",
        "signature": "youtube_dl.extractor.safari.SafariCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        course_id = self._match_id(url)\n\n        course_json = self._download_json(\n            '%s/%s/?override_format=%s' % (self._API_BASE, course_id, self._API_FORMAT),\n            course_id, 'Downloading course JSON')\n\n        if 'chapters' not in course_json:\n            raise ExtractorError(\n                'No chapters found for course %s' % course_id, expected=True)\n\n        entries = [\n            self.url_result(chapter, 'Safari')\n            for chapter in course_json['chapters']]\n\n        course_title = course_json['title']\n\n        return self.playlist_result(entries, course_id, course_title)",
        "begin_line": 141,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.movieclips.MovieClipsIE._real_extract#33",
        "src_path": "youtube_dl/extractor/movieclips.py",
        "class_name": "youtube_dl.extractor.movieclips.MovieClipsIE",
        "signature": "youtube_dl.extractor.movieclips.MovieClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n        show_id = display_id or video_id\n\n        config = self._download_xml(\n            'http://config.movieclips.com/player/config/%s' % video_id,\n            show_id, 'Downloading player config')\n\n        if config.find('./country-region').text == 'false':\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, config.find('./region_alert').text), expected=True)\n\n        properties = config.find('./video/properties')\n        smil_file = properties.attrib['smil_file']\n\n        smil = self._download_xml(smil_file, show_id, 'Downloading SMIL')\n        base_url = smil.find('./head/meta').attrib['base']\n\n        formats = []\n        for video in smil.findall('./body/switch/video'):\n            vbr = int(video.attrib['system-bitrate']) / 1000\n            src = video.attrib['src']\n            formats.append({\n                'url': base_url,\n                'play_path': src,\n                'ext': src.split(':')[0],\n                'vbr': vbr,\n                'format_id': '%dk' % vbr,\n            })\n\n        self._sort_formats(formats)\n\n        title = '%s - %s' % (properties.attrib['clip_movie_title'], properties.attrib['clip_title'])\n        description = clean_html(compat_str(properties.attrib['clip_description']))\n        thumbnail = properties.attrib['image']\n        categories = properties.attrib['clip_categories'].split(',')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 33,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.techtalks.TechTalksIE._real_extract#43",
        "src_path": "youtube_dl/extractor/techtalks.py",
        "class_name": "youtube_dl.extractor.techtalks.TechTalksIE",
        "signature": "youtube_dl.extractor.techtalks.TechTalksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        talk_id = mobj.group('id')\n        webpage = self._download_webpage(url, talk_id)\n        rtmp_url = self._search_regex(\n            r'netConnectionUrl: \\'(.*?)\\'', webpage, 'rtmp url')\n        play_path = self._search_regex(\n            r'href=\\'(.*?)\\' [^>]*id=\"flowplayer_presenter\"',\n            webpage, 'presenter play path')\n        title = clean_html(get_element_by_attribute('class', 'title', webpage))\n        video_info = {\n            'id': talk_id,\n            'title': title,\n            'url': rtmp_url,\n            'play_path': play_path,\n            'ext': 'flv',\n        }\n        m_slides = re.search(r'<a class=\"slides\" href=\\'(.*?)\\'', webpage)\n        if m_slides is None:\n            return video_info\n        else:\n            return {\n                '_type': 'playlist',\n                'id': talk_id,\n                'title': title,\n                'entries': [\n                    video_info,\n                    # The slides video\n                    {\n                        'id': talk_id + '-slides',\n                        'title': title,\n                        'url': rtmp_url,\n                        'play_path': m_slides.group(1),\n                        'ext': 'flv',\n                    },\n                ],\n            }",
        "begin_line": 43,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pyvideo.PyvideoIE._real_extract#38",
        "src_path": "youtube_dl/extractor/pyvideo.py",
        "class_name": "youtube_dl.extractor.pyvideo.PyvideoIE",
        "signature": "youtube_dl.extractor.pyvideo.PyvideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        m_youtube = re.search(r'(https?://www\\.youtube\\.com/watch\\?v=.*)', webpage)\n        if m_youtube is not None:\n            return self.url_result(m_youtube.group(1), 'Youtube')\n\n        title = self._html_search_regex(\n            r'<div class=\"section\">\\s*<h3(?:\\s+class=\"[^\"]*\"[^>]*)?>([^>]+?)</h3>',\n            webpage, 'title', flags=re.DOTALL)\n        video_url = self._search_regex(\n            [r'<source src=\"(.*?)\"', r'<dt>Download</dt>.*?<a href=\"(.+?)\"'],\n            webpage, 'video url', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'title': os.path.splitext(title)[0],\n            'url': video_url,\n        }",
        "begin_line": 38,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.franceinter.FranceInterIE._real_extract#25",
        "src_path": "youtube_dl/extractor/franceinter.py",
        "class_name": "youtube_dl.extractor.franceinter.FranceInterIE",
        "signature": "youtube_dl.extractor.franceinter.FranceInterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        path = self._search_regex(\n            r'<a id=\"player\".+?href=\"([^\"]+)\"', webpage, 'video url')\n        video_url = 'http://www.franceinter.fr/' + path\n\n        title = self._html_search_regex(\n            r'<span class=\"title\">(.+?)</span>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<span class=\"description\">(.*?)</span>',\n            webpage, 'description', fatal=False)\n        timestamp = int_or_none(self._search_regex(\n            r'data-date=\"(\\d+)\"', webpage, 'upload date', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'formats': [{\n                'url': video_url,\n                'vcodec': 'none',\n            }],\n        }",
        "begin_line": 25,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.oktoberfesttv.OktoberfestTVIE._real_extract#24",
        "src_path": "youtube_dl/extractor/oktoberfesttv.py",
        "class_name": "youtube_dl.extractor.oktoberfesttv.OktoberfestTVIE",
        "signature": "youtube_dl.extractor.oktoberfesttv.OktoberfestTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._live_title(self._html_search_regex(\n            r'<h1><strong>.*?</strong>(.*?)</h1>', webpage, 'title'))\n\n        clip = self._search_regex(\n            r\"clip:\\s*\\{\\s*url:\\s*'([^']+)'\", webpage, 'clip')\n        ncurl = self._search_regex(\n            r\"netConnectionUrl:\\s*'([^']+)'\", webpage, 'rtmp base')\n        video_url = ncurl + clip\n        thumbnail = self._search_regex(\n            r\"canvas:\\s*\\{\\s*backgroundImage:\\s*'url\\(([^)]+)\\)'\", webpage,\n            'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'ext': 'mp4',\n            'is_live': True,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 24,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xbef.XBefIE._real_extract#21",
        "src_path": "youtube_dl/extractor/xbef.py",
        "class_name": "youtube_dl.extractor.xbef.XBefIE",
        "signature": "youtube_dl.extractor.xbef.XBefIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h1[^>]*>(.*?)</h1>', webpage, 'title')\n\n        config_url_enc = self._download_webpage(\n            'http://xbef.com/Main/GetVideoURLEncoded/%s' % video_id, video_id,\n            note='Retrieving config URL')\n        config_url = compat_urllib_parse_unquote(config_url_enc)\n        config = self._download_xml(\n            config_url, video_id, note='Retrieving config')\n\n        video_url = config.find('./file').text\n        thumbnail = config.find('./image').text\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 21,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.webofstories.WebOfStoriesIE._real_extract#42",
        "src_path": "youtube_dl/extractor/webofstories.py",
        "class_name": "youtube_dl.extractor.webofstories.WebOfStoriesIE",
        "signature": "youtube_dl.extractor.webofstories.WebOfStoriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage)\n        description = self._html_search_meta('description', webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        embed_params = [s.strip(\" \\r\\n\\t'\") for s in self._search_regex(\n            r'(?s)\\$\\(\"#embedCode\"\\).html\\(getEmbedCode\\((.*?)\\)',\n            webpage, 'embed params').split(',')]\n\n        (\n            _, speaker_id, story_id, story_duration,\n            speaker_type, great_life, _thumbnail, _has_subtitles,\n            story_filename, _story_order) = embed_params\n\n        is_great_life_series = great_life == 'true'\n        duration = int_or_none(story_duration)\n\n        # URL building, see: http://www.webofstories.com/scripts/player.js\n        ms_prefix = ''\n        if speaker_type.lower() == 'ms':\n            ms_prefix = 'mini_sites/'\n\n        if is_great_life_series:\n            mp4_url = '{0:}lives/{1:}/{2:}.mp4'.format(\n                self._VIDEO_DOMAIN, speaker_id, story_filename)\n            rtmp_ext = 'flv'\n            streamer = self._GREAT_LIFE_STREAMER\n            play_path = 'stories/{0:}/{1:}'.format(\n                speaker_id, story_filename)\n        else:\n            mp4_url = '{0:}{1:}{2:}/{3:}.mp4'.format(\n                self._VIDEO_DOMAIN, ms_prefix, speaker_id, story_filename)\n            rtmp_ext = 'mp4'\n            streamer = self._USER_STREAMER\n            play_path = 'mp4:{0:}{1:}/{2}.mp4'.format(\n                ms_prefix, speaker_id, story_filename)\n\n        formats = [{\n            'format_id': 'mp4_sd',\n            'url': mp4_url,\n        }, {\n            'format_id': 'rtmp_sd',\n            'page_url': url,\n            'url': streamer,\n            'ext': rtmp_ext,\n            'play_path': play_path,\n        }]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': story_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n        }",
        "begin_line": 42,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.webofstories.WebOfStoriesPlaylistIE._real_extract#116",
        "src_path": "youtube_dl/extractor/webofstories.py",
        "class_name": "youtube_dl.extractor.webofstories.WebOfStoriesPlaylistIE",
        "signature": "youtube_dl.extractor.webofstories.WebOfStoriesPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = [\n            self.url_result('http://www.webofstories.com/play/%s' % video_number, 'WebOfStories')\n            for video_number in set(re.findall('href=\"/playAll/%s\\?sId=(\\d+)\"' % playlist_id, webpage))\n        ]\n\n        title = self._search_regex(\n            r'<div id=\"speakerName\">\\s*<span>([^<]+)</span>',\n            webpage, 'speaker', default=None)\n        if title:\n            field = self._search_regex(\n                r'<span id=\"primaryField\">([^<]+)</span>',\n                webpage, 'field', default=None)\n            if field:\n                title += ' (%s)' % field\n\n        if not title:\n            title = self._search_regex(\n                r'<title>Play\\s+all\\s+stories\\s*-\\s*([^<]+)\\s*-\\s*Web\\s+of\\s+Stories</title>',\n                webpage, 'title')\n\n        return self.playlist_result(entries, playlist_id, title)",
        "begin_line": 116,
        "end_line": 141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.chaturbate.ChaturbateIE._real_extract#26",
        "src_path": "youtube_dl/extractor/chaturbate.py",
        "class_name": "youtube_dl.extractor.chaturbate.ChaturbateIE",
        "signature": "youtube_dl.extractor.chaturbate.ChaturbateIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        m3u8_url = self._search_regex(\n            r'src=([\"\\'])(?P<url>http.+?\\.m3u8.*?)\\1', webpage,\n            'playlist', default=None, group='url')\n\n        if not m3u8_url:\n            error = self._search_regex(\n                r'<span[^>]+class=([\"\\'])desc_span\\1[^>]*>(?P<error>[^<]+)</span>',\n                webpage, 'error', group='error')\n            raise ExtractorError(error, expected=True)\n\n        formats = self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4')\n\n        return {\n            'id': video_id,\n            'title': self._live_title(video_id),\n            'thumbnail': 'https://cdn-s.highwebmedia.com/uHK3McUtGCG3SMFcd4ZJsRv8/roomimage/%s.jpg' % video_id,\n            'age_limit': self._rta_search(webpage),\n            'is_live': True,\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.__init__.get_postprocessor#20",
        "src_path": "youtube_dl/postprocessor/__init__.py",
        "class_name": "youtube_dl.postprocessor.__init__",
        "signature": "youtube_dl.postprocessor.__init__.get_postprocessor(key)",
        "snippet": "def get_postprocessor(key):\n    return globals()[key + 'PP']",
        "begin_line": 20,
        "end_line": 21,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.laola1tv.Laola1TvIE._real_extract#30",
        "src_path": "youtube_dl/extractor/laola1tv.py",
        "class_name": "youtube_dl.extractor.laola1tv.Laola1TvIE",
        "signature": "youtube_dl.extractor.laola1tv.Laola1TvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        lang = mobj.group('lang')\n        portal = mobj.group('portal')\n\n        webpage = self._download_webpage(url, video_id)\n        iframe_url = self._search_regex(\n            r'<iframe[^>]*?class=\"main_tv_player\"[^>]*?src=\"([^\"]+)\"',\n            webpage, 'iframe URL')\n\n        iframe = self._download_webpage(\n            iframe_url, video_id, note='Downloading iframe')\n        flashvars_m = re.findall(\n            r'flashvars\\.([_a-zA-Z0-9]+)\\s*=\\s*\"([^\"]*)\";', iframe)\n        flashvars = dict((m[0], m[1]) for m in flashvars_m)\n\n        partner_id = self._search_regex(\n            r'partnerid\\s*:\\s*\"([^\"]+)\"', iframe, 'partner id')\n\n        xml_url = ('http://www.laola1.tv/server/hd_video.php?' +\n                   'play=%s&partner=%s&portal=%s&v5ident=&lang=%s' % (\n                       video_id, partner_id, portal, lang))\n        hd_doc = self._download_xml(xml_url, video_id)\n\n        title = xpath_text(hd_doc, './/video/title', fatal=True)\n        flash_url = xpath_text(hd_doc, './/video/url', fatal=True)\n        uploader = xpath_text(hd_doc, './/video/meta_organistation')\n        is_live = xpath_text(hd_doc, './/video/islive') == 'true'\n\n        categories = xpath_text(hd_doc, './/video/meta_sports')\n        if categories:\n            categories = categories.split(',')\n\n        ident = random.randint(10000000, 99999999)\n        token_url = '%s&ident=%s&klub=0&unikey=0&timestamp=%s&auth=%s' % (\n            flash_url, ident, flashvars['timestamp'], flashvars['auth'])\n\n        token_doc = self._download_xml(\n            token_url, video_id, note='Downloading token')\n        token_attrib = token_doc.find('.//token').attrib\n        if token_attrib.get('auth') in ('blocked', 'restricted'):\n            raise ExtractorError(\n                'Token error: %s' % token_attrib.get('comment'), expected=True)\n\n        video_url = '%s?hdnea=%s&hdcore=3.2.0' % (\n            token_attrib['url'], token_attrib['auth'])\n\n        return {\n            'id': video_id,\n            'is_live': is_live,\n            'title': title,\n            'url': video_url,\n            'uploader': uploader,\n            'categories': categories,\n            'ext': 'mp4',\n        }",
        "begin_line": 30,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.lecture2go.Lecture2GoIE._real_extract#28",
        "src_path": "youtube_dl/extractor/lecture2go.py",
        "class_name": "youtube_dl.extractor.lecture2go.Lecture2GoIE",
        "signature": "youtube_dl.extractor.lecture2go.Lecture2GoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(r'<em[^>]+class=\"title\">(.+)</em>', webpage, 'title')\n\n        formats = []\n        for url in set(re.findall(r'\"src\",\"([^\"]+)\"', webpage)):\n            ext = determine_ext(url)\n            if ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(url, video_id))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(url, video_id))\n            else:\n                formats.append({\n                    'url': url,\n                })\n\n        self._sort_formats(formats)\n\n        creator = self._html_search_regex(\n            r'<div[^>]+id=\"description\">([^<]+)</div>', webpage, 'creator', fatal=False)\n        duration = parse_duration(self._html_search_regex(\n            r'Duration:\\s*</em>\\s*<em[^>]*>([^<]+)</em>', webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'Views:\\s*</em>\\s*<em[^>]+>(\\d+)</em>', webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'creator': creator,\n            'duration': duration,\n            'view_count': view_count,\n        }",
        "begin_line": 28,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tenplay.TenPlayIE._real_extract#35",
        "src_path": "youtube_dl/extractor/tenplay.py",
        "class_name": "youtube_dl.extractor.tenplay.TenPlayIE",
        "signature": "youtube_dl.extractor.tenplay.TenPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, url)\n        video_id = self._html_search_regex(\n            r'videoID: \"(\\d+?)\"', webpage, 'video_id')\n        api_token = self._html_search_regex(\n            r'apiToken: \"([a-zA-Z0-9-_\\.]+?)\"', webpage, 'api_token')\n        title = self._html_search_regex(\n            r'<meta property=\"og:title\" content=\"\\s*(.*?)\\s*\"\\s*/?\\s*>',\n            webpage, 'title')\n\n        json = self._download_json('https://api.brightcove.com/services/library?command=find_video_by_id&video_id=%s&token=%s&video_fields=%s' % (video_id, api_token, ','.join(self._video_fields)), title)\n\n        formats = []\n        for rendition in json['renditions']:\n            url = rendition['remoteUrl'] or rendition['url']\n            protocol = 'rtmp' if url.startswith('rtmp') else 'http'\n            ext = 'flv' if protocol == 'rtmp' else rendition['videoContainer'].lower()\n\n            if protocol == 'rtmp':\n                url = url.replace('&mp4:', '')\n\n                tbr = int_or_none(rendition.get('encodingRate'), 1000)\n\n            formats.append({\n                'format_id': '_'.join(\n                    ['rtmp', rendition['videoContainer'].lower(),\n                     rendition['videoCodec'].lower(), '%sk' % tbr]),\n                'width': int_or_none(rendition['frameWidth']),\n                'height': int_or_none(rendition['frameHeight']),\n                'tbr': tbr,\n                'filesize': int_or_none(rendition['size']),\n                'protocol': protocol,\n                'ext': ext,\n                'vcodec': rendition['videoCodec'].lower(),\n                'container': rendition['videoContainer'].lower(),\n                'url': url,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': json['referenceId'],\n            'title': json['name'],\n            'description': json['shortDescription'] or json['longDescription'],\n            'formats': formats,\n            'thumbnails': [{\n                'url': json['videoStillURL']\n            }, {\n                'url': json['thumbnailURL']\n            }],\n            'thumbnail': json['videoStillURL'],\n            'duration': float_or_none(json.get('length'), 1000),\n            'timestamp': float_or_none(json.get('creationDate'), 1000),\n            'uploader': json.get('customFields', {}).get('production_company_distributor') or 'TENplay',\n            'view_count': int_or_none(json.get('playsTotal')),\n        }",
        "begin_line": 35,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD.real_download#18",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n\n        retval = self._call_downloader(tmpfilename, info_dict)\n        if retval == 0:\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('\\r[%s] Downloaded %s bytes' % (self.get_basename(), fsize))\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr('\\n')\n            self.report_error('%s exited with code %d' % (\n                self.get_basename(), retval))\n            return False",
        "begin_line": 18,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD.get_basename#41",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD.get_basename(cls)",
        "snippet": "    def get_basename(cls):\n        return cls.__name__[:-2].lower()",
        "begin_line": 41,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD.exe#45",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD.exe(self)",
        "snippet": "    def exe(self):\n        return self.params.get('external_downloader')",
        "begin_line": 45,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD.supports#49",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD.supports(cls, info_dict)",
        "snippet": "    def supports(cls, info_dict):\n        return info_dict['protocol'] in ('http', 'https', 'ftp', 'ftps')",
        "begin_line": 49,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD._option#52",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD._option(self, command_option, param)",
        "snippet": "    def _option(self, command_option, param):\n        return cli_option(self.params, command_option, param)",
        "begin_line": 52,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD._bool_option#55",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD._bool_option(self, command_option, param, true_value='true', false_value='false', separator=None)",
        "snippet": "    def _bool_option(self, command_option, param, true_value='true', false_value='false', separator=None):\n        return cli_bool_option(self.params, command_option, param, true_value, false_value, separator)",
        "begin_line": 55,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD._valueless_option#58",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD._valueless_option(self, command_option, param, expected_value=True)",
        "snippet": "    def _valueless_option(self, command_option, param, expected_value=True):\n        return cli_valueless_option(self.params, command_option, param, expected_value)",
        "begin_line": 58,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD._configuration_args#61",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD._configuration_args(self, default=[])",
        "snippet": "    def _configuration_args(self, default=[]):\n        return cli_configuration_args(self.params, 'external_downloader_args', default)",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD._call_downloader#64",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD._call_downloader(self, tmpfilename, info_dict)",
        "snippet": "    def _call_downloader(self, tmpfilename, info_dict):\n        \"\"\" Either overwrite this or implement _make_cmd \"\"\"\n        cmd = [encodeArgument(a) for a in self._make_cmd(tmpfilename, info_dict)]\n\n        self._debug_cmd(cmd)\n\n        p = subprocess.Popen(\n            cmd, stderr=subprocess.PIPE)\n        _, stderr = p.communicate()\n        if p.returncode != 0:\n            self.to_stderr(stderr)\n        return p.returncode",
        "begin_line": 64,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.CurlFD._make_cmd#79",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.CurlFD",
        "signature": "youtube_dl.downloader.external.CurlFD._make_cmd(self, tmpfilename, info_dict)",
        "snippet": "    def _make_cmd(self, tmpfilename, info_dict):\n        cmd = [self.exe, '--location', '-o', tmpfilename]\n        for key, val in info_dict['http_headers'].items():\n            cmd += ['--header', '%s: %s' % (key, val)]\n        cmd += self._option('--interface', 'source_address')\n        cmd += self._option('--proxy', 'proxy')\n        cmd += self._valueless_option('--insecure', 'nocheckcertificate')\n        cmd += self._configuration_args()\n        cmd += ['--', info_dict['url']]\n        return cmd",
        "begin_line": 79,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.AxelFD._make_cmd#92",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.AxelFD",
        "signature": "youtube_dl.downloader.external.AxelFD._make_cmd(self, tmpfilename, info_dict)",
        "snippet": "    def _make_cmd(self, tmpfilename, info_dict):\n        cmd = [self.exe, '-o', tmpfilename]\n        for key, val in info_dict['http_headers'].items():\n            cmd += ['-H', '%s: %s' % (key, val)]\n        cmd += self._configuration_args()\n        cmd += ['--', info_dict['url']]\n        return cmd",
        "begin_line": 92,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.WgetFD._make_cmd#102",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.WgetFD",
        "signature": "youtube_dl.downloader.external.WgetFD._make_cmd(self, tmpfilename, info_dict)",
        "snippet": "    def _make_cmd(self, tmpfilename, info_dict):\n        cmd = [self.exe, '-O', tmpfilename, '-nv', '--no-cookies']\n        for key, val in info_dict['http_headers'].items():\n            cmd += ['--header', '%s: %s' % (key, val)]\n        cmd += self._option('--bind-address', 'source_address')\n        cmd += self._option('--proxy', 'proxy')\n        cmd += self._valueless_option('--no-check-certificate', 'nocheckcertificate')\n        cmd += self._configuration_args()\n        cmd += ['--', info_dict['url']]\n        return cmd",
        "begin_line": 102,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.Aria2cFD._make_cmd#115",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.Aria2cFD",
        "signature": "youtube_dl.downloader.external.Aria2cFD._make_cmd(self, tmpfilename, info_dict)",
        "snippet": "    def _make_cmd(self, tmpfilename, info_dict):\n        cmd = [self.exe, '-c']\n        cmd += self._configuration_args([\n            '--min-split-size', '1M', '--max-connection-per-server', '4'])\n        dn = os.path.dirname(tmpfilename)\n        if dn:\n            cmd += ['--dir', dn]\n        cmd += ['--out', os.path.basename(tmpfilename)]\n        for key, val in info_dict['http_headers'].items():\n            cmd += ['--header', '%s: %s' % (key, val)]\n        cmd += self._option('--interface', 'source_address')\n        cmd += self._option('--all-proxy', 'proxy')\n        cmd += self._bool_option('--check-certificate', 'nocheckcertificate', 'false', 'true', '=')\n        cmd += ['--', info_dict['url']]\n        return cmd",
        "begin_line": 115,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.HttpieFD._make_cmd#133",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.HttpieFD",
        "signature": "youtube_dl.downloader.external.HttpieFD._make_cmd(self, tmpfilename, info_dict)",
        "snippet": "    def _make_cmd(self, tmpfilename, info_dict):\n        cmd = ['http', '--download', '--output', tmpfilename, info_dict['url']]\n        for key, val in info_dict['http_headers'].items():\n            cmd += ['%s:%s' % (key, val)]\n        return cmd",
        "begin_line": 133,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.list_external_downloaders#146",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external",
        "signature": "youtube_dl.downloader.external.list_external_downloaders()",
        "snippet": "def list_external_downloaders():\n    return sorted(_BY_NAME.keys())",
        "begin_line": 146,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.external.get_external_downloader#150",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external",
        "signature": "youtube_dl.downloader.external.get_external_downloader(external_downloader)",
        "snippet": "def get_external_downloader(external_downloader):\n    \"\"\" Given the name of the executable, see whether we support the given\n        downloader . \"\"\"\n    # Drop .exe extension on Windows\n    bn = os.path.splitext(os.path.basename(external_downloader))[0]\n    return _BY_NAME[bn]",
        "begin_line": 150,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE._real_extract#52",
        "src_path": "youtube_dl/extractor/chilloutzone.py",
        "class_name": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE",
        "signature": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        base64_video_info = self._html_search_regex(\n            r'var cozVidData = \"(.+?)\";', webpage, 'video data')\n        decoded_video_info = base64.b64decode(base64_video_info.encode('utf-8')).decode('utf-8')\n        video_info_dict = json.loads(decoded_video_info)\n\n        # get video information from dict\n        video_url = video_info_dict['mediaUrl']\n        description = clean_html(video_info_dict.get('description'))\n        title = video_info_dict['title']\n        native_platform = video_info_dict['nativePlatform']\n        native_video_id = video_info_dict['nativeVideoId']\n        source_priority = video_info_dict['sourcePriority']\n\n        # If nativePlatform is None a fallback mechanism is used (i.e. youtube embed)\n        if native_platform is None:\n            youtube_url = self._html_search_regex(\n                r'<iframe.* src=\"((?:https?:)?//(?:[^.]+\\.)?youtube\\.com/.+?)\"',\n                webpage, 'fallback video URL', default=None)\n            if youtube_url is not None:\n                return self.url_result(youtube_url, ie='Youtube')\n\n        # Non Fallback: Decide to use native source (e.g. youtube or vimeo) or\n        # the own CDN\n        if source_priority == 'native':\n            if native_platform == 'youtube':\n                return self.url_result(native_video_id, ie='Youtube')\n            if native_platform == 'vimeo':\n                return self.url_result(\n                    'http://vimeo.com/' + native_video_id, ie='Vimeo')\n\n        if not video_url:\n            raise ExtractorError('No video found')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 52,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dump.DumpIE._real_extract#23",
        "src_path": "youtube_dl/extractor/dump.py",
        "class_name": "youtube_dl.extractor.dump.DumpIE",
        "signature": "youtube_dl.extractor.dump.DumpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(\n            r's1.addVariable\\(\"file\",\\s*\"([^\"]+)\"', webpage, 'video URL')\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 23,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mgoon.MgoonIE._real_extract#43",
        "src_path": "youtube_dl/extractor/mgoon.py",
        "class_name": "youtube_dl.extractor.mgoon.MgoonIE",
        "signature": "youtube_dl.extractor.mgoon.MgoonIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        data = self._download_json(self._API_URL.format(video_id), video_id)\n\n        if data.get('errorInfo', {}).get('code') != 'NONE':\n            raise ExtractorError('%s encountered an error: %s' % (\n                self.IE_NAME, data['errorInfo']['message']), expected=True)\n\n        v_info = data['videoInfo']\n        title = v_info.get('v_title')\n        thumbnail = v_info.get('v_thumbnail')\n        duration = v_info.get('v_duration')\n        upload_date = unified_strdate(v_info.get('v_reg_date'))\n        uploader_id = data.get('userInfo', {}).get('u_alias')\n        if duration:\n            duration /= 1000.0\n\n        age_limit = None\n        if data.get('accessInfo', {}).get('code') == 'VIDEO_STATUS_ADULT':\n            age_limit = 18\n\n        formats = []\n        get_quality = qualities(['360p', '480p', '720p', '1080p'])\n        for fmt in data['videoFiles']:\n            formats.append({\n                'format_id': fmt['label'],\n                'quality': get_quality(fmt['label']),\n                'url': fmt['url'],\n                'ext': fmt['format'],\n\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'age_limit': age_limit,\n        }",
        "begin_line": 43,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ard.ARDMediathekIE._extract_media_info#64",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDMediathekIE",
        "signature": "youtube_dl.extractor.ard.ARDMediathekIE._extract_media_info(self, media_info_url, webpage, video_id)",
        "snippet": "    def _extract_media_info(self, media_info_url, webpage, video_id):\n        media_info = self._download_json(\n            media_info_url, video_id, 'Downloading media JSON')\n\n        formats = self._extract_formats(media_info, video_id)\n\n        if not formats:\n            if '\"fsk\"' in webpage:\n                raise ExtractorError(\n                    'This video is only available after 20:00', expected=True)\n            elif media_info.get('_geoblocked'):\n                raise ExtractorError('This video is not available due to geo restriction', expected=True)\n\n        self._sort_formats(formats)\n\n        duration = int_or_none(media_info.get('_duration'))\n        thumbnail = media_info.get('_previewImage')\n\n        subtitles = {}\n        subtitle_url = media_info.get('_subtitleUrl')\n        if subtitle_url:\n            subtitles['de'] = [{\n                'ext': 'srt',\n                'url': subtitle_url,\n            }]\n\n        return {\n            'id': video_id,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 64,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ard.ARDMediathekIE._extract_formats#98",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDMediathekIE",
        "signature": "youtube_dl.extractor.ard.ARDMediathekIE._extract_formats(self, media_info, video_id)",
        "snippet": "    def _extract_formats(self, media_info, video_id):\n        type_ = media_info.get('_type')\n        media_array = media_info.get('_mediaArray', [])\n        formats = []\n        for num, media in enumerate(media_array):\n            for stream in media.get('_mediaStreamArray', []):\n                stream_urls = stream.get('_stream')\n                if not stream_urls:\n                    continue\n                if not isinstance(stream_urls, list):\n                    stream_urls = [stream_urls]\n                quality = stream.get('_quality')\n                server = stream.get('_server')\n                for stream_url in stream_urls:\n                    ext = determine_ext(stream_url)\n                    if ext == 'f4m':\n                        formats.extend(self._extract_f4m_formats(\n                            stream_url + '?hdcore=3.1.1&plugin=aasp-3.1.1.69.124',\n                            video_id, preference=-1, f4m_id='hds'))\n                    elif ext == 'm3u8':\n                        formats.extend(self._extract_m3u8_formats(\n                            stream_url, video_id, 'mp4', preference=1, m3u8_id='hls'))\n                    else:\n                        if server and server.startswith('rtmp'):\n                            f = {\n                                'url': server,\n                                'play_path': stream_url,\n                                'format_id': 'a%s-rtmp-%s' % (num, quality),\n                            }\n                        elif stream_url.startswith('http'):\n                            f = {\n                                'url': stream_url,\n                                'format_id': 'a%s-%s-%s' % (num, ext, quality)\n                            }\n                        else:\n                            continue\n                        m = re.search(r'_(?P<width>\\d+)x(?P<height>\\d+)\\.mp4$', stream_url)\n                        if m:\n                            f.update({\n                                'width': int(m.group('width')),\n                                'height': int(m.group('height')),\n                            })\n                        if type_ == 'audio':\n                            f['vcodec'] = 'none'\n                        formats.append(f)\n        return formats",
        "begin_line": 98,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ard.ARDMediathekIE._real_extract#145",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDMediathekIE",
        "signature": "youtube_dl.extractor.ard.ARDMediathekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # determine video id from url\n        m = re.match(self._VALID_URL, url)\n\n        numid = re.search(r'documentId=([0-9]+)', url)\n        if numid:\n            video_id = numid.group(1)\n        else:\n            video_id = m.group('video_id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        if '>Der gew\u00fcnschte Beitrag ist nicht mehr verf\u00fcgbar.<' in webpage:\n            raise ExtractorError('Video %s is no longer available' % video_id, expected=True)\n\n        if 'Diese Sendung ist f\u00fcr Jugendliche unter 12 Jahren nicht geeignet. Der Clip ist deshalb nur von 20 bis 6 Uhr verf\u00fcgbar.' in webpage:\n            raise ExtractorError('This program is only suitable for those aged 12 and older. Video %s is therefore only available between 20 pm and 6 am.' % video_id, expected=True)\n\n        if re.search(r'[\\?&]rss($|[=&])', url):\n            doc = compat_etree_fromstring(webpage.encode('utf-8'))\n            if doc.tag == 'rss':\n                return GenericIE()._extract_rss(url, video_id, doc)\n\n        title = self._html_search_regex(\n            [r'<h1(?:\\s+class=\"boxTopHeadline\")?>(.*?)</h1>',\n             r'<meta name=\"dcterms.title\" content=\"(.*?)\"/>',\n             r'<h4 class=\"headline\">(.*?)</h4>'],\n            webpage, 'title')\n        description = self._html_search_meta(\n            'dcterms.abstract', webpage, 'description', default=None)\n        if description is None:\n            description = self._html_search_meta(\n                'description', webpage, 'meta description')\n\n        # Thumbnail is sometimes not present.\n        # It is in the mobile version, but that seems to use a different URL\n        # structure altogether.\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n\n        media_streams = re.findall(r'''(?x)\n            mediaCollection\\.addMediaStream\\([0-9]+,\\s*[0-9]+,\\s*\"[^\"]*\",\\s*\n            \"([^\"]+)\"''', webpage)\n\n        if media_streams:\n            QUALITIES = qualities(['lo', 'hi', 'hq'])\n            formats = []\n            for furl in set(media_streams):\n                if furl.endswith('.f4m'):\n                    fid = 'f4m'\n                else:\n                    fid_m = re.match(r'.*\\.([^.]+)\\.[^.]+$', furl)\n                    fid = fid_m.group(1) if fid_m else None\n                formats.append({\n                    'quality': QUALITIES(fid),\n                    'format_id': fid,\n                    'url': furl,\n                })\n            self._sort_formats(formats)\n            info = {\n                'formats': formats,\n            }\n        else:  # request JSON file\n            info = self._extract_media_info(\n                'http://www.ardmediathek.de/play/media/%s' % video_id, webpage, video_id)\n\n        info.update({\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        })\n\n        return info",
        "begin_line": 145,
        "end_line": 217,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ard.ARDIE._real_extract#236",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDIE",
        "signature": "youtube_dl.extractor.ard.ARDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n\n        player_url = mobj.group('mainurl') + '~playerXml.xml'\n        doc = self._download_xml(player_url, display_id)\n        video_node = doc.find('./video')\n        upload_date = unified_strdate(xpath_text(\n            video_node, './broadcastDate'))\n        thumbnail = xpath_text(video_node, './/teaserImage//variant/url')\n\n        formats = []\n        for a in video_node.findall('.//asset'):\n            f = {\n                'format_id': a.attrib['type'],\n                'width': int_or_none(a.find('./frameWidth').text),\n                'height': int_or_none(a.find('./frameHeight').text),\n                'vbr': int_or_none(a.find('./bitrateVideo').text),\n                'abr': int_or_none(a.find('./bitrateAudio').text),\n                'vcodec': a.find('./codecVideo').text,\n                'tbr': int_or_none(a.find('./totalBitrate').text),\n            }\n            if a.find('./serverPrefix').text:\n                f['url'] = a.find('./serverPrefix').text\n                f['playpath'] = a.find('./fileName').text\n            else:\n                f['url'] = a.find('./fileName').text\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': mobj.group('id'),\n            'formats': formats,\n            'display_id': display_id,\n            'title': video_node.find('./title').text,\n            'duration': parse_duration(video_node.find('./duration').text),\n            'upload_date': upload_date,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 236,
        "end_line": 274,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ard.SportschauIE._real_extract#295",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.SportschauIE",
        "signature": "youtube_dl.extractor.ard.SportschauIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        base_url = mobj.group('baseurl')\n\n        webpage = self._download_webpage(url, video_id)\n        title = get_element_by_attribute('class', 'headline', webpage)\n        description = self._html_search_meta('description', webpage, 'description')\n\n        info = self._extract_media_info(\n            base_url + '-mc_defaultQuality-h.json', webpage, video_id)\n\n        info.update({\n            'title': title,\n            'description': description,\n        })\n\n        return info",
        "begin_line": 295,
        "end_line": 312,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xstream.XstreamIE._real_extract#45",
        "src_path": "youtube_dl/extractor/xstream.py",
        "class_name": "youtube_dl.extractor.xstream.XstreamIE",
        "signature": "youtube_dl.extractor.xstream.XstreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        partner_id = mobj.group('partner_id')\n        video_id = mobj.group('id')\n\n        data = self._download_xml(\n            'http://frontend.xstream.dk/%s/feed/video/?platform=web&id=%s'\n            % (partner_id, video_id),\n            video_id)\n\n        NS_MAP = {\n            'atom': 'http://www.w3.org/2005/Atom',\n            'xt': 'http://xstream.dk/',\n            'media': 'http://search.yahoo.com/mrss/',\n        }\n\n        entry = data.find(xpath_with_ns('./atom:entry', NS_MAP))\n\n        title = xpath_text(\n            entry, xpath_with_ns('./atom:title', NS_MAP), 'title')\n        description = xpath_text(\n            entry, xpath_with_ns('./atom:summary', NS_MAP), 'description')\n        timestamp = parse_iso8601(xpath_text(\n            entry, xpath_with_ns('./atom:published', NS_MAP), 'upload date'))\n\n        formats = []\n        media_group = entry.find(xpath_with_ns('./media:group', NS_MAP))\n        for media_content in media_group.findall(xpath_with_ns('./media:content', NS_MAP)):\n            media_url = media_content.get('url')\n            if not media_url:\n                continue\n            tbr = int_or_none(media_content.get('bitrate'))\n            mobj = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', media_url)\n            if mobj:\n                formats.append({\n                    'url': mobj.group('url'),\n                    'play_path': 'mp4:%s' % mobj.group('playpath'),\n                    'app': mobj.group('app'),\n                    'ext': 'flv',\n                    'tbr': tbr,\n                    'format_id': 'rtmp-%d' % tbr,\n                })\n            else:\n                formats.append({\n                    'url': media_url,\n                    'tbr': tbr,\n                })\n        self._sort_formats(formats)\n\n        link = find_xpath_attr(\n            entry, xpath_with_ns('./atom:link', NS_MAP), 'rel', 'original')\n        if link is not None:\n            formats.append({\n                'url': link.get('href'),\n                'format_id': link.get('rel'),\n            })\n\n        thumbnails = [{\n            'url': splash.get('url'),\n            'width': int_or_none(splash.get('width')),\n            'height': int_or_none(splash.get('height')),\n        } for splash in media_group.findall(xpath_with_ns('./xt:splash', NS_MAP))]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 45,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._extract_clip#215",
        "src_path": "youtube_dl/extractor/prosiebensat1.py",
        "class_name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE",
        "signature": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._extract_clip(self, url, webpage)",
        "snippet": "    def _extract_clip(self, url, webpage):\n        clip_id = self._html_search_regex(self._CLIPID_REGEXES, webpage, 'clip id')\n\n        access_token = 'prosieben'\n        client_name = 'kolibri-2.0.19-splec4'\n        client_location = url\n\n        videos_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos?%s' % compat_urllib_parse.urlencode({\n            'access_token': access_token,\n            'client_location': client_location,\n            'client_name': client_name,\n            'ids': clip_id,\n        })\n\n        video = self._download_json(videos_api_url, clip_id, 'Downloading videos JSON')[0]\n\n        if video.get('is_protected') is True:\n            raise ExtractorError('This video is DRM protected.', expected=True)\n\n        duration = float_or_none(video.get('duration'))\n        source_ids = [source['id'] for source in video['sources']]\n        source_ids_str = ','.join(map(str, source_ids))\n\n        g = '01!8d8F_)r9]4s[qeuXfP%'\n\n        client_id = g[:2] + sha1(''.join([clip_id, g, access_token, client_location, g, client_name])\n                                 .encode('utf-8')).hexdigest()\n\n        sources_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources?%s' % (clip_id, compat_urllib_parse.urlencode({\n            'access_token': access_token,\n            'client_id': client_id,\n            'client_location': client_location,\n            'client_name': client_name,\n        }))\n\n        sources = self._download_json(sources_api_url, clip_id, 'Downloading sources JSON')\n        server_id = sources['server_id']\n\n        client_id = g[:2] + sha1(''.join([g, clip_id, access_token, server_id,\n                                          client_location, source_ids_str, g, client_name])\n                                 .encode('utf-8')).hexdigest()\n\n        url_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources/url?%s' % (clip_id, compat_urllib_parse.urlencode({\n            'access_token': access_token,\n            'client_id': client_id,\n            'client_location': client_location,\n            'client_name': client_name,\n            'server_id': server_id,\n            'source_ids': source_ids_str,\n        }))\n\n        urls = self._download_json(url_api_url, clip_id, 'Downloading urls JSON')\n\n        title = self._html_search_regex(self._TITLE_REGEXES, webpage, 'title')\n        description = self._html_search_regex(self._DESCRIPTION_REGEXES, webpage, 'description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        upload_date = unified_strdate(self._html_search_regex(\n            self._UPLOAD_DATE_REGEXES, webpage, 'upload date', default=None))\n\n        formats = []\n\n        urls_sources = urls['sources']\n        if isinstance(urls_sources, dict):\n            urls_sources = urls_sources.values()\n\n        def fix_bitrate(bitrate):\n            bitrate = int_or_none(bitrate)\n            if not bitrate:\n                return None\n            return (bitrate // 1000) if bitrate % 1000 == 0 else bitrate\n\n        for source in urls_sources:\n            protocol = source['protocol']\n            source_url = source['url']\n            if protocol == 'rtmp' or protocol == 'rtmpe':\n                mobj = re.search(r'^(?P<url>rtmpe?://[^/]+)/(?P<path>.+)$', source_url)\n                if not mobj:\n                    continue\n                path = mobj.group('path')\n                mp4colon_index = path.rfind('mp4:')\n                app = path[:mp4colon_index]\n                play_path = path[mp4colon_index:]\n                formats.append({\n                    'url': '%s/%s' % (mobj.group('url'), app),\n                    'app': app,\n                    'play_path': play_path,\n                    'player_url': 'http://livepassdl.conviva.com/hf/ver/2.79.0.17083/LivePassModuleMain.swf',\n                    'page_url': 'http://www.prosieben.de',\n                    'vbr': fix_bitrate(source['bitrate']),\n                    'ext': 'mp4',\n                    'format_id': '%s_%s' % (source['cdn'], source['bitrate']),\n                })\n            elif 'f4mgenerator' in source_url or determine_ext(source_url) == 'f4m':\n                formats.extend(self._extract_f4m_formats(source_url, clip_id))\n            else:\n                formats.append({\n                    'url': source_url,\n                    'vbr': fix_bitrate(source['bitrate']),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': clip_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 215,
        "end_line": 326,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._extract_playlist#328",
        "src_path": "youtube_dl/extractor/prosiebensat1.py",
        "class_name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE",
        "signature": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._extract_playlist(self, url, webpage)",
        "snippet": "    def _extract_playlist(self, url, webpage):\n        playlist_id = self._html_search_regex(\n            self._PLAYLIST_ID_REGEXES, webpage, 'playlist id')\n        for regex in self._PLAYLIST_CLIP_REGEXES:\n            playlist_clips = re.findall(regex, webpage)\n            if playlist_clips:\n                title = self._html_search_regex(\n                    self._TITLE_REGEXES, webpage, 'title')\n                description = self._html_search_regex(\n                    self._DESCRIPTION_REGEXES, webpage, 'description', fatal=False)\n                entries = [\n                    self.url_result(\n                        re.match('(.+?//.+?)/', url).group(1) + clip_path,\n                        'ProSiebenSat1')\n                    for clip_path in playlist_clips]\n                return self.playlist_result(entries, playlist_id, title, description)",
        "begin_line": 328,
        "end_line": 343,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._real_extract#345",
        "src_path": "youtube_dl/extractor/prosiebensat1.py",
        "class_name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE",
        "signature": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        page_type = self._search_regex(\n            self._PAGE_TYPE_REGEXES, webpage,\n            'page type', default='clip').lower()\n        if page_type == 'clip':\n            return self._extract_clip(url, webpage)\n        elif page_type == 'playlist':\n            return self._extract_playlist(url, webpage)",
        "begin_line": 345,
        "end_line": 354,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tvp.TvpIE._real_extract#47",
        "src_path": "youtube_dl/extractor/tvp.py",
        "class_name": "youtube_dl.extractor.tvp.TvpIE",
        "signature": "youtube_dl.extractor.tvp.TvpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.tvp.pl/sess/tvplayer.php?object_id=%s' % video_id, video_id)\n\n        title = self._search_regex(\n            r'name\\s*:\\s*([\\'\"])Title\\1\\s*,\\s*value\\s*:\\s*\\1(?P<title>.+?)\\1',\n            webpage, 'title', group='title')\n        series_title = self._search_regex(\n            r'name\\s*:\\s*([\\'\"])SeriesTitle\\1\\s*,\\s*value\\s*:\\s*\\1(?P<series>.+?)\\1',\n            webpage, 'series', group='series', default=None)\n        if series_title:\n            title = '%s, %s' % (series_title, title)\n\n        thumbnail = self._search_regex(\n            r\"poster\\s*:\\s*'([^']+)'\", webpage, 'thumbnail', default=None)\n\n        video_url = self._search_regex(\n            r'0:{src:([\\'\"])(?P<url>.*?)\\1', webpage, 'formats', group='url', default=None)\n        if not video_url:\n            video_url = self._download_json(\n                'http://www.tvp.pl/pub/stat/videofileinfo?video_id=%s' % video_id,\n                video_id)['video_url']\n\n        ext = video_url.rsplit('.', 1)[-1]\n        if ext != 'ism/manifest':\n            if '/' in ext:\n                ext = 'mp4'\n            formats = [{\n                'format_id': 'direct',\n                'url': video_url,\n                'ext': ext,\n            }]\n        else:\n            m3u8_url = re.sub('([^/]*)\\.ism/manifest', r'\\1.ism/\\1.m3u8', video_url)\n            formats = self._extract_m3u8_formats(m3u8_url, video_id, 'mp4')\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 47,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tvp.TvpSeriesIE._real_extract#115",
        "src_path": "youtube_dl/extractor/tvp.py",
        "class_name": "youtube_dl.extractor.tvp.TvpSeriesIE",
        "signature": "youtube_dl.extractor.tvp.TvpSeriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id, tries=5)\n\n        title = self._html_search_regex(\n            r'(?s) id=[\\'\"]path[\\'\"]>(?:.*? / ){2}(.*?)</span>', webpage, 'series')\n        playlist_id = self._search_regex(r'nodeId:\\s*(\\d+)', webpage, 'playlist id')\n        playlist = self._download_webpage(\n            'http://vod.tvp.pl/vod/seriesAjax?type=series&nodeId=%s&recommend'\n            'edId=0&sort=&page=0&pageSize=10000' % playlist_id, display_id, tries=5,\n            note='Downloading playlist')\n\n        videos_paths = re.findall(\n            '(?s)class=\"shortTitle\">.*?href=\"(/[^\"]+)', playlist)\n        entries = [\n            self.url_result('http://vod.tvp.pl%s' % v_path, ie=TvpIE.ie_key())\n            for v_path in videos_paths]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'display_id': display_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 115,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tunein.TuneInIE._real_extract#48",
        "src_path": "youtube_dl/extractor/tunein.py",
        "class_name": "youtube_dl.extractor.tunein.TuneInIE",
        "signature": "youtube_dl.extractor.tunein.TuneInIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        redirect_id = mobj.group('redirect_id')\n        if redirect_id:\n            # The server doesn't support HEAD requests\n            urlh = self._request_webpage(\n                url, redirect_id, note='Downloading redirect page')\n            url = urlh.geturl()\n            self.to_screen('Following redirect: %s' % url)\n            mobj = re.match(self._VALID_URL, url)\n        station_id = mobj.group('id')\n\n        station_info = self._download_json(\n            self._API_URL_TEMPLATE.format(station_id),\n            station_id, note='Downloading station JSON')\n\n        title = station_info['Title']\n        thumbnail = station_info.get('Logo')\n        location = station_info.get('Location')\n        streams_url = station_info.get('StreamUrl')\n        if not streams_url:\n            raise ExtractorError('No downloadable streams found',\n                                 expected=True)\n        stream_data = self._download_webpage(\n            streams_url, station_id, note='Downloading stream data')\n        streams = json.loads(self._search_regex(\n            r'\\((.*)\\);', stream_data, 'stream info'))['Streams']\n\n        is_live = None\n        formats = []\n        for stream in streams:\n            if stream.get('Type') == 'Live':\n                is_live = True\n            reliability = stream.get('Reliability')\n            format_note = (\n                'Reliability: %d%%' % reliability\n                if reliability is not None else None)\n            formats.append({\n                'preference': (\n                    0 if reliability is None or reliability > 90\n                    else 1),\n                'abr': stream.get('Bandwidth'),\n                'ext': stream.get('MediaType').lower(),\n                'acodec': stream.get('MediaType'),\n                'vcodec': 'none',\n                'url': stream.get('Url'),\n                'source_preference': reliability,\n                'format_note': format_note,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': station_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'location': location,\n            'is_live': is_live,\n        }",
        "begin_line": 48,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.karaoketv.KaraoketvIE._real_extract#22",
        "src_path": "youtube_dl/extractor/karaoketv.py",
        "class_name": "youtube_dl.extractor.karaoketv.KaraoketvIE",
        "signature": "youtube_dl.extractor.karaoketv.KaraoketvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        page_video_url = self._og_search_video_url(webpage, video_id)\n        config_json = compat_urllib_parse_unquote_plus(self._search_regex(\n            r'config=(.*)', page_video_url, 'configuration'))\n\n        urls_info_json = self._download_json(\n            config_json, video_id, 'Downloading configuration',\n            transform_source=js_to_json)\n\n        url = urls_info_json['playlist'][0]['url']\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'url': url,\n        }",
        "begin_line": 22,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rbmaradio.RBMARadioIE._real_extract#29",
        "src_path": "youtube_dl/extractor/rbmaradio.py",
        "class_name": "youtube_dl.extractor.rbmaradio.RBMARadioIE",
        "signature": "youtube_dl.extractor.rbmaradio.RBMARadioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('videoID')\n\n        webpage = self._download_webpage(url, video_id)\n\n        json_data = self._search_regex(r'window\\.gon.*?gon\\.show=(.+?);$',\n                                       webpage, 'json data', flags=re.MULTILINE)\n\n        try:\n            data = json.loads(json_data)\n        except ValueError as e:\n            raise ExtractorError('Invalid JSON: ' + str(e))\n\n        video_url = data['akamai_url'] + '&cbr=256'\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': data['title'],\n            'description': data.get('teaser_text'),\n            'location': data.get('country_of_origin'),\n            'uploader': data.get('host', {}).get('name'),\n            'uploader_id': data.get('host', {}).get('slug'),\n            'thumbnail': data.get('image', {}).get('large_url_2x'),\n            'duration': data.get('duration'),\n        }",
        "begin_line": 29,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.airmozilla.AirMozillaIE._real_extract#34",
        "src_path": "youtube_dl/extractor/airmozilla.py",
        "class_name": "youtube_dl.extractor.airmozilla.AirMozillaIE",
        "signature": "youtube_dl.extractor.airmozilla.AirMozillaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        video_id = self._html_search_regex(r'//vid.ly/(.*?)/embed', webpage, 'id')\n\n        embed_script = self._download_webpage('https://vid.ly/{0}/embed'.format(video_id), video_id)\n        jwconfig = self._search_regex(r'\\svar jwconfig = (\\{.*?\\});\\s', embed_script, 'metadata')\n        metadata = self._parse_json(jwconfig, video_id)\n\n        formats = [{\n            'url': source['file'],\n            'ext': source['type'],\n            'format_id': self._search_regex(r'&format=(.*)$', source['file'], 'video format'),\n            'format': source['label'],\n            'height': int(source['label'].rstrip('p')),\n        } for source in metadata['playlist'][0]['sources']]\n        self._sort_formats(formats)\n\n        view_count = int_or_none(self._html_search_regex(\n            r'Views since archived: ([0-9]+)',\n            webpage, 'view count', fatal=False))\n        timestamp = parse_iso8601(self._html_search_regex(\n            r'<time datetime=\"(.*?)\"', webpage, 'timestamp', fatal=False))\n        duration = parse_duration(self._search_regex(\n            r'Duration:\\s*(\\d+\\s*hours?\\s*\\d+\\s*minutes?)',\n            webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'url': self._og_search_url(webpage),\n            'display_id': display_id,\n            'thumbnail': metadata['playlist'][0].get('image'),\n            'description': self._og_search_description(webpage),\n            'timestamp': timestamp,\n            'location': self._html_search_regex(r'Location: (.*)', webpage, 'location', default=None),\n            'duration': duration,\n            'view_count': view_count,\n            'categories': re.findall(r'<a href=\".*?\" class=\"channel\">(.*?)</a>', webpage),\n        }",
        "begin_line": 34,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mailru.MailRuIE._real_extract#47",
        "src_path": "youtube_dl/extractor/mailru.py",
        "class_name": "youtube_dl.extractor.mailru.MailRuIE",
        "signature": "youtube_dl.extractor.mailru.MailRuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('idv1')\n\n        if not video_id:\n            video_id = mobj.group('idv2prefix') + mobj.group('idv2suffix')\n\n        video_data = self._download_json(\n            'http://api.video.mail.ru/videos/%s.json?new=1' % video_id, video_id, 'Downloading video JSON')\n\n        author = video_data['author']\n        uploader = author['name']\n        uploader_id = author.get('id') or author.get('email')\n        view_count = video_data.get('views_count')\n\n        meta_data = video_data['meta']\n        content_id = '%s_%s' % (\n            meta_data.get('accId', ''), meta_data['itemId'])\n        title = meta_data['title']\n        if title.endswith('.mp4'):\n            title = title[:-4]\n        thumbnail = meta_data['poster']\n        duration = meta_data['duration']\n        timestamp = meta_data['timestamp']\n\n        formats = [\n            {\n                'url': video['url'],\n                'format_id': video['key'],\n                'height': int(video['key'].rstrip('p'))\n            } for video in video_data['videos']\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': content_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 47,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.hypem.HypemIE._real_extract#29",
        "src_path": "youtube_dl/extractor/hypem.py",
        "class_name": "youtube_dl.extractor.hypem.HypemIE",
        "signature": "youtube_dl.extractor.hypem.HypemIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        track_id = self._match_id(url)\n\n        data = {'ax': 1, 'ts': time.time()}\n        data_encoded = compat_urllib_parse.urlencode(data)\n        complete_url = url + \"?\" + data_encoded\n        request = compat_urllib_request.Request(complete_url)\n        response, urlh = self._download_webpage_handle(\n            request, track_id, 'Downloading webpage with the url')\n        cookie = urlh.headers.get('Set-Cookie', '')\n\n        html_tracks = self._html_search_regex(\n            r'(?ms)<script type=\"application/json\" id=\"displayList-data\">\\s*(.*?)\\s*</script>',\n            response, 'tracks')\n        try:\n            track_list = json.loads(html_tracks)\n            track = track_list['tracks'][0]\n        except ValueError:\n            raise ExtractorError('Hypemachine contained invalid JSON.')\n\n        key = track['key']\n        track_id = track['id']\n        artist = track['artist']\n        title = track['song']\n\n        serve_url = \"http://hypem.com/serve/source/%s/%s\" % (track_id, key)\n        request = compat_urllib_request.Request(\n            serve_url, '', {'Content-Type': 'application/json'})\n        request.add_header('cookie', cookie)\n        song_data = self._download_json(request, track_id, 'Downloading metadata')\n        final_url = song_data[\"url\"]\n\n        return {\n            'id': track_id,\n            'url': final_url,\n            'ext': 'mp3',\n            'title': title,\n            'uploader': artist,\n        }",
        "begin_line": 29,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.streamcz._get_api_key#16",
        "src_path": "youtube_dl/extractor/streamcz.py",
        "class_name": "youtube_dl.extractor.streamcz",
        "signature": "youtube_dl.extractor.streamcz._get_api_key(api_path)",
        "snippet": "def _get_api_key(api_path):\n    if api_path.endswith('?'):\n        api_path = api_path[:-1]\n\n    api_key = 'fb5f58a820353bd7095de526253c14fd'\n    a = '{0:}{1:}{2:}'.format(api_key, api_path, int(round(time.time() / 24 / 3600)))\n    return hashlib.md5(a.encode('ascii')).hexdigest()",
        "begin_line": 16,
        "end_line": 22,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.streamcz.StreamCZIE._real_extract#53",
        "src_path": "youtube_dl/extractor/streamcz.py",
        "class_name": "youtube_dl.extractor.streamcz.StreamCZIE",
        "signature": "youtube_dl.extractor.streamcz.StreamCZIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        api_path = '/episode/%s' % video_id\n\n        req = compat_urllib_request.Request(self._API_URL + api_path)\n        req.add_header('Api-Password', _get_api_key(api_path))\n        data = self._download_json(req, video_id)\n\n        formats = []\n        for quality, video in enumerate(data['video_qualities']):\n            for f in video['formats']:\n                typ = f['type'].partition('/')[2]\n                qlabel = video.get('quality_label')\n                formats.append({\n                    'format_note': '%s-%s' % (qlabel, typ) if qlabel else typ,\n                    'format_id': '%s-%s' % (typ, f['quality']),\n                    'url': f['source'],\n                    'height': int_or_none(f['quality'].rstrip('p')),\n                    'quality': quality,\n                })\n        self._sort_formats(formats)\n\n        image = data.get('image')\n        if image:\n            thumbnail = self._proto_relative_url(\n                image.replace('{width}', '1240').replace('{height}', '697'),\n                scheme='http:',\n            )\n        else:\n            thumbnail = None\n\n        stream = data.get('_embedded', {}).get('stream:show', {}).get('name')\n        if stream:\n            title = '%s: %s' % (stream, data['name'])\n        else:\n            title = data['name']\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n            'description': data.get('web_site_text'),\n            'duration': int_or_none(data.get('duration')),\n            'view_count': int_or_none(data.get('views')),\n        }",
        "begin_line": 53,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.telemb.TeleMBIE._real_extract#40",
        "src_path": "youtube_dl/extractor/telemb.py",
        "class_name": "youtube_dl.extractor.telemb.TeleMBIE",
        "signature": "youtube_dl.extractor.telemb.TeleMBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        formats = []\n        for video_url in re.findall(r'file\\s*:\\s*\"([^\"]+)\"', webpage):\n            fmt = {\n                'url': video_url,\n                'format_id': video_url.split(':')[0]\n            }\n            rtmp = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+))/(?P<playpath>mp4:.+)$', video_url)\n            if rtmp:\n                fmt.update({\n                    'play_path': rtmp.group('playpath'),\n                    'app': rtmp.group('app'),\n                    'player_url': 'http://p.jwpcdn.com/6/10/jwplayer.flash.swf',\n                    'page_url': 'http://www.telemb.be',\n                    'preference': -1,\n                })\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        title = remove_start(self._og_search_title(webpage), 'T\u00e9l\u00e9MB : ')\n        description = self._html_search_regex(\n            r'<meta property=\"og:description\" content=\"(.+?)\" />',\n            webpage, 'description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 40,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._real_extract#79",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        page = self._download_webpage(url, display_id)\n        xml_url = self._search_regex(\n            r\"return BRavFramework\\.register\\(BRavFramework\\('avPlayer_(?:[a-f0-9-]{36})'\\)\\.setup\\({dataURL:'(/(?:[a-z0-9\\-]+/)+[a-z0-9/~_.-]+)'}\\)\\);\", page, 'XMLURL')\n        xml = self._download_xml(self._BASE_URL + xml_url, None)\n\n        medias = []\n\n        for xml_media in xml.findall('video') + xml.findall('audio'):\n            media = {\n                'id': xml_media.get('externalId'),\n                'title': xml_media.find('title').text,\n                'duration': parse_duration(xml_media.find('duration').text),\n                'formats': self._extract_formats(xml_media.find('assets')),\n                'thumbnails': self._extract_thumbnails(xml_media.find('teaserImage/variants')),\n                'description': ' '.join(xml_media.find('shareTitle').text.splitlines()),\n                'webpage_url': xml_media.find('permalink').text\n            }\n            if xml_media.find('author').text:\n                media['uploader'] = xml_media.find('author').text\n            if xml_media.find('broadcastDate').text:\n                media['upload_date'] = ''.join(reversed(xml_media.find('broadcastDate').text.split('.')))\n            medias.append(media)\n\n        if len(medias) > 1:\n            self._downloader.report_warning(\n                'found multiple medias; please '\n                'report this with the video URL to http://yt-dl.org/bug')\n        if not medias:\n            raise ExtractorError('No media entries found')\n        return medias[0]",
        "begin_line": 79,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._extract_formats#112",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._extract_formats(self, assets)",
        "snippet": "    def _extract_formats(self, assets):\n\n        def text_or_none(asset, tag):\n            elem = asset.find(tag)\n            return None if elem is None else elem.text\n\n        formats = [{\n            'url': text_or_none(asset, 'downloadUrl'),\n            'ext': text_or_none(asset, 'mediaType'),\n            'format_id': asset.get('type'),\n            'width': int_or_none(text_or_none(asset, 'frameWidth')),\n            'height': int_or_none(text_or_none(asset, 'frameHeight')),\n            'tbr': int_or_none(text_or_none(asset, 'bitrateVideo')),\n            'abr': int_or_none(text_or_none(asset, 'bitrateAudio')),\n            'vcodec': text_or_none(asset, 'codecVideo'),\n            'acodec': text_or_none(asset, 'codecAudio'),\n            'container': text_or_none(asset, 'mediaType'),\n            'filesize': int_or_none(text_or_none(asset, 'size')),\n        } for asset in assets.findall('asset')\n            if asset.find('downloadUrl') is not None]\n\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 112,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._extract_thumbnails#136",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._extract_thumbnails(self, variants)",
        "snippet": "    def _extract_thumbnails(self, variants):\n        thumbnails = [{\n            'url': self._BASE_URL + variant.find('url').text,\n            'width': int_or_none(variant.find('width').text),\n            'height': int_or_none(variant.find('height').text),\n        } for variant in variants.findall('variant')]\n        thumbnails.sort(key=lambda x: x['width'] * x['height'], reverse=True)\n        return thumbnails",
        "begin_line": 136,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.teachertube.TeacherTubeIE._real_extract#59",
        "src_path": "youtube_dl/extractor/teachertube.py",
        "class_name": "youtube_dl.extractor.teachertube.TeacherTubeIE",
        "signature": "youtube_dl.extractor.teachertube.TeacherTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta('title', webpage, 'title', fatal=True)\n        TITLE_SUFFIX = ' - TeacherTube'\n        if title.endswith(TITLE_SUFFIX):\n            title = title[:-len(TITLE_SUFFIX)].strip()\n\n        description = self._html_search_meta('description', webpage, 'description')\n        if description:\n            description = description.strip()\n\n        quality = qualities(['mp3', 'flv', 'mp4'])\n\n        media_urls = re.findall(r'data-contenturl=\"([^\"]+)\"', webpage)\n        media_urls.extend(re.findall(r'var\\s+filePath\\s*=\\s*\"([^\"]+)\"', webpage))\n        media_urls.extend(re.findall(r'\\'file\\'\\s*:\\s*[\"\\']([^\"\\']+)[\"\\'],', webpage))\n\n        formats = [\n            {\n                'url': media_url,\n                'quality': quality(determine_ext(media_url))\n            } for media_url in set(media_urls)\n        ]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': self._html_search_regex(r'\\'image\\'\\s*:\\s*[\"\\']([^\"\\']+)[\"\\']', webpage, 'thumbnail'),\n            'formats': formats,\n            'description': description,\n        }",
        "begin_line": 59,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.teachertube.TeacherTubeUserIE._real_extract#115",
        "src_path": "youtube_dl/extractor/teachertube.py",
        "class_name": "youtube_dl.extractor.teachertube.TeacherTubeUserIE",
        "signature": "youtube_dl.extractor.teachertube.TeacherTubeUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('user')\n\n        urls = []\n        webpage = self._download_webpage(url, user_id)\n        urls.extend(re.findall(self._MEDIA_RE, webpage))\n\n        pages = re.findall(r'/ajax-user/user-videos/%s\\?page=([0-9]+)' % user_id, webpage)[:-1]\n        for p in pages:\n            more = 'http://www.teachertube.com/ajax-user/user-videos/%s?page=%s' % (user_id, p)\n            webpage = self._download_webpage(more, user_id, 'Downloading page %s/%s' % (p, len(pages)))\n            video_urls = re.findall(self._MEDIA_RE, webpage)\n            urls.extend(video_urls)\n\n        entries = [self.url_result(vurl, 'TeacherTube') for vurl in urls]\n        return self.playlist_result(entries, user_id)",
        "begin_line": 115,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dfb.DFBIE._real_extract#25",
        "src_path": "youtube_dl/extractor/dfb.py",
        "class_name": "youtube_dl.extractor.dfb.DFBIE",
        "signature": "youtube_dl.extractor.dfb.DFBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n        player_info = self._download_xml(\n            'http://tv.dfb.de/server/hd_video.php?play=%s' % video_id,\n            display_id)\n        video_info = player_info.find('video')\n\n        f4m_info = self._download_xml(\n            self._proto_relative_url(video_info.find('url').text.strip()), display_id)\n        token_el = f4m_info.find('token')\n        manifest_url = token_el.attrib['url'] + '?' + 'hdnea=' + token_el.attrib['auth'] + '&hdcore=3.2.0'\n        formats = self._extract_f4m_formats(manifest_url, display_id)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': video_info.find('title').text,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'upload_date': unified_strdate(video_info.find('time_date').text),\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._extract_tags#14",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._extract_tags(file_contents)",
        "snippet": "def _extract_tags(file_contents):\n    if file_contents[1:3] != b'WS':\n        raise ExtractorError(\n            'Not an SWF file; header is %r' % file_contents[:3])\n    if file_contents[:1] == b'C':\n        content = zlib.decompress(file_contents[8:])\n    else:\n        raise NotImplementedError(\n            'Unsupported compression format %r' %\n            file_contents[:1])\n\n    # Determine number of bits in framesize rectangle\n    framesize_nbits = struct_unpack('!B', content[:1])[0] >> 3\n    framesize_len = (5 + 4 * framesize_nbits + 7) // 8\n\n    pos = framesize_len + 2 + 2\n    while pos < len(content):\n        header16 = struct_unpack('<H', content[pos:pos + 2])[0]\n        pos += 2\n        tag_code = header16 >> 6\n        tag_len = header16 & 0x3f\n        if tag_len == 0x3f:\n            tag_len = struct_unpack('<I', content[pos:pos + 4])[0]\n            pos += 4\n        assert pos + tag_len <= len(content), \\\n            ('Tag %d ends at %d+%d - that\\'s longer than the file (%d)'\n                % (tag_code, pos, tag_len, len(content)))\n        yield (tag_code, content[pos:pos + tag_len])\n        pos += tag_len",
        "begin_line": 14,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass_Object.__init__#46",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass_Object",
        "signature": "youtube_dl.swfinterp._AVMClass_Object.__init__(self, avm_class)",
        "snippet": "    def __init__(self, avm_class):\n        self.avm_class = avm_class",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass_Object.__repr__#49",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass_Object",
        "signature": "youtube_dl.swfinterp._AVMClass_Object.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '%s#%x' % (self.avm_class.name, id(self))",
        "begin_line": 49,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._ScopeDict.__init__#54",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._ScopeDict",
        "signature": "youtube_dl.swfinterp._ScopeDict.__init__(self, avm_class)",
        "snippet": "    def __init__(self, avm_class):\n        super(_ScopeDict, self).__init__()\n        self.avm_class = avm_class",
        "begin_line": 54,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._ScopeDict.__repr__#58",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._ScopeDict",
        "signature": "youtube_dl.swfinterp._ScopeDict.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '%s__Scope(%s)' % (\n            self.avm_class.name,\n            super(_ScopeDict, self).__repr__())",
        "begin_line": 58,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.__init__#65",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.__init__(self, name_idx, name, static_properties=None)",
        "snippet": "    def __init__(self, name_idx, name, static_properties=None):\n        self.name_idx = name_idx\n        self.name = name\n        self.method_names = {}\n        self.method_idxs = {}\n        self.methods = {}\n        self.method_pyfunctions = {}\n        self.static_properties = static_properties if static_properties else {}\n\n        self.variables = _ScopeDict(self)\n        self.constants = {}",
        "begin_line": 65,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.make_object#77",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.make_object(self)",
        "snippet": "    def make_object(self):\n        return _AVMClass_Object(self)",
        "begin_line": 77,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.__repr__#80",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '_AVMClass(%s)' % (self.name)",
        "begin_line": 80,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.register_methods#83",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.register_methods(self, methods)",
        "snippet": "    def register_methods(self, methods):\n        self.method_names.update(methods.items())\n        self.method_idxs.update(dict(\n            (idx, name)\n            for name, idx in methods.items()))",
        "begin_line": 83,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._Multiname.__init__#91",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Multiname",
        "signature": "youtube_dl.swfinterp._Multiname.__init__(self, kind)",
        "snippet": "    def __init__(self, kind):\n        self.kind = kind",
        "begin_line": 91,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._Multiname.__repr__#94",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Multiname",
        "signature": "youtube_dl.swfinterp._Multiname.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '[MULTINAME kind: 0x%x]' % self.kind",
        "begin_line": 94,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._read_int#98",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_int(reader)",
        "snippet": "def _read_int(reader):\n    res = 0\n    shift = 0\n    for _ in range(5):\n        buf = reader.read(1)\n        assert len(buf) == 1\n        b = struct_unpack('<B', buf)[0]\n        res = res | ((b & 0x7f) << shift)\n        if b & 0x80 == 0:\n            break\n        shift += 7\n    return res",
        "begin_line": 98,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._u30#112",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._u30(reader)",
        "snippet": "def _u30(reader):\n    res = _read_int(reader)\n    assert res & 0xf0000000 == 0\n    return res",
        "begin_line": 112,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._s32#119",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._s32(reader)",
        "snippet": "def _s32(reader):\n    v = _read_int(reader)\n    if v & 0x80000000 != 0:\n        v = - ((v ^ 0xffffffff) + 1)\n    return v",
        "begin_line": 119,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._s24#126",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._s24(reader)",
        "snippet": "def _s24(reader):\n    bs = reader.read(3)\n    assert len(bs) == 3\n    last_byte = b'\\xff' if (ord(bs[2:3]) >= 0x80) else b'\\x00'\n    return struct_unpack('<i', bs + last_byte)[0]",
        "begin_line": 126,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._read_string#133",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_string(reader)",
        "snippet": "def _read_string(reader):\n    slen = _u30(reader)\n    resb = reader.read(slen)\n    assert len(resb) == slen\n    return resb.decode('utf-8')",
        "begin_line": 133,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._read_bytes#140",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_bytes(count, reader)",
        "snippet": "def _read_bytes(count, reader):\n    assert count >= 0\n    resb = reader.read(count)\n    assert len(resb) == count\n    return resb",
        "begin_line": 140,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._read_byte#147",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_byte(reader)",
        "snippet": "def _read_byte(reader):\n    resb = _read_bytes(1, reader=reader)\n    res = struct_unpack('<B', resb)[0]\n    return res",
        "begin_line": 147,
        "end_line": 150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._Undefined.__bool__#166",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Undefined",
        "signature": "youtube_dl.swfinterp._Undefined.__bool__(self)",
        "snippet": "    def __bool__(self):\n        return False",
        "begin_line": 166,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._Undefined.__hash__#170",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Undefined",
        "signature": "youtube_dl.swfinterp._Undefined.__hash__(self)",
        "snippet": "    def __hash__(self):\n        return 0",
        "begin_line": 170,
        "end_line": 171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp._Undefined.__str__#173",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Undefined",
        "signature": "youtube_dl.swfinterp._Undefined.__str__(self)",
        "snippet": "    def __str__(self):\n        return 'undefined'",
        "begin_line": 173,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.__init__#181",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.__init__(self, file_contents)",
        "snippet": "    def __init__(self, file_contents):\n        self._patched_functions = {\n            (TimerClass, 'addEventListener'): lambda params: undefined,\n        }\n        code_tag = next(tag\n                        for tag_code, tag in _extract_tags(file_contents)\n                        if tag_code == 82)\n        p = code_tag.index(b'\\0', 4) + 1\n        code_reader = io.BytesIO(code_tag[p:])\n\n        # Parse ABC (AVM2 ByteCode)\n\n        # Define a couple convenience methods\n        u30 = lambda *args: _u30(*args, reader=code_reader)\n        s32 = lambda *args: _s32(*args, reader=code_reader)\n        u32 = lambda *args: _u32(*args, reader=code_reader)\n        read_bytes = lambda *args: _read_bytes(*args, reader=code_reader)\n        read_byte = lambda *args: _read_byte(*args, reader=code_reader)\n\n        # minor_version + major_version\n        read_bytes(2 + 2)\n\n        # Constant pool\n        int_count = u30()\n        self.constant_ints = [0]\n        for _c in range(1, int_count):\n            self.constant_ints.append(s32())\n        self.constant_uints = [0]\n        uint_count = u30()\n        for _c in range(1, uint_count):\n            self.constant_uints.append(u32())\n        double_count = u30()\n        read_bytes(max(0, (double_count - 1)) * 8)\n        string_count = u30()\n        self.constant_strings = ['']\n        for _c in range(1, string_count):\n            s = _read_string(code_reader)\n            self.constant_strings.append(s)\n        namespace_count = u30()\n        for _c in range(1, namespace_count):\n            read_bytes(1)  # kind\n            u30()  # name\n        ns_set_count = u30()\n        for _c in range(1, ns_set_count):\n            count = u30()\n            for _c2 in range(count):\n                u30()\n        multiname_count = u30()\n        MULTINAME_SIZES = {\n            0x07: 2,  # QName\n            0x0d: 2,  # QNameA\n            0x0f: 1,  # RTQName\n            0x10: 1,  # RTQNameA\n            0x11: 0,  # RTQNameL\n            0x12: 0,  # RTQNameLA\n            0x09: 2,  # Multiname\n            0x0e: 2,  # MultinameA\n            0x1b: 1,  # MultinameL\n            0x1c: 1,  # MultinameLA\n        }\n        self.multinames = ['']\n        for _c in range(1, multiname_count):\n            kind = u30()\n            assert kind in MULTINAME_SIZES, 'Invalid multiname kind %r' % kind\n            if kind == 0x07:\n                u30()  # namespace_idx\n                name_idx = u30()\n                self.multinames.append(self.constant_strings[name_idx])\n            elif kind == 0x09:\n                name_idx = u30()\n                u30()\n                self.multinames.append(self.constant_strings[name_idx])\n            else:\n                self.multinames.append(_Multiname(kind))\n                for _c2 in range(MULTINAME_SIZES[kind]):\n                    u30()\n\n        # Methods\n        method_count = u30()\n        MethodInfo = collections.namedtuple(\n            'MethodInfo',\n            ['NEED_ARGUMENTS', 'NEED_REST'])\n        method_infos = []\n        for method_id in range(method_count):\n            param_count = u30()\n            u30()  # return type\n            for _ in range(param_count):\n                u30()  # param type\n            u30()  # name index (always 0 for youtube)\n            flags = read_byte()\n            if flags & 0x08 != 0:\n                # Options present\n                option_count = u30()\n                for c in range(option_count):\n                    u30()  # val\n                    read_bytes(1)  # kind\n            if flags & 0x80 != 0:\n                # Param names present\n                for _ in range(param_count):\n                    u30()  # param name\n            mi = MethodInfo(flags & 0x01 != 0, flags & 0x04 != 0)\n            method_infos.append(mi)\n\n        # Metadata\n        metadata_count = u30()\n        for _c in range(metadata_count):\n            u30()  # name\n            item_count = u30()\n            for _c2 in range(item_count):\n                u30()  # key\n                u30()  # value\n\n        def parse_traits_info():\n            trait_name_idx = u30()\n            kind_full = read_byte()\n            kind = kind_full & 0x0f\n            attrs = kind_full >> 4\n            methods = {}\n            constants = None\n            if kind == 0x00:  # Slot\n                u30()  # Slot id\n                u30()  # type_name_idx\n                vindex = u30()\n                if vindex != 0:\n                    read_byte()  # vkind\n            elif kind == 0x06:  # Const\n                u30()  # Slot id\n                u30()  # type_name_idx\n                vindex = u30()\n                vkind = 'any'\n                if vindex != 0:\n                    vkind = read_byte()\n                if vkind == 0x03:  # Constant_Int\n                    value = self.constant_ints[vindex]\n                elif vkind == 0x04:  # Constant_UInt\n                    value = self.constant_uints[vindex]\n                else:\n                    return {}, None  # Ignore silently for now\n                constants = {self.multinames[trait_name_idx]: value}\n            elif kind in (0x01, 0x02, 0x03):  # Method / Getter / Setter\n                u30()  # disp_id\n                method_idx = u30()\n                methods[self.multinames[trait_name_idx]] = method_idx\n            elif kind == 0x04:  # Class\n                u30()  # slot_id\n                u30()  # classi\n            elif kind == 0x05:  # Function\n                u30()  # slot_id\n                function_idx = u30()\n                methods[function_idx] = self.multinames[trait_name_idx]\n            else:\n                raise ExtractorError('Unsupported trait kind %d' % kind)\n\n            if attrs & 0x4 != 0:  # Metadata present\n                metadata_count = u30()\n                for _c3 in range(metadata_count):\n                    u30()  # metadata index\n\n            return methods, constants\n\n        # Classes\n        class_count = u30()\n        classes = []\n        for class_id in range(class_count):\n            name_idx = u30()\n\n            cname = self.multinames[name_idx]\n            avm_class = _AVMClass(name_idx, cname)\n            classes.append(avm_class)\n\n            u30()  # super_name idx\n            flags = read_byte()\n            if flags & 0x08 != 0:  # Protected namespace is present\n                u30()  # protected_ns_idx\n            intrf_count = u30()\n            for _c2 in range(intrf_count):\n                u30()\n            u30()  # iinit\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                trait_methods, trait_constants = parse_traits_info()\n                avm_class.register_methods(trait_methods)\n                if trait_constants:\n                    avm_class.constants.update(trait_constants)\n\n        assert len(classes) == class_count\n        self._classes_by_name = dict((c.name, c) for c in classes)\n\n        for avm_class in classes:\n            avm_class.cinit_idx = u30()\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                trait_methods, trait_constants = parse_traits_info()\n                avm_class.register_methods(trait_methods)\n                if trait_constants:\n                    avm_class.constants.update(trait_constants)\n\n        # Scripts\n        script_count = u30()\n        for _c in range(script_count):\n            u30()  # init\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                parse_traits_info()\n\n        # Method bodies\n        method_body_count = u30()\n        Method = collections.namedtuple('Method', ['code', 'local_count'])\n        self._all_methods = []\n        for _c in range(method_body_count):\n            method_idx = u30()\n            u30()  # max_stack\n            local_count = u30()\n            u30()  # init_scope_depth\n            u30()  # max_scope_depth\n            code_length = u30()\n            code = read_bytes(code_length)\n            m = Method(code, local_count)\n            self._all_methods.append(m)\n            for avm_class in classes:\n                if method_idx in avm_class.method_idxs:\n                    avm_class.methods[avm_class.method_idxs[method_idx]] = m\n            exception_count = u30()\n            for _c2 in range(exception_count):\n                u30()  # from\n                u30()  # to\n                u30()  # target\n                u30()  # exc_type\n                u30()  # var_name\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                parse_traits_info()\n\n        assert p + code_reader.tell() == len(code_tag)",
        "begin_line": 181,
        "end_line": 414,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.patch_function#416",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.patch_function(self, avm_class, func_name, f)",
        "snippet": "    def patch_function(self, avm_class, func_name, f):\n        self._patched_functions[(avm_class, func_name)] = f",
        "begin_line": 416,
        "end_line": 417,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.extract_class#419",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.extract_class(self, class_name, call_cinit=True)",
        "snippet": "    def extract_class(self, class_name, call_cinit=True):\n        try:\n            res = self._classes_by_name[class_name]\n        except KeyError:\n            raise ExtractorError('Class %r not found' % class_name)\n\n        if call_cinit and hasattr(res, 'cinit_idx'):\n            res.register_methods({'$cinit': res.cinit_idx})\n            res.methods['$cinit'] = self._all_methods[res.cinit_idx]\n            cinit = self.extract_function(res, '$cinit')\n            cinit([])\n\n        return res",
        "begin_line": 419,
        "end_line": 431,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.extract_function#433",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.extract_function(self, avm_class, func_name)",
        "snippet": "    def extract_function(self, avm_class, func_name):\n        p = self._patched_functions.get((avm_class, func_name))\n        if p:\n            return p\n        if func_name in avm_class.method_pyfunctions:\n            return avm_class.method_pyfunctions[func_name]\n        if func_name in self._classes_by_name:\n            return self._classes_by_name[func_name].make_object()\n        if func_name not in avm_class.methods:\n            raise ExtractorError('Cannot find function %s.%s' % (\n                avm_class.name, func_name))\n        m = avm_class.methods[func_name]\n\n        def resfunc(args):\n            # Helper functions\n            coder = io.BytesIO(m.code)\n            s24 = lambda: _s24(coder)\n            u30 = lambda: _u30(coder)\n\n            registers = [avm_class.variables] + list(args) + [None] * m.local_count\n            stack = []\n            scopes = collections.deque([\n                self._classes_by_name, avm_class.constants, avm_class.variables])\n            while True:\n                opcode = _read_byte(coder)\n                if opcode == 9:  # label\n                    pass  # Spec says: \"Do nothing.\"\n                elif opcode == 16:  # jump\n                    offset = s24()\n                    coder.seek(coder.tell() + offset)\n                elif opcode == 17:  # iftrue\n                    offset = s24()\n                    value = stack.pop()\n                    if value:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 18:  # iffalse\n                    offset = s24()\n                    value = stack.pop()\n                    if not value:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 19:  # ifeq\n                    offset = s24()\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    if value2 == value1:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 20:  # ifne\n                    offset = s24()\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    if value2 != value1:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 21:  # iflt\n                    offset = s24()\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    if value1 < value2:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 32:  # pushnull\n                    stack.append(None)\n                elif opcode == 33:  # pushundefined\n                    stack.append(undefined)\n                elif opcode == 36:  # pushbyte\n                    v = _read_byte(coder)\n                    stack.append(v)\n                elif opcode == 37:  # pushshort\n                    v = u30()\n                    stack.append(v)\n                elif opcode == 38:  # pushtrue\n                    stack.append(True)\n                elif opcode == 39:  # pushfalse\n                    stack.append(False)\n                elif opcode == 40:  # pushnan\n                    stack.append(float('NaN'))\n                elif opcode == 42:  # dup\n                    value = stack[-1]\n                    stack.append(value)\n                elif opcode == 44:  # pushstring\n                    idx = u30()\n                    stack.append(self.constant_strings[idx])\n                elif opcode == 48:  # pushscope\n                    new_scope = stack.pop()\n                    scopes.append(new_scope)\n                elif opcode == 66:  # construct\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n                    res = obj.avm_class.make_object()\n                    stack.append(res)\n                elif opcode == 70:  # callproperty\n                    index = u30()\n                    mname = self.multinames[index]\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n\n                    if obj == StringClass:\n                        if mname == 'String':\n                            assert len(args) == 1\n                            assert isinstance(args[0], (\n                                int, compat_str, _Undefined))\n                            if args[0] == undefined:\n                                res = 'undefined'\n                            else:\n                                res = compat_str(args[0])\n                            stack.append(res)\n                            continue\n                        else:\n                            raise NotImplementedError(\n                                'Function String.%s is not yet implemented'\n                                % mname)\n                    elif isinstance(obj, _AVMClass_Object):\n                        func = self.extract_function(obj.avm_class, mname)\n                        res = func(args)\n                        stack.append(res)\n                        continue\n                    elif isinstance(obj, _AVMClass):\n                        func = self.extract_function(obj, mname)\n                        res = func(args)\n                        stack.append(res)\n                        continue\n                    elif isinstance(obj, _ScopeDict):\n                        if mname in obj.avm_class.method_names:\n                            func = self.extract_function(obj.avm_class, mname)\n                            res = func(args)\n                        else:\n                            res = obj[mname]\n                        stack.append(res)\n                        continue\n                    elif isinstance(obj, compat_str):\n                        if mname == 'split':\n                            assert len(args) == 1\n                            assert isinstance(args[0], compat_str)\n                            if args[0] == '':\n                                res = list(obj)\n                            else:\n                                res = obj.split(args[0])\n                            stack.append(res)\n                            continue\n                        elif mname == 'charCodeAt':\n                            assert len(args) <= 1\n                            idx = 0 if len(args) == 0 else args[0]\n                            assert isinstance(idx, int)\n                            res = ord(obj[idx])\n                            stack.append(res)\n                            continue\n                    elif isinstance(obj, list):\n                        if mname == 'slice':\n                            assert len(args) == 1\n                            assert isinstance(args[0], int)\n                            res = obj[args[0]:]\n                            stack.append(res)\n                            continue\n                        elif mname == 'join':\n                            assert len(args) == 1\n                            assert isinstance(args[0], compat_str)\n                            res = args[0].join(obj)\n                            stack.append(res)\n                            continue\n                    raise NotImplementedError(\n                        'Unsupported property %r on %r'\n                        % (mname, obj))\n                elif opcode == 71:  # returnvoid\n                    res = undefined\n                    return res\n                elif opcode == 72:  # returnvalue\n                    res = stack.pop()\n                    return res\n                elif opcode == 73:  # constructsuper\n                    # Not yet implemented, just hope it works without it\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n                elif opcode == 74:  # constructproperty\n                    index = u30()\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n\n                    mname = self.multinames[index]\n                    assert isinstance(obj, _AVMClass)\n\n                    # We do not actually call the constructor for now;\n                    # we just pretend it does nothing\n                    stack.append(obj.make_object())\n                elif opcode == 79:  # callpropvoid\n                    index = u30()\n                    mname = self.multinames[index]\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n                    if isinstance(obj, _AVMClass_Object):\n                        func = self.extract_function(obj.avm_class, mname)\n                        res = func(args)\n                        assert res is undefined\n                        continue\n                    if isinstance(obj, _ScopeDict):\n                        assert mname in obj.avm_class.method_names\n                        func = self.extract_function(obj.avm_class, mname)\n                        res = func(args)\n                        assert res is undefined\n                        continue\n                    if mname == 'reverse':\n                        assert isinstance(obj, list)\n                        obj.reverse()\n                    else:\n                        raise NotImplementedError(\n                            'Unsupported (void) property %r on %r'\n                            % (mname, obj))\n                elif opcode == 86:  # newarray\n                    arg_count = u30()\n                    arr = []\n                    for i in range(arg_count):\n                        arr.append(stack.pop())\n                    arr = arr[::-1]\n                    stack.append(arr)\n                elif opcode == 93:  # findpropstrict\n                    index = u30()\n                    mname = self.multinames[index]\n                    for s in reversed(scopes):\n                        if mname in s:\n                            res = s\n                            break\n                    else:\n                        res = scopes[0]\n                    if mname not in res and mname in _builtin_classes:\n                        stack.append(_builtin_classes[mname])\n                    else:\n                        stack.append(res[mname])\n                elif opcode == 94:  # findproperty\n                    index = u30()\n                    mname = self.multinames[index]\n                    for s in reversed(scopes):\n                        if mname in s:\n                            res = s\n                            break\n                    else:\n                        res = avm_class.variables\n                    stack.append(res)\n                elif opcode == 96:  # getlex\n                    index = u30()\n                    mname = self.multinames[index]\n                    for s in reversed(scopes):\n                        if mname in s:\n                            scope = s\n                            break\n                    else:\n                        scope = avm_class.variables\n\n                    if mname in scope:\n                        res = scope[mname]\n                    elif mname in _builtin_classes:\n                        res = _builtin_classes[mname]\n                    else:\n                        # Assume unitialized\n                        # TODO warn here\n                        res = undefined\n                    stack.append(res)\n                elif opcode == 97:  # setproperty\n                    index = u30()\n                    value = stack.pop()\n                    idx = self.multinames[index]\n                    if isinstance(idx, _Multiname):\n                        idx = stack.pop()\n                    obj = stack.pop()\n                    obj[idx] = value\n                elif opcode == 98:  # getlocal\n                    index = u30()\n                    stack.append(registers[index])\n                elif opcode == 99:  # setlocal\n                    index = u30()\n                    value = stack.pop()\n                    registers[index] = value\n                elif opcode == 102:  # getproperty\n                    index = u30()\n                    pname = self.multinames[index]\n                    if pname == 'length':\n                        obj = stack.pop()\n                        assert isinstance(obj, (compat_str, list))\n                        stack.append(len(obj))\n                    elif isinstance(pname, compat_str):  # Member access\n                        obj = stack.pop()\n                        if isinstance(obj, _AVMClass):\n                            res = obj.static_properties[pname]\n                            stack.append(res)\n                            continue\n\n                        assert isinstance(obj, (dict, _ScopeDict)),\\\n                            'Accessing member %r on %r' % (pname, obj)\n                        res = obj.get(pname, undefined)\n                        stack.append(res)\n                    else:  # Assume attribute access\n                        idx = stack.pop()\n                        assert isinstance(idx, int)\n                        obj = stack.pop()\n                        assert isinstance(obj, list)\n                        stack.append(obj[idx])\n                elif opcode == 104:  # initproperty\n                    index = u30()\n                    value = stack.pop()\n                    idx = self.multinames[index]\n                    if isinstance(idx, _Multiname):\n                        idx = stack.pop()\n                    obj = stack.pop()\n                    obj[idx] = value\n                elif opcode == 115:  # convert_\n                    value = stack.pop()\n                    intvalue = int(value)\n                    stack.append(intvalue)\n                elif opcode == 128:  # coerce\n                    u30()\n                elif opcode == 130:  # coerce_a\n                    value = stack.pop()\n                    # um, yes, it's any value\n                    stack.append(value)\n                elif opcode == 133:  # coerce_s\n                    assert isinstance(stack[-1], (type(None), compat_str))\n                elif opcode == 147:  # decrement\n                    value = stack.pop()\n                    assert isinstance(value, int)\n                    stack.append(value - 1)\n                elif opcode == 149:  # typeof\n                    value = stack.pop()\n                    return {\n                        _Undefined: 'undefined',\n                        compat_str: 'String',\n                        int: 'Number',\n                        float: 'Number',\n                    }[type(value)]\n                elif opcode == 160:  # add\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 + value2\n                    stack.append(res)\n                elif opcode == 161:  # subtract\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 - value2\n                    stack.append(res)\n                elif opcode == 162:  # multiply\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 * value2\n                    stack.append(res)\n                elif opcode == 164:  # modulo\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 % value2\n                    stack.append(res)\n                elif opcode == 168:  # bitand\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    assert isinstance(value1, int)\n                    assert isinstance(value2, int)\n                    res = value1 & value2\n                    stack.append(res)\n                elif opcode == 171:  # equals\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    result = value1 == value2\n                    stack.append(result)\n                elif opcode == 175:  # greaterequals\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    result = value1 >= value2\n                    stack.append(result)\n                elif opcode == 192:  # increment_i\n                    value = stack.pop()\n                    assert isinstance(value, int)\n                    stack.append(value + 1)\n                elif opcode == 208:  # getlocal_0\n                    stack.append(registers[0])\n                elif opcode == 209:  # getlocal_1\n                    stack.append(registers[1])\n                elif opcode == 210:  # getlocal_2\n                    stack.append(registers[2])\n                elif opcode == 211:  # getlocal_3\n                    stack.append(registers[3])\n                elif opcode == 212:  # setlocal_0\n                    registers[0] = stack.pop()\n                elif opcode == 213:  # setlocal_1\n                    registers[1] = stack.pop()\n                elif opcode == 214:  # setlocal_2\n                    registers[2] = stack.pop()\n                elif opcode == 215:  # setlocal_3\n                    registers[3] = stack.pop()\n                else:\n                    raise NotImplementedError(\n                        'Unsupported opcode %d' % opcode)\n\n        avm_class.method_pyfunctions[func_name] = resfunc\n        return resfunc",
        "begin_line": 433,
        "end_line": 829,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.iconosquare.IconosquareIE._real_extract#30",
        "src_path": "youtube_dl/extractor/iconosquare.py",
        "class_name": "youtube_dl.extractor.iconosquare.IconosquareIE",
        "signature": "youtube_dl.extractor.iconosquare.IconosquareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        media = self._parse_json(\n            get_element_by_id('mediaJson', webpage),\n            video_id)\n\n        formats = [{\n            'url': f['url'],\n            'format_id': format_id,\n            'width': int_or_none(f.get('width')),\n            'height': int_or_none(f.get('height'))\n        } for format_id, f in media['videos'].items()]\n        self._sort_formats(formats)\n\n        title = remove_end(self._og_search_title(webpage), ' - via Iconosquare')\n\n        timestamp = int_or_none(media.get('created_time') or media.get('caption', {}).get('created_time'))\n        description = media.get('caption', {}).get('text')\n\n        uploader = media.get('user', {}).get('username')\n        uploader_id = media.get('user', {}).get('id')\n\n        comment_count = int_or_none(media.get('comments', {}).get('count'))\n        like_count = int_or_none(media.get('likes', {}).get('count'))\n\n        thumbnails = [{\n            'url': t['url'],\n            'id': thumbnail_id,\n            'width': int_or_none(t.get('width')),\n            'height': int_or_none(t.get('height'))\n        } for thumbnail_id, t in media.get('images', {}).items()]\n\n        comments = [{\n            'id': comment.get('id'),\n            'text': comment['text'],\n            'timestamp': int_or_none(comment.get('created_time')),\n            'author': comment.get('from', {}).get('full_name'),\n            'author_id': comment.get('from', {}).get('username'),\n        } for comment in media.get('comments', {}).get('data', []) if 'text' in comment]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'comment_count': comment_count,\n            'like_count': like_count,\n            'formats': formats,\n            'comments': comments,\n        }",
        "begin_line": 30,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor._extract_video#21",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor",
        "signature": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor._extract_video(self, video_id, catalogue)",
        "snippet": "    def _extract_video(self, video_id, catalogue):\n        info = self._download_json(\n            'http://webservices.francetelevisions.fr/tools/getInfosOeuvre/v2/?idDiffusion=%s&catalogue=%s'\n            % (video_id, catalogue),\n            video_id, 'Downloading video JSON')\n\n        if info.get('status') == 'NOK':\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, info['message']), expected=True)\n        allowed_countries = info['videos'][0].get('geoblocage')\n        if allowed_countries:\n            georestricted = True\n            geo_info = self._download_json(\n                'http://geo.francetv.fr/ws/edgescape.json', video_id,\n                'Downloading geo restriction info')\n            country = geo_info['reponse']['geo_info']['country_code']\n            if country not in allowed_countries:\n                raise ExtractorError(\n                    'The video is not available from your location',\n                    expected=True)\n        else:\n            georestricted = False\n\n        formats = []\n        for video in info['videos']:\n            if video['statut'] != 'ONLINE':\n                continue\n            video_url = video['url']\n            if not video_url:\n                continue\n            format_id = video['format']\n            ext = determine_ext(video_url)\n            if ext == 'f4m':\n                if georestricted:\n                    # See https://github.com/rg3/youtube-dl/issues/3963\n                    # m3u8 urls work fine\n                    continue\n                f4m_url = self._download_webpage(\n                    'http://hdfauth.francetv.fr/esi/TA?url=%s' % video_url,\n                    video_id, 'Downloading f4m manifest token', fatal=False)\n                if f4m_url:\n                    formats.extend(self._extract_f4m_formats(\n                        f4m_url + '&hdcore=3.7.0&plugin=aasp-3.7.0.39.44', video_id, 1, format_id))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(video_url, video_id, 'mp4', m3u8_id=format_id))\n            elif video_url.startswith('rtmp'):\n                formats.append({\n                    'url': video_url,\n                    'format_id': 'rtmp-%s' % format_id,\n                    'ext': 'flv',\n                    'preference': 1,\n                })\n            else:\n                formats.append({\n                    'url': video_url,\n                    'format_id': format_id,\n                    'preference': -1,\n                })\n        self._sort_formats(formats)\n\n        title = info['titre']\n        subtitle = info.get('sous_titre')\n        if subtitle:\n            title += ' - %s' % subtitle\n\n        subtitles = {}\n        subtitles_list = [{\n            'url': subformat['url'],\n            'ext': subformat.get('format'),\n        } for subformat in info.get('subtitles', []) if subformat.get('url')]\n        if subtitles_list:\n            subtitles['fr'] = subtitles_list\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': clean_html(info['synopsis']),\n            'thumbnail': compat_urlparse.urljoin('http://pluzz.francetv.fr', info['image']),\n            'duration': int_or_none(info.get('real_duration')) or parse_duration(info['duree']),\n            'timestamp': int_or_none(info['diffusion']['timestamp']),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 21,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.PluzzIE._real_extract#112",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.PluzzIE",
        "signature": "youtube_dl.extractor.francetv.PluzzIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._html_search_meta(\n            'id_video', webpage, 'video id', default=None)\n        if not video_id:\n            video_id = self._search_regex(\n                r'data-diffusion=[\"\\'](\\d+)', webpage, 'video id')\n\n        return self._extract_video(video_id, 'Pluzz')",
        "begin_line": 112,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTvInfoIE._real_extract#165",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTvInfoIE",
        "signature": "youtube_dl.extractor.francetv.FranceTvInfoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n\n        dmcloud_url = DailymotionCloudIE._extract_dmcloud_url(webpage)\n        if dmcloud_url:\n            return self.url_result(dmcloud_url, 'DailymotionCloud')\n\n        video_id, catalogue = self._search_regex(\n            r'id-video=([^@]+@[^\"]+)', webpage, 'video id').split('@')\n        return self._extract_video(video_id, catalogue)",
        "begin_line": 165,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTVIE._real_extract#288",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTVIE",
        "signature": "youtube_dl.extractor.francetv.FranceTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video_id, catalogue = self._html_search_regex(\n            r'href=\"http://videos?\\.francetv\\.fr/video/([^@]+@[^\"]+)\"',\n            webpage, 'video ID').split('@')\n        return self._extract_video(video_id, catalogue)",
        "begin_line": 288,
        "end_line": 294,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.GenerationQuoiIE._real_extract#315",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.GenerationQuoiIE",
        "signature": "youtube_dl.extractor.francetv.GenerationQuoiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        info_url = compat_urlparse.urljoin(url, '/medias/video/%s.json' % display_id)\n        info_json = self._download_webpage(info_url, display_id)\n        info = json.loads(info_json)\n        return self.url_result('http://www.dailymotion.com/video/%s' % info['id'],\n                               ie='Dailymotion')",
        "begin_line": 315,
        "end_line": 321,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.CultureboxIE._real_extract#342",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.CultureboxIE",
        "signature": "youtube_dl.extractor.francetv.CultureboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n\n        webpage = self._download_webpage(url, name)\n\n        if \">Ce live n'est plus disponible en replay<\" in webpage:\n            raise ExtractorError('Video %s is not available' % name, expected=True)\n\n        video_id, catalogue = self._search_regex(\n            r'\"http://videos\\.francetv\\.fr/video/([^@]+@[^\"]+)\"', webpage, 'video id').split('@')\n\n        return self._extract_video(video_id, catalogue)",
        "begin_line": 342,
        "end_line": 354,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pornovoisines.PornoVoisinesIE.build_video_url#43",
        "src_path": "youtube_dl/extractor/pornovoisines.py",
        "class_name": "youtube_dl.extractor.pornovoisines.PornoVoisinesIE",
        "signature": "youtube_dl.extractor.pornovoisines.PornoVoisinesIE.build_video_url(cls, num)",
        "snippet": "    def build_video_url(cls, num):\n        return cls._VIDEO_URL_TEMPLATE % (random.choice(cls._SERVER_NUMBERS), num)",
        "begin_line": 43,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pornovoisines.PornoVoisinesIE._real_extract#46",
        "src_path": "youtube_dl/extractor/pornovoisines.py",
        "class_name": "youtube_dl.extractor.pornovoisines.PornoVoisinesIE",
        "signature": "youtube_dl.extractor.pornovoisines.PornoVoisinesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self.build_video_url(video_id)\n\n        title = self._html_search_regex(\n            r'<h1>(.+?)</h1>', webpage, 'title', flags=re.DOTALL)\n        description = self._html_search_regex(\n            r'<article id=\"descriptif\">(.+?)</article>',\n            webpage, \"description\", fatal=False, flags=re.DOTALL)\n\n        thumbnail = self._search_regex(\n            r'<div id=\"mediaspace%s\">\\s*<img src=\"/?([^\"]+)\"' % video_id,\n            webpage, 'thumbnail', fatal=False)\n        if thumbnail:\n            thumbnail = 'http://www.pornovoisines.com/%s' % thumbnail\n\n        upload_date = unified_strdate(self._search_regex(\n            r'Publi\u00e9 le ([\\d-]+)', webpage, 'upload date', fatal=False))\n        duration = int_or_none(self._search_regex(\n            'Dur\u00e9e (\\d+)', webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._search_regex(\n            r'(\\d+) vues', webpage, 'view count', fatal=False))\n        average_rating = self._search_regex(\n            r'Note\\s*:\\s*(\\d+(?:,\\d+)?)', webpage, 'average rating', fatal=False)\n        if average_rating:\n            average_rating = float_or_none(average_rating.replace(',', '.'))\n\n        categories = self._html_search_meta(\n            'keywords', webpage, 'categories', fatal=False)\n        if categories:\n            categories = [category.strip() for category in categories.split(',')]\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'view_count': view_count,\n            'average_rating': average_rating,\n            'categories': categories,\n            'age_limit': 18,\n        }",
        "begin_line": 46,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.morningstar.MorningstarIE._real_extract#24",
        "src_path": "youtube_dl/extractor/morningstar.py",
        "class_name": "youtube_dl.extractor.morningstar.MorningstarIE",
        "signature": "youtube_dl.extractor.morningstar.MorningstarIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(\n            r'<h1 id=\"titleLink\">(.*?)</h1>', webpage, 'title')\n        video_url = self._html_search_regex(\n            r'<input type=\"hidden\" id=\"hidVideoUrl\" value=\"([^\"]+)\"',\n            webpage, 'video URL')\n        thumbnail = self._html_search_regex(\n            r'<input type=\"hidden\" id=\"hidSnapshot\" value=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n        description = self._html_search_regex(\n            r'<div id=\"mstarDeck\".*?>(.*?)</div>',\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 24,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tinypic.TinyPicIE._real_extract#30",
        "src_path": "youtube_dl/extractor/tinypic.py",
        "class_name": "youtube_dl.extractor.tinypic.TinyPicIE",
        "signature": "youtube_dl.extractor.tinypic.TinyPicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id, 'Downloading page')\n\n        mobj = re.search(r'(?m)fo\\.addVariable\\(\"file\",\\s\"(?P<fileid>[\\da-z]+)\"\\);\\n'\n                         '\\s+fo\\.addVariable\\(\"s\",\\s\"(?P<serverid>\\d+)\"\\);', webpage)\n        if mobj is None:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        file_id = mobj.group('fileid')\n        server_id = mobj.group('serverid')\n\n        KEYWORDS_SUFFIX = ', Video, images, photos, videos, myspace, ebay, video hosting, photo hosting'\n        keywords = self._html_search_meta('keywords', webpage, 'title')\n        title = keywords[:-len(KEYWORDS_SUFFIX)] if keywords.endswith(KEYWORDS_SUFFIX) else ''\n\n        video_url = 'http://v%s.tinypic.com/%s.flv' % (server_id, file_id)\n        thumbnail = 'http://v%s.tinypic.com/%s_th.jpg' % (server_id, file_id)\n\n        return {\n            'id': file_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title\n        }",
        "begin_line": 30,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tmz.TMZIE._real_extract#22",
        "src_path": "youtube_dl/extractor/tmz.py",
        "class_name": "youtube_dl.extractor.tmz.TMZIE",
        "signature": "youtube_dl.extractor.tmz.TMZIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        return {\n            'id': video_id,\n            'url': self._html_search_meta('VideoURL', webpage, fatal=True),\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._html_search_meta('ThumbURL', webpage),\n        }",
        "begin_line": 22,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tmz.TMZArticleIE._real_extract#48",
        "src_path": "youtube_dl/extractor/tmz.py",
        "class_name": "youtube_dl.extractor.tmz.TMZArticleIE",
        "signature": "youtube_dl.extractor.tmz.TMZArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        embedded_video_info_str = self._html_search_regex(\n            r'tmzVideoEmbedV2\\(\"([^)]+)\"\\);', webpage, 'embedded video info')\n\n        embedded_video_info = self._parse_json(\n            embedded_video_info_str, video_id,\n            transform_source=lambda s: s.replace('\\\\', ''))\n\n        return self.url_result(\n            'http://www.tmz.com/videos/%s/' % embedded_video_info['id'])",
        "begin_line": 48,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pinkbike.PinkbikeIE._real_extract#39",
        "src_path": "youtube_dl/extractor/pinkbike.py",
        "class_name": "youtube_dl.extractor.pinkbike.PinkbikeIE",
        "signature": "youtube_dl.extractor.pinkbike.PinkbikeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.pinkbike.com/video/%s' % video_id, video_id)\n\n        formats = []\n        for _, format_id, src in re.findall(\n                r'data-quality=((?:\\\\)?[\"\\'])(.+?)\\1[^>]+src=\\1(.+?)\\1', webpage):\n            height = int_or_none(self._search_regex(\n                r'^(\\d+)[pP]$', format_id, 'height', default=None))\n            formats.append({\n                'url': src,\n                'format_id': format_id,\n                'height': height,\n            })\n        self._sort_formats(formats)\n\n        title = remove_end(self._og_search_title(webpage), ' Video - Pinkbike')\n        description = self._html_search_regex(\n            r'(?s)id=\"media-description\"[^>]*>(.+?)<',\n            webpage, 'description', default=None) or remove_start(\n            self._og_search_description(webpage), title + '. ')\n        thumbnail = self._og_search_thumbnail(webpage)\n        duration = int_or_none(self._html_search_meta(\n            'video:duration', webpage, 'duration'))\n\n        uploader = self._search_regex(\n            r'un:\\s*\"([^\"]+)\"', webpage, 'uploader', fatal=False)\n        upload_date = unified_strdate(self._search_regex(\n            r'class=\"fullTime\"[^>]+title=\"([^\"]+)\"',\n            webpage, 'upload date', fatal=False))\n\n        location = self._html_search_regex(\n            r'(?s)<dt>Location</dt>\\s*<dd>(.+?)<',\n            webpage, 'location', fatal=False)\n\n        def extract_count(webpage, label):\n            return str_to_int(self._search_regex(\n                r'<span[^>]+class=\"stat-num\"[^>]*>([\\d,.]+)</span>\\s*<span[^>]+class=\"stat-label\"[^>]*>%s' % label,\n                webpage, label, fatal=False))\n\n        view_count = extract_count(webpage, 'Views')\n        comment_count = extract_count(webpage, 'Comments')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'upload_date': upload_date,\n            'uploader': uploader,\n            'location': location,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats\n        }",
        "begin_line": 39,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mdr.MDRIE._real_extract#65",
        "src_path": "youtube_dl/extractor/mdr.py",
        "class_name": "youtube_dl.extractor.mdr.MDRIE",
        "signature": "youtube_dl.extractor.mdr.MDRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        data_url = self._search_regex(\n            r'dataURL\\s*:\\s*([\"\\'])(?P<url>/.+/(?:video|audio)[0-9]+-avCustom\\.xml)\\1',\n            webpage, 'data url', group='url')\n\n        doc = self._download_xml(\n            compat_urlparse.urljoin(url, data_url), video_id)\n\n        title = xpath_text(doc, ['./title', './broadcast/broadcastName'], 'title', fatal=True)\n\n        formats = []\n        processed_urls = []\n        for asset in doc.findall('./assets/asset'):\n            for source in (\n                    'progressiveDownload',\n                    'dynamicHttpStreamingRedirector',\n                    'adaptiveHttpStreamingRedirector'):\n                url_el = asset.find('./%sUrl' % source)\n                if url_el is None:\n                    continue\n\n                video_url = url_el.text\n                if video_url in processed_urls:\n                    continue\n\n                processed_urls.append(video_url)\n\n                vbr = int_or_none(xpath_text(asset, './bitrateVideo', 'vbr'), 1000)\n                abr = int_or_none(xpath_text(asset, './bitrateAudio', 'abr'), 1000)\n\n                ext = determine_ext(url_el.text)\n                if ext == 'm3u8':\n                    url_formats = self._extract_m3u8_formats(\n                        video_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                        preference=0, m3u8_id='HLS', fatal=False)\n                elif ext == 'f4m':\n                    url_formats = self._extract_f4m_formats(\n                        video_url + '?hdcore=3.7.0&plugin=aasp-3.7.0.39.44', video_id,\n                        preference=0, f4m_id='HDS', fatal=False)\n                else:\n                    media_type = xpath_text(asset, './mediaType', 'media type', default='MP4')\n                    vbr = int_or_none(xpath_text(asset, './bitrateVideo', 'vbr'), 1000)\n                    abr = int_or_none(xpath_text(asset, './bitrateAudio', 'abr'), 1000)\n                    filesize = int_or_none(xpath_text(asset, './fileSize', 'file size'))\n\n                    f = {\n                        'url': video_url,\n                        'format_id': '%s-%d' % (media_type, vbr or abr),\n                        'filesize': filesize,\n                        'abr': abr,\n                        'preference': 1,\n                    }\n\n                    if vbr:\n                        width = int_or_none(xpath_text(asset, './frameWidth', 'width'))\n                        height = int_or_none(xpath_text(asset, './frameHeight', 'height'))\n                        f.update({\n                            'vbr': vbr,\n                            'width': width,\n                            'height': height,\n                        })\n\n                    url_formats = [f]\n\n                if not url_formats:\n                    continue\n\n                if not vbr:\n                    for f in url_formats:\n                        abr = f.get('tbr') or abr\n                        if 'tbr' in f:\n                            del f['tbr']\n                        f.update({\n                            'abr': abr,\n                            'vcodec': 'none',\n                        })\n\n                formats.extend(url_formats)\n\n        self._sort_formats(formats)\n\n        description = xpath_text(doc, './broadcast/broadcastDescription', 'description')\n        timestamp = parse_iso8601(\n            xpath_text(\n                doc, [\n                    './broadcast/broadcastDate',\n                    './broadcast/broadcastStartDate',\n                    './broadcast/broadcastEndDate'],\n                'timestamp', default=None))\n        duration = parse_duration(xpath_text(doc, './duration', 'duration'))\n        uploader = xpath_text(doc, './rights', 'uploader')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'duration': duration,\n            'uploader': uploader,\n            'formats': formats,\n        }",
        "begin_line": 65,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nerdcubed.NerdCubedFeedIE._real_extract#20",
        "src_path": "youtube_dl/extractor/nerdcubed.py",
        "class_name": "youtube_dl.extractor.nerdcubed.NerdCubedFeedIE",
        "signature": "youtube_dl.extractor.nerdcubed.NerdCubedFeedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        feed = self._download_json(url, url, \"Downloading NerdCubed JSON feed\")\n\n        entries = [{\n            '_type': 'url',\n            'title': feed_entry['title'],\n            'uploader': feed_entry['source']['name'] if feed_entry['source'] else None,\n            'upload_date': datetime.datetime.strptime(feed_entry['date'], '%Y-%m-%d').strftime('%Y%m%d'),\n            'url': \"http://www.youtube.com/watch?v=\" + feed_entry['youtube_id'],\n        } for feed_entry in feed]\n\n        return {\n            '_type': 'playlist',\n            'title': 'nerdcubed.co.uk feed',\n            'id': 'nerdcubed-feed',\n            'entries': entries,\n        }",
        "begin_line": 20,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tvigle.TvigleIE._real_extract#53",
        "src_path": "youtube_dl/extractor/tvigle.py",
        "class_name": "youtube_dl.extractor.tvigle.TvigleIE",
        "signature": "youtube_dl.extractor.tvigle.TvigleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        if not video_id:\n            webpage = self._download_webpage(url, display_id)\n            video_id = self._html_search_regex(\n                r'class=\"video-preview current_playing\" id=\"(\\d+)\">',\n                webpage, 'video id')\n\n        video_data = self._download_json(\n            'http://cloud.tvigle.ru/api/play/video/%s/' % video_id, display_id)\n\n        item = video_data['playlist']['items'][0]\n\n        videos = item.get('videos')\n\n        error_message = item.get('errorMessage')\n        if not videos and error_message:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error_message), expected=True)\n\n        title = item['title']\n        description = item.get('description')\n        thumbnail = item.get('thumbnail')\n        duration = float_or_none(item.get('durationMilliseconds'), 1000)\n        age_limit = parse_age_limit(item.get('ageRestrictions'))\n\n        formats = []\n        for vcodec, fmts in item['videos'].items():\n            for format_id, video_url in fmts.items():\n                if format_id == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        video_url, video_id, 'mp4', m3u8_id=vcodec))\n                    continue\n                height = self._search_regex(\n                    r'^(\\d+)[pP]$', format_id, 'height', default=None)\n                formats.append({\n                    'url': video_url,\n                    'format_id': '%s-%s' % (vcodec, format_id),\n                    'vcodec': vcodec,\n                    'height': int_or_none(height),\n                    'filesize': int_or_none(item.get('video_files_size', {}).get(vcodec, {}).get(format_id)),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 53,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.r7.R7IE._real_extract#44",
        "src_path": "youtube_dl/extractor/r7.py",
        "class_name": "youtube_dl.extractor.r7.R7IE",
        "signature": "youtube_dl.extractor.r7.R7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://player.r7.com/video/i/%s' % video_id, video_id)\n\n        item = self._parse_json(js_to_json(self._search_regex(\n            r'(?s)var\\s+item\\s*=\\s*({.+?});', webpage, 'player')), video_id)\n\n        title = unescapeHTML(item['title'])\n        thumbnail = item.get('init', {}).get('thumbUri')\n        duration = None\n\n        statistics = item.get('statistics', {})\n        like_count = int_or_none(statistics.get('likes'))\n        view_count = int_or_none(statistics.get('views'))\n\n        formats = []\n        for format_key, format_dict in item['playlist'][0].items():\n            src = format_dict.get('src')\n            if not src:\n                continue\n            format_id = format_dict.get('format') or format_key\n            if duration is None:\n                duration = format_dict.get('duration')\n            if '.f4m' in src:\n                formats.extend(self._extract_f4m_formats(src, video_id, preference=-1))\n            elif src.endswith('.m3u8'):\n                formats.extend(self._extract_m3u8_formats(src, video_id, 'mp4', preference=-2))\n            else:\n                formats.append({\n                    'url': src,\n                    'format_id': format_id,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'like_count': like_count,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 44,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._real_extract#79",
        "src_path": "youtube_dl/extractor/ceskatelevize.py",
        "class_name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE",
        "signature": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url = url.replace('/porady/', '/ivysilani/').replace('/video/', '')\n\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        NOT_AVAILABLE_STRING = 'This content is not available at your territory due to limited copyright.'\n        if '%s</p>' % NOT_AVAILABLE_STRING in webpage:\n            raise ExtractorError(NOT_AVAILABLE_STRING, expected=True)\n\n        typ = self._html_search_regex(\n            r'getPlaylistUrl\\(\\[\\{\"type\":\"(.+?)\",\"id\":\".+?\"\\}\\],', webpage, 'type')\n        episode_id = self._html_search_regex(\n            r'getPlaylistUrl\\(\\[\\{\"type\":\".+?\",\"id\":\"(.+?)\"\\}\\],', webpage, 'episode_id')\n\n        data = {\n            'playlist[0][type]': typ,\n            'playlist[0][id]': episode_id,\n            'requestUrl': compat_urllib_parse_urlparse(url).path,\n            'requestSource': 'iVysilani',\n        }\n\n        req = compat_urllib_request.Request(\n            'http://www.ceskatelevize.cz/ivysilani/ajax/get-client-playlist',\n            data=compat_urllib_parse.urlencode(data))\n\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n        req.add_header('x-addr', '127.0.0.1')\n        req.add_header('X-Requested-With', 'XMLHttpRequest')\n        req.add_header('Referer', url)\n\n        playlistpage = self._download_json(req, playlist_id)\n\n        playlist_url = playlistpage['url']\n        if playlist_url == 'error_region':\n            raise ExtractorError(NOT_AVAILABLE_STRING, expected=True)\n\n        req = compat_urllib_request.Request(compat_urllib_parse_unquote(playlist_url))\n        req.add_header('Referer', url)\n\n        playlist_title = self._og_search_title(webpage)\n        playlist_description = self._og_search_description(webpage)\n\n        playlist = self._download_json(req, playlist_id)['playlist']\n        playlist_len = len(playlist)\n\n        entries = []\n        for item in playlist:\n            formats = []\n            for format_id, stream_url in item['streamUrls'].items():\n                formats.extend(self._extract_m3u8_formats(\n                    stream_url, playlist_id, 'mp4', entry_protocol='m3u8_native'))\n            self._sort_formats(formats)\n\n            item_id = item.get('id') or item['assetId']\n            title = item['title']\n\n            duration = float_or_none(item.get('duration'))\n            thumbnail = item.get('previewImageUrl')\n\n            subtitles = {}\n            if item.get('type') == 'VOD':\n                subs = item.get('subtitles')\n                if subs:\n                    subtitles = self.extract_subtitles(episode_id, subs)\n\n            entries.append({\n                'id': item_id,\n                'title': playlist_title if playlist_len == 1 else '%s (%s)' % (playlist_title, title),\n                'description': playlist_description if playlist_len == 1 else None,\n                'thumbnail': thumbnail,\n                'duration': duration,\n                'formats': formats,\n                'subtitles': subtitles,\n            })\n\n        return self.playlist_result(entries, playlist_id, playlist_title, playlist_description)",
        "begin_line": 79,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._get_subtitles#159",
        "src_path": "youtube_dl/extractor/ceskatelevize.py",
        "class_name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE",
        "signature": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._get_subtitles(self, episode_id, subs)",
        "snippet": "    def _get_subtitles(self, episode_id, subs):\n        original_subtitles = self._download_webpage(\n            subs[0]['url'], episode_id, 'Downloading subtitles')\n        srt_subs = self._fix_subtitles(original_subtitles)\n        return {\n            'cs': [{\n                'ext': 'srt',\n                'data': srt_subs,\n            }]\n        }",
        "begin_line": 159,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._fix_subtitles#171",
        "src_path": "youtube_dl/extractor/ceskatelevize.py",
        "class_name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE",
        "signature": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._fix_subtitles(subtitles)",
        "snippet": "    def _fix_subtitles(subtitles):\n        \"\"\" Convert millisecond-based subtitles to SRT \"\"\"\n\n        def _msectotimecode(msec):\n            \"\"\" Helper utility to convert milliseconds to timecode \"\"\"\n            components = []\n            for divider in [1000, 60, 60, 100]:\n                components.append(msec % divider)\n                msec //= divider\n            return \"{3:02}:{2:02}:{1:02},{0:03}\".format(*components)\n\n        def _fix_subtitle(subtitle):\n            for line in subtitle.splitlines():\n                m = re.match(r\"^\\s*([0-9]+);\\s*([0-9]+)\\s+([0-9]+)\\s*$\", line)\n                if m:\n                    yield m.group(1)\n                    start, stop = (_msectotimecode(int(t)) for t in m.groups()[1:])\n                    yield \"{0} --> {1}\".format(start, stop)\n                else:\n                    yield line\n\n        return \"\\r\\n\".join(_fix_subtitle(subtitles))",
        "begin_line": 171,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.musicplayon.MusicPlayOnIE._real_extract#29",
        "src_path": "youtube_dl/extractor/musicplayon.py",
        "class_name": "youtube_dl.extractor.musicplayon.MusicPlayOnIE",
        "signature": "youtube_dl.extractor.musicplayon.MusicPlayOnIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(page)\n        description = self._og_search_description(page)\n        thumbnail = self._og_search_thumbnail(page)\n        duration = self._html_search_meta('video:duration', page, 'duration', fatal=False)\n        view_count = self._og_search_property('count', page, fatal=False)\n        uploader = self._html_search_regex(\n            r'<div>by&nbsp;<a href=\"[^\"]+\" class=\"purple\">([^<]+)</a></div>', page, 'uploader', fatal=False)\n\n        formats = [\n            {\n                'url': 'http://media0-eu-nl.musicplayon.com/stream-mobile?id=%s&type=.mp4' % video_id,\n                'ext': 'mp4',\n            }\n        ]\n\n        manifest = self._download_webpage(\n            'http://en.musicplayon.com/manifest.m3u8?v=%s' % video_id, video_id, 'Downloading manifest')\n\n        for entry in manifest.split('#')[1:]:\n            if entry.startswith('EXT-X-STREAM-INF:'):\n                meta, url, _ = entry.split('\\n')\n                params = dict(param.split('=') for param in meta.split(',')[1:])\n                formats.append({\n                    'url': url,\n                    'ext': 'mp4',\n                    'tbr': int(params['BANDWIDTH']),\n                    'width': int(params['RESOLUTION'].split('x')[1]),\n                    'height': int(params['RESOLUTION'].split('x')[-1]),\n                    'format_note': params['NAME'].replace('\"', '').strip(),\n                })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'duration': int_or_none(duration),\n            'view_count': int_or_none(view_count),\n            'formats': formats,\n        }",
        "begin_line": 29,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.aftonbladet.AftonbladetIE._real_extract#22",
        "src_path": "youtube_dl/extractor/aftonbladet.py",
        "class_name": "youtube_dl.extractor.aftonbladet.AftonbladetIE",
        "signature": "youtube_dl.extractor.aftonbladet.AftonbladetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        # find internal video meta data\n        meta_url = 'http://aftonbladet-play.drlib.aptoma.no/video/%s.json'\n        player_config = self._parse_json(self._html_search_regex(\n            r'data-player-config=\"([^\"]+)\"', webpage, 'player config'), video_id)\n        internal_meta_id = player_config['videoId']\n        internal_meta_url = meta_url % internal_meta_id\n        internal_meta_json = self._download_json(\n            internal_meta_url, video_id, 'Downloading video meta data')\n\n        # find internal video formats\n        format_url = 'http://aftonbladet-play.videodata.drvideo.aptoma.no/actions/video/?id=%s'\n        internal_video_id = internal_meta_json['videoId']\n        internal_formats_url = format_url % internal_video_id\n        internal_formats_json = self._download_json(\n            internal_formats_url, video_id, 'Downloading video formats')\n\n        formats = []\n        for fmt in internal_formats_json['formats']['http']['pseudostreaming']['mp4']:\n            p = fmt['paths'][0]\n            formats.append({\n                'url': 'http://%s:%d/%s/%s' % (p['address'], p['port'], p['path'], p['filename']),\n                'ext': 'mp4',\n                'width': int_or_none(fmt.get('width')),\n                'height': int_or_none(fmt.get('height')),\n                'tbr': int_or_none(fmt.get('bitrate')),\n                'protocol': 'http',\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': internal_meta_json['title'],\n            'formats': formats,\n            'thumbnail': internal_meta_json.get('imageUrl'),\n            'description': internal_meta_json.get('shortPreamble'),\n            'timestamp': int_or_none(internal_meta_json.get('timePublished')),\n            'duration': int_or_none(internal_meta_json.get('duration')),\n            'view_count': int_or_none(internal_meta_json.get('views')),\n        }",
        "begin_line": 22,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dropbox.DropboxIE._real_extract#28",
        "src_path": "youtube_dl/extractor/dropbox.py",
        "class_name": "youtube_dl.extractor.dropbox.DropboxIE",
        "signature": "youtube_dl.extractor.dropbox.DropboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        fn = compat_urllib_parse_unquote(url_basename(url))\n        title = os.path.splitext(fn)[0]\n        video_url = re.sub(r'[?&]dl=0', '', url)\n        video_url += ('?' if '?' not in video_url else '&') + 'dl=1'\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 28,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.wat.WatIE.download_video_info#47",
        "src_path": "youtube_dl/extractor/wat.py",
        "class_name": "youtube_dl.extractor.wat.WatIE",
        "signature": "youtube_dl.extractor.wat.WatIE.download_video_info(self, real_id)",
        "snippet": "    def download_video_info(self, real_id):\n        # 'contentv4' is used in the website, but it also returns the related\n        # videos, we don't need them\n        info = self._download_json('http://www.wat.tv/interface/contentv3/' + real_id, real_id)\n        return info['media']",
        "begin_line": 47,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.wat.WatIE._real_extract#53",
        "src_path": "youtube_dl/extractor/wat.py",
        "class_name": "youtube_dl.extractor.wat.WatIE",
        "signature": "youtube_dl.extractor.wat.WatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        def real_id_for_chapter(chapter):\n            return chapter['tc_start'].split('-')[0]\n        mobj = re.match(self._VALID_URL, url)\n        short_id = mobj.group('short_id')\n        display_id = mobj.group('display_id')\n        webpage = self._download_webpage(url, display_id or short_id)\n        real_id = self._search_regex(r'xtpage = \".*-(.*?)\";', webpage, 'real id')\n\n        video_info = self.download_video_info(real_id)\n\n        error_desc = video_info.get('error_desc')\n        if error_desc:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error_desc), expected=True)\n\n        geo_list = video_info.get('geoList')\n        country = geo_list[0] if geo_list else ''\n\n        chapters = video_info['chapters']\n        first_chapter = chapters[0]\n        files = video_info['files']\n        first_file = files[0]\n\n        if real_id_for_chapter(first_chapter) != real_id:\n            self.to_screen('Multipart video detected')\n            chapter_urls = []\n            for chapter in chapters:\n                chapter_id = real_id_for_chapter(chapter)\n                # Yes, when we this chapter is processed by WatIE,\n                # it will download the info again\n                chapter_info = self.download_video_info(chapter_id)\n                chapter_urls.append(chapter_info['url'])\n            entries = [self.url_result(chapter_url) for chapter_url in chapter_urls]\n            return self.playlist_result(entries, real_id, video_info['title'])\n\n        upload_date = None\n        if 'date_diffusion' in first_chapter:\n            upload_date = unified_strdate(first_chapter['date_diffusion'])\n        # Otherwise we can continue and extract just one part, we have to use\n        # the short id for getting the video url\n\n        formats = [{\n            'url': 'http://wat.tv/get/android5/%s.mp4' % real_id,\n            'format_id': 'Mobile',\n        }]\n\n        fmts = [('SD', 'web')]\n        if first_file.get('hasHD'):\n            fmts.append(('HD', 'webhd'))\n\n        def compute_token(param):\n            timestamp = '%08x' % int(self._download_webpage(\n                'http://www.wat.tv/servertime', real_id,\n                'Downloading server time').split('|')[0])\n            magic = '9b673b13fa4682ed14c3cfa5af5310274b514c4133e9b3a81e6e3aba009l2564'\n            return '%s/%s' % (hashlib.md5((magic + param + timestamp).encode('ascii')).hexdigest(), timestamp)\n\n        for fmt in fmts:\n            webid = '/%s/%s' % (fmt[1], real_id)\n            video_url = self._download_webpage(\n                'http://www.wat.tv/get%s?token=%s&getURL=1&country=%s' % (webid, compute_token(webid), country),\n                real_id,\n                'Downloading %s video URL' % fmt[0],\n                'Failed to download %s video URL' % fmt[0],\n                False)\n            if not video_url:\n                continue\n            formats.append({\n                'url': video_url,\n                'ext': 'mp4',\n                'format_id': fmt[0],\n            })\n\n        return {\n            'id': real_id,\n            'display_id': display_id,\n            'title': first_chapter['title'],\n            'thumbnail': first_chapter['preview'],\n            'description': first_chapter['description'],\n            'view_count': video_info['views'],\n            'upload_date': upload_date,\n            'duration': first_file['duration'],\n            'formats': formats,\n        }",
        "begin_line": 53,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.periscope.PeriscopeIE._call_api#30",
        "src_path": "youtube_dl/extractor/periscope.py",
        "class_name": "youtube_dl.extractor.periscope.PeriscopeIE",
        "signature": "youtube_dl.extractor.periscope.PeriscopeIE._call_api(self, method, token)",
        "snippet": "    def _call_api(self, method, token):\n        return self._download_json(\n            'https://api.periscope.tv/api/v2/%s?token=%s' % (method, token), token)",
        "begin_line": 30,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.periscope.PeriscopeIE._real_extract#34",
        "src_path": "youtube_dl/extractor/periscope.py",
        "class_name": "youtube_dl.extractor.periscope.PeriscopeIE",
        "signature": "youtube_dl.extractor.periscope.PeriscopeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        token = self._match_id(url)\n\n        broadcast_data = self._call_api('getBroadcastPublic', token)\n        broadcast = broadcast_data['broadcast']\n        status = broadcast['status']\n\n        uploader = broadcast.get('user_display_name') or broadcast_data.get('user', {}).get('display_name')\n        uploader_id = broadcast.get('user_id') or broadcast_data.get('user', {}).get('id')\n\n        title = '%s - %s' % (uploader, status) if uploader else status\n        state = broadcast.get('state').lower()\n        if state == 'running':\n            title = self._live_title(title)\n        timestamp = parse_iso8601(broadcast.get('created_at'))\n\n        thumbnails = [{\n            'url': broadcast[image],\n        } for image in ('image_url', 'image_url_small') if broadcast.get(image)]\n\n        stream = self._call_api('getAccessPublic', token)\n\n        formats = []\n        for format_id in ('replay', 'rtmp', 'hls', 'https_hls'):\n            video_url = stream.get(format_id + '_url')\n            if not video_url:\n                continue\n            f = {\n                'url': video_url,\n                'ext': 'flv' if format_id == 'rtmp' else 'mp4',\n            }\n            if format_id != 'rtmp':\n                f['protocol'] = 'm3u8_native' if state == 'ended' else 'm3u8'\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': broadcast.get('id') or token,\n            'title': title,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.periscope.QuickscopeIE._real_extract#89",
        "src_path": "youtube_dl/extractor/periscope.py",
        "class_name": "youtube_dl.extractor.periscope.QuickscopeIE",
        "signature": "youtube_dl.extractor.periscope.QuickscopeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        broadcast_id = self._match_id(url)\n        request = compat_urllib_request.Request(\n            'https://watchonperiscope.com/api/accessChannel', compat_urllib_parse.urlencode({\n                'broadcast_id': broadcast_id,\n                'entry_ticket': '',\n                'from_push': 'false',\n                'uses_sessions': 'true',\n            }).encode('utf-8'))\n        return self.url_result(\n            self._download_json(request, broadcast_id)['share_url'], 'Periscope')",
        "begin_line": 89,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cinchcast.CinchcastIE._real_extract#19",
        "src_path": "youtube_dl/extractor/cinchcast.py",
        "class_name": "youtube_dl.extractor.cinchcast.CinchcastIE",
        "signature": "youtube_dl.extractor.cinchcast.CinchcastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        doc = self._download_xml(\n            'http://www.blogtalkradio.com/playerasset/mrss?assetType=single&assetId=%s' % video_id,\n            video_id)\n\n        item = doc.find('.//item')\n        title = xpath_text(item, './title', fatal=True)\n        date_str = xpath_text(\n            item, './{http://developer.longtailvideo.com/trac/}date')\n        upload_date = unified_strdate(date_str, day_first=False)\n        # duration is present but wrong\n        formats = [{\n            'format_id': 'main',\n            'url': item.find('./{http://search.yahoo.com/mrss/}content').attrib['url'],\n        }]\n        backup_url = xpath_text(\n            item, './{http://developer.longtailvideo.com/trac/}backupContent')\n        if backup_url:\n            formats.append({\n                'preference': 2,  # seems to be more reliable\n                'format_id': 'backup',\n                'url': backup_url,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 19,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cinemassacre.CinemassacreIE._real_extract#78",
        "src_path": "youtube_dl/extractor/cinemassacre.py",
        "class_name": "youtube_dl.extractor.cinemassacre.CinemassacreIE",
        "signature": "youtube_dl.extractor.cinemassacre.CinemassacreIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n        video_date = mobj.group('date_y') + mobj.group('date_m') + mobj.group('date_d')\n\n        webpage = self._download_webpage(url, display_id)\n\n        playerdata_url = self._search_regex(\n            [\n                ScreenwaveMediaIE.EMBED_PATTERN,\n                r'<iframe[^>]+src=\"(?P<url>(?:https?:)?//(?:[^.]+\\.)?youtube\\.com/.+?)\"',\n            ],\n            webpage, 'player data URL', default=None, group='url')\n        if not playerdata_url:\n            playerdata_url = BlipTVIE._extract_url(webpage)\n        if not playerdata_url:\n            raise ExtractorError('Unable to find player data')\n\n        video_title = self._html_search_regex(\n            r'<title>(?P<title>.+?)\\|', webpage, 'title')\n        video_description = self._html_search_regex(\n            r'<div class=\"entry-content\">(?P<description>.+?)</div>',\n            webpage, 'description', flags=re.DOTALL, fatal=False)\n        video_thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            '_type': 'url_transparent',\n            'display_id': display_id,\n            'title': video_title,\n            'description': video_description,\n            'upload_date': video_date,\n            'thumbnail': video_thumbnail,\n            'url': playerdata_url,\n        }",
        "begin_line": 78,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.svt.SVTBaseIE._extract_video#13",
        "src_path": "youtube_dl/extractor/svt.py",
        "class_name": "youtube_dl.extractor.svt.SVTBaseIE",
        "signature": "youtube_dl.extractor.svt.SVTBaseIE._extract_video(self, url, video_id)",
        "snippet": "    def _extract_video(self, url, video_id):\n        info = self._download_json(url, video_id)\n\n        title = info['context']['title']\n        thumbnail = info['context'].get('thumbnailImage')\n\n        video_info = info['video']\n        formats = []\n        for vr in video_info['videoReferences']:\n            vurl = vr['url']\n            ext = determine_ext(vurl)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    vurl, video_id,\n                    ext='mp4', entry_protocol='m3u8_native',\n                    m3u8_id=vr.get('playerType')))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    vurl + '?hdcore=3.3.0', video_id,\n                    f4m_id=vr.get('playerType')))\n            else:\n                formats.append({\n                    'format_id': vr.get('playerType'),\n                    'url': vurl,\n                })\n        self._sort_formats(formats)\n\n        duration = video_info.get('materialLength')\n        age_limit = 18 if video_info.get('inappropriateForChildren') else 0\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': age_limit,\n        }",
        "begin_line": 13,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.svt.SVTIE._extract_url#68",
        "src_path": "youtube_dl/extractor/svt.py",
        "class_name": "youtube_dl.extractor.svt.SVTIE",
        "signature": "youtube_dl.extractor.svt.SVTIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'(?:<iframe src|href)=\"(?P<url>%s[^\"]*)\"' % SVTIE._VALID_URL, webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 68,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.svt.SVTIE._real_extract#74",
        "src_path": "youtube_dl/extractor/svt.py",
        "class_name": "youtube_dl.extractor.svt.SVTIE",
        "signature": "youtube_dl.extractor.svt.SVTIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        widget_id = mobj.group('widget_id')\n        article_id = mobj.group('id')\n        return self._extract_video(\n            'http://www.svt.se/wd?widgetId=%s&articleId=%s&format=json&type=embed&output=json' % (widget_id, article_id),\n            article_id)",
        "begin_line": 74,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.svt.SVTPlayIE._real_extract#111",
        "src_path": "youtube_dl/extractor/svt.py",
        "class_name": "youtube_dl.extractor.svt.SVTPlayIE",
        "signature": "youtube_dl.extractor.svt.SVTPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        host = mobj.group('host')\n        return self._extract_video(\n            'http://www.%s.se/video/%s?output=json' % (host, video_id),\n            video_id)",
        "begin_line": 111,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.izlesene.IzleseneIE._real_extract#58",
        "src_path": "youtube_dl/extractor/izlesene.py",
        "class_name": "youtube_dl.extractor.izlesene.IzleseneIE",
        "signature": "youtube_dl.extractor.izlesene.IzleseneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        url = 'http://www.izlesene.com/video/%s' % video_id\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._proto_relative_url(\n            self._og_search_thumbnail(webpage), scheme='http:')\n\n        uploader = self._html_search_regex(\n            r\"adduserUsername\\s*=\\s*'([^']+)';\",\n            webpage, 'uploader', fatal=False)\n        timestamp = parse_iso8601(self._html_search_meta(\n            'uploadDate', webpage, 'upload date'))\n\n        duration = float_or_none(self._html_search_regex(\n            r'\"videoduration\"\\s*:\\s*\"([^\"]+)\"',\n            webpage, 'duration', fatal=False), scale=1000)\n\n        view_count = str_to_int(get_element_by_id('videoViewCount', webpage))\n        comment_count = self._html_search_regex(\n            r'comment_count\\s*=\\s*\\'([^\\']+)\\';',\n            webpage, 'comment_count', fatal=False)\n\n        content_url = self._html_search_meta(\n            'contentURL', webpage, 'content URL', fatal=False)\n        ext = determine_ext(content_url, 'mp4')\n\n        # Might be empty for some videos.\n        streams = self._html_search_regex(\n            r'\"qualitylevel\"\\s*:\\s*\"([^\"]+)\"', webpage, 'streams', default='')\n\n        formats = []\n        if streams:\n            for stream in streams.split('|'):\n                quality, url = re.search(r'\\[(\\w+)\\](.+)', stream).groups()\n                formats.append({\n                    'format_id': '%sp' % quality if quality else 'sd',\n                    'url': compat_urllib_parse_unquote(url),\n                    'ext': ext,\n                })\n        else:\n            stream_url = self._search_regex(\n                r'\"streamurl\"\\s*:\\s*\"([^\"]+)\"', webpage, 'stream URL')\n            formats.append({\n                'format_id': 'sd',\n                'url': compat_urllib_parse_unquote(stream_url),\n                'ext': ext,\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader_id': uploader,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': int_or_none(view_count),\n            'comment_count': int_or_none(comment_count),\n            'age_limit': self._family_friendly_search(webpage),\n            'formats': formats,\n        }",
        "begin_line": 58,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.parliamentliveuk.ParliamentLiveUKIE._real_extract#26",
        "src_path": "youtube_dl/extractor/parliamentliveuk.py",
        "class_name": "youtube_dl.extractor.parliamentliveuk.ParliamentLiveUKIE",
        "signature": "youtube_dl.extractor.parliamentliveuk.ParliamentLiveUKIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        asx_url = self._html_search_regex(\n            r'embed.*?src=\"([^\"]+)\" name=\"MediaPlayer\"', webpage,\n            'metadata URL')\n        asx = self._download_xml(asx_url, video_id, 'Downloading ASX metadata')\n        video_url = asx.find('.//REF').attrib['HREF']\n\n        title = self._search_regex(\n            r'''(?x)player\\.setClipDetails\\(\n                (?:(?:[0-9]+|\"[^\"]+\"),\\s*){2}\n                \"([^\"]+\",\\s*\"[^\"]+)\"\n                ''',\n            webpage, 'title').replace('\", \"', ', ')\n        description = self._html_search_regex(\n            r'(?s)<span id=\"MainContentPlaceHolder_CaptionsBlock_WitnessInfo\">(.*?)</span>',\n            webpage, 'description')\n\n        return {\n            'id': video_id,\n            'ext': 'asf',\n            'url': video_url,\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 26,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bild.BildIE._real_extract#27",
        "src_path": "youtube_dl/extractor/bild.py",
        "class_name": "youtube_dl.extractor.bild.BildIE",
        "signature": "youtube_dl.extractor.bild.BildIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_data = self._download_json(\n            url.split('.bild.html')[0] + ',view=json.bild.html', video_id)\n\n        return {\n            'id': video_id,\n            'title': unescapeHTML(video_data['title']).strip(),\n            'description': unescapeHTML(video_data.get('description')),\n            'url': video_data['clipList'][0]['srces'][0]['src'],\n            'thumbnail': video_data.get('poster'),\n            'duration': int_or_none(video_data.get('durationSec')),\n        }",
        "begin_line": 27,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.slutload.SlutloadIE._real_extract#22",
        "src_path": "youtube_dl/extractor/slutload.py",
        "class_name": "youtube_dl.extractor.slutload.SlutloadIE",
        "signature": "youtube_dl.extractor.slutload.SlutloadIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._html_search_regex(r'<h1><strong>([^<]+)</strong>',\n                                              webpage, 'title').strip()\n\n        video_url = self._html_search_regex(\n            r'(?s)<div id=\"vidPlayer\"\\s+data-url=\"([^\"]+)\"',\n            webpage, 'video URL')\n        thumbnail = self._html_search_regex(\n            r'(?s)<div id=\"vidPlayer\"\\s+.*?previewer-file=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'age_limit': 18\n        }",
        "begin_line": 22,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.fivemin.FiveMinIE._real_extract#93",
        "src_path": "youtube_dl/extractor/fivemin.py",
        "class_name": "youtube_dl.extractor.fivemin.FiveMinIE",
        "signature": "youtube_dl.extractor.fivemin.FiveMinIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        embed_url = 'https://embed.5min.com/playerseed/?playList=%s' % video_id\n        embed_page = self._download_webpage(embed_url, video_id,\n                                            'Downloading embed page')\n        sid = self._search_regex(r'sid=(\\d+)', embed_page, 'sid')\n        query = compat_urllib_parse.urlencode({\n            'func': 'GetResults',\n            'playlist': video_id,\n            'sid': sid,\n            'isPlayerSeed': 'true',\n            'url': embed_url,\n        })\n        response = self._download_json(\n            'https://syn.5min.com/handlers/SenseHandler.ashx?' + query,\n            video_id)\n        if not response['success']:\n            raise ExtractorError(\n                '%s said: %s' % (\n                    self.IE_NAME,\n                    self._ERRORS.get(response['errorMessage'], response['errorMessage'])),\n                expected=True)\n        info = response['binding'][0]\n\n        formats = []\n        parsed_video_url = compat_urllib_parse_urlparse(compat_parse_qs(\n            compat_urllib_parse_urlparse(info['EmbededURL']).query)['videoUrl'][0])\n        for rendition in info['Renditions']:\n            if rendition['RenditionType'] == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(rendition['Url'], video_id, m3u8_id='hls'))\n            elif rendition['RenditionType'] == 'aac':\n                continue\n            else:\n                rendition_url = compat_urlparse.urlunparse(parsed_video_url._replace(path=replace_extension(parsed_video_url.path.replace('//', '/%s/' % rendition['ID']), rendition['RenditionType'])))\n                quality = self._QUALITIES.get(rendition['ID'], {})\n                formats.append({\n                    'format_id': '%s-%d' % (rendition['RenditionType'], rendition['ID']),\n                    'url': rendition_url,\n                    'width': quality.get('width'),\n                    'height': quality.get('height'),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info['Title'],\n            'thumbnail': info.get('ThumbURL'),\n            'duration': parse_duration(info.get('Duration')),\n            'formats': formats,\n        }",
        "begin_line": 93,
        "end_line": 142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.slideshare.SlideshareIE._real_extract#28",
        "src_path": "youtube_dl/extractor/slideshare.py",
        "class_name": "youtube_dl.extractor.slideshare.SlideshareIE",
        "signature": "youtube_dl.extractor.slideshare.SlideshareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n        slideshare_obj = self._search_regex(\n            r'\\$\\.extend\\(slideshare_object,\\s*(\\{.*?\\})\\);',\n            webpage, 'slideshare object')\n        info = json.loads(slideshare_obj)\n        if info['slideshow']['type'] != 'video':\n            raise ExtractorError('Webpage type is \"%s\": only video extraction is supported for Slideshare' % info['slideshow']['type'], expected=True)\n\n        doc = info['doc']\n        bucket = info['jsplayer']['video_bucket']\n        ext = info['jsplayer']['video_extension']\n        video_url = compat_urlparse.urljoin(bucket, doc + '-SD.' + ext)\n        description = self._html_search_regex(\n            r'(?s)<p[^>]+itemprop=\"description\"[^>]*>(.+?)</p>', webpage,\n            'description', fatal=False)\n\n        return {\n            '_type': 'video',\n            'id': info['slideshow']['id'],\n            'title': info['slideshow']['title'],\n            'ext': ext,\n            'url': video_url,\n            'thumbnail': info['slideshow']['pin_image_url'],\n            'description': description,\n        }",
        "begin_line": 28,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.chirbit.ChirbitIE._real_extract#30",
        "src_path": "youtube_dl/extractor/chirbit.py",
        "class_name": "youtube_dl.extractor.chirbit.ChirbitIE",
        "signature": "youtube_dl.extractor.chirbit.ChirbitIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        audio_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://chirb.it/%s' % audio_id, audio_id)\n\n        audio_url = self._search_regex(\n            r'\"setFile\"\\s*,\\s*\"([^\"]+)\"', webpage, 'audio url')\n\n        title = self._search_regex(\n            r'itemprop=\"name\">([^<]+)', webpage, 'title')\n        duration = parse_duration(self._html_search_meta(\n            'duration', webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._search_regex(\n            r'itemprop=\"playCount\"\\s*>(\\d+)', webpage,\n            'listen count', fatal=False))\n        comment_count = int_or_none(self._search_regex(\n            r'>(\\d+) Comments?:', webpage,\n            'comment count', fatal=False))\n\n        return {\n            'id': audio_id,\n            'url': audio_url,\n            'title': title,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n        }",
        "begin_line": 30,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.chirbit.ChirbitProfileIE._real_extract#72",
        "src_path": "youtube_dl/extractor/chirbit.py",
        "class_name": "youtube_dl.extractor.chirbit.ChirbitProfileIE",
        "signature": "youtube_dl.extractor.chirbit.ChirbitProfileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        profile_id = self._match_id(url)\n\n        rss = self._download_xml(\n            'http://chirbit.com/rss/%s' % profile_id, profile_id)\n\n        entries = [\n            self.url_result(audio_url.text, 'Chirbit')\n            for audio_url in rss.findall('./channel/item/link')]\n\n        title = rss.find('./channel/title').text\n\n        return self.playlist_result(entries, profile_id, title)",
        "begin_line": 72,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.teamcoco.TeamcocoIE._real_extract#73",
        "src_path": "youtube_dl/extractor/teamcoco.py",
        "class_name": "youtube_dl.extractor.teamcoco.TeamcocoIE",
        "signature": "youtube_dl.extractor.teamcoco.TeamcocoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        display_id = mobj.group('display_id')\n        webpage, urlh = self._download_webpage_handle(url, display_id)\n        if 'src=expired' in urlh.geturl():\n            raise ExtractorError('This video is expired.', expected=True)\n\n        video_id = mobj.group('video_id')\n        if not video_id:\n            video_id = self._html_search_regex(\n                self._VIDEO_ID_REGEXES, webpage, 'video id')\n\n        data = None\n\n        preload_codes = self._html_search_regex(\n            r'(function.+)setTimeout\\(function\\(\\)\\{playlist',\n            webpage, 'preload codes')\n        base64_fragments = re.findall(r'\"([a-zA-z0-9+/=]+)\"', preload_codes)\n        base64_fragments.remove('init')\n\n        def _check_sequence(cur_fragments):\n            if not cur_fragments:\n                return\n            for i in range(len(cur_fragments)):\n                cur_sequence = (''.join(cur_fragments[i:] + cur_fragments[:i])).encode('ascii')\n                try:\n                    raw_data = base64.b64decode(cur_sequence)\n                    if compat_ord(raw_data[0]) == compat_ord('{'):\n                        return json.loads(raw_data.decode('utf-8'))\n                except (TypeError, binascii.Error, UnicodeDecodeError, ValueError):\n                    continue\n\n        def _check_data():\n            for i in range(len(base64_fragments) + 1):\n                for j in range(i, len(base64_fragments) + 1):\n                    data = _check_sequence(base64_fragments[:i] + base64_fragments[j:])\n                    if data:\n                        return data\n\n        self.to_screen('Try to compute possible data sequence. This may take some time.')\n        data = _check_data()\n\n        if not data:\n            raise ExtractorError(\n                'Preload information could not be extracted', expected=True)\n\n        formats = []\n        get_quality = qualities(['500k', '480p', '1000k', '720p', '1080p'])\n        for filed in data['files']:\n            if determine_ext(filed['url']) == 'm3u8':\n                # compat_urllib_parse.urljoin does not work here\n                if filed['url'].startswith('/'):\n                    m3u8_url = 'http://ht.cdn.turner.com/tbs/big/teamcoco' + filed['url']\n                else:\n                    m3u8_url = filed['url']\n                m3u8_formats = self._extract_m3u8_formats(\n                    m3u8_url, video_id, ext='mp4')\n                for m3u8_format in m3u8_formats:\n                    if m3u8_format not in formats:\n                        formats.append(m3u8_format)\n            elif determine_ext(filed['url']) == 'f4m':\n                # TODO Correct f4m extraction\n                continue\n            else:\n                if filed['url'].startswith('/mp4:protected/'):\n                    # TODO Correct extraction for these files\n                    continue\n                m_format = re.search(r'(\\d+(k|p))\\.mp4', filed['url'])\n                if m_format is not None:\n                    format_id = m_format.group(1)\n                else:\n                    format_id = filed['bitrate']\n                tbr = (\n                    int(filed['bitrate'])\n                    if filed['bitrate'].isdigit()\n                    else None)\n\n                formats.append({\n                    'url': filed['url'],\n                    'ext': 'mp4',\n                    'tbr': tbr,\n                    'format_id': format_id,\n                    'quality': get_quality(format_id),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'formats': formats,\n            'title': data['title'],\n            'thumbnail': data.get('thumb', {}).get('href'),\n            'description': data.get('teaser'),\n            'duration': data.get('duration'),\n            'age_limit': self._family_friendly_search(webpage),\n        }",
        "begin_line": 73,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dreisat.DreiSatIE._real_extract#34",
        "src_path": "youtube_dl/extractor/dreisat.py",
        "class_name": "youtube_dl.extractor.dreisat.DreiSatIE",
        "signature": "youtube_dl.extractor.dreisat.DreiSatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        details_url = 'http://www.3sat.de/mediathek/xmlservice/web/beitragsDetails?ak=web&id=%s' % video_id\n        details_doc = self._download_xml(details_url, video_id, 'Downloading video details')\n\n        status_code = details_doc.find('./status/statuscode')\n        if status_code is not None and status_code.text != 'ok':\n            code = status_code.text\n            if code == 'notVisibleAnymore':\n                message = 'Video %s is not available' % video_id\n            else:\n                message = '%s returned error: %s' % (self.IE_NAME, code)\n            raise ExtractorError(message, expected=True)\n\n        thumbnail_els = details_doc.findall('.//teaserimage')\n        thumbnails = [{\n            'width': int(te.attrib['key'].partition('x')[0]),\n            'height': int(te.attrib['key'].partition('x')[2]),\n            'url': te.text,\n        } for te in thumbnail_els]\n\n        information_el = details_doc.find('.//information')\n        video_title = information_el.find('./title').text\n        video_description = information_el.find('./detail').text\n\n        details_el = details_doc.find('.//details')\n        video_uploader = details_el.find('./channel').text\n        upload_date = unified_strdate(details_el.find('./airtime').text)\n\n        format_els = details_doc.findall('.//formitaet')\n        formats = [{\n            'format_id': fe.attrib['basetype'],\n            'width': int(fe.find('./width').text),\n            'height': int(fe.find('./height').text),\n            'url': fe.find('./url').text,\n            'filesize': int(fe.find('./filesize').text),\n            'video_bitrate': int(fe.find('./videoBitrate').text),\n        } for fe in format_els\n            if not fe.find('./url').text.startswith('http://www.metafilegenerator.de/')]\n\n        self._sort_formats(formats)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'description': video_description,\n            'thumbnails': thumbnails,\n            'thumbnail': thumbnails[-1]['url'],\n            'uploader': video_uploader,\n            'upload_date': upload_date,\n        }",
        "begin_line": 34,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.behindkink.BehindKinkIE._real_extract#26",
        "src_path": "youtube_dl/extractor/behindkink.py",
        "class_name": "youtube_dl.extractor.behindkink.BehindKinkIE",
        "signature": "youtube_dl.extractor.behindkink.BehindKinkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._search_regex(\n            r'<source src=\"([^\"]+)\"', webpage, 'video URL')\n        video_id = url_basename(video_url).split('_')[0]\n        upload_date = mobj.group('year') + mobj.group('month') + mobj.group('day')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n            'upload_date': upload_date,\n            'age_limit': 18,\n        }",
        "begin_line": 26,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.shahid.ShahidIE._handle_error#36",
        "src_path": "youtube_dl/extractor/shahid.py",
        "class_name": "youtube_dl.extractor.shahid.ShahidIE",
        "signature": "youtube_dl.extractor.shahid.ShahidIE._handle_error(self, response)",
        "snippet": "    def _handle_error(self, response):\n        if not isinstance(response, dict):\n            return\n        error = response.get('error')\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, '\\n'.join(error.values())),\n                expected=True)",
        "begin_line": 36,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.shahid.ShahidIE._download_json#45",
        "src_path": "youtube_dl/extractor/shahid.py",
        "class_name": "youtube_dl.extractor.shahid.ShahidIE",
        "signature": "youtube_dl.extractor.shahid.ShahidIE._download_json(self, url, video_id, note='Downloading JSON metadata')",
        "snippet": "    def _download_json(self, url, video_id, note='Downloading JSON metadata'):\n        response = super(ShahidIE, self)._download_json(url, video_id, note)['data']\n        self._handle_error(response)\n        return response",
        "begin_line": 45,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.shahid.ShahidIE._real_extract#50",
        "src_path": "youtube_dl/extractor/shahid.py",
        "class_name": "youtube_dl.extractor.shahid.ShahidIE",
        "signature": "youtube_dl.extractor.shahid.ShahidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        api_vars = {\n            'id': video_id,\n            'type': 'player',\n            'url': 'http://api.shahid.net/api/v1_1',\n            'playerType': 'episode',\n        }\n\n        flashvars = self._search_regex(\n            r'var\\s+flashvars\\s*=\\s*({[^}]+})', webpage, 'flashvars', default=None)\n        if flashvars:\n            for key in api_vars.keys():\n                value = self._search_regex(\n                    r'\\b%s\\s*:\\s*(?P<q>[\"\\'])(?P<value>.+?)(?P=q)' % key,\n                    flashvars, 'type', default=None, group='value')\n                if value:\n                    api_vars[key] = value\n\n        player = self._download_json(\n            'https://shahid.mbc.net/arContent/getPlayerContent-param-.id-%s.type-%s.html'\n            % (video_id, api_vars['type']), video_id, 'Downloading player JSON')\n\n        formats = self._extract_m3u8_formats(player['url'], video_id, 'mp4')\n\n        video = self._download_json(\n            '%s/%s/%s?%s' % (\n                api_vars['url'], api_vars['playerType'], api_vars['id'],\n                compat_urllib_parse.urlencode({\n                    'apiKey': 'sh@hid0nlin3',\n                    'hash': 'b2wMCTHpSmyxGqQjJFOycRmLSex+BpTK/ooxy6vHaqs=',\n                })),\n            video_id, 'Downloading video JSON')\n\n        video = video[api_vars['playerType']]\n\n        title = video['title']\n        description = video.get('description')\n        thumbnail = video.get('thumbnailUrl')\n        duration = int_or_none(video.get('duration'))\n        timestamp = parse_iso8601(video.get('referenceDate'))\n        categories = [\n            category['name']\n            for category in video.get('genres', []) if 'name' in category]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 50,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.shared.SharedIE._real_extract#40",
        "src_path": "youtube_dl/extractor/shared.py",
        "class_name": "youtube_dl.extractor.shared.SharedIE",
        "signature": "youtube_dl.extractor.shared.SharedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        if '>File does not exist<' in webpage:\n            raise ExtractorError(\n                'Video %s does not exist' % video_id, expected=True)\n\n        download_form = self._hidden_inputs(webpage)\n        request = compat_urllib_request.Request(\n            url, compat_urllib_parse.urlencode(download_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n\n        video_page = self._download_webpage(\n            request, video_id, 'Downloading video page')\n\n        video_url = self._html_search_regex(\n            r'data-url=\"([^\"]+)\"', video_page, 'video URL')\n        title = base64.b64decode(self._html_search_meta(\n            'full:title', webpage, 'title').encode('utf-8')).decode('utf-8')\n        filesize = int_or_none(self._html_search_meta(\n            'full:size', webpage, 'file size', fatal=False))\n        thumbnail = self._html_search_regex(\n            r'data-poster=\"([^\"]+)\"', video_page, 'thumbnail', default=None)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'filesize': filesize,\n            'title': title,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 40,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.adultswim.AdultSwimIE.find_video_info#85",
        "src_path": "youtube_dl/extractor/adultswim.py",
        "class_name": "youtube_dl.extractor.adultswim.AdultSwimIE",
        "signature": "youtube_dl.extractor.adultswim.AdultSwimIE.find_video_info(collection, slug)",
        "snippet": "    def find_video_info(collection, slug):\n        for video in collection.get('videos'):\n            if video.get('slug') == slug:\n                return video",
        "begin_line": 85,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.adultswim.AdultSwimIE.find_collection_by_linkURL#91",
        "src_path": "youtube_dl/extractor/adultswim.py",
        "class_name": "youtube_dl.extractor.adultswim.AdultSwimIE",
        "signature": "youtube_dl.extractor.adultswim.AdultSwimIE.find_collection_by_linkURL(collections, linkURL)",
        "snippet": "    def find_collection_by_linkURL(collections, linkURL):\n        for collection in collections:\n            if collection.get('linkURL') == linkURL:\n                return collection",
        "begin_line": 91,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.adultswim.AdultSwimIE.find_collection_containing_video#97",
        "src_path": "youtube_dl/extractor/adultswim.py",
        "class_name": "youtube_dl.extractor.adultswim.AdultSwimIE",
        "signature": "youtube_dl.extractor.adultswim.AdultSwimIE.find_collection_containing_video(collections, slug)",
        "snippet": "    def find_collection_containing_video(collections, slug):\n        for collection in collections:\n            for video in collection.get('videos'):\n                if video.get('slug') == slug:\n                    return collection, video\n        return None, None",
        "begin_line": 97,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.adultswim.AdultSwimIE._real_extract#104",
        "src_path": "youtube_dl/extractor/adultswim.py",
        "class_name": "youtube_dl.extractor.adultswim.AdultSwimIE",
        "signature": "youtube_dl.extractor.adultswim.AdultSwimIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        show_path = mobj.group('show_path')\n        episode_path = mobj.group('episode_path')\n        is_playlist = True if mobj.group('is_playlist') else False\n\n        webpage = self._download_webpage(url, episode_path)\n\n        # Extract the value of `bootstrappedData` from the Javascript in the page.\n        bootstrapped_data = self._parse_json(self._search_regex(\n            r'var bootstrappedData = ({.*});', webpage, 'bootstraped data'), episode_path)\n\n        # Downloading videos from a /videos/playlist/ URL needs to be handled differently.\n        # NOTE: We are only downloading one video (the current one) not the playlist\n        if is_playlist:\n            collections = bootstrapped_data['playlists']['collections']\n            collection = self.find_collection_by_linkURL(collections, show_path)\n            video_info = self.find_video_info(collection, episode_path)\n\n            show_title = video_info['showTitle']\n            segment_ids = [video_info['videoPlaybackID']]\n        else:\n            collections = bootstrapped_data['show']['collections']\n            collection, video_info = self.find_collection_containing_video(collections, episode_path)\n            # Video wasn't found in the collections, let's try `slugged_video`.\n            if video_info is None:\n                if bootstrapped_data.get('slugged_video', {}).get('slug') == episode_path:\n                    video_info = bootstrapped_data['slugged_video']\n                else:\n                    raise ExtractorError('Unable to find video info')\n\n            show = bootstrapped_data['show']\n            show_title = show['title']\n            stream = video_info.get('stream')\n            clips = [stream] if stream else video_info.get('clips')\n            if not clips:\n                raise ExtractorError(\n                    'This video is only available via cable service provider subscription that'\n                    ' is not currently supported. You may want to use --cookies.'\n                    if video_info.get('auth') is True else 'Unable to find stream or clips',\n                    expected=True)\n            segment_ids = [clip['videoPlaybackID'] for clip in clips]\n\n        episode_id = video_info['id']\n        episode_title = video_info['title']\n        episode_description = video_info['description']\n        episode_duration = video_info.get('duration')\n\n        entries = []\n        for part_num, segment_id in enumerate(segment_ids):\n            segment_url = 'http://www.adultswim.com/videos/api/v0/assets?id=%s&platform=desktop' % segment_id\n\n            segment_title = '%s - %s' % (show_title, episode_title)\n            if len(segment_ids) > 1:\n                segment_title += ' Part %d' % (part_num + 1)\n\n            idoc = self._download_xml(\n                segment_url, segment_title,\n                'Downloading segment information', 'Unable to download segment information')\n\n            segment_duration = float_or_none(\n                xpath_text(idoc, './/trt', 'segment duration').strip())\n\n            formats = []\n            file_els = idoc.findall('.//files/file') or idoc.findall('./files/file')\n\n            unique_urls = []\n            unique_file_els = []\n            for file_el in file_els:\n                media_url = file_el.text\n                if not media_url or determine_ext(media_url) == 'f4m':\n                    continue\n                if file_el.text not in unique_urls:\n                    unique_urls.append(file_el.text)\n                    unique_file_els.append(file_el)\n\n            for file_el in unique_file_els:\n                bitrate = file_el.attrib.get('bitrate')\n                ftype = file_el.attrib.get('type')\n                media_url = file_el.text\n                if determine_ext(media_url) == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        media_url, segment_title, 'mp4', preference=0, m3u8_id='hls'))\n                else:\n                    formats.append({\n                        'format_id': '%s_%s' % (bitrate, ftype),\n                        'url': file_el.text.strip(),\n                        # The bitrate may not be a number (for example: 'iphone')\n                        'tbr': int(bitrate) if bitrate.isdigit() else None,\n                    })\n\n            self._sort_formats(formats)\n\n            entries.append({\n                'id': segment_id,\n                'title': segment_title,\n                'formats': formats,\n                'duration': segment_duration,\n                'description': episode_description\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': episode_id,\n            'display_id': episode_path,\n            'entries': entries,\n            'title': '%s - %s' % (show_title, episode_title),\n            'description': episode_description,\n            'duration': episode_duration\n        }",
        "begin_line": 104,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.metacritic.MetacriticIE._real_extract#25",
        "src_path": "youtube_dl/extractor/metacritic.py",
        "class_name": "youtube_dl.extractor.metacritic.MetacriticIE",
        "signature": "youtube_dl.extractor.metacritic.MetacriticIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        # The xml is not well formatted, there are raw '&'\n        info = self._download_xml('http://www.metacritic.com/video_data?video=' + video_id,\n                                  video_id, 'Downloading info xml', transform_source=fix_xml_ampersands)\n\n        clip = next(c for c in info.findall('playList/clip') if c.find('id').text == video_id)\n        formats = []\n        for videoFile in clip.findall('httpURI/videoFile'):\n            rate_str = videoFile.find('rate').text\n            video_url = videoFile.find('filePath').text\n            formats.append({\n                'url': video_url,\n                'ext': 'mp4',\n                'format_id': rate_str,\n                'tbr': int(rate_str),\n            })\n        self._sort_formats(formats)\n\n        description = self._html_search_regex(r'<b>Description:</b>(.*?)</p>',\n                                              webpage, 'description', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'title': clip.find('title').text,\n            'formats': formats,\n            'description': description,\n            'duration': int(clip.find('duration').text),\n        }",
        "begin_line": 25,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor._extract_item#12",
        "src_path": "youtube_dl/extractor/zingmp3.py",
        "class_name": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor",
        "signature": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor._extract_item(self, item, fatal=True)",
        "snippet": "    def _extract_item(self, item, fatal=True):\n        error_message = item.find('./errormessage').text\n        if error_message:\n            if not fatal:\n                return\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error_message),\n                expected=True)\n\n        title = item.find('./title').text.strip()\n        source = item.find('./source').text\n        extension = item.attrib['type']\n        thumbnail = item.find('./backimage').text\n\n        return {\n            'title': title,\n            'url': source,\n            'ext': extension,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 12,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor._extract_player_xml#33",
        "src_path": "youtube_dl/extractor/zingmp3.py",
        "class_name": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor",
        "signature": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor._extract_player_xml(self, player_xml_url, id, playlist_title=None)",
        "snippet": "    def _extract_player_xml(self, player_xml_url, id, playlist_title=None):\n        player_xml = self._download_xml(player_xml_url, id, 'Downloading Player XML')\n        items = player_xml.findall('./item')\n\n        if len(items) == 1:\n            # one single song\n            data = self._extract_item(items[0])\n            data['id'] = id\n\n            return data\n        else:\n            # playlist of songs\n            entries = []\n\n            for i, item in enumerate(items, 1):\n                entry = self._extract_item(item, fatal=False)\n                if not entry:\n                    continue\n                entry['id'] = '%s-%d' % (id, i)\n                entries.append(entry)\n\n            return {\n                '_type': 'playlist',\n                'id': id,\n                'title': playlist_title,\n                'entries': entries,\n            }",
        "begin_line": 33,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.zingmp3.ZingMp3SongIE._real_extract#77",
        "src_path": "youtube_dl/extractor/zingmp3.py",
        "class_name": "youtube_dl.extractor.zingmp3.ZingMp3SongIE",
        "signature": "youtube_dl.extractor.zingmp3.ZingMp3SongIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        matched = re.match(self._VALID_URL, url)\n        slug = matched.group('slug')\n        song_id = matched.group('song_id')\n\n        webpage = self._download_webpage(\n            'http://mp3.zing.vn/bai-hat/%s/%s.html' % (slug, song_id), song_id)\n\n        player_xml_url = self._search_regex(\n            r'&amp;xmlURL=(?P<xml_url>[^&]+)&', webpage, 'player xml url')\n\n        return self._extract_player_xml(player_xml_url, song_id)",
        "begin_line": 77,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.zingmp3.ZingMp3AlbumIE._real_extract#108",
        "src_path": "youtube_dl/extractor/zingmp3.py",
        "class_name": "youtube_dl.extractor.zingmp3.ZingMp3AlbumIE",
        "signature": "youtube_dl.extractor.zingmp3.ZingMp3AlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        matched = re.match(self._VALID_URL, url)\n        slug = matched.group('slug')\n        album_id = matched.group('album_id')\n\n        webpage = self._download_webpage(\n            'http://mp3.zing.vn/album/%s/%s.html' % (slug, album_id), album_id)\n        player_xml_url = self._search_regex(\n            r'&amp;xmlURL=(?P<xml_url>[^&]+)&', webpage, 'player xml url')\n\n        return self._extract_player_xml(\n            player_xml_url, album_id,\n            playlist_title=self._og_search_title(webpage))",
        "begin_line": 108,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.liveleak.LiveLeakIE._real_extract#56",
        "src_path": "youtube_dl/extractor/liveleak.py",
        "class_name": "youtube_dl.extractor.liveleak.LiveLeakIE",
        "signature": "youtube_dl.extractor.liveleak.LiveLeakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._og_search_title(webpage).replace('LiveLeak.com -', '').strip()\n        video_description = self._og_search_description(webpage)\n        video_uploader = self._html_search_regex(\n            r'By:.*?(\\w+)</a>', webpage, 'uploader', fatal=False)\n        age_limit = int_or_none(self._search_regex(\n            r'you confirm that you are ([0-9]+) years and over.',\n            webpage, 'age limit', default=None))\n\n        sources_raw = self._search_regex(\n            r'(?s)sources:\\s*(\\[.*?\\]),', webpage, 'video URLs', default=None)\n        if sources_raw is None:\n            alt_source = self._search_regex(\n                r'(file: \".*?\"),', webpage, 'video URL', default=None)\n            if alt_source:\n                sources_raw = '[{ %s}]' % alt_source\n            else:\n                # Maybe an embed?\n                embed_url = self._search_regex(\n                    r'<iframe[^>]+src=\"(http://www.prochan.com/embed\\?[^\"]+)\"',\n                    webpage, 'embed URL')\n                return {\n                    '_type': 'url_transparent',\n                    'url': embed_url,\n                    'id': video_id,\n                    'title': video_title,\n                    'description': video_description,\n                    'uploader': video_uploader,\n                    'age_limit': age_limit,\n                }\n\n        sources_json = re.sub(r'\\s([a-z]+):\\s', r'\"\\1\": ', sources_raw)\n        sources = json.loads(sources_json)\n\n        formats = [{\n            'format_id': '%s' % i,\n            'format_note': s.get('label'),\n            'url': s['file'],\n        } for i, s in enumerate(sources)]\n        for i, s in enumerate(sources):\n            # Removing '.h264_*.mp4' gives the raw video, which is essentially\n            # the same video without the LiveLeak logo at the top (see\n            # https://github.com/rg3/youtube-dl/pull/4768)\n            orig_url = re.sub(r'\\.h264_.+?\\.mp4', '', s['file'])\n            if s['file'] != orig_url:\n                formats.append({\n                    'format_id': 'original-%s' % i,\n                    'format_note': s.get('label'),\n                    'url': orig_url,\n                    'preference': 1,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': video_description,\n            'uploader': video_uploader,\n            'formats': formats,\n            'age_limit': age_limit,\n        }",
        "begin_line": 56,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.googlesearch.GoogleSearchIE._get_n_results#26",
        "src_path": "youtube_dl/extractor/googlesearch.py",
        "class_name": "youtube_dl.extractor.googlesearch.GoogleSearchIE",
        "signature": "youtube_dl.extractor.googlesearch.GoogleSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        entries = []\n        res = {\n            '_type': 'playlist',\n            'id': query,\n            'title': query,\n        }\n\n        for pagenum in itertools.count():\n            result_url = (\n                'http://www.google.com/search?tbm=vid&q=%s&start=%s&hl=en'\n                % (compat_urllib_parse.quote_plus(query), pagenum * 10))\n\n            webpage = self._download_webpage(\n                result_url, 'gvsearch:' + query,\n                note='Downloading result page ' + str(pagenum + 1))\n\n            for hit_idx, mobj in enumerate(re.finditer(\n                    r'<h3 class=\"r\"><a href=\"([^\"]+)\"', webpage)):\n\n                # Skip playlists\n                if not re.search(r'id=\"vidthumb%d\"' % (hit_idx + 1), webpage):\n                    continue\n\n                entries.append({\n                    '_type': 'url',\n                    'url': mobj.group(1)\n                })\n\n            if (len(entries) >= n) or not re.search(r'id=\"pnnext\"', webpage):\n                res['entries'] = entries[:n]\n                return res",
        "begin_line": 26,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicIE.m_r_get_ruin#72",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicIE.m_r_get_ruin()",
        "snippet": "    def m_r_get_ruin():\n        curMs = int(time.time() * 1000) % 1000\n        return int(round(random.random() * 2147483647) * curMs % 1E10)",
        "begin_line": 72,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicIE._real_extract#76",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mid = self._match_id(url)\n\n        detail_info_page = self._download_webpage(\n            'http://s.plcloud.music.qq.com/fcgi-bin/fcg_yqq_song_detail_info.fcg?songmid=%s&play=0' % mid,\n            mid, note='Download song detail info',\n            errnote='Unable to get song detail info', encoding='gbk')\n\n        song_name = self._html_search_regex(\n            r\"songname:\\s*'([^']+)'\", detail_info_page, 'song name')\n\n        publish_time = self._html_search_regex(\n            r'\u53d1\u884c\u65f6\u95f4\uff1a(\\d{4}-\\d{2}-\\d{2})', detail_info_page,\n            'publish time', default=None)\n        if publish_time:\n            publish_time = publish_time.replace('-', '')\n\n        singer = self._html_search_regex(\n            r\"singer:\\s*'([^']+)\", detail_info_page, 'singer', default=None)\n\n        lrc_content = self._html_search_regex(\n            r'<div class=\"content\" id=\"lrc_content\"[^<>]*>([^<>]+)</div>',\n            detail_info_page, 'LRC lyrics', default=None)\n        if lrc_content:\n            lrc_content = lrc_content.replace('\\\\n', '\\n')\n\n        thumbnail_url = None\n        albummid = self._search_regex(\n            [r'albummid:\\'([0-9a-zA-Z]+)\\'', r'\"albummid\":\"([0-9a-zA-Z]+)\"'],\n            detail_info_page, 'album mid', default=None)\n        if albummid:\n            thumbnail_url = \"http://i.gtimg.cn/music/photo/mid_album_500/%s/%s/%s.jpg\" \\\n                            % (albummid[-2:-1], albummid[-1], albummid)\n\n        guid = self.m_r_get_ruin()\n\n        vkey = self._download_json(\n            'http://base.music.qq.com/fcgi-bin/fcg_musicexpress.fcg?json=3&guid=%s' % guid,\n            mid, note='Retrieve vkey', errnote='Unable to get vkey',\n            transform_source=strip_jsonp)['key']\n\n        formats = []\n        for format_id, details in self._FORMATS.items():\n            formats.append({\n                'url': 'http://cc.stream.qqmusic.qq.com/%s%s.%s?vkey=%s&guid=%s&fromtag=0'\n                       % (details['prefix'], mid, details['ext'], vkey, guid),\n                'format': format_id,\n                'format_id': format_id,\n                'preference': details['preference'],\n                'abr': details.get('abr'),\n            })\n        self._check_formats(formats, mid)\n        self._sort_formats(formats)\n\n        actual_lrc_lyrics = ''.join(\n            line + '\\n' for line in re.findall(\n                r'(?m)^(\\[[0-9]{2}:[0-9]{2}(?:\\.[0-9]{2,})?\\][^\\n]*|\\[[^\\]]*\\])', lrc_content))\n\n        info_dict = {\n            'id': mid,\n            'formats': formats,\n            'title': song_name,\n            'release_date': publish_time,\n            'creator': singer,\n            'description': lrc_content,\n            'thumbnail': thumbnail_url\n        }\n        if actual_lrc_lyrics:\n            info_dict['subtitles'] = {\n                'origin': [{\n                    'ext': 'lrc',\n                    'data': actual_lrc_lyrics,\n                }]\n            }\n        return info_dict",
        "begin_line": 76,
        "end_line": 150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE.qq_static_url#155",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE",
        "signature": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE.qq_static_url(category, mid)",
        "snippet": "    def qq_static_url(category, mid):\n        return 'http://y.qq.com/y/static/%s/%s/%s/%s.html' % (category, mid[-2], mid[-1], mid)",
        "begin_line": 155,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE.get_entries_from_page#159",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE",
        "signature": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE.get_entries_from_page(cls, page)",
        "snippet": "    def get_entries_from_page(cls, page):\n        entries = []\n\n        for item in re.findall(r'class=\"data\"[^<>]*>([^<>]+)</', page):\n            song_mid = unescapeHTML(item).split('|')[-5]\n            entries.append(cls.url_result(\n                'http://y.qq.com/#type=song&mid=' + song_mid, 'QQMusic',\n                song_mid))\n\n        return entries",
        "begin_line": 159,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicSingerIE._real_extract#185",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicSingerIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicSingerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mid = self._match_id(url)\n\n        singer_page = self._download_webpage(\n            self.qq_static_url('singer', mid), mid, 'Download singer page')\n\n        entries = self.get_entries_from_page(singer_page)\n\n        singer_name = self._html_search_regex(\n            r\"singername\\s*:\\s*'([^']+)'\", singer_page, 'singer name',\n            default=None)\n\n        singer_id = self._html_search_regex(\n            r\"singerid\\s*:\\s*'([0-9]+)'\", singer_page, 'singer id',\n            default=None)\n\n        singer_desc = None\n\n        if singer_id:\n            req = compat_urllib_request.Request(\n                'http://s.plcloud.music.qq.com/fcgi-bin/fcg_get_singer_desc.fcg?utf8=1&outCharset=utf-8&format=xml&singerid=%s' % singer_id)\n            req.add_header(\n                'Referer', 'http://s.plcloud.music.qq.com/xhr_proxy_utf8.html')\n            singer_desc_page = self._download_xml(\n                req, mid, 'Donwload singer description XML')\n\n            singer_desc = singer_desc_page.find('./data/info/desc').text\n\n        return self.playlist_result(entries, mid, singer_name, singer_desc)",
        "begin_line": 185,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicAlbumIE._real_extract#239",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicAlbumIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mid = self._match_id(url)\n\n        album = self._download_json(\n            'http://i.y.qq.com/v8/fcg-bin/fcg_v8_album_info_cp.fcg?albummid=%s&format=json' % mid,\n            mid, 'Download album page')['data']\n\n        entries = [\n            self.url_result(\n                'http://y.qq.com/#type=song&mid=' + song['songmid'], 'QQMusic', song['songmid']\n            ) for song in album['list']\n        ]\n        album_name = album.get('name')\n        album_detail = album.get('desc')\n        if album_detail is not None:\n            album_detail = album_detail.strip()\n\n        return self.playlist_result(entries, mid, album_name, album_detail)",
        "begin_line": 239,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicToplistIE._real_extract#291",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicToplistIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicToplistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n\n        list_type, num_id = list_id.split(\"_\")\n\n        toplist_json = self._download_json(\n            'http://i.y.qq.com/v8/fcg-bin/fcg_v8_toplist_cp.fcg?type=%s&topid=%s&format=json'\n            % (list_type, num_id),\n            list_id, 'Download toplist page')\n\n        entries = [\n            self.url_result(\n                'http://y.qq.com/#type=song&mid=' + song['data']['songmid'], 'QQMusic', song['data']['songmid']\n            ) for song in toplist_json['songlist']\n        ]\n\n        topinfo = toplist_json.get('topinfo', {})\n        list_name = topinfo.get('ListName')\n        list_description = topinfo.get('info')\n        return self.playlist_result(entries, list_id, list_name, list_description)",
        "begin_line": 291,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicPlaylistIE._real_extract#328",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicPlaylistIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n\n        list_json = self._download_json(\n            'http://i.y.qq.com/qzone-music/fcg-bin/fcg_ucc_getcdinfo_byids_cp.fcg?type=1&json=1&utf8=1&onlysong=0&disstid=%s'\n            % list_id, list_id, 'Download list page',\n            transform_source=strip_jsonp)['cdlist'][0]\n\n        entries = [\n            self.url_result(\n                'http://y.qq.com/#type=song&mid=' + song['songmid'], 'QQMusic', song['songmid']\n            ) for song in list_json['songlist']\n        ]\n\n        list_name = list_json.get('dissname')\n        list_description = clean_html(unescapeHTML(list_json.get('desc')))\n        return self.playlist_result(entries, list_id, list_name, list_description)",
        "begin_line": 328,
        "end_line": 344,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mpora.MporaIE._real_extract#23",
        "src_path": "youtube_dl/extractor/mpora.py",
        "class_name": "youtube_dl.extractor.mpora.MporaIE",
        "signature": "youtube_dl.extractor.mpora.MporaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        data_json = self._search_regex(\n            [r\"new FM\\.Player\\('[^']+',\\s*(\\{.*?)\\).player;\",\n             r\"new\\s+FM\\.Kaltura\\.Player\\('[^']+'\\s*,\\s*({.+?})\\);\"],\n            webpage, 'json')\n        data = self._parse_json(data_json, video_id)\n\n        uploader = data['info_overlay'].get('username')\n        duration = data['video']['duration'] // 1000\n        thumbnail = data['video']['encodings']['sd']['poster']\n        title = data['info_overlay']['title']\n\n        formats = []\n        for encoding_id, edata in data['video']['encodings'].items():\n            for src in edata['sources']:\n                width_str = self._search_regex(\n                    r'_([0-9]+)\\.[a-zA-Z0-9]+$', src['src'],\n                    False, default=None)\n                vcodec = src['type'].partition('/')[2]\n\n                formats.append({\n                    'format_id': encoding_id + '-' + vcodec,\n                    'url': src['src'],\n                    'vcodec': vcodec,\n                    'width': int_or_none(width_str),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'uploader': uploader,\n            'duration': duration,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 23,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.franceculture.FranceCultureIE._real_extract#31",
        "src_path": "youtube_dl/extractor/franceculture.py",
        "class_name": "youtube_dl.extractor.franceculture.FranceCultureIE",
        "signature": "youtube_dl.extractor.franceculture.FranceCultureIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_path = self._search_regex(\n            r'<a id=\"player\".*?href=\"([^\"]+)\"', webpage, 'video path')\n        video_url = compat_urlparse.urljoin(url, video_path)\n        timestamp = int_or_none(self._search_regex(\n            r'<a id=\"player\".*?data-date=\"([0-9]+)\"',\n            webpage, 'upload date', fatal=False))\n        thumbnail = self._search_regex(\n            r'<a id=\"player\".*?>\\s+<img src=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        title = self._html_search_regex(\n            r'<span class=\"title-diffusion\">(.*?)</span>', webpage, 'title')\n        alt_title = self._html_search_regex(\n            r'<span class=\"title\">(.*?)</span>',\n            webpage, 'alt_title', fatal=False)\n        description = self._html_search_regex(\n            r'<span class=\"description\">(.*?)</span>',\n            webpage, 'description', fatal=False)\n\n        uploader = self._html_search_regex(\n            r'(?s)<div id=\"emission\".*?<span class=\"author\">(.*?)</span>',\n            webpage, 'uploader', default=None)\n        vcodec = 'none' if determine_ext(video_url.lower()) == 'mp3' else None\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'vcodec': vcodec,\n            'uploader': uploader,\n            'timestamp': timestamp,\n            'title': title,\n            'alt_title': alt_title,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 31,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE._real_extract#27",
        "src_path": "youtube_dl/extractor/jeuxvideo.py",
        "class_name": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE",
        "signature": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group(1)\n        webpage = self._download_webpage(url, title)\n        title = self._html_search_meta('name', webpage) or self._og_search_title(webpage)\n        config_url = self._html_search_regex(\n            r'data-src=\"(/contenu/medias/video.php.*?)\"',\n            webpage, 'config URL')\n        config_url = 'http://www.jeuxvideo.com' + config_url\n\n        video_id = self._search_regex(\n            r'id=(\\d+)',\n            config_url, 'video ID')\n\n        config = self._download_json(\n            config_url, title, 'Downloading JSON config')\n\n        formats = [{\n            'url': source['file'],\n            'format_id': source['label'],\n            'resolution': source['label'],\n        } for source in reversed(config['sources'])]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': config.get('image'),\n        }",
        "begin_line": 27,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.lifenews.LifeNewsIE._real_extract#59",
        "src_path": "youtube_dl/extractor/lifenews.py",
        "class_name": "youtube_dl.extractor.lifenews.LifeNewsIE",
        "signature": "youtube_dl.extractor.lifenews.LifeNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        section = mobj.group('section')\n\n        webpage = self._download_webpage(\n            'http://lifenews.ru/%s/%s' % (section, video_id),\n            video_id, 'Downloading page')\n\n        videos = re.findall(r'<video.*?poster=\"(?P<poster>[^\"]+)\".*?src=\"(?P<video>[^\"]+)\".*?></video>', webpage)\n        iframe_link = self._html_search_regex(\n            '<iframe[^>]+src=[\"\\']([^\"\\']+)[\"\\']', webpage, 'iframe link', default=None)\n        if not videos and not iframe_link:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        title = remove_end(\n            self._og_search_title(webpage),\n            ' - \u041f\u0435\u0440\u0432\u044b\u0439 \u043f\u043e \u0441\u0440\u043e\u0447\u043d\u044b\u043c \u043d\u043e\u0432\u043e\u0441\u0442\u044f\u043c \u2014 LIFE | NEWS')\n\n        description = self._og_search_description(webpage)\n\n        view_count = self._html_search_regex(\n            r'<div class=\\'views\\'>\\s*(\\d+)\\s*</div>', webpage, 'view count', fatal=False)\n        comment_count = self._html_search_regex(\n            r'=\\'commentCount\\'[^>]*>\\s*(\\d+)\\s*<',\n            webpage, 'comment count', fatal=False)\n\n        upload_date = self._html_search_regex(\n            r'<time[^>]*datetime=\\'([^\\']+)\\'', webpage, 'upload date', fatal=False)\n        if upload_date is not None:\n            upload_date = unified_strdate(upload_date)\n\n        common_info = {\n            'description': description,\n            'view_count': int_or_none(view_count),\n            'comment_count': int_or_none(comment_count),\n            'upload_date': upload_date,\n        }\n\n        def make_entry(video_id, media, video_number=None):\n            cur_info = dict(common_info)\n            cur_info.update({\n                'id': video_id,\n                'url': media[1],\n                'thumbnail': media[0],\n                'title': title if video_number is None else '%s-video%s' % (title, video_number),\n            })\n            return cur_info\n\n        if iframe_link:\n            iframe_link = self._proto_relative_url(iframe_link, 'http:')\n            cur_info = dict(common_info)\n            cur_info.update({\n                '_type': 'url_transparent',\n                'id': video_id,\n                'title': title,\n                'url': iframe_link,\n            })\n            return cur_info\n\n        if len(videos) == 1:\n            return make_entry(video_id, videos[0])\n        else:\n            return [make_entry(video_id, media, video_number + 1) for video_number, media in enumerate(videos)]",
        "begin_line": 59,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.lifenews.LifeEmbedIE._real_extract#140",
        "src_path": "youtube_dl/extractor/lifenews.py",
        "class_name": "youtube_dl.extractor.lifenews.LifeEmbedIE",
        "signature": "youtube_dl.extractor.lifenews.LifeEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        formats = []\n        for video_url in re.findall(r'\"file\"\\s*:\\s*\"([^\"]+)', webpage):\n            video_url = compat_urlparse.urljoin(url, video_url)\n            ext = determine_ext(video_url)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4', m3u8_id='m3u8'))\n            else:\n                formats.append({\n                    'url': video_url,\n                    'format_id': ext,\n                    'preference': 1,\n                })\n        self._sort_formats(formats)\n\n        thumbnail = self._search_regex(\n            r'\"image\"\\s*:\\s*\"([^\"]+)', webpage, 'thumbnail', default=None)\n\n        return {\n            'id': video_id,\n            'title': video_id,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 140,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.radiojavan.RadioJavanIE._real_extract#29",
        "src_path": "youtube_dl/extractor/radiojavan.py",
        "class_name": "youtube_dl.extractor.radiojavan.RadioJavanIE",
        "signature": "youtube_dl.extractor.radiojavan.RadioJavanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        formats = [{\n            'url': 'https://media.rdjavan.com/media/music_video/%s' % video_path,\n            'format_id': '%sp' % height,\n            'height': int(height),\n        } for height, video_path in re.findall(r\"RJ\\.video(\\d+)p\\s*=\\s*'/?([^']+)'\", webpage)]\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        upload_date = unified_strdate(self._search_regex(\n            r'class=\"date_added\">Date added: ([^<]+)<',\n            webpage, 'upload date', fatal=False))\n\n        view_count = str_to_int(self._search_regex(\n            r'class=\"views\">Plays: ([\\d,]+)',\n            webpage, 'view count', fatal=False))\n        like_count = str_to_int(self._search_regex(\n            r'class=\"rating\">([\\d,]+) likes',\n            webpage, 'like count', fatal=False))\n        dislike_count = str_to_int(self._search_regex(\n            r'class=\"rating\">([\\d,]+) dislikes',\n            webpage, 'dislike count', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'formats': formats,\n        }",
        "begin_line": 29,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.unistra.UnistraIE._real_extract#35",
        "src_path": "youtube_dl/extractor/unistra.py",
        "class_name": "youtube_dl.extractor.unistra.UnistraIE",
        "signature": "youtube_dl.extractor.unistra.UnistraIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        files = set(re.findall(r'file\\s*:\\s*\"([^\"]+)\"', webpage))\n\n        quality = qualities(['SD', 'HD'])\n        formats = []\n        for file_path in files:\n            format_id = 'HD' if file_path.endswith('-HD.mp4') else 'SD'\n            formats.append({\n                'url': 'http://vod-flash.u-strasbg.fr:8080%s' % file_path,\n                'format_id': format_id,\n                'quality': quality(format_id)\n            })\n\n        title = self._html_search_regex(\n            r'<title>UTV - (.*?)</', webpage, 'title')\n        description = self._html_search_regex(\n            r'<meta name=\"Description\" content=\"(.*?)\"', webpage, 'description', flags=re.DOTALL)\n        thumbnail = self._search_regex(\n            r'image: \"(.*?)\"', webpage, 'thumbnail')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats\n        }",
        "begin_line": 35,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._real_initialize#75",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        req = compat_urllib_request.Request(\n            'http://www.vevo.com/auth', data=b'')\n        webpage = self._download_webpage(\n            req, None,\n            note='Retrieving oauth token',\n            errnote='Unable to retrieve oauth token',\n            fatal=False)\n        if webpage is False:\n            self._oauth_token = None\n        else:\n            self._oauth_token = self._search_regex(\n                r'access_token\":\\s*\"([^\"]+)\"',\n                webpage, 'access token', fatal=False)",
        "begin_line": 75,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._formats_from_json#90",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._formats_from_json(self, video_info)",
        "snippet": "    def _formats_from_json(self, video_info):\n        last_version = {'version': -1}\n        for version in video_info['videoVersions']:\n            # These are the HTTP downloads, other types are for different manifests\n            if version['sourceType'] == 2:\n                if version['version'] > last_version['version']:\n                    last_version = version\n        if last_version['version'] == -1:\n            raise ExtractorError('Unable to extract last version of the video')\n\n        renditions = compat_etree_fromstring(last_version['data'])\n        formats = []\n        # Already sorted from worst to best quality\n        for rend in renditions.findall('rendition'):\n            attr = rend.attrib\n            format_note = '%(videoCodec)s@%(videoBitrate)4sk, %(audioCodec)s@%(audioBitrate)3sk' % attr\n            formats.append({\n                'url': attr['url'],\n                'format_id': attr['name'],\n                'format_note': format_note,\n                'height': int(attr['frameheight']),\n                'width': int(attr['frameWidth']),\n            })\n        return formats",
        "begin_line": 90,
        "end_line": 113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._formats_from_smil#115",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._formats_from_smil(self, smil_xml)",
        "snippet": "    def _formats_from_smil(self, smil_xml):\n        formats = []\n        smil_doc = compat_etree_fromstring(smil_xml.encode('utf-8'))\n        els = smil_doc.findall('.//{http://www.w3.org/2001/SMIL20/Language}video')\n        for el in els:\n            src = el.attrib['src']\n            m = re.match(r'''(?xi)\n                (?P<ext>[a-z0-9]+):\n                (?P<path>\n                    [/a-z0-9]+     # The directory and main part of the URL\n                    _(?P<cbr>[0-9]+)k\n                    _(?P<width>[0-9]+)x(?P<height>[0-9]+)\n                    _(?P<vcodec>[a-z0-9]+)\n                    _(?P<vbr>[0-9]+)\n                    _(?P<acodec>[a-z0-9]+)\n                    _(?P<abr>[0-9]+)\n                    \\.[a-z0-9]+  # File extension\n                )''', src)\n            if not m:\n                continue\n\n            format_url = self._SMIL_BASE_URL + m.group('path')\n            formats.append({\n                'url': format_url,\n                'format_id': 'SMIL_' + m.group('cbr'),\n                'vcodec': m.group('vcodec'),\n                'acodec': m.group('acodec'),\n                'vbr': int(m.group('vbr')),\n                'abr': int(m.group('abr')),\n                'ext': m.group('ext'),\n                'width': int(m.group('width')),\n                'height': int(m.group('height')),\n            })\n        return formats",
        "begin_line": 115,
        "end_line": 148,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._download_api_formats#150",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._download_api_formats(self, video_id)",
        "snippet": "    def _download_api_formats(self, video_id):\n        if not self._oauth_token:\n            self._downloader.report_warning(\n                'No oauth token available, skipping API HLS download')\n            return []\n\n        api_url = 'https://apiv2.vevo.com/video/%s/streams/hls?token=%s' % (\n            video_id, self._oauth_token)\n        api_data = self._download_json(\n            api_url, video_id,\n            note='Downloading HLS formats',\n            errnote='Failed to download HLS format list', fatal=False)\n        if api_data is None:\n            return []\n\n        m3u8_url = api_data[0]['url']\n        return self._extract_m3u8_formats(\n            m3u8_url, video_id, entry_protocol='m3u8_native', ext='mp4',\n            preference=0)",
        "begin_line": 150,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._real_extract#170",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        json_url = 'http://videoplayer.vevo.com/VideoService/AuthenticateVideo?isrc=%s' % video_id\n        response = self._download_json(json_url, video_id)\n        video_info = response['video']\n\n        if not video_info:\n            if 'statusMessage' in response:\n                raise ExtractorError('%s said: %s' % (self.IE_NAME, response['statusMessage']), expected=True)\n            raise ExtractorError('Unable to extract videos')\n\n        formats = self._formats_from_json(video_info)\n\n        is_explicit = video_info.get('isExplicit')\n        if is_explicit is True:\n            age_limit = 18\n        elif is_explicit is False:\n            age_limit = 0\n        else:\n            age_limit = None\n\n        # Download via HLS API\n        formats.extend(self._download_api_formats(video_id))\n\n        # Download SMIL\n        smil_blocks = sorted((\n            f for f in video_info['videoVersions']\n            if f['sourceType'] == 13),\n            key=lambda f: f['version'])\n        smil_url = '%s/Video/V2/VFILE/%s/%sr.smil' % (\n            self._SMIL_BASE_URL, video_id, video_id.lower())\n        if smil_blocks:\n            smil_url_m = self._search_regex(\n                r'url=\"([^\"]+)\"', smil_blocks[-1]['data'], 'SMIL URL',\n                default=None)\n            if smil_url_m is not None:\n                smil_url = smil_url_m\n        if smil_url:\n            smil_xml = self._download_webpage(\n                smil_url, video_id, 'Downloading SMIL info', fatal=False)\n            if smil_xml:\n                formats.extend(self._formats_from_smil(smil_xml))\n\n        self._sort_formats(formats)\n        timestamp_ms = int_or_none(self._search_regex(\n            r'/Date\\((\\d+)\\)/',\n            video_info['launchDate'], 'launch date', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': video_info['title'],\n            'formats': formats,\n            'thumbnail': video_info['imageUrl'],\n            'timestamp': timestamp_ms // 1000,\n            'uploader': video_info['mainArtists'][0]['artistName'],\n            'duration': video_info['duration'],\n            'age_limit': age_limit,\n        }",
        "begin_line": 170,
        "end_line": 229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.theonion.TheOnionIE._real_extract#23",
        "src_path": "youtube_dl/extractor/theonion.py",
        "class_name": "youtube_dl.extractor.theonion.TheOnionIE",
        "signature": "youtube_dl.extractor.theonion.TheOnionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            r'\"videoId\":\\s(\\d+),', webpage, 'video ID')\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        sources = re.findall(r'<source src=\"([^\"]+)\" type=\"([^\"]+)\"', webpage)\n        formats = []\n        for src, type_ in sources:\n            if type_ == 'video/mp4':\n                formats.append({\n                    'format_id': 'mp4_sd',\n                    'preference': 1,\n                    'url': src,\n                })\n            elif type_ == 'video/webm':\n                formats.append({\n                    'format_id': 'webm_sd',\n                    'preference': 0,\n                    'url': src,\n                })\n            elif type_ == 'application/x-mpegURL':\n                formats.extend(\n                    self._extract_m3u8_formats(src, display_id, preference=-1))\n            else:\n                self.report_warning(\n                    'Encountered unexpected format: %s' % type_)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 23,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.restudy.RestudyIE._real_extract#23",
        "src_path": "youtube_dl/extractor/restudy.py",
        "class_name": "youtube_dl.extractor.restudy.RestudyIE",
        "signature": "youtube_dl.extractor.restudy.RestudyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage).strip()\n        description = self._og_search_description(webpage).strip()\n\n        formats = self._extract_smil_formats(\n            'https://www.restudy.dk/awsmedia/SmilDirectory/video_%s.xml' % video_id,\n            video_id)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n        }",
        "begin_line": 23,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vube.VubeIE._real_extract#101",
        "src_path": "youtube_dl/extractor/vube.py",
        "class_name": "youtube_dl.extractor.vube.VubeIE",
        "signature": "youtube_dl.extractor.vube.VubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video = self._download_json(\n            'http://vube.com/t-api/v1/video/%s' % video_id, video_id, 'Downloading video JSON')\n\n        public_id = video['public_id']\n\n        formats = []\n\n        for media in video['media'].get('video', []) + video['media'].get('audio', []):\n            if media['transcoding_status'] != 'processed':\n                continue\n            fmt = {\n                'url': 'http://video.thestaticvube.com/video/%s/%s.mp4' % (media['media_resolution_id'], public_id),\n                'abr': int(media['audio_bitrate']),\n                'format_id': compat_str(media['media_resolution_id']),\n            }\n            vbr = int(media['video_bitrate'])\n            if vbr:\n                fmt.update({\n                    'vbr': vbr,\n                    'height': int(media['height']),\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        if not formats and video.get('vst') == 'dmca':\n            raise ExtractorError(\n                'This video has been removed in response to a complaint received under the US Digital Millennium Copyright Act.',\n                expected=True)\n\n        title = video['title']\n        description = video.get('description')\n        thumbnail = self._proto_relative_url(video.get('thumbnail_src'), scheme='http:')\n        uploader = video.get('user_alias') or video.get('channel')\n        timestamp = int_or_none(video.get('upload_time'))\n        duration = video['duration']\n        view_count = video.get('raw_view_count')\n        like_count = video.get('total_likes')\n        dislike_count = video.get('total_hates')\n\n        comments = video.get('comments')\n        comment_count = None\n        if comments is None:\n            comment_data = self._download_json(\n                'http://vube.com/api/video/%s/comment' % video_id,\n                video_id, 'Downloading video comment JSON', fatal=False)\n            if comment_data is not None:\n                comment_count = int_or_none(comment_data.get('total'))\n        else:\n            comment_count = len(comments)\n\n        categories = [tag['text'] for tag in video['tags']]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'categories': categories,\n        }",
        "begin_line": 101,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.streetvoice.StreetVoiceIE._real_extract#31",
        "src_path": "youtube_dl/extractor/streetvoice.py",
        "class_name": "youtube_dl.extractor.streetvoice.StreetVoiceIE",
        "signature": "youtube_dl.extractor.streetvoice.StreetVoiceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n\n        song = self._download_json(\n            'http://streetvoice.com/music/api/song/%s' % song_id, song_id)\n\n        title = song['name']\n        author = song['musician']['name']\n\n        return {\n            'id': song_id,\n            'url': song['file'],\n            'filesize': song.get('size'),\n            'title': title,\n            'description': '%s - %s' % (author, title),\n            'thumbnail': self._proto_relative_url(song.get('image'), 'http:'),\n            'duration': song.get('length'),\n            'upload_date': unified_strdate(song.get('created_at')),\n            'uploader': author,\n            'uploader_id': compat_str(song['musician']['id']),\n        }",
        "begin_line": 31,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.veehd.VeeHDIE._real_extract#53",
        "src_path": "youtube_dl/extractor/veehd.py",
        "class_name": "youtube_dl.extractor.veehd.VeeHDIE",
        "signature": "youtube_dl.extractor.veehd.VeeHDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # VeeHD seems to send garbage on the first request.\n        # See https://github.com/rg3/youtube-dl/issues/2102\n        self._download_webpage(url, video_id, 'Requesting webpage')\n        webpage = self._download_webpage(url, video_id)\n\n        if 'This video has been removed<' in webpage:\n            raise ExtractorError('Video %s has been removed' % video_id, expected=True)\n\n        player_path = self._search_regex(\n            r'\\$\\(\"#playeriframe\"\\).attr\\({src : \"(.+?)\"',\n            webpage, 'player path')\n        player_url = compat_urlparse.urljoin(url, player_path)\n\n        self._download_webpage(player_url, video_id, 'Requesting player page')\n        player_page = self._download_webpage(\n            player_url, video_id, 'Downloading player page')\n\n        video_url = None\n\n        config_json = self._search_regex(\n            r'value=\\'config=({.+?})\\'', player_page, 'config json', default=None)\n\n        if config_json:\n            config = json.loads(config_json)\n            video_url = compat_urllib_parse_unquote(config['clip']['url'])\n\n        if not video_url:\n            video_url = self._html_search_regex(\n                r'<embed[^>]+type=\"video/divx\"[^>]+src=\"([^\"]+)\"',\n                player_page, 'video url', default=None)\n\n        if not video_url:\n            iframe_src = self._search_regex(\n                r'<iframe[^>]+src=\"/?([^\"]+)\"', player_page, 'iframe url')\n            iframe_url = 'http://veehd.com/%s' % iframe_src\n\n            self._download_webpage(iframe_url, video_id, 'Requesting iframe page')\n            iframe_page = self._download_webpage(\n                iframe_url, video_id, 'Downloading iframe page')\n\n            video_url = self._search_regex(\n                r\"file\\s*:\\s*'([^']+)'\", iframe_page, 'video url')\n\n        title = clean_html(get_element_by_id('videoName', webpage).rpartition('|')[0])\n        uploader_id = self._html_search_regex(\n            r'<a href=\"/profile/\\d+\">(.+?)</a>',\n            webpage, 'uploader')\n        thumbnail = self._search_regex(\n            r'<img id=\"veehdpreview\" src=\"(.+?)\"',\n            webpage, 'thumbnail')\n        description = self._html_search_regex(\n            r'<td class=\"infodropdown\".*?<div>(.*?)<ul',\n            webpage, 'description', flags=re.DOTALL)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'uploader_id': uploader_id,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 53,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_long_long#32",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_long_long(self)",
        "snippet": "    def read_unsigned_long_long(self):\n        return struct_unpack('!Q', self.read(8))[0]",
        "begin_line": 32,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_int#35",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_int(self)",
        "snippet": "    def read_unsigned_int(self):\n        return struct_unpack('!I', self.read(4))[0]",
        "begin_line": 35,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_char#38",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_char(self)",
        "snippet": "    def read_unsigned_char(self):\n        return struct_unpack('!B', self.read(1))[0]",
        "begin_line": 38,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_string#41",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_string(self)",
        "snippet": "    def read_string(self):\n        res = b''\n        while True:\n            char = self.read(1)\n            if char == b'\\x00':\n                break\n            res += char\n        return res",
        "begin_line": 41,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_box_info#50",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_box_info(self)",
        "snippet": "    def read_box_info(self):\n        \"\"\"\n        Read a box and return the info as a tuple: (box_size, box_type, box_data)\n        \"\"\"\n        real_size = size = self.read_unsigned_int()\n        box_type = self.read(4)\n        header_end = 8\n        if size == 1:\n            real_size = self.read_unsigned_long_long()\n            header_end = 16\n        return real_size, box_type, self.read(real_size - header_end)",
        "begin_line": 50,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_asrt#62",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_asrt(self)",
        "snippet": "    def read_asrt(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read(3)\n        quality_entry_count = self.read_unsigned_char()\n        # QualityEntryCount\n        for i in range(quality_entry_count):\n            self.read_string()\n\n        segment_run_count = self.read_unsigned_int()\n        segments = []\n        for i in range(segment_run_count):\n            first_segment = self.read_unsigned_int()\n            fragments_per_segment = self.read_unsigned_int()\n            segments.append((first_segment, fragments_per_segment))\n\n        return {\n            'segment_run': segments,\n        }",
        "begin_line": 62,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_afrt#83",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_afrt(self)",
        "snippet": "    def read_afrt(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read(3)\n        # time scale\n        self.read_unsigned_int()\n\n        quality_entry_count = self.read_unsigned_char()\n        # QualitySegmentUrlModifiers\n        for i in range(quality_entry_count):\n            self.read_string()\n\n        fragments_count = self.read_unsigned_int()\n        fragments = []\n        for i in range(fragments_count):\n            first = self.read_unsigned_int()\n            first_ts = self.read_unsigned_long_long()\n            duration = self.read_unsigned_int()\n            if duration == 0:\n                discontinuity_indicator = self.read_unsigned_char()\n            else:\n                discontinuity_indicator = None\n            fragments.append({\n                'first': first,\n                'ts': first_ts,\n                'duration': duration,\n                'discontinuity_indicator': discontinuity_indicator,\n            })\n\n        return {\n            'fragments': fragments,\n        }",
        "begin_line": 83,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_abst#117",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_abst(self)",
        "snippet": "    def read_abst(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read(3)\n\n        self.read_unsigned_int()  # BootstrapinfoVersion\n        # Profile,Live,Update,Reserved\n        flags = self.read_unsigned_char()\n        live = flags & 0x20 != 0\n        # time scale\n        self.read_unsigned_int()\n        # CurrentMediaTime\n        self.read_unsigned_long_long()\n        # SmpteTimeCodeOffset\n        self.read_unsigned_long_long()\n\n        self.read_string()  # MovieIdentifier\n        server_count = self.read_unsigned_char()\n        # ServerEntryTable\n        for i in range(server_count):\n            self.read_string()\n        quality_count = self.read_unsigned_char()\n        # QualityEntryTable\n        for i in range(quality_count):\n            self.read_string()\n        # DrmData\n        self.read_string()\n        # MetaData\n        self.read_string()\n\n        segments_count = self.read_unsigned_char()\n        segments = []\n        for i in range(segments_count):\n            box_size, box_type, box_data = self.read_box_info()\n            assert box_type == b'asrt'\n            segment = FlvReader(box_data).read_asrt()\n            segments.append(segment)\n        fragments_run_count = self.read_unsigned_char()\n        fragments = []\n        for i in range(fragments_run_count):\n            box_size, box_type, box_data = self.read_box_info()\n            assert box_type == b'afrt'\n            fragments.append(FlvReader(box_data).read_afrt())\n\n        return {\n            'segments': segments,\n            'fragments': fragments,\n            'live': live,\n        }",
        "begin_line": 117,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_bootstrap_info#168",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_bootstrap_info(self)",
        "snippet": "    def read_bootstrap_info(self):\n        total_size, box_type, box_data = self.read_box_info()\n        assert box_type == b'abst'\n        return FlvReader(box_data).read_abst()",
        "begin_line": 168,
        "end_line": 171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.read_bootstrap_info#174",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.read_bootstrap_info(bootstrap_bytes)",
        "snippet": "def read_bootstrap_info(bootstrap_bytes):\n    return FlvReader(bootstrap_bytes).read_bootstrap_info()",
        "begin_line": 174,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.build_fragments_list#178",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.build_fragments_list(boot_info)",
        "snippet": "def build_fragments_list(boot_info):\n    \"\"\" Return a list of (segment, fragment) for each fragment in the video \"\"\"\n    res = []\n    segment_run_table = boot_info['segments'][0]\n    fragment_run_entry_table = boot_info['fragments'][0]['fragments']\n    first_frag_number = fragment_run_entry_table[0]['first']\n    fragments_counter = itertools.count(first_frag_number)\n    for segment, fragments_count in segment_run_table['segment_run']:\n        for _ in range(fragments_count):\n            res.append((segment, next(fragments_counter)))\n\n    if boot_info['live']:\n        res = res[-2:]\n\n    return res",
        "begin_line": 178,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.write_unsigned_int#195",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.write_unsigned_int(stream, val)",
        "snippet": "def write_unsigned_int(stream, val):\n    stream.write(struct_pack('!I', val))",
        "begin_line": 195,
        "end_line": 196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.write_unsigned_int_24#199",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.write_unsigned_int_24(stream, val)",
        "snippet": "def write_unsigned_int_24(stream, val):\n    stream.write(struct_pack('!I', val)[1:])",
        "begin_line": 199,
        "end_line": 200,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.write_flv_header#203",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.write_flv_header(stream)",
        "snippet": "def write_flv_header(stream):\n    \"\"\"Writes the FLV header to stream\"\"\"\n    # FLV header\n    stream.write(b'FLV\\x01')\n    stream.write(b'\\x05')\n    stream.write(b'\\x00\\x00\\x00\\x09')\n    stream.write(b'\\x00\\x00\\x00\\x00')",
        "begin_line": 203,
        "end_line": 209,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.write_metadata_tag#212",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.write_metadata_tag(stream, metadata)",
        "snippet": "def write_metadata_tag(stream, metadata):\n    \"\"\"Writes optional metadata tag to stream\"\"\"\n    SCRIPT_TAG = b'\\x12'\n    FLV_TAG_HEADER_LEN = 11\n\n    if metadata:\n        stream.write(SCRIPT_TAG)\n        write_unsigned_int_24(stream, len(metadata))\n        stream.write(b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00')\n        stream.write(metadata)\n        write_unsigned_int(stream, FLV_TAG_HEADER_LEN + len(metadata))",
        "begin_line": 212,
        "end_line": 222,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m._add_ns#225",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m._add_ns(prop)",
        "snippet": "def _add_ns(prop):\n    return '{http://ns.adobe.com/f4m/1.0}%s' % prop",
        "begin_line": 225,
        "end_line": 226,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD._get_unencrypted_media#236",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD._get_unencrypted_media(self, doc)",
        "snippet": "    def _get_unencrypted_media(self, doc):\n        media = doc.findall(_add_ns('media'))\n        if not media:\n            self.report_error('No media found')\n        for e in (doc.findall(_add_ns('drmAdditionalHeader')) +\n                  doc.findall(_add_ns('drmAdditionalHeaderSet'))):\n            # If id attribute is missing it's valid for all media nodes\n            # without drmAdditionalHeaderId or drmAdditionalHeaderSetId attribute\n            if 'id' not in e.attrib:\n                self.report_error('Missing ID in f4m DRM')\n        media = list(filter(lambda e: 'drmAdditionalHeaderId' not in e.attrib and\n                                      'drmAdditionalHeaderSetId' not in e.attrib,\n                            media))\n        if not media:\n            self.report_error('Unsupported DRM')\n        return media",
        "begin_line": 236,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD._get_bootstrap_from_url#253",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD._get_bootstrap_from_url(self, bootstrap_url)",
        "snippet": "    def _get_bootstrap_from_url(self, bootstrap_url):\n        bootstrap = self.ydl.urlopen(bootstrap_url).read()\n        return read_bootstrap_info(bootstrap)",
        "begin_line": 253,
        "end_line": 255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD._update_live_fragments#257",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD._update_live_fragments(self, bootstrap_url, latest_fragment)",
        "snippet": "    def _update_live_fragments(self, bootstrap_url, latest_fragment):\n        fragments_list = []\n        retries = 30\n        while (not fragments_list) and (retries > 0):\n            boot_info = self._get_bootstrap_from_url(bootstrap_url)\n            fragments_list = build_fragments_list(boot_info)\n            fragments_list = [f for f in fragments_list if f[1] > latest_fragment]\n            if not fragments_list:\n                # Retry after a while\n                time.sleep(5.0)\n                retries -= 1\n\n        if not fragments_list:\n            self.report_error('Failed to update fragments')\n\n        return fragments_list",
        "begin_line": 257,
        "end_line": 272,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD._parse_bootstrap_node#274",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD._parse_bootstrap_node(self, node, base_url)",
        "snippet": "    def _parse_bootstrap_node(self, node, base_url):\n        if node.text is None:\n            bootstrap_url = compat_urlparse.urljoin(\n                base_url, node.attrib['url'])\n            boot_info = self._get_bootstrap_from_url(bootstrap_url)\n        else:\n            bootstrap_url = None\n            bootstrap = base64.b64decode(node.text.encode('ascii'))\n            boot_info = read_bootstrap_info(bootstrap)\n        return (boot_info, bootstrap_url)",
        "begin_line": 274,
        "end_line": 283,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD.real_download#285",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        man_url = info_dict['url']\n        requested_bitrate = info_dict.get('tbr')\n        self.to_screen('[%s] Downloading f4m manifest' % self.FD_NAME)\n        urlh = self.ydl.urlopen(man_url)\n        man_url = urlh.geturl()\n        manifest = urlh.read()\n\n        doc = compat_etree_fromstring(manifest)\n        formats = [(int(f.attrib.get('bitrate', -1)), f)\n                   for f in self._get_unencrypted_media(doc)]\n        if requested_bitrate is None:\n            # get the best format\n            formats = sorted(formats, key=lambda f: f[0])\n            rate, media = formats[-1]\n        else:\n            rate, media = list(filter(\n                lambda f: int(f[0]) == requested_bitrate, formats))[0]\n\n        base_url = compat_urlparse.urljoin(man_url, media.attrib['url'])\n        bootstrap_node = doc.find(_add_ns('bootstrapInfo'))\n        boot_info, bootstrap_url = self._parse_bootstrap_node(bootstrap_node, base_url)\n        live = boot_info['live']\n        metadata_node = media.find(_add_ns('metadata'))\n        if metadata_node is not None:\n            metadata = base64.b64decode(metadata_node.text.encode('ascii'))\n        else:\n            metadata = None\n\n        fragments_list = build_fragments_list(boot_info)\n        if self.params.get('test', False):\n            # We only download the first fragment\n            fragments_list = fragments_list[:1]\n        total_frags = len(fragments_list)\n        # For some akamai manifests we'll need to add a query to the fragment url\n        akamai_pv = xpath_text(doc, _add_ns('pv-2.0'))\n\n        ctx = {\n            'filename': filename,\n            'total_frags': total_frags,\n        }\n\n        self._prepare_frag_download(ctx)\n\n        dest_stream = ctx['dest_stream']\n\n        write_flv_header(dest_stream)\n        if not live:\n            write_metadata_tag(dest_stream, metadata)\n\n        base_url_parsed = compat_urllib_parse_urlparse(base_url)\n\n        self._start_frag_download(ctx)\n\n        frags_filenames = []\n        while fragments_list:\n            seg_i, frag_i = fragments_list.pop(0)\n            name = 'Seg%d-Frag%d' % (seg_i, frag_i)\n            query = []\n            if base_url_parsed.query:\n                query.append(base_url_parsed.query)\n            if akamai_pv:\n                query.append(akamai_pv.strip(';'))\n            if info_dict.get('extra_param_to_segment_url'):\n                query.append(info_dict['extra_param_to_segment_url'])\n            url_parsed = base_url_parsed._replace(path=base_url_parsed.path + name, query='&'.join(query))\n            frag_filename = '%s-%s' % (ctx['tmpfilename'], name)\n            try:\n                success = ctx['dl'].download(frag_filename, {'url': url_parsed.geturl()})\n                if not success:\n                    return False\n                (down, frag_sanitized) = sanitize_open(frag_filename, 'rb')\n                down_data = down.read()\n                down.close()\n                reader = FlvReader(down_data)\n                while True:\n                    _, box_type, box_data = reader.read_box_info()\n                    if box_type == b'mdat':\n                        dest_stream.write(box_data)\n                        break\n                if live:\n                    os.remove(encodeFilename(frag_sanitized))\n                else:\n                    frags_filenames.append(frag_sanitized)\n            except (compat_urllib_error.HTTPError, ) as err:\n                if live and (err.code == 404 or err.code == 410):\n                    # We didn't keep up with the live window. Continue\n                    # with the next available fragment.\n                    msg = 'Fragment %d unavailable' % frag_i\n                    self.report_warning(msg)\n                    fragments_list = []\n                else:\n                    raise\n\n            if not fragments_list and live and bootstrap_url:\n                fragments_list = self._update_live_fragments(bootstrap_url, frag_i)\n                total_frags += len(fragments_list)\n                if fragments_list and (fragments_list[0][1] > frag_i + 1):\n                    msg = 'Missed %d fragments' % (fragments_list[0][1] - (frag_i + 1))\n                    self.report_warning(msg)\n\n        self._finish_frag_download(ctx)\n\n        for frag_file in frags_filenames:\n            os.remove(encodeFilename(frag_file))\n\n        return True",
        "begin_line": 285,
        "end_line": 391,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.glide.GlideIE._real_extract#21",
        "src_path": "youtube_dl/extractor/glide.py",
        "class_name": "youtube_dl.extractor.glide.GlideIE",
        "signature": "youtube_dl.extractor.glide.GlideIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(\n            r'<title>(.*?)</title>', webpage, 'title')\n        video_url = self.http_scheme() + self._search_regex(\n            r'<source src=\"(.*?)\" type=\"video/mp4\">', webpage, 'video URL')\n        thumbnail_url = self._search_regex(\n            r'<img id=\"video-thumbnail\" src=\"(.*?)\"',\n            webpage, 'thumbnail url', fatal=False)\n        thumbnail = (\n            thumbnail_url if thumbnail_url is None\n            else self.http_scheme() + thumbnail_url)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 21,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.__init__#14",
        "src_path": "youtube_dl/postprocessor/metadatafromtitle.py",
        "class_name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP",
        "signature": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.__init__(self, downloader, titleformat)",
        "snippet": "    def __init__(self, downloader, titleformat):\n        super(MetadataFromTitlePP, self).__init__(downloader)\n        self._titleformat = titleformat\n        self._titleregex = self.format_to_regex(titleformat)",
        "begin_line": 14,
        "end_line": 17,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.format_to_regex#19",
        "src_path": "youtube_dl/postprocessor/metadatafromtitle.py",
        "class_name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP",
        "signature": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.format_to_regex(self, fmt)",
        "snippet": "    def format_to_regex(self, fmt):\n        \"\"\"\n        Converts a string like\n           '%(title)s - %(artist)s'\n        to a regex like\n           '(?P<title>.+)\\ \\-\\ (?P<artist>.+)'\n        \"\"\"\n        lastpos = 0\n        regex = \"\"\n        # replace %(..)s with regex group and escape other string parts\n        for match in re.finditer(r'%\\((\\w+)\\)s', fmt):\n            regex += re.escape(fmt[lastpos:match.start()])\n            regex += r'(?P<' + match.group(1) + '>.+)'\n            lastpos = match.end()\n        if lastpos < len(fmt):\n            regex += re.escape(fmt[lastpos:len(fmt)])\n        return regex",
        "begin_line": 19,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.run#37",
        "src_path": "youtube_dl/postprocessor/metadatafromtitle.py",
        "class_name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP",
        "signature": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.run(self, info)",
        "snippet": "    def run(self, info):\n        title = info['title']\n        match = re.match(self._titleregex, title)\n        if match is None:\n            raise MetadataFromTitlePPError('Could not interpret title of video as \"%s\"' % self._titleformat)\n        for attribute, value in match.groupdict().items():\n            value = match.group(attribute)\n            info[attribute] = value\n            self._downloader.to_screen('[fromtitle] parsed ' + attribute + ': ' + value)\n\n        return [], info",
        "begin_line": 37,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.wistia.WistiaIE._real_extract#23",
        "src_path": "youtube_dl/extractor/wistia.py",
        "class_name": "youtube_dl.extractor.wistia.WistiaIE",
        "signature": "youtube_dl.extractor.wistia.WistiaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        request = compat_urllib_request.Request(self._API_URL.format(video_id))\n        request.add_header('Referer', url)  # Some videos require this.\n        data_json = self._download_json(request, video_id)\n        if data_json.get('error'):\n            raise ExtractorError('Error while getting the playlist',\n                                 expected=True)\n        data = data_json['media']\n\n        formats = []\n        thumbnails = []\n        for atype, a in data['assets'].items():\n            if atype == 'still':\n                thumbnails.append({\n                    'url': a['url'],\n                    'resolution': '%dx%d' % (a['width'], a['height']),\n                })\n                continue\n            if atype == 'preview':\n                continue\n            formats.append({\n                'format_id': atype,\n                'url': a['url'],\n                'width': a['width'],\n                'height': a['height'],\n                'filesize': a['size'],\n                'ext': a['ext'],\n                'preference': 1 if atype == 'original' else None,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': data['name'],\n            'formats': formats,\n            'thumbnails': thumbnails,\n            'duration': data.get('duration'),\n        }",
        "begin_line": 23,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.spiegel.SpiegelIE._real_extract#47",
        "src_path": "youtube_dl/extractor/spiegel.py",
        "class_name": "youtube_dl.extractor.spiegel.SpiegelIE",
        "signature": "youtube_dl.extractor.spiegel.SpiegelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage, handle = self._download_webpage_handle(url, video_id)\n\n        # 302 to spiegel.tv, like http://www.spiegel.de/video/der-film-zum-wochenende-die-wahrheit-ueber-maenner-video-99003272.html\n        if SpiegeltvIE.suitable(handle.geturl()):\n            return self.url_result(handle.geturl(), 'Spiegeltv')\n\n        title = re.sub(r'\\s+', ' ', self._html_search_regex(\n            r'(?s)<(?:h1|div) class=\"module-title\"[^>]*>(.*?)</(?:h1|div)>',\n            webpage, 'title'))\n        description = self._html_search_meta('description', webpage, 'description')\n\n        base_url = self._search_regex(\n            r'var\\s+server\\s*=\\s*\"([^\"]+)\\\"', webpage, 'server URL')\n\n        xml_url = base_url + video_id + '.xml'\n        idoc = self._download_xml(xml_url, video_id)\n\n        formats = []\n        for n in list(idoc):\n            if n.tag.startswith('type') and n.tag != 'type6':\n                format_id = n.tag.rpartition('type')[2]\n                video_url = base_url + n.find('./filename').text\n                formats.append({\n                    'format_id': format_id,\n                    'url': video_url,\n                    'width': int(n.find('./width').text),\n                    'height': int(n.find('./height').text),\n                    'abr': int(n.find('./audiobitrate').text),\n                    'vbr': int(n.find('./videobitrate').text),\n                    'vcodec': n.find('./codec').text,\n                    'acodec': 'MP4A',\n                })\n        duration = float(idoc[0].findall('./duration')[0].text)\n\n        self._check_formats(formats, video_id)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 47,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.spiegel.SpiegelArticleIE._real_extract#115",
        "src_path": "youtube_dl/extractor/spiegel.py",
        "class_name": "youtube_dl.extractor.spiegel.SpiegelArticleIE",
        "signature": "youtube_dl.extractor.spiegel.SpiegelArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        # Single video on top of the page\n        video_link = self._search_regex(\n            r'<a href=\"([^\"]+)\" onclick=\"return spOpenVideo\\(this,', webpage,\n            'video page URL', default=None)\n        if video_link:\n            video_url = compat_urlparse.urljoin(\n                self.http_scheme() + '//spiegel.de/', video_link)\n            return self.url_result(video_url)\n\n        # Multiple embedded videos\n        embeds = re.findall(\n            r'<div class=\"vid_holder[0-9]+.*?</div>\\s*.*?url\\s*=\\s*\"([^\"]+)\"',\n            webpage)\n        entries = [\n            self.url_result(compat_urlparse.urljoin(\n                self.http_scheme() + '//spiegel.de/', embed_path))\n            for embed_path in embeds\n        ]\n        return self.playlist_result(entries)",
        "begin_line": 115,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.telecinco.TelecincoIE._real_extract#58",
        "src_path": "youtube_dl/extractor/telecinco.py",
        "class_name": "youtube_dl.extractor.telecinco.TelecincoIE",
        "signature": "youtube_dl.extractor.telecinco.TelecincoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        episode = self._match_id(url)\n        webpage = self._download_webpage(url, episode)\n        embed_data_json = self._search_regex(\n            r'(?s)MSV\\.embedData\\[.*?\\]\\s*=\\s*({.*?});', webpage, 'embed data',\n        ).replace('\\'', '\"')\n        embed_data = json.loads(embed_data_json)\n\n        domain = embed_data['mediaUrl']\n        if not domain.startswith('http'):\n            # only happens in telecinco.es videos\n            domain = 'http://' + domain\n        info_url = compat_urlparse.urljoin(\n            domain,\n            compat_urllib_parse_unquote(embed_data['flashvars']['host'])\n        )\n        info_el = self._download_xml(info_url, episode).find('./video/info')\n\n        video_link = info_el.find('videoUrl/link').text\n        token_query = compat_urllib_parse.urlencode({'id': video_link})\n        token_info = self._download_json(\n            embed_data['flashvars']['ov_tk'] + '?' + token_query,\n            episode,\n            transform_source=strip_jsonp\n        )\n        formats = self._extract_m3u8_formats(\n            token_info['tokenizedUrl'], episode, ext='mp4', entry_protocol='m3u8_native')\n\n        return {\n            'id': embed_data['videoId'],\n            'display_id': episode,\n            'title': info_el.find('title').text,\n            'formats': formats,\n            'description': get_element_by_attribute('class', 'text', webpage),\n            'thumbnail': info_el.find('thumb').text,\n            'duration': parse_duration(info_el.find('duration').text),\n        }",
        "begin_line": 58,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yourupload.YourUploadIE._real_extract#35",
        "src_path": "youtube_dl/extractor/yourupload.py",
        "class_name": "youtube_dl.extractor.yourupload.YourUploadIE",
        "signature": "youtube_dl.extractor.yourupload.YourUploadIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        embed_url = 'http://embed.yucache.net/{0:}'.format(video_id)\n        webpage = self._download_webpage(embed_url, video_id)\n\n        title = self._og_search_title(webpage)\n        video_url = self._og_search_video_url(webpage)\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'http_headers': {\n                'Referer': embed_url,\n            },\n        }",
        "begin_line": 35,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nowtv.NowTVIE._real_extract#138",
        "src_path": "youtube_dl/extractor/nowtv.py",
        "class_name": "youtube_dl.extractor.nowtv.NowTVIE",
        "signature": "youtube_dl.extractor.nowtv.NowTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        display_id_split = display_id.split('/')\n        if len(display_id) > 2:\n            display_id = '/'.join((display_id_split[0], display_id_split[-1]))\n\n        info = self._download_json(\n            'https://api.nowtv.de/v3/movies/%s?fields=id,title,free,geoblocked,articleLong,articleShort,broadcastStartDate,seoUrl,duration,format,files' % display_id,\n            display_id)\n\n        video_id = compat_str(info['id'])\n\n        files = info['files']\n        if not files:\n            if info.get('geoblocked', False):\n                raise ExtractorError(\n                    'Video %s is not available from your location due to geo restriction' % video_id,\n                    expected=True)\n            if not info.get('free', True):\n                raise ExtractorError(\n                    'Video %s is not available for free' % video_id, expected=True)\n\n        formats = []\n        for item in files['items']:\n            if determine_ext(item['path']) != 'f4v':\n                continue\n            app, play_path = remove_start(item['path'], '/').split('/', 1)\n            formats.append({\n                'url': 'rtmpe://fms.rtl.de',\n                'app': app,\n                'play_path': 'mp4:%s' % play_path,\n                'ext': 'flv',\n                'page_url': 'http://rtlnow.rtl.de',\n                'player_url': 'http://cdn.static-fra.de/now/vodplayer.swf',\n                'tbr': int_or_none(item.get('bitrate')),\n            })\n        self._sort_formats(formats)\n\n        title = info['title']\n        description = info.get('articleLong') or info.get('articleShort')\n        timestamp = parse_iso8601(info.get('broadcastStartDate'), ' ')\n        duration = parse_duration(info.get('duration'))\n\n        f = info.get('format', {})\n        thumbnail = f.get('defaultImage169Format') or f.get('defaultImage169Logo')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 138,
        "end_line": 193,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tudou.TudouIE._url_for_id#35",
        "src_path": "youtube_dl/extractor/tudou.py",
        "class_name": "youtube_dl.extractor.tudou.TudouIE",
        "signature": "youtube_dl.extractor.tudou.TudouIE._url_for_id(self, video_id, quality=None)",
        "snippet": "    def _url_for_id(self, video_id, quality=None):\n        info_url = 'http://v2.tudou.com/f?id=' + compat_str(video_id)\n        if quality:\n            info_url += '&hd' + quality\n        xml_data = self._download_xml(info_url, video_id, \"Opening the info XML page\")\n        final_url = xml_data.text\n        return final_url",
        "begin_line": 35,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tudou.TudouIE._real_extract#43",
        "src_path": "youtube_dl/extractor/tudou.py",
        "class_name": "youtube_dl.extractor.tudou.TudouIE",
        "signature": "youtube_dl.extractor.tudou.TudouIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        youku_vcode = self._search_regex(\n            r'vcode\\s*:\\s*[\\'\"]([^\\'\"]*)[\\'\"]', webpage, 'youku vcode', default=None)\n        if youku_vcode:\n            return self.url_result('youku:' + youku_vcode, ie='Youku')\n\n        title = self._search_regex(\n            r',kw\\s*:\\s*[\\'\"]([^\\'\"]+)[\\'\"]', webpage, 'title')\n        thumbnail_url = self._search_regex(\n            r',pic\\s*:\\s*[\\'\"]([^\\'\"]+)[\\'\"]', webpage, 'thumbnail URL', fatal=False)\n\n        player_url = self._search_regex(\n            r'playerUrl\\s*:\\s*[\\'\"]([^\\'\"]+\\.swf)[\\'\"]',\n            webpage, 'player URL', default=self._PLAYER_URL)\n\n        segments = self._parse_json(self._search_regex(\n            r'segs: \\'([^\\']+)\\'', webpage, 'segments'), video_id)\n        # It looks like the keys are the arguments that have to be passed as\n        # the hd field in the request url, we pick the higher\n        # Also, filter non-number qualities (see issue #3643).\n        quality = sorted(filter(lambda k: k.isdigit(), segments.keys()),\n                         key=lambda k: int(k))[-1]\n        parts = segments[quality]\n        result = []\n        len_parts = len(parts)\n        if len_parts > 1:\n            self.to_screen('%s: found %s parts' % (video_id, len_parts))\n        for part in parts:\n            part_id = part['k']\n            final_url = self._url_for_id(part_id, quality)\n            ext = (final_url.split('?')[0]).split('.')[-1]\n            part_info = {\n                'id': '%s' % part_id,\n                'url': final_url,\n                'ext': ext,\n                'title': title,\n                'thumbnail': thumbnail_url,\n                'http_headers': {\n                    'Referer': player_url,\n                },\n            }\n            result.append(part_info)\n\n        return {\n            '_type': 'multi_video',\n            'entries': result,\n            'id': video_id,\n            'title': title,\n        }",
        "begin_line": 43,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.daum.DaumIE._real_extract#35",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumIE",
        "signature": "youtube_dl.extractor.daum.DaumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        canonical_url = 'http://tvpot.daum.net/v/%s' % video_id\n        webpage = self._download_webpage(canonical_url, video_id)\n        full_id = self._search_regex(\n            r'src=[\"\\']http://videofarm\\.daum\\.net/controller/video/viewer/Video\\.html\\?.*?vid=(.+?)[&\"\\']',\n            webpage, 'full id')\n        query = compat_urllib_parse.urlencode({'vid': full_id})\n        info = self._download_xml(\n            'http://tvpot.daum.net/clip/ClipInfoXml.do?' + query, video_id,\n            'Downloading video info')\n        urls = self._download_xml(\n            'http://videofarm.daum.net/controller/api/open/v1_2/MovieData.apixml?' + query,\n            video_id, 'Downloading video formats info')\n\n        formats = []\n        for format_el in urls.findall('result/output_list/output_list'):\n            profile = format_el.attrib['profile']\n            format_query = compat_urllib_parse.urlencode({\n                'vid': full_id,\n                'profile': profile,\n            })\n            url_doc = self._download_xml(\n                'http://videofarm.daum.net/controller/api/open/v1_2/MovieLocation.apixml?' + format_query,\n                video_id, note='Downloading video data for %s format' % profile)\n            format_url = url_doc.find('result/url').text\n            formats.append({\n                'url': format_url,\n                'format_id': profile,\n            })\n\n        return {\n            'id': video_id,\n            'title': info.find('TITLE').text,\n            'formats': formats,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': info.find('CONTENTS').text,\n            'duration': int(info.find('DURATION').text),\n            'upload_date': info.find('REGDTTM').text[:8],\n        }",
        "begin_line": 35,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.snotr.SnotrIE._real_extract#38",
        "src_path": "youtube_dl/extractor/snotr.py",
        "class_name": "youtube_dl.extractor.snotr.SnotrIE",
        "signature": "youtube_dl.extractor.snotr.SnotrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage)\n\n        description = self._og_search_description(webpage)\n        video_url = \"http://cdn.videos.snotr.com/%s.flv\" % video_id\n\n        view_count = str_to_int(self._html_search_regex(\n            r'<p>\\n<strong>Views:</strong>\\n([\\d,\\.]+)</p>',\n            webpage, 'view count', fatal=False))\n\n        duration = parse_duration(self._html_search_regex(\n            r'<p>\\n<strong>Length:</strong>\\n\\s*([0-9:]+).*?</p>',\n            webpage, 'duration', fatal=False))\n\n        filesize_approx = float_or_none(self._html_search_regex(\n            r'<p>\\n<strong>Filesize:</strong>\\n\\s*([0-9.]+)\\s*megabyte</p>',\n            webpage, 'filesize', fatal=False), invscale=1024 * 1024)\n\n        return {\n            'id': video_id,\n            'description': description,\n            'title': title,\n            'url': video_url,\n            'view_count': view_count,\n            'duration': duration,\n            'filesize_approx': filesize_approx,\n        }",
        "begin_line": 38,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bloomberg.BloombergIE._real_extract#22",
        "src_path": "youtube_dl/extractor/bloomberg.py",
        "class_name": "youtube_dl.extractor.bloomberg.BloombergIE",
        "signature": "youtube_dl.extractor.bloomberg.BloombergIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        name = self._match_id(url)\n        webpage = self._download_webpage(url, name)\n        video_id = self._search_regex(r'\"bmmrId\":\"(.+?)\"', webpage, 'id')\n        title = re.sub(': Video$', '', self._og_search_title(webpage))\n\n        embed_info = self._download_json(\n            'http://www.bloomberg.com/api/embed?id=%s' % video_id, video_id)\n        formats = []\n        for stream in embed_info['streams']:\n            if stream[\"muxing_format\"] == \"TS\":\n                formats.extend(self._extract_m3u8_formats(stream['url'], video_id))\n            else:\n                formats.extend(self._extract_f4m_formats(stream['url'], video_id))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 22,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.hearthisat.HearThisAtIE._real_extract#41",
        "src_path": "youtube_dl/extractor/hearthisat.py",
        "class_name": "youtube_dl.extractor.hearthisat.HearThisAtIE",
        "signature": "youtube_dl.extractor.hearthisat.HearThisAtIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        display_id = '{artist:s} - {title:s}'.format(**m.groupdict())\n\n        webpage = self._download_webpage(url, display_id)\n        track_id = self._search_regex(\n            r'intTrackId\\s*=\\s*(\\d+)', webpage, 'track ID')\n\n        payload = urlencode_postdata({'tracks[]': track_id})\n        req = compat_urllib_request.Request(self._PLAYLIST_URL, payload)\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n        track = self._download_json(req, track_id, 'Downloading playlist')[0]\n        title = '{artist:s} - {title:s}'.format(**track)\n\n        categories = None\n        if track.get('category'):\n            categories = [track['category']]\n\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        meta_span = r'<span[^>]+class=\"%s\".*?</i>([^<]+)</span>'\n        view_count = str_to_int(self._search_regex(\n            meta_span % 'plays_count', webpage, 'view count', fatal=False))\n        like_count = str_to_int(self._search_regex(\n            meta_span % 'likes_count', webpage, 'like count', fatal=False))\n        comment_count = str_to_int(self._search_regex(\n            meta_span % 'comment_count', webpage, 'comment count', fatal=False))\n        duration = str_to_int(self._search_regex(\n            r'data-length=\"(\\d+)', webpage, 'duration', fatal=False))\n        timestamp = str_to_int(self._search_regex(\n            r'<span[^>]+class=\"calctime\"[^>]+data-time=\"(\\d+)', webpage, 'timestamp', fatal=False))\n\n        formats = []\n        mp3_url = self._search_regex(\n            r'(?s)<a class=\"player-link\"\\s+(?:[a-zA-Z0-9_:-]+=\"[^\"]+\"\\s+)*?data-mp3=\"([^\"]+)\"',\n            webpage, 'mp3 URL', fatal=False)\n        if mp3_url:\n            formats.append({\n                'format_id': 'mp3',\n                'vcodec': 'none',\n                'acodec': 'mp3',\n                'url': mp3_url,\n            })\n        download_path = self._search_regex(\n            r'<a class=\"[^\"]*download_fct[^\"]*\"\\s+href=\"([^\"]+)\"',\n            webpage, 'download URL', default=None)\n        if download_path:\n            download_url = compat_urlparse.urljoin(url, download_path)\n            ext_req = HEADRequest(download_url)\n            ext_handle = self._request_webpage(\n                ext_req, display_id, note='Determining extension')\n            ext = urlhandle_detect_ext(ext_handle)\n            formats.append({\n                'format_id': 'download',\n                'vcodec': 'none',\n                'ext': ext,\n                'url': download_url,\n                'preference': 2,  # Usually better quality\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': track_id,\n            'display_id': display_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'like_count': like_count,\n            'categories': categories,\n        }",
        "begin_line": 41,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.planetaplay.PlanetaPlayIE._real_extract#30",
        "src_path": "youtube_dl/extractor/planetaplay.py",
        "class_name": "youtube_dl.extractor.planetaplay.PlanetaPlayIE",
        "signature": "youtube_dl.extractor.planetaplay.PlanetaPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        response = self._download_json(\n            self._API_URL.format(video_id), video_id)['response']\n        try:\n            data = response.get('data')[0]\n        except IndexError:\n            raise ExtractorError(\n                '%s: failed to get the playlist' % self.IE_NAME, expected=True)\n\n        title = '{song_artists:} - {sng_name:}'.format(**data)\n        thumbnail = self._THUMBNAIL_URL.format(**data)\n\n        formats = []\n        for format_id, (quality, url_template) in self._SONG_FORMATS.items():\n            formats.append({\n                'format_id': format_id,\n                'url': url_template.format(**data),\n                'quality': quality,\n                'ext': 'flv',\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 30,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sport5.Sport5IE._real_extract#38",
        "src_path": "youtube_dl/extractor/sport5.py",
        "class_name": "youtube_dl.extractor.sport5.Sport5IE",
        "signature": "youtube_dl.extractor.sport5.Sport5IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        media_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, media_id)\n\n        video_id = self._html_search_regex('clipId=([\\w-]+)', webpage, 'video id')\n\n        metadata = self._download_xml(\n            'http://sport5-metadata-rr-d.nsacdn.com/vod/vod/%s/HDS/metadata.xml' % video_id,\n            video_id)\n\n        error = metadata.find('./Error')\n        if error is not None:\n            raise ExtractorError(\n                '%s returned error: %s - %s' % (\n                    self.IE_NAME,\n                    error.find('./Name').text,\n                    error.find('./Description').text),\n                expected=True)\n\n        title = metadata.find('./Title').text\n        description = metadata.find('./Description').text\n        duration = int(metadata.find('./Duration').text)\n\n        posters_el = metadata.find('./PosterLinks')\n        thumbnails = [{\n            'url': thumbnail.text,\n            'width': int(thumbnail.get('width')),\n            'height': int(thumbnail.get('height')),\n        } for thumbnail in posters_el.findall('./PosterIMG')] if posters_el is not None else []\n\n        categories_el = metadata.find('./Categories')\n        categories = [\n            cat.get('name') for cat in categories_el.findall('./Category')\n        ] if categories_el is not None else []\n\n        formats = [{\n            'url': fmt.text,\n            'ext': 'mp4',\n            'vbr': int(fmt.get('bitrate')),\n            'width': int(fmt.get('width')),\n            'height': int(fmt.get('height')),\n        } for fmt in metadata.findall('./PlaybackLinks/FileURL')]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'duration': duration,\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 38,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.allocine.AllocineIE._real_extract#52",
        "src_path": "youtube_dl/extractor/allocine.py",
        "class_name": "youtube_dl.extractor.allocine.AllocineIE",
        "signature": "youtube_dl.extractor.allocine.AllocineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        typ = mobj.group('typ')\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        if typ == 'film':\n            video_id = self._search_regex(r'href=\"/video/player_gen_cmedia=([0-9]+).+\"', webpage, 'video id')\n        else:\n            player = self._search_regex(r'data-player=\\'([^\\']+)\\'>', webpage, 'data player')\n\n            player_data = json.loads(player)\n            video_id = compat_str(player_data['refMedia'])\n\n        xml = self._download_xml('http://www.allocine.fr/ws/AcVisiondataV4.ashx?media=%s' % video_id, display_id)\n\n        video = xml.find('.//AcVisionVideo').attrib\n        quality = qualities(['ld', 'md', 'hd'])\n\n        formats = []\n        for k, v in video.items():\n            if re.match(r'.+_path', k):\n                format_id = k.split('_')[0]\n                formats.append({\n                    'format_id': format_id,\n                    'quality': quality(format_id),\n                    'url': v,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video['videoTitle'],\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 52,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ultimedia.UltimediaIE._real_extract#44",
        "src_path": "youtube_dl/extractor/ultimedia.py",
        "class_name": "youtube_dl.extractor.ultimedia.UltimediaIE",
        "signature": "youtube_dl.extractor.ultimedia.UltimediaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        deliver_url = self._proto_relative_url(self._search_regex(\n            r'<iframe[^>]+src=\"((?:https?:)?//(?:www\\.)?ultimedia\\.com/deliver/[^\"]+)\"',\n            webpage, 'deliver URL'), compat_urllib_parse_urlparse(url).scheme + ':')\n\n        deliver_page = self._download_webpage(\n            deliver_url, video_id, 'Downloading iframe page')\n\n        if '>This video is currently not available' in deliver_page:\n            raise ExtractorError(\n                'Video %s is currently not available' % video_id, expected=True)\n\n        player = self._parse_json(\n            self._search_regex(\n                r\"jwplayer\\('player(?:_temp)?'\\)\\.setup\\(({.+?})\\)\\.on\",\n                deliver_page, 'player'),\n            video_id)\n\n        quality = qualities(['flash', 'html5'])\n        formats = []\n        for mode in player['modes']:\n            video_url = mode.get('config', {}).get('file')\n            if not video_url:\n                continue\n            if re.match(r'https?://www\\.youtube\\.com/.+?', video_url):\n                return self.url_result(video_url, 'Youtube')\n            formats.append({\n                'url': video_url,\n                'format_id': mode.get('type'),\n                'quality': quality(mode.get('type')),\n            })\n        self._sort_formats(formats)\n\n        thumbnail = player.get('image')\n\n        title = clean_html((\n            self._html_search_regex(\n                r'(?s)<div\\s+id=\"catArticle\">.+?</div>(.+?)</h1>',\n                webpage, 'title', default=None) or\n            self._search_regex(\n                r\"var\\s+nameVideo\\s*=\\s*'([^']+)'\",\n                deliver_page, 'title')))\n\n        description = clean_html(self._html_search_regex(\n            r'(?s)<span>Description</span>(.+?)</p>', webpage,\n            'description', fatal=False))\n\n        upload_date = unified_strdate(self._search_regex(\n            r'Ajout\u00e9 le\\s*<span>([^<]+)', webpage,\n            'upload date', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 44,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.screencast.ScreencastIE._real_extract#59",
        "src_path": "youtube_dl/extractor/screencast.py",
        "class_name": "youtube_dl.extractor.screencast.ScreencastIE",
        "signature": "youtube_dl.extractor.screencast.ScreencastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'<embed name=\"Video\".*?src=\"([^\"]+)\"', webpage,\n            'QuickTime embed', default=None)\n\n        if video_url is None:\n            flash_vars_s = self._html_search_regex(\n                r'<param name=\"flashVars\" value=\"([^\"]+)\"', webpage, 'flash vars',\n                default=None)\n            if not flash_vars_s:\n                flash_vars_s = self._html_search_regex(\n                    r'<param name=\"initParams\" value=\"([^\"]+)\"', webpage, 'flash vars',\n                    default=None)\n                if flash_vars_s:\n                    flash_vars_s = flash_vars_s.replace(',', '&')\n            if flash_vars_s:\n                flash_vars = compat_parse_qs(flash_vars_s)\n                video_url_raw = compat_urllib_request.quote(\n                    flash_vars['content'][0])\n                video_url = video_url_raw.replace('http%3A', 'http:')\n\n        if video_url is None:\n            video_meta = self._html_search_meta(\n                'og:video', webpage, default=None)\n            if video_meta:\n                video_url = self._search_regex(\n                    r'src=(.*?)(?:$|&)', video_meta,\n                    'meta tag video URL', default=None)\n\n        if video_url is None:\n            raise ExtractorError('Cannot find video')\n\n        title = self._og_search_title(webpage, default=None)\n        if title is None:\n            title = self._html_search_regex(\n                [r'<b>Title:</b> ([^<]*)</div>',\n                 r'class=\"tabSeperator\">></span><span class=\"tabText\">(.*?)<'],\n                webpage, 'title')\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage, default=None)\n        if description is None:\n            description = self._html_search_meta('description', webpage)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 59,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.beatportpro.BeatportProIE._real_extract#42",
        "src_path": "youtube_dl/extractor/beatportpro.py",
        "class_name": "youtube_dl.extractor.beatportpro.BeatportProIE",
        "signature": "youtube_dl.extractor.beatportpro.BeatportProIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        track_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        playables = self._parse_json(\n            self._search_regex(\n                r'window\\.Playables\\s*=\\s*({.+?});', webpage,\n                'playables info', flags=re.DOTALL),\n            track_id)\n\n        track = next(t for t in playables['tracks'] if t['id'] == int(track_id))\n\n        title = ', '.join((a['name'] for a in track['artists'])) + ' - ' + track['name']\n        if track['mix']:\n            title += ' (' + track['mix'] + ')'\n\n        formats = []\n        for ext, info in track['preview'].items():\n            if not info['url']:\n                continue\n            fmt = {\n                'url': info['url'],\n                'ext': ext,\n                'format_id': ext,\n                'vcodec': 'none',\n            }\n            if ext == 'mp3':\n                fmt['preference'] = 0\n                fmt['acodec'] = 'mp3'\n                fmt['abr'] = 96\n                fmt['asr'] = 44100\n            elif ext == 'mp4':\n                fmt['preference'] = 1\n                fmt['acodec'] = 'aac'\n                fmt['abr'] = 96\n                fmt['asr'] = 44100\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        images = []\n        for name, info in track['images'].items():\n            image_url = info.get('url')\n            if name == 'dynamic' or not image_url:\n                continue\n            image = {\n                'id': name,\n                'url': image_url,\n                'height': int_or_none(info.get('height')),\n                'width': int_or_none(info.get('width')),\n            }\n            images.append(image)\n\n        return {\n            'id': compat_str(track.get('id')) or track_id,\n            'display_id': track.get('slug') or display_id,\n            'title': title,\n            'formats': formats,\n            'thumbnails': images,\n        }",
        "begin_line": 42,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gazeta.GazetaIE._real_extract#26",
        "src_path": "youtube_dl/extractor/gazeta.py",
        "class_name": "youtube_dl.extractor.gazeta.GazetaIE",
        "signature": "youtube_dl.extractor.gazeta.GazetaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        display_id = mobj.group('id')\n        embed_url = '%s?p=embed' % mobj.group('url')\n        embed_page = self._download_webpage(\n            embed_url, display_id, 'Downloading embed page')\n\n        video_id = self._search_regex(\n            r'<div[^>]*?class=\"eagleplayer\"[^>]*?data-id=\"([^\"]+)\"', embed_page, 'video id')\n\n        return self.url_result(\n            'eagleplatform:gazeta.media.eagleplatform.com:%s' % video_id, 'EaglePlatform')",
        "begin_line": 26,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rte.RteIE._real_extract#28",
        "src_path": "youtube_dl/extractor/rte.py",
        "class_name": "youtube_dl.extractor.rte.RteIE",
        "signature": "youtube_dl.extractor.rte.RteIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage)\n        description = self._html_search_meta('description', webpage, 'description')\n        duration = float_or_none(self._html_search_meta(\n            'duration', webpage, 'duration', fatal=False), 1000)\n\n        thumbnail_id = self._search_regex(\n            r'<meta name=\"thumbnail\" content=\"uri:irus:(.*?)\" />', webpage, 'thumbnail')\n        thumbnail = 'http://img.rasset.ie/' + thumbnail_id + '.jpg'\n\n        feeds_url = self._html_search_meta(\"feeds-prefix\", webpage, 'feeds url') + video_id\n        json_string = self._download_json(feeds_url, video_id)\n\n        # f4m_url = server + relative_url\n        f4m_url = json_string['shows'][0]['media:group'][0]['rte:server'] + json_string['shows'][0]['media:group'][0]['url']\n        f4m_formats = self._extract_f4m_formats(f4m_url, video_id)\n        f4m_formats = [{\n            'format_id': f['format_id'],\n            'url': f['url'],\n            'ext': 'mp4',\n            'width': f['width'],\n            'height': f['height'],\n        } for f in f4m_formats]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': f4m_formats,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 28,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ntvde.NTVDeIE._real_extract#32",
        "src_path": "youtube_dl/extractor/ntvde.py",
        "class_name": "youtube_dl.extractor.ntvde.NTVDeIE",
        "signature": "youtube_dl.extractor.ntvde.NTVDeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        info = self._parse_json(self._search_regex(\n            r'(?s)ntv.pageInfo.article =\\s(\\{.*?\\});', webpage, 'info'),\n            video_id, transform_source=js_to_json)\n        timestamp = int_or_none(info.get('publishedDateAsUnixTimeStamp'))\n        vdata = self._parse_json(self._search_regex(\n            r'(?s)\\$\\(\\s*\"\\#player\"\\s*\\)\\s*\\.data\\(\\s*\"player\",\\s*(\\{.*?\\})\\);',\n            webpage, 'player data'),\n            video_id, transform_source=js_to_json)\n        duration = parse_duration(vdata.get('duration'))\n        formats = [{\n            'format_id': 'flash',\n            'url': 'rtmp://fms.n-tv.de/' + vdata['video'],\n        }, {\n            'format_id': 'mobile',\n            'url': 'http://video.n-tv.de' + vdata['videoMp4'],\n            'tbr': 400,  # estimation\n        }]\n        m3u8_url = 'http://video.n-tv.de' + vdata['videoM3u8']\n        formats.extend(self._extract_m3u8_formats(\n            m3u8_url, video_id, ext='mp4',\n            entry_protocol='m3u8_native', preference=0))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info['headline'],\n            'description': info.get('intro'),\n            'alt_title': info.get('kicker'),\n            'timestamp': timestamp,\n            'thumbnail': vdata.get('html5VideoPoster'),\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.toypics.ToypicsIE._real_extract#23",
        "src_path": "youtube_dl/extractor/toypics.py",
        "class_name": "youtube_dl.extractor.toypics.ToypicsIE",
        "signature": "youtube_dl.extractor.toypics.ToypicsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        page = self._download_webpage(url, video_id)\n        video_url = self._html_search_regex(\n            r'src:\\s+\"(http://static[0-9]+\\.toypics\\.net/flvideo/[^\"]+)\"', page, 'video URL')\n        title = self._html_search_regex(\n            r'<title>Toypics - ([^<]+)</title>', page, 'title')\n        username = self._html_search_regex(\n            r'toypics.net/([^/\"]+)\" class=\"user-name\">', page, 'username')\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'uploader': username,\n            'age_limit': 18,\n        }",
        "begin_line": 23,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.toypics.ToypicsUserIE._real_extract#53",
        "src_path": "youtube_dl/extractor/toypics.py",
        "class_name": "youtube_dl.extractor.toypics.ToypicsUserIE",
        "signature": "youtube_dl.extractor.toypics.ToypicsUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        username = mobj.group('username')\n\n        profile_page = self._download_webpage(\n            url, username, note='Retrieving profile page')\n\n        video_count = int(self._search_regex(\n            r'public/\">Public Videos \\(([0-9]+)\\)</a></li>', profile_page,\n            'video count'))\n\n        PAGE_SIZE = 8\n        urls = []\n        page_count = (video_count + PAGE_SIZE + 1) // PAGE_SIZE\n        for n in range(1, page_count + 1):\n            lpage_url = url + '/public/%d' % n\n            lpage = self._download_webpage(\n                lpage_url, username,\n                note='Downloading page %d/%d' % (n, page_count))\n            urls.extend(\n                re.findall(\n                    r'<p class=\"video-entry-title\">\\s+<a href=\"(https?://videos.toypics.net/view/[^\"]+)\">',\n                    lpage))\n\n        return {\n            '_type': 'playlist',\n            'id': username,\n            'entries': [{\n                '_type': 'url',\n                'url': eurl,\n                'ie_key': 'Toypics',\n            } for eurl in urls]\n        }",
        "begin_line": 53,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE._extract_theplatform_smil#31",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformBaseIE._extract_theplatform_smil(self, smil_url, video_id, note='Downloading SMIL data')",
        "snippet": "    def _extract_theplatform_smil(self, smil_url, video_id, note='Downloading SMIL data'):\n        meta = self._download_xml(smil_url, video_id, note=note)\n        try:\n            error_msg = next(\n                n.attrib['abstract']\n                for n in meta.findall(_x('.//smil:ref'))\n                if n.attrib.get('title') == 'Geographic Restriction' or n.attrib.get('title') == 'Expired')\n        except StopIteration:\n            pass\n        else:\n            raise ExtractorError(error_msg, expected=True)\n\n        formats = self._parse_smil_formats(\n            meta, smil_url, video_id, namespace=default_ns,\n            # the parameters are from syfy.com, other sites may use others,\n            # they also work for nbc.com\n            f4m_params={'g': 'UXWGVKRWHFSP', 'hdcore': '3.0.3'},\n            transform_rtmp_url=lambda streamer, src: (streamer, 'mp4:' + src))\n\n        for _format in formats:\n            ext = determine_ext(_format['url'])\n            if ext == 'once':\n                _format['ext'] = 'mp4'\n\n        self._sort_formats(formats)\n\n        subtitles = self._parse_smil_subtitles(meta, default_ns)\n\n        return formats, subtitles",
        "begin_line": 31,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE.get_metadata#61",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformBaseIE.get_metadata(self, path, video_id)",
        "snippet": "    def get_metadata(self, path, video_id):\n        info_url = 'http://link.theplatform.com/s/%s?format=preview' % path\n        info = self._download_json(info_url, video_id)\n\n        subtitles = {}\n        captions = info.get('captions')\n        if isinstance(captions, list):\n            for caption in captions:\n                lang, src, mime = caption.get('lang', 'en'), caption.get('src'), caption.get('type')\n                subtitles[lang] = [{\n                    'ext': 'srt' if mime == 'text/srt' else 'ttml',\n                    'url': src,\n                }]\n\n        return {\n            'title': info['title'],\n            'subtitles': subtitles,\n            'description': info['description'],\n            'thumbnail': info['defaultThumbnailUrl'],\n            'duration': int_or_none(info.get('duration'), 1000),\n        }",
        "begin_line": 61,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformIE._sign_url#145",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformIE._sign_url(url, sig_key, sig_secret, life=600, include_qs=False)",
        "snippet": "    def _sign_url(url, sig_key, sig_secret, life=600, include_qs=False):\n        flags = '10' if include_qs else '00'\n        expiration_date = '%x' % (int(time.time()) + life)\n\n        def str_to_hex(str):\n            return binascii.b2a_hex(str.encode('ascii')).decode('ascii')\n\n        def hex_to_str(hex):\n            return binascii.a2b_hex(hex)\n\n        relative_path = url.split('http://link.theplatform.com/s/')[1].split('?')[0]\n        clear_text = hex_to_str(flags + expiration_date + str_to_hex(relative_path))\n        checksum = hmac.new(sig_key.encode('ascii'), clear_text, hashlib.sha1).hexdigest()\n        sig = flags + expiration_date + checksum + str_to_hex(sig_secret)\n        return '%s&sig=%s' % (url, sig)",
        "begin_line": 145,
        "end_line": 159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformIE._real_extract#161",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        mobj = re.match(self._VALID_URL, url)\n        provider_id = mobj.group('provider_id')\n        video_id = mobj.group('id')\n\n        if not provider_id:\n            provider_id = 'dJ5BDC'\n\n        path = provider_id\n        if mobj.group('media'):\n            path += '/media'\n        path += '/' + video_id\n\n        qs_dict = compat_parse_qs(compat_urllib_parse_urlparse(url).query)\n        if 'guid' in qs_dict:\n            webpage = self._download_webpage(url, video_id)\n            scripts = re.findall(r'<script[^>]+src=\"([^\"]+)\"', webpage)\n            feed_id = None\n            # feed id usually locates in the last script.\n            # Seems there's no pattern for the interested script filename, so\n            # I try one by one\n            for script in reversed(scripts):\n                feed_script = self._download_webpage(script, video_id, 'Downloading feed script')\n                feed_id = self._search_regex(r'defaultFeedId\\s*:\\s*\"([^\"]+)\"', feed_script, 'default feed id', default=None)\n                if feed_id is not None:\n                    break\n            if feed_id is None:\n                raise ExtractorError('Unable to find feed id')\n            return self.url_result('http://feed.theplatform.com/f/%s/%s?byGuid=%s' % (\n                provider_id, feed_id, qs_dict['guid'][0]))\n\n        if smuggled_data.get('force_smil_url', False):\n            smil_url = url\n        elif mobj.group('config'):\n            config_url = url + '&form=json'\n            config_url = config_url.replace('swf/', 'config/')\n            config_url = config_url.replace('onsite/', 'onsite/config/')\n            config = self._download_json(config_url, video_id, 'Downloading config')\n            if 'releaseUrl' in config:\n                release_url = config['releaseUrl']\n            else:\n                release_url = 'http://link.theplatform.com/s/%s?mbr=true' % path\n            smil_url = release_url + '&format=SMIL&formats=MPEG4&manifest=f4m'\n        else:\n            smil_url = 'http://link.theplatform.com/s/%s/meta.smil?format=smil&mbr=true' % path\n\n        sig = smuggled_data.get('sig')\n        if sig:\n            smil_url = self._sign_url(smil_url, sig['key'], sig['secret'])\n\n        formats, subtitles = self._extract_theplatform_smil(smil_url, video_id)\n\n        ret = self.get_metadata(path, video_id)\n        combined_subtitles = self._merge_subtitles(ret.get('subtitles', {}), subtitles)\n        ret.update({\n            'id': video_id,\n            'formats': formats,\n            'subtitles': combined_subtitles,\n        })\n\n        return ret",
        "begin_line": 161,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformFeedIE._real_extract#246",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformFeedIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformFeedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        provider_id = mobj.group('provider_id')\n        feed_id = mobj.group('feed_id')\n\n        real_url = self._URL_TEMPLATE % (self.http_scheme(), provider_id, feed_id, video_id)\n        feed = self._download_json(real_url, video_id)\n        entry = feed['entries'][0]\n\n        formats = []\n        subtitles = {}\n        first_video_id = None\n        duration = None\n        for item in entry['media$content']:\n            smil_url = item['plfile$url'] + '&format=SMIL&Tracking=true&Embedded=true&formats=MPEG4,F4M'\n            cur_video_id = url_basename(smil_url)\n            if first_video_id is None:\n                first_video_id = cur_video_id\n                duration = float_or_none(item.get('plfile$duration'))\n            cur_formats, cur_subtitles = self._extract_theplatform_smil(smil_url, video_id, 'Downloading SMIL data for %s' % cur_video_id)\n            formats.extend(cur_formats)\n            subtitles = self._merge_subtitles(subtitles, cur_subtitles)\n\n        self._sort_formats(formats)\n\n        thumbnails = [{\n            'url': thumbnail['plfile$url'],\n            'width': int_or_none(thumbnail.get('plfile$width')),\n            'height': int_or_none(thumbnail.get('plfile$height')),\n        } for thumbnail in entry.get('media$thumbnails', [])]\n\n        timestamp = int_or_none(entry.get('media$availableDate'), scale=1000)\n        categories = [item['media$name'] for item in entry.get('media$categories', [])]\n\n        ret = self.get_metadata('%s/%s' % (provider_id, first_video_id), video_id)\n        subtitles = self._merge_subtitles(subtitles, ret['subtitles'])\n        ret.update({\n            'id': video_id,\n            'formats': formats,\n            'subtitles': subtitles,\n            'thumbnails': thumbnails,\n            'duration': duration,\n            'timestamp': timestamp,\n            'categories': categories,\n        })\n\n        return ret",
        "begin_line": 246,
        "end_line": 294,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE.make_json_request#34",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE.make_json_request(url, data)",
        "snippet": "    def make_json_request(url, data):\n        payload = json.dumps(data).encode('utf-8')\n        req = compat_urllib_request.Request(url, payload)\n        req.add_header('Content-Type', 'application/json; charset=utf-8')\n        return req",
        "begin_line": 34,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE.find_assets#41",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE.find_assets(data, asset_type, asset_id=None)",
        "snippet": "    def find_assets(data, asset_type, asset_id=None):\n        for asset in data.get('assets', []):\n            if not asset.get('type') == asset_type:\n                continue\n            elif asset_id is not None and not asset.get('id') == asset_id:\n                continue\n            else:\n                yield asset",
        "begin_line": 41,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE._check_access_rights#50",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE._check_access_rights(self, data)",
        "snippet": "    def _check_access_rights(self, data):\n        access_info = data.get('__view', {})\n        if not access_info.get('allow_access', True):\n            err_code = access_info.get('error_code') or ''\n            if err_code == 'ITEM_PAID_ONLY':\n                raise ExtractorError(\n                    'This video requires subscription.', expected=True)\n            else:\n                raise ExtractorError(\n                    'Access to this content is restricted. (%s said: %s)' % (self.IE_NAME, err_code), expected=True)",
        "begin_line": 50,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE._login#61",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n        self.report_login()\n        data = {\n            'client_id': 'web',\n            'type': 'password',\n            'user_key': username,\n            'password': password,\n        }\n        login_request = VesselIE.make_json_request(self._LOGIN_URL, data)\n        self._download_webpage(login_request, None, False, 'Wrong login info')",
        "begin_line": 61,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE._real_initialize#75",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 75,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE._real_extract#78",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        data = self._parse_json(self._search_regex(\n            r'App\\.bootstrapData\\((.*?)\\);', webpage, 'data'), video_id)\n        asset_id = data['model']['data']['id']\n\n        req = VesselIE.make_json_request(\n            self._API_URL_TEMPLATE % asset_id, {'client': 'web'})\n        data = self._download_json(req, video_id)\n        video_asset_id = data.get('main_video_asset')\n\n        self._check_access_rights(data)\n\n        try:\n            video_asset = next(\n                VesselIE.find_assets(data, 'video', asset_id=video_asset_id))\n        except StopIteration:\n            raise ExtractorError('No video assets found')\n\n        formats = []\n        for f in video_asset.get('sources', []):\n            if f['name'] == 'hls-index':\n                formats.extend(self._extract_m3u8_formats(\n                    f['location'], video_id, ext='mp4', m3u8_id='m3u8'))\n            else:\n                formats.append({\n                    'format_id': f['name'],\n                    'tbr': f.get('bitrate'),\n                    'height': f.get('height'),\n                    'width': f.get('width'),\n                    'url': f['location'],\n                })\n        self._sort_formats(formats)\n\n        thumbnails = []\n        for im_asset in VesselIE.find_assets(data, 'image'):\n            thumbnails.append({\n                'url': im_asset['location'],\n                'width': im_asset.get('width', 0),\n                'height': im_asset.get('height', 0),\n            })\n\n        return {\n            'id': video_id,\n            'title': data['title'],\n            'formats': formats,\n            'thumbnails': thumbnails,\n            'description': data.get('short_description'),\n            'duration': data.get('duration'),\n            'comment_count': data.get('comment_count'),\n            'like_count': data.get('like_count'),\n            'view_count': data.get('view_count'),\n            'timestamp': parse_iso8601(data.get('released_at')),\n        }",
        "begin_line": 78,
        "end_line": 133,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tweakers.TweakersIE._real_extract#21",
        "src_path": "youtube_dl/extractor/tweakers.py",
        "class_name": "youtube_dl.extractor.tweakers.TweakersIE",
        "signature": "youtube_dl.extractor.tweakers.TweakersIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        entries = self._extract_xspf_playlist(\n            'https://tweakers.net/video/s1playlist/%s/playlist.xspf' % playlist_id, playlist_id)\n        return self.playlist_result(entries, playlist_id)",
        "begin_line": 21,
        "end_line": 25,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.europa.EuropaIE._real_extract#40",
        "src_path": "youtube_dl/extractor/europa.py",
        "class_name": "youtube_dl.extractor.europa.EuropaIE",
        "signature": "youtube_dl.extractor.europa.EuropaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        playlist = self._download_xml(\n            'http://ec.europa.eu/avservices/video/player/playlist.cfm?ID=%s' % video_id, video_id)\n\n        def get_item(type_, preference):\n            items = {}\n            for item in playlist.findall('./info/%s/item' % type_):\n                lang, label = xpath_text(item, 'lg', default=None), xpath_text(item, 'label', default=None)\n                if lang and label:\n                    items[lang] = label.strip()\n            for p in preference:\n                if items.get(p):\n                    return items[p]\n\n        query = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        preferred_lang = query.get('sitelang', ('en', ))[0]\n\n        preferred_langs = orderedSet((preferred_lang, 'en', 'int'))\n\n        title = get_item('title', preferred_langs) or video_id\n        description = get_item('description', preferred_langs)\n        thumbnmail = xpath_text(playlist, './info/thumburl', 'thumbnail')\n        upload_date = unified_strdate(xpath_text(playlist, './info/date', 'upload date'))\n        duration = parse_duration(xpath_text(playlist, './info/duration', 'duration'))\n        view_count = int_or_none(xpath_text(playlist, './info/views', 'views'))\n\n        language_preference = qualities(preferred_langs[::-1])\n\n        formats = []\n        for file_ in playlist.findall('./files/file'):\n            video_url = xpath_text(file_, './url')\n            if not video_url:\n                continue\n            lang = xpath_text(file_, './lg')\n            formats.append({\n                'url': video_url,\n                'format_id': lang,\n                'format_note': xpath_text(file_, './lglabel'),\n                'language_preference': language_preference(lang)\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnmail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats\n        }",
        "begin_line": 40,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.aparat.AparatIE._real_extract#28",
        "src_path": "youtube_dl/extractor/aparat.py",
        "class_name": "youtube_dl.extractor.aparat.AparatIE",
        "signature": "youtube_dl.extractor.aparat.AparatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Note: There is an easier-to-parse configuration at\n        # http://www.aparat.com/video/video/config/videohash/%video_id\n        # but the URL in there does not work\n        embed_url = ('http://www.aparat.com/video/video/embed/videohash/' +\n                     video_id + '/vt/frame')\n        webpage = self._download_webpage(embed_url, video_id)\n\n        video_urls = [video_url.replace('\\\\/', '/') for video_url in re.findall(\n            r'(?:fileList\\[[0-9]+\\]\\s*=|\"file\"\\s*:)\\s*\"([^\"]+)\"', webpage)]\n        for i, video_url in enumerate(video_urls):\n            req = HEADRequest(video_url)\n            res = self._request_webpage(\n                req, video_id, note='Testing video URL %d' % i, errnote=False)\n            if res:\n                break\n        else:\n            raise ExtractorError('No working video URLs found')\n\n        title = self._search_regex(r'\\s+title:\\s*\"([^\"]+)\"', webpage, 'title')\n        thumbnail = self._search_regex(\n            r'image:\\s*\"([^\"]+)\"', webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'ext': 'mp4',\n            'thumbnail': thumbnail,\n            'age_limit': self._family_friendly_search(webpage),\n        }",
        "begin_line": 28,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.echomsk.EchoMskIE._real_extract#21",
        "src_path": "youtube_dl/extractor/echomsk.py",
        "class_name": "youtube_dl.extractor.echomsk.EchoMskIE",
        "signature": "youtube_dl.extractor.echomsk.EchoMskIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        audio_url = self._search_regex(\n            r'<a rel=\"mp3\" href=\"([^\"]+)\">', webpage, 'audio URL')\n\n        title = self._html_search_regex(\n            r'<a href=\"/programs/[^\"]+\" target=\"_blank\">([^<]+)</a>',\n            webpage, 'title')\n\n        air_date = self._html_search_regex(\n            r'(?s)<div class=\"date\">(.+?)</div>',\n            webpage, 'date', fatal=False, default=None)\n\n        if air_date:\n            air_date = re.sub(r'(\\s)\\1+', r'\\1', air_date)\n            if air_date:\n                title = '%s - %s' % (title, air_date)\n\n        return {\n            'id': video_id,\n            'url': audio_url,\n            'title': title,\n        }",
        "begin_line": 21,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tf1.TF1IE._real_extract#43",
        "src_path": "youtube_dl/extractor/tf1.py",
        "class_name": "youtube_dl.extractor.tf1.TF1IE",
        "signature": "youtube_dl.extractor.tf1.TF1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        embed_url = self._html_search_regex(\n            r'[\"\\'](https?://www.wat.tv/embedframe/.*?)[\"\\']', webpage, 'embed url')\n        embed_page = self._download_webpage(embed_url, video_id,\n                                            'Downloading embed player page')\n        wat_id = self._search_regex(r'UVID=(.*?)&', embed_page, 'wat id')\n        wat_info = self._download_json(\n            'http://www.wat.tv/interface/contentv3/%s' % wat_id, video_id)\n        return self.url_result(wat_info['media']['url'], 'Wat')",
        "begin_line": 43,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.canalplus.CanalplusIE._real_extract#69",
        "src_path": "youtube_dl/extractor/canalplus.py",
        "class_name": "youtube_dl.extractor.canalplus.CanalplusIE",
        "signature": "youtube_dl.extractor.canalplus.CanalplusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.groupdict().get('id')\n\n        site_id = self._SITE_ID_MAP[mobj.group('site') or 'canal']\n\n        # Beware, some subclasses do not define an id group\n        display_id = url_basename(mobj.group('path'))\n\n        if video_id is None:\n            webpage = self._download_webpage(url, display_id)\n            video_id = self._search_regex(\n                [r'<canal:player[^>]+?videoId=([\"\\'])(?P<id>\\d+)', r'id=[\"\\']canal_video_player(?P<id>\\d+)'],\n                webpage, 'video id', group='id')\n\n        info_url = self._VIDEO_INFO_TEMPLATE % (site_id, video_id)\n        doc = self._download_xml(info_url, video_id, 'Downloading video XML')\n\n        video_info = [video for video in doc if video.find('ID').text == video_id][0]\n        media = video_info.find('MEDIA')\n        infos = video_info.find('INFOS')\n\n        preference = qualities(['MOBILE', 'BAS_DEBIT', 'HAUT_DEBIT', 'HD', 'HLS', 'HDS'])\n\n        fmt_url = next(iter(media.find('VIDEOS'))).text\n        if '/geo' in fmt_url.lower():\n            response = self._request_webpage(\n                HEADRequest(fmt_url), video_id,\n                'Checking if the video is georestricted')\n            if '/blocage' in response.geturl():\n                raise ExtractorError(\n                    'The video is not available in your country',\n                    expected=True)\n\n        formats = []\n        for fmt in media.find('VIDEOS'):\n            format_url = fmt.text\n            if not format_url:\n                continue\n            format_id = fmt.tag\n            if format_id == 'HLS':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', preference=preference(format_id)))\n            elif format_id == 'HDS':\n                formats.extend(self._extract_f4m_formats(\n                    format_url + '?hdcore=2.11.3', video_id, preference=preference(format_id)))\n            else:\n                formats.append({\n                    'url': format_url,\n                    'format_id': format_id,\n                    'preference': preference(format_id),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': '%s - %s' % (infos.find('TITRAGE/TITRE').text,\n                                  infos.find('TITRAGE/SOUS_TITRE').text),\n            'upload_date': unified_strdate(infos.find('PUBLICATION/DATE').text),\n            'thumbnail': media.find('IMAGES/GRAND').text,\n            'description': infos.find('DESCRIPTION').text,\n            'view_count': int(infos.find('NB_VUES').text),\n            'like_count': int(infos.find('NB_LIKES').text),\n            'comment_count': int(infos.find('NB_COMMENTS').text),\n            'formats': formats,\n        }",
        "begin_line": 69,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.firstpost.FirstpostIE._real_extract#20",
        "src_path": "youtube_dl/extractor/firstpost.py",
        "class_name": "youtube_dl.extractor.firstpost.FirstpostIE",
        "signature": "youtube_dl.extractor.firstpost.FirstpostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        page = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta('twitter:title', page, 'title', fatal=True)\n        description = self._html_search_meta('twitter:description', page, 'title')\n\n        data = self._download_xml(\n            'http://www.firstpost.com/getvideoxml-%s.xml' % video_id, video_id,\n            'Downloading video XML')\n\n        item = data.find('./playlist/item')\n        thumbnail = item.find('./image').text\n\n        formats = [\n            {\n                'url': details.find('./file').text,\n                'format_id': details.find('./label').text.strip(),\n                'width': int(details.find('./width').text.strip()),\n                'height': int(details.find('./height').text.strip()),\n            } for details in item.findall('./source/file_details') if details.find('./file').text\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 20,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bet.BetIE._real_extract#56",
        "src_path": "youtube_dl/extractor/bet.py",
        "class_name": "youtube_dl.extractor.bet.BetIE",
        "signature": "youtube_dl.extractor.bet.BetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        media_url = compat_urllib_parse_unquote(self._search_regex(\n            [r'mediaURL\\s*:\\s*\"([^\"]+)\"', r\"var\\s+mrssMediaUrl\\s*=\\s*'([^']+)'\"],\n            webpage, 'media URL'))\n\n        video_id = self._search_regex(\n            r'/video/(.*)/_jcr_content/', media_url, 'video id')\n\n        mrss = self._download_xml(media_url, display_id)\n\n        item = mrss.find('./channel/item')\n\n        NS_MAP = {\n            'dc': 'http://purl.org/dc/elements/1.1/',\n            'media': 'http://search.yahoo.com/mrss/',\n            'ka': 'http://kickapps.com/karss',\n        }\n\n        title = xpath_text(item, './title', 'title')\n        description = xpath_text(\n            item, './description', 'description', fatal=False)\n\n        timestamp = parse_iso8601(xpath_text(\n            item, xpath_with_ns('./dc:date', NS_MAP),\n            'upload date', fatal=False))\n        uploader = xpath_text(\n            item, xpath_with_ns('./dc:creator', NS_MAP),\n            'uploader', fatal=False)\n\n        media_content = item.find(\n            xpath_with_ns('./media:content', NS_MAP))\n        duration = int_or_none(media_content.get('duration'))\n        smil_url = media_content.get('url')\n\n        thumbnail = media_content.find(\n            xpath_with_ns('./media:thumbnail', NS_MAP)).get('url')\n\n        formats = self._extract_smil_formats(smil_url, display_id)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 56,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cliphunter._decode#15",
        "src_path": "youtube_dl/extractor/cliphunter.py",
        "class_name": "youtube_dl.extractor.cliphunter",
        "signature": "youtube_dl.extractor.cliphunter._decode(s)",
        "snippet": "def _decode(s):\n    return ''.join(_translation_table.get(c, c) for c in s)",
        "begin_line": 15,
        "end_line": 16,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cliphunter.CliphunterIE._real_extract#38",
        "src_path": "youtube_dl/extractor/cliphunter.py",
        "class_name": "youtube_dl.extractor.cliphunter.CliphunterIE",
        "signature": "youtube_dl.extractor.cliphunter.CliphunterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._search_regex(\n            r'mediaTitle = \"([^\"]+)\"', webpage, 'title')\n\n        fmts = {}\n        for fmt in ('mp4', 'flv'):\n            fmt_list = self._parse_json(self._search_regex(\n                r'var %sjson\\s*=\\s*(\\[.*?\\]);' % fmt, webpage, '%s formats' % fmt), video_id)\n            for f in fmt_list:\n                fmts[f['fname']] = _decode(f['sUrl'])\n\n        qualities = self._parse_json(self._search_regex(\n            r'var player_btns\\s*=\\s*(.*?);\\n', webpage, 'quality info'), video_id)\n\n        formats = []\n        for fname, url in fmts.items():\n            f = {\n                'url': url,\n            }\n            if fname in qualities:\n                qual = qualities[fname]\n                f.update({\n                    'format_id': '%s_%sp' % (determine_ext(url), qual['h']),\n                    'width': qual['w'],\n                    'height': qual['h'],\n                    'tbr': qual['br'],\n                })\n            formats.append(f)\n\n        self._sort_formats(formats)\n\n        thumbnail = self._search_regex(\n            r\"var\\s+mov_thumb\\s*=\\s*'([^']+)';\",\n            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'age_limit': self._rta_search(webpage),\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 38,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vidzi.VidziIE._real_extract#19",
        "src_path": "youtube_dl/extractor/vidzi.py",
        "class_name": "youtube_dl.extractor.vidzi.VidziIE",
        "signature": "youtube_dl.extractor.vidzi.VidziIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._html_search_regex(\n            r'{\\s*file\\s*:\\s*\"([^\"]+)\"\\s*}', webpage, 'video url')\n        title = self._html_search_regex(\n            r'(?s)<h2 class=\"video-title\">(.*?)</h2>', webpage, 'title')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 19,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.hornbunny.HornBunnyIE._real_extract#27",
        "src_path": "youtube_dl/extractor/hornbunny.py",
        "class_name": "youtube_dl.extractor.hornbunny.HornBunnyIE",
        "signature": "youtube_dl.extractor.hornbunny.HornBunnyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(\n            url, video_id, note='Downloading initial webpage')\n        title = self._html_search_regex(\n            r'class=\"title\">(.*?)</h2>', webpage, 'title')\n        redirect_url = self._html_search_regex(\n            r'pg&settings=(.*?)\\|0\"\\);', webpage, 'title')\n        webpage2 = self._download_webpage(redirect_url, video_id)\n        video_url = self._html_search_regex(\n            r'flvMask:(.*?);', webpage2, 'video_url')\n\n        duration = parse_duration(self._search_regex(\n            r'<strong>Runtime:</strong>\\s*([0-9:]+)</div>',\n            webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._search_regex(\n            r'<strong>Views:</strong>\\s*(\\d+)</div>',\n            webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'ext': 'flv',\n            'duration': duration,\n            'view_count': view_count,\n            'age_limit': 18,\n        }",
        "begin_line": 27,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youjizz.YouJizzIE._real_extract#24",
        "src_path": "youtube_dl/extractor/youjizz.py",
        "class_name": "youtube_dl.extractor.youjizz.YouJizzIE",
        "signature": "youtube_dl.extractor.youjizz.YouJizzIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        age_limit = self._rta_search(webpage)\n        video_title = self._html_search_regex(\n            r'<title>\\s*(.*)\\s*</title>', webpage, 'title')\n\n        embed_page_url = self._search_regex(\n            r'(https?://www.youjizz.com/videos/embed/[0-9]+)',\n            webpage, 'embed page')\n        webpage = self._download_webpage(\n            embed_page_url, video_id, note='downloading embed page')\n\n        # Get the video URL\n        m_playlist = re.search(r'so.addVariable\\(\"playlist\", ?\"(?P<playlist>.+?)\"\\);', webpage)\n        if m_playlist is not None:\n            playlist_url = m_playlist.group('playlist')\n            playlist_page = self._download_webpage(playlist_url, video_id,\n                                                   'Downloading playlist page')\n            m_levels = list(re.finditer(r'<level bitrate=\"(\\d+?)\" file=\"(.*?)\"', playlist_page))\n            if len(m_levels) == 0:\n                raise ExtractorError('Unable to extract video url')\n            videos = [(int(m.group(1)), m.group(2)) for m in m_levels]\n            (_, video_url) = sorted(videos)[0]\n            video_url = video_url.replace('%252F', '%2F')\n        else:\n            video_url = self._search_regex(r'so.addVariable\\(\"file\",encodeURIComponent\\(\"(?P<source>[^\"]+)\"\\)\\);',\n                                           webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'ext': 'flv',\n            'format': 'flv',\n            'player_url': embed_page_url,\n            'age_limit': age_limit,\n        }",
        "begin_line": 24,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.deezer.DeezerPlaylistIE._real_extract#28",
        "src_path": "youtube_dl/extractor/deezer.py",
        "class_name": "youtube_dl.extractor.deezer.DeezerPlaylistIE",
        "signature": "youtube_dl.extractor.deezer.DeezerPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        if 'test' not in self._downloader.params:\n            self._downloader.report_warning('For now, this extractor only supports the 30 second previews. Patches welcome!')\n\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, playlist_id)\n        geoblocking_msg = self._html_search_regex(\n            r'<p class=\"soon-txt\">(.*?)</p>', webpage, 'geoblocking message',\n            default=None)\n        if geoblocking_msg is not None:\n            raise ExtractorError(\n                'Deezer said: %s' % geoblocking_msg, expected=True)\n\n        data_json = self._search_regex(\n            r'naboo\\.display\\(\\'[^\\']+\\',\\s*(.*?)\\);\\n', webpage, 'data JSON')\n        data = json.loads(data_json)\n\n        playlist_title = data.get('DATA', {}).get('TITLE')\n        playlist_uploader = data.get('DATA', {}).get('PARENT_USERNAME')\n        playlist_thumbnail = self._search_regex(\n            r'<img id=\"naboo_playlist_image\".*?src=\"([^\"]+)\"', webpage,\n            'playlist thumbnail')\n\n        preview_pattern = self._search_regex(\n            r\"var SOUND_PREVIEW_GATEWAY\\s*=\\s*'([^']+)';\", webpage,\n            'preview URL pattern', fatal=False)\n        entries = []\n        for s in data['SONGS']['data']:\n            puid = s['MD5_ORIGIN']\n            preview_video_url = preview_pattern.\\\n                replace('{0}', puid[0]).\\\n                replace('{1}', puid).\\\n                replace('{2}', s['MEDIA_VERSION'])\n            formats = [{\n                'format_id': 'preview',\n                'url': preview_video_url,\n                'preference': -100,  # Only the first 30 seconds\n                'ext': 'mp3',\n            }]\n            self._sort_formats(formats)\n            artists = ', '.join(\n                orderedSet(a['ART_NAME'] for a in s['ARTISTS']))\n            entries.append({\n                'id': s['SNG_ID'],\n                'duration': int_or_none(s.get('DURATION')),\n                'title': '%s - %s' % (artists, s['SNG_TITLE']),\n                'uploader': s['ART_NAME'],\n                'uploader_id': s['ART_ID'],\n                'age_limit': 16 if s.get('EXPLICIT_LYRICS') == '1' else 0,\n                'formats': formats,\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_title,\n            'uploader': playlist_uploader,\n            'thumbnail': playlist_thumbnail,\n            'entries': entries,\n        }",
        "begin_line": 28,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.veoh.VeohIE._extract_formats#58",
        "src_path": "youtube_dl/extractor/veoh.py",
        "class_name": "youtube_dl.extractor.veoh.VeohIE",
        "signature": "youtube_dl.extractor.veoh.VeohIE._extract_formats(self, source)",
        "snippet": "    def _extract_formats(self, source):\n        formats = []\n        link = source.get('aowPermalink')\n        if link:\n            formats.append({\n                'url': link,\n                'ext': 'mp4',\n                'format_id': 'aow',\n            })\n        link = source.get('fullPreviewHashLowPath')\n        if link:\n            formats.append({\n                'url': link,\n                'format_id': 'low',\n            })\n        link = source.get('fullPreviewHashHighPath')\n        if link:\n            formats.append({\n                'url': link,\n                'format_id': 'high',\n            })\n        return formats",
        "begin_line": 58,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.veoh.VeohIE._extract_video#81",
        "src_path": "youtube_dl/extractor/veoh.py",
        "class_name": "youtube_dl.extractor.veoh.VeohIE",
        "signature": "youtube_dl.extractor.veoh.VeohIE._extract_video(self, source)",
        "snippet": "    def _extract_video(self, source):\n        return {\n            'id': source.get('videoId'),\n            'title': source.get('title'),\n            'description': source.get('description'),\n            'thumbnail': source.get('highResImage') or source.get('medResImage'),\n            'uploader': source.get('username'),\n            'duration': int_or_none(source.get('length')),\n            'view_count': int_or_none(source.get('views')),\n            'age_limit': 18 if source.get('isMature') == 'true' or source.get('isSexy') == 'true' else 0,\n            'formats': self._extract_formats(source),\n        }",
        "begin_line": 81,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.veoh.VeohIE._real_extract#94",
        "src_path": "youtube_dl/extractor/veoh.py",
        "class_name": "youtube_dl.extractor.veoh.VeohIE",
        "signature": "youtube_dl.extractor.veoh.VeohIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        if video_id.startswith('v'):\n            rsp = self._download_xml(\n                r'http://www.veoh.com/api/findByPermalink?permalink=%s' % video_id, video_id, 'Downloading video XML')\n            stat = rsp.get('stat')\n            if stat == 'ok':\n                return self._extract_video(rsp.find('./videoList/video'))\n            elif stat == 'fail':\n                raise ExtractorError(\n                    '%s said: %s' % (self.IE_NAME, rsp.find('./errorList/error').get('errorMessage')), expected=True)\n\n        webpage = self._download_webpage(url, video_id)\n        age_limit = 0\n        if 'class=\"adultwarning-container\"' in webpage:\n            self.report_age_confirmation()\n            age_limit = 18\n            request = compat_urllib_request.Request(url)\n            request.add_header('Cookie', 'confirmedAdult=true')\n            webpage = self._download_webpage(request, video_id)\n\n        m_youtube = re.search(r'http://www\\.youtube\\.com/v/(.*?)(\\&|\"|\\?)', webpage)\n        if m_youtube is not None:\n            youtube_id = m_youtube.group(1)\n            self.to_screen('%s: detected Youtube video.' % video_id)\n            return self.url_result(youtube_id, 'Youtube')\n\n        info = json.loads(\n            self._search_regex(r'videoDetailsJSON = \\'({.*?})\\';', webpage, 'info').replace('\\\\\\'', '\\''))\n\n        video = self._extract_video(info)\n        video['age_limit'] = age_limit\n\n        return video",
        "begin_line": 94,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ruutu.RuutuIE._real_extract#45",
        "src_path": "youtube_dl/extractor/ruutu.py",
        "class_name": "youtube_dl.extractor.ruutu.RuutuIE",
        "signature": "youtube_dl.extractor.ruutu.RuutuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_xml = self._download_xml(\n            'http://gatling.ruutu.fi/media-xml-cache?id=%s' % video_id, video_id)\n\n        formats = []\n        processed_urls = []\n\n        def extract_formats(node):\n            for child in node:\n                if child.tag.endswith('Files'):\n                    extract_formats(child)\n                elif child.tag.endswith('File'):\n                    video_url = child.text\n                    if not video_url or video_url in processed_urls or 'NOT_USED' in video_url:\n                        return\n                    processed_urls.append(video_url)\n                    ext = determine_ext(video_url)\n                    if ext == 'm3u8':\n                        formats.extend(self._extract_m3u8_formats(\n                            video_url, video_id, 'mp4', m3u8_id='hls'))\n                    elif ext == 'f4m':\n                        formats.extend(self._extract_f4m_formats(\n                            video_url, video_id, f4m_id='hds'))\n                    else:\n                        proto = compat_urllib_parse_urlparse(video_url).scheme\n                        if not child.tag.startswith('HTTP') and proto != 'rtmp':\n                            continue\n                        preference = -1 if proto == 'rtmp' else 1\n                        label = child.get('label')\n                        tbr = int_or_none(child.get('bitrate'))\n                        width, height = [int_or_none(x) for x in child.get('resolution', 'x').split('x')[:2]]\n                        formats.append({\n                            'format_id': '%s-%s' % (proto, label if label else tbr),\n                            'url': video_url,\n                            'width': width,\n                            'height': height,\n                            'tbr': tbr,\n                            'preference': preference,\n                        })\n\n        extract_formats(video_xml.find('./Clip'))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': xpath_attr(video_xml, './/Behavior/Program', 'program_name', 'title', fatal=True),\n            'description': xpath_attr(video_xml, './/Behavior/Program', 'description', 'description'),\n            'thumbnail': xpath_attr(video_xml, './/Behavior/Startpicture', 'href', 'thumbnail'),\n            'duration': int_or_none(xpath_text(video_xml, './/Runtime', 'duration')),\n            'age_limit': int_or_none(xpath_text(video_xml, './/AgeLimit', 'age limit')),\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.howcast.HowcastIE._real_extract#26",
        "src_path": "youtube_dl/extractor/howcast.py",
        "class_name": "youtube_dl.extractor.howcast.HowcastIE",
        "signature": "youtube_dl.extractor.howcast.HowcastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        embed_code = self._search_regex(\n            r'<iframe[^>]+src=\"[^\"]+\\bembed_code=([^\\b]+)\\b',\n            webpage, 'ooyala embed code')\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'Ooyala',\n            'url': 'ooyala:%s' % embed_code,\n            'id': video_id,\n            'timestamp': parse_iso8601(self._html_search_meta(\n                'article:published_time', webpage, 'timestamp')),\n        }",
        "begin_line": 26,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessBaseIE._extract_url_result#14",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessBaseIE",
        "signature": "youtube_dl.extractor.nowness.NownessBaseIE._extract_url_result(self, post)",
        "snippet": "    def _extract_url_result(self, post):\n        if post['type'] == 'video':\n            for media in post['media']:\n                if media['type'] == 'video':\n                    video_id = media['content']\n                    source = media['source']\n                    if source == 'brightcove':\n                        player_code = self._download_webpage(\n                            'http://www.nowness.com/iframe?id=%s' % video_id, video_id,\n                            note='Downloading player JavaScript',\n                            errnote='Unable to download player JavaScript')\n                        bc_url = BrightcoveIE._extract_brightcove_url(player_code)\n                        if bc_url is None:\n                            raise ExtractorError('Could not find player definition')\n                        return self.url_result(bc_url, 'Brightcove')\n                    elif source == 'vimeo':\n                        return self.url_result('http://vimeo.com/%s' % video_id, 'Vimeo')\n                    elif source == 'youtube':\n                        return self.url_result(video_id, 'Youtube')\n                    elif source == 'cinematique':\n                        # youtube-dl currently doesn't support cinematique\n                        # return self.url_result('http://cinematique.com/embed/%s' % video_id, 'Cinematique')\n                        pass",
        "begin_line": 14,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessBaseIE._api_request#38",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessBaseIE",
        "signature": "youtube_dl.extractor.nowness.NownessBaseIE._api_request(self, url, request_path)",
        "snippet": "    def _api_request(self, url, request_path):\n        display_id = self._match_id(url)\n        request = compat_urllib_request.Request(\n            'http://api.nowness.com/api/' + request_path % display_id,\n            headers={\n                'X-Nowness-Language': 'zh-cn' if 'cn.nowness.com' in url else 'en-us',\n            })\n        return display_id, self._download_json(request, display_id)",
        "begin_line": 38,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessIE._real_extract#89",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessIE",
        "signature": "youtube_dl.extractor.nowness.NownessIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        _, post = self._api_request(url, 'post/getBySlug/%s')\n        return self._extract_url_result(post)",
        "begin_line": 89,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessPlaylistIE._real_extract#105",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessPlaylistIE",
        "signature": "youtube_dl.extractor.nowness.NownessPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id, playlist = self._api_request(url, 'post?PlaylistId=%s')\n        entries = [self._extract_url_result(item) for item in playlist['items']]\n        return self.playlist_result(entries, playlist_id)",
        "begin_line": 105,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessSeriesIE._real_extract#124",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessSeriesIE",
        "signature": "youtube_dl.extractor.nowness.NownessSeriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id, series = self._api_request(url, 'series/getBySlug/%s')\n        entries = [self._extract_url_result(post) for post in series['posts']]\n        series_title = None\n        series_description = None\n        translations = series.get('translations', [])\n        if translations:\n            series_title = translations[0].get('title') or translations[0]['seoTitle']\n            series_description = translations[0].get('seoDescription')\n        return self.playlist_result(\n            entries, compat_str(series['id']), series_title, series_description)",
        "begin_line": 124,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gfycat.GfycatIE._real_extract#49",
        "src_path": "youtube_dl/extractor/gfycat.py",
        "class_name": "youtube_dl.extractor.gfycat.GfycatIE",
        "signature": "youtube_dl.extractor.gfycat.GfycatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        gfy = self._download_json(\n            'http://gfycat.com/cajax/get/%s' % video_id,\n            video_id, 'Downloading video info')\n        if 'error' in gfy:\n            raise ExtractorError('Gfycat said: ' + gfy['error'], expected=True)\n        gfy = gfy['gfyItem']\n\n        title = gfy.get('title') or gfy['gfyName']\n        description = gfy.get('description')\n        timestamp = int_or_none(gfy.get('createDate'))\n        uploader = gfy.get('userName')\n        view_count = int_or_none(gfy.get('views'))\n        like_count = int_or_none(gfy.get('likes'))\n        dislike_count = int_or_none(gfy.get('dislikes'))\n        age_limit = 18 if gfy.get('nsfw') == '1' else 0\n\n        width = int_or_none(gfy.get('width'))\n        height = int_or_none(gfy.get('height'))\n        fps = int_or_none(gfy.get('frameRate'))\n        num_frames = int_or_none(gfy.get('numFrames'))\n\n        duration = float_or_none(num_frames, fps) if num_frames and fps else None\n\n        categories = gfy.get('tags') or gfy.get('extraLemmas') or []\n\n        FORMATS = ('gif', 'webm', 'mp4')\n        quality = qualities(FORMATS)\n\n        formats = []\n        for format_id in FORMATS:\n            video_url = gfy.get('%sUrl' % format_id)\n            if not video_url:\n                continue\n            filesize = gfy.get('%sSize' % format_id)\n            formats.append({\n                'url': video_url,\n                'format_id': format_id,\n                'width': width,\n                'height': height,\n                'fps': fps,\n                'filesize': filesize,\n                'quality': quality(format_id),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'categories': categories,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 49,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kaltura.KalturaIE._kaltura_api_call#64",
        "src_path": "youtube_dl/extractor/kaltura.py",
        "class_name": "youtube_dl.extractor.kaltura.KalturaIE",
        "signature": "youtube_dl.extractor.kaltura.KalturaIE._kaltura_api_call(self, video_id, actions, *args, **kwargs)",
        "snippet": "    def _kaltura_api_call(self, video_id, actions, *args, **kwargs):\n        params = actions[0]\n        if len(actions) > 1:\n            for i, a in enumerate(actions[1:], start=1):\n                for k, v in a.items():\n                    params['%d:%s' % (i, k)] = v\n\n        query = compat_urllib_parse.urlencode(params)\n        url = self._API_BASE + query\n        data = self._download_json(url, video_id, *args, **kwargs)\n\n        status = data if len(actions) == 1 else data[0]\n        if status.get('objectType') == 'KalturaAPIException':\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, status['message']))\n\n        return data",
        "begin_line": 64,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kaltura.KalturaIE._get_kaltura_signature#82",
        "src_path": "youtube_dl/extractor/kaltura.py",
        "class_name": "youtube_dl.extractor.kaltura.KalturaIE",
        "signature": "youtube_dl.extractor.kaltura.KalturaIE._get_kaltura_signature(self, video_id, partner_id)",
        "snippet": "    def _get_kaltura_signature(self, video_id, partner_id):\n        actions = [{\n            'apiVersion': '3.1',\n            'expiry': 86400,\n            'format': 1,\n            'service': 'session',\n            'action': 'startWidgetSession',\n            'widgetId': '_%s' % partner_id,\n        }]\n        return self._kaltura_api_call(\n            video_id, actions, note='Downloading Kaltura signature')['ks']",
        "begin_line": 82,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kaltura.KalturaIE._get_video_info#94",
        "src_path": "youtube_dl/extractor/kaltura.py",
        "class_name": "youtube_dl.extractor.kaltura.KalturaIE",
        "signature": "youtube_dl.extractor.kaltura.KalturaIE._get_video_info(self, video_id, partner_id)",
        "snippet": "    def _get_video_info(self, video_id, partner_id):\n        signature = self._get_kaltura_signature(video_id, partner_id)\n        actions = [\n            {\n                'action': 'null',\n                'apiVersion': '3.1.5',\n                'clientTag': 'kdp:v3.8.5',\n                'format': 1,  # JSON, 2 = XML, 3 = PHP\n                'service': 'multirequest',\n                'ks': signature,\n            },\n            {\n                'action': 'get',\n                'entryId': video_id,\n                'service': 'baseentry',\n                'version': '-1',\n            },\n            {\n                'action': 'getContextData',\n                'contextDataParams:objectType': 'KalturaEntryContextDataParams',\n                'contextDataParams:referrer': 'http://www.kaltura.com/',\n                'contextDataParams:streamerType': 'http',\n                'entryId': video_id,\n                'service': 'baseentry',\n            },\n        ]\n        return self._kaltura_api_call(\n            video_id, actions, note='Downloading video info JSON')",
        "begin_line": 94,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kaltura.KalturaIE._real_extract#123",
        "src_path": "youtube_dl/extractor/kaltura.py",
        "class_name": "youtube_dl.extractor.kaltura.KalturaIE",
        "signature": "youtube_dl.extractor.kaltura.KalturaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        partner_id = mobj.group('partner_id_s') or mobj.group('partner_id') or mobj.group('partner_id_html5')\n        entry_id = mobj.group('id_s') or mobj.group('id') or mobj.group('id_html5')\n\n        info, source_data = self._get_video_info(entry_id, partner_id)\n\n        formats = [{\n            'format_id': '%(fileExt)s-%(bitrate)s' % f,\n            'ext': f['fileExt'],\n            'tbr': f['bitrate'],\n            'fps': f.get('frameRate'),\n            'filesize_approx': int_or_none(f.get('size'), invscale=1024),\n            'container': f.get('containerFormat'),\n            'vcodec': f.get('videoCodecId'),\n            'height': f.get('height'),\n            'width': f.get('width'),\n            'url': '%s/flavorId/%s' % (info['dataUrl'], f['id']),\n        } for f in source_data['flavorAssets']]\n        self._sort_formats(formats)\n\n        return {\n            'id': entry_id,\n            'title': info['name'],\n            'formats': formats,\n            'description': info.get('description'),\n            'thumbnail': info.get('thumbnailUrl'),\n            'duration': info.get('duration'),\n            'timestamp': info.get('createdAt'),\n            'uploader_id': info.get('userId'),\n            'view_count': info.get('plays'),\n        }",
        "begin_line": 123,
        "end_line": 154,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dbtv.DBTVIE._real_extract#35",
        "src_path": "youtube_dl/extractor/dbtv.py",
        "class_name": "youtube_dl.extractor.dbtv.DBTVIE",
        "signature": "youtube_dl.extractor.dbtv.DBTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        data = self._download_json(\n            'http://api.dbtv.no/discovery/%s' % video_id, display_id)\n\n        video = data['playlist'][0]\n\n        formats = [{\n            'url': f['URL'],\n            'vcodec': f.get('container'),\n            'width': int_or_none(f.get('width')),\n            'height': int_or_none(f.get('height')),\n            'vbr': float_or_none(f.get('rate'), 1000),\n            'filesize': int_or_none(f.get('size')),\n        } for f in video['renditions'] if 'URL' in f]\n\n        if not formats:\n            for url_key, format_id in [('URL', 'mp4'), ('HLSURL', 'hls')]:\n                if url_key in video:\n                    formats.append({\n                        'url': video[url_key],\n                        'format_id': format_id,\n                    })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': compat_str(video['id']),\n            'display_id': display_id,\n            'title': video['title'],\n            'description': clean_html(video['desc']),\n            'thumbnail': video.get('splash') or video.get('thumb'),\n            'timestamp': float_or_none(video.get('publishedAt'), 1000),\n            'duration': float_or_none(video.get('length'), 1000),\n            'view_count': int_or_none(video.get('views')),\n            'categories': video.get('tags'),\n            'formats': formats,\n        }",
        "begin_line": 35,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._parse_smil#59",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._parse_smil(self, video_id, smil_url)",
        "snippet": "    def _parse_smil(self, video_id, smil_url):\n        formats = []\n        _SWITCH_XPATH = (\n            './/{http://www.w3.org/2001/SMIL20/Language}body/'\n            '{http://www.w3.org/2001/SMIL20/Language}switch')\n        smil_doc = self._download_xml(\n            smil_url, video_id,\n            note='Downloading SMIL information',\n            errnote='Unable to download SMIL information',\n            fatal=False)\n        if smil_doc is False:  # Download failed\n            return formats\n        title_node = find_xpath_attr(\n            smil_doc, './/{http://www.w3.org/2001/SMIL20/Language}meta',\n            'name', 'title')\n        if title_node is None:\n            self.report_warning('Cannot find SMIL id')\n            switch_node = smil_doc.find(_SWITCH_XPATH)\n        else:\n            title_id = title_node.attrib['content']\n            switch_node = find_xpath_attr(\n                smil_doc, _SWITCH_XPATH, 'id', title_id)\n        if switch_node is None:\n            raise ExtractorError('Cannot find switch node')\n        video_nodes = switch_node.findall(\n            '{http://www.w3.org/2001/SMIL20/Language}video')\n\n        for vn in video_nodes:\n            tbr = int_or_none(vn.attrib.get('system-bitrate'))\n            furl = (\n                'http://livestream-f.akamaihd.net/%s?v=3.0.3&fp=WIN%%2014,0,0,145' %\n                (vn.attrib['src']))\n            if 'clipBegin' in vn.attrib:\n                furl += '&ssek=' + vn.attrib['clipBegin']\n            formats.append({\n                'url': furl,\n                'format_id': 'smil_%d' % tbr,\n                'ext': 'flv',\n                'tbr': tbr,\n                'preference': -1000,\n            })\n        return formats",
        "begin_line": 59,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._extract_video_info#102",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._extract_video_info(self, video_data)",
        "snippet": "    def _extract_video_info(self, video_data):\n        video_id = compat_str(video_data['id'])\n\n        FORMAT_KEYS = (\n            ('sd', 'progressive_url'),\n            ('hd', 'progressive_url_hd'),\n        )\n        formats = [{\n            'format_id': format_id,\n            'url': video_data[key],\n            'quality': i + 1,\n        } for i, (format_id, key) in enumerate(FORMAT_KEYS)\n            if video_data.get(key)]\n\n        smil_url = video_data.get('smil_url')\n        if smil_url:\n            formats.extend(self._parse_smil(video_id, smil_url))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_data['caption'],\n            'thumbnail': video_data.get('thumbnail_url'),\n            'upload_date': video_data['updated_at'].replace('-', '')[:8],\n            'like_count': video_data.get('likes', {}).get('total'),\n            'view_count': video_data.get('views'),\n        }",
        "begin_line": 102,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._extract_event#131",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._extract_event(self, info)",
        "snippet": "    def _extract_event(self, info):\n        event_id = compat_str(info['id'])\n        account = compat_str(info['owner_account_id'])\n        root_url = (\n            'https://new.livestream.com/api/accounts/{account}/events/{event}/'\n            'feed.json'.format(account=account, event=event_id))\n\n        def _extract_videos():\n            last_video = None\n            for i in itertools.count(1):\n                if last_video is None:\n                    info_url = root_url\n                else:\n                    info_url = '{root}?&id={id}&newer=-1&type=video'.format(\n                        root=root_url, id=last_video)\n                videos_info = self._download_json(info_url, event_id, 'Downloading page {0}'.format(i))['data']\n                videos_info = [v['data'] for v in videos_info if v['type'] == 'video']\n                if not videos_info:\n                    break\n                for v in videos_info:\n                    yield self._extract_video_info(v)\n                last_video = videos_info[-1]['id']\n        return self.playlist_result(_extract_videos(), event_id, info['full_name'])",
        "begin_line": 131,
        "end_line": 153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._real_extract#155",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        event_name = mobj.group('event_name')\n        webpage = self._download_webpage(url, video_id or event_name)\n\n        og_video = self._og_search_video_url(\n            webpage, 'player url', fatal=False, default=None)\n        if og_video is not None:\n            query_str = compat_urllib_parse_urlparse(og_video).query\n            query = compat_urlparse.parse_qs(query_str)\n            if 'play_url' in query:\n                api_url = query['play_url'][0].replace('.smil', '')\n                info = json.loads(self._download_webpage(\n                    api_url, video_id, 'Downloading video info'))\n                return self._extract_video_info(info)\n\n        config_json = self._search_regex(\n            r'window.config = ({.*?});', webpage, 'window config')\n        info = json.loads(config_json)['event']\n\n        def is_relevant(vdata, vid):\n            result = vdata['type'] == 'video'\n            if video_id is not None:\n                result = result and compat_str(vdata['data']['id']) == vid\n            return result\n\n        if video_id is None:\n            # This is an event page:\n            return self._extract_event(info)\n        else:\n            videos = [self._extract_video_info(video_data['data'])\n                      for video_data in info['feed']['data']\n                      if is_relevant(video_data, video_id)]\n            if not videos:\n                raise ExtractorError('Cannot find video %s' % video_id)\n            return videos[0]",
        "begin_line": 155,
        "end_line": 191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_video#216",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_video(self, user, video_id)",
        "snippet": "    def _extract_video(self, user, video_id):\n        api_url = 'http://x{0}x.api.channel.livestream.com/2.0/clipdetails?extendedInfo=true&id={1}'.format(user, video_id)\n\n        info = self._download_xml(api_url, video_id)\n        # this url is used on mobile devices\n        stream_url = 'http://x{0}x.api.channel.livestream.com/3.0/getstream.json?id={1}'.format(user, video_id)\n        stream_info = self._download_json(stream_url, video_id)\n        item = info.find('channel').find('item')\n        ns = {'media': 'http://search.yahoo.com/mrss'}\n        thumbnail_url = item.find(xpath_with_ns('media:thumbnail', ns)).attrib['url']\n\n        return {\n            'id': video_id,\n            'title': item.find('title').text,\n            'url': stream_info['progressiveUrl'],\n            'thumbnail': thumbnail_url,\n        }",
        "begin_line": 216,
        "end_line": 232,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_folder#234",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_folder(self, url, folder_id)",
        "snippet": "    def _extract_folder(self, url, folder_id):\n        webpage = self._download_webpage(url, folder_id)\n        paths = orderedSet(re.findall(\n            r'''(?x)(?:\n                <li\\s+class=\"folder\">\\s*<a\\s+href=\"|\n                <a\\s+href=\"(?=https?://livestre\\.am/)\n            )([^\"]+)\"''', webpage))\n\n        return {\n            '_type': 'playlist',\n            'id': folder_id,\n            'entries': [{\n                '_type': 'url',\n                'url': compat_urlparse.urljoin(url, p),\n            } for p in paths],\n        }",
        "begin_line": 234,
        "end_line": 249,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._real_extract#251",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        id = mobj.group('id')\n        user = mobj.group('user')\n        url_type = mobj.group('type')\n        if url_type == 'folder':\n            return self._extract_folder(url, id)\n        else:\n            return self._extract_video(user, id)",
        "begin_line": 251,
        "end_line": 259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamShortenerIE._real_extract#269",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamShortenerIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamShortenerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        id = mobj.group('id')\n        webpage = self._download_webpage(url, id)\n\n        return {\n            '_type': 'url',\n            'url': self._og_search_url(webpage),\n        }",
        "begin_line": 269,
        "end_line": 277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.escapist._decrypt_config#16",
        "src_path": "youtube_dl/extractor/escapist.py",
        "class_name": "youtube_dl.extractor.escapist",
        "signature": "youtube_dl.extractor.escapist._decrypt_config(key, string)",
        "snippet": "def _decrypt_config(key, string):\n    a = ''\n    i = ''\n    r = ''\n\n    while len(a) < (len(string) / 2):\n        a += key\n\n    a = a[0:int(len(string) / 2)]\n\n    t = 0\n    while t < len(string):\n        i += chr(int(string[t] + string[t + 1], 16))\n        t += 2\n\n    icko = [s for s in i]\n\n    for t, c in enumerate(a):\n        r += chr(ord(c) ^ ord(icko[t]))\n\n    return r",
        "begin_line": 16,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.escapist.EscapistIE._real_extract#67",
        "src_path": "youtube_dl/extractor/escapist.py",
        "class_name": "youtube_dl.extractor.escapist.EscapistIE",
        "signature": "youtube_dl.extractor.escapist.EscapistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        ims_video = self._parse_json(\n            self._search_regex(\n                r'imsVideo\\.play\\(({.+?})\\);', webpage, 'imsVideo'),\n            video_id)\n        video_id = ims_video['videoID']\n        key = ims_video['hash']\n\n        config_req = compat_urllib_request.Request(\n            'http://www.escapistmagazine.com/videos/'\n            'vidconfig.php?videoID=%s&hash=%s' % (video_id, key))\n        config_req.add_header('Referer', url)\n        config = self._download_webpage(config_req, video_id, 'Downloading video config')\n\n        data = json.loads(_decrypt_config(key, config))\n\n        video_data = data['videoData']\n\n        title = clean_html(video_data['title'])\n        duration = float_or_none(video_data.get('duration'), 1000)\n        uploader = video_data.get('publisher')\n\n        formats = [{\n            'url': video['src'],\n            'format_id': '%s-%sp' % (determine_ext(video['src']), video['res']),\n            'height': int_or_none(video.get('res')),\n        } for video in data['files']['videos']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n            'duration': duration,\n            'uploader': uploader,\n        }",
        "begin_line": 67,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twentyfourvideo.TwentyFourVideoIE._real_extract#40",
        "src_path": "youtube_dl/extractor/twentyfourvideo.py",
        "class_name": "youtube_dl.extractor.twentyfourvideo.TwentyFourVideoIE",
        "signature": "youtube_dl.extractor.twentyfourvideo.TwentyFourVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.24video.net/video/view/%s' % video_id, video_id)\n\n        title = self._og_search_title(webpage)\n        description = self._html_search_regex(\n            r'<span itemprop=\"description\">([^<]+)</span>', webpage, 'description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n        duration = int_or_none(self._og_search_property(\n            'duration', webpage, 'duration', fatal=False))\n        timestamp = parse_iso8601(self._search_regex(\n            r'<time id=\"video-timeago\" datetime=\"([^\"]+)\" itemprop=\"uploadDate\">',\n            webpage, 'upload date'))\n\n        uploader = self._html_search_regex(\n            r'class=\"video-uploaded\"[^>]*>\\s*<a href=\"/jsecUser/movies/[^\"]+\"[^>]*>([^<]+)</a>',\n            webpage, 'uploader', fatal=False)\n\n        view_count = int_or_none(self._html_search_regex(\n            r'<span class=\"video-views\">(\\d+) \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440',\n            webpage, 'view count', fatal=False))\n        comment_count = int_or_none(self._html_search_regex(\n            r'<div class=\"comments-title\" id=\"comments-count\">(\\d+) \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438',\n            webpage, 'comment count', fatal=False))\n\n        formats = []\n\n        pc_video = self._download_xml(\n            'http://www.24video.net/video/xml/%s?mode=play' % video_id,\n            video_id, 'Downloading PC video URL').find('.//video')\n\n        formats.append({\n            'url': pc_video.attrib['url'],\n            'format_id': 'pc',\n            'quality': 1,\n        })\n\n        like_count = int_or_none(pc_video.get('ratingPlus'))\n        dislike_count = int_or_none(pc_video.get('ratingMinus'))\n        age_limit = 18 if pc_video.get('adult') == 'true' else 0\n\n        mobile_video = self._download_xml(\n            'http://www.24video.net/video/xml/%s' % video_id,\n            video_id, 'Downloading mobile video URL').find('.//video')\n\n        formats.append({\n            'url': mobile_video.attrib['url'],\n            'format_id': 'mobile',\n            'quality': 0,\n        })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'duration': duration,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 40,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.commonmistakes.CommonMistakesIE._real_extract#21",
        "src_path": "youtube_dl/extractor/commonmistakes.py",
        "class_name": "youtube_dl.extractor.commonmistakes.CommonMistakesIE",
        "signature": "youtube_dl.extractor.commonmistakes.CommonMistakesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        msg = (\n            'You\\'ve asked youtube-dl to download the URL \"%s\". '\n            'That doesn\\'t make any sense. '\n            'Simply remove the parameter in your command or configuration.'\n        ) % url\n        if not self._downloader.params.get('verbose'):\n            msg += ' Add -v to the command line to see what arguments and configuration youtube-dl got.'\n        raise ExtractorError(msg, expected=True)",
        "begin_line": 21,
        "end_line": 29,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.commonmistakes.UnicodeBOMIE._real_extract#41",
        "src_path": "youtube_dl/extractor/commonmistakes.py",
        "class_name": "youtube_dl.extractor.commonmistakes.UnicodeBOMIE",
        "signature": "youtube_dl.extractor.commonmistakes.UnicodeBOMIE._real_extract(self, url)",
        "snippet": "        def _real_extract(self, url):\n            real_url = self._match_id(url)\n            self.report_warning(\n                'Your URL starts with a Byte Order Mark (BOM). '\n                'Removing the BOM and looking for \"%s\" ...' % real_url)\n            return self.url_result(real_url)",
        "begin_line": 41,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE._real_extract#20",
        "src_path": "youtube_dl/extractor/ebaumsworld.py",
        "class_name": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE",
        "signature": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        config = self._download_xml(\n            'http://www.ebaumsworld.com/video/player/%s' % video_id, video_id)\n        video_url = config.find('file').text\n\n        return {\n            'id': video_id,\n            'title': config.find('title').text,\n            'url': video_url,\n            'description': config.find('description').text,\n            'thumbnail': config.find('image').text,\n            'uploader': config.find('username').text,\n        }",
        "begin_line": 20,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitter.TwitterCardIE._real_extract#56",
        "src_path": "youtube_dl/extractor/twitter.py",
        "class_name": "youtube_dl.extractor.twitter.TwitterCardIE",
        "signature": "youtube_dl.extractor.twitter.TwitterCardIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Different formats served for different User-Agents\n        USER_AGENTS = [\n            'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20150101 Firefox/20.0 (Chrome)',  # mp4\n            'Mozilla/5.0 (Windows NT 5.2; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0',  # webm\n        ]\n\n        config = None\n        formats = []\n        for user_agent in USER_AGENTS:\n            request = compat_urllib_request.Request(url)\n            request.add_header('User-Agent', user_agent)\n            webpage = self._download_webpage(request, video_id)\n\n            youtube_url = self._html_search_regex(\n                r'<iframe[^>]+src=\"((?:https?:)?//www.youtube.com/embed/[^\"]+)\"',\n                webpage, 'youtube iframe', default=None)\n            if youtube_url:\n                return self.url_result(youtube_url, 'Youtube')\n\n            config = self._parse_json(self._html_search_regex(\n                r'data-player-config=\"([^\"]+)\"', webpage, 'data player config'),\n                video_id)\n            if 'playlist' not in config:\n                if 'vmapUrl' in config:\n                    vmap_data = self._download_xml(config['vmapUrl'], video_id)\n                    video_url = xpath_text(vmap_data, './/MediaFile').strip()\n                    formats.append({\n                        'url': video_url,\n                    })\n                    break   # same video regardless of UA\n                continue\n\n            video_url = config['playlist'][0]['source']\n\n            f = {\n                'url': video_url,\n            }\n\n            m = re.search(r'/(?P<width>\\d+)x(?P<height>\\d+)/', video_url)\n            if m:\n                f.update({\n                    'width': int(m.group('width')),\n                    'height': int(m.group('height')),\n                })\n            formats.append(f)\n        self._sort_formats(formats)\n\n        thumbnail = config.get('posterImageUrl')\n        duration = float_or_none(config.get('duration'))\n\n        return {\n            'id': video_id,\n            'title': 'TwitterCard',\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 56,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twitter.TwitterIE._real_extract#138",
        "src_path": "youtube_dl/extractor/twitter.py",
        "class_name": "youtube_dl.extractor.twitter.TwitterIE",
        "signature": "youtube_dl.extractor.twitter.TwitterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('user_id')\n        twid = mobj.group('id')\n\n        webpage = self._download_webpage(self._TEMPLATE_URL % (user_id, twid), twid)\n\n        username = remove_end(self._og_search_title(webpage), ' on Twitter')\n\n        title = self._og_search_description(webpage).strip('').replace('\\n', ' ')\n\n        # strip  'https -_t.co_BJYgOjSeGA' junk from filenames\n        mobj = re.match(r'\u201c(.*)\\s+(https?://[^ ]+)\u201d', title)\n        title, short_url = mobj.groups()\n\n        card_id = self._search_regex(\n            r'[\"\\']/i/cards/tfw/v1/(\\d+)', webpage, 'twitter card url')\n        card_url = 'https://twitter.com/i/cards/tfw/v1/' + card_id\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'TwitterCard',\n            'uploader_id': user_id,\n            'uploader': username,\n            'url': card_url,\n            'webpage_url': url,\n            'description': '%s on Twitter: \"%s %s\"' % (username, title, short_url),\n            'title': username + ' - ' + title,\n        }",
        "begin_line": 138,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sexu.SexuIE._real_extract#24",
        "src_path": "youtube_dl/extractor/sexu.py",
        "class_name": "youtube_dl.extractor.sexu.SexuIE",
        "signature": "youtube_dl.extractor.sexu.SexuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        quality_arr = self._search_regex(\n            r'sources:\\s*\\[([^\\]]+)\\]', webpage, 'forrmat string')\n        formats = [{\n            'url': fmt[0].replace('\\\\', ''),\n            'format_id': fmt[1],\n            'height': int(fmt[1][:3]),\n        } for fmt in re.findall(r'\"file\":\"([^\"]+)\",\"label\":\"([^\"]+)\"', quality_arr)]\n        self._sort_formats(formats)\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)\\s*-\\s*Sexu\\.Com</title>', webpage, 'title')\n\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n\n        thumbnail = self._html_search_regex(\n            r'image:\\s*\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        categories_str = self._html_search_meta(\n            'keywords', webpage, 'categories')\n        categories = (\n            None if categories_str is None\n            else categories_str.split(','))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 24,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.steam.SteamIE._real_extract#62",
        "src_path": "youtube_dl/extractor/steam.py",
        "class_name": "youtube_dl.extractor.steam.SteamIE",
        "signature": "youtube_dl.extractor.steam.SteamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        fileID = m.group('fileID')\n        if fileID:\n            videourl = url\n            playlist_id = fileID\n        else:\n            gameID = m.group('gameID')\n            playlist_id = gameID\n            videourl = self._VIDEO_PAGE_TEMPLATE % playlist_id\n        webpage = self._download_webpage(videourl, playlist_id)\n\n        if re.search('<h2>Please enter your birth date to continue:</h2>', webpage) is not None:\n            videourl = self._AGECHECK_TEMPLATE % playlist_id\n            self.report_age_confirmation()\n            webpage = self._download_webpage(videourl, playlist_id)\n\n        if fileID:\n            playlist_title = self._html_search_regex(\n                r'<div class=\"workshopItemTitle\">(.+)</div>', webpage, 'title')\n            mweb = re.finditer(r'''(?x)\n                'movie_(?P<videoID>[0-9]+)':\\s*\\{\\s*\n                YOUTUBE_VIDEO_ID:\\s*\"(?P<youtube_id>[^\"]+)\",\n                ''', webpage)\n            videos = [{\n                '_type': 'url',\n                'url': vid.group('youtube_id'),\n                'ie_key': 'Youtube',\n            } for vid in mweb]\n        else:\n            playlist_title = self._html_search_regex(\n                r'<h2 class=\"pageheader\">(.*?)</h2>', webpage, 'game title')\n\n            mweb = re.finditer(r'''(?x)\n                'movie_(?P<videoID>[0-9]+)':\\s*\\{\\s*\n                FILENAME:\\s*\"(?P<videoURL>[\\w:/\\.\\?=]+)\"\n                (,\\s*MOVIE_NAME:\\s*\\\"(?P<videoName>[\\w:/\\.\\?=\\+-]+)\\\")?\\s*\\},\n                ''', webpage)\n            titles = re.finditer(\n                r'<span class=\"title\">(?P<videoName>.+?)</span>', webpage)\n            thumbs = re.finditer(\n                r'<img class=\"movie_thumb\" src=\"(?P<thumbnail>.+?)\">', webpage)\n            videos = []\n\n            for vid, vtitle, thumb in zip(mweb, titles, thumbs):\n                video_id = vid.group('videoID')\n                title = vtitle.group('videoName')\n                video_url = vid.group('videoURL')\n                video_thumb = thumb.group('thumbnail')\n                if not video_url:\n                    raise ExtractorError('Cannot find video url for %s' % video_id)\n                videos.append({\n                    'id': video_id,\n                    'url': video_url,\n                    'ext': 'flv',\n                    'title': unescapeHTML(title),\n                    'thumbnail': video_thumb\n                })\n        if not videos:\n            raise ExtractorError('Could not find any videos')\n\n        return self.playlist_result(videos, playlist_id, playlist_title)",
        "begin_line": 62,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cloudy.CloudyIE._extract_video#50",
        "src_path": "youtube_dl/extractor/cloudy.py",
        "class_name": "youtube_dl.extractor.cloudy.CloudyIE",
        "signature": "youtube_dl.extractor.cloudy.CloudyIE._extract_video(self, video_host, video_id, file_key, error_url=None, try_num=0)",
        "snippet": "    def _extract_video(self, video_host, video_id, file_key, error_url=None, try_num=0):\n\n        if try_num > self._MAX_TRIES - 1:\n            raise ExtractorError('Unable to extract video URL', expected=True)\n\n        form = {\n            'file': video_id,\n            'key': file_key,\n        }\n\n        if error_url:\n            form.update({\n                'numOfErrors': try_num,\n                'errorCode': '404',\n                'errorUrl': error_url,\n            })\n\n        data_url = self._API_URL % (video_host, compat_urllib_parse.urlencode(form))\n        player_data = self._download_webpage(\n            data_url, video_id, 'Downloading player data')\n        data = compat_parse_qs(player_data)\n\n        try_num += 1\n\n        if 'error' in data:\n            raise ExtractorError(\n                '%s error: %s' % (self.IE_NAME, ' '.join(data['error_msg'])),\n                expected=True)\n\n        title = data.get('title', [None])[0]\n        if title:\n            title = remove_end(title, '&asdasdas').strip()\n\n        video_url = data.get('url', [None])[0]\n\n        if video_url:\n            try:\n                self._request_webpage(HEADRequest(video_url), video_id, 'Checking video URL')\n            except ExtractorError as e:\n                if isinstance(e.cause, compat_HTTPError) and e.cause.code in [404, 410]:\n                    self.report_warning('Invalid video URL, requesting another', video_id)\n                    return self._extract_video(video_host, video_id, file_key, video_url, try_num)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n        }",
        "begin_line": 50,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cloudy.CloudyIE._real_extract#99",
        "src_path": "youtube_dl/extractor/cloudy.py",
        "class_name": "youtube_dl.extractor.cloudy.CloudyIE",
        "signature": "youtube_dl.extractor.cloudy.CloudyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_host = mobj.group('host')\n        video_id = mobj.group('id')\n\n        url = self._EMBED_URL % (video_host, video_id)\n        webpage = self._download_webpage(url, video_id)\n\n        file_key = self._search_regex(\n            [r'key\\s*:\\s*\"([^\"]+)\"', r'filekey\\s*=\\s*\"([^\"]+)\"'],\n            webpage, 'file_key')\n\n        return self._extract_video(video_host, video_id, file_key)",
        "begin_line": 99,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.radiode.RadioDeIE._real_extract#24",
        "src_path": "youtube_dl/extractor/radiode.py",
        "class_name": "youtube_dl.extractor.radiode.RadioDeIE",
        "signature": "youtube_dl.extractor.radiode.RadioDeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        radio_id = self._match_id(url)\n        webpage = self._download_webpage(url, radio_id)\n        jscode = self._search_regex(\n            r\"'components/station/stationService':\\s*\\{\\s*'?station'?:\\s*(\\{.*?\\s*\\}),\\n\",\n            webpage, 'broadcast')\n\n        broadcast = self._parse_json(jscode, radio_id)\n        title = self._live_title(broadcast['name'])\n        description = broadcast.get('description') or broadcast.get('shortDescription')\n        thumbnail = broadcast.get('picture4Url') or broadcast.get('picture4TransUrl') or broadcast.get('logo100x100')\n\n        formats = [{\n            'url': stream['streamUrl'],\n            'ext': stream['streamContentFormat'].lower(),\n            'acodec': stream['streamContentFormat'],\n            'abr': stream['bitRate'],\n            'asr': stream['sampleRate']\n        } for stream in broadcast['streamUrls']]\n        self._sort_formats(formats)\n\n        return {\n            'id': radio_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'is_live': True,\n            'formats': formats,\n        }",
        "begin_line": 24,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tapely.TapelyIE._real_extract#51",
        "src_path": "youtube_dl/extractor/tapely.py",
        "class_name": "youtube_dl.extractor.tapely.TapelyIE",
        "signature": "youtube_dl.extractor.tapely.TapelyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        playlist_url = self._API_URL.format(display_id)\n        request = compat_urllib_request.Request(playlist_url)\n        request.add_header('X-Requested-With', 'XMLHttpRequest')\n        request.add_header('Accept', 'application/json')\n        request.add_header('Referer', url)\n\n        playlist = self._download_json(request, display_id)\n\n        tape = playlist['tape']\n\n        entries = []\n        for s in tape['songs']:\n            song = s['song']\n            entry = {\n                'id': song['id'],\n                'duration': float_or_none(song.get('songduration'), 1000),\n                'title': song['title'],\n            }\n            if song['source'] == 'S3':\n                entry.update({\n                    'url': self._S3_SONG_URL.format(song['filename']),\n                })\n                entries.append(entry)\n            elif song['source'] == 'YT':\n                self.to_screen('YouTube video detected')\n                yt_id = song['filename'].replace('/youtube/', '')\n                entry.update(self.url_result(yt_id, 'Youtube', video_id=yt_id))\n                entries.append(entry)\n            elif song['source'] == 'SC':\n                self.to_screen('SoundCloud song detected')\n                sc_url = self._SOUNDCLOUD_SONG_URL.format(song['filename'])\n                entry.update(self.url_result(sc_url, 'Soundcloud'))\n                entries.append(entry)\n            else:\n                self.report_warning('Unknown song source: %s' % song['source'])\n\n        if mobj.group('songnr'):\n            songnr = int(mobj.group('songnr')) - 1\n            try:\n                return entries[songnr]\n            except IndexError:\n                raise ExtractorError(\n                    'No song with index: %s' % mobj.group('songnr'),\n                    expected=True)\n\n        return {\n            '_type': 'playlist',\n            'id': tape['id'],\n            'display_id': display_id,\n            'title': tape['name'],\n            'entries': entries,\n            'thumbnail': tape.get('image_url'),\n            'description': clean_html(tape.get('subtext')),\n            'like_count': tape.get('likescount'),\n            'uploader_id': tape.get('user_id'),\n            'timestamp': parse_iso8601(tape.get('published_at')),\n        }",
        "begin_line": 51,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.foxsports.FoxSportsIE._real_extract#21",
        "src_path": "youtube_dl/extractor/foxsports.py",
        "class_name": "youtube_dl.extractor.foxsports.FoxSportsIE",
        "signature": "youtube_dl.extractor.foxsports.FoxSportsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        config = self._parse_json(\n            self._search_regex(\n                r\"data-player-config='([^']+)'\", webpage, 'data player config'),\n            video_id)\n\n        return self.url_result(smuggle_url(\n            config['releaseURL'] + '&manifest=f4m', {'force_smil_url': True}))",
        "begin_line": 21,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimple.SprutoBaseIE._extract_spruto#8",
        "src_path": "youtube_dl/extractor/vimple.py",
        "class_name": "youtube_dl.extractor.vimple.SprutoBaseIE",
        "signature": "youtube_dl.extractor.vimple.SprutoBaseIE._extract_spruto(self, spruto, video_id)",
        "snippet": "    def _extract_spruto(self, spruto, video_id):\n        playlist = spruto['playlist'][0]\n        title = playlist['title']\n        video_id = playlist.get('videoId') or video_id\n        thumbnail = playlist.get('posterUrl') or playlist.get('thumbnailUrl')\n        duration = int_or_none(playlist.get('duration'))\n\n        formats = [{\n            'url': f['url'],\n        } for f in playlist['video']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 8,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vimple.VimpleIE._real_extract#49",
        "src_path": "youtube_dl/extractor/vimple.py",
        "class_name": "youtube_dl.extractor.vimple.VimpleIE",
        "signature": "youtube_dl.extractor.vimple.VimpleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://player.vimple.ru/iframe/%s' % video_id, video_id)\n\n        spruto = self._parse_json(\n            self._search_regex(\n                r'sprutoData\\s*:\\s*({.+?}),\\r\\n', webpage, 'spruto data'),\n            video_id)\n\n        return self._extract_spruto(spruto, video_id)",
        "begin_line": 49,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.letv.LetvIE.urshift#67",
        "src_path": "youtube_dl/extractor/letv.py",
        "class_name": "youtube_dl.extractor.letv.LetvIE",
        "signature": "youtube_dl.extractor.letv.LetvIE.urshift(val, n)",
        "snippet": "    def urshift(val, n):\n        return val >> n if val >= 0 else (val + 0x100000000) >> n",
        "begin_line": 67,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.letv.LetvIE.ror#71",
        "src_path": "youtube_dl/extractor/letv.py",
        "class_name": "youtube_dl.extractor.letv.LetvIE",
        "signature": "youtube_dl.extractor.letv.LetvIE.ror(self, param1, param2)",
        "snippet": "    def ror(self, param1, param2):\n        _loc3_ = 0\n        while _loc3_ < param2:\n            param1 = self.urshift(param1, 1) + ((param1 & 1) << 31)\n            _loc3_ += 1\n        return param1",
        "begin_line": 71,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.letv.LetvIE.calc_time_key#78",
        "src_path": "youtube_dl/extractor/letv.py",
        "class_name": "youtube_dl.extractor.letv.LetvIE",
        "signature": "youtube_dl.extractor.letv.LetvIE.calc_time_key(self, param1)",
        "snippet": "    def calc_time_key(self, param1):\n        _loc2_ = 773625421\n        _loc3_ = self.ror(param1, _loc2_ % 13)\n        _loc3_ = _loc3_ ^ _loc2_\n        _loc3_ = self.ror(_loc3_, _loc2_ % 17)\n        return _loc3_",
        "begin_line": 78,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.letv.LetvIE.decrypt_m3u8#87",
        "src_path": "youtube_dl/extractor/letv.py",
        "class_name": "youtube_dl.extractor.letv.LetvIE",
        "signature": "youtube_dl.extractor.letv.LetvIE.decrypt_m3u8(encrypted_data)",
        "snippet": "    def decrypt_m3u8(encrypted_data):\n        if encrypted_data[:5].decode('utf-8').lower() != 'vc_01':\n            return encrypted_data\n        encrypted_data = encrypted_data[5:]\n\n        _loc4_ = bytearray()\n        while encrypted_data:\n            b = compat_ord(encrypted_data[0])\n            _loc4_.extend([b // 16, b & 0x0f])\n            encrypted_data = encrypted_data[1:]\n        idx = len(_loc4_) - 11\n        _loc4_ = _loc4_[idx:] + _loc4_[:idx]\n        _loc7_ = bytearray()\n        while _loc4_:\n            _loc7_.append(_loc4_[0] * 16 + _loc4_[1])\n            _loc4_ = _loc4_[2:]\n\n        return bytes(_loc7_)",
        "begin_line": 87,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.letv.LetvIE._real_extract#106",
        "src_path": "youtube_dl/extractor/letv.py",
        "class_name": "youtube_dl.extractor.letv.LetvIE",
        "signature": "youtube_dl.extractor.letv.LetvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        media_id = self._match_id(url)\n        page = self._download_webpage(url, media_id)\n        params = {\n            'id': media_id,\n            'platid': 1,\n            'splatid': 101,\n            'format': 1,\n            'tkey': self.calc_time_key(int(time.time())),\n            'domain': 'www.letv.com'\n        }\n        play_json_req = compat_urllib_request.Request(\n            'http://api.letv.com/mms/out/video/playJson?' + compat_urllib_parse.urlencode(params)\n        )\n        cn_verification_proxy = self._downloader.params.get('cn_verification_proxy')\n        if cn_verification_proxy:\n            play_json_req.add_header('Ytdl-request-proxy', cn_verification_proxy)\n\n        play_json = self._download_json(\n            play_json_req,\n            media_id, 'Downloading playJson data')\n\n        # Check for errors\n        playstatus = play_json['playstatus']\n        if playstatus['status'] == 0:\n            flag = playstatus['flag']\n            if flag == 1:\n                msg = 'Country %s auth error' % playstatus['country']\n            else:\n                msg = 'Generic error. flag = %d' % flag\n            raise ExtractorError(msg, expected=True)\n\n        playurl = play_json['playurl']\n\n        formats = ['350', '1000', '1300', '720p', '1080p']\n        dispatch = playurl['dispatch']\n\n        urls = []\n        for format_id in formats:\n            if format_id in dispatch:\n                media_url = playurl['domain'][0] + dispatch[format_id][0]\n                media_url += '&' + compat_urllib_parse.urlencode({\n                    'm3v': 1,\n                    'format': 1,\n                    'expect': 3,\n                    'rateid': format_id,\n                })\n\n                nodes_data = self._download_json(\n                    media_url, media_id,\n                    'Download JSON metadata for format %s' % format_id)\n\n                req = self._request_webpage(\n                    nodes_data['nodelist'][0]['location'], media_id,\n                    note='Downloading m3u8 information for format %s' % format_id)\n\n                m3u8_data = self.decrypt_m3u8(req.read())\n\n                url_info_dict = {\n                    'url': encode_data_uri(m3u8_data, 'application/vnd.apple.mpegurl'),\n                    'ext': determine_ext(dispatch[format_id][1]),\n                    'format_id': format_id,\n                    'protocol': 'm3u8',\n                }\n\n                if format_id[-1:] == 'p':\n                    url_info_dict['height'] = int_or_none(format_id[:-1])\n\n                urls.append(url_info_dict)\n\n        publish_time = parse_iso8601(self._html_search_regex(\n            r'\u53d1\u5e03\u65f6\u95f4&nbsp;([^<>]+) ', page, 'publish time', default=None),\n            delimiter=' ', timezone=datetime.timedelta(hours=8))\n        description = self._html_search_meta('description', page, fatal=False)\n\n        return {\n            'id': media_id,\n            'formats': urls,\n            'title': playurl['title'],\n            'thumbnail': playurl['pic'],\n            'description': description,\n            'timestamp': publish_time,\n        }",
        "begin_line": 106,
        "end_line": 188,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.letv.LetvTvIE._real_extract#203",
        "src_path": "youtube_dl/extractor/letv.py",
        "class_name": "youtube_dl.extractor.letv.LetvTvIE",
        "signature": "youtube_dl.extractor.letv.LetvTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        page = self._download_webpage(url, playlist_id)\n\n        media_urls = list(set(re.findall(\n            r'http://www.letv.com/ptv/vplay/\\d+.html', page)))\n        entries = [self.url_result(media_url, ie='Letv')\n                   for media_url in media_urls]\n\n        title = self._html_search_meta('keywords', page,\n                                       fatal=False).split('\uff0c')[0]\n        description = self._html_search_meta('description', page, fatal=False)\n\n        return self.playlist_result(entries, playlist_id, playlist_title=title,\n                                    playlist_description=description)",
        "begin_line": 203,
        "end_line": 217,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.__init__#251",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        \"\"\"Constructor. Receives an optional downloader.\"\"\"\n        self._ready = False\n        self.set_downloader(downloader)",
        "begin_line": 251,
        "end_line": 254,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003787878787878788,
            "pseudo_dstar_susp": 0.008064516129032258,
            "pseudo_tarantula_susp": 0.0010141987829614604,
            "pseudo_op2_susp": 0.008064516129032258,
            "pseudo_barinel_susp": 0.0010141987829614604
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.suitable#257",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        \"\"\"Receives a URL and returns True if suitable for this IE.\"\"\"\n\n        # This does not use has/getattr intentionally - we want to know whether\n        # we have cached the regexp for *this* class, whereas getattr would also\n        # match the superclass\n        if '_VALID_URL_RE' not in cls.__dict__:\n            cls._VALID_URL_RE = re.compile(cls._VALID_URL)\n        return cls._VALID_URL_RE.match(url) is not None",
        "begin_line": 257,
        "end_line": 265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005917159763313609,
            "pseudo_dstar_susp": 0.00558659217877095,
            "pseudo_tarantula_susp": 0.0011682242990654205,
            "pseudo_op2_susp": 0.00558659217877095,
            "pseudo_barinel_susp": 0.0011682242990654205
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._match_id#268",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._match_id(cls, url)",
        "snippet": "    def _match_id(cls, url):\n        if '_VALID_URL_RE' not in cls.__dict__:\n            cls._VALID_URL_RE = re.compile(cls._VALID_URL)\n        m = cls._VALID_URL_RE.match(url)\n        assert m\n        return m.group('id')",
        "begin_line": 268,
        "end_line": 273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027548209366391185,
            "pseudo_dstar_susp": 0.002570694087403599,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.002570694087403599,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.working#276",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.working(cls)",
        "snippet": "    def working(cls):\n        \"\"\"Getter method for _WORKING.\"\"\"\n        return cls._WORKING",
        "begin_line": 276,
        "end_line": 278,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.017241379310344827,
            "pseudo_dstar_susp": 0.006756756756756757,
            "pseudo_tarantula_susp": 0.001644736842105263,
            "pseudo_op2_susp": 0.006756756756756757,
            "pseudo_barinel_susp": 0.001644736842105263
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.initialize#280",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.initialize(self)",
        "snippet": "    def initialize(self):\n        \"\"\"Initializes an instance (authentication, etc).\"\"\"\n        if not self._ready:\n            self._real_initialize()\n            self._ready = True",
        "begin_line": 280,
        "end_line": 284,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.037037037037037035,
            "pseudo_dstar_susp": 0.038461538461538464,
            "pseudo_tarantula_susp": 0.0015432098765432098,
            "pseudo_op2_susp": 0.038461538461538464,
            "pseudo_barinel_susp": 0.0015432098765432098
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract#286",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract(self, url)",
        "snippet": "    def extract(self, url):\n        \"\"\"Extracts URL information and returns it in list of dicts.\"\"\"\n        try:\n            self.initialize()\n            return self._real_extract(url)\n        except ExtractorError:\n            raise\n        except compat_http_client.IncompleteRead as e:\n            raise ExtractorError('A network error has occured.', cause=e, expected=True)\n        except (KeyError, StopIteration) as e:\n            raise ExtractorError('An extractor error has occured.', cause=e)",
        "begin_line": 286,
        "end_line": 296,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.038461538461538464,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.038461538461538464,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.set_downloader#298",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.set_downloader(self, downloader)",
        "snippet": "    def set_downloader(self, downloader):\n        \"\"\"Sets the downloader for this IE.\"\"\"\n        self._downloader = downloader",
        "begin_line": 298,
        "end_line": 300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003787878787878788,
            "pseudo_dstar_susp": 0.008064516129032258,
            "pseudo_tarantula_susp": 0.0010141987829614604,
            "pseudo_op2_susp": 0.008064516129032258,
            "pseudo_barinel_susp": 0.0010141987829614604
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._real_initialize#302",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        \"\"\"Real initialization process. Redefine in subclasses.\"\"\"\n        pass",
        "begin_line": 302,
        "end_line": 304,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003937007874015748,
            "pseudo_dstar_susp": 0.003745318352059925,
            "pseudo_tarantula_susp": 0.0014684287812041115,
            "pseudo_op2_susp": 0.003745318352059925,
            "pseudo_barinel_susp": 0.0014684287812041115
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._real_extract#306",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        \"\"\"Real extraction process. Redefine in subclasses.\"\"\"\n        pass",
        "begin_line": 306,
        "end_line": 308,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.ie_key#311",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.ie_key(cls)",
        "snippet": "    def ie_key(cls):\n        \"\"\"A string for getting the InfoExtractor with get_info_extractor\"\"\"\n        return compat_str(cls.__name__[:-2])",
        "begin_line": 311,
        "end_line": 313,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006493506493506494,
            "pseudo_dstar_susp": 0.005714285714285714,
            "pseudo_tarantula_susp": 0.0013280212483399733,
            "pseudo_op2_susp": 0.005714285714285714,
            "pseudo_barinel_susp": 0.0013280212483399733
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.IE_NAME#316",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.IE_NAME(self)",
        "snippet": "    def IE_NAME(self):\n        return compat_str(type(self).__name__[:-2])",
        "begin_line": 316,
        "end_line": 317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002881844380403458,
            "pseudo_dstar_susp": 0.003484320557491289,
            "pseudo_tarantula_susp": 0.0011737089201877935,
            "pseudo_op2_susp": 0.003484320557491289,
            "pseudo_barinel_susp": 0.0011737089201877935
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._request_webpage#319",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True)",
        "snippet": "    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True):\n        \"\"\" Returns the response handle \"\"\"\n        if note is None:\n            self.report_download_webpage(video_id)\n        elif note is not False:\n            if video_id is None:\n                self.to_screen('%s' % (note,))\n            else:\n                self.to_screen('%s: %s' % (video_id, note))\n        try:\n            return self._downloader.urlopen(url_or_request)\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            if errnote is False:\n                return False\n            if errnote is None:\n                errnote = 'Unable to download webpage'\n            errmsg = '%s: %s' % (errnote, compat_str(err))\n            if fatal:\n                raise ExtractorError(errmsg, sys.exc_info()[2], cause=err)\n            else:\n                self._downloader.report_warning(errmsg)\n                return False",
        "begin_line": 319,
        "end_line": 340,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.09090909090909091,
            "pseudo_dstar_susp": 0.09090909090909091,
            "pseudo_tarantula_susp": 0.001718213058419244,
            "pseudo_op2_susp": 0.09090909090909091,
            "pseudo_barinel_susp": 0.001718213058419244
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_webpage_handle#342",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None)",
        "snippet": "    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None):\n        \"\"\" Returns a tuple (page content as string, URL handle) \"\"\"\n        # Strip hashes from the URL (#1038)\n        if isinstance(url_or_request, (compat_str, str)):\n            url_or_request = url_or_request.partition('#')[0]\n\n        urlh = self._request_webpage(url_or_request, video_id, note, errnote, fatal)\n        if urlh is False:\n            assert not fatal\n            return False\n        content = self._webpage_read_content(urlh, url_or_request, video_id, note, errnote, fatal, encoding=encoding)\n        return (content, urlh)",
        "begin_line": 342,
        "end_line": 353,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.2,
            "pseudo_dstar_susp": 0.2,
            "pseudo_tarantula_susp": 0.0018083182640144665,
            "pseudo_op2_susp": 0.2,
            "pseudo_barinel_susp": 0.0018083182640144665
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._guess_encoding_from_content#356",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._guess_encoding_from_content(content_type, webpage_bytes)",
        "snippet": "    def _guess_encoding_from_content(content_type, webpage_bytes):\n        m = re.match(r'[a-zA-Z0-9_.-]+/[a-zA-Z0-9_.-]+\\s*;\\s*charset=(.+)', content_type)\n        if m:\n            encoding = m.group(1)\n        else:\n            m = re.search(br'<meta[^>]+charset=[\\'\"]?([^\\'\")]+)[ /\\'\">]',\n                          webpage_bytes[:1024])\n            if m:\n                encoding = m.group(1).decode('ascii')\n            elif webpage_bytes.startswith(b'\\xff\\xfe'):\n                encoding = 'utf-16'\n            else:\n                encoding = 'utf-8'\n\n        return encoding",
        "begin_line": 356,
        "end_line": 370,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006993006993006993,
            "pseudo_dstar_susp": 0.00423728813559322,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.00423728813559322,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._webpage_read_content#372",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True, prefix=None, encoding=None)",
        "snippet": "    def _webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True, prefix=None, encoding=None):\n        content_type = urlh.headers.get('Content-Type', '')\n        webpage_bytes = urlh.read()\n        if prefix is not None:\n            webpage_bytes = prefix + webpage_bytes\n        if not encoding:\n            encoding = self._guess_encoding_from_content(content_type, webpage_bytes)\n        if self._downloader.params.get('dump_intermediate_pages', False):\n            try:\n                url = url_or_request.get_full_url()\n            except AttributeError:\n                url = url_or_request\n            self.to_screen('Dumping request to ' + url)\n            dump = base64.b64encode(webpage_bytes).decode('ascii')\n            self._downloader.to_screen(dump)\n        if self._downloader.params.get('write_pages', False):\n            try:\n                url = url_or_request.get_full_url()\n            except AttributeError:\n                url = url_or_request\n            basen = '%s_%s' % (video_id, url)\n            if len(basen) > 240:\n                h = '___' + hashlib.md5(basen.encode('utf-8')).hexdigest()\n                basen = basen[:240 - len(h)] + h\n            raw_filename = basen + '.dump'\n            filename = sanitize_filename(raw_filename, restricted=True)\n            self.to_screen('Saving request to ' + filename)\n            # Working around MAX_PATH limitation on Windows (see\n            # http://msdn.microsoft.com/en-us/library/windows/desktop/aa365247(v=vs.85).aspx)\n            if os.name == 'nt':\n                absfilepath = os.path.abspath(filename)\n                if len(absfilepath) > 259:\n                    filename = '\\\\\\\\?\\\\' + absfilepath\n            with open(filename, 'wb') as outf:\n                outf.write(webpage_bytes)\n\n        try:\n            content = webpage_bytes.decode(encoding, 'replace')\n        except LookupError:\n            content = webpage_bytes.decode('utf-8', 'replace')\n\n        if ('<title>Access to this site is blocked</title>' in content and\n                'Websense' in content[:512]):\n            msg = 'Access to this webpage has been blocked by Websense filtering software in your network.'\n            blocked_iframe = self._html_search_regex(\n                r'<iframe src=\"([^\"]+)\"', content,\n                'Websense information URL', default=None)\n            if blocked_iframe:\n                msg += ' Visit %s for more details' % blocked_iframe\n            raise ExtractorError(msg, expected=True)\n        if '<title>The URL you requested has been blocked</title>' in content[:512]:\n            msg = (\n                'Access to this webpage has been blocked by Indian censorship. '\n                'Use a VPN or proxy server (with --proxy) to route around it.')\n            block_msg = self._html_search_regex(\n                r'</h1><p>(.*?)</p>',\n                content, 'block message', default=None)\n            if block_msg:\n                msg += ' (Message: \"%s\")' % block_msg.replace('\\n', ' ')\n            raise ExtractorError(msg, expected=True)\n\n        return content",
        "begin_line": 372,
        "end_line": 433,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006993006993006993,
            "pseudo_dstar_susp": 0.00423728813559322,
            "pseudo_tarantula_susp": 0.001607717041800643,
            "pseudo_op2_susp": 0.00423728813559322,
            "pseudo_barinel_susp": 0.001607717041800643
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_webpage#435",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None)",
        "snippet": "    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None):\n        \"\"\" Returns the data of the page as a string \"\"\"\n        success = False\n        try_count = 0\n        while success is False:\n            try:\n                res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal, encoding=encoding)\n                success = True\n            except compat_http_client.IncompleteRead as e:\n                try_count += 1\n                if try_count >= tries:\n                    raise e\n                self._sleep(timeout, video_id)\n        if res is False:\n            return res\n        else:\n            content, _ = res\n            return content",
        "begin_line": 435,
        "end_line": 452,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.2,
            "pseudo_dstar_susp": 0.2,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.2,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_xml#454",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_xml(self, url_or_request, video_id, note='Downloading XML', errnote='Unable to download XML', transform_source=None, fatal=True, encoding=None)",
        "snippet": "    def _download_xml(self, url_or_request, video_id,\n                      note='Downloading XML', errnote='Unable to download XML',\n                      transform_source=None, fatal=True, encoding=None):\n        \"\"\"Return the xml as an xml.etree.ElementTree.Element\"\"\"\n        xml_string = self._download_webpage(\n            url_or_request, video_id, note, errnote, fatal=fatal, encoding=encoding)\n        if xml_string is False:\n            return xml_string\n        if transform_source:\n            xml_string = transform_source(xml_string)\n        return compat_etree_fromstring(xml_string.encode('utf-8'))",
        "begin_line": 454,
        "end_line": 464,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002061855670103093,
            "pseudo_dstar_susp": 0.002028397565922921,
            "pseudo_tarantula_susp": 0.0013003901170351106,
            "pseudo_op2_susp": 0.002028397565922921,
            "pseudo_barinel_susp": 0.0013003901170351106
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_json#466",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_json(self, url_or_request, video_id, note='Downloading JSON metadata', errnote='Unable to download JSON metadata', transform_source=None, fatal=True, encoding=None)",
        "snippet": "    def _download_json(self, url_or_request, video_id,\n                       note='Downloading JSON metadata',\n                       errnote='Unable to download JSON metadata',\n                       transform_source=None,\n                       fatal=True, encoding=None):\n        json_string = self._download_webpage(\n            url_or_request, video_id, note, errnote, fatal=fatal,\n            encoding=encoding)\n        if (not fatal) and json_string is False:\n            return None\n        return self._parse_json(\n            json_string, video_id, transform_source=transform_source, fatal=fatal)",
        "begin_line": 466,
        "end_line": 477,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026041666666666665,
            "pseudo_dstar_susp": 0.0025380710659898475,
            "pseudo_tarantula_susp": 0.0014285714285714286,
            "pseudo_op2_susp": 0.0025380710659898475,
            "pseudo_barinel_susp": 0.0014285714285714286
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_json#479",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_json(self, json_string, video_id, transform_source=None, fatal=True)",
        "snippet": "    def _parse_json(self, json_string, video_id, transform_source=None, fatal=True):\n        if transform_source:\n            json_string = transform_source(json_string)\n        try:\n            return json.loads(json_string)\n        except ValueError as ve:\n            errmsg = '%s: Failed to parse JSON ' % video_id\n            if fatal:\n                raise ExtractorError(errmsg, cause=ve)\n            else:\n                self.report_warning(errmsg + str(ve))",
        "begin_line": 479,
        "end_line": 489,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026041666666666665,
            "pseudo_dstar_susp": 0.0025380710659898475,
            "pseudo_tarantula_susp": 0.0014285714285714286,
            "pseudo_op2_susp": 0.0025380710659898475,
            "pseudo_barinel_susp": 0.0014285714285714286
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_warning#491",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_warning(self, msg, video_id=None)",
        "snippet": "    def report_warning(self, msg, video_id=None):\n        idstr = '' if video_id is None else '%s: ' % video_id\n        self._downloader.report_warning(\n            '[%s] %s%s' % (self.IE_NAME, idstr, msg))",
        "begin_line": 491,
        "end_line": 494,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.to_screen#496",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.to_screen(self, msg)",
        "snippet": "    def to_screen(self, msg):\n        \"\"\"Print msg to screen, prefixing it with '[ie_name]'\"\"\"\n        self._downloader.to_screen('[%s] %s' % (self.IE_NAME, msg))",
        "begin_line": 496,
        "end_line": 498,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.037037037037037035,
            "pseudo_dstar_susp": 0.038461538461538464,
            "pseudo_tarantula_susp": 0.0015432098765432098,
            "pseudo_op2_susp": 0.038461538461538464,
            "pseudo_barinel_susp": 0.0015432098765432098
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_extraction#500",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_extraction(self, id_or_name)",
        "snippet": "    def report_extraction(self, id_or_name):\n        \"\"\"Report information extraction.\"\"\"\n        self.to_screen('%s: Extracting information' % id_or_name)",
        "begin_line": 500,
        "end_line": 502,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002061855670103093,
            "pseudo_dstar_susp": 0.002028397565922921,
            "pseudo_tarantula_susp": 0.0013003901170351106,
            "pseudo_op2_susp": 0.002028397565922921,
            "pseudo_barinel_susp": 0.0013003901170351106
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_download_webpage#504",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_download_webpage(self, video_id)",
        "snippet": "    def report_download_webpage(self, video_id):\n        \"\"\"Report webpage download.\"\"\"\n        self.to_screen('%s: Downloading webpage' % video_id)",
        "begin_line": 504,
        "end_line": 506,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006578947368421052,
            "pseudo_dstar_susp": 0.004048582995951417,
            "pseudo_tarantula_susp": 0.001718213058419244,
            "pseudo_op2_susp": 0.004048582995951417,
            "pseudo_barinel_susp": 0.001718213058419244
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_age_confirmation#508",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_age_confirmation(self)",
        "snippet": "    def report_age_confirmation(self):\n        \"\"\"Report attempt to confirm age.\"\"\"\n        self.to_screen('Confirming age')",
        "begin_line": 508,
        "end_line": 510,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_login#512",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_login(self)",
        "snippet": "    def report_login(self):\n        \"\"\"Report attempt to log in.\"\"\"\n        self.to_screen('Logging in')",
        "begin_line": 512,
        "end_line": 514,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.raise_login_required#517",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.raise_login_required(msg='This video is only available for registered users')",
        "snippet": "    def raise_login_required(msg='This video is only available for registered users'):\n        raise ExtractorError(\n            '%s. Use --username and --password or --netrc to provide account credentials.' % msg,\n            expected=True)",
        "begin_line": 517,
        "end_line": 520,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.raise_geo_restricted#523",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.raise_geo_restricted(msg='This video is not available from your location due to geo restriction')",
        "snippet": "    def raise_geo_restricted(msg='This video is not available from your location due to geo restriction'):\n        raise ExtractorError(\n            '%s. You might want to use --proxy to workaround.' % msg,\n            expected=True)",
        "begin_line": 523,
        "end_line": 526,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.url_result#530",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.url_result(url, ie=None, video_id=None, video_title=None)",
        "snippet": "    def url_result(url, ie=None, video_id=None, video_title=None):\n        \"\"\"Returns a URL that points to a page that should be processed\"\"\"\n        # TODO: ie should be the class used for getting the info\n        video_info = {'_type': 'url',\n                      'url': url,\n                      'ie_key': ie}\n        if video_id is not None:\n            video_info['id'] = video_id\n        if video_title is not None:\n            video_info['title'] = video_title\n        return video_info",
        "begin_line": 530,
        "end_line": 540,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.playlist_result#543",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.playlist_result(entries, playlist_id=None, playlist_title=None, playlist_description=None)",
        "snippet": "    def playlist_result(entries, playlist_id=None, playlist_title=None, playlist_description=None):\n        \"\"\"Returns a playlist\"\"\"\n        video_info = {'_type': 'playlist',\n                      'entries': entries}\n        if playlist_id:\n            video_info['id'] = playlist_id\n        if playlist_title:\n            video_info['title'] = playlist_title\n        if playlist_description:\n            video_info['description'] = playlist_description\n        return video_info",
        "begin_line": 543,
        "end_line": 553,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._search_regex#555",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None)",
        "snippet": "    def _search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None):\n        \"\"\"\n        Perform a regex search on the given string, using a single or a list of\n        patterns returning the first matching group.\n        In case of failure return a default value or raise a WARNING or a\n        RegexNotFoundError, depending on fatal, specifying the field name.\n        \"\"\"\n        if isinstance(pattern, (str, compat_str, compiled_regex_type)):\n            mobj = re.search(pattern, string, flags)\n        else:\n            for p in pattern:\n                mobj = re.search(p, string, flags)\n                if mobj:\n                    break\n\n        if not self._downloader.params.get('no_color') and os.name != 'nt' and sys.stderr.isatty():\n            _name = '\\033[0;34m%s\\033[0m' % name\n        else:\n            _name = name\n\n        if mobj:\n            if group is None:\n                # return the first matching group\n                return next(g for g in mobj.groups() if g is not None)\n            else:\n                return mobj.group(group)\n        elif default is not NO_DEFAULT:\n            return default\n        elif fatal:\n            raise RegexNotFoundError('Unable to extract %s' % _name)\n        else:\n            self._downloader.report_warning('unable to extract %s' % _name + bug_reports_message())\n            return None",
        "begin_line": 555,
        "end_line": 587,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003484320557491289,
            "pseudo_dstar_susp": 0.003703703703703704,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.003703703703703704,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._html_search_regex#589",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._html_search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None)",
        "snippet": "    def _html_search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None):\n        \"\"\"\n        Like _search_regex, but strips HTML tags and unescapes entities.\n        \"\"\"\n        res = self._search_regex(pattern, string, name, default, fatal, flags, group)\n        if res:\n            return clean_html(res).strip()\n        else:\n            return res",
        "begin_line": 589,
        "end_line": 597,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0028735632183908046,
            "pseudo_dstar_susp": 0.0033333333333333335,
            "pseudo_tarantula_susp": 0.0013003901170351106,
            "pseudo_op2_susp": 0.0033333333333333335,
            "pseudo_barinel_susp": 0.0013003901170351106
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_login_info#599",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_login_info(self)",
        "snippet": "    def _get_login_info(self):\n        \"\"\"\n        Get the login info as (username, password)\n        It will look in the netrc file using the _NETRC_MACHINE value\n        If there's no info available, return (None, None)\n        \"\"\"\n        if self._downloader is None:\n            return (None, None)\n\n        username = None\n        password = None\n        downloader_params = self._downloader.params\n\n        # Attempt to use provided username and password or .netrc data\n        if downloader_params.get('username', None) is not None:\n            username = downloader_params['username']\n            password = downloader_params['password']\n        elif downloader_params.get('usenetrc', False):\n            try:\n                info = netrc.netrc().authenticators(self._NETRC_MACHINE)\n                if info is not None:\n                    username = info[0]\n                    password = info[2]\n                else:\n                    raise netrc.NetrcParseError('No authenticators for %s' % self._NETRC_MACHINE)\n            except (IOError, netrc.NetrcParseError) as err:\n                self._downloader.report_warning('parsing .netrc: %s' % compat_str(err))\n\n        return (username, password)",
        "begin_line": 599,
        "end_line": 627,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005235602094240838,
            "pseudo_dstar_susp": 0.003861003861003861,
            "pseudo_tarantula_susp": 0.0016835016835016834,
            "pseudo_op2_susp": 0.003861003861003861,
            "pseudo_barinel_susp": 0.0016835016835016834
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_tfa_info#629",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_tfa_info(self, note='two-factor verification code')",
        "snippet": "    def _get_tfa_info(self, note='two-factor verification code'):\n        \"\"\"\n        Get the two-factor authentication info\n        TODO - asking the user will be required for sms/phone verify\n        currently just uses the command line option\n        If there's no info available, return None\n        \"\"\"\n        if self._downloader is None:\n            return None\n        downloader_params = self._downloader.params\n\n        if downloader_params.get('twofactor', None) is not None:\n            return downloader_params['twofactor']\n\n        return compat_getpass('Type %s and press [Return]: ' % note)",
        "begin_line": 629,
        "end_line": 643,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_regexes#647",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_regexes(prop)",
        "snippet": "    def _og_regexes(prop):\n        content_re = r'content=(?:\"([^\"]+?)\"|\\'([^\\']+?)\\'|\\s*([^\\s\"\\'=<>`]+?))'\n        property_re = (r'(?:name|property)=(?:\\'og:%(prop)s\\'|\"og:%(prop)s\"|\\s*og:%(prop)s\\b)'\n                       % {'prop': re.escape(prop)})\n        template = r'<meta[^>]+?%s[^>]+?%s'\n        return [\n            template % (property_re, content_re),\n            template % (content_re, property_re),\n        ]",
        "begin_line": 647,
        "end_line": 655,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001445086705202312,
            "pseudo_dstar_susp": 0.00141643059490085,
            "pseudo_tarantula_susp": 0.001226993865030675,
            "pseudo_op2_susp": 0.00141643059490085,
            "pseudo_barinel_susp": 0.0012254901960784314
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._meta_regex#658",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._meta_regex(prop)",
        "snippet": "    def _meta_regex(prop):\n        return r'''(?isx)<meta\n                    (?=[^>]+(?:itemprop|name|property|id|http-equiv)=([\"\\']?)%s\\1)\n                    [^>]+?content=([\"\\'])(?P<content>.*?)\\2''' % re.escape(prop)",
        "begin_line": 658,
        "end_line": 661,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002061855670103093,
            "pseudo_dstar_susp": 0.002028397565922921,
            "pseudo_tarantula_susp": 0.0013003901170351106,
            "pseudo_op2_susp": 0.002028397565922921,
            "pseudo_barinel_susp": 0.0013003901170351106
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_property#663",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_property(self, prop, html, name=None, **kargs)",
        "snippet": "    def _og_search_property(self, prop, html, name=None, **kargs):\n        if name is None:\n            name = 'OpenGraph %s' % prop\n        escaped = self._search_regex(self._og_regexes(prop), html, name, flags=re.DOTALL, **kargs)\n        if escaped is None:\n            return None\n        return unescapeHTML(escaped)",
        "begin_line": 663,
        "end_line": 669,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001445086705202312,
            "pseudo_dstar_susp": 0.00141643059490085,
            "pseudo_tarantula_susp": 0.001226993865030675,
            "pseudo_op2_susp": 0.00141643059490085,
            "pseudo_barinel_susp": 0.0012254901960784314
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_thumbnail#671",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_thumbnail(self, html, **kargs)",
        "snippet": "    def _og_search_thumbnail(self, html, **kargs):\n        return self._og_search_property('image', html, 'thumbnail URL', fatal=False, **kargs)",
        "begin_line": 671,
        "end_line": 672,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_description#674",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_description(self, html, **kargs)",
        "snippet": "    def _og_search_description(self, html, **kargs):\n        return self._og_search_property('description', html, fatal=False, **kargs)",
        "begin_line": 674,
        "end_line": 675,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001445086705202312,
            "pseudo_dstar_susp": 0.00141643059490085,
            "pseudo_tarantula_susp": 0.001226993865030675,
            "pseudo_op2_susp": 0.00141643059490085,
            "pseudo_barinel_susp": 0.0012254901960784314
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_title#677",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_title(self, html, **kargs)",
        "snippet": "    def _og_search_title(self, html, **kargs):\n        return self._og_search_property('title', html, **kargs)",
        "begin_line": 677,
        "end_line": 678,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_video_url#680",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_video_url(self, html, name='video url', secure=True, **kargs)",
        "snippet": "    def _og_search_video_url(self, html, name='video url', secure=True, **kargs):\n        regexes = self._og_regexes('video') + self._og_regexes('video:url')\n        if secure:\n            regexes = self._og_regexes('video:secure_url') + regexes\n        return self._html_search_regex(regexes, html, name, **kargs)",
        "begin_line": 680,
        "end_line": 684,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_url#686",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_url(self, html, **kargs)",
        "snippet": "    def _og_search_url(self, html, **kargs):\n        return self._og_search_property('url', html, **kargs)",
        "begin_line": 686,
        "end_line": 687,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._html_search_meta#689",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._html_search_meta(self, name, html, display_name=None, fatal=False, **kwargs)",
        "snippet": "    def _html_search_meta(self, name, html, display_name=None, fatal=False, **kwargs):\n        if display_name is None:\n            display_name = name\n        return self._html_search_regex(\n            self._meta_regex(name),\n            html, display_name, fatal=fatal, group='content', **kwargs)",
        "begin_line": 689,
        "end_line": 694,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002061855670103093,
            "pseudo_dstar_susp": 0.002028397565922921,
            "pseudo_tarantula_susp": 0.0013003901170351106,
            "pseudo_op2_susp": 0.002028397565922921,
            "pseudo_barinel_susp": 0.0013003901170351106
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._dc_search_uploader#696",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._dc_search_uploader(self, html)",
        "snippet": "    def _dc_search_uploader(self, html):\n        return self._html_search_meta('dc.creator', html, 'uploader')",
        "begin_line": 696,
        "end_line": 697,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._rta_search#699",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._rta_search(self, html)",
        "snippet": "    def _rta_search(self, html):\n        # See http://www.rtalabel.org/index.php?content=howtofaq#single\n        if re.search(r'(?ix)<meta\\s+name=\"rating\"\\s+'\n                     r'     content=\"RTA-5042-1996-1400-1577-RTA\"',\n                     html):\n            return 18\n        return 0",
        "begin_line": 699,
        "end_line": 705,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001445086705202312,
            "pseudo_dstar_susp": 0.00141643059490085,
            "pseudo_tarantula_susp": 0.001226993865030675,
            "pseudo_op2_susp": 0.00141643059490085,
            "pseudo_barinel_susp": 0.0012254901960784314
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._media_rating_search#707",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._media_rating_search(self, html)",
        "snippet": "    def _media_rating_search(self, html):\n        # See http://www.tjg-designs.com/WP/metadata-code-examples-adding-metadata-to-your-web-pages/\n        rating = self._html_search_meta('rating', html)\n\n        if not rating:\n            return None\n\n        RATING_TABLE = {\n            'safe for kids': 0,\n            'general': 8,\n            '14 years': 14,\n            'mature': 17,\n            'restricted': 19,\n        }\n        return RATING_TABLE.get(rating.lower(), None)",
        "begin_line": 707,
        "end_line": 721,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._family_friendly_search#723",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._family_friendly_search(self, html)",
        "snippet": "    def _family_friendly_search(self, html):\n        # See http://schema.org/VideoObject\n        family_friendly = self._html_search_meta('isFamilyFriendly', html)\n\n        if not family_friendly:\n            return None\n\n        RATING_TABLE = {\n            '1': 0,\n            'true': 0,\n            '0': 18,\n            'false': 18,\n        }\n        return RATING_TABLE.get(family_friendly.lower(), None)",
        "begin_line": 723,
        "end_line": 736,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._twitter_search_player#738",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._twitter_search_player(self, html)",
        "snippet": "    def _twitter_search_player(self, html):\n        return self._html_search_meta('twitter:player', html,\n                                      'twitter card player')",
        "begin_line": 738,
        "end_line": 740,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._hidden_inputs#743",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._hidden_inputs(html)",
        "snippet": "    def _hidden_inputs(html):\n        html = re.sub(r'<!--(?:(?!<!--).)*-->', '', html)\n        hidden_inputs = {}\n        for input in re.findall(r'(?i)<input([^>]+)>', html):\n            if not re.search(r'type=([\"\\'])(?:hidden|submit)\\1', input):\n                continue\n            name = re.search(r'name=([\"\\'])(?P<value>.+?)\\1', input)\n            if not name:\n                continue\n            value = re.search(r'value=([\"\\'])(?P<value>.*?)\\1', input)\n            if not value:\n                continue\n            hidden_inputs[name.group('value')] = value.group('value')\n        return hidden_inputs",
        "begin_line": 743,
        "end_line": 756,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._form_hidden_inputs#758",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._form_hidden_inputs(self, form_id, html)",
        "snippet": "    def _form_hidden_inputs(self, form_id, html):\n        form = self._search_regex(\n            r'(?is)<form[^>]+?id=([\"\\'])%s\\1[^>]*>(?P<form>.+?)</form>' % form_id,\n            html, '%s form' % form_id, group='form')\n        return self._hidden_inputs(form)",
        "begin_line": 758,
        "end_line": 762,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._sort_formats#764",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._sort_formats(self, formats, field_preference=None)",
        "snippet": "    def _sort_formats(self, formats, field_preference=None):\n        if not formats:\n            raise ExtractorError('No video formats found')\n\n        def _formats_key(f):\n            # TODO remove the following workaround\n            from ..utils import determine_ext\n            if not f.get('ext') and 'url' in f:\n                f['ext'] = determine_ext(f['url'])\n\n            if isinstance(field_preference, (list, tuple)):\n                return tuple(f.get(field) if f.get(field) is not None else -1 for field in field_preference)\n\n            preference = f.get('preference')\n            if preference is None:\n                proto = f.get('protocol')\n                if proto is None:\n                    proto = compat_urllib_parse_urlparse(f.get('url', '')).scheme\n\n                preference = 0 if proto in ['http', 'https'] else -0.1\n                if f.get('ext') in ['f4f', 'f4m']:  # Not yet supported\n                    preference -= 0.5\n\n            if f.get('vcodec') == 'none':  # audio only\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['aac', 'mp3', 'm4a', 'webm', 'ogg', 'opus']\n                else:\n                    ORDER = ['webm', 'opus', 'ogg', 'mp3', 'aac', 'm4a']\n                ext_preference = 0\n                try:\n                    audio_ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    audio_ext_preference = -1\n            else:\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['flv', 'mp4', 'webm']\n                else:\n                    ORDER = ['webm', 'flv', 'mp4']\n                try:\n                    ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    ext_preference = -1\n                audio_ext_preference = 0\n\n            return (\n                preference,\n                f.get('language_preference') if f.get('language_preference') is not None else -1,\n                f.get('quality') if f.get('quality') is not None else -1,\n                f.get('tbr') if f.get('tbr') is not None else -1,\n                f.get('filesize') if f.get('filesize') is not None else -1,\n                f.get('vbr') if f.get('vbr') is not None else -1,\n                f.get('height') if f.get('height') is not None else -1,\n                f.get('width') if f.get('width') is not None else -1,\n                ext_preference,\n                f.get('abr') if f.get('abr') is not None else -1,\n                audio_ext_preference,\n                f.get('fps') if f.get('fps') is not None else -1,\n                f.get('filesize_approx') if f.get('filesize_approx') is not None else -1,\n                f.get('source_preference') if f.get('source_preference') is not None else -1,\n                f.get('format_id') if f.get('format_id') is not None else '',\n            )\n        formats.sort(key=_formats_key)",
        "begin_line": 764,
        "end_line": 825,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0022675736961451248,
            "pseudo_dstar_susp": 0.002207505518763797,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.002207505518763797,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._formats_key#768",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._formats_key(f)",
        "snippet": "        def _formats_key(f):\n            # TODO remove the following workaround\n            from ..utils import determine_ext\n            if not f.get('ext') and 'url' in f:\n                f['ext'] = determine_ext(f['url'])\n\n            if isinstance(field_preference, (list, tuple)):\n                return tuple(f.get(field) if f.get(field) is not None else -1 for field in field_preference)\n\n            preference = f.get('preference')\n            if preference is None:\n                proto = f.get('protocol')\n                if proto is None:\n                    proto = compat_urllib_parse_urlparse(f.get('url', '')).scheme\n\n                preference = 0 if proto in ['http', 'https'] else -0.1\n                if f.get('ext') in ['f4f', 'f4m']:  # Not yet supported\n                    preference -= 0.5\n\n            if f.get('vcodec') == 'none':  # audio only\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['aac', 'mp3', 'm4a', 'webm', 'ogg', 'opus']\n                else:\n                    ORDER = ['webm', 'opus', 'ogg', 'mp3', 'aac', 'm4a']\n                ext_preference = 0\n                try:\n                    audio_ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    audio_ext_preference = -1\n            else:\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['flv', 'mp4', 'webm']\n                else:\n                    ORDER = ['webm', 'flv', 'mp4']\n                try:\n                    ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    ext_preference = -1\n                audio_ext_preference = 0\n\n            return (\n                preference,\n                f.get('language_preference') if f.get('language_preference') is not None else -1,\n                f.get('quality') if f.get('quality') is not None else -1,\n                f.get('tbr') if f.get('tbr') is not None else -1,\n                f.get('filesize') if f.get('filesize') is not None else -1,\n                f.get('vbr') if f.get('vbr') is not None else -1,\n                f.get('height') if f.get('height') is not None else -1,\n                f.get('width') if f.get('width') is not None else -1,\n                ext_preference,\n                f.get('abr') if f.get('abr') is not None else -1,\n                audio_ext_preference,\n                f.get('fps') if f.get('fps') is not None else -1,\n                f.get('filesize_approx') if f.get('filesize_approx') is not None else -1,\n                f.get('source_preference') if f.get('source_preference') is not None else -1,\n                f.get('format_id') if f.get('format_id') is not None else '',\n            )",
        "begin_line": 768,
        "end_line": 824,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._check_formats#827",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._check_formats(self, formats, video_id)",
        "snippet": "    def _check_formats(self, formats, video_id):\n        if formats:\n            formats[:] = filter(\n                lambda f: self._is_valid_url(\n                    f['url'], video_id,\n                    item='%s video format' % f.get('format_id') if f.get('format_id') else 'video'),\n                formats)",
        "begin_line": 827,
        "end_line": 833,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._is_valid_url#835",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._is_valid_url(self, url, video_id, item='video')",
        "snippet": "    def _is_valid_url(self, url, video_id, item='video'):\n        url = self._proto_relative_url(url, scheme='http:')\n        # For now assume non HTTP(S) URLs always valid\n        if not (url.startswith('http://') or url.startswith('https://')):\n            return True\n        try:\n            self._request_webpage(url, video_id, 'Checking %s URL' % item)\n            return True\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_urllib_error.URLError):\n                self.to_screen(\n                    '%s: %s URL is invalid, skipping' % (video_id, item))\n                return False\n            raise",
        "begin_line": 835,
        "end_line": 848,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.http_scheme#850",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.http_scheme(self)",
        "snippet": "    def http_scheme(self):\n        \"\"\" Either \"http:\" or \"https:\", depending on the user's preferences \"\"\"\n        return (\n            'http:'\n            if self._downloader.params.get('prefer_insecure', False)\n            else 'https:')",
        "begin_line": 850,
        "end_line": 855,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._proto_relative_url#857",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._proto_relative_url(self, url, scheme=None)",
        "snippet": "    def _proto_relative_url(self, url, scheme=None):\n        if url is None:\n            return url\n        if url.startswith('//'):\n            if scheme is None:\n                scheme = self.http_scheme()\n            return scheme + url\n        else:\n            return url",
        "begin_line": 857,
        "end_line": 865,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._sleep#867",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._sleep(self, timeout, video_id, msg_template=None)",
        "snippet": "    def _sleep(self, timeout, video_id, msg_template=None):\n        if msg_template is None:\n            msg_template = '%(video_id)s: Waiting for %(timeout)s seconds'\n        msg = msg_template % {'video_id': video_id, 'timeout': timeout}\n        self.to_screen(msg)\n        time.sleep(timeout)",
        "begin_line": 867,
        "end_line": 872,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_f4m_formats#874",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_f4m_formats(self, manifest_url, video_id, preference=None, f4m_id=None, transform_source=lambda s: fix_xml_ampersands(s).strip(), fatal=True)",
        "snippet": "    def _extract_f4m_formats(self, manifest_url, video_id, preference=None, f4m_id=None,\n                             transform_source=lambda s: fix_xml_ampersands(s).strip(),\n                             fatal=True):\n        manifest = self._download_xml(\n            manifest_url, video_id, 'Downloading f4m manifest',\n            'Unable to download f4m manifest',\n            # Some manifests may be malformed, e.g. prosiebensat1 generated manifests\n            # (see https://github.com/rg3/youtube-dl/issues/6215#issuecomment-121704244)\n            transform_source=transform_source,\n            fatal=fatal)\n\n        if manifest is False:\n            return manifest\n\n        formats = []\n        manifest_version = '1.0'\n        media_nodes = manifest.findall('{http://ns.adobe.com/f4m/1.0}media')\n        if not media_nodes:\n            manifest_version = '2.0'\n            media_nodes = manifest.findall('{http://ns.adobe.com/f4m/2.0}media')\n        for i, media_el in enumerate(media_nodes):\n            if manifest_version == '2.0':\n                media_url = media_el.attrib.get('href') or media_el.attrib.get('url')\n                if not media_url:\n                    continue\n                manifest_url = (\n                    media_url if media_url.startswith('http://') or media_url.startswith('https://')\n                    else ('/'.join(manifest_url.split('/')[:-1]) + '/' + media_url))\n                # If media_url is itself a f4m manifest do the recursive extraction\n                # since bitrates in parent manifest (this one) and media_url manifest\n                # may differ leading to inability to resolve the format by requested\n                # bitrate in f4m downloader\n                if determine_ext(manifest_url) == 'f4m':\n                    f4m_formats = self._extract_f4m_formats(\n                        manifest_url, video_id, preference, f4m_id, fatal=fatal)\n                    if f4m_formats:\n                        formats.extend(f4m_formats)\n                    continue\n            tbr = int_or_none(media_el.attrib.get('bitrate'))\n            formats.append({\n                'format_id': '-'.join(filter(None, [f4m_id, compat_str(i if tbr is None else tbr)])),\n                'url': manifest_url,\n                'ext': 'flv',\n                'tbr': tbr,\n                'width': int_or_none(media_el.attrib.get('width')),\n                'height': int_or_none(media_el.attrib.get('height')),\n                'preference': preference,\n            })\n        self._sort_formats(formats)\n\n        return formats",
        "begin_line": 874,
        "end_line": 924,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_m3u8_formats#926",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_m3u8_formats(self, m3u8_url, video_id, ext=None, entry_protocol='m3u8', preference=None, m3u8_id=None, note=None, errnote=None, fatal=True)",
        "snippet": "    def _extract_m3u8_formats(self, m3u8_url, video_id, ext=None,\n                              entry_protocol='m3u8', preference=None,\n                              m3u8_id=None, note=None, errnote=None,\n                              fatal=True):\n\n        formats = [{\n            'format_id': '-'.join(filter(None, [m3u8_id, 'meta'])),\n            'url': m3u8_url,\n            'ext': ext,\n            'protocol': 'm3u8',\n            'preference': preference - 1 if preference else -1,\n            'resolution': 'multiple',\n            'format_note': 'Quality selection URL',\n        }]\n\n        format_url = lambda u: (\n            u\n            if re.match(r'^https?://', u)\n            else compat_urlparse.urljoin(m3u8_url, u))\n\n        res = self._download_webpage_handle(\n            m3u8_url, video_id,\n            note=note or 'Downloading m3u8 information',\n            errnote=errnote or 'Failed to download m3u8 information',\n            fatal=fatal)\n        if res is False:\n            return res\n        m3u8_doc, urlh = res\n        m3u8_url = urlh.geturl()\n        last_info = None\n        last_media = None\n        kv_rex = re.compile(\n            r'(?P<key>[a-zA-Z_-]+)=(?P<val>\"[^\"]+\"|[^\",]+)(?:,|$)')\n        for line in m3u8_doc.splitlines():\n            if line.startswith('#EXT-X-STREAM-INF:'):\n                last_info = {}\n                for m in kv_rex.finditer(line):\n                    v = m.group('val')\n                    if v.startswith('\"'):\n                        v = v[1:-1]\n                    last_info[m.group('key')] = v\n            elif line.startswith('#EXT-X-MEDIA:'):\n                last_media = {}\n                for m in kv_rex.finditer(line):\n                    v = m.group('val')\n                    if v.startswith('\"'):\n                        v = v[1:-1]\n                    last_media[m.group('key')] = v\n            elif line.startswith('#') or not line.strip():\n                continue\n            else:\n                if last_info is None:\n                    formats.append({'url': format_url(line)})\n                    continue\n                tbr = int_or_none(last_info.get('BANDWIDTH'), scale=1000)\n                format_id = []\n                if m3u8_id:\n                    format_id.append(m3u8_id)\n                last_media_name = last_media.get('NAME') if last_media and last_media.get('TYPE') != 'SUBTITLES' else None\n                format_id.append(last_media_name if last_media_name else '%d' % (tbr if tbr else len(formats)))\n                f = {\n                    'format_id': '-'.join(format_id),\n                    'url': format_url(line.strip()),\n                    'tbr': tbr,\n                    'ext': ext,\n                    'protocol': entry_protocol,\n                    'preference': preference,\n                }\n                codecs = last_info.get('CODECS')\n                if codecs:\n                    # TODO: looks like video codec is not always necessarily goes first\n                    va_codecs = codecs.split(',')\n                    if va_codecs[0]:\n                        f['vcodec'] = va_codecs[0].partition('.')[0]\n                    if len(va_codecs) > 1 and va_codecs[1]:\n                        f['acodec'] = va_codecs[1].partition('.')[0]\n                resolution = last_info.get('RESOLUTION')\n                if resolution:\n                    width_str, height_str = resolution.split('x')\n                    f['width'] = int(width_str)\n                    f['height'] = int(height_str)\n                if last_media is not None:\n                    f['m3u8_media'] = last_media\n                    last_media = None\n                formats.append(f)\n                last_info = {}\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 926,
        "end_line": 1013,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._xpath_ns#1016",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._xpath_ns(path, namespace=None)",
        "snippet": "    def _xpath_ns(path, namespace=None):\n        if not namespace:\n            return path\n        out = []\n        for c in path.split('/'):\n            if not c or c == '.':\n                out.append(c)\n            else:\n                out.append('{%s}%s' % (namespace, c))\n        return '/'.join(out)",
        "begin_line": 1016,
        "end_line": 1025,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_smil_formats#1027",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_smil_formats(self, smil_url, video_id, fatal=True, f4m_params=None)",
        "snippet": "    def _extract_smil_formats(self, smil_url, video_id, fatal=True, f4m_params=None):\n        smil = self._download_smil(smil_url, video_id, fatal=fatal)\n\n        if smil is False:\n            assert not fatal\n            return []\n\n        namespace = self._parse_smil_namespace(smil)\n\n        return self._parse_smil_formats(\n            smil, smil_url, video_id, namespace=namespace, f4m_params=f4m_params)",
        "begin_line": 1027,
        "end_line": 1037,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_smil_info#1039",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_smil_info(self, smil_url, video_id, fatal=True, f4m_params=None)",
        "snippet": "    def _extract_smil_info(self, smil_url, video_id, fatal=True, f4m_params=None):\n        smil = self._download_smil(smil_url, video_id, fatal=fatal)\n        if smil is False:\n            return {}\n        return self._parse_smil(smil, smil_url, video_id, f4m_params=f4m_params)",
        "begin_line": 1039,
        "end_line": 1043,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_smil#1045",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_smil(self, smil_url, video_id, fatal=True)",
        "snippet": "    def _download_smil(self, smil_url, video_id, fatal=True):\n        return self._download_xml(\n            smil_url, video_id, 'Downloading SMIL file',\n            'Unable to download SMIL file', fatal=fatal)",
        "begin_line": 1045,
        "end_line": 1048,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_smil#1050",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_smil(self, smil, smil_url, video_id, f4m_params=None)",
        "snippet": "    def _parse_smil(self, smil, smil_url, video_id, f4m_params=None):\n        namespace = self._parse_smil_namespace(smil)\n\n        formats = self._parse_smil_formats(\n            smil, smil_url, video_id, namespace=namespace, f4m_params=f4m_params)\n        subtitles = self._parse_smil_subtitles(smil, namespace=namespace)\n\n        video_id = os.path.splitext(url_basename(smil_url))[0]\n        title = None\n        description = None\n        upload_date = None\n        for meta in smil.findall(self._xpath_ns('./head/meta', namespace)):\n            name = meta.attrib.get('name')\n            content = meta.attrib.get('content')\n            if not name or not content:\n                continue\n            if not title and name == 'title':\n                title = content\n            elif not description and name in ('description', 'abstract'):\n                description = content\n            elif not upload_date and name == 'date':\n                upload_date = unified_strdate(content)\n\n        thumbnails = [{\n            'id': image.get('type'),\n            'url': image.get('src'),\n            'width': int_or_none(image.get('width')),\n            'height': int_or_none(image.get('height')),\n        } for image in smil.findall(self._xpath_ns('.//image', namespace)) if image.get('src')]\n\n        return {\n            'id': video_id,\n            'title': title or video_id,\n            'description': description,\n            'upload_date': upload_date,\n            'thumbnails': thumbnails,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 1050,
        "end_line": 1088,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_smil_namespace#1090",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_smil_namespace(self, smil)",
        "snippet": "    def _parse_smil_namespace(self, smil):\n        return self._search_regex(\n            r'(?i)^{([^}]+)?}smil$', smil.tag, 'namespace', default=None)",
        "begin_line": 1090,
        "end_line": 1092,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_smil_formats#1094",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None, transform_rtmp_url=None)",
        "snippet": "    def _parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None, transform_rtmp_url=None):\n        base = smil_url\n        for meta in smil.findall(self._xpath_ns('./head/meta', namespace)):\n            b = meta.get('base') or meta.get('httpBase')\n            if b:\n                base = b\n                break\n\n        formats = []\n        rtmp_count = 0\n        http_count = 0\n\n        videos = smil.findall(self._xpath_ns('.//video', namespace))\n        for video in videos:\n            src = video.get('src')\n            if not src:\n                continue\n\n            bitrate = float_or_none(video.get('system-bitrate') or video.get('systemBitrate'), 1000)\n            filesize = int_or_none(video.get('size') or video.get('fileSize'))\n            width = int_or_none(video.get('width'))\n            height = int_or_none(video.get('height'))\n            proto = video.get('proto')\n            ext = video.get('ext')\n            src_ext = determine_ext(src)\n            streamer = video.get('streamer') or base\n\n            if proto == 'rtmp' or streamer.startswith('rtmp'):\n                rtmp_count += 1\n                formats.append({\n                    'url': streamer,\n                    'play_path': src,\n                    'ext': 'flv',\n                    'format_id': 'rtmp-%d' % (rtmp_count if bitrate is None else bitrate),\n                    'tbr': bitrate,\n                    'filesize': filesize,\n                    'width': width,\n                    'height': height,\n                })\n                if transform_rtmp_url:\n                    streamer, src = transform_rtmp_url(streamer, src)\n                    formats[-1].update({\n                        'url': streamer,\n                        'play_path': src,\n                    })\n                continue\n\n            src_url = src if src.startswith('http') else compat_urlparse.urljoin(base, src)\n\n            if proto == 'm3u8' or src_ext == 'm3u8':\n                m3u8_formats = self._extract_m3u8_formats(\n                    src_url, video_id, ext or 'mp4', m3u8_id='hls', fatal=False)\n                if m3u8_formats:\n                    formats.extend(m3u8_formats)\n                continue\n\n            if src_ext == 'f4m':\n                f4m_url = src_url\n                if not f4m_params:\n                    f4m_params = {\n                        'hdcore': '3.2.0',\n                        'plugin': 'flowplayer-3.2.0.1',\n                    }\n                f4m_url += '&' if '?' in f4m_url else '?'\n                f4m_url += compat_urllib_parse.urlencode(f4m_params)\n                f4m_formats = self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False)\n                if f4m_formats:\n                    formats.extend(f4m_formats)\n                continue\n\n            if src_url.startswith('http') and self._is_valid_url(src, video_id):\n                http_count += 1\n                formats.append({\n                    'url': src_url,\n                    'ext': ext or src_ext or 'flv',\n                    'format_id': 'http-%d' % (bitrate or http_count),\n                    'tbr': bitrate,\n                    'filesize': filesize,\n                    'width': width,\n                    'height': height,\n                })\n                continue\n\n        self._sort_formats(formats)\n\n        return formats",
        "begin_line": 1094,
        "end_line": 1179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_smil_subtitles#1181",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_smil_subtitles(self, smil, namespace=None, subtitles_lang='en')",
        "snippet": "    def _parse_smil_subtitles(self, smil, namespace=None, subtitles_lang='en'):\n        subtitles = {}\n        for num, textstream in enumerate(smil.findall(self._xpath_ns('.//textstream', namespace))):\n            src = textstream.get('src')\n            if not src:\n                continue\n            ext = textstream.get('ext') or determine_ext(src)\n            if not ext:\n                type_ = textstream.get('type')\n                SUBTITLES_TYPES = {\n                    'text/vtt': 'vtt',\n                    'text/srt': 'srt',\n                    'application/smptett+xml': 'tt',\n                }\n                if type_ in SUBTITLES_TYPES:\n                    ext = SUBTITLES_TYPES[type_]\n            lang = textstream.get('systemLanguage') or textstream.get('systemLanguageName') or textstream.get('lang') or subtitles_lang\n            subtitles.setdefault(lang, []).append({\n                'url': src,\n                'ext': ext,\n            })\n        return subtitles",
        "begin_line": 1181,
        "end_line": 1202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_xspf_playlist#1204",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_xspf_playlist(self, playlist_url, playlist_id, fatal=True)",
        "snippet": "    def _extract_xspf_playlist(self, playlist_url, playlist_id, fatal=True):\n        xspf = self._download_xml(\n            playlist_url, playlist_id, 'Downloading xpsf playlist',\n            'Unable to download xspf manifest', fatal=fatal)\n        if xspf is False:\n            return []\n        return self._parse_xspf(xspf, playlist_id)",
        "begin_line": 1204,
        "end_line": 1210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_xspf#1212",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_xspf(self, playlist, playlist_id)",
        "snippet": "    def _parse_xspf(self, playlist, playlist_id):\n        NS_MAP = {\n            'xspf': 'http://xspf.org/ns/0/',\n            's1': 'http://static.streamone.nl/player/ns/0',\n        }\n\n        entries = []\n        for track in playlist.findall(xpath_with_ns('./xspf:trackList/xspf:track', NS_MAP)):\n            title = xpath_text(\n                track, xpath_with_ns('./xspf:title', NS_MAP), 'title', default=playlist_id)\n            description = xpath_text(\n                track, xpath_with_ns('./xspf:annotation', NS_MAP), 'description')\n            thumbnail = xpath_text(\n                track, xpath_with_ns('./xspf:image', NS_MAP), 'thumbnail')\n            duration = float_or_none(\n                xpath_text(track, xpath_with_ns('./xspf:duration', NS_MAP), 'duration'), 1000)\n\n            formats = [{\n                'url': location.text,\n                'format_id': location.get(xpath_with_ns('s1:label', NS_MAP)),\n                'width': int_or_none(location.get(xpath_with_ns('s1:width', NS_MAP))),\n                'height': int_or_none(location.get(xpath_with_ns('s1:height', NS_MAP))),\n            } for location in track.findall(xpath_with_ns('./xspf:location', NS_MAP))]\n            self._sort_formats(formats)\n\n            entries.append({\n                'id': playlist_id,\n                'title': title,\n                'description': description,\n                'thumbnail': thumbnail,\n                'duration': duration,\n                'formats': formats,\n            })\n        return entries",
        "begin_line": 1212,
        "end_line": 1245,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._live_title#1247",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._live_title(self, name)",
        "snippet": "    def _live_title(self, name):\n        \"\"\" Generate the title for a live video \"\"\"\n        now = datetime.datetime.now()\n        now_str = now.strftime(\"%Y-%m-%d %H:%M\")\n        return name + ' ' + now_str",
        "begin_line": 1247,
        "end_line": 1251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._int#1253",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._int(self, v, name, fatal=False, **kwargs)",
        "snippet": "    def _int(self, v, name, fatal=False, **kwargs):\n        res = int_or_none(v, **kwargs)\n        if 'get_attr' in kwargs:\n            print(getattr(v, kwargs['get_attr']))\n        if res is None:\n            msg = 'Failed to extract %s: Could not parse value %r' % (name, v)\n            if fatal:\n                raise ExtractorError(msg)\n            else:\n                self._downloader.report_warning(msg)\n        return res",
        "begin_line": 1253,
        "end_line": 1263,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._float#1265",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._float(self, v, name, fatal=False, **kwargs)",
        "snippet": "    def _float(self, v, name, fatal=False, **kwargs):\n        res = float_or_none(v, **kwargs)\n        if res is None:\n            msg = 'Failed to extract %s: Could not parse value %r' % (name, v)\n            if fatal:\n                raise ExtractorError(msg)\n            else:\n                self._downloader.report_warning(msg)\n        return res",
        "begin_line": 1265,
        "end_line": 1273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._set_cookie#1275",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._set_cookie(self, domain, name, value, expire_time=None)",
        "snippet": "    def _set_cookie(self, domain, name, value, expire_time=None):\n        cookie = compat_cookiejar.Cookie(\n            0, name, value, None, None, domain, None,\n            None, '/', True, False, expire_time, '', None, None, None)\n        self._downloader.cookiejar.set_cookie(cookie)",
        "begin_line": 1275,
        "end_line": 1279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031746031746031746,
            "pseudo_dstar_susp": 0.0029850746268656717,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0029850746268656717,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_cookies#1281",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_cookies(self, url)",
        "snippet": "    def _get_cookies(self, url):\n        \"\"\" Return a compat_cookies.SimpleCookie with the cookies for the url \"\"\"\n        req = compat_urllib_request.Request(url)\n        self._downloader.cookiejar.add_cookie_header(req)\n        return compat_cookies.SimpleCookie(req.get_header('Cookie'))",
        "begin_line": 1281,
        "end_line": 1285,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.get_testcases#1287",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.get_testcases(self, include_onlymatching=False)",
        "snippet": "    def get_testcases(self, include_onlymatching=False):\n        t = getattr(self, '_TEST', None)\n        if t:\n            assert not hasattr(self, '_TESTS'), \\\n                '%s has _TEST and _TESTS' % type(self).__name__\n            tests = [t]\n        else:\n            tests = getattr(self, '_TESTS', [])\n        for t in tests:\n            if not include_onlymatching and t.get('only_matching', False):\n                continue\n            t['name'] = type(self).__name__[:-len('IE')]\n            yield t",
        "begin_line": 1287,
        "end_line": 1299,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.is_suitable#1301",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.is_suitable(self, age_limit)",
        "snippet": "    def is_suitable(self, age_limit):\n        \"\"\" Test whether the extractor is generally suitable for the given\n        age limit (i.e. pornographic sites are not, all others usually are) \"\"\"\n\n        any_restricted = False\n        for tc in self.get_testcases(include_onlymatching=False):\n            if 'playlist' in tc:\n                tc = tc['playlist'][0]\n            is_restricted = age_restricted(\n                tc.get('info_dict', {}).get('age_limit'), age_limit)\n            if not is_restricted:\n                return True\n            any_restricted = any_restricted or is_restricted\n        return not any_restricted",
        "begin_line": 1301,
        "end_line": 1314,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract_subtitles#1316",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract_subtitles(self, *args, **kwargs)",
        "snippet": "    def extract_subtitles(self, *args, **kwargs):\n        if (self._downloader.params.get('writesubtitles', False) or\n                self._downloader.params.get('listsubtitles')):\n            return self._get_subtitles(*args, **kwargs)\n        return {}",
        "begin_line": 1316,
        "end_line": 1320,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_subtitles#1322",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_subtitles(self, *args, **kwargs)",
        "snippet": "    def _get_subtitles(self, *args, **kwargs):\n        raise NotImplementedError(\"This method must be implemented by subclasses\")",
        "begin_line": 1322,
        "end_line": 1323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._merge_subtitle_items#1326",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._merge_subtitle_items(subtitle_list1, subtitle_list2)",
        "snippet": "    def _merge_subtitle_items(subtitle_list1, subtitle_list2):\n        \"\"\" Merge subtitle items for one language. Items with duplicated URLs\n        will be dropped. \"\"\"\n        list1_urls = set([item['url'] for item in subtitle_list1])\n        ret = list(subtitle_list1)\n        ret.extend([item for item in subtitle_list2 if item['url'] not in list1_urls])\n        return ret",
        "begin_line": 1326,
        "end_line": 1332,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._merge_subtitles#1335",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._merge_subtitles(cls, subtitle_dict1, subtitle_dict2)",
        "snippet": "    def _merge_subtitles(cls, subtitle_dict1, subtitle_dict2):\n        \"\"\" Merge two subtitle dictionaries, language by language. \"\"\"\n        ret = dict(subtitle_dict1)\n        for lang in subtitle_dict2:\n            ret[lang] = cls._merge_subtitle_items(subtitle_dict1.get(lang, []), subtitle_dict2[lang])\n        return ret",
        "begin_line": 1335,
        "end_line": 1340,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract_automatic_captions#1342",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract_automatic_captions(self, *args, **kwargs)",
        "snippet": "    def extract_automatic_captions(self, *args, **kwargs):\n        if (self._downloader.params.get('writeautomaticsub', False) or\n                self._downloader.params.get('listsubtitles')):\n            return self._get_automatic_captions(*args, **kwargs)\n        return {}",
        "begin_line": 1342,
        "end_line": 1346,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_automatic_captions#1348",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_automatic_captions(self, *args, **kwargs)",
        "snippet": "    def _get_automatic_captions(self, *args, **kwargs):\n        raise NotImplementedError(\"This method must be implemented by subclasses\")",
        "begin_line": 1348,
        "end_line": 1349,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._make_valid_url#1360",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._make_valid_url(cls)",
        "snippet": "    def _make_valid_url(cls):\n        return r'%s(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' % cls._SEARCH_KEY",
        "begin_line": 1360,
        "end_line": 1361,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009225092250922509,
            "pseudo_dstar_susp": 0.0009225092250922509,
            "pseudo_tarantula_susp": 0.0009233610341643582,
            "pseudo_op2_susp": 0.0009225092250922509,
            "pseudo_barinel_susp": 0.0009233610341643582
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor.suitable#1364",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return re.match(cls._make_valid_url(), url) is not None",
        "begin_line": 1364,
        "end_line": 1365,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009225092250922509,
            "pseudo_dstar_susp": 0.0009225092250922509,
            "pseudo_tarantula_susp": 0.0009233610341643582,
            "pseudo_op2_susp": 0.0009225092250922509,
            "pseudo_barinel_susp": 0.0009233610341643582
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._real_extract#1367",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._real_extract(self, query)",
        "snippet": "    def _real_extract(self, query):\n        mobj = re.match(self._make_valid_url(), query)\n        if mobj is None:\n            raise ExtractorError('Invalid search query \"%s\"' % query)\n\n        prefix = mobj.group('prefix')\n        query = mobj.group('query')\n        if prefix == '':\n            return self._get_n_results(query, 1)\n        elif prefix == 'all':\n            return self._get_n_results(query, self._MAX_RESULTS)\n        else:\n            n = int(prefix)\n            if n <= 0:\n                raise ExtractorError('invalid download number %s for query \"%s\"' % (n, query))\n            elif n > self._MAX_RESULTS:\n                self._downloader.report_warning('%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))\n                n = self._MAX_RESULTS\n            return self._get_n_results(query, n)",
        "begin_line": 1367,
        "end_line": 1385,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._get_n_results#1387",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n        raise NotImplementedError(\"This method must be implemented by subclasses\")",
        "begin_line": 1387,
        "end_line": 1389,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor.SEARCH_KEY#1392",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor.SEARCH_KEY(self)",
        "snippet": "    def SEARCH_KEY(self):\n        return self._SEARCH_KEY",
        "begin_line": 1392,
        "end_line": 1393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.thisamericanlife.ThisAmericanLifeIE._real_extract#23",
        "src_path": "youtube_dl/extractor/thisamericanlife.py",
        "class_name": "youtube_dl.extractor.thisamericanlife.ThisAmericanLifeIE",
        "signature": "youtube_dl.extractor.thisamericanlife.ThisAmericanLifeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.thisamericanlife.org/radio-archives/episode/%s' % video_id, video_id)\n\n        return {\n            'id': video_id,\n            'url': 'http://stream.thisamericanlife.org/{0}/stream/{0}_64k.m3u8'.format(video_id),\n            'protocol': 'm3u8_native',\n            'ext': 'm4a',\n            'acodec': 'aac',\n            'vcodec': 'none',\n            'abr': 64,\n            'title': self._html_search_meta(r'twitter:title', webpage, 'title', fatal=True),\n            'description': self._html_search_meta(r'description', webpage, 'description'),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 23,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.normalboots.NormalbootsIE._real_extract#30",
        "src_path": "youtube_dl/extractor/normalboots.py",
        "class_name": "youtube_dl.extractor.normalboots.NormalbootsIE",
        "signature": "youtube_dl.extractor.normalboots.NormalbootsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_uploader = self._html_search_regex(\n            r'Posted\\sby\\s<a\\shref=\"[A-Za-z0-9/]*\">(?P<uploader>[A-Za-z]*)\\s</a>',\n            webpage, 'uploader', fatal=False)\n        video_upload_date = unified_strdate(self._html_search_regex(\n            r'<span style=\"text-transform:uppercase; font-size:inherit;\">[A-Za-z]+, (?P<date>.*)</span>',\n            webpage, 'date', fatal=False))\n\n        player_url = self._html_search_regex(\n            r'<iframe\\swidth=\"[0-9]+\"\\sheight=\"[0-9]+\"\\ssrc=\"(?P<url>[\\S]+)\"',\n            webpage, 'player url')\n        player_page = self._download_webpage(player_url, video_id)\n        video_url = self._html_search_regex(\n            r\"file:\\s'(?P<file>[^']+\\.mp4)'\", player_page, 'file')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader': video_uploader,\n            'upload_date': video_upload_date,\n        }",
        "begin_line": 30,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.flickr.FlickrIE._real_extract#27",
        "src_path": "youtube_dl/extractor/flickr.py",
        "class_name": "youtube_dl.extractor.flickr.FlickrIE",
        "signature": "youtube_dl.extractor.flickr.FlickrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        video_uploader_id = mobj.group('uploader_id')\n        webpage_url = 'http://www.flickr.com/photos/' + video_uploader_id + '/' + video_id\n        req = compat_urllib_request.Request(webpage_url)\n        req.add_header(\n            'User-Agent',\n            # it needs a more recent version\n            'Mozilla/5.0 (X11; Linux x86_64; rv:38.0) Gecko/20150101 Firefox/38.0 (Chrome)')\n        webpage = self._download_webpage(req, video_id)\n\n        secret = self._search_regex(r'secret\"\\s*:\\s*\"(\\w+)\"', webpage, 'secret')\n\n        first_url = 'https://secure.flickr.com/apps/video/video_mtl_xml.gne?v=x&photo_id=' + video_id + '&secret=' + secret + '&bitrate=700&target=_self'\n        first_xml = self._download_xml(first_url, video_id, 'Downloading first data webpage')\n\n        node_id = find_xpath_attr(\n            first_xml, './/{http://video.yahoo.com/YEP/1.0/}Item', 'id',\n            'id').text\n\n        second_url = 'https://secure.flickr.com/video_playlist.gne?node_id=' + node_id + '&tech=flash&mode=playlist&bitrate=700&secret=' + secret + '&rd=video.yahoo.com&noad=1'\n        second_xml = self._download_xml(second_url, video_id, 'Downloading second data webpage')\n\n        self.report_extraction(video_id)\n\n        stream = second_xml.find('.//STREAM')\n        if stream is None:\n            raise ExtractorError('Unable to extract video url')\n        video_url = stream.attrib['APP'] + stream.attrib['FULLPATH']\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader_id': video_uploader_id,\n        }",
        "begin_line": 27,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.yesjapan.YesJapanIE._real_extract#28",
        "src_path": "youtube_dl/extractor/yesjapan.py",
        "class_name": "youtube_dl.extractor.yesjapan.YesJapanIE",
        "signature": "youtube_dl.extractor.yesjapan.YesJapanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage)\n        video_url = self._og_search_video_url(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        timestamp = None\n        submit_info = get_element_by_attribute('class', 'pm-submit-data', webpage)\n        if submit_info:\n            timestamp = parse_iso8601(self._search_regex(\n                r'datetime=\"([^\"]+)\"', submit_info, 'upload date', fatal=False, default=None))\n\n        # attempt to resolve the final URL in order to get a proper extension\n        redirect_req = HEADRequest(video_url)\n        req = self._request_webpage(\n            redirect_req, video_id, note='Resolving final URL', errnote='Could not resolve final URL', fatal=False)\n        if req:\n            video_url = req.geturl()\n\n        formats = [{\n            'format_id': 'sd',\n            'url': video_url,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'timestamp': timestamp,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 28,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.netzkino.NetzkinoIE._real_extract#37",
        "src_path": "youtube_dl/extractor/netzkino.py",
        "class_name": "youtube_dl.extractor.netzkino.NetzkinoIE",
        "signature": "youtube_dl.extractor.netzkino.NetzkinoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        category_id = mobj.group('category')\n        video_id = mobj.group('id')\n\n        api_url = 'http://api.netzkino.de.simplecache.net/capi-2.0a/categories/%s.json?d=www' % category_id\n        api_info = self._download_json(api_url, video_id)\n        info = next(\n            p for p in api_info['posts'] if p['slug'] == video_id)\n        custom_fields = info['custom_fields']\n\n        production_js = self._download_webpage(\n            'http://www.netzkino.de/beta/dist/production.min.js', video_id,\n            note='Downloading player code')\n        avo_js = self._search_regex(\n            r'var urlTemplate=(\\{.*?\"\\})',\n            production_js, 'URL templates')\n        templates = self._parse_json(\n            avo_js, video_id, transform_source=js_to_json)\n\n        suffix = {\n            'hds': '.mp4/manifest.f4m',\n            'hls': '.mp4/master.m3u8',\n            'pmd': '.mp4',\n        }\n        film_fn = custom_fields['Streaming'][0]\n        formats = [{\n            'format_id': key,\n            'ext': 'mp4',\n            'url': tpl.replace('{}', film_fn) + suffix[key],\n        } for key, tpl in templates.items()]\n        self._sort_formats(formats)\n\n        comments = [{\n            'timestamp': parse_iso8601(c.get('date'), delimiter=' '),\n            'id': c['id'],\n            'author': c['name'],\n            'html': c['content'],\n            'parent': 'root' if c.get('parent', 0) == 0 else c['parent'],\n        } for c in info.get('comments', [])]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'comments': comments,\n            'title': info['title'],\n            'age_limit': int_or_none(custom_fields.get('FSK')[0]),\n            'timestamp': parse_iso8601(info.get('date'), delimiter=' '),\n            'description': clean_html(info.get('content')),\n            'thumbnail': info.get('thumbnail'),\n            'playlist_title': api_info.get('title'),\n            'playlist_id': category_id,\n        }",
        "begin_line": 37,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soompi.SoompiBaseIE._get_episodes#19",
        "src_path": "youtube_dl/extractor/soompi.py",
        "class_name": "youtube_dl.extractor.soompi.SoompiBaseIE",
        "signature": "youtube_dl.extractor.soompi.SoompiBaseIE._get_episodes(self, webpage, episode_filter=None)",
        "snippet": "    def _get_episodes(self, webpage, episode_filter=None):\n        episodes = self._parse_json(\n            self._search_regex(\n                r'VIDEOS\\s*=\\s*(\\[.+?\\]);', webpage, 'episodes JSON'),\n            None)\n        return list(filter(episode_filter, episodes))",
        "begin_line": 19,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soompi.SoompiIE._get_episode#43",
        "src_path": "youtube_dl/extractor/soompi.py",
        "class_name": "youtube_dl.extractor.soompi.SoompiIE",
        "signature": "youtube_dl.extractor.soompi.SoompiIE._get_episode(self, webpage, video_id)",
        "snippet": "    def _get_episode(self, webpage, video_id):\n        return self._get_episodes(webpage, lambda x: x['id'] == video_id)[0]",
        "begin_line": 43,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soompi.SoompiIE._get_subtitles#46",
        "src_path": "youtube_dl/extractor/soompi.py",
        "class_name": "youtube_dl.extractor.soompi.SoompiIE",
        "signature": "youtube_dl.extractor.soompi.SoompiIE._get_subtitles(self, config, video_id)",
        "snippet": "    def _get_subtitles(self, config, video_id):\n        sub_langs = {}\n        for subtitle in config.findall('./{default}preload/subtitles/subtitle'):\n            sub_langs[subtitle.attrib['id']] = subtitle.attrib['title']\n\n        subtitles = {}\n        for s in config.findall('./{default}preload/subtitle'):\n            lang_code = sub_langs.get(s.attrib['id'])\n            if not lang_code:\n                continue\n            sub_id = s.get('id')\n            data = xpath_text(s, './data', 'data')\n            iv = xpath_text(s, './iv', 'iv')\n            if not id or not iv or not data:\n                continue\n            subtitle = self._decrypt_subtitles(data, iv, sub_id).decode('utf-8')\n            subtitles[lang_code] = self._extract_subtitles(subtitle)\n        return subtitles",
        "begin_line": 46,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soompi.SoompiIE._real_extract#65",
        "src_path": "youtube_dl/extractor/soompi.py",
        "class_name": "youtube_dl.extractor.soompi.SoompiIE",
        "signature": "youtube_dl.extractor.soompi.SoompiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        try:\n            webpage = self._download_webpage(\n                url, video_id, 'Downloading episode page')\n        except ExtractorError as ee:\n            if isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 403:\n                webpage = ee.cause.read()\n                block_message = self._html_search_regex(\n                    r'(?s)<div class=\"block-message\">(.+?)</div>', webpage,\n                    'block message', default=None)\n                if block_message:\n                    raise ExtractorError(block_message, expected=True)\n            raise\n\n        formats = []\n        config = None\n        for format_id in re.findall(r'\\?quality=([0-9a-zA-Z]+)', webpage):\n            config = self._download_xml(\n                'http://tv.soompi.com/en/show/_/%s-config.xml?mode=hls&quality=%s' % (video_id, format_id),\n                video_id, 'Downloading %s XML' % format_id)\n            m3u8_url = xpath_text(\n                config, './{default}preload/stream_info/file',\n                '%s m3u8 URL' % format_id)\n            if not m3u8_url:\n                continue\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', m3u8_id=format_id))\n        self._sort_formats(formats)\n\n        episode = self._get_episode(webpage, video_id)\n\n        title = episode['name']\n        description = episode.get('description')\n        duration = int_or_none(episode.get('duration'))\n\n        thumbnails = [{\n            'id': thumbnail_id,\n            'url': thumbnail_url,\n        } for thumbnail_id, thumbnail_url in episode.get('img_url', {}).items()]\n\n        subtitles = self.extract_subtitles(config, video_id)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles\n        }",
        "begin_line": 65,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.soompi.SoompiShowIE._real_extract#133",
        "src_path": "youtube_dl/extractor/soompi.py",
        "class_name": "youtube_dl.extractor.soompi.SoompiShowIE",
        "signature": "youtube_dl.extractor.soompi.SoompiShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            url, show_id, 'Downloading show page')\n\n        title = remove_start(self._og_search_title(webpage), 'SoompiTV | ')\n        description = self._og_search_description(webpage)\n\n        entries = [\n            self.url_result('http://tv.soompi.com/en/watch/%s' % episode['id'], 'Soompi')\n            for episode in self._get_episodes(webpage)]\n\n        return self.playlist_result(entries, show_id, title, description)",
        "begin_line": 133,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVIE._extract_url#121",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(r'<meta\\s[^>]*https?://api\\.blip\\.tv/\\w+/redirect/\\w+/(\\d+)', webpage)\n        if mobj:\n            return 'http://blip.tv/a/a-' + mobj.group(1)\n        mobj = re.search(r'<(?:iframe|embed|object)\\s[^>]*(https?://(?:\\w+\\.)?blip\\.tv/(?:play/|api\\.swf#)[a-zA-Z0-9_]+)', webpage)\n        if mobj:\n            return mobj.group(1)",
        "begin_line": 121,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVIE._real_extract#129",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        lookup_id = mobj.group('lookup_id')\n\n        # See https://github.com/rg3/youtube-dl/issues/857 and\n        # https://github.com/rg3/youtube-dl/issues/4197\n        if lookup_id:\n            urlh = self._request_webpage(\n                'http://blip.tv/play/%s' % lookup_id, lookup_id, 'Resolving lookup id')\n            url = compat_urlparse.urlparse(urlh.geturl())\n            qs = compat_urlparse.parse_qs(url.query)\n            mobj = re.match(self._VALID_URL, qs['file'][0])\n\n        video_id = mobj.group('id')\n\n        rss = self._download_xml('http://blip.tv/rss/flash/%s' % video_id, video_id, 'Downloading video RSS')\n\n        def _x(p):\n            return xpath_with_ns(p, {\n                'blip': 'http://blip.tv/dtd/blip/1.0',\n                'media': 'http://search.yahoo.com/mrss/',\n                'itunes': 'http://www.itunes.com/dtds/podcast-1.0.dtd',\n            })\n\n        item = rss.find('channel/item')\n\n        video_id = xpath_text(item, _x('blip:item_id'), 'video id') or lookup_id\n        title = xpath_text(item, 'title', 'title', fatal=True)\n        description = clean_html(xpath_text(item, _x('blip:puredescription'), 'description'))\n        timestamp = parse_iso8601(xpath_text(item, _x('blip:datestamp'), 'timestamp'))\n        uploader = xpath_text(item, _x('blip:user'), 'uploader')\n        uploader_id = xpath_text(item, _x('blip:userid'), 'uploader id')\n        duration = int_or_none(xpath_text(item, _x('blip:runtime'), 'duration'))\n        media_thumbnail = item.find(_x('media:thumbnail'))\n        thumbnail = (media_thumbnail.get('url') if media_thumbnail is not None\n                     else xpath_text(item, 'image', 'thumbnail'))\n        categories = [category.text for category in item.findall('category') if category is not None]\n\n        formats = []\n        subtitles_urls = {}\n\n        media_group = item.find(_x('media:group'))\n        for media_content in media_group.findall(_x('media:content')):\n            url = media_content.get('url')\n            role = media_content.get(_x('blip:role'))\n            msg = self._download_webpage(\n                url + '?showplayer=20140425131715&referrer=http://blip.tv&mask=7&skin=flashvars&view=url',\n                video_id, 'Resolving URL for %s' % role)\n            real_url = compat_urlparse.parse_qs(msg.strip())['message'][0]\n\n            media_type = media_content.get('type')\n            if media_type == 'text/srt' or url.endswith('.srt'):\n                LANGS = {\n                    'english': 'en',\n                }\n                lang = role.rpartition('-')[-1].strip().lower()\n                langcode = LANGS.get(lang, lang)\n                subtitles_urls[langcode] = url\n            elif media_type.startswith('video/'):\n                formats.append({\n                    'url': real_url,\n                    'format_id': role,\n                    'format_note': media_type,\n                    'vcodec': media_content.get(_x('blip:vcodec')) or 'none',\n                    'acodec': media_content.get(_x('blip:acodec')),\n                    'filesize': media_content.get('filesize'),\n                    'width': int_or_none(media_content.get('width')),\n                    'height': int_or_none(media_content.get('height')),\n                })\n        self._check_formats(formats, video_id)\n        self._sort_formats(formats)\n\n        subtitles = self.extract_subtitles(video_id, subtitles_urls)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 129,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVIE._get_subtitles#217",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVIE._get_subtitles(self, video_id, subtitles_urls)",
        "snippet": "    def _get_subtitles(self, video_id, subtitles_urls):\n        subtitles = {}\n        for lang, url in subtitles_urls.items():\n            # For some weird reason, blip.tv serves a video instead of subtitles\n            # when we request with a common UA\n            req = compat_urllib_request.Request(url)\n            req.add_header('User-Agent', 'youtube-dl')\n            subtitles[lang] = [{\n                # The extension is 'srt' but it's actually an 'ass' file\n                'ext': 'ass',\n                'data': self._download_webpage(req, None, note=False),\n            }]\n        return subtitles",
        "begin_line": 217,
        "end_line": 229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVUserIE._real_extract#245",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVUserIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        username = mobj.group(1)\n\n        page_base = 'http://m.blip.tv/pr/show_get_full_episode_list?users_id=%s&lite=0&esi=1'\n\n        page = self._download_webpage(url, username, 'Downloading user page')\n        mobj = re.search(r'data-users-id=\"([^\"]+)\"', page)\n        page_base = page_base % mobj.group(1)\n        title = self._og_search_title(page)\n\n        # Download video ids using BlipTV Ajax calls. Result size per\n        # query is limited (currently to 12 videos) so we need to query\n        # page by page until there are no video ids - it means we got\n        # all of them.\n\n        video_ids = []\n        pagenum = 1\n\n        while True:\n            url = page_base + \"&page=\" + str(pagenum)\n            page = self._download_webpage(\n                url, username, 'Downloading video ids from page %d' % pagenum)\n\n            # Extract video identifiers\n            ids_in_page = []\n\n            for mobj in re.finditer(r'href=\"/([^\"]+)\"', page):\n                if mobj.group(1) not in ids_in_page:\n                    ids_in_page.append(unescapeHTML(mobj.group(1)))\n\n            video_ids.extend(ids_in_page)\n\n            # A little optimization - if current page is not\n            # \"full\", ie. does not contain PAGE_SIZE video ids then\n            # we can assume that this page is the last one - there\n            # are no more ids on further pages - no need to query\n            # again.\n\n            if len(ids_in_page) < self._PAGE_SIZE:\n                break\n\n            pagenum += 1\n\n        urls = ['http://blip.tv/%s' % video_id for video_id in video_ids]\n        url_entries = [self.url_result(vurl, 'BlipTV') for vurl in urls]\n        return self.playlist_result(\n            url_entries, playlist_title=title, playlist_id=username)",
        "begin_line": 245,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.phoenix.PhoenixIE._real_extract#36",
        "src_path": "youtube_dl/extractor/phoenix.py",
        "class_name": "youtube_dl.extractor.phoenix.PhoenixIE",
        "signature": "youtube_dl.extractor.phoenix.PhoenixIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        internal_id = self._search_regex(\n            r'<div class=\"phx_vod\" id=\"phx_vod_([0-9]+)\"',\n            webpage, 'internal video ID')\n\n        api_url = 'http://www.phoenix.de/php/zdfplayer-v1.3/data/beitragsDetails.php?ak=web&id=%s' % internal_id\n        return extract_from_xml_url(self, video_id, api_url)",
        "begin_line": 36,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vier.VierIE._real_extract#34",
        "src_path": "youtube_dl/extractor/vier.py",
        "class_name": "youtube_dl.extractor.vier.VierIE",
        "signature": "youtube_dl.extractor.vier.VierIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        embed_id = mobj.group('embed_id')\n        display_id = mobj.group('display_id') or embed_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            [r'data-nid=\"(\\d+)\"', r'\"nid\"\\s*:\\s*\"(\\d+)\"'],\n            webpage, 'video id')\n        application = self._search_regex(\n            [r'data-application=\"([^\"]+)\"', r'\"application\"\\s*:\\s*\"([^\"]+)\"'],\n            webpage, 'application', default='vier_vod')\n        filename = self._search_regex(\n            [r'data-filename=\"([^\"]+)\"', r'\"filename\"\\s*:\\s*\"([^\"]+)\"'],\n            webpage, 'filename')\n\n        playlist_url = 'http://vod.streamcloud.be/%s/mp4:_definst_/%s.mp4/playlist.m3u8' % (application, filename)\n        formats = self._extract_m3u8_formats(playlist_url, display_id, 'mp4')\n\n        title = self._og_search_title(webpage, default=display_id)\n        description = self._og_search_description(webpage, default=None)\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vier.VierVideosIE._real_extract#91",
        "src_path": "youtube_dl/extractor/vier.py",
        "class_name": "youtube_dl.extractor.vier.VierVideosIE",
        "signature": "youtube_dl.extractor.vier.VierVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        program = mobj.group('program')\n\n        page_id = mobj.group('page')\n        if page_id:\n            page_id = int(page_id)\n            start_page = page_id\n            playlist_id = '%s-page%d' % (program, page_id)\n        else:\n            start_page = 0\n            playlist_id = program\n\n        entries = []\n        for current_page_id in itertools.count(start_page):\n            current_page = self._download_webpage(\n                'http://www.vier.be/%s/videos?page=%d' % (program, current_page_id),\n                program,\n                'Downloading page %d' % (current_page_id + 1))\n            page_entries = [\n                self.url_result('http://www.vier.be' + video_url, 'Vier')\n                for video_url in re.findall(\n                    r'<h3><a href=\"(/[^/]+/videos/[^/]+(?:/\\d+)?)\">', current_page)]\n            entries.extend(page_entries)\n            if page_id or '>Meer<' not in current_page:\n                break\n\n        return self.playlist_result(entries, playlist_id)",
        "begin_line": 91,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tv2.TV2IE._real_extract#34",
        "src_path": "youtube_dl/extractor/tv2.py",
        "class_name": "youtube_dl.extractor.tv2.TV2IE",
        "signature": "youtube_dl.extractor.tv2.TV2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        formats = []\n        format_urls = []\n        for protocol in ('HDS', 'HLS'):\n            data = self._download_json(\n                'http://sumo.tv2.no/api/web/asset/%s/play.json?protocol=%s&videoFormat=SMIL+ISMUSP' % (video_id, protocol),\n                video_id, 'Downloading play JSON')['playback']\n            for item in data['items']['item']:\n                video_url = item.get('url')\n                if not video_url or video_url in format_urls:\n                    continue\n                format_id = '%s-%s' % (protocol.lower(), item.get('mediaFormat'))\n                if not self._is_valid_url(video_url, video_id, format_id):\n                    continue\n                format_urls.append(video_url)\n                ext = determine_ext(video_url)\n                if ext == 'f4m':\n                    formats.extend(self._extract_f4m_formats(\n                        video_url, video_id, f4m_id=format_id))\n                elif ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        video_url, video_id, 'mp4', m3u8_id=format_id))\n                elif ext == 'ism' or video_url.endswith('.ism/Manifest'):\n                    pass\n                else:\n                    formats.append({\n                        'url': video_url,\n                        'format_id': format_id,\n                        'tbr': int_or_none(item.get('bitrate')),\n                        'filesize': int_or_none(item.get('fileSize')),\n                    })\n        self._sort_formats(formats)\n\n        asset = self._download_json(\n            'http://sumo.tv2.no/api/web/asset/%s.json' % video_id,\n            video_id, 'Downloading metadata JSON')['asset']\n\n        title = asset['title']\n        description = asset.get('description')\n        timestamp = parse_iso8601(asset.get('createTime'))\n        duration = float_or_none(asset.get('accurateDuration') or asset.get('duration'))\n        view_count = int_or_none(asset.get('views'))\n        categories = asset.get('keywords', '').split(',')\n\n        thumbnails = [{\n            'id': thumbnail.get('@type'),\n            'url': thumbnail.get('url'),\n        } for _, thumbnail in asset.get('imageVersions', {}).items()]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': view_count,\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tv2.TV2ArticleIE._real_extract#114",
        "src_path": "youtube_dl/extractor/tv2.py",
        "class_name": "youtube_dl.extractor.tv2.TV2ArticleIE",
        "signature": "youtube_dl.extractor.tv2.TV2ArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = [\n            self.url_result('http://www.tv2.no/v/%s' % video_id, 'TV2')\n            for video_id in re.findall(r'data-assetid=\"(\\d+)\"', webpage)]\n\n        title = remove_end(self._og_search_title(webpage), ' - TV2.no')\n        description = remove_end(self._og_search_description(webpage), ' - TV2.no')\n\n        return self.playlist_result(entries, playlist_id, title, description)",
        "begin_line": 114,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.blinkx.BlinkxIE._real_extract#31",
        "src_path": "youtube_dl/extractor/blinkx.py",
        "class_name": "youtube_dl.extractor.blinkx.BlinkxIE",
        "signature": "youtube_dl.extractor.blinkx.BlinkxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        display_id = video_id[:8]\n\n        api_url = ('https://apib4.blinkx.com/api.php?action=play_video&' +\n                   'video=%s' % video_id)\n        data_json = self._download_webpage(api_url, display_id)\n        data = json.loads(data_json)['api']['results'][0]\n        duration = None\n        thumbnails = []\n        formats = []\n        for m in data['media']:\n            if m['type'] == 'jpg':\n                thumbnails.append({\n                    'url': m['link'],\n                    'width': int(m['w']),\n                    'height': int(m['h']),\n                })\n            elif m['type'] == 'original':\n                duration = float(m['d'])\n            elif m['type'] == 'youtube':\n                yt_id = m['link']\n                self.to_screen('Youtube video detected: %s' % yt_id)\n                return self.url_result(yt_id, 'Youtube', video_id=yt_id)\n            elif m['type'] in ('flv', 'mp4'):\n                vcodec = remove_start(m['vcodec'], 'ff')\n                acodec = remove_start(m['acodec'], 'ff')\n                vbr = int_or_none(m.get('vbr') or m.get('vbitrate'), 1000)\n                abr = int_or_none(m.get('abr') or m.get('abitrate'), 1000)\n                tbr = vbr + abr if vbr and abr else None\n                format_id = '%s-%sk-%s' % (vcodec, tbr, m['w'])\n                formats.append({\n                    'format_id': format_id,\n                    'url': m['link'],\n                    'vcodec': vcodec,\n                    'acodec': acodec,\n                    'abr': abr,\n                    'vbr': vbr,\n                    'tbr': tbr,\n                    'width': int_or_none(m.get('w')),\n                    'height': int_or_none(m.get('h')),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': display_id,\n            'fullid': video_id,\n            'title': data['title'],\n            'formats': formats,\n            'uploader': data['channel_name'],\n            'timestamp': data['pubdate_epoch'],\n            'description': data.get('description'),\n            'thumbnails': thumbnails,\n            'duration': duration,\n        }",
        "begin_line": 31,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tass.TassIE._real_extract#33",
        "src_path": "youtube_dl/extractor/tass.py",
        "class_name": "youtube_dl.extractor.tass.TassIE",
        "signature": "youtube_dl.extractor.tass.TassIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        sources = json.loads(js_to_json(self._search_regex(\n            r'(?s)sources\\s*:\\s*(\\[.+?\\])', webpage, 'sources')))\n\n        quality = qualities(['sd', 'hd'])\n\n        formats = []\n        for source in sources:\n            video_url = source.get('file')\n            if not video_url or not video_url.startswith('http') or not video_url.endswith('.mp4'):\n                continue\n            label = source.get('label')\n            formats.append({\n                'url': video_url,\n                'format_id': label,\n                'quality': quality(label),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n        }",
        "begin_line": 33,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.MediaSelectionError.__init__#199",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.MediaSelectionError",
        "signature": "youtube_dl.extractor.bbc.MediaSelectionError.__init__(self, id)",
        "snippet": "        def __init__(self, id):\n            self.id = id",
        "begin_line": 199,
        "end_line": 200,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_asx_playlist#202",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_asx_playlist(self, connection, programme_id)",
        "snippet": "    def _extract_asx_playlist(self, connection, programme_id):\n        asx = self._download_xml(connection.get('href'), programme_id, 'Downloading ASX playlist')\n        return [ref.get('href') for ref in asx.findall('./Entry/ref')]",
        "begin_line": 202,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_connection#206",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_connection(self, connection, programme_id)",
        "snippet": "    def _extract_connection(self, connection, programme_id):\n        formats = []\n        kind = connection.get('kind')\n        protocol = connection.get('protocol')\n        supplier = connection.get('supplier')\n        if protocol == 'http':\n            href = connection.get('href')\n            transfer_format = connection.get('transferFormat')\n            # ASX playlist\n            if supplier == 'asx':\n                for i, ref in enumerate(self._extract_asx_playlist(connection, programme_id)):\n                    formats.append({\n                        'url': ref,\n                        'format_id': 'ref%s_%s' % (i, supplier),\n                    })\n            # Skip DASH until supported\n            elif transfer_format == 'dash':\n                pass\n            elif transfer_format == 'hls':\n                m3u8_formats = self._extract_m3u8_formats(\n                    href, programme_id, ext='mp4', entry_protocol='m3u8_native',\n                    m3u8_id=supplier, fatal=False)\n                if m3u8_formats:\n                    formats.extend(m3u8_formats)\n            # Direct link\n            else:\n                formats.append({\n                    'url': href,\n                    'format_id': supplier or kind or protocol,\n                })\n        elif protocol == 'rtmp':\n            application = connection.get('application', 'ondemand')\n            auth_string = connection.get('authString')\n            identifier = connection.get('identifier')\n            server = connection.get('server')\n            formats.append({\n                'url': '%s://%s/%s?%s' % (protocol, server, application, auth_string),\n                'play_path': identifier,\n                'app': '%s?%s' % (application, auth_string),\n                'page_url': 'http://www.bbc.co.uk',\n                'player_url': 'http://www.bbc.co.uk/emp/releases/iplayer/revisions/617463_618125_4/617463_618125_4_emp.swf',\n                'rtmp_live': False,\n                'ext': 'flv',\n                'format_id': supplier,\n            })\n        return formats",
        "begin_line": 206,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_items#253",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_items(self, playlist)",
        "snippet": "    def _extract_items(self, playlist):\n        return playlist.findall('./{%s}item' % self._EMP_PLAYLIST_NS)",
        "begin_line": 253,
        "end_line": 254,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._findall_ns#256",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._findall_ns(self, element, xpath)",
        "snippet": "    def _findall_ns(self, element, xpath):\n        elements = []\n        for ns in self._NAMESPACES:\n            elements.extend(element.findall(xpath % ns))\n        return elements",
        "begin_line": 256,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_medias#262",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_medias(self, media_selection)",
        "snippet": "    def _extract_medias(self, media_selection):\n        error = media_selection.find('./{%s}error' % self._MEDIASELECTION_NS)\n        if error is None:\n            media_selection.find('./{%s}error' % self._EMP_PLAYLIST_NS)\n        if error is not None:\n            raise BBCCoUkIE.MediaSelectionError(error.get('id'))\n        return self._findall_ns(media_selection, './{%s}media')",
        "begin_line": 262,
        "end_line": 268,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_connections#270",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_connections(self, media)",
        "snippet": "    def _extract_connections(self, media):\n        return self._findall_ns(media, './{%s}connection')",
        "begin_line": 270,
        "end_line": 271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_video#273",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_video(self, media, programme_id)",
        "snippet": "    def _extract_video(self, media, programme_id):\n        formats = []\n        vbr = int_or_none(media.get('bitrate'))\n        vcodec = media.get('encoding')\n        service = media.get('service')\n        width = int_or_none(media.get('width'))\n        height = int_or_none(media.get('height'))\n        file_size = int_or_none(media.get('media_file_size'))\n        for connection in self._extract_connections(media):\n            conn_formats = self._extract_connection(connection, programme_id)\n            for format in conn_formats:\n                format.update({\n                    'width': width,\n                    'height': height,\n                    'vbr': vbr,\n                    'vcodec': vcodec,\n                    'filesize': file_size,\n                })\n                if service:\n                    format['format_id'] = '%s_%s' % (service, format['format_id'])\n            formats.extend(conn_formats)\n        return formats",
        "begin_line": 273,
        "end_line": 294,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_audio#296",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_audio(self, media, programme_id)",
        "snippet": "    def _extract_audio(self, media, programme_id):\n        formats = []\n        abr = int_or_none(media.get('bitrate'))\n        acodec = media.get('encoding')\n        service = media.get('service')\n        for connection in self._extract_connections(media):\n            conn_formats = self._extract_connection(connection, programme_id)\n            for format in conn_formats:\n                format.update({\n                    'format_id': '%s_%s' % (service, format['format_id']),\n                    'abr': abr,\n                    'acodec': acodec,\n                })\n            formats.extend(conn_formats)\n        return formats",
        "begin_line": 296,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._get_subtitles#312",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._get_subtitles(self, media, programme_id)",
        "snippet": "    def _get_subtitles(self, media, programme_id):\n        subtitles = {}\n        for connection in self._extract_connections(media):\n            captions = self._download_xml(connection.get('href'), programme_id, 'Downloading captions')\n            lang = captions.get('{http://www.w3.org/XML/1998/namespace}lang', 'en')\n            subtitles[lang] = [\n                {\n                    'url': connection.get('href'),\n                    'ext': 'ttml',\n                },\n            ]\n        return subtitles",
        "begin_line": 312,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._raise_extractor_error#325",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._raise_extractor_error(self, media_selection_error)",
        "snippet": "    def _raise_extractor_error(self, media_selection_error):\n        raise ExtractorError(\n            '%s returned error: %s' % (self.IE_NAME, media_selection_error.id),\n            expected=True)",
        "begin_line": 325,
        "end_line": 328,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._download_media_selector#330",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._download_media_selector(self, programme_id)",
        "snippet": "    def _download_media_selector(self, programme_id):\n        last_exception = None\n        for mediaselector_url in self._MEDIASELECTOR_URLS:\n            try:\n                return self._download_media_selector_url(\n                    mediaselector_url % programme_id, programme_id)\n            except BBCCoUkIE.MediaSelectionError as e:\n                if e.id in ('notukerror', 'geolocation'):\n                    last_exception = e\n                    continue\n                self._raise_extractor_error(e)\n        self._raise_extractor_error(last_exception)",
        "begin_line": 330,
        "end_line": 341,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._download_media_selector_url#343",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._download_media_selector_url(self, url, programme_id=None)",
        "snippet": "    def _download_media_selector_url(self, url, programme_id=None):\n        try:\n            media_selection = self._download_xml(\n                url, programme_id, 'Downloading media selection XML')\n        except ExtractorError as ee:\n            if isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 403:\n                media_selection = compat_etree_fromstring(ee.cause.read().decode('utf-8'))\n            else:\n                raise\n        return self._process_media_selector(media_selection, programme_id)",
        "begin_line": 343,
        "end_line": 352,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._process_media_selector#354",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._process_media_selector(self, media_selection, programme_id)",
        "snippet": "    def _process_media_selector(self, media_selection, programme_id):\n        formats = []\n        subtitles = None\n\n        for media in self._extract_medias(media_selection):\n            kind = media.get('kind')\n            if kind == 'audio':\n                formats.extend(self._extract_audio(media, programme_id))\n            elif kind == 'video':\n                formats.extend(self._extract_video(media, programme_id))\n            elif kind == 'captions':\n                subtitles = self.extract_subtitles(media, programme_id)\n        return formats, subtitles",
        "begin_line": 354,
        "end_line": 366,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._download_playlist#368",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._download_playlist(self, playlist_id)",
        "snippet": "    def _download_playlist(self, playlist_id):\n        try:\n            playlist = self._download_json(\n                'http://www.bbc.co.uk/programmes/%s/playlist.json' % playlist_id,\n                playlist_id, 'Downloading playlist JSON')\n\n            version = playlist.get('defaultAvailableVersion')\n            if version:\n                smp_config = version['smpConfig']\n                title = smp_config['title']\n                description = smp_config['summary']\n                for item in smp_config['items']:\n                    kind = item['kind']\n                    if kind != 'programme' and kind != 'radioProgramme':\n                        continue\n                    programme_id = item.get('vpid')\n                    duration = int_or_none(item.get('duration'))\n                    formats, subtitles = self._download_media_selector(programme_id)\n                return programme_id, title, description, duration, formats, subtitles\n        except ExtractorError as ee:\n            if not (isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 404):\n                raise\n\n        # fallback to legacy playlist\n        return self._process_legacy_playlist(playlist_id)",
        "begin_line": 368,
        "end_line": 392,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._process_legacy_playlist_url#394",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._process_legacy_playlist_url(self, url, display_id)",
        "snippet": "    def _process_legacy_playlist_url(self, url, display_id):\n        playlist = self._download_legacy_playlist_url(url, display_id)\n        return self._extract_from_legacy_playlist(playlist, display_id)",
        "begin_line": 394,
        "end_line": 396,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._process_legacy_playlist#398",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._process_legacy_playlist(self, playlist_id)",
        "snippet": "    def _process_legacy_playlist(self, playlist_id):\n        return self._process_legacy_playlist_url(\n            'http://www.bbc.co.uk/iplayer/playlist/%s' % playlist_id, playlist_id)",
        "begin_line": 398,
        "end_line": 400,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._download_legacy_playlist_url#402",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._download_legacy_playlist_url(self, url, playlist_id=None)",
        "snippet": "    def _download_legacy_playlist_url(self, url, playlist_id=None):\n        return self._download_xml(\n            url, playlist_id, 'Downloading legacy playlist XML')",
        "begin_line": 402,
        "end_line": 404,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_from_legacy_playlist#406",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_from_legacy_playlist(self, playlist, playlist_id)",
        "snippet": "    def _extract_from_legacy_playlist(self, playlist, playlist_id):\n        no_items = playlist.find('./{%s}noItems' % self._EMP_PLAYLIST_NS)\n        if no_items is not None:\n            reason = no_items.get('reason')\n            if reason == 'preAvailability':\n                msg = 'Episode %s is not yet available' % playlist_id\n            elif reason == 'postAvailability':\n                msg = 'Episode %s is no longer available' % playlist_id\n            elif reason == 'noMedia':\n                msg = 'Episode %s is not currently available' % playlist_id\n            else:\n                msg = 'Episode %s is not available: %s' % (playlist_id, reason)\n            raise ExtractorError(msg, expected=True)\n\n        for item in self._extract_items(playlist):\n            kind = item.get('kind')\n            if kind != 'programme' and kind != 'radioProgramme':\n                continue\n            title = playlist.find('./{%s}title' % self._EMP_PLAYLIST_NS).text\n            description_el = playlist.find('./{%s}summary' % self._EMP_PLAYLIST_NS)\n            description = description_el.text if description_el is not None else None\n\n            def get_programme_id(item):\n                def get_from_attributes(item):\n                    for p in('identifier', 'group'):\n                        value = item.get(p)\n                        if value and re.match(r'^[pb][\\da-z]{7}$', value):\n                            return value\n                get_from_attributes(item)\n                mediator = item.find('./{%s}mediator' % self._EMP_PLAYLIST_NS)\n                if mediator is not None:\n                    return get_from_attributes(mediator)\n\n            programme_id = get_programme_id(item)\n            duration = int_or_none(item.get('duration'))\n\n            if programme_id:\n                formats, subtitles = self._download_media_selector(programme_id)\n            else:\n                formats, subtitles = self._process_media_selector(item, playlist_id)\n                programme_id = playlist_id\n\n        return programme_id, title, description, duration, formats, subtitles",
        "begin_line": 406,
        "end_line": 448,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._real_extract#450",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        group_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, group_id, 'Downloading video page')\n\n        programme_id = None\n\n        tviplayer = self._search_regex(\n            r'mediator\\.bind\\(({.+?})\\s*,\\s*document\\.getElementById',\n            webpage, 'player', default=None)\n\n        if tviplayer:\n            player = self._parse_json(tviplayer, group_id).get('player', {})\n            duration = int_or_none(player.get('duration'))\n            programme_id = player.get('vpid')\n\n        if not programme_id:\n            programme_id = self._search_regex(\n                r'\"vpid\"\\s*:\\s*\"([\\da-z]{8})\"', webpage, 'vpid', fatal=False, default=None)\n\n        if programme_id:\n            formats, subtitles = self._download_media_selector(programme_id)\n            title = self._og_search_title(webpage)\n            description = self._search_regex(\n                r'<p class=\"[^\"]*medium-description[^\"]*\">([^<]+)</p>',\n                webpage, 'description', fatal=False)\n        else:\n            programme_id, title, description, duration, formats, subtitles = self._download_playlist(group_id)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': programme_id,\n            'title': title,\n            'description': description,\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 450,
        "end_line": 489,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCIE.suitable#656",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCIE",
        "signature": "youtube_dl.extractor.bbc.BBCIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if BBCCoUkIE.suitable(url) or BBCCoUkArticleIE.suitable(url) else super(BBCIE, cls).suitable(url)",
        "begin_line": 656,
        "end_line": 657,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009225092250922509,
            "pseudo_dstar_susp": 0.0009225092250922509,
            "pseudo_tarantula_susp": 0.0009233610341643582,
            "pseudo_op2_susp": 0.0009225092250922509,
            "pseudo_barinel_susp": 0.0009233610341643582
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCIE._extract_from_media_meta#659",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCIE",
        "signature": "youtube_dl.extractor.bbc.BBCIE._extract_from_media_meta(self, media_meta, video_id)",
        "snippet": "    def _extract_from_media_meta(self, media_meta, video_id):\n        # Direct links to media in media metadata (e.g.\n        # http://www.bbc.com/turkce/haberler/2015/06/150615_telabyad_kentin_cogu)\n        # TODO: there are also f4m and m3u8 streams incorporated in playlist.sxml\n        source_files = media_meta.get('sourceFiles')\n        if source_files:\n            return [{\n                'url': f['url'],\n                'format_id': format_id,\n                'ext': f.get('encoding'),\n                'tbr': float_or_none(f.get('bitrate'), 1000),\n                'filesize': int_or_none(f.get('filesize')),\n            } for format_id, f in source_files.items() if f.get('url')], []\n\n        programme_id = media_meta.get('externalId')\n        if programme_id:\n            return self._download_media_selector(programme_id)\n\n        # Process playlist.sxml as legacy playlist\n        href = media_meta.get('href')\n        if href:\n            playlist = self._download_legacy_playlist_url(href)\n            _, _, _, _, formats, subtitles = self._extract_from_legacy_playlist(playlist, video_id)\n            return formats, subtitles\n\n        return [], []",
        "begin_line": 659,
        "end_line": 684,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCIE._extract_from_playlist_sxml#686",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCIE",
        "signature": "youtube_dl.extractor.bbc.BBCIE._extract_from_playlist_sxml(self, url, playlist_id, timestamp)",
        "snippet": "    def _extract_from_playlist_sxml(self, url, playlist_id, timestamp):\n        programme_id, title, description, duration, formats, subtitles = \\\n            self._process_legacy_playlist_url(url, playlist_id)\n        self._sort_formats(formats)\n        return {\n            'id': programme_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 686,
        "end_line": 698,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCIE._real_extract#700",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCIE",
        "signature": "youtube_dl.extractor.bbc.BBCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        timestamp = None\n        playlist_title = None\n        playlist_description = None\n\n        ld = self._parse_json(\n            self._search_regex(\n                r'(?s)<script type=\"application/ld\\+json\">(.+?)</script>',\n                webpage, 'ld json', default='{}'),\n            playlist_id, fatal=False)\n        if ld:\n            timestamp = parse_iso8601(ld.get('datePublished'))\n            playlist_title = ld.get('headline')\n            playlist_description = ld.get('articleBody')\n\n        if not timestamp:\n            timestamp = parse_iso8601(self._search_regex(\n                [r'<meta[^>]+property=\"article:published_time\"[^>]+content=\"([^\"]+)\"',\n                 r'itemprop=\"datePublished\"[^>]+datetime=\"([^\"]+)\"',\n                 r'\"datePublished\":\\s*\"([^\"]+)'],\n                webpage, 'date', default=None))\n\n        entries = []\n\n        # article with multiple videos embedded with playlist.sxml (e.g.\n        # http://www.bbc.com/sport/0/football/34475836)\n        playlists = re.findall(r'<param[^>]+name=\"playlist\"[^>]+value=\"([^\"]+)\"', webpage)\n        if playlists:\n            entries = [\n                self._extract_from_playlist_sxml(playlist_url, playlist_id, timestamp)\n                for playlist_url in playlists]\n\n        # news article with multiple videos embedded with data-playable\n        data_playables = re.findall(r'data-playable=([\"\\'])({.+?})\\1', webpage)\n        if data_playables:\n            for _, data_playable_json in data_playables:\n                data_playable = self._parse_json(\n                    unescapeHTML(data_playable_json), playlist_id, fatal=False)\n                if not data_playable:\n                    continue\n                settings = data_playable.get('settings', {})\n                if settings:\n                    # data-playable with video vpid in settings.playlistObject.items (e.g.\n                    # http://www.bbc.com/news/world-us-canada-34473351)\n                    playlist_object = settings.get('playlistObject', {})\n                    if playlist_object:\n                        items = playlist_object.get('items')\n                        if items and isinstance(items, list):\n                            title = playlist_object['title']\n                            description = playlist_object.get('summary')\n                            duration = int_or_none(items[0].get('duration'))\n                            programme_id = items[0].get('vpid')\n                            formats, subtitles = self._download_media_selector(programme_id)\n                            self._sort_formats(formats)\n                            entries.append({\n                                'id': programme_id,\n                                'title': title,\n                                'description': description,\n                                'timestamp': timestamp,\n                                'duration': duration,\n                                'formats': formats,\n                                'subtitles': subtitles,\n                            })\n                    else:\n                        # data-playable without vpid but with a playlist.sxml URLs\n                        # in otherSettings.playlist (e.g.\n                        # http://www.bbc.com/turkce/multimedya/2015/10/151010_vid_ankara_patlama_ani)\n                        playlist = data_playable.get('otherSettings', {}).get('playlist', {})\n                        if playlist:\n                            entries.append(self._extract_from_playlist_sxml(\n                                playlist.get('progressiveDownloadUrl'), playlist_id, timestamp))\n\n        if entries:\n            playlist_title = playlist_title or remove_end(self._og_search_title(webpage), ' - BBC News')\n            playlist_description = playlist_description or self._og_search_description(webpage, default=None)\n            return self.playlist_result(entries, playlist_id, playlist_title, playlist_description)\n\n        # single video story (e.g. http://www.bbc.com/travel/story/20150625-sri-lankas-spicy-secret)\n        programme_id = self._search_regex(\n            [r'data-video-player-vpid=\"([\\da-z]{8})\"',\n             r'<param[^>]+name=\"externalIdentifier\"[^>]+value=\"([\\da-z]{8})\"'],\n            webpage, 'vpid', default=None)\n\n        if programme_id:\n            formats, subtitles = self._download_media_selector(programme_id)\n            self._sort_formats(formats)\n            # digitalData may be missing (e.g. http://www.bbc.com/autos/story/20130513-hyundais-rock-star)\n            digital_data = self._parse_json(\n                self._search_regex(\n                    r'var\\s+digitalData\\s*=\\s*({.+?});?\\n', webpage, 'digital data', default='{}'),\n                programme_id, fatal=False)\n            page_info = digital_data.get('page', {}).get('pageInfo', {})\n            title = page_info.get('pageName') or self._og_search_title(webpage)\n            description = page_info.get('description') or self._og_search_description(webpage)\n            timestamp = parse_iso8601(page_info.get('publicationDate')) or timestamp\n            return {\n                'id': programme_id,\n                'title': title,\n                'description': description,\n                'timestamp': timestamp,\n                'formats': formats,\n                'subtitles': subtitles,\n            }\n\n        playlist_title = self._html_search_regex(\n            r'<title>(.*?)(?:\\s*-\\s*BBC [^ ]+)?</title>', webpage, 'playlist title')\n        playlist_description = self._og_search_description(webpage, default=None)\n\n        def extract_all(pattern):\n            return list(filter(None, map(\n                lambda s: self._parse_json(s, playlist_id, fatal=False),\n                re.findall(pattern, webpage))))\n\n        # Multiple video article (e.g.\n        # http://www.bbc.co.uk/blogs/adamcurtis/entries/3662a707-0af9-3149-963f-47bea720b460)\n        EMBED_URL = r'https?://(?:www\\.)?bbc\\.co\\.uk/(?:[^/]+/)+[\\da-z]{8}(?:\\b[^\"]+)?'\n        entries = []\n        for match in extract_all(r'new\\s+SMP\\(({.+?})\\)'):\n            embed_url = match.get('playerSettings', {}).get('externalEmbedUrl')\n            if embed_url and re.match(EMBED_URL, embed_url):\n                entries.append(embed_url)\n        entries.extend(re.findall(\n            r'setPlaylist\\(\"(%s)\"\\)' % EMBED_URL, webpage))\n        if entries:\n            return self.playlist_result(\n                [self.url_result(entry, 'BBCCoUk') for entry in entries],\n                playlist_id, playlist_title, playlist_description)\n\n        # Multiple video article (e.g. http://www.bbc.com/news/world-europe-32668511)\n        medias = extract_all(r\"data-media-meta='({[^']+})'\")\n\n        if not medias:\n            # Single video article (e.g. http://www.bbc.com/news/video_and_audio/international)\n            media_asset = self._search_regex(\n                r'mediaAssetPage\\.init\\(\\s*({.+?}), \"/',\n                webpage, 'media asset', default=None)\n            if media_asset:\n                media_asset_page = self._parse_json(media_asset, playlist_id, fatal=False)\n                medias = []\n                for video in media_asset_page.get('videos', {}).values():\n                    medias.extend(video.values())\n\n        if not medias:\n            # Multiple video playlist with single `now playing` entry (e.g.\n            # http://www.bbc.com/news/video_and_audio/must_see/33767813)\n            vxp_playlist = self._parse_json(\n                self._search_regex(\n                    r'<script[^>]+class=\"vxp-playlist-data\"[^>]+type=\"application/json\"[^>]*>([^<]+)</script>',\n                    webpage, 'playlist data'),\n                playlist_id)\n            playlist_medias = []\n            for item in vxp_playlist:\n                media = item.get('media')\n                if not media:\n                    continue\n                playlist_medias.append(media)\n                # Download single video if found media with asset id matching the video id from URL\n                if item.get('advert', {}).get('assetId') == playlist_id:\n                    medias = [media]\n                    break\n            # Fallback to the whole playlist\n            if not medias:\n                medias = playlist_medias\n\n        entries = []\n        for num, media_meta in enumerate(medias, start=1):\n            formats, subtitles = self._extract_from_media_meta(media_meta, playlist_id)\n            if not formats:\n                continue\n            self._sort_formats(formats)\n\n            video_id = media_meta.get('externalId')\n            if not video_id:\n                video_id = playlist_id if len(medias) == 1 else '%s-%s' % (playlist_id, num)\n\n            title = media_meta.get('caption')\n            if not title:\n                title = playlist_title if len(medias) == 1 else '%s - Video %s' % (playlist_title, num)\n\n            duration = int_or_none(media_meta.get('durationInSeconds')) or parse_duration(media_meta.get('duration'))\n\n            images = []\n            for image in media_meta.get('images', {}).values():\n                images.extend(image.values())\n            if 'image' in media_meta:\n                images.append(media_meta['image'])\n\n            thumbnails = [{\n                'url': image.get('href'),\n                'width': int_or_none(image.get('width')),\n                'height': int_or_none(image.get('height')),\n            } for image in images]\n\n            entries.append({\n                'id': video_id,\n                'title': title,\n                'thumbnails': thumbnails,\n                'duration': duration,\n                'timestamp': timestamp,\n                'formats': formats,\n                'subtitles': subtitles,\n            })\n\n        return self.playlist_result(entries, playlist_id, playlist_title, playlist_description)",
        "begin_line": 700,
        "end_line": 907,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkArticleIE._real_extract#926",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkArticleIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage).strip()\n\n        entries = [self.url_result(programme_url) for programme_url in re.findall(\n            r'<div[^>]+typeof=\"Clip\"[^>]+resource=\"([^\"]+)\"', webpage)]\n\n        return self.playlist_result(entries, playlist_id, title, description)",
        "begin_line": 926,
        "end_line": 937,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.m6.M6IE._real_extract#25",
        "src_path": "youtube_dl/extractor/m6.py",
        "class_name": "youtube_dl.extractor.m6.M6IE",
        "signature": "youtube_dl.extractor.m6.M6IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        rss = self._download_xml('http://ws.m6.fr/v1/video/info/m6/bonus/%s' % video_id, video_id,\n                                 'Downloading video RSS')\n\n        title = rss.find('./channel/item/title').text\n        description = rss.find('./channel/item/description').text\n        thumbnail = rss.find('./channel/item/visuel_clip_big').text\n        duration = int(rss.find('./channel/item/duration').text)\n        view_count = int(rss.find('./channel/item/nombre_vues').text)\n\n        formats = []\n        for format_id in ['lq', 'sd', 'hq', 'hd']:\n            video_url = rss.find('./channel/item/url_video_%s' % format_id)\n            if video_url is None:\n                continue\n            formats.append({\n                'url': video_url.text,\n                'format_id': format_id,\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.__init__#33",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        PostProcessor.__init__(self, downloader)\n        self._determine_executables()",
        "begin_line": 33,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.check_version#37",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.check_version(self)",
        "snippet": "    def check_version(self):\n        if not self.available:\n            raise FFmpegPostProcessorError('ffmpeg or avconv not found. Please install one.')\n\n        required_version = '10-0' if self.basename == 'avconv' else '1.0'\n        if is_outdated_version(\n                self._versions[self.basename], required_version):\n            warning = 'Your copy of %s is outdated, update %s to version %s or newer if you encounter any errors.' % (\n                self.basename, self.basename, required_version)\n            if self._downloader:\n                self._downloader.report_warning(warning)",
        "begin_line": 37,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.get_versions#50",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.get_versions(downloader=None)",
        "snippet": "    def get_versions(downloader=None):\n        return FFmpegPostProcessor(downloader)._versions",
        "begin_line": 50,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._determine_executables#53",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._determine_executables(self)",
        "snippet": "    def _determine_executables(self):\n        programs = ['avprobe', 'avconv', 'ffmpeg', 'ffprobe']\n        prefer_ffmpeg = self._downloader.params.get('prefer_ffmpeg', False)\n\n        self.basename = None\n        self.probe_basename = None\n\n        self._paths = None\n        self._versions = None\n        if self._downloader:\n            location = self._downloader.params.get('ffmpeg_location')\n            if location is not None:\n                if not os.path.exists(location):\n                    self._downloader.report_warning(\n                        'ffmpeg-location %s does not exist! '\n                        'Continuing without avconv/ffmpeg.' % (location))\n                    self._versions = {}\n                    return\n                elif not os.path.isdir(location):\n                    basename = os.path.splitext(os.path.basename(location))[0]\n                    if basename not in programs:\n                        self._downloader.report_warning(\n                            'Cannot identify executable %s, its basename should be one of %s. '\n                            'Continuing without avconv/ffmpeg.' %\n                            (location, ', '.join(programs)))\n                        self._versions = {}\n                        return None\n                    location = os.path.dirname(os.path.abspath(location))\n                    if basename in ('ffmpeg', 'ffprobe'):\n                        prefer_ffmpeg = True\n\n                self._paths = dict(\n                    (p, os.path.join(location, p)) for p in programs)\n                self._versions = dict(\n                    (p, get_exe_version(self._paths[p], args=['-version']))\n                    for p in programs)\n        if self._versions is None:\n            self._versions = dict(\n                (p, get_exe_version(p, args=['-version'])) for p in programs)\n            self._paths = dict((p, p) for p in programs)\n\n        if prefer_ffmpeg:\n            prefs = ('ffmpeg', 'avconv')\n        else:\n            prefs = ('avconv', 'ffmpeg')\n        for p in prefs:\n            if self._versions[p]:\n                self.basename = p\n                break\n\n        if prefer_ffmpeg:\n            prefs = ('ffprobe', 'avprobe')\n        else:\n            prefs = ('avprobe', 'ffprobe')\n        for p in prefs:\n            if self._versions[p]:\n                self.probe_basename = p\n                break",
        "begin_line": 53,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.available#113",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.available(self)",
        "snippet": "    def available(self):\n        return self.basename is not None",
        "begin_line": 113,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.executable#117",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.executable(self)",
        "snippet": "    def executable(self):\n        return self._paths[self.basename]",
        "begin_line": 117,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.probe_available#121",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.probe_available(self)",
        "snippet": "    def probe_available(self):\n        return self.probe_basename is not None",
        "begin_line": 121,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.probe_executable#125",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.probe_executable(self)",
        "snippet": "    def probe_executable(self):\n        return self._paths[self.probe_basename]",
        "begin_line": 125,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg_multiple_files#128",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg_multiple_files(self, input_paths, out_path, opts)",
        "snippet": "    def run_ffmpeg_multiple_files(self, input_paths, out_path, opts):\n        self.check_version()\n\n        oldest_mtime = min(\n            os.stat(encodeFilename(path)).st_mtime for path in input_paths)\n\n        opts += self._configuration_args()\n\n        files_cmd = []\n        for path in input_paths:\n            files_cmd.extend([\n                encodeArgument('-i'),\n                encodeFilename(self._ffmpeg_filename_argument(path), True)\n            ])\n        cmd = ([encodeFilename(self.executable, True), encodeArgument('-y')] +\n               files_cmd +\n               [encodeArgument(o) for o in opts] +\n               [encodeFilename(self._ffmpeg_filename_argument(out_path), True)])\n\n        if self._downloader.params.get('verbose', False):\n            self._downloader.to_screen('[debug] ffmpeg command line: %s' % shell_quote(cmd))\n        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n        stdout, stderr = p.communicate()\n        if p.returncode != 0:\n            stderr = stderr.decode('utf-8', 'replace')\n            msg = stderr.strip().split('\\n')[-1]\n            raise FFmpegPostProcessorError(msg)\n        self.try_utime(out_path, oldest_mtime, oldest_mtime)",
        "begin_line": 128,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg#157",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg(self, path, out_path, opts)",
        "snippet": "    def run_ffmpeg(self, path, out_path, opts):\n        self.run_ffmpeg_multiple_files([path], out_path, opts)",
        "begin_line": 157,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._ffmpeg_filename_argument#160",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._ffmpeg_filename_argument(self, fn)",
        "snippet": "    def _ffmpeg_filename_argument(self, fn):\n        # Always use 'file:' because the filename may contain ':' (ffmpeg\n        # interprets that as a protocol) or can start with '-' (-- is broken in\n        # ffmpeg, see https://ffmpeg.org/trac/ffmpeg/ticket/2127 for details)\n        return 'file:' + fn",
        "begin_line": 160,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.__init__#168",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.__init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False)",
        "snippet": "    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False):\n        FFmpegPostProcessor.__init__(self, downloader)\n        if preferredcodec is None:\n            preferredcodec = 'best'\n        self._preferredcodec = preferredcodec\n        self._preferredquality = preferredquality\n        self._nopostoverwrites = nopostoverwrites",
        "begin_line": 168,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.get_audio_codec#176",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.get_audio_codec(self, path)",
        "snippet": "    def get_audio_codec(self, path):\n\n        if not self.probe_available:\n            raise PostProcessingError('ffprobe or avprobe not found. Please install one.')\n        try:\n            cmd = [\n                encodeFilename(self.probe_executable, True),\n                encodeArgument('-show_streams'),\n                encodeFilename(self._ffmpeg_filename_argument(path), True)]\n            if self._downloader.params.get('verbose', False):\n                self._downloader.to_screen('[debug] %s command line: %s' % (self.basename, shell_quote(cmd)))\n            handle = subprocess.Popen(cmd, stderr=compat_subprocess_get_DEVNULL(), stdout=subprocess.PIPE, stdin=subprocess.PIPE)\n            output = handle.communicate()[0]\n            if handle.wait() != 0:\n                return None\n        except (IOError, OSError):\n            return None\n        audio_codec = None\n        for line in output.decode('ascii', 'ignore').split('\\n'):\n            if line.startswith('codec_name='):\n                audio_codec = line.split('=')[1].strip()\n            elif line.strip() == 'codec_type=audio' and audio_codec is not None:\n                return audio_codec\n        return None",
        "begin_line": 176,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run_ffmpeg#201",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run_ffmpeg(self, path, out_path, codec, more_opts)",
        "snippet": "    def run_ffmpeg(self, path, out_path, codec, more_opts):\n        if codec is None:\n            acodec_opts = []\n        else:\n            acodec_opts = ['-acodec', codec]\n        opts = ['-vn'] + acodec_opts + more_opts\n        try:\n            FFmpegPostProcessor.run_ffmpeg(self, path, out_path, opts)\n        except FFmpegPostProcessorError as err:\n            raise AudioConversionError(err.msg)",
        "begin_line": 201,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run#212",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run(self, information)",
        "snippet": "    def run(self, information):\n        path = information['filepath']\n\n        filecodec = self.get_audio_codec(path)\n        if filecodec is None:\n            raise PostProcessingError('WARNING: unable to obtain file audio codec with ffprobe')\n\n        more_opts = []\n        if self._preferredcodec == 'best' or self._preferredcodec == filecodec or (self._preferredcodec == 'm4a' and filecodec == 'aac'):\n            if filecodec == 'aac' and self._preferredcodec in ['m4a', 'best']:\n                # Lossless, but in another container\n                acodec = 'copy'\n                extension = 'm4a'\n                more_opts = ['-bsf:a', 'aac_adtstoasc']\n            elif filecodec in ['aac', 'mp3', 'vorbis', 'opus']:\n                # Lossless if possible\n                acodec = 'copy'\n                extension = filecodec\n                if filecodec == 'aac':\n                    more_opts = ['-f', 'adts']\n                if filecodec == 'vorbis':\n                    extension = 'ogg'\n            else:\n                # MP3 otherwise.\n                acodec = 'libmp3lame'\n                extension = 'mp3'\n                more_opts = []\n                if self._preferredquality is not None:\n                    if int(self._preferredquality) < 10:\n                        more_opts += ['-q:a', self._preferredquality]\n                    else:\n                        more_opts += ['-b:a', self._preferredquality + 'k']\n        else:\n            # We convert the audio (lossy)\n            acodec = {'mp3': 'libmp3lame', 'aac': 'aac', 'm4a': 'aac', 'opus': 'opus', 'vorbis': 'libvorbis', 'wav': None}[self._preferredcodec]\n            extension = self._preferredcodec\n            more_opts = []\n            if self._preferredquality is not None:\n                # The opus codec doesn't support the -aq option\n                if int(self._preferredquality) < 10 and extension != 'opus':\n                    more_opts += ['-q:a', self._preferredquality]\n                else:\n                    more_opts += ['-b:a', self._preferredquality + 'k']\n            if self._preferredcodec == 'aac':\n                more_opts += ['-f', 'adts']\n            if self._preferredcodec == 'm4a':\n                more_opts += ['-bsf:a', 'aac_adtstoasc']\n            if self._preferredcodec == 'vorbis':\n                extension = 'ogg'\n            if self._preferredcodec == 'wav':\n                extension = 'wav'\n                more_opts += ['-f', 'wav']\n\n        prefix, sep, ext = path.rpartition('.')  # not os.path.splitext, since the latter does not work on unicode in all setups\n        new_path = prefix + sep + extension\n\n        # If we download foo.mp3 and convert it to... foo.mp3, then don't delete foo.mp3, silly.\n        if (new_path == path or\n                (self._nopostoverwrites and os.path.exists(encodeFilename(new_path)))):\n            self._downloader.to_screen('[ffmpeg] Post-process file %s exists, skipping' % new_path)\n            return [], information\n\n        try:\n            self._downloader.to_screen('[' + self.basename + '] Destination: ' + new_path)\n            self.run_ffmpeg(path, new_path, acodec, more_opts)\n        except AudioConversionError as e:\n            raise PostProcessingError(\n                'audio conversion failed: ' + e.msg)\n        except Exception:\n            raise PostProcessingError('error running ' + self.basename)\n\n        # Try to update the date time for extracted audio file.\n        if information.get('filetime') is not None:\n            self.try_utime(\n                new_path, time.time(), information['filetime'],\n                errnote='Cannot update utime of audio file')\n\n        information['filepath'] = new_path\n        information['ext'] = extension\n\n        return [path], information",
        "begin_line": 212,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP.__init__#296",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP.__init__(self, downloader=None, preferedformat=None)",
        "snippet": "    def __init__(self, downloader=None, preferedformat=None):\n        super(FFmpegVideoConvertorPP, self).__init__(downloader)\n        self._preferedformat = preferedformat",
        "begin_line": 296,
        "end_line": 298,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP.run#300",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP.run(self, information)",
        "snippet": "    def run(self, information):\n        path = information['filepath']\n        if information['ext'] == self._preferedformat:\n            self._downloader.to_screen('[ffmpeg] Not converting video file %s - already is in target format %s' % (path, self._preferedformat))\n            return [], information\n        options = []\n        if self._preferedformat == 'avi':\n            options.extend(['-c:v', 'libxvid', '-vtag', 'XVID'])\n        prefix, sep, ext = path.rpartition('.')\n        outpath = prefix + sep + self._preferedformat\n        self._downloader.to_screen('[' + 'ffmpeg' + '] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) + outpath)\n        self.run_ffmpeg(path, outpath, options)\n        information['filepath'] = outpath\n        information['format'] = self._preferedformat\n        information['ext'] = self._preferedformat\n        return [path], information",
        "begin_line": 300,
        "end_line": 315,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.run#319",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.run(self, information)",
        "snippet": "    def run(self, information):\n        if information['ext'] not in ['mp4', 'mkv']:\n            self._downloader.to_screen('[ffmpeg] Subtitles can only be embedded in mp4 or mkv files')\n            return [], information\n        subtitles = information.get('requested_subtitles')\n        if not subtitles:\n            self._downloader.to_screen('[ffmpeg] There aren\\'t any subtitles to embed')\n            return [], information\n\n        sub_langs = list(subtitles.keys())\n        filename = information['filepath']\n        sub_filenames = [subtitles_filename(filename, lang, sub_info['ext']) for lang, sub_info in subtitles.items()]\n        input_files = [filename] + sub_filenames\n\n        opts = [\n            '-map', '0',\n            '-c', 'copy',\n            # Don't copy the existing subtitles, we may be running the\n            # postprocessor a second time\n            '-map', '-0:s',\n        ]\n        if information['ext'] == 'mp4':\n            opts += ['-c:s', 'mov_text']\n        for (i, lang) in enumerate(sub_langs):\n            opts.extend(['-map', '%d:0' % (i + 1)])\n            lang_code = ISO639Utils.short2long(lang)\n            if lang_code is not None:\n                opts.extend(['-metadata:s:s:%d' % i, 'language=%s' % lang_code])\n\n        temp_filename = prepend_extension(filename, 'temp')\n        self._downloader.to_screen('[ffmpeg] Embedding subtitles in \\'%s\\'' % filename)\n        self.run_ffmpeg_multiple_files(input_files, temp_filename, opts)\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return sub_filenames, information",
        "begin_line": 319,
        "end_line": 354,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP.run#358",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP.run(self, info)",
        "snippet": "    def run(self, info):\n        metadata = {}\n        if info.get('title') is not None:\n            metadata['title'] = info['title']\n        if info.get('upload_date') is not None:\n            metadata['date'] = info['upload_date']\n        if info.get('artist') is not None:\n            metadata['artist'] = info['artist']\n        elif info.get('uploader') is not None:\n            metadata['artist'] = info['uploader']\n        elif info.get('uploader_id') is not None:\n            metadata['artist'] = info['uploader_id']\n        if info.get('description') is not None:\n            metadata['description'] = info['description']\n            metadata['comment'] = info['description']\n        if info.get('webpage_url') is not None:\n            metadata['purl'] = info['webpage_url']\n        if info.get('album') is not None:\n            metadata['album'] = info['album']\n\n        if not metadata:\n            self._downloader.to_screen('[ffmpeg] There isn\\'t any metadata to add')\n            return [], info\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        if info['ext'] == 'm4a':\n            options = ['-vn', '-acodec', 'copy']\n        else:\n            options = ['-c', 'copy']\n\n        for (name, value) in metadata.items():\n            options.extend(['-metadata', '%s=%s' % (name, value)])\n\n        self._downloader.to_screen('[ffmpeg] Adding metadata to \\'%s\\'' % filename)\n        self.run_ffmpeg(filename, temp_filename, options)\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n        return [], info",
        "begin_line": 358,
        "end_line": 397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.run#401",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.run(self, info)",
        "snippet": "    def run(self, info):\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n        args = ['-c', 'copy', '-map', '0:v:0', '-map', '1:a:0']\n        self._downloader.to_screen('[ffmpeg] Merging formats into \"%s\"' % filename)\n        self.run_ffmpeg_multiple_files(info['__files_to_merge'], temp_filename, args)\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n        return info['__files_to_merge'], info",
        "begin_line": 401,
        "end_line": 408,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.can_merge#410",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.can_merge(self)",
        "snippet": "    def can_merge(self):\n        # TODO: figure out merge-capable ffmpeg version\n        if self.basename != 'avconv':\n            return True\n\n        required_version = '10-0'\n        if is_outdated_version(\n                self._versions[self.basename], required_version):\n            warning = ('Your copy of %s is outdated and unable to properly mux separate video and audio files, '\n                       'youtube-dl will download single file media. '\n                       'Update %s to version %s or newer to fix this.') % (\n                           self.basename, self.basename, required_version)\n            if self._downloader:\n                self._downloader.report_warning(warning)\n            return False\n        return True",
        "begin_line": 410,
        "end_line": 425,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupStretchedPP.run#429",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupStretchedPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupStretchedPP.run(self, info)",
        "snippet": "    def run(self, info):\n        stretched_ratio = info.get('stretched_ratio')\n        if stretched_ratio is None or stretched_ratio == 1:\n            return [], info\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        options = ['-c', 'copy', '-aspect', '%f' % stretched_ratio]\n        self._downloader.to_screen('[ffmpeg] Fixing aspect ratio in \"%s\"' % filename)\n        self.run_ffmpeg(filename, temp_filename, options)\n\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return [], info",
        "begin_line": 429,
        "end_line": 444,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupM4aPP.run#448",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupM4aPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupM4aPP.run(self, info)",
        "snippet": "    def run(self, info):\n        if info.get('container') != 'm4a_dash':\n            return [], info\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        options = ['-c', 'copy', '-f', 'mp4']\n        self._downloader.to_screen('[ffmpeg] Correcting container in \"%s\"' % filename)\n        self.run_ffmpeg(filename, temp_filename, options)\n\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return [], info",
        "begin_line": 448,
        "end_line": 462,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP.__init__#466",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP.__init__(self, downloader=None, format=None)",
        "snippet": "    def __init__(self, downloader=None, format=None):\n        super(FFmpegSubtitlesConvertorPP, self).__init__(downloader)\n        self.format = format",
        "begin_line": 466,
        "end_line": 468,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP.run#470",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP.run(self, info)",
        "snippet": "    def run(self, info):\n        subs = info.get('requested_subtitles')\n        filename = info['filepath']\n        new_ext = self.format\n        new_format = new_ext\n        if new_format == 'vtt':\n            new_format = 'webvtt'\n        if subs is None:\n            self._downloader.to_screen('[ffmpeg] There aren\\'t any subtitles to convert')\n            return [], info\n        self._downloader.to_screen('[ffmpeg] Converting subtitles')\n        for lang, sub in subs.items():\n            ext = sub['ext']\n            if ext == new_ext:\n                self._downloader.to_screen(\n                    '[ffmpeg] Subtitle file for %s is already in the requested'\n                    'format' % new_ext)\n                continue\n            new_file = subtitles_filename(filename, lang, new_ext)\n\n            if ext == 'dfxp' or ext == 'ttml':\n                self._downloader.report_warning(\n                    'You have requested to convert dfxp (TTML) subtitles into another format, '\n                    'which results in style information loss')\n\n                dfxp_file = subtitles_filename(filename, lang, ext)\n                srt_file = subtitles_filename(filename, lang, 'srt')\n\n                with io.open(dfxp_file, 'rt', encoding='utf-8') as f:\n                    srt_data = dfxp2srt(f.read())\n\n                with io.open(srt_file, 'wt', encoding='utf-8') as f:\n                    f.write(srt_data)\n\n                ext = 'srt'\n                subs[lang] = {\n                    'ext': 'srt',\n                    'data': srt_data\n                }\n\n                if new_ext == 'srt':\n                    continue\n\n            self.run_ffmpeg(\n                subtitles_filename(filename, lang, ext),\n                new_file, ['-f', new_format])\n\n            with io.open(new_file, 'rt', encoding='utf-8') as f:\n                subs[lang] = {\n                    'ext': ext,\n                    'data': f.read(),\n                }\n\n        return [], info",
        "begin_line": 470,
        "end_line": 523,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.__init__#98",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.__init__(self)",
        "snippet": "        def __init__(self):\n            pass",
        "begin_line": 98,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.JSArray.__getitem__#102",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.JSArray",
        "signature": "youtube_dl.extractor.globo.JSArray.__getitem__(self, y)",
        "snippet": "            def __getitem__(self, y):\n                try:\n                    return list.__getitem__(self, y)\n                except IndexError:\n                    return 0",
        "begin_line": 102,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.JSArray.__setitem__#108",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.JSArray",
        "signature": "youtube_dl.extractor.globo.JSArray.__setitem__(self, i, y)",
        "snippet": "            def __setitem__(self, i, y):\n                try:\n                    return list.__setitem__(self, i, y)\n                except IndexError:\n                    self.extend([0] * (i - len(self) + 1))\n                    self[-1] = y",
        "begin_line": 108,
        "end_line": 113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.hex_md5#116",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.hex_md5(cls, param1)",
        "snippet": "        def hex_md5(cls, param1):\n            return cls.rstr2hex(cls.rstr_md5(cls.str2rstr_utf8(param1)))",
        "begin_line": 116,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.b64_md5#120",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.b64_md5(cls, param1, param2=None)",
        "snippet": "        def b64_md5(cls, param1, param2=None):\n            return cls.rstr2b64(cls.rstr_md5(cls.str2rstr_utf8(param1, param2)))",
        "begin_line": 120,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.any_md5#124",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.any_md5(cls, param1, param2)",
        "snippet": "        def any_md5(cls, param1, param2):\n            return cls.rstr2any(cls.rstr_md5(cls.str2rstr_utf8(param1)), param2)",
        "begin_line": 124,
        "end_line": 125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.rstr_md5#128",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.rstr_md5(cls, param1)",
        "snippet": "        def rstr_md5(cls, param1):\n            return cls.binl2rstr(cls.binl_md5(cls.rstr2binl(param1), len(param1) * 8))",
        "begin_line": 128,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.rstr2hex#132",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.rstr2hex(cls, param1)",
        "snippet": "        def rstr2hex(cls, param1):\n            _loc_2 = '0123456789ABCDEF' if cls.hexcase else '0123456789abcdef'\n            _loc_3 = ''\n            for _loc_5 in range(0, len(param1)):\n                _loc_4 = compat_ord(param1[_loc_5])\n                _loc_3 += _loc_2[_loc_4 >> 4 & 15] + _loc_2[_loc_4 & 15]\n            return _loc_3",
        "begin_line": 132,
        "end_line": 138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.rstr2b64#141",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.rstr2b64(cls, param1)",
        "snippet": "        def rstr2b64(cls, param1):\n            _loc_2 = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'\n            _loc_3 = ''\n            _loc_4 = len(param1)\n            for _loc_5 in range(0, _loc_4, 3):\n                _loc_6_1 = compat_ord(param1[_loc_5]) << 16\n                _loc_6_2 = compat_ord(param1[_loc_5 + 1]) << 8 if _loc_5 + 1 < _loc_4 else 0\n                _loc_6_3 = compat_ord(param1[_loc_5 + 2]) if _loc_5 + 2 < _loc_4 else 0\n                _loc_6 = _loc_6_1 | _loc_6_2 | _loc_6_3\n                for _loc_7 in range(0, 4):\n                    if _loc_5 * 8 + _loc_7 * 6 > len(param1) * 8:\n                        _loc_3 += cls.b64pad\n                    else:\n                        _loc_3 += _loc_2[_loc_6 >> 6 * (3 - _loc_7) & 63]\n            return _loc_3",
        "begin_line": 141,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.rstr2any#158",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.rstr2any(param1, param2)",
        "snippet": "        def rstr2any(param1, param2):\n            _loc_3 = len(param2)\n            _loc_4 = []\n            _loc_9 = [0] * ((len(param1) >> 2) + 1)\n            for _loc_5 in range(0, len(_loc_9)):\n                _loc_9[_loc_5] = compat_ord(param1[_loc_5 * 2]) << 8 | compat_ord(param1[_loc_5 * 2 + 1])\n\n            while len(_loc_9) > 0:\n                _loc_8 = []\n                _loc_7 = 0\n                for _loc_5 in range(0, len(_loc_9)):\n                    _loc_7 = (_loc_7 << 16) + _loc_9[_loc_5]\n                    _loc_6 = math.floor(_loc_7 / _loc_3)\n                    _loc_7 -= _loc_6 * _loc_3\n                    if len(_loc_8) > 0 or _loc_6 > 0:\n                        _loc_8[len(_loc_8)] = _loc_6\n\n                _loc_4[len(_loc_4)] = _loc_7\n                _loc_9 = _loc_8\n\n            _loc_10 = ''\n            _loc_5 = len(_loc_4) - 1\n            while _loc_5 >= 0:\n                _loc_10 += param2[_loc_4[_loc_5]]\n                _loc_5 -= 1\n\n            return _loc_10",
        "begin_line": 158,
        "end_line": 184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.str2rstr_utf8#187",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.str2rstr_utf8(cls, param1, param2=None)",
        "snippet": "        def str2rstr_utf8(cls, param1, param2=None):\n            _loc_3 = ''\n            _loc_4 = -1\n            if not param2:\n                param2 = cls.PADDING\n            param1 = param1 + param2[1:9]\n            while True:\n                _loc_4 += 1\n                if _loc_4 >= len(param1):\n                    break\n                _loc_5 = compat_ord(param1[_loc_4])\n                _loc_6 = compat_ord(param1[_loc_4 + 1]) if _loc_4 + 1 < len(param1) else 0\n                if 55296 <= _loc_5 <= 56319 and 56320 <= _loc_6 <= 57343:\n                    _loc_5 = 65536 + ((_loc_5 & 1023) << 10) + (_loc_6 & 1023)\n                    _loc_4 += 1\n                if _loc_5 <= 127:\n                    _loc_3 += compat_chr(_loc_5)\n                    continue\n                if _loc_5 <= 2047:\n                    _loc_3 += compat_chr(192 | _loc_5 >> 6 & 31) + compat_chr(128 | _loc_5 & 63)\n                    continue\n                if _loc_5 <= 65535:\n                    _loc_3 += compat_chr(224 | _loc_5 >> 12 & 15) + compat_chr(128 | _loc_5 >> 6 & 63) + compat_chr(\n                        128 | _loc_5 & 63)\n                    continue\n                if _loc_5 <= 2097151:\n                    _loc_3 += compat_chr(240 | _loc_5 >> 18 & 7) + compat_chr(128 | _loc_5 >> 12 & 63) + compat_chr(\n                        128 | _loc_5 >> 6 & 63) + compat_chr(128 | _loc_5 & 63)\n            return _loc_3",
        "begin_line": 187,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.rstr2binl#218",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.rstr2binl(param1)",
        "snippet": "        def rstr2binl(param1):\n            _loc_2 = [0] * ((len(param1) >> 2) + 1)\n            for _loc_3 in range(0, len(_loc_2)):\n                _loc_2[_loc_3] = 0\n            for _loc_3 in range(0, len(param1) * 8, 8):\n                _loc_2[_loc_3 >> 5] |= (compat_ord(param1[_loc_3 // 8]) & 255) << _loc_3 % 32\n            return _loc_2",
        "begin_line": 218,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.binl2rstr#227",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.binl2rstr(param1)",
        "snippet": "        def binl2rstr(param1):\n            _loc_2 = ''\n            for _loc_3 in range(0, len(param1) * 32, 8):\n                _loc_2 += compat_chr(param1[_loc_3 >> 5] >> _loc_3 % 32 & 255)\n            return _loc_2",
        "begin_line": 227,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.binl_md5#234",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.binl_md5(cls, param1, param2)",
        "snippet": "        def binl_md5(cls, param1, param2):\n            param1 = cls.JSArray(param1)\n            param1[param2 >> 5] |= 128 << param2 % 32\n            param1[(param2 + 64 >> 9 << 4) + 14] = param2\n            _loc_3 = 1732584193\n            _loc_4 = -271733879\n            _loc_5 = -1732584194\n            _loc_6 = 271733878\n            for _loc_7 in range(0, len(param1), 16):\n                _loc_8 = _loc_3\n                _loc_9 = _loc_4\n                _loc_10 = _loc_5\n                _loc_11 = _loc_6\n                _loc_3 = cls.md5_ff(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 0], 7, -680876936)\n                _loc_6 = cls.md5_ff(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 1], 12, -389564586)\n                _loc_5 = cls.md5_ff(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 2], 17, 606105819)\n                _loc_4 = cls.md5_ff(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 3], 22, -1044525330)\n                _loc_3 = cls.md5_ff(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 4], 7, -176418897)\n                _loc_6 = cls.md5_ff(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 5], 12, 1200080426)\n                _loc_5 = cls.md5_ff(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 6], 17, -1473231341)\n                _loc_4 = cls.md5_ff(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 7], 22, -45705983)\n                _loc_3 = cls.md5_ff(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 8], 7, 1770035416)\n                _loc_6 = cls.md5_ff(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 9], 12, -1958414417)\n                _loc_5 = cls.md5_ff(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 10], 17, -42063)\n                _loc_4 = cls.md5_ff(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 11], 22, -1990404162)\n                _loc_3 = cls.md5_ff(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 12], 7, 1804603682)\n                _loc_6 = cls.md5_ff(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 13], 12, -40341101)\n                _loc_5 = cls.md5_ff(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 14], 17, -1502002290)\n                _loc_4 = cls.md5_ff(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 15], 22, 1236535329)\n                _loc_3 = cls.md5_gg(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 1], 5, -165796510)\n                _loc_6 = cls.md5_gg(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 6], 9, -1069501632)\n                _loc_5 = cls.md5_gg(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 11], 14, 643717713)\n                _loc_4 = cls.md5_gg(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 0], 20, -373897302)\n                _loc_3 = cls.md5_gg(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 5], 5, -701558691)\n                _loc_6 = cls.md5_gg(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 10], 9, 38016083)\n                _loc_5 = cls.md5_gg(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 15], 14, -660478335)\n                _loc_4 = cls.md5_gg(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 4], 20, -405537848)\n                _loc_3 = cls.md5_gg(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 9], 5, 568446438)\n                _loc_6 = cls.md5_gg(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 14], 9, -1019803690)\n                _loc_5 = cls.md5_gg(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 3], 14, -187363961)\n                _loc_4 = cls.md5_gg(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 8], 20, 1163531501)\n                _loc_3 = cls.md5_gg(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 13], 5, -1444681467)\n                _loc_6 = cls.md5_gg(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 2], 9, -51403784)\n                _loc_5 = cls.md5_gg(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 7], 14, 1735328473)\n                _loc_4 = cls.md5_gg(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 12], 20, -1926607734)\n                _loc_3 = cls.md5_hh(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 5], 4, -378558)\n                _loc_6 = cls.md5_hh(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 8], 11, -2022574463)\n                _loc_5 = cls.md5_hh(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 11], 16, 1839030562)\n                _loc_4 = cls.md5_hh(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 14], 23, -35309556)\n                _loc_3 = cls.md5_hh(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 1], 4, -1530992060)\n                _loc_6 = cls.md5_hh(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 4], 11, 1272893353)\n                _loc_5 = cls.md5_hh(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 7], 16, -155497632)\n                _loc_4 = cls.md5_hh(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 10], 23, -1094730640)\n                _loc_3 = cls.md5_hh(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 13], 4, 681279174)\n                _loc_6 = cls.md5_hh(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 0], 11, -358537222)\n                _loc_5 = cls.md5_hh(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 3], 16, -722521979)\n                _loc_4 = cls.md5_hh(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 6], 23, 76029189)\n                _loc_3 = cls.md5_hh(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 9], 4, -640364487)\n                _loc_6 = cls.md5_hh(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 12], 11, -421815835)\n                _loc_5 = cls.md5_hh(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 15], 16, 530742520)\n                _loc_4 = cls.md5_hh(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 2], 23, -995338651)\n                _loc_3 = cls.md5_ii(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 0], 6, -198630844)\n                _loc_6 = cls.md5_ii(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 7], 10, 1126891415)\n                _loc_5 = cls.md5_ii(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 14], 15, -1416354905)\n                _loc_4 = cls.md5_ii(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 5], 21, -57434055)\n                _loc_3 = cls.md5_ii(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 12], 6, 1700485571)\n                _loc_6 = cls.md5_ii(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 3], 10, -1894986606)\n                _loc_5 = cls.md5_ii(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 10], 15, -1051523)\n                _loc_4 = cls.md5_ii(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 1], 21, -2054922799)\n                _loc_3 = cls.md5_ii(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 8], 6, 1873313359)\n                _loc_6 = cls.md5_ii(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 15], 10, -30611744)\n                _loc_5 = cls.md5_ii(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 6], 15, -1560198380)\n                _loc_4 = cls.md5_ii(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 13], 21, 1309151649)\n                _loc_3 = cls.md5_ii(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 4], 6, -145523070)\n                _loc_6 = cls.md5_ii(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 11], 10, -1120210379)\n                _loc_5 = cls.md5_ii(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 2], 15, 718787259)\n                _loc_4 = cls.md5_ii(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 9], 21, -343485551)\n                _loc_3 = cls.safe_add(_loc_3, _loc_8)\n                _loc_4 = cls.safe_add(_loc_4, _loc_9)\n                _loc_5 = cls.safe_add(_loc_5, _loc_10)\n                _loc_6 = cls.safe_add(_loc_6, _loc_11)\n            return [_loc_3, _loc_4, _loc_5, _loc_6]",
        "begin_line": 234,
        "end_line": 315,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.md5_cmn#318",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.md5_cmn(cls, param1, param2, param3, param4, param5, param6)",
        "snippet": "        def md5_cmn(cls, param1, param2, param3, param4, param5, param6):\n            return cls.safe_add(\n                cls.bit_rol(cls.safe_add(cls.safe_add(param2, param1), cls.safe_add(param4, param6)), param5), param3)",
        "begin_line": 318,
        "end_line": 320,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.md5_ff#323",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.md5_ff(cls, param1, param2, param3, param4, param5, param6, param7)",
        "snippet": "        def md5_ff(cls, param1, param2, param3, param4, param5, param6, param7):\n            return cls.md5_cmn(param2 & param3 | ~param2 & param4, param1, param2, param5, param6, param7)",
        "begin_line": 323,
        "end_line": 324,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.md5_gg#327",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.md5_gg(cls, param1, param2, param3, param4, param5, param6, param7)",
        "snippet": "        def md5_gg(cls, param1, param2, param3, param4, param5, param6, param7):\n            return cls.md5_cmn(param2 & param4 | param3 & ~param4, param1, param2, param5, param6, param7)",
        "begin_line": 327,
        "end_line": 328,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.md5_hh#331",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.md5_hh(cls, param1, param2, param3, param4, param5, param6, param7)",
        "snippet": "        def md5_hh(cls, param1, param2, param3, param4, param5, param6, param7):\n            return cls.md5_cmn(param2 ^ param3 ^ param4, param1, param2, param5, param6, param7)",
        "begin_line": 331,
        "end_line": 332,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.md5_ii#335",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.md5_ii(cls, param1, param2, param3, param4, param5, param6, param7)",
        "snippet": "        def md5_ii(cls, param1, param2, param3, param4, param5, param6, param7):\n            return cls.md5_cmn(param3 ^ (param2 | ~param4), param1, param2, param5, param6, param7)",
        "begin_line": 335,
        "end_line": 336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.safe_add#339",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.safe_add(cls, param1, param2)",
        "snippet": "        def safe_add(cls, param1, param2):\n            _loc_3 = (param1 & 65535) + (param2 & 65535)\n            _loc_4 = (param1 >> 16) + (param2 >> 16) + (_loc_3 >> 16)\n            return cls.lshift(_loc_4, 16) | _loc_3 & 65535",
        "begin_line": 339,
        "end_line": 342,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.bit_rol#345",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.bit_rol(cls, param1, param2)",
        "snippet": "        def bit_rol(cls, param1, param2):\n            return cls.lshift(param1, param2) | (param1 & 0xFFFFFFFF) >> (32 - param2)",
        "begin_line": 345,
        "end_line": 346,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.lshift#349",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.lshift(value, count)",
        "snippet": "        def lshift(value, count):\n            r = (0xFFFFFFFF & value) << count\n            return -(~(r - 1) & 0xFFFFFFFF) if r > 0x7FFFFFFF else r",
        "begin_line": 349,
        "end_line": 351,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.globo.GloboIE._real_extract#353",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.GloboIE",
        "signature": "youtube_dl.extractor.globo.GloboIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        video_id = self._search_regex(self._VIDEOID_REGEXES, webpage, 'video id')\n\n        video = self._download_json(\n            self._API_URL_TEMPLATE % video_id, video_id)['videos'][0]\n\n        title = video['title']\n\n        formats = []\n        for resource in video['resources']:\n            resource_id = resource.get('_id')\n            if not resource_id:\n                continue\n\n            security = self._download_json(\n                self._SECURITY_URL_TEMPLATE % (video_id, resource_id),\n                video_id, 'Downloading security hash for %s' % resource_id)\n\n            security_hash = security.get('hash')\n            if not security_hash:\n                message = security.get('message')\n                if message:\n                    raise ExtractorError(\n                        '%s returned error: %s' % (self.IE_NAME, message), expected=True)\n                continue\n\n            hash_code = security_hash[:2]\n            received_time = int(security_hash[2:12])\n            received_random = security_hash[12:22]\n            received_md5 = security_hash[22:]\n\n            sign_time = received_time + self._RESIGN_EXPIRATION\n            padding = '%010d' % random.randint(1, 10000000000)\n\n            signed_md5 = self.MD5.b64_md5(received_md5 + compat_str(sign_time) + padding)\n            signed_hash = hash_code + compat_str(received_time) + received_random + compat_str(sign_time) + padding + signed_md5\n\n            resource_url = resource['url']\n            signed_url = '%s?h=%s&k=%s' % (resource_url, signed_hash, 'flash')\n            if resource_id.endswith('m3u8') or resource_url.endswith('.m3u8'):\n                formats.extend(self._extract_m3u8_formats(signed_url, resource_id, 'mp4'))\n            else:\n                formats.append({\n                    'url': signed_url,\n                    'format_id': resource_id,\n                    'height': resource.get('height'),\n                })\n\n        self._sort_formats(formats)\n\n        duration = float_or_none(video.get('duration'), 1000)\n        like_count = int_or_none(video.get('likes'))\n        uploader = video.get('channel')\n        uploader_id = video.get('channel_id')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'like_count': like_count,\n            'formats': formats\n        }",
        "begin_line": 353,
        "end_line": 419,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.testtube.TestTubeIE._real_extract#38",
        "src_path": "youtube_dl/extractor/testtube.py",
        "class_name": "youtube_dl.extractor.testtube.TestTubeIE",
        "signature": "youtube_dl.extractor.testtube.TestTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        youtube_url = self._html_search_regex(\n            r'<iframe[^>]+src=\"((?:https?:)?//www.youtube.com/embed/[^\"]+)\"',\n            webpage, 'youtube iframe', default=None)\n        if youtube_url:\n            return self.url_result(youtube_url, 'Youtube', video_id=display_id)\n\n        video_id = self._search_regex(\n            r\"player\\.loadRevision3Item\\('video_id',\\s*([0-9]+)\\);\",\n            webpage, 'video ID')\n\n        all_info = self._download_json(\n            'https://testtube.com/api/getPlaylist.json?api_key=ba9c741bce1b9d8e3defcc22193f3651b8867e62&codecs=h264,vp8,theora&video_id=%s' % video_id,\n            video_id)\n        info = all_info['items'][0]\n\n        formats = []\n        for vcodec, fdatas in info['media'].items():\n            for name, fdata in fdatas.items():\n                formats.append({\n                    'format_id': '%s-%s' % (vcodec, name),\n                    'url': fdata['url'],\n                    'vcodec': vcodec,\n                    'tbr': fdata.get('bitrate'),\n                })\n        self._sort_formats(formats)\n\n        duration = int_or_none(info.get('duration'))\n        images = info.get('images')\n        thumbnails = None\n        preference = qualities(['mini', 'small', 'medium', 'large'])\n        if images:\n            thumbnails = [{\n                'id': thumbnail_id,\n                'url': img_url,\n                'preference': preference(thumbnail_id)\n            } for thumbnail_id, img_url in images.items()]\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': info['title'],\n            'description': info.get('summary'),\n            'thumbnails': thumbnails,\n            'uploader': info.get('show', {}).get('name'),\n            'uploader_id': info.get('show', {}).get('slug'),\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 38,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.played.PlayedIE._real_extract#32",
        "src_path": "youtube_dl/extractor/played.py",
        "class_name": "youtube_dl.extractor.played.PlayedIE",
        "signature": "youtube_dl.extractor.played.PlayedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        orig_webpage = self._download_webpage(url, video_id)\n\n        m_error = re.search(\n            r'(?s)Reason for deletion:.*?<b class=\"err\"[^>]*>(?P<msg>[^<]+)</b>', orig_webpage)\n        if m_error:\n            raise ExtractorError(m_error.group('msg'), expected=True)\n\n        data = self._hidden_inputs(orig_webpage)\n\n        self._sleep(2, video_id)\n\n        post = compat_urllib_parse.urlencode(data)\n        headers = {\n            b'Content-Type': b'application/x-www-form-urlencoded',\n        }\n        req = compat_urllib_request.Request(url, post, headers)\n        webpage = self._download_webpage(\n            req, video_id, note='Downloading video page ...')\n\n        title = os.path.splitext(data['fname'])[0]\n\n        video_url = self._search_regex(\n            r'file: \"?(.+?)\",', webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 32,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.abc.ABCIE._real_extract#53",
        "src_path": "youtube_dl/extractor/abc.py",
        "class_name": "youtube_dl.extractor.abc.ABCIE",
        "signature": "youtube_dl.extractor.abc.ABCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        mobj = re.search(\n            r'inline(?P<type>Video|Audio|YouTube)Data\\.push\\((?P<json_data>[^)]+)\\);',\n            webpage)\n        if mobj is None:\n            raise ExtractorError('Unable to extract video urls')\n\n        urls_info = self._parse_json(\n            mobj.group('json_data'), video_id, transform_source=js_to_json)\n\n        if not isinstance(urls_info, list):\n            urls_info = [urls_info]\n\n        if mobj.group('type') == 'YouTube':\n            return self.playlist_result([\n                self.url_result(url_info['url']) for url_info in urls_info])\n\n        formats = [{\n            'url': url_info['url'],\n            'vcodec': url_info.get('codec') if mobj.group('type') == 'Video' else 'none',\n            'width': int_or_none(url_info.get('width')),\n            'height': int_or_none(url_info.get('height')),\n            'tbr': int_or_none(url_info.get('bitrate')),\n            'filesize': int_or_none(url_info.get('filesize')),\n        } for url_info in urls_info]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 53,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.hellporno.HellPornoIE._real_extract#27",
        "src_path": "youtube_dl/extractor/hellporno.py",
        "class_name": "youtube_dl.extractor.hellporno.HellPornoIE",
        "signature": "youtube_dl.extractor.hellporno.HellPornoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = remove_end(self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title'), ' - Hell Porno')\n\n        flashvars = self._parse_json(self._search_regex(\n            r'var\\s+flashvars\\s*=\\s*({.+?});', webpage, 'flashvars'),\n            display_id, transform_source=js_to_json)\n\n        video_id = flashvars.get('video_id')\n        thumbnail = flashvars.get('preview_url')\n        ext = flashvars.get('postfix', '.mp4')[1:]\n\n        formats = []\n        for video_url_key in ['video_url', 'video_alt_url']:\n            video_url = flashvars.get(video_url_key)\n            if not video_url:\n                continue\n            video_text = flashvars.get('%s_text' % video_url_key)\n            fmt = {\n                'url': video_url,\n                'ext': ext,\n                'format_id': video_text,\n            }\n            m = re.search(r'^(?P<height>\\d+)[pP]', video_text)\n            if m:\n                fmt['height'] = int(m.group('height'))\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        categories = self._html_search_meta(\n            'keywords', webpage, 'categories', default='').split(',')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.newgrounds.NewgroundsIE._real_extract#22",
        "src_path": "youtube_dl/extractor/newgrounds.py",
        "class_name": "youtube_dl.extractor.newgrounds.NewgroundsIE",
        "signature": "youtube_dl.extractor.newgrounds.NewgroundsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        music_id = mobj.group('id')\n        webpage = self._download_webpage(url, music_id)\n\n        title = self._html_search_regex(\n            r',\"name\":\"([^\"]+)\",', webpage, 'music title')\n        uploader = self._html_search_regex(\n            r',\"artist\":\"([^\"]+)\",', webpage, 'music uploader')\n\n        music_url_json_string = self._html_search_regex(\n            r'({\"url\":\"[^\"]+\"),', webpage, 'music url') + '}'\n        music_url_json = json.loads(music_url_json_string)\n        music_url = music_url_json['url']\n\n        return {\n            'id': music_id,\n            'title': title,\n            'url': music_url,\n            'uploader': uploader,\n        }",
        "begin_line": 22,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pornhd.PornHdIE._real_extract#31",
        "src_path": "youtube_dl/extractor/pornhd.py",
        "class_name": "youtube_dl.extractor.pornhd.PornHdIE",
        "signature": "youtube_dl.extractor.pornhd.PornHdIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id or video_id)\n\n        title = self._html_search_regex(\n            r'<title>(.+) porn HD.+?</title>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"description\">([^<]+)</div>', webpage, 'description', fatal=False)\n        view_count = int_or_none(self._html_search_regex(\n            r'(\\d+) views\\s*</span>', webpage, 'view count', fatal=False))\n        thumbnail = self._search_regex(\n            r\"'poster'\\s*:\\s*'([^']+)'\", webpage, 'thumbnail', fatal=False)\n\n        quality = qualities(['sd', 'hd'])\n        sources = json.loads(js_to_json(self._search_regex(\n            r\"(?s)'sources'\\s*:\\s*(\\{.+?\\})\\s*\\}[;,)]\",\n            webpage, 'sources')))\n        formats = []\n        for qname, video_url in sources.items():\n            if not video_url:\n                continue\n            formats.append({\n                'url': video_url,\n                'format_id': qname,\n                'quality': quality(qname),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'view_count': view_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 31,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pbs.PBSIE._extract_webpage#165",
        "src_path": "youtube_dl/extractor/pbs.py",
        "class_name": "youtube_dl.extractor.pbs.PBSIE",
        "signature": "youtube_dl.extractor.pbs.PBSIE._extract_webpage(self, url)",
        "snippet": "    def _extract_webpage(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        presumptive_id = mobj.group('presumptive_id')\n        display_id = presumptive_id\n        if presumptive_id:\n            webpage = self._download_webpage(url, display_id)\n\n            upload_date = unified_strdate(self._search_regex(\n                r'<input type=\"hidden\" id=\"air_date_[0-9]+\" value=\"([^\"]+)\"',\n                webpage, 'upload date', default=None))\n\n            # tabbed frontline videos\n            tabbed_videos = re.findall(\n                r'<div[^>]+class=\"videotab[^\"]*\"[^>]+vid=\"(\\d+)\"', webpage)\n            if tabbed_videos:\n                return tabbed_videos, presumptive_id, upload_date\n\n            MEDIA_ID_REGEXES = [\n                r\"div\\s*:\\s*'videoembed'\\s*,\\s*mediaid\\s*:\\s*'(\\d+)'\",  # frontline video embed\n                r'class=\"coveplayerid\">([^<]+)<',                       # coveplayer\n                r'<input type=\"hidden\" id=\"pbs_video_id_[0-9]+\" value=\"([0-9]+)\"/>',  # jwplayer\n            ]\n\n            media_id = self._search_regex(\n                MEDIA_ID_REGEXES, webpage, 'media ID', fatal=False, default=None)\n            if media_id:\n                return media_id, presumptive_id, upload_date\n\n            url = self._search_regex(\n                r'(?s)<iframe[^>]+?(?:[a-z-]+?=[\"\\'].*?[\"\\'][^>]+?)*?\\bsrc=[\"\\']([^\\'\"]+partnerplayer[^\\'\"]+)[\"\\']',\n                webpage, 'player URL')\n            mobj = re.match(self._VALID_URL, url)\n\n        player_id = mobj.group('player_id')\n        if not display_id:\n            display_id = player_id\n        if player_id:\n            player_page = self._download_webpage(\n                url, display_id, note='Downloading player page',\n                errnote='Could not download player page')\n            video_id = self._search_regex(\n                r'<div\\s+id=\"video_([0-9]+)\"', player_page, 'video ID')\n        else:\n            video_id = mobj.group('id')\n            display_id = video_id\n\n        return video_id, display_id, None",
        "begin_line": 165,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pbs.PBSIE._real_extract#214",
        "src_path": "youtube_dl/extractor/pbs.py",
        "class_name": "youtube_dl.extractor.pbs.PBSIE",
        "signature": "youtube_dl.extractor.pbs.PBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, display_id, upload_date = self._extract_webpage(url)\n\n        if isinstance(video_id, list):\n            entries = [self.url_result(\n                'http://video.pbs.org/video/%s' % vid_id, 'PBS', vid_id)\n                for vid_id in video_id]\n            return self.playlist_result(entries, display_id)\n\n        info = self._download_json(\n            'http://video.pbs.org/videoInfo/%s?format=json&type=partner' % video_id,\n            display_id)\n\n        formats = []\n        for encoding_name in ('recommended_encoding', 'alternate_encoding'):\n            redirect = info.get(encoding_name)\n            if not redirect:\n                continue\n            redirect_url = redirect.get('url')\n            if not redirect_url:\n                continue\n\n            redirect_info = self._download_json(\n                redirect_url + '?format=json', display_id,\n                'Downloading %s video url info' % encoding_name)\n\n            if redirect_info['status'] == 'error':\n                raise ExtractorError(\n                    '%s said: %s' % (\n                        self.IE_NAME,\n                        self._ERRORS.get(redirect_info['http_code'], redirect_info['message'])),\n                    expected=True)\n\n            format_url = redirect_info.get('url')\n            if not format_url:\n                continue\n\n            if determine_ext(format_url) == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, display_id, 'mp4', preference=1, m3u8_id='hls'))\n            else:\n                formats.append({\n                    'url': format_url,\n                    'format_id': redirect.get('eeid'),\n                })\n        self._sort_formats(formats)\n\n        rating_str = info.get('rating')\n        if rating_str is not None:\n            rating_str = rating_str.rpartition('-')[2]\n        age_limit = US_RATINGS.get(rating_str)\n\n        subtitles = {}\n        closed_captions_url = info.get('closed_captions_url')\n        if closed_captions_url:\n            subtitles['en'] = [{\n                'ext': 'ttml',\n                'url': closed_captions_url,\n            }]\n\n        # info['title'] is often incomplete (e.g. 'Full Episode', 'Episode 5', etc)\n        # Try turning it to 'program - title' naming scheme if possible\n        alt_title = info.get('program', {}).get('title')\n        if alt_title:\n            info['title'] = alt_title + ' - ' + re.sub(r'^' + alt_title + '[\\s\\-:]+', '', info['title'])\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': info['title'],\n            'description': info['program'].get('description'),\n            'thumbnail': info.get('image_url'),\n            'duration': int_or_none(info.get('duration')),\n            'age_limit': age_limit,\n            'upload_date': upload_date,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 214,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.puls4.Puls4IE._real_extract#38",
        "src_path": "youtube_dl/extractor/puls4.py",
        "class_name": "youtube_dl.extractor.puls4.Puls4IE",
        "signature": "youtube_dl.extractor.puls4.Puls4IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        error_message = self._html_search_regex(\n            r'<div class=\"message-error\">(.+?)</div>',\n            webpage, 'error message', default=None)\n        if error_message:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error_message), expected=True)\n\n        real_url = self._html_search_regex(\n            r'\\\"fsk-button\\\".+?href=\\\"([^\"]+)',\n            webpage, 'fsk_button', default=None)\n        if real_url:\n            webpage = self._download_webpage(real_url, video_id)\n\n        player = self._search_regex(\n            r'p4_video_player(?:_iframe)?\\(\"video_\\d+_container\"\\s*,(.+?)\\);\\s*\\}',\n            webpage, 'player')\n\n        player_json = self._parse_json(\n            '[%s]' % player, video_id,\n            transform_source=lambda s: s.replace('undefined,', ''))\n\n        formats = None\n        result = None\n\n        for v in player_json:\n            if isinstance(v, list) and not formats:\n                formats = [{\n                    'url': f['url'],\n                    'format': 'hd' if f.get('hd') else 'sd',\n                    'width': int_or_none(f.get('size_x')),\n                    'height': int_or_none(f.get('size_y')),\n                    'tbr': int_or_none(f.get('bitrate')),\n                } for f in v]\n                self._sort_formats(formats)\n            elif isinstance(v, dict) and not result:\n                result = {\n                    'id': video_id,\n                    'title': v['videopartname'].strip(),\n                    'description': v.get('videotitle'),\n                    'duration': int_or_none(v.get('videoduration') or v.get('episodeduration')),\n                    'upload_date': unified_strdate(v.get('clipreleasetime')),\n                    'uploader': v.get('channel'),\n                }\n\n        result['formats'] = formats\n\n        return result",
        "begin_line": 38,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.eporner.EpornerIE._real_extract#29",
        "src_path": "youtube_dl/extractor/eporner.py",
        "class_name": "youtube_dl.extractor.eporner.EpornerIE",
        "signature": "youtube_dl.extractor.eporner.EpornerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n        title = self._html_search_regex(\n            r'<title>(.*?) - EPORNER', webpage, 'title')\n\n        redirect_url = 'http://www.eporner.com/config5/%s' % video_id\n        player_code = self._download_webpage(\n            redirect_url, display_id, note='Downloading player config')\n\n        sources = self._search_regex(\n            r'(?s)sources\\s*:\\s*\\[\\s*({.+?})\\s*\\]', player_code, 'sources')\n\n        formats = []\n        for video_url, format_id in re.findall(r'file\\s*:\\s*\"([^\"]+)\",\\s*label\\s*:\\s*\"([^\"]+)\"', sources):\n            fmt = {\n                'url': video_url,\n                'format_id': format_id,\n            }\n            m = re.search(r'^(\\d+)', format_id)\n            if m:\n                fmt['height'] = int(m.group(1))\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        duration = parse_duration(self._html_search_meta('duration', webpage))\n        view_count = str_to_int(self._search_regex(\n            r'id=\"cinemaviews\">\\s*([0-9,]+)\\s*<small>views',\n            webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 29,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.spankwire.SpankwireIE._real_extract#50",
        "src_path": "youtube_dl/extractor/spankwire.py",
        "class_name": "youtube_dl.extractor.spankwire.SpankwireIE",
        "signature": "youtube_dl.extractor.spankwire.SpankwireIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        req = compat_urllib_request.Request('http://www.' + mobj.group('url'))\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        title = self._html_search_regex(\n            r'<h1>([^<]+)', webpage, 'title')\n        description = self._html_search_regex(\n            r'(?s)<div\\s+id=\"descriptionContent\">(.+?)</div>',\n            webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'playerData\\.screenShot\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']',\n            webpage, 'thumbnail', fatal=False)\n\n        uploader = self._html_search_regex(\n            r'by:\\s*<a [^>]*>(.+?)</a>',\n            webpage, 'uploader', fatal=False)\n        uploader_id = self._html_search_regex(\n            r'by:\\s*<a href=\"/(?:user/viewProfile|Profile\\.aspx)\\?.*?UserId=(\\d+).*?\"',\n            webpage, 'uploader id', fatal=False)\n        upload_date = unified_strdate(self._html_search_regex(\n            r'</a> on (.+?) at \\d+:\\d+',\n            webpage, 'upload date', fatal=False))\n\n        view_count = str_to_int(self._html_search_regex(\n            r'<div id=\"viewsCounter\"><span>([\\d,\\.]+)</span> views</div>',\n            webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r'<span\\s+id=\"spCommentCount\"[^>]*>([\\d,\\.]+)</span>',\n            webpage, 'comment count', fatal=False))\n\n        videos = re.findall(\n            r'playerData\\.cdnPath([0-9]{3,})\\s*=\\s*(?:encodeURIComponent\\()?[\"\\']([^\"\\']+)[\"\\']', webpage)\n        heights = [int(video[0]) for video in videos]\n        video_urls = list(map(compat_urllib_parse_unquote, [video[1] for video in videos]))\n        if webpage.find('flashvars\\.encrypted = \"true\"') != -1:\n            password = self._search_regex(\n                r'flashvars\\.video_title = \"([^\"]+)',\n                webpage, 'password').replace('+', ' ')\n            video_urls = list(map(\n                lambda s: aes_decrypt_text(s, password, 32).decode('utf-8'),\n                video_urls))\n\n        formats = []\n        for height, video_url in zip(heights, video_urls):\n            path = compat_urllib_parse_urlparse(video_url).path\n            _, quality = path.split('/')[4].split('_')[:2]\n            f = {\n                'url': video_url,\n                'height': height,\n            }\n            tbr = self._search_regex(r'^(\\d+)[Kk]$', quality, 'tbr', default=None)\n            if tbr:\n                f.update({\n                    'tbr': int(tbr),\n                    'format_id': '%dp' % height,\n                })\n            else:\n                f['format_id'] = quality\n            formats.append(f)\n        self._sort_formats(formats)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': age_limit,\n        }",
        "begin_line": 50,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.thvideo.THVideoIE._real_extract#28",
        "src_path": "youtube_dl/extractor/thvideo.py",
        "class_name": "youtube_dl.extractor.thvideo.THVideoIE",
        "signature": "youtube_dl.extractor.thvideo.THVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # extract download link from mobile player page\n        webpage_player = self._download_webpage(\n            'http://thvideo.tv/mobile.php?cid=%s-0' % (video_id),\n            video_id, note='Downloading video source page')\n        video_url = self._html_search_regex(\n            r'<source src=\"(.*?)\" type', webpage_player, 'video url')\n\n        # extract video info from main page\n        webpage = self._download_webpage(\n            'http://thvideo.tv/v/th%s' % (video_id), video_id)\n        title = self._og_search_title(webpage)\n        display_id = 'th%s' % video_id\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage)\n        upload_date = unified_strdate(self._html_search_regex(\n            r'span itemprop=\"datePublished\" content=\"(.*?)\">', webpage,\n            'upload date', fatal=False))\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'url': video_url,\n            'title': title,\n            'display_id': display_id,\n            'thumbnail': thumbnail,\n            'description': description,\n            'upload_date': upload_date\n        }",
        "begin_line": 28,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.thvideo.THVideoPlaylistIE._real_extract#72",
        "src_path": "youtube_dl/extractor/thvideo.py",
        "class_name": "youtube_dl.extractor.thvideo.THVideoPlaylistIE",
        "signature": "youtube_dl.extractor.thvideo.THVideoPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n        list_title = self._html_search_regex(\n            r'<h1 class=\"show_title\">(.*?)<b id', webpage, 'playlist title',\n            fatal=False)\n\n        entries = [\n            self.url_result('http://thvideo.tv/v/th' + id, 'THVideo')\n            for id in re.findall(r'<dd><a href=\"http://thvideo.tv/v/th(\\d+)/\" target=', webpage)]\n\n        return self.playlist_result(entries, playlist_id, list_title)",
        "begin_line": 72,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.baidu.BaiduVideoIE._real_extract#31",
        "src_path": "youtube_dl/extractor/baidu.py",
        "class_name": "youtube_dl.extractor.baidu.BaiduVideoIE",
        "signature": "youtube_dl.extractor.baidu.BaiduVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        category = category2 = mobj.group('type')\n        if category == 'show':\n            category2 = 'tvshow'\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        playlist_title = self._html_search_regex(\n            r'title\\s*:\\s*([\"\\'])(?P<title>[^\\']+)\\1', webpage,\n            'playlist title', group='title')\n        playlist_description = self._html_search_regex(\n            r'<input[^>]+class=\"j-data-intro\"[^>]+value=\"([^\"]+)\"/>', webpage,\n            playlist_id, 'playlist description')\n\n        site = self._html_search_regex(\n            r'filterSite\\s*:\\s*[\"\\']([^\"]*)[\"\\']', webpage,\n            'primary provider site')\n        api_result = self._download_json(\n            'http://v.baidu.com/%s_intro/?dtype=%sPlayUrl&id=%s&site=%s' % (\n                category, category2, playlist_id, site),\n            playlist_id, 'Get playlist links')\n\n        entries = []\n        for episode in api_result[0]['episodes']:\n            episode_id = '%s_%s' % (playlist_id, episode['episode'])\n\n            redirect_page = self._download_webpage(\n                compat_urlparse.urljoin(url, episode['url']), episode_id,\n                note='Download Baidu redirect page')\n            real_url = self._html_search_regex(\n                r'location\\.replace\\(\"([^\"]+)\"\\)', redirect_page, 'real URL')\n\n            entries.append(self.url_result(\n                real_url, video_title=episode['single_title']))\n\n        return self.playlist_result(\n            entries, playlist_id, playlist_title, playlist_description)",
        "begin_line": 31,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ccc.CCCIE._real_extract#31",
        "src_path": "youtube_dl/extractor/ccc.py",
        "class_name": "youtube_dl.extractor.ccc.CCCIE",
        "signature": "youtube_dl.extractor.ccc.CCCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        if self._downloader.params.get('prefer_free_formats'):\n            preference = qualities(['mp3', 'opus', 'mp4-lq', 'webm-lq', 'h264-sd', 'mp4-sd', 'webm-sd', 'mp4', 'webm', 'mp4-hd', 'h264-hd', 'webm-hd'])\n        else:\n            preference = qualities(['opus', 'mp3', 'webm-lq', 'mp4-lq', 'webm-sd', 'h264-sd', 'mp4-sd', 'webm', 'mp4', 'webm-hd', 'mp4-hd', 'h264-hd'])\n\n        title = self._html_search_regex(\n            r'(?s)<h1>(.*?)</h1>', webpage, 'title')\n        description = self._html_search_regex(\n            r\"(?s)<p class='description'>(.*?)</p>\",\n            webpage, 'description', fatal=False)\n        upload_date = unified_strdate(self._html_search_regex(\n            r\"(?s)<span class='[^']*fa-calendar-o'></span>(.*?)</li>\",\n            webpage, 'upload date', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r\"(?s)<span class='[^']*fa-eye'></span>(.*?)</li>\",\n            webpage, 'view count', fatal=False))\n\n        matches = re.finditer(r'''(?xs)\n            <(?:span|div)\\s+class='label\\s+filetype'>(?P<format>.*?)</(?:span|div)>\\s*\n            <a\\s+download\\s+href='(?P<http_url>[^']+)'>\\s*\n            (?:\n                .*?\n                <a\\s+href='(?P<torrent_url>[^']+\\.torrent)'\n            )?''', webpage)\n        formats = []\n        for m in matches:\n            format = m.group('format')\n            format_id = self._search_regex(\n                r'.*/([a-z0-9_-]+)/[^/]*$',\n                m.group('http_url'), 'format id', default=None)\n            vcodec = 'h264' if 'h264' in format_id else (\n                'none' if format_id in ('mp3', 'opus') else None\n            )\n            formats.append({\n                'format_id': format_id,\n                'format': format,\n                'url': m.group('http_url'),\n                'vcodec': vcodec,\n                'preference': preference(format_id),\n            })\n\n            if m.group('torrent_url'):\n                formats.append({\n                    'format_id': 'torrent-%s' % (format if format_id is None else format_id),\n                    'format': '%s (torrent)' % format,\n                    'proto': 'torrent',\n                    'format_note': '(unsupported; will just download the .torrent file)',\n                    'vcodec': vcodec,\n                    'preference': -100 + preference(format_id),\n                    'url': m.group('torrent_url'),\n                })\n        self._sort_formats(formats)\n\n        thumbnail = self._html_search_regex(\n            r\"<video.*?poster='([^']+)'\", webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'view_count': view_count,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.historicfilms.HistoricFilmsIE._real_extract#22",
        "src_path": "youtube_dl/extractor/historicfilms.py",
        "class_name": "youtube_dl.extractor.historicfilms.HistoricFilmsIE",
        "signature": "youtube_dl.extractor.historicfilms.HistoricFilmsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        tape_id = self._search_regex(\n            [r'class=\"tapeId\"[^>]*>([^<]+)<', r'tapeId\\s*:\\s*\"([^\"]+)\"'],\n            webpage, 'tape id')\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._html_search_meta(\n            'thumbnailUrl', webpage, 'thumbnails') or self._og_search_thumbnail(webpage)\n        duration = parse_duration(self._html_search_meta(\n            'duration', webpage, 'duration'))\n\n        video_url = 'http://www.historicfilms.com/video/%s_%s_web.mov' % (tape_id, video_id)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 22,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtlnl.RtlNlIE._real_extract#70",
        "src_path": "youtube_dl/extractor/rtlnl.py",
        "class_name": "youtube_dl.extractor.rtlnl.RtlNlIE",
        "signature": "youtube_dl.extractor.rtlnl.RtlNlIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        uuid = self._match_id(url)\n        info = self._download_json(\n            'http://www.rtl.nl/system/s4m/vfd/version=2/uuid=%s/fmt=adaptive/' % uuid,\n            uuid)\n\n        material = info['material'][0]\n        title = info['abstracts'][0]['name']\n        subtitle = material.get('title')\n        if subtitle:\n            title += ' - %s' % subtitle\n        description = material.get('synopsis')\n\n        meta = info.get('meta', {})\n\n        # m3u8 streams are encrypted and may not be handled properly by older ffmpeg/avconv.\n        # To workaround this previously adaptive -> flash trick was used to obtain\n        # unencrypted m3u8 streams (see https://github.com/rg3/youtube-dl/issues/4118)\n        # and bypass georestrictions as well.\n        # Currently, unencrypted m3u8 playlists are (intentionally?) invalid and therefore\n        # unusable albeit can be fixed by simple string replacement (see\n        # https://github.com/rg3/youtube-dl/pull/6337)\n        # Since recent ffmpeg and avconv handle encrypted streams just fine encrypted\n        # streams are used now.\n        videopath = material['videopath']\n        m3u8_url = meta.get('videohost', 'http://manifest.us.rtl.nl') + videopath\n\n        formats = self._extract_m3u8_formats(m3u8_url, uuid, ext='mp4')\n\n        video_urlpart = videopath.split('/adaptive/')[1][:-5]\n        PG_URL_TEMPLATE = 'http://pg.us.rtl.nl/rtlxl/network/%s/progressive/%s.mp4'\n\n        formats.extend([\n            {\n                'url': PG_URL_TEMPLATE % ('a2m', video_urlpart),\n                'format_id': 'pg-sd',\n            },\n            {\n                'url': PG_URL_TEMPLATE % ('a3m', video_urlpart),\n                'format_id': 'pg-hd',\n                'quality': 0,\n            }\n        ])\n        self._sort_formats(formats)\n\n        thumbnails = []\n\n        for p in ('poster_base_url', '\"thumb_base_url\"'):\n            if not meta.get(p):\n                continue\n\n            thumbnails.append({\n                'url': self._proto_relative_url(meta[p] + uuid),\n                'width': int_or_none(self._search_regex(\n                    r'/sz=([0-9]+)', meta[p], 'thumbnail width', fatal=False)),\n                'height': int_or_none(self._search_regex(\n                    r'/sz=[0-9]+x([0-9]+)',\n                    meta[p], 'thumbnail height', fatal=False))\n            })\n\n        return {\n            'id': uuid,\n            'title': title,\n            'formats': formats,\n            'timestamp': material['original_date'],\n            'description': description,\n            'duration': parse_duration(material.get('duration')),\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 70,
        "end_line": 138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.weibo.WeiboIE._real_extract#33",
        "src_path": "youtube_dl/extractor/weibo.py",
        "class_name": "youtube_dl.extractor.weibo.WeiboIE",
        "signature": "youtube_dl.extractor.weibo.WeiboIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        video_id = mobj.group('id')\n        info_url = 'http://video.weibo.com/?s=v&a=play_list&format=json&mix_video_id=t_%s' % video_id\n        info = self._download_json(info_url, video_id)\n\n        videos_urls = map(lambda v: v['play_page_url'], info['result']['data'])\n        # Prefer sina video since they have thumbnails\n        videos_urls = sorted(videos_urls, key=lambda u: 'video.sina.com' in u)\n        player_url = videos_urls[-1]\n        m_sina = re.match(r'https?://video\\.sina\\.com\\.cn/v/b/(\\d+)-\\d+\\.html',\n                          player_url)\n        if m_sina is not None:\n            self.to_screen('Sina video detected')\n            sina_id = m_sina.group(1)\n            player_url = 'http://you.video.sina.com.cn/swf/quotePlayer.swf?vid=%s' % sina_id\n        return self.url_result(player_url)",
        "begin_line": 33,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.motorsport.MotorsportIE._real_extract#32",
        "src_path": "youtube_dl/extractor/motorsport.py",
        "class_name": "youtube_dl.extractor.motorsport.MotorsportIE",
        "signature": "youtube_dl.extractor.motorsport.MotorsportIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        iframe_path = self._html_search_regex(\n            r'<iframe id=\"player_iframe\"[^>]+src=\"([^\"]+)\"', webpage,\n            'iframe path')\n        iframe = self._download_webpage(\n            compat_urlparse.urljoin(url, iframe_path), display_id,\n            'Downloading iframe')\n        youtube_id = self._search_regex(\n            r'www.youtube.com/embed/(.{11})', iframe, 'youtube id')\n\n        return {\n            '_type': 'url_transparent',\n            'display_id': display_id,\n            'url': 'https://youtube.com/watch?v=%s' % youtube_id,\n        }",
        "begin_line": 32,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._login#37",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n        self.report_login()\n        login_url = 'https://www.crunchyroll.com/?a=formhandler'\n        data = urlencode_postdata({\n            'formname': 'RpcApiUser_Login',\n            'name': username,\n            'password': password,\n        })\n        login_request = compat_urllib_request.Request(login_url, data)\n        login_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        self._download_webpage(login_request, None, False, 'Wrong login info')",
        "begin_line": 37,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._real_initialize#52",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 52,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._download_webpage#55",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None)",
        "snippet": "    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None):\n        request = (url_or_request if isinstance(url_or_request, compat_urllib_request.Request)\n                   else compat_urllib_request.Request(url_or_request))\n        # Accept-Language must be set explicitly to accept any language to avoid issues\n        # similar to https://github.com/rg3/youtube-dl/issues/6797.\n        # Along with IP address Crunchyroll uses Accept-Language to guess whether georestriction\n        # should be imposed or not (from what I can see it just takes the first language\n        # ignoring the priority and requires it to correspond the IP). By the way this causes\n        # Crunchyroll to not work in georestriction cases in some browsers that don't place\n        # the locale lang first in header. However allowing any language seems to workaround the issue.\n        request.add_header('Accept-Language', '*')\n        return super(CrunchyrollBaseIE, self)._download_webpage(\n            request, video_id, note, errnote, fatal, tries, timeout, encoding)",
        "begin_line": 55,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._add_skip_wall#70",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._add_skip_wall(url)",
        "snippet": "    def _add_skip_wall(url):\n        parsed_url = compat_urlparse.urlparse(url)\n        qs = compat_urlparse.parse_qs(parsed_url.query)\n        # Always force skip_wall to bypass maturity wall, namely 18+ confirmation message:\n        # > This content may be inappropriate for some people.\n        # > Are you sure you want to continue?\n        # since it's not disabled by default in crunchyroll account's settings.\n        # See https://github.com/rg3/youtube-dl/issues/7202.\n        qs['skip_wall'] = ['1']\n        return compat_urlparse.urlunparse(\n            parsed_url._replace(query=compat_urllib_parse.urlencode(qs, True)))",
        "begin_line": 70,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._decrypt_subtitles#132",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._decrypt_subtitles(self, data, iv, id)",
        "snippet": "    def _decrypt_subtitles(self, data, iv, id):\n        data = bytes_to_intlist(base64.b64decode(data.encode('utf-8')))\n        iv = bytes_to_intlist(base64.b64decode(iv.encode('utf-8')))\n        id = int(id)\n\n        def obfuscate_key_aux(count, modulo, start):\n            output = list(start)\n            for _ in range(count):\n                output.append(output[-1] + output[-2])\n            # cut off start values\n            output = output[2:]\n            output = list(map(lambda x: x % modulo + 33, output))\n            return output\n\n        def obfuscate_key(key):\n            num1 = int(floor(pow(2, 25) * sqrt(6.9)))\n            num2 = (num1 ^ key) << 5\n            num3 = key ^ num1\n            num4 = num3 ^ (num3 >> 3) ^ num2\n            prefix = intlist_to_bytes(obfuscate_key_aux(20, 97, (1, 2)))\n            shaHash = bytes_to_intlist(sha1(prefix + str(num4).encode('ascii')).digest())\n            # Extend 160 Bit hash to 256 Bit\n            return shaHash + [0] * 12\n\n        key = obfuscate_key(id)\n\n        decrypted_data = intlist_to_bytes(aes_cbc_decrypt(data, key, iv))\n        return zlib.decompress(decrypted_data)",
        "begin_line": 132,
        "end_line": 159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_srt#161",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_srt(self, sub_root)",
        "snippet": "    def _convert_subtitles_to_srt(self, sub_root):\n        output = ''\n\n        for i, event in enumerate(sub_root.findall('./events/event'), 1):\n            start = event.attrib['start'].replace('.', ',')\n            end = event.attrib['end'].replace('.', ',')\n            text = event.attrib['text'].replace('\\\\N', '\\n')\n            output += '%d\\n%s --> %s\\n%s\\n\\n' % (i, start, end, text)\n        return output",
        "begin_line": 161,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_ass#171",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_ass(self, sub_root)",
        "snippet": "    def _convert_subtitles_to_ass(self, sub_root):\n        output = ''\n\n        def ass_bool(strvalue):\n            assvalue = '0'\n            if strvalue == '1':\n                assvalue = '-1'\n            return assvalue\n\n        output = '[Script Info]\\n'\n        output += 'Title: %s\\n' % sub_root.attrib[\"title\"]\n        output += 'ScriptType: v4.00+\\n'\n        output += 'WrapStyle: %s\\n' % sub_root.attrib[\"wrap_style\"]\n        output += 'PlayResX: %s\\n' % sub_root.attrib[\"play_res_x\"]\n        output += 'PlayResY: %s\\n' % sub_root.attrib[\"play_res_y\"]\n        output += \"\"\"ScaledBorderAndShadow: yes\n\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n\"\"\"\n        for style in sub_root.findall('./styles/style'):\n            output += 'Style: ' + style.attrib[\"name\"]\n            output += ',' + style.attrib[\"font_name\"]\n            output += ',' + style.attrib[\"font_size\"]\n            output += ',' + style.attrib[\"primary_colour\"]\n            output += ',' + style.attrib[\"secondary_colour\"]\n            output += ',' + style.attrib[\"outline_colour\"]\n            output += ',' + style.attrib[\"back_colour\"]\n            output += ',' + ass_bool(style.attrib[\"bold\"])\n            output += ',' + ass_bool(style.attrib[\"italic\"])\n            output += ',' + ass_bool(style.attrib[\"underline\"])\n            output += ',' + ass_bool(style.attrib[\"strikeout\"])\n            output += ',' + style.attrib[\"scale_x\"]\n            output += ',' + style.attrib[\"scale_y\"]\n            output += ',' + style.attrib[\"spacing\"]\n            output += ',' + style.attrib[\"angle\"]\n            output += ',' + style.attrib[\"border_style\"]\n            output += ',' + style.attrib[\"outline\"]\n            output += ',' + style.attrib[\"shadow\"]\n            output += ',' + style.attrib[\"alignment\"]\n            output += ',' + style.attrib[\"margin_l\"]\n            output += ',' + style.attrib[\"margin_r\"]\n            output += ',' + style.attrib[\"margin_v\"]\n            output += ',' + style.attrib[\"encoding\"]\n            output += '\\n'\n\n        output += \"\"\"\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n\"\"\"\n        for event in sub_root.findall('./events/event'):\n            output += 'Dialogue: 0'\n            output += ',' + event.attrib[\"start\"]\n            output += ',' + event.attrib[\"end\"]\n            output += ',' + event.attrib[\"style\"]\n            output += ',' + event.attrib[\"name\"]\n            output += ',' + event.attrib[\"margin_l\"]\n            output += ',' + event.attrib[\"margin_r\"]\n            output += ',' + event.attrib[\"margin_v\"]\n            output += ',' + event.attrib[\"effect\"]\n            output += ',' + event.attrib[\"text\"]\n            output += '\\n'\n\n        return output",
        "begin_line": 171,
        "end_line": 234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._extract_subtitles#236",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._extract_subtitles(self, subtitle)",
        "snippet": "    def _extract_subtitles(self, subtitle):\n        sub_root = compat_etree_fromstring(subtitle)\n        return [{\n            'ext': 'srt',\n            'data': self._convert_subtitles_to_srt(sub_root),\n        }, {\n            'ext': 'ass',\n            'data': self._convert_subtitles_to_ass(sub_root),\n        }]",
        "begin_line": 236,
        "end_line": 244,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._get_subtitles#246",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._get_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_subtitles(self, video_id, webpage):\n        subtitles = {}\n        for sub_id, sub_name in re.findall(r'\\bssid=([0-9]+)\"[^>]+?\\btitle=\"([^\"]+)', webpage):\n            sub_page = self._download_webpage(\n                'http://www.crunchyroll.com/xml/?req=RpcApiSubtitle_GetXml&subtitle_script_id=' + sub_id,\n                video_id, note='Downloading subtitles for ' + sub_name)\n            id = self._search_regex(r'id=\\'([0-9]+)', sub_page, 'subtitle_id', fatal=False)\n            iv = self._search_regex(r'<iv>([^<]+)', sub_page, 'subtitle_iv', fatal=False)\n            data = self._search_regex(r'<data>([^<]+)', sub_page, 'subtitle_data', fatal=False)\n            if not id or not iv or not data:\n                continue\n            subtitle = self._decrypt_subtitles(data, iv, id).decode('utf-8')\n            lang_code = self._search_regex(r'lang_code=[\"\\']([^\"\\']+)', subtitle, 'subtitle_lang_code', fatal=False)\n            if not lang_code:\n                continue\n            subtitles[lang_code] = self._extract_subtitles(subtitle)\n        return subtitles",
        "begin_line": 246,
        "end_line": 262,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._real_extract#264",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        if mobj.group('prefix') == 'm':\n            mobile_webpage = self._download_webpage(url, video_id, 'Downloading mobile webpage')\n            webpage_url = self._search_regex(r'<link rel=\"canonical\" href=\"([^\"]+)\" />', mobile_webpage, 'webpage_url')\n        else:\n            webpage_url = 'http://www.' + mobj.group('url')\n\n        webpage = self._download_webpage(self._add_skip_wall(webpage_url), video_id, 'Downloading webpage')\n        note_m = self._html_search_regex(\n            r'<div class=\"showmedia-trailer-notice\">(.+?)</div>',\n            webpage, 'trailer-notice', default='')\n        if note_m:\n            raise ExtractorError(note_m)\n\n        mobj = re.search(r'Page\\.messaging_box_controller\\.addItems\\(\\[(?P<msg>{.+?})\\]\\)', webpage)\n        if mobj:\n            msg = json.loads(mobj.group('msg'))\n            if msg.get('type') == 'error':\n                raise ExtractorError('crunchyroll returned error: %s' % msg['message_body'], expected=True)\n\n        if 'To view this, please log in to verify you are 18 or older.' in webpage:\n            self.raise_login_required()\n\n        video_title = self._html_search_regex(r'<h1[^>]*>(.+?)</h1>', webpage, 'video_title', flags=re.DOTALL)\n        video_title = re.sub(r' {2,}', ' ', video_title)\n        video_description = self._html_search_regex(r'\"description\":\"([^\"]+)', webpage, 'video_description', default='')\n        if not video_description:\n            video_description = None\n        video_upload_date = self._html_search_regex(\n            [r'<div>Availability for free users:(.+?)</div>', r'<div>[^<>]+<span>\\s*(.+?\\d{4})\\s*</span></div>'],\n            webpage, 'video_upload_date', fatal=False, flags=re.DOTALL)\n        if video_upload_date:\n            video_upload_date = unified_strdate(video_upload_date)\n        video_uploader = self._html_search_regex(\n            r'<a[^>]+href=\"/publisher/[^\"]+\"[^>]*>([^<]+)</a>', webpage,\n            'video_uploader', fatal=False)\n\n        playerdata_url = compat_urllib_parse_unquote(self._html_search_regex(r'\"config_url\":\"([^\"]+)', webpage, 'playerdata_url'))\n        playerdata_req = compat_urllib_request.Request(playerdata_url)\n        playerdata_req.data = compat_urllib_parse.urlencode({'current_page': webpage_url})\n        playerdata_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        playerdata = self._download_webpage(playerdata_req, video_id, note='Downloading media info')\n\n        stream_id = self._search_regex(r'<media_id>([^<]+)', playerdata, 'stream_id')\n        video_thumbnail = self._search_regex(r'<episode_image_url>([^<]+)', playerdata, 'thumbnail', fatal=False)\n\n        formats = []\n        for fmt in re.findall(r'showmedia\\.([0-9]{3,4})p', webpage):\n            stream_quality, stream_format = self._FORMAT_IDS[fmt]\n            video_format = fmt + 'p'\n            streamdata_req = compat_urllib_request.Request(\n                'http://www.crunchyroll.com/xml/?req=RpcApiVideoPlayer_GetStandardConfig&media_id=%s&video_format=%s&video_quality=%s'\n                % (stream_id, stream_format, stream_quality),\n                compat_urllib_parse.urlencode({'current_page': url}).encode('utf-8'))\n            streamdata_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            streamdata = self._download_xml(\n                streamdata_req, video_id,\n                note='Downloading media info for %s' % video_format)\n            stream_info = streamdata.find('./{default}preload/stream_info')\n            video_url = stream_info.find('./host').text\n            video_play_path = stream_info.find('./file').text\n            metadata = stream_info.find('./metadata')\n            format_info = {\n                'format': video_format,\n                'format_id': video_format,\n                'height': int_or_none(xpath_text(metadata, './height')),\n                'width': int_or_none(xpath_text(metadata, './width')),\n            }\n\n            if '.fplive.net/' in video_url:\n                video_url = re.sub(r'^rtmpe?://', 'http://', video_url.strip())\n                parsed_video_url = compat_urlparse.urlparse(video_url)\n                direct_video_url = compat_urlparse.urlunparse(parsed_video_url._replace(\n                    netloc='v.lvlt.crcdn.net',\n                    path='%s/%s' % (remove_end(parsed_video_url.path, '/'), video_play_path.split(':')[-1])))\n                if self._is_valid_url(direct_video_url, video_id, video_format):\n                    format_info.update({\n                        'url': direct_video_url,\n                    })\n                    formats.append(format_info)\n                    continue\n\n            format_info.update({\n                'url': video_url,\n                'play_path': video_play_path,\n                'ext': 'flv',\n            })\n            formats.append(format_info)\n\n        subtitles = self.extract_subtitles(video_id, webpage)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': video_description,\n            'thumbnail': video_thumbnail,\n            'uploader': video_uploader,\n            'upload_date': video_upload_date,\n            'subtitles': subtitles,\n            'formats': formats,\n        }",
        "begin_line": 264,
        "end_line": 367,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollShowPlaylistIE._real_extract#396",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollShowPlaylistIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollShowPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_id = self._match_id(url)\n\n        webpage = self._download_webpage(self._add_skip_wall(url), show_id)\n        title = self._html_search_regex(\n            r'(?s)<h1[^>]*>\\s*<span itemprop=\"name\">(.*?)</span>',\n            webpage, 'title')\n        episode_paths = re.findall(\n            r'(?s)<li id=\"showview_videos_media_[0-9]+\"[^>]+>.*?<a href=\"([^\"]+)\"',\n            webpage)\n        entries = [\n            self.url_result('http://www.crunchyroll.com' + ep, 'Crunchyroll')\n            for ep in episode_paths\n        ]\n        entries.reverse()\n\n        return {\n            '_type': 'playlist',\n            'id': show_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 396,
        "end_line": 417,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cracked.CrackedIE._real_extract#39",
        "src_path": "youtube_dl/extractor/cracked.py",
        "class_name": "youtube_dl.extractor.cracked.CrackedIE",
        "signature": "youtube_dl.extractor.cracked.CrackedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        youtube_url = self._search_regex(\n            r'<iframe[^>]+src=\"((?:https?:)?//www\\.youtube\\.com/embed/[^\"]+)\"',\n            webpage, 'youtube url', default=None)\n        if youtube_url:\n            return self.url_result(youtube_url, 'Youtube')\n\n        video_url = self._html_search_regex(\n            [r'var\\s+CK_vidSrc\\s*=\\s*\"([^\"]+)\"', r'<video\\s+src=\"([^\"]+)\"'],\n            webpage, 'video URL')\n\n        title = self._search_regex(\n            [r'property=\"?og:title\"?\\s+content=\"([^\"]+)\"', r'class=\"?title\"?>([^<]+)'],\n            webpage, 'title')\n\n        description = self._search_regex(\n            r'name=\"?(?:og:)?description\"?\\s+content=\"([^\"]+)\"',\n            webpage, 'description', default=None)\n\n        timestamp = self._html_search_regex(\n            r'\"date\"\\s*:\\s*\"([^\"]+)\"', webpage, 'upload date', fatal=False)\n        if timestamp:\n            timestamp = parse_iso8601(timestamp[:-6])\n\n        view_count = str_to_int(self._html_search_regex(\n            r'<span\\s+class=\"?views\"? id=\"?viewCounts\"?>([\\d,\\.]+) Views</span>',\n            webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r'<span\\s+id=\"?commentCounts\"?>([\\d,\\.]+)</span>',\n            webpage, 'comment count', fatal=False))\n\n        m = re.search(r'_(?P<width>\\d+)X(?P<height>\\d+)\\.mp4$', video_url)\n        if m:\n            width = int(m.group('width'))\n            height = int(m.group('height'))\n        else:\n            width = height = None\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'height': height,\n            'width': width,\n        }",
        "begin_line": 39,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vesti.VestiIE._real_extract#103",
        "src_path": "youtube_dl/extractor/vesti.py",
        "class_name": "youtube_dl.extractor.vesti.VestiIE",
        "signature": "youtube_dl.extractor.vesti.VestiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        mobj = re.search(\n            r'<meta[^>]+?property=\"og:video\"[^>]+?content=\"http://www\\.vesti\\.ru/i/flvplayer_videoHost\\.swf\\?vid=(?P<id>\\d+)',\n            page)\n        if mobj:\n            video_id = mobj.group('id')\n            page = self._download_webpage('http://www.vesti.ru/only_video.html?vid=%s' % video_id, video_id,\n                                          'Downloading video page')\n\n        rutv_url = RUTVIE._extract_url(page)\n        if rutv_url:\n            return self.url_result(rutv_url, 'RUTV')\n\n        raise ExtractorError('No video found', expected=True)",
        "begin_line": 103,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._fix_json#20",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor",
        "signature": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._fix_json(json_string)",
        "snippet": "    def _fix_json(json_string):\n        return json_string.replace('\\\\\\'', '\\'')",
        "begin_line": 20,
        "end_line": 21,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._real_extract_video#23",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor",
        "signature": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._real_extract_video(self, video_id)",
        "snippet": "    def _real_extract_video(self, video_id):\n        vid_parts = video_id.split(',')\n        if len(vid_parts) == 3:\n            video_id = '%s0%s%s-X-h' % (vid_parts[0][:4], vid_parts[1], vid_parts[2].rjust(4, '0'))\n        json_url = 'http://video.nhl.com/videocenter/servlets/playlist?ids=%s&format=json' % video_id\n        data = self._download_json(\n            json_url, video_id, transform_source=self._fix_json)\n        return self._extract_video(data[0])",
        "begin_line": 23,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._extract_video#32",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor",
        "signature": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._extract_video(self, info)",
        "snippet": "    def _extract_video(self, info):\n        video_id = info['id']\n        self.report_extraction(video_id)\n\n        initial_video_url = info['publishPoint']\n        if info['formats'] == '1':\n            parsed_url = compat_urllib_parse_urlparse(initial_video_url)\n            filename, ext = os.path.splitext(parsed_url.path)\n            path = '%s_sd%s' % (filename, ext)\n            data = compat_urllib_parse.urlencode({\n                'type': 'fvod',\n                'path': compat_urlparse.urlunparse(parsed_url[:2] + (path,) + parsed_url[3:])\n            })\n            path_url = 'http://video.nhl.com/videocenter/servlets/encryptvideopath?' + data\n            path_doc = self._download_xml(\n                path_url, video_id, 'Downloading final video url')\n            video_url = path_doc.find('path').text\n        else:\n            video_url = initial_video_url\n\n        join = compat_urlparse.urljoin\n        ret = {\n            'id': video_id,\n            'title': info['name'],\n            'url': video_url,\n            'description': info['description'],\n            'duration': int(info['duration']),\n            'thumbnail': join(join(video_url, '/u/'), info['bigImage']),\n            'upload_date': unified_strdate(info['releaseDate'].split('.')[0]),\n        }\n        if video_url.startswith('rtmp:'):\n            mobj = re.match(r'(?P<tc_url>rtmp://[^/]+/(?P<app>[a-z0-9/]+))/(?P<play_path>mp4:.*)', video_url)\n            ret.update({\n                'tc_url': mobj.group('tc_url'),\n                'play_path': mobj.group('play_path'),\n                'app': mobj.group('app'),\n                'no_resume': True,\n            })\n        return ret",
        "begin_line": 32,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLIE._real_extract#144",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLIE",
        "signature": "youtube_dl.extractor.nhl.NHLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self._real_extract_video(video_id)",
        "begin_line": 144,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLNewsIE._real_extract#179",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLNewsIE",
        "signature": "youtube_dl.extractor.nhl.NHLNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        news_id = self._match_id(url)\n        webpage = self._download_webpage(url, news_id)\n        video_id = self._search_regex(\n            [r'pVid(\\d+)', r\"nlid\\s*:\\s*'(\\d+)'\",\n             r'<iframe[^>]+src=[\"\\']https?://video.*?\\.nhl\\.com/videocenter/embed\\?.*\\bplaylist=(\\d+)'],\n            webpage, 'video id')\n        return self._real_extract_video(video_id)",
        "begin_line": 179,
        "end_line": 186,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLVideocenterIE._real_extract#202",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLVideocenterIE",
        "signature": "youtube_dl.extractor.nhl.NHLVideocenterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        team = mobj.group('team')\n        webpage = self._download_webpage(url, team)\n        cat_id = self._search_regex(\n            [r'var defaultCatId = \"(.+?)\";',\n             r'{statusIndex:0,index:0,.*?id:(.*?),'],\n            webpage, 'category id')\n        playlist_title = self._html_search_regex(\n            r'tab0\"[^>]*?>(.*?)</td>',\n            webpage, 'playlist title', flags=re.DOTALL).lower().capitalize()\n\n        data = compat_urllib_parse.urlencode({\n            'cid': cat_id,\n            # This is the default value\n            'count': 12,\n            'ptrs': 3,\n            'format': 'json',\n        })\n        path = '/videocenter/servlets/browse?' + data\n        request_url = compat_urlparse.urljoin(url, path)\n        response = self._download_webpage(request_url, playlist_title)\n        response = self._fix_json(response)\n        if not response.strip():\n            self._downloader.report_warning('Got an empty reponse, trying '\n                                            'adding the \"newvideos\" parameter')\n            response = self._download_webpage(request_url + '&newvideos=true',\n                                              playlist_title)\n            response = self._fix_json(response)\n        videos = json.loads(response)\n\n        return {\n            '_type': 'playlist',\n            'title': playlist_title,\n            'id': cat_id,\n            'entries': [self._extract_video(v) for v in videos],\n        }",
        "begin_line": 202,
        "end_line": 238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTvIE._real_extract#28",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTvIE",
        "signature": "youtube_dl.extractor.arte.ArteTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        lang = mobj.group('lang')\n        video_id = mobj.group('id')\n\n        ref_xml_url = url.replace('/videos/', '/do_delegate/videos/')\n        ref_xml_url = ref_xml_url.replace('.html', ',view,asPlayerXml.xml')\n        ref_xml_doc = self._download_xml(\n            ref_xml_url, video_id, note='Downloading metadata')\n        config_node = find_xpath_attr(ref_xml_doc, './/video', 'lang', lang)\n        config_xml_url = config_node.attrib['ref']\n        config = self._download_xml(\n            config_xml_url, video_id, note='Downloading configuration')\n\n        formats = [{\n            'format_id': q.attrib['quality'],\n            # The playpath starts at 'mp4:', if we don't manually\n            # split the url, rtmpdump will incorrectly parse them\n            'url': q.text.split('mp4:', 1)[0],\n            'play_path': 'mp4:' + q.text.split('mp4:', 1)[1],\n            'ext': 'flv',\n            'quality': 2 if q.attrib['quality'] == 'hd' else 1,\n        } for q in config.findall('./urls/url')]\n        self._sort_formats(formats)\n\n        title = config.find('.//name').text\n        thumbnail = config.find('.//firstThumbnailUrl').text\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_url_info#68",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_url_info(cls, url)",
        "snippet": "    def _extract_url_info(cls, url):\n        mobj = re.match(cls._VALID_URL, url)\n        lang = mobj.group('lang')\n        # This is not a real id, it can be for example AJT for the news\n        # http://www.arte.tv/guide/fr/emissions/AJT/arte-journal\n        video_id = mobj.group('id')\n        return video_id, lang",
        "begin_line": 68,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._real_extract#76",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, lang = self._extract_url_info(url)\n        webpage = self._download_webpage(url, video_id)\n        return self._extract_from_webpage(webpage, video_id, lang)",
        "begin_line": 76,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_webpage#81",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_webpage(self, webpage, video_id, lang)",
        "snippet": "    def _extract_from_webpage(self, webpage, video_id, lang):\n        json_url = self._html_search_regex(\n            [r'arte_vp_url=[\"\\'](.*?)[\"\\']', r'data-url=[\"\\']([^\"]+)[\"\\']'],\n            webpage, 'json vp url', default=None)\n        if not json_url:\n            iframe_url = self._html_search_regex(\n                r'<iframe[^>]+src=([\"\\'])(?P<url>.+\\bjson_url=.+?)\\1',\n                webpage, 'iframe url', group='url')\n            json_url = compat_parse_qs(\n                compat_urllib_parse_urlparse(iframe_url).query)['json_url'][0]\n        return self._extract_from_json_url(json_url, video_id, lang)",
        "begin_line": 81,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_json_url#93",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_json_url(self, json_url, video_id, lang)",
        "snippet": "    def _extract_from_json_url(self, json_url, video_id, lang):\n        info = self._download_json(json_url, video_id)\n        player_info = info['videoJsonPlayer']\n\n        upload_date_str = player_info.get('shootingDate')\n        if not upload_date_str:\n            upload_date_str = player_info.get('VDA', '').split(' ')[0]\n\n        title = player_info['VTI'].strip()\n        subtitle = player_info.get('VSU', '').strip()\n        if subtitle:\n            title += ' - %s' % subtitle\n\n        info_dict = {\n            'id': player_info['VID'],\n            'title': title,\n            'description': player_info.get('VDE'),\n            'upload_date': unified_strdate(upload_date_str),\n            'thumbnail': player_info.get('programImage') or player_info.get('VTU', {}).get('IUR'),\n        }\n        qfunc = qualities(['HQ', 'MQ', 'EQ', 'SQ'])\n\n        formats = []\n        for format_id, format_dict in player_info['VSR'].items():\n            f = dict(format_dict)\n            versionCode = f.get('versionCode')\n\n            langcode = {\n                'fr': 'F',\n                'de': 'A',\n            }.get(lang, lang)\n            lang_rexs = [r'VO?%s' % langcode, r'VO?.-ST%s' % langcode]\n            lang_pref = (\n                None if versionCode is None else (\n                    10 if any(re.match(r, versionCode) for r in lang_rexs)\n                    else -10))\n            source_pref = 0\n            if versionCode is not None:\n                # The original version with subtitles has lower relevance\n                if re.match(r'VO-ST(F|A)', versionCode):\n                    source_pref -= 10\n                # The version with sourds/mal subtitles has also lower relevance\n                elif re.match(r'VO?(F|A)-STM\\1', versionCode):\n                    source_pref -= 9\n            format = {\n                'format_id': format_id,\n                'preference': -10 if f.get('videoFormat') == 'M3U8' else None,\n                'language_preference': lang_pref,\n                'format_note': '%s, %s' % (f.get('versionCode'), f.get('versionLibelle')),\n                'width': int_or_none(f.get('width')),\n                'height': int_or_none(f.get('height')),\n                'tbr': int_or_none(f.get('bitrate')),\n                'quality': qfunc(f.get('quality')),\n                'source_preference': source_pref,\n            }\n\n            if f.get('mediaType') == 'rtmp':\n                format['url'] = f['streamer']\n                format['play_path'] = 'mp4:' + f['url']\n                format['ext'] = 'flv'\n            else:\n                format['url'] = f['url']\n\n            formats.append(format)\n\n        self._check_formats(formats, video_id)\n        self._sort_formats(formats)\n\n        info_dict['formats'] = formats\n        return info_dict",
        "begin_line": 93,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVFutureIE._real_extract#204",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVFutureIE",
        "signature": "youtube_dl.extractor.arte.ArteTVFutureIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        anchor_id, lang = self._extract_url_info(url)\n        webpage = self._download_webpage(url, anchor_id)\n        row = self._search_regex(\n            r'(?s)id=\"%s\"[^>]*>.+?(<div[^>]*arte_vp_url[^>]*>)' % anchor_id,\n            webpage, 'row')\n        return self._extract_from_webpage(row, anchor_id, lang)",
        "begin_line": 204,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVDDCIE._real_extract#217",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVDDCIE",
        "signature": "youtube_dl.extractor.arte.ArteTVDDCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, lang = self._extract_url_info(url)\n        if lang == 'folge':\n            lang = 'de'\n        elif lang == 'emission':\n            lang = 'fr'\n        webpage = self._download_webpage(url, video_id)\n        scriptElement = get_element_by_attribute('class', 'visu_video_block', webpage)\n        script_url = self._html_search_regex(r'src=\"(.*?)\"', scriptElement, 'script url')\n        javascriptPlayerGenerator = self._download_webpage(script_url, video_id, 'Download javascript player generator')\n        json_url = self._search_regex(r\"json_url=(.*)&rendering_place.*\", javascriptPlayerGenerator, 'json url')\n        return self._extract_from_json_url(json_url, video_id, lang)",
        "begin_line": 217,
        "end_line": 228,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVEmbedIE._real_extract#259",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVEmbedIE",
        "signature": "youtube_dl.extractor.arte.ArteTVEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        lang = mobj.group('lang')\n        json_url = mobj.group('json_url')\n        return self._extract_from_json_url(json_url, video_id, lang)",
        "begin_line": 259,
        "end_line": 264,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.karrierevideos.KarriereVideosIE._real_extract#45",
        "src_path": "youtube_dl/extractor/karrierevideos.py",
        "class_name": "youtube_dl.extractor.karrierevideos.KarriereVideosIE",
        "signature": "youtube_dl.extractor.karrierevideos.KarriereVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = (self._html_search_meta('title', webpage, default=None) or\n                 self._search_regex(r'<h1 class=\"title\">([^<]+)</h1>'))\n\n        video_id = self._search_regex(\n            r'/config/video/(.+?)\\.xml', webpage, 'video id')\n        playlist = self._download_xml(\n            'http://www.karrierevideos.at/player-playlist.xml.php?p=%s' % video_id,\n            video_id, transform_source=fix_xml_ampersands)\n\n        NS_MAP = {\n            'jwplayer': 'http://developer.longtailvideo.com/trac/wiki/FlashFormats'\n        }\n\n        def ns(path):\n            return xpath_with_ns(path, NS_MAP)\n\n        item = playlist.find('./tracklist/item')\n        video_file = xpath_text(\n            item, ns('./jwplayer:file'), 'video url', fatal=True)\n        streamer = xpath_text(\n            item, ns('./jwplayer:streamer'), 'streamer', fatal=True)\n\n        uploader = xpath_text(\n            item, ns('./jwplayer:author'), 'uploader')\n        duration = float_or_none(\n            xpath_text(item, ns('./jwplayer:duration'), 'duration'))\n\n        description = self._html_search_regex(\n            r'(?s)<div class=\"leadtext\">(.+?)</div>',\n            webpage, 'description')\n\n        thumbnail = self._html_search_meta(\n            'thumbnail', webpage, 'thumbnail')\n        if thumbnail:\n            thumbnail = compat_urlparse.urljoin(url, thumbnail)\n\n        return {\n            'id': video_id,\n            'url': streamer.replace('rtmpt', 'rtmp'),\n            'play_path': 'mp4:%s' % video_file,\n            'ext': 'flv',\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'duration': duration,\n        }",
        "begin_line": 45,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.__init__#34",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        self._downloader = downloader",
        "begin_line": 34,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009784735812133072,
            "pseudo_dstar_susp": 0.0009775171065493646,
            "pseudo_tarantula_susp": 0.0009930486593843098,
            "pseudo_op2_susp": 0.0009775171065493646,
            "pseudo_barinel_susp": 0.0009930486593843098
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.set_downloader#37",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.set_downloader(self, downloader)",
        "snippet": "    def set_downloader(self, downloader):\n        \"\"\"Sets the downloader for this PP.\"\"\"\n        self._downloader = downloader",
        "begin_line": 37,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.run#41",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.run(self, information)",
        "snippet": "    def run(self, information):\n        \"\"\"Run the PostProcessor.\n\n        The \"information\" argument is a dictionary like the ones\n        composed by InfoExtractors. The only difference is that this\n        one has an extra field called \"filepath\" that points to the\n        downloaded file.\n\n        This method returns a tuple, the first element is a list of the files\n        that can be deleted, and the second of which is the updated\n        information.\n\n        In addition, this method may raise a PostProcessingError\n        exception if post processing fails.\n        \"\"\"\n        return [], information  # by default, keep file and do nothing",
        "begin_line": 41,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.try_utime#58",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.try_utime(self, path, atime, mtime, errnote='Cannot update utime of file')",
        "snippet": "    def try_utime(self, path, atime, mtime, errnote='Cannot update utime of file'):\n        try:\n            os.utime(encodeFilename(path), (atime, mtime))\n        except Exception:\n            self._downloader.report_warning(errnote)",
        "begin_line": 58,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor._configuration_args#64",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor._configuration_args(self, default=[])",
        "snippet": "    def _configuration_args(self, default=[]):\n        return cli_configuration_args(self._downloader.params, 'postprocessor_args', default)",
        "begin_line": 64,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.__init__#11",
        "src_path": "youtube_dl/postprocessor/execafterdownload.py",
        "class_name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP",
        "signature": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.__init__(self, downloader, exec_cmd)",
        "snippet": "    def __init__(self, downloader, exec_cmd):\n        super(ExecAfterDownloadPP, self).__init__(downloader)\n        self.exec_cmd = exec_cmd",
        "begin_line": 11,
        "end_line": 13,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.run#15",
        "src_path": "youtube_dl/postprocessor/execafterdownload.py",
        "class_name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP",
        "signature": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.run(self, information)",
        "snippet": "    def run(self, information):\n        cmd = self.exec_cmd\n        if '{}' not in cmd:\n            cmd += ' {}'\n\n        cmd = cmd.replace('{}', shlex_quote(information['filepath']))\n\n        self._downloader.to_screen(\"[exec] Executing command: %s\" % cmd)\n        retCode = subprocess.call(cmd, shell=True)\n        if retCode != 0:\n            raise PostProcessingError(\n                'Command returned error code %d' % retCode)\n\n        return [], information",
        "begin_line": 15,
        "end_line": 28,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.c56.C56IE._real_extract#23",
        "src_path": "youtube_dl/extractor/c56.py",
        "class_name": "youtube_dl.extractor.c56.C56IE",
        "signature": "youtube_dl.extractor.c56.C56IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        text_id = mobj.group('textid')\n\n        page = self._download_json(\n            'http://vxml.56.com/json/%s/' % text_id, text_id, 'Downloading video info')\n\n        info = page['info']\n\n        formats = [\n            {\n                'format_id': f['type'],\n                'filesize': int(f['filesize']),\n                'url': f['url']\n            } for f in info['rfiles']\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': info['vid'],\n            'title': info['Subject'],\n            'duration': int(info['duration']) / 1000.0,\n            'formats': formats,\n            'thumbnail': info.get('bimg') or info.get('img'),\n        }",
        "begin_line": 23,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.roxwel.RoxwelIE._real_extract#29",
        "src_path": "youtube_dl/extractor/roxwel.py",
        "class_name": "youtube_dl.extractor.roxwel.RoxwelIE",
        "signature": "youtube_dl.extractor.roxwel.RoxwelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        filename = mobj.group('filename')\n        info_url = 'http://www.roxwel.com/api/videos/%s' % filename\n        info = self._download_json(info_url, filename)\n\n        rtmp_rates = sorted([int(r.replace('flv_', '')) for r in info['media_rates'] if r.startswith('flv_')])\n        best_rate = rtmp_rates[-1]\n        url_page_url = 'http://roxwel.com/pl_one_time.php?filename=%s&quality=%s' % (filename, best_rate)\n        rtmp_url = self._download_webpage(url_page_url, filename, 'Downloading video url')\n        ext = determine_ext(rtmp_url)\n        if ext == 'f4v':\n            rtmp_url = rtmp_url.replace(filename, 'mp4:%s' % filename)\n\n        return {\n            'id': filename,\n            'title': info['title'],\n            'url': rtmp_url,\n            'ext': 'flv',\n            'description': info['description'],\n            'thumbnail': info.get('player_image_url') or info.get('image_url_large'),\n            'uploader': info['artist'],\n            'uploader_id': info['artistname'],\n            'upload_date': unified_strdate(info['dbdate']),\n        }",
        "begin_line": 29,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xvideos.XVideosIE._real_extract#32",
        "src_path": "youtube_dl/extractor/xvideos.py",
        "class_name": "youtube_dl.extractor.xvideos.XVideosIE",
        "signature": "youtube_dl.extractor.xvideos.XVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        mobj = re.search(r'<h1 class=\"inlineError\">(.+?)</h1>', webpage)\n        if mobj:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, clean_html(mobj.group(1))), expected=True)\n\n        video_url = compat_urllib_parse_unquote(\n            self._search_regex(r'flv_url=(.+?)&', webpage, 'video URL'))\n        video_title = self._html_search_regex(\n            r'<title>(.*?)\\s+-\\s+XVID', webpage, 'title')\n        video_thumbnail = self._search_regex(\n            r'url_bigthumb=(.+?)&amp', webpage, 'thumbnail', fatal=False)\n\n        formats = [{\n            'url': video_url,\n        }]\n\n        android_req = compat_urllib_request.Request(url)\n        android_req.add_header('User-Agent', self._ANDROID_USER_AGENT)\n        android_webpage = self._download_webpage(android_req, video_id, fatal=False)\n\n        if android_webpage is not None:\n            player_params_str = self._search_regex(\n                'mobileReplacePlayerDivTwoQual\\(([^)]+)\\)',\n                android_webpage, 'player parameters', default='')\n            player_params = list(map(lambda s: s.strip(' \\''), player_params_str.split(',')))\n            if player_params:\n                formats.extend([{\n                    'url': param,\n                    'preference': -10,\n                } for param in player_params if determine_ext(param) == 'mp4'])\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_title,\n            'ext': 'flv',\n            'thumbnail': video_thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 32,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.wdr.WDRIE._real_extract#98",
        "src_path": "youtube_dl/extractor/wdr.py",
        "class_name": "youtube_dl.extractor.wdr.WDRIE",
        "signature": "youtube_dl.extractor.wdr.WDRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_url = mobj.group('url')\n        page_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, page_id)\n\n        if mobj.group('player') is None:\n            entries = [\n                self.url_result(page_url + href, 'WDR')\n                for href in re.findall(r'<a href=\"/?(.+?%s\\.html)\" rel=\"nofollow\"' % self._PLAYER_REGEX, webpage)\n            ]\n\n            if entries:  # Playlist page\n                return self.playlist_result(entries, page_id)\n\n            # Overview page\n            entries = []\n            for page_num in itertools.count(2):\n                hrefs = re.findall(\n                    r'<li class=\"mediathekvideo\"\\s*>\\s*<img[^>]*>\\s*<a href=\"(/mediathek/video/[^\"]+)\"',\n                    webpage)\n                entries.extend(\n                    self.url_result(page_url + href, 'WDR')\n                    for href in hrefs)\n                next_url_m = re.search(\n                    r'<li class=\"nextToLast\">\\s*<a href=\"([^\"]+)\"', webpage)\n                if not next_url_m:\n                    break\n                next_url = page_url + next_url_m.group(1)\n                webpage = self._download_webpage(\n                    next_url, page_id,\n                    note='Downloading playlist page %d' % page_num)\n            return self.playlist_result(entries, page_id)\n\n        flashvars = compat_parse_qs(\n            self._html_search_regex(r'<param name=\"flashvars\" value=\"([^\"]+)\"', webpage, 'flashvars'))\n\n        page_id = flashvars['trackerClipId'][0]\n        video_url = flashvars['dslSrc'][0]\n        title = flashvars['trackerClipTitle'][0]\n        thumbnail = flashvars['startPicture'][0] if 'startPicture' in flashvars else None\n        is_live = flashvars.get('isLive', ['0'])[0] == '1'\n\n        if is_live:\n            title = self._live_title(title)\n\n        if 'trackerClipAirTime' in flashvars:\n            upload_date = flashvars['trackerClipAirTime'][0]\n        else:\n            upload_date = self._html_search_meta('DC.Date', webpage, 'upload date')\n\n        if upload_date:\n            upload_date = unified_strdate(upload_date)\n\n        if video_url.endswith('.f4m'):\n            video_url += '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18'\n            ext = 'flv'\n        elif video_url.endswith('.smil'):\n            fmt = self._extract_smil_formats(video_url, page_id)[0]\n            video_url = fmt['url']\n            sep = '&' if '?' in video_url else '?'\n            video_url += sep\n            video_url += 'hdcore=3.3.0&plugin=aasp-3.3.0.99.43'\n            ext = fmt['ext']\n        else:\n            ext = determine_ext(video_url)\n\n        description = self._html_search_meta('Description', webpage, 'description')\n\n        return {\n            'id': page_id,\n            'url': video_url,\n            'ext': ext,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'is_live': is_live\n        }",
        "begin_line": 98,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.wdr.WDRMobileIE._real_extract#198",
        "src_path": "youtube_dl/extractor/wdr.py",
        "class_name": "youtube_dl.extractor.wdr.WDRMobileIE",
        "signature": "youtube_dl.extractor.wdr.WDRMobileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        return {\n            'id': mobj.group('id'),\n            'title': mobj.group('title'),\n            'age_limit': int(mobj.group('age_limit')),\n            'url': url,\n            'http_headers': {\n                'User-Agent': 'mobile',\n            },\n        }",
        "begin_line": 198,
        "end_line": 208,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.wdr.WDRMausIE._real_extract#235",
        "src_path": "youtube_dl/extractor/wdr.py",
        "class_name": "youtube_dl.extractor.wdr.WDRMausIE",
        "signature": "youtube_dl.extractor.wdr.WDRMausIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        param_code = self._html_search_regex(\n            r'<a href=\"\\?startVideo=1&amp;([^\"]+)\"', webpage, 'parameters')\n\n        title_date = self._search_regex(\n            r'<div class=\"sendedatum\"><p>Sendedatum:\\s*([0-9\\.]+)</p>',\n            webpage, 'air date')\n        title_str = self._html_search_regex(\n            r'<h1>(.*?)</h1>', webpage, 'title')\n        title = '%s - %s' % (title_date, title_str)\n        upload_date = unified_strdate(\n            self._html_search_meta('dc.date', webpage))\n\n        fields = compat_parse_qs(param_code)\n        video_url = fields['firstVideo'][0]\n        thumbnail = compat_urlparse.urljoin(url, fields['startPicture'][0])\n\n        formats = [{\n            'format_id': 'rtmp',\n            'url': video_url,\n        }]\n\n        jscode = self._download_webpage(\n            'http://www.wdrmaus.de/codebase/js/extended-medien.min.js',\n            video_id, fatal=False,\n            note='Downloading URL translation table',\n            errnote='Could not download URL translation table')\n        if jscode:\n            for m in re.finditer(\n                    r\"stream:\\s*'dslSrc=(?P<stream>[^']+)',\\s*download:\\s*'(?P<dl>[^']+)'\\s*\\}\",\n                    jscode):\n                if video_url.startswith(m.group('stream')):\n                    http_url = video_url.replace(\n                        m.group('stream'), m.group('dl'))\n                    formats.append({\n                        'format_id': 'http',\n                        'url': http_url,\n                    })\n                    break\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 235,
        "end_line": 286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ubu.UbuIE._real_extract#25",
        "src_path": "youtube_dl/extractor/ubu.py",
        "class_name": "youtube_dl.extractor.ubu.UbuIE",
        "signature": "youtube_dl.extractor.ubu.UbuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<title>.+?Film &amp; Video: ([^<]+)</title>', webpage, 'title')\n\n        duration = int_or_none(self._html_search_regex(\n            r'Duration: (\\d+) minutes', webpage, 'duration', fatal=False),\n            invscale=60)\n\n        formats = []\n        FORMAT_REGEXES = [\n            ('sq', r\"'flashvars'\\s*,\\s*'file=([^']+)'\"),\n            ('hq', r'href=\"(http://ubumexico\\.centro\\.org\\.mx/video/[^\"]+)\"'),\n        ]\n        preference = qualities([fid for fid, _ in FORMAT_REGEXES])\n        for format_id, format_regex in FORMAT_REGEXES:\n            m = re.search(format_regex, webpage)\n            if m:\n                formats.append({\n                    'url': m.group(1),\n                    'format_id': format_id,\n                    'preference': preference(format_id),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtvnh.RTVNHIE._real_extract#21",
        "src_path": "youtube_dl/extractor/rtvnh.py",
        "class_name": "youtube_dl.extractor.rtvnh.RTVNHIE",
        "signature": "youtube_dl.extractor.rtvnh.RTVNHIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        meta = self._parse_json(self._download_webpage(\n            'http://www.rtvnh.nl/video/json?m=' + video_id, video_id), video_id)\n\n        status = meta.get('status')\n        if status != 200:\n            raise ExtractorError(\n                '%s returned error code %d' % (self.IE_NAME, status), expected=True)\n\n        formats = self._extract_smil_formats(\n            'http://www.rtvnh.nl/video/smil?m=' + video_id, video_id, fatal=False)\n\n        for item in meta['source']['fb']:\n            if item.get('type') == 'hls':\n                formats.extend(self._extract_m3u8_formats(\n                    item['file'], video_id, ext='mp4', entry_protocol='m3u8_native'))\n            elif item.get('type') == '':\n                formats.append({'url': item['file']})\n\n        return {\n            'id': video_id,\n            'title': meta['title'].strip(),\n            'thumbnail': meta.get('image'),\n            'formats': formats\n        }",
        "begin_line": 21,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ctsnews.CtsNewsIE._real_extract#53",
        "src_path": "youtube_dl/extractor/ctsnews.py",
        "class_name": "youtube_dl.extractor.ctsnews.CtsNewsIE",
        "signature": "youtube_dl.extractor.ctsnews.CtsNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        news_id = self._match_id(url)\n        page = self._download_webpage(url, news_id)\n\n        if self._search_regex(r'(CTSPlayer2)', page, 'CTSPlayer2 identifier', default=None):\n            feed_url = self._html_search_regex(\n                r'(http://news\\.cts\\.com\\.tw/action/mp4feed\\.php\\?news_id=\\d+)',\n                page, 'feed url')\n            video_url = self._download_webpage(\n                feed_url, news_id, note='Fetching feed')\n        else:\n            self.to_screen('Not CTSPlayer video, trying Youtube...')\n            youtube_url = self._search_regex(\n                r'src=\"(//www\\.youtube\\.com/embed/[^\"]+)\"', page, 'youtube url',\n                default=None)\n            if not youtube_url:\n                raise ExtractorError('The news includes no videos!', expected=True)\n\n            return {\n                '_type': 'url',\n                'url': youtube_url,\n                'ie_key': 'Youtube',\n            }\n\n        description = self._html_search_meta('description', page)\n        title = self._html_search_meta('title', page)\n        thumbnail = self._html_search_meta('image', page)\n\n        datetime_str = self._html_search_regex(\n            r'(\\d{4}/\\d{2}/\\d{2} \\d{2}:\\d{2})', page, 'date and time')\n        # Transform into ISO 8601 format with timezone info\n        datetime_str = datetime_str.replace('/', '-') + ':00+0800'\n        timestamp = parse_iso8601(datetime_str, delimiter=' ')\n\n        return {\n            'id': news_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n        }",
        "begin_line": 53,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.update.rsa_verify#20",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.rsa_verify(message, signature, key)",
        "snippet": "def rsa_verify(message, signature, key):\n    from struct import pack\n    from hashlib import sha256\n\n    assert isinstance(message, bytes)\n    block_size = 0\n    n = key[0]\n    while n:\n        block_size += 1\n        n >>= 8\n    signature = pow(int(signature, 16), key[1], key[0])\n    raw_bytes = []\n    while signature:\n        raw_bytes.insert(0, pack(\"B\", signature & 0xFF))\n        signature >>= 8\n    signature = (block_size - len(raw_bytes)) * b'\\x00' + b''.join(raw_bytes)\n    if signature[0:2] != b'\\x00\\x01':\n        return False\n    signature = signature[2:]\n    if b'\\x00' not in signature:\n        return False\n    signature = signature[signature.index(b'\\x00') + 1:]\n    if not signature.startswith(b'\\x30\\x31\\x30\\x0D\\x06\\x09\\x60\\x86\\x48\\x01\\x65\\x03\\x04\\x02\\x01\\x05\\x00\\x04\\x20'):\n        return False\n    signature = signature[19:]\n    if signature != sha256(message).digest():\n        return False\n    return True",
        "begin_line": 20,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.update.update_self#50",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.update_self(to_screen, verbose)",
        "snippet": "def update_self(to_screen, verbose):\n    \"\"\"Update the program file with the latest version from the repository\"\"\"\n\n    UPDATE_URL = \"https://rg3.github.io/youtube-dl/update/\"\n    VERSION_URL = UPDATE_URL + 'LATEST_VERSION'\n    JSON_URL = UPDATE_URL + 'versions.json'\n    UPDATES_RSA_KEY = (0x9d60ee4d8f805312fdb15a62f87b95bd66177b91df176765d13514a0f1754bcd2057295c5b6f1d35daa6742c3ffc9a82d3e118861c207995a8031e151d863c9927e304576bc80692bc8e094896fcf11b66f3e29e04e3a71e9a11558558acea1840aec37fc396fb6b65dc81a1c4144e03bd1c011de62e3f1357b327d08426fe93, 65537)\n\n    if not isinstance(globals().get('__loader__'), zipimporter) and not hasattr(sys, \"frozen\"):\n        to_screen('It looks like you installed youtube-dl with a package manager, pip, setup.py or a tarball. Please use that to update.')\n        return\n\n    https_handler = make_HTTPS_handler({})\n    opener = compat_urllib_request.build_opener(https_handler)\n\n    # Check if there is a new version\n    try:\n        newversion = opener.open(VERSION_URL).read().decode('utf-8').strip()\n    except Exception:\n        if verbose:\n            to_screen(compat_str(traceback.format_exc()))\n        to_screen('ERROR: can\\'t find the current version. Please try again later.')\n        return\n    if newversion == __version__:\n        to_screen('youtube-dl is up-to-date (' + __version__ + ')')\n        return\n\n    # Download and check versions info\n    try:\n        versions_info = opener.open(JSON_URL).read().decode('utf-8')\n        versions_info = json.loads(versions_info)\n    except Exception:\n        if verbose:\n            to_screen(compat_str(traceback.format_exc()))\n        to_screen('ERROR: can\\'t obtain versions info. Please try again later.')\n        return\n    if 'signature' not in versions_info:\n        to_screen('ERROR: the versions file is not signed or corrupted. Aborting.')\n        return\n    signature = versions_info['signature']\n    del versions_info['signature']\n    if not rsa_verify(json.dumps(versions_info, sort_keys=True).encode('utf-8'), signature, UPDATES_RSA_KEY):\n        to_screen('ERROR: the versions file signature is invalid. Aborting.')\n        return\n\n    version_id = versions_info['latest']\n\n    def version_tuple(version_str):\n        return tuple(map(int, version_str.split('.')))\n    if version_tuple(__version__) >= version_tuple(version_id):\n        to_screen('youtube-dl is up to date (%s)' % __version__)\n        return\n\n    to_screen('Updating to version ' + version_id + ' ...')\n    version = versions_info['versions'][version_id]\n\n    print_notes(to_screen, versions_info['versions'])\n\n    filename = sys.argv[0]\n    # Py2EXE: Filename could be different\n    if hasattr(sys, \"frozen\") and not os.path.isfile(filename):\n        if os.path.isfile(filename + '.exe'):\n            filename += '.exe'\n\n    if not os.access(filename, os.W_OK):\n        to_screen('ERROR: no write permissions on %s' % filename)\n        return\n\n    # Py2EXE\n    if hasattr(sys, \"frozen\"):\n        exe = os.path.abspath(filename)\n        directory = os.path.dirname(exe)\n        if not os.access(directory, os.W_OK):\n            to_screen('ERROR: no write permissions on %s' % directory)\n            return\n\n        try:\n            urlh = opener.open(version['exe'][0])\n            newcontent = urlh.read()\n            urlh.close()\n        except (IOError, OSError):\n            if verbose:\n                to_screen(compat_str(traceback.format_exc()))\n            to_screen('ERROR: unable to download latest version')\n            return\n\n        newcontent_hash = hashlib.sha256(newcontent).hexdigest()\n        if newcontent_hash != version['exe'][1]:\n            to_screen('ERROR: the downloaded file hash does not match. Aborting.')\n            return\n\n        try:\n            with open(exe + '.new', 'wb') as outf:\n                outf.write(newcontent)\n        except (IOError, OSError):\n            if verbose:\n                to_screen(compat_str(traceback.format_exc()))\n            to_screen('ERROR: unable to write the new version')\n            return\n\n        try:\n            bat = os.path.join(directory, 'youtube-dl-updater.bat')\n            with io.open(bat, 'w') as batfile:\n                batfile.write('''\n@echo off\necho Waiting for file handle to be closed ...\nping 127.0.0.1 -n 5 -w 1000 > NUL\nmove /Y \"%s.new\" \"%s\" > NUL\necho Updated youtube-dl to version %s.\nstart /b \"\" cmd /c del \"%%~f0\"&exit /b\"\n                \\n''' % (exe, exe, version_id))\n\n            subprocess.Popen([bat])  # Continues to run in the background\n            return  # Do not show premature success messages\n        except (IOError, OSError):\n            if verbose:\n                to_screen(compat_str(traceback.format_exc()))\n            to_screen('ERROR: unable to overwrite current version')\n            return\n\n    # Zip unix package\n    elif isinstance(globals().get('__loader__'), zipimporter):\n        try:\n            urlh = opener.open(version['bin'][0])\n            newcontent = urlh.read()\n            urlh.close()\n        except (IOError, OSError):\n            if verbose:\n                to_screen(compat_str(traceback.format_exc()))\n            to_screen('ERROR: unable to download latest version')\n            return\n\n        newcontent_hash = hashlib.sha256(newcontent).hexdigest()\n        if newcontent_hash != version['bin'][1]:\n            to_screen('ERROR: the downloaded file hash does not match. Aborting.')\n            return\n\n        try:\n            with open(filename, 'wb') as outf:\n                outf.write(newcontent)\n        except (IOError, OSError):\n            if verbose:\n                to_screen(compat_str(traceback.format_exc()))\n            to_screen('ERROR: unable to overwrite current version')\n            return\n\n    to_screen('Updated youtube-dl. Restart youtube-dl to use the new version.')",
        "begin_line": 50,
        "end_line": 196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.update.get_notes#199",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.get_notes(versions, fromVersion)",
        "snippet": "def get_notes(versions, fromVersion):\n    notes = []\n    for v, vdata in sorted(versions.items()):\n        if v > fromVersion:\n            notes.extend(vdata.get('notes', []))\n    return notes",
        "begin_line": 199,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.update.print_notes#207",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.print_notes(to_screen, versions, fromVersion=__version__)",
        "snippet": "def print_notes(to_screen, versions, fromVersion=__version__):\n    notes = get_notes(versions, fromVersion)\n    if notes:\n        to_screen('PLEASE NOTE:')\n        for note in notes:\n            to_screen(note)",
        "begin_line": 207,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._handle_error#52",
        "src_path": "youtube_dl/extractor/eagleplatform.py",
        "class_name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE",
        "signature": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._handle_error(response)",
        "snippet": "    def _handle_error(response):\n        status = int_or_none(response.get('status', 200))\n        if status != 200:\n            raise ExtractorError(' '.join(response['errors']), expected=True)",
        "begin_line": 52,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._download_json#57",
        "src_path": "youtube_dl/extractor/eagleplatform.py",
        "class_name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE",
        "signature": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._download_json(self, url_or_request, video_id, note='Downloading JSON metadata')",
        "snippet": "    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata'):\n        response = super(EaglePlatformIE, self)._download_json(url_or_request, video_id, note)\n        self._handle_error(response)\n        return response",
        "begin_line": 57,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._get_video_url#62",
        "src_path": "youtube_dl/extractor/eagleplatform.py",
        "class_name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE",
        "signature": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._get_video_url(self, url_or_request, video_id, note='Downloading JSON metadata')",
        "snippet": "    def _get_video_url(self, url_or_request, video_id, note='Downloading JSON metadata'):\n        return self._download_json(url_or_request, video_id, note)['data'][0]",
        "begin_line": 62,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._real_extract#65",
        "src_path": "youtube_dl/extractor/eagleplatform.py",
        "class_name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE",
        "signature": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        host, video_id = mobj.group('custom_host') or mobj.group('host'), mobj.group('id')\n\n        player_data = self._download_json(\n            'http://%s/api/player_data?id=%s' % (host, video_id), video_id)\n\n        media = player_data['data']['playlist']['viewports'][0]['medialist'][0]\n\n        title = media['title']\n        description = media.get('description')\n        thumbnail = self._proto_relative_url(media.get('snapshot'), 'http:')\n        duration = int_or_none(media.get('duration'))\n        view_count = int_or_none(media.get('views'))\n\n        age_restriction = media.get('age_restriction')\n        age_limit = None\n        if age_restriction:\n            age_limit = 0 if age_restriction == 'allow_all' else 18\n\n        secure_m3u8 = self._proto_relative_url(media['sources']['secure_m3u8']['auto'], 'http:')\n\n        m3u8_url = self._get_video_url(secure_m3u8, video_id, 'Downloading m3u8 JSON')\n        formats = self._extract_m3u8_formats(\n            m3u8_url, video_id,\n            'mp4', entry_protocol='m3u8_native', m3u8_id='hls')\n\n        mp4_url = self._get_video_url(\n            # Secure mp4 URL is constructed according to Player.prototype.mp4 from\n            # http://lentaru.media.eagleplatform.com/player/player.js\n            re.sub(r'm3u8|hlsvod|hls|f4m', 'mp4', secure_m3u8),\n            video_id, 'Downloading mp4 JSON')\n        formats.append({'url': mp4_url, 'format_id': 'mp4'})\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 65,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.exfm.ExfmIE._real_extract#41",
        "src_path": "youtube_dl/extractor/exfm.py",
        "class_name": "youtube_dl.extractor.exfm.ExfmIE",
        "signature": "youtube_dl.extractor.exfm.ExfmIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        song_id = mobj.group('id')\n        info_url = \"http://ex.fm/api/v3/song/%s\" % song_id\n        info = self._download_json(info_url, song_id)['song']\n        song_url = info['url']\n        if re.match(self._SOUNDCLOUD_URL, song_url) is not None:\n            self.to_screen('Soundcloud song detected')\n            return self.url_result(song_url.replace('/stream', ''), 'Soundcloud')\n        return {\n            'id': song_id,\n            'url': song_url,\n            'ext': 'mp3',\n            'title': info['title'],\n            'thumbnail': info['image']['large'],\n            'uploader': info['artist'],\n            'view_count': info['loved_count'],\n        }",
        "begin_line": 41,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.freesound.FreesoundIE._real_extract#22",
        "src_path": "youtube_dl/extractor/freesound.py",
        "class_name": "youtube_dl.extractor.freesound.FreesoundIE",
        "signature": "youtube_dl.extractor.freesound.FreesoundIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        music_id = mobj.group('id')\n        webpage = self._download_webpage(url, music_id)\n        title = self._html_search_regex(\n            r'<div id=\"single_sample_header\">.*?<a href=\"#\">(.+?)</a>',\n            webpage, 'music title', flags=re.DOTALL)\n        description = self._html_search_regex(\n            r'<div id=\"sound_description\">(.*?)</div>', webpage, 'description',\n            fatal=False, flags=re.DOTALL)\n\n        return {\n            'id': music_id,\n            'title': title,\n            'url': self._og_search_property('audio', webpage, 'music url'),\n            'uploader': self._og_search_property('audio:artist', webpage, 'music uploader'),\n            'description': description,\n        }",
        "begin_line": 22,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pladform.PladformIE._real_extract#47",
        "src_path": "youtube_dl/extractor/pladform.py",
        "class_name": "youtube_dl.extractor.pladform.PladformIE",
        "signature": "youtube_dl.extractor.pladform.PladformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_xml(\n            'http://out.pladform.ru/getVideo?pl=1&videoid=%s' % video_id,\n            video_id)\n\n        if video.tag == 'error':\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, video.text),\n                expected=True)\n\n        quality = qualities(('ld', 'sd', 'hd'))\n\n        formats = [{\n            'url': src.text,\n            'format_id': src.get('quality'),\n            'quality': quality(src.get('quality')),\n        } for src in video.findall('./src')]\n        self._sort_formats(formats)\n\n        webpage = self._download_webpage(\n            'http://video.pladform.ru/catalog/video/videoid/%s' % video_id,\n            video_id)\n\n        title = self._og_search_title(webpage, fatal=False) or xpath_text(\n            video, './/title', 'title', fatal=True)\n        description = self._search_regex(\n            r'</h3>\\s*<p>([^<]+)</p>', webpage, 'description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage) or xpath_text(\n            video, './/cover', 'cover')\n\n        duration = int_or_none(xpath_text(video, './/time', 'duration'))\n        age_limit = int_or_none(xpath_text(video, './/age18', 'age limit'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 47,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.aljazeera.AlJazeeraIE._real_extract#22",
        "src_path": "youtube_dl/extractor/aljazeera.py",
        "class_name": "youtube_dl.extractor.aljazeera.AlJazeeraIE",
        "signature": "youtube_dl.extractor.aljazeera.AlJazeeraIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        program_name = self._match_id(url)\n        webpage = self._download_webpage(url, program_name)\n        brightcove_id = self._search_regex(\n            r'RenderPagesVideo\\(\\'(.+?)\\'', webpage, 'brightcove id')\n\n        return {\n            '_type': 'url',\n            'url': (\n                'brightcove:'\n                'playerKey=AQ~~%2CAAAAmtVJIFk~%2CTVGOQ5ZTwJbeMWnq5d_H4MOM57xfzApc'\n                '&%40videoPlayer={0}'.format(brightcove_id)\n            ),\n            'ie_key': 'Brightcove',\n        }",
        "begin_line": 22,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.toutv.TouTvIE._real_extract#36",
        "src_path": "youtube_dl/extractor/toutv.py",
        "class_name": "youtube_dl.extractor.toutv.TouTvIE",
        "signature": "youtube_dl.extractor.toutv.TouTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        mediaId = self._search_regex(\n            r'\"idMedia\":\\s*\"([^\"]+)\"', webpage, 'media ID')\n\n        streams_url = 'http://release.theplatform.com/content.select?pid=' + mediaId\n        streams_doc = self._download_xml(\n            streams_url, video_id, note='Downloading stream list')\n\n        video_url = next(n.text\n                         for n in streams_doc.findall('.//choice/url')\n                         if '//ad.doubleclick' not in n.text)\n        if video_url.endswith('/Unavailable.flv'):\n            raise ExtractorError(\n                'Access to this video is blocked from outside of Canada',\n                expected=True)\n\n        duration_str = self._html_search_meta(\n            'video:duration', webpage, 'duration')\n        duration = int(duration_str) if duration_str else None\n        upload_date_str = self._html_search_meta(\n            'video:release_date', webpage, 'upload date')\n        upload_date = unified_strdate(upload_date_str) if upload_date_str else None\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'url': video_url,\n            'description': self._og_search_description(webpage),\n            'uploader': self._dc_search_uploader(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'age_limit': self._media_rating_search(webpage),\n            'duration': duration,\n            'upload_date': upload_date,\n            'ext': 'mp4',\n        }",
        "begin_line": 36,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nationalgeographic.NationalGeographicIE._real_extract#36",
        "src_path": "youtube_dl/extractor/nationalgeographic.py",
        "class_name": "youtube_dl.extractor.nationalgeographic.NationalGeographicIE",
        "signature": "youtube_dl.extractor.nationalgeographic.NationalGeographicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        name = url_basename(url)\n\n        webpage = self._download_webpage(url, name)\n        feed_url = self._search_regex(\n            r'data-feed-url=\"([^\"]+)\"', webpage, 'feed url')\n        guid = self._search_regex(\n            r'id=\"(?:videoPlayer|player-container)\"[^>]+data-guid=\"([^\"]+)\"',\n            webpage, 'guid')\n\n        feed = self._download_xml('%s?byGuid=%s' % (feed_url, guid), name)\n        content = feed.find('.//{http://search.yahoo.com/mrss/}content')\n        theplatform_id = url_basename(content.attrib.get('url'))\n\n        return self.url_result(smuggle_url(\n            'http://link.theplatform.com/s/ngs/%s?format=SMIL&formats=MPEG4&manifest=f4m' % theplatform_id,\n            # For some reason, the normal links don't work and we must force\n            # the use of f4m\n            {'force_smil_url': True}))",
        "begin_line": 36,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE._real_extract#150",
        "src_path": "youtube_dl/extractor/comedycentral.py",
        "class_name": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE",
        "signature": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        if mobj.group('shortname'):\n            return self.url_result('http://www.cc.com/shows/the-daily-show-with-trevor-noah/full-episodes')\n\n        if mobj.group('clip'):\n            if mobj.group('videotitle'):\n                epTitle = mobj.group('videotitle')\n            elif mobj.group('showname') == 'thedailyshow':\n                epTitle = mobj.group('tdstitle')\n            else:\n                epTitle = mobj.group('cntitle')\n            dlNewest = False\n        elif mobj.group('interview'):\n            epTitle = mobj.group('interview_title')\n            dlNewest = False\n        else:\n            dlNewest = not mobj.group('episode')\n            if dlNewest:\n                epTitle = mobj.group('showname')\n            else:\n                epTitle = mobj.group('episode')\n        show_name = mobj.group('showname')\n\n        webpage, htmlHandle = self._download_webpage_handle(url, epTitle)\n        if dlNewest:\n            url = htmlHandle.geturl()\n            mobj = re.match(self._VALID_URL, url, re.VERBOSE)\n            if mobj is None:\n                raise ExtractorError('Invalid redirected URL: ' + url)\n            if mobj.group('episode') == '':\n                raise ExtractorError('Redirected URL is still not specific: ' + url)\n            epTitle = (mobj.group('episode') or mobj.group('videotitle')).rpartition('/')[-1]\n\n        mMovieParams = re.findall('(?:<param name=\"movie\" value=\"|var url = \")(http://media.mtvnservices.com/([^\"]*(?:episode|video).*?:.*?))\"', webpage)\n        if len(mMovieParams) == 0:\n            # The Colbert Report embeds the information in a without\n            # a URL prefix; so extract the alternate reference\n            # and then add the URL prefix manually.\n\n            altMovieParams = re.findall('data-mgid=\"([^\"]*(?:episode|video|playlist).*?:.*?)\"', webpage)\n            if len(altMovieParams) == 0:\n                raise ExtractorError('unable to find Flash URL in webpage ' + url)\n            else:\n                mMovieParams = [(\"http://media.mtvnservices.com/\" + altMovieParams[0], altMovieParams[0])]\n\n        uri = mMovieParams[0][1]\n        # Correct cc.com in uri\n        uri = re.sub(r'(episode:[^.]+)(\\.cc)?\\.com', r'\\1.com', uri)\n\n        index_url = 'http://%s.cc.com/feeds/mrss?%s' % (show_name, compat_urllib_parse.urlencode({'uri': uri}))\n        idoc = self._download_xml(\n            index_url, epTitle,\n            'Downloading show index', 'Unable to download episode index')\n\n        title = idoc.find('./channel/title').text\n        description = idoc.find('./channel/description').text\n\n        entries = []\n        item_els = idoc.findall('.//item')\n        for part_num, itemEl in enumerate(item_els):\n            upload_date = unified_strdate(itemEl.findall('./pubDate')[0].text)\n            thumbnail = itemEl.find('.//{http://search.yahoo.com/mrss/}thumbnail').attrib.get('url')\n\n            content = itemEl.find('.//{http://search.yahoo.com/mrss/}content')\n            duration = float_or_none(content.attrib.get('duration'))\n            mediagen_url = content.attrib['url']\n            guid = itemEl.find('./guid').text.rpartition(':')[-1]\n\n            cdoc = self._download_xml(\n                mediagen_url, epTitle,\n                'Downloading configuration for segment %d / %d' % (part_num + 1, len(item_els)))\n\n            turls = []\n            for rendition in cdoc.findall('.//rendition'):\n                finfo = (rendition.attrib['bitrate'], rendition.findall('./src')[0].text)\n                turls.append(finfo)\n\n            formats = []\n            for format, rtmp_video_url in turls:\n                w, h = self._video_dimensions.get(format, (None, None))\n                formats.append({\n                    'format_id': 'vhttp-%s' % format,\n                    'url': self._transform_rtmp_url(rtmp_video_url),\n                    'ext': self._video_extensions.get(format, 'mp4'),\n                    'height': h,\n                    'width': w,\n                })\n                formats.append({\n                    'format_id': 'rtmp-%s' % format,\n                    'url': rtmp_video_url.replace('viacomccstrm', 'viacommtvstrm'),\n                    'ext': self._video_extensions.get(format, 'mp4'),\n                    'height': h,\n                    'width': w,\n                })\n                self._sort_formats(formats)\n\n            subtitles = self._extract_subtitles(cdoc, guid)\n\n            virtual_id = show_name + ' ' + epTitle + ' part ' + compat_str(part_num + 1)\n            entries.append({\n                'id': guid,\n                'title': virtual_id,\n                'formats': formats,\n                'uploader': show_name,\n                'upload_date': upload_date,\n                'duration': duration,\n                'thumbnail': thumbnail,\n                'description': description,\n                'subtitles': subtitles,\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': epTitle,\n            'entries': entries,\n            'title': show_name + ' ' + title,\n            'description': description,\n        }",
        "begin_line": 150,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.rtmp.rtmpdump_version#18",
        "src_path": "youtube_dl/downloader/rtmp.py",
        "class_name": "youtube_dl.downloader.rtmp",
        "signature": "youtube_dl.downloader.rtmp.rtmpdump_version()",
        "snippet": "def rtmpdump_version():\n    return get_exe_version(\n        'rtmpdump', ['--help'], r'(?i)RTMPDump\\s*v?([0-9a-zA-Z._-]+)')",
        "begin_line": 18,
        "end_line": 20,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.downloader.rtmp.RtmpFD.real_download#24",
        "src_path": "youtube_dl/downloader/rtmp.py",
        "class_name": "youtube_dl.downloader.rtmp.RtmpFD",
        "signature": "youtube_dl.downloader.rtmp.RtmpFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        def run_rtmpdump(args):\n            start = time.time()\n            resume_percent = None\n            resume_downloaded_data_len = None\n            proc = subprocess.Popen(args, stderr=subprocess.PIPE)\n            cursor_in_new_line = True\n            proc_stderr_closed = False\n            while not proc_stderr_closed:\n                # read line from stderr\n                line = ''\n                while True:\n                    char = proc.stderr.read(1)\n                    if not char:\n                        proc_stderr_closed = True\n                        break\n                    if char in [b'\\r', b'\\n']:\n                        break\n                    line += char.decode('ascii', 'replace')\n                if not line:\n                    # proc_stderr_closed is True\n                    continue\n                mobj = re.search(r'([0-9]+\\.[0-9]{3}) kB / [0-9]+\\.[0-9]{2} sec \\(([0-9]{1,2}\\.[0-9])%\\)', line)\n                if mobj:\n                    downloaded_data_len = int(float(mobj.group(1)) * 1024)\n                    percent = float(mobj.group(2))\n                    if not resume_percent:\n                        resume_percent = percent\n                        resume_downloaded_data_len = downloaded_data_len\n                    time_now = time.time()\n                    eta = self.calc_eta(start, time_now, 100 - resume_percent, percent - resume_percent)\n                    speed = self.calc_speed(start, time_now, downloaded_data_len - resume_downloaded_data_len)\n                    data_len = None\n                    if percent > 0:\n                        data_len = int(downloaded_data_len * 100 / percent)\n                    self._hook_progress({\n                        'status': 'downloading',\n                        'downloaded_bytes': downloaded_data_len,\n                        'total_bytes_estimate': data_len,\n                        'tmpfilename': tmpfilename,\n                        'filename': filename,\n                        'eta': eta,\n                        'elapsed': time_now - start,\n                        'speed': speed,\n                    })\n                    cursor_in_new_line = False\n                else:\n                    # no percent for live streams\n                    mobj = re.search(r'([0-9]+\\.[0-9]{3}) kB / [0-9]+\\.[0-9]{2} sec', line)\n                    if mobj:\n                        downloaded_data_len = int(float(mobj.group(1)) * 1024)\n                        time_now = time.time()\n                        speed = self.calc_speed(start, time_now, downloaded_data_len)\n                        self._hook_progress({\n                            'downloaded_bytes': downloaded_data_len,\n                            'tmpfilename': tmpfilename,\n                            'filename': filename,\n                            'status': 'downloading',\n                            'elapsed': time_now - start,\n                            'speed': speed,\n                        })\n                        cursor_in_new_line = False\n                    elif self.params.get('verbose', False):\n                        if not cursor_in_new_line:\n                            self.to_screen('')\n                        cursor_in_new_line = True\n                        self.to_screen('[rtmpdump] ' + line)\n            proc.wait()\n            if not cursor_in_new_line:\n                self.to_screen('')\n            return proc.returncode\n\n        url = info_dict['url']\n        player_url = info_dict.get('player_url', None)\n        page_url = info_dict.get('page_url', None)\n        app = info_dict.get('app', None)\n        play_path = info_dict.get('play_path', None)\n        tc_url = info_dict.get('tc_url', None)\n        flash_version = info_dict.get('flash_version', None)\n        live = info_dict.get('rtmp_live', False)\n        conn = info_dict.get('rtmp_conn', None)\n        protocol = info_dict.get('rtmp_protocol', None)\n        real_time = info_dict.get('rtmp_real_time', False)\n        no_resume = info_dict.get('no_resume', False)\n        continue_dl = self.params.get('continuedl', True)\n\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n        test = self.params.get('test', False)\n\n        # Check for rtmpdump first\n        if not check_executable('rtmpdump', ['-h']):\n            self.report_error('RTMP download detected but \"rtmpdump\" could not be run. Please install it.')\n            return False\n\n        # Download using rtmpdump. rtmpdump returns exit code 2 when\n        # the connection was interrumpted and resuming appears to be\n        # possible. This is part of rtmpdump's normal usage, AFAIK.\n        basic_args = [\n            'rtmpdump', '--verbose', '-r', url,\n            '-o', tmpfilename]\n        if player_url is not None:\n            basic_args += ['--swfVfy', player_url]\n        if page_url is not None:\n            basic_args += ['--pageUrl', page_url]\n        if app is not None:\n            basic_args += ['--app', app]\n        if play_path is not None:\n            basic_args += ['--playpath', play_path]\n        if tc_url is not None:\n            basic_args += ['--tcUrl', tc_url]\n        if test:\n            basic_args += ['--stop', '1']\n        if flash_version is not None:\n            basic_args += ['--flashVer', flash_version]\n        if live:\n            basic_args += ['--live']\n        if isinstance(conn, list):\n            for entry in conn:\n                basic_args += ['--conn', entry]\n        elif isinstance(conn, compat_str):\n            basic_args += ['--conn', conn]\n        if protocol is not None:\n            basic_args += ['--protocol', protocol]\n        if real_time:\n            basic_args += ['--realtime']\n\n        args = basic_args\n        if not no_resume and continue_dl and not live:\n            args += ['--resume']\n        if not live and continue_dl:\n            args += ['--skip', '1']\n\n        args = [encodeArgument(a) for a in args]\n\n        self._debug_cmd(args, exe='rtmpdump')\n\n        RD_SUCCESS = 0\n        RD_FAILED = 1\n        RD_INCOMPLETE = 2\n        RD_NO_CONNECT = 3\n\n        retval = run_rtmpdump(args)\n\n        if retval == RD_NO_CONNECT:\n            self.report_error('[rtmpdump] Could not connect to RTMP server.')\n            return False\n\n        while (retval == RD_INCOMPLETE or retval == RD_FAILED) and not test and not live:\n            prevsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('[rtmpdump] %s bytes' % prevsize)\n            time.sleep(5.0)  # This seems to be needed\n            args = basic_args + ['--resume']\n            if retval == RD_FAILED:\n                args += ['--skip', '1']\n            args = [encodeArgument(a) for a in args]\n            retval = run_rtmpdump(args)\n            cursize = os.path.getsize(encodeFilename(tmpfilename))\n            if prevsize == cursize and retval == RD_FAILED:\n                break\n            # Some rtmp streams seem abort after ~ 99.8%. Don't complain for those\n            if prevsize == cursize and retval == RD_INCOMPLETE and cursize > 1024:\n                self.to_screen('[rtmpdump] Could not download the whole video. This can happen for some advertisements.')\n                retval = RD_SUCCESS\n                break\n        if retval == RD_SUCCESS or (test and retval == RD_INCOMPLETE):\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('[rtmpdump] %s bytes' % fsize)\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr('\\n')\n            self.report_error('rtmpdump exited with code %d' % retval)\n            return False",
        "begin_line": 24,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.archiveorg.ArchiveOrgIE._real_extract#33",
        "src_path": "youtube_dl/extractor/archiveorg.py",
        "class_name": "youtube_dl.extractor.archiveorg.ArchiveOrgIE",
        "signature": "youtube_dl.extractor.archiveorg.ArchiveOrgIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        json_url = url + ('&' if '?' in url else '?') + 'output=json'\n        data = self._download_json(json_url, video_id)\n\n        def get_optional(data_dict, field):\n            return data_dict['metadata'].get(field, [None])[0]\n\n        title = get_optional(data, 'title')\n        description = get_optional(data, 'description')\n        uploader = get_optional(data, 'creator')\n        upload_date = unified_strdate(get_optional(data, 'date'))\n\n        formats = [\n            {\n                'format': fdata['format'],\n                'url': 'http://' + data['server'] + data['dir'] + fn,\n                'file_size': int(fdata['size']),\n            }\n            for fn, fdata in data['files'].items()\n            if 'Video' in fdata['format']]\n\n        self._sort_formats(formats)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'thumbnail': data.get('misc', {}).get('image'),\n        }",
        "begin_line": 33,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.folketinget.FolketingetIE._real_extract#39",
        "src_path": "youtube_dl/extractor/folketinget.py",
        "class_name": "youtube_dl.extractor.folketinget.FolketingetIE",
        "signature": "youtube_dl.extractor.folketinget.FolketingetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage)\n        description = self._html_search_regex(\n            r'(?s)<div class=\"video-item-agenda\"[^>]*>(.*?)<',\n            webpage, 'description', fatal=False)\n\n        player_params = compat_parse_qs(self._search_regex(\n            r'<embed src=\"http://ft\\.arkena\\.tv/flash/ftplayer\\.swf\\?([^\"]+)\"',\n            webpage, 'player params'))\n        xml_url = player_params['xml'][0]\n        doc = self._download_xml(xml_url, video_id)\n\n        timestamp = parse_iso8601(xpath_text(doc, './/date'))\n        duration = parse_duration(xpath_text(doc, './/duration'))\n        width = int_or_none(xpath_text(doc, './/width'))\n        height = int_or_none(xpath_text(doc, './/height'))\n        view_count = int_or_none(xpath_text(doc, './/views'))\n\n        formats = [{\n            'format_id': n.attrib['bitrate'],\n            'url': xpath_text(n, './url', fatal=True),\n            'tbr': int_or_none(n.attrib['bitrate']),\n        } for n in doc.findall('.//streams/stream')]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'timestamp': timestamp,\n            'width': width,\n            'height': height,\n            'duration': duration,\n            'view_count': view_count,\n        }",
        "begin_line": 39,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xuite.XuiteIE.base64_decode_utf8#74",
        "src_path": "youtube_dl/extractor/xuite.py",
        "class_name": "youtube_dl.extractor.xuite.XuiteIE",
        "signature": "youtube_dl.extractor.xuite.XuiteIE.base64_decode_utf8(data)",
        "snippet": "    def base64_decode_utf8(data):\n        return base64.b64decode(data.encode('utf-8')).decode('utf-8')",
        "begin_line": 74,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xuite.XuiteIE.base64_encode_utf8#78",
        "src_path": "youtube_dl/extractor/xuite.py",
        "class_name": "youtube_dl.extractor.xuite.XuiteIE",
        "signature": "youtube_dl.extractor.xuite.XuiteIE.base64_encode_utf8(data)",
        "snippet": "    def base64_encode_utf8(data):\n        return base64.b64encode(data.encode('utf-8')).decode('utf-8')",
        "begin_line": 78,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xuite.XuiteIE._extract_flv_config#81",
        "src_path": "youtube_dl/extractor/xuite.py",
        "class_name": "youtube_dl.extractor.xuite.XuiteIE",
        "signature": "youtube_dl.extractor.xuite.XuiteIE._extract_flv_config(self, media_id)",
        "snippet": "    def _extract_flv_config(self, media_id):\n        base64_media_id = self.base64_encode_utf8(media_id)\n        flv_config = self._download_xml(\n            'http://vlog.xuite.net/flash/player?media=%s' % base64_media_id,\n            'flv config')\n        prop_dict = {}\n        for prop in flv_config.findall('./property'):\n            prop_id = self.base64_decode_utf8(prop.attrib['id'])\n            # CDATA may be empty in flv config\n            if not prop.text:\n                continue\n            encoded_content = self.base64_decode_utf8(prop.text)\n            prop_dict[prop_id] = compat_urllib_parse_unquote(encoded_content)\n        return prop_dict",
        "begin_line": 81,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xuite.XuiteIE._real_extract#96",
        "src_path": "youtube_dl/extractor/xuite.py",
        "class_name": "youtube_dl.extractor.xuite.XuiteIE",
        "signature": "youtube_dl.extractor.xuite.XuiteIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        error_msg = self._search_regex(\n            r'<div id=\"error-message-content\">([^<]+)',\n            webpage, 'error message', default=None)\n        if error_msg:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error_msg),\n                expected=True)\n\n        video_id = self._html_search_regex(\n            r'data-mediaid=\"(\\d+)\"', webpage, 'media id')\n        flv_config = self._extract_flv_config(video_id)\n\n        FORMATS = {\n            'audio': 'mp3',\n            'video': 'mp4',\n        }\n\n        formats = []\n        for format_tag in ('src', 'hq_src'):\n            video_url = flv_config.get(format_tag)\n            if not video_url:\n                continue\n            format_id = self._search_regex(\n                r'\\bq=(.+?)\\b', video_url, 'format id', default=format_tag)\n            formats.append({\n                'url': video_url,\n                'ext': FORMATS.get(flv_config['type'], 'mp4'),\n                'format_id': format_id,\n                'height': int(format_id) if format_id.isnumeric() else None,\n            })\n        self._sort_formats(formats)\n\n        timestamp = flv_config.get('publish_datetime')\n        if timestamp:\n            timestamp = parse_iso8601(timestamp + ' +0800', ' ')\n\n        category = flv_config.get('category')\n        categories = [category] if category else []\n\n        return {\n            'id': video_id,\n            'title': flv_config['title'],\n            'description': flv_config.get('description'),\n            'thumbnail': flv_config.get('thumb'),\n            'timestamp': timestamp,\n            'uploader': flv_config.get('author_name'),\n            'uploader_id': flv_config.get('author_id'),\n            'duration': parse_duration(flv_config.get('duration')),\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 96,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mitele.MiTeleIE._real_extract#33",
        "src_path": "youtube_dl/extractor/mitele.py",
        "class_name": "youtube_dl.extractor.mitele.MiTeleIE",
        "signature": "youtube_dl.extractor.mitele.MiTeleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        config_url = self._search_regex(\n            r'data-config\\s*=\\s*\"([^\"]+)\"', webpage, 'data config url')\n        config_url = compat_urlparse.urljoin(url, config_url)\n\n        config = self._download_json(\n            config_url, display_id, 'Downloading config JSON')\n\n        mmc = self._download_json(\n            config['services']['mmc'], display_id, 'Downloading mmc JSON')\n\n        formats = []\n        for location in mmc['locations']:\n            gat = self._proto_relative_url(location.get('gat'), 'http:')\n            bas = location.get('bas')\n            loc = location.get('loc')\n            ogn = location.get('ogn')\n            if None in (gat, bas, loc, ogn):\n                continue\n            token_data = {\n                'bas': bas,\n                'icd': loc,\n                'ogn': ogn,\n                'sta': '0',\n            }\n            media = self._download_json(\n                '%s/?%s' % (gat, compat_urllib_parse.urlencode(encode_dict(token_data))),\n                display_id, 'Downloading %s JSON' % location['loc'])\n            file_ = media.get('file')\n            if not file_:\n                continue\n            formats.extend(self._extract_f4m_formats(\n                file_ + '&hdcore=3.2.0&plugin=aasp-3.2.0.77.18',\n                display_id, f4m_id=loc))\n\n        title = self._search_regex(\n            r'class=\"Destacado-text\"[^>]*>\\s*<strong>([^<]+)</strong>', webpage, 'title')\n\n        video_id = self._search_regex(\n            r'data-media-id\\s*=\\s*\"([^\"]+)\"', webpage,\n            'data media id', default=None) or display_id\n        thumbnail = config.get('poster', {}).get('imageUrl')\n        duration = int_or_none(mmc.get('duration'))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': get_element_by_attribute('class', 'text', webpage),\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 33,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__init__#277",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__init__(self, params=None, auto_init=True)",
        "snippet": "    def __init__(self, params=None, auto_init=True):\n        \"\"\"Create a FileDownloader object with the given options.\"\"\"\n        if params is None:\n            params = {}\n        self._ies = []\n        self._ies_instances = {}\n        self._pps = []\n        self._progress_hooks = []\n        self._download_retcode = 0\n        self._num_downloads = 0\n        self._screen_file = [sys.stdout, sys.stderr][params.get('logtostderr', False)]\n        self._err_file = sys.stderr\n        self.params = {\n            # Default parameters\n            'nocheckcertificate': False,\n        }\n        self.params.update(params)\n        self.cache = Cache(self)\n\n        if params.get('bidi_workaround', False):\n            try:\n                import pty\n                master, slave = pty.openpty()\n                width = compat_get_terminal_size().columns\n                if width is None:\n                    width_args = []\n                else:\n                    width_args = ['-w', str(width)]\n                sp_kwargs = dict(\n                    stdin=subprocess.PIPE,\n                    stdout=slave,\n                    stderr=self._err_file)\n                try:\n                    self._output_process = subprocess.Popen(\n                        ['bidiv'] + width_args, **sp_kwargs\n                    )\n                except OSError:\n                    self._output_process = subprocess.Popen(\n                        ['fribidi', '-c', 'UTF-8'] + width_args, **sp_kwargs)\n                self._output_channel = os.fdopen(master, 'rb')\n            except OSError as ose:\n                if ose.errno == 2:\n                    self.report_warning('Could not find fribidi executable, ignoring --bidi-workaround . Make sure that  fribidi  is an executable file in one of the directories in your $PATH.')\n                else:\n                    raise\n\n        if (sys.version_info >= (3,) and sys.platform != 'win32' and\n                sys.getfilesystemencoding() in ['ascii', 'ANSI_X3.4-1968'] and\n                not params.get('restrictfilenames', False)):\n            # On Python 3, the Unicode filesystem API will throw errors (#1474)\n            self.report_warning(\n                'Assuming --restrict-filenames since file system encoding '\n                'cannot encode all characters. '\n                'Set the LC_ALL environment variable to fix this.')\n            self.params['restrictfilenames'] = True\n\n        if isinstance(params.get('outtmpl'), bytes):\n            self.report_warning(\n                'Parameter outtmpl is bytes, but should be a unicode string. '\n                'Put  from __future__ import unicode_literals  at the top of your code file or consider switching to Python 3.x.')\n\n        self._setup_opener()\n\n        if auto_init:\n            self.print_debug_header()\n            self.add_default_info_extractors()\n\n        for pp_def_raw in self.params.get('postprocessors', []):\n            pp_class = get_postprocessor(pp_def_raw['key'])\n            pp_def = dict(pp_def_raw)\n            del pp_def['key']\n            pp = pp_class(self, **compat_kwargs(pp_def))\n            self.add_post_processor(pp)\n\n        for ph in self.params.get('progress_hooks', []):\n            self.add_progress_hook(ph)",
        "begin_line": 277,
        "end_line": 352,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004424778761061947,
            "pseudo_dstar_susp": 0.011494252873563218,
            "pseudo_tarantula_susp": 0.0010660980810234541,
            "pseudo_op2_susp": 0.011494252873563218,
            "pseudo_barinel_susp": 0.0010660980810234541
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.warn_if_short_id#354",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.warn_if_short_id(self, argv)",
        "snippet": "    def warn_if_short_id(self, argv):\n        # short YouTube ID starting with dash?\n        idxs = [\n            i for i, a in enumerate(argv)\n            if re.match(r'^-[0-9A-Za-z_-]{10}$', a)]\n        if idxs:\n            correct_argv = (\n                ['youtube-dl'] +\n                [a for i, a in enumerate(argv) if i not in idxs] +\n                ['--'] + [argv[i] for i in idxs]\n            )\n            self.report_warning(\n                'Long argument string detected. '\n                'Use -- to separate parameters and URLs, like this:\\n%s\\n' %\n                args_to_str(correct_argv))",
        "begin_line": 354,
        "end_line": 368,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_info_extractor#370",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_info_extractor(self, ie)",
        "snippet": "    def add_info_extractor(self, ie):\n        \"\"\"Add an InfoExtractor object to the end of the list.\"\"\"\n        self._ies.append(ie)\n        self._ies_instances[ie.ie_key()] = ie\n        ie.set_downloader(self)",
        "begin_line": 370,
        "end_line": 374,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008064516129032258,
            "pseudo_dstar_susp": 0.005813953488372093,
            "pseudo_tarantula_susp": 0.001349527665317139,
            "pseudo_op2_susp": 0.005813953488372093,
            "pseudo_barinel_susp": 0.001349527665317139
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.get_info_extractor#376",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.get_info_extractor(self, ie_key)",
        "snippet": "    def get_info_extractor(self, ie_key):\n        \"\"\"\n        Get an instance of an IE with name ie_key, it will try to get one from\n        the _ies list, if there's no instance it will create a new one and add\n        it to the extractor list.\n        \"\"\"\n        ie = self._ies_instances.get(ie_key)\n        if ie is None:\n            ie = get_info_extractor(ie_key)()\n            self.add_info_extractor(ie)\n        return ie",
        "begin_line": 376,
        "end_line": 386,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_default_info_extractors#388",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_default_info_extractors(self)",
        "snippet": "    def add_default_info_extractors(self):\n        \"\"\"\n        Add the InfoExtractors returned by gen_extractors to the end of the list\n        \"\"\"\n        for ie in gen_extractors():\n            self.add_info_extractor(ie)",
        "begin_line": 388,
        "end_line": 393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009372071227741331,
            "pseudo_dstar_susp": 0.0009363295880149813,
            "pseudo_tarantula_susp": 0.0009389671361502347,
            "pseudo_op2_susp": 0.0009363295880149813,
            "pseudo_barinel_susp": 0.0009389671361502347
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_post_processor#395",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_post_processor(self, pp)",
        "snippet": "    def add_post_processor(self, pp):\n        \"\"\"Add a PostProcessor object to the end of the chain.\"\"\"\n        self._pps.append(pp)\n        pp.set_downloader(self)",
        "begin_line": 395,
        "end_line": 398,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_progress_hook#400",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_progress_hook(self, ph)",
        "snippet": "    def add_progress_hook(self, ph):\n        \"\"\"Add the progress hook (currently only for the file downloader)\"\"\"\n        self._progress_hooks.append(ph)",
        "begin_line": 400,
        "end_line": 402,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._bidi_workaround#404",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._bidi_workaround(self, message)",
        "snippet": "    def _bidi_workaround(self, message):\n        if not hasattr(self, '_output_channel'):\n            return message\n\n        assert hasattr(self, '_output_process')\n        assert isinstance(message, compat_str)\n        line_count = message.count('\\n') + 1\n        self._output_process.stdin.write((message + '\\n').encode('utf-8'))\n        self._output_process.stdin.flush()\n        res = ''.join(self._output_channel.readline().decode('utf-8')\n                      for _ in range(line_count))\n        return res[:-len('\\n')]",
        "begin_line": 404,
        "end_line": 415,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024691358024691358,
            "pseudo_dstar_susp": 0.002421307506053269,
            "pseudo_tarantula_susp": 0.0013774104683195593,
            "pseudo_op2_susp": 0.002421307506053269,
            "pseudo_barinel_susp": 0.0013774104683195593
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_screen#417",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_screen(self, message, skip_eol=False)",
        "snippet": "    def to_screen(self, message, skip_eol=False):\n        \"\"\"Print message to stdout if not in quiet mode.\"\"\"\n        return self.to_stdout(message, skip_eol, check_quiet=True)",
        "begin_line": 417,
        "end_line": 419,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009784735812133072,
            "pseudo_dstar_susp": 0.0009775171065493646,
            "pseudo_tarantula_susp": 0.0009930486593843098,
            "pseudo_op2_susp": 0.0009775171065493646,
            "pseudo_barinel_susp": 0.0009930486593843098
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._write_string#421",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._write_string(self, s, out=None)",
        "snippet": "    def _write_string(self, s, out=None):\n        write_string(s, out=out, encoding=self.params.get('encoding'))",
        "begin_line": 421,
        "end_line": 422,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024691358024691358,
            "pseudo_dstar_susp": 0.002421307506053269,
            "pseudo_tarantula_susp": 0.0013774104683195593,
            "pseudo_op2_susp": 0.002421307506053269,
            "pseudo_barinel_susp": 0.0013774104683195593
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_stdout#424",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_stdout(self, message, skip_eol=False, check_quiet=False)",
        "snippet": "    def to_stdout(self, message, skip_eol=False, check_quiet=False):\n        \"\"\"Print message to stdout if not in quiet mode.\"\"\"\n        if self.params.get('logger'):\n            self.params['logger'].debug(message)\n        elif not check_quiet or not self.params.get('quiet', False):\n            message = self._bidi_workaround(message)\n            terminator = ['\\n', ''][skip_eol]\n            output = message + terminator\n\n            self._write_string(output, self._screen_file)",
        "begin_line": 424,
        "end_line": 433,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009930486593843098,
            "pseudo_dstar_susp": 0.000992063492063492,
            "pseudo_tarantula_susp": 0.0011337868480725624,
            "pseudo_op2_susp": 0.000992063492063492,
            "pseudo_barinel_susp": 0.0011337868480725624
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_stderr#435",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_stderr(self, message)",
        "snippet": "    def to_stderr(self, message):\n        \"\"\"Print message to stderr.\"\"\"\n        assert isinstance(message, compat_str)\n        if self.params.get('logger'):\n            self.params['logger'].error(message)\n        else:\n            message = self._bidi_workaround(message)\n            output = message + '\\n'\n            self._write_string(output, self._err_file)",
        "begin_line": 435,
        "end_line": 443,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0022675736961451248,
            "pseudo_dstar_susp": 0.002207505518763797,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.002207505518763797,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_console_title#445",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_console_title(self, message)",
        "snippet": "    def to_console_title(self, message):\n        if not self.params.get('consoletitle', False):\n            return\n        if os.name == 'nt' and ctypes.windll.kernel32.GetConsoleWindow():\n            # c_wchar_p() might not be necessary if `message` is\n            # already of type unicode()\n            ctypes.windll.kernel32.SetConsoleTitleW(ctypes.c_wchar_p(message))\n        elif 'TERM' in os.environ:\n            self._write_string('\\033]0;%s\\007' % message, self._screen_file)",
        "begin_line": 445,
        "end_line": 453,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.save_console_title#455",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.save_console_title(self)",
        "snippet": "    def save_console_title(self):\n        if not self.params.get('consoletitle', False):\n            return\n        if 'TERM' in os.environ:\n            # Save the title on stack\n            self._write_string('\\033[22;0t', self._screen_file)",
        "begin_line": 455,
        "end_line": 460,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.restore_console_title#462",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.restore_console_title(self)",
        "snippet": "    def restore_console_title(self):\n        if not self.params.get('consoletitle', False):\n            return\n        if 'TERM' in os.environ:\n            # Restore the title from stack\n            self._write_string('\\033[23;0t', self._screen_file)",
        "begin_line": 462,
        "end_line": 467,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__enter__#469",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__enter__(self)",
        "snippet": "    def __enter__(self):\n        self.save_console_title()\n        return self",
        "begin_line": 469,
        "end_line": 471,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__exit__#473",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__exit__(self, *args)",
        "snippet": "    def __exit__(self, *args):\n        self.restore_console_title()\n\n        if self.params.get('cookiefile') is not None:\n            self.cookiejar.save()",
        "begin_line": 473,
        "end_line": 477,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.trouble#479",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.trouble(self, message=None, tb=None)",
        "snippet": "    def trouble(self, message=None, tb=None):\n        \"\"\"Determine action to take when a download problem appears.\n\n        Depending on if the downloader has been configured to ignore\n        download errors or not, this method may throw an exception or\n        not when errors are found, after printing the message.\n\n        tb, if given, is additional traceback information.\n        \"\"\"\n        if message is not None:\n            self.to_stderr(message)\n        if self.params.get('verbose'):\n            if tb is None:\n                if sys.exc_info()[0]:  # if .trouble has been called from an except block\n                    tb = ''\n                    if hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:\n                        tb += ''.join(traceback.format_exception(*sys.exc_info()[1].exc_info))\n                    tb += compat_str(traceback.format_exc())\n                else:\n                    tb_data = traceback.format_list(traceback.extract_stack())\n                    tb = ''.join(tb_data)\n            self.to_stderr(tb)\n        if not self.params.get('ignoreerrors', False):\n            if sys.exc_info()[0] and hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:\n                exc_info = sys.exc_info()[1].exc_info\n            else:\n                exc_info = sys.exc_info()\n            raise DownloadError(message, exc_info)\n        self._download_retcode = 1",
        "begin_line": 479,
        "end_line": 507,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_warning#509",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_warning(self, message)",
        "snippet": "    def report_warning(self, message):\n        '''\n        Print the message to stderr, it will be prefixed with 'WARNING:'\n        If stderr is a tty file the 'WARNING:' will be colored\n        '''\n        if self.params.get('logger') is not None:\n            self.params['logger'].warning(message)\n        else:\n            if self.params.get('no_warnings'):\n                return\n            if not self.params.get('no_color') and self._err_file.isatty() and os.name != 'nt':\n                _msg_header = '\\033[0;33mWARNING:\\033[0m'\n            else:\n                _msg_header = 'WARNING:'\n            warning_message = '%s %s' % (_msg_header, message)\n            self.to_stderr(warning_message)",
        "begin_line": 509,
        "end_line": 524,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0022675736961451248,
            "pseudo_dstar_susp": 0.002207505518763797,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.002207505518763797,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_error#526",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_error(self, message, tb=None)",
        "snippet": "    def report_error(self, message, tb=None):\n        '''\n        Do the same as trouble, but prefixes the message with 'ERROR:', colored\n        in red if stderr is a tty file.\n        '''\n        if not self.params.get('no_color') and self._err_file.isatty() and os.name != 'nt':\n            _msg_header = '\\033[0;31mERROR:\\033[0m'\n        else:\n            _msg_header = 'ERROR:'\n        error_message = '%s %s' % (_msg_header, message)\n        self.trouble(error_message, tb)",
        "begin_line": 526,
        "end_line": 536,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.011904761904761904,
            "pseudo_dstar_susp": 0.005291005291005291,
            "pseudo_tarantula_susp": 0.001763668430335097,
            "pseudo_op2_susp": 0.005291005291005291,
            "pseudo_barinel_susp": 0.001763668430335097
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_file_already_downloaded#538",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_file_already_downloaded(self, file_name)",
        "snippet": "    def report_file_already_downloaded(self, file_name):\n        \"\"\"Report file has already been fully downloaded.\"\"\"\n        try:\n            self.to_screen('[download] %s has already been downloaded' % file_name)\n        except UnicodeEncodeError:\n            self.to_screen('[download] The file has already been downloaded')",
        "begin_line": 538,
        "end_line": 543,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.prepare_filename#545",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.prepare_filename(self, info_dict)",
        "snippet": "    def prepare_filename(self, info_dict):\n        \"\"\"Generate the output filename.\"\"\"\n        try:\n            template_dict = dict(info_dict)\n\n            template_dict['epoch'] = int(time.time())\n            autonumber_size = self.params.get('autonumber_size')\n            if autonumber_size is None:\n                autonumber_size = 5\n            autonumber_templ = '%0' + str(autonumber_size) + 'd'\n            template_dict['autonumber'] = autonumber_templ % self._num_downloads\n            if template_dict.get('playlist_index') is not None:\n                template_dict['playlist_index'] = '%0*d' % (len(str(template_dict['n_entries'])), template_dict['playlist_index'])\n            if template_dict.get('resolution') is None:\n                if template_dict.get('width') and template_dict.get('height'):\n                    template_dict['resolution'] = '%dx%d' % (template_dict['width'], template_dict['height'])\n                elif template_dict.get('height'):\n                    template_dict['resolution'] = '%sp' % template_dict['height']\n                elif template_dict.get('width'):\n                    template_dict['resolution'] = '?x%d' % template_dict['width']\n\n            sanitize = lambda k, v: sanitize_filename(\n                compat_str(v),\n                restricted=self.params.get('restrictfilenames'),\n                is_id=(k == 'id'))\n            template_dict = dict((k, sanitize(k, v))\n                                 for k, v in template_dict.items()\n                                 if v is not None)\n            template_dict = collections.defaultdict(lambda: 'NA', template_dict)\n\n            outtmpl = sanitize_path(self.params.get('outtmpl', DEFAULT_OUTTMPL))\n            tmpl = compat_expanduser(outtmpl)\n            filename = tmpl % template_dict\n            # Temporary fix for #4787\n            # 'Treat' all problem characters by passing filename through preferredencoding\n            # to workaround encoding issues with subprocess on python2 @ Windows\n            if sys.version_info < (3, 0) and sys.platform == 'win32':\n                filename = encodeFilename(filename, True).decode(preferredencoding())\n            return filename\n        except ValueError as err:\n            self.report_error('Error in output template: ' + str(err) + ' (encoding: ' + repr(preferredencoding()) + ')')\n            return None",
        "begin_line": 545,
        "end_line": 586,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._match_entry#588",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._match_entry(self, info_dict, incomplete)",
        "snippet": "    def _match_entry(self, info_dict, incomplete):\n        \"\"\" Returns None iff the file should be downloaded \"\"\"\n\n        video_title = info_dict.get('title', info_dict.get('id', 'video'))\n        if 'title' in info_dict:\n            # This can happen when we're just evaluating the playlist\n            title = info_dict['title']\n            matchtitle = self.params.get('matchtitle', False)\n            if matchtitle:\n                if not re.search(matchtitle, title, re.IGNORECASE):\n                    return '\"' + title + '\" title did not match pattern \"' + matchtitle + '\"'\n            rejecttitle = self.params.get('rejecttitle', False)\n            if rejecttitle:\n                if re.search(rejecttitle, title, re.IGNORECASE):\n                    return '\"' + title + '\" title matched reject pattern \"' + rejecttitle + '\"'\n        date = info_dict.get('upload_date', None)\n        if date is not None:\n            dateRange = self.params.get('daterange', DateRange())\n            if date not in dateRange:\n                return '%s upload date is not in range %s' % (date_from_str(date).isoformat(), dateRange)\n        view_count = info_dict.get('view_count', None)\n        if view_count is not None:\n            min_views = self.params.get('min_views')\n            if min_views is not None and view_count < min_views:\n                return 'Skipping %s, because it has not reached minimum view count (%d/%d)' % (video_title, view_count, min_views)\n            max_views = self.params.get('max_views')\n            if max_views is not None and view_count > max_views:\n                return 'Skipping %s, because it has exceeded the maximum view count (%d/%d)' % (video_title, view_count, max_views)\n        if age_restricted(info_dict.get('age_limit'), self.params.get('age_limit')):\n            return 'Skipping \"%s\" because it is age restricted' % video_title\n        if self.in_download_archive(info_dict):\n            return '%s has already been recorded in archive' % video_title\n\n        if not incomplete:\n            match_filter = self.params.get('match_filter')\n            if match_filter is not None:\n                ret = match_filter(info_dict)\n                if ret is not None:\n                    return ret\n\n        return None",
        "begin_line": 588,
        "end_line": 628,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_extra_info#631",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_extra_info(info_dict, extra_info)",
        "snippet": "    def add_extra_info(info_dict, extra_info):\n        '''Set the keys from extra_info in info dict if they are missing'''\n        for key, value in extra_info.items():\n            info_dict.setdefault(key, value)",
        "begin_line": 631,
        "end_line": 634,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.extract_info#636",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.extract_info(self, url, download=True, ie_key=None, extra_info={}, process=True, force_generic_extractor=False)",
        "snippet": "    def extract_info(self, url, download=True, ie_key=None, extra_info={},\n                     process=True, force_generic_extractor=False):\n        '''\n        Returns a list with a dictionary for each video we find.\n        If 'download', also downloads the videos.\n        extra_info is a dict containing the extra values to add to each result\n        '''\n\n        if not ie_key and force_generic_extractor:\n            ie_key = 'Generic'\n\n        if ie_key:\n            ies = [self.get_info_extractor(ie_key)]\n        else:\n            ies = self._ies\n\n        for ie in ies:\n            if not ie.suitable(url):\n                continue\n\n            if not ie.working():\n                self.report_warning('The program functionality for this site has been marked as broken, '\n                                    'and will probably not work.')\n\n            try:\n                ie_result = ie.extract(url)\n                if ie_result is None:  # Finished already (backwards compatibility; listformats and friends should be moved here)\n                    break\n                if isinstance(ie_result, list):\n                    # Backwards compatibility: old IE result format\n                    ie_result = {\n                        '_type': 'compat_list',\n                        'entries': ie_result,\n                    }\n                self.add_default_extra_info(ie_result, ie, url)\n                if process:\n                    return self.process_ie_result(ie_result, download, extra_info)\n                else:\n                    return ie_result\n            except ExtractorError as de:  # An error we somewhat expected\n                self.report_error(compat_str(de), de.format_traceback())\n                break\n            except MaxDownloadsReached:\n                raise\n            except Exception as e:\n                if self.params.get('ignoreerrors', False):\n                    self.report_error(compat_str(e), tb=compat_str(traceback.format_exc()))\n                    break\n                else:\n                    raise\n        else:\n            self.report_error('no suitable InfoExtractor for URL %s' % url)",
        "begin_line": 636,
        "end_line": 687,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02040816326530612,
            "pseudo_dstar_susp": 0.006993006993006993,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.006993006993006993,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_default_extra_info#689",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_default_extra_info(self, ie_result, ie, url)",
        "snippet": "    def add_default_extra_info(self, ie_result, ie, url):\n        self.add_extra_info(ie_result, {\n            'extractor': ie.IE_NAME,\n            'webpage_url': url,\n            'webpage_url_basename': url_basename(url),\n            'extractor_key': ie.ie_key(),\n        })",
        "begin_line": 689,
        "end_line": 695,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_ie_result#697",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_ie_result(self, ie_result, download=True, extra_info={})",
        "snippet": "    def process_ie_result(self, ie_result, download=True, extra_info={}):\n        \"\"\"\n        Take the result of the ie(may be modified) and resolve all unresolved\n        references (URLs, playlist items).\n\n        It will also download the videos if 'download'.\n        Returns the resolved ie_result.\n        \"\"\"\n\n        result_type = ie_result.get('_type', 'video')\n\n        if result_type in ('url', 'url_transparent'):\n            extract_flat = self.params.get('extract_flat', False)\n            if ((extract_flat == 'in_playlist' and 'playlist' in extra_info) or\n                    extract_flat is True):\n                if self.params.get('forcejson', False):\n                    self.to_stdout(json.dumps(ie_result))\n                return ie_result\n\n        if result_type == 'video':\n            self.add_extra_info(ie_result, extra_info)\n            return self.process_video_result(ie_result, download=download)\n        elif result_type == 'url':\n            # We have to add extra_info to the results because it may be\n            # contained in a playlist\n            return self.extract_info(ie_result['url'],\n                                     download,\n                                     ie_key=ie_result.get('ie_key'),\n                                     extra_info=extra_info)\n        elif result_type == 'url_transparent':\n            # Use the information from the embedding page\n            info = self.extract_info(\n                ie_result['url'], ie_key=ie_result.get('ie_key'),\n                extra_info=extra_info, download=False, process=False)\n\n            force_properties = dict(\n                (k, v) for k, v in ie_result.items() if v is not None)\n            for f in ('_type', 'url'):\n                if f in force_properties:\n                    del force_properties[f]\n            new_result = info.copy()\n            new_result.update(force_properties)\n\n            assert new_result.get('_type') != 'url_transparent'\n\n            return self.process_ie_result(\n                new_result, download=download, extra_info=extra_info)\n        elif result_type == 'playlist' or result_type == 'multi_video':\n            # We process each entry in the playlist\n            playlist = ie_result.get('title', None) or ie_result.get('id', None)\n            self.to_screen('[download] Downloading playlist: %s' % playlist)\n\n            playlist_results = []\n\n            playliststart = self.params.get('playliststart', 1) - 1\n            playlistend = self.params.get('playlistend', None)\n            # For backwards compatibility, interpret -1 as whole list\n            if playlistend == -1:\n                playlistend = None\n\n            playlistitems_str = self.params.get('playlist_items', None)\n            playlistitems = None\n            if playlistitems_str is not None:\n                def iter_playlistitems(format):\n                    for string_segment in format.split(','):\n                        if '-' in string_segment:\n                            start, end = string_segment.split('-')\n                            for item in range(int(start), int(end) + 1):\n                                yield int(item)\n                        else:\n                            yield int(string_segment)\n                playlistitems = iter_playlistitems(playlistitems_str)\n\n            ie_entries = ie_result['entries']\n            if isinstance(ie_entries, list):\n                n_all_entries = len(ie_entries)\n                if playlistitems:\n                    entries = [\n                        ie_entries[i - 1] for i in playlistitems\n                        if -n_all_entries <= i - 1 < n_all_entries]\n                else:\n                    entries = ie_entries[playliststart:playlistend]\n                n_entries = len(entries)\n                self.to_screen(\n                    \"[%s] playlist %s: Collected %d video ids (downloading %d of them)\" %\n                    (ie_result['extractor'], playlist, n_all_entries, n_entries))\n            elif isinstance(ie_entries, PagedList):\n                if playlistitems:\n                    entries = []\n                    for item in playlistitems:\n                        entries.extend(ie_entries.getslice(\n                            item - 1, item\n                        ))\n                else:\n                    entries = ie_entries.getslice(\n                        playliststart, playlistend)\n                n_entries = len(entries)\n                self.to_screen(\n                    \"[%s] playlist %s: Downloading %d videos\" %\n                    (ie_result['extractor'], playlist, n_entries))\n            else:  # iterable\n                if playlistitems:\n                    entry_list = list(ie_entries)\n                    entries = [entry_list[i - 1] for i in playlistitems]\n                else:\n                    entries = list(itertools.islice(\n                        ie_entries, playliststart, playlistend))\n                n_entries = len(entries)\n                self.to_screen(\n                    \"[%s] playlist %s: Downloading %d videos\" %\n                    (ie_result['extractor'], playlist, n_entries))\n\n            if self.params.get('playlistreverse', False):\n                entries = entries[::-1]\n\n            for i, entry in enumerate(entries, 1):\n                self.to_screen('[download] Downloading video %s of %s' % (i, n_entries))\n                extra = {\n                    'n_entries': n_entries,\n                    'playlist': playlist,\n                    'playlist_id': ie_result.get('id'),\n                    'playlist_title': ie_result.get('title'),\n                    'playlist_index': i + playliststart,\n                    'extractor': ie_result['extractor'],\n                    'webpage_url': ie_result['webpage_url'],\n                    'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                    'extractor_key': ie_result['extractor_key'],\n                }\n\n                reason = self._match_entry(entry, incomplete=True)\n                if reason is not None:\n                    self.to_screen('[download] ' + reason)\n                    continue\n\n                entry_result = self.process_ie_result(entry,\n                                                      download=download,\n                                                      extra_info=extra)\n                playlist_results.append(entry_result)\n            ie_result['entries'] = playlist_results\n            return ie_result\n        elif result_type == 'compat_list':\n            self.report_warning(\n                'Extractor %s returned a compat_list result. '\n                'It needs to be updated.' % ie_result.get('extractor'))\n\n            def _fixup(r):\n                self.add_extra_info(\n                    r,\n                    {\n                        'extractor': ie_result['extractor'],\n                        'webpage_url': ie_result['webpage_url'],\n                        'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                        'extractor_key': ie_result['extractor_key'],\n                    }\n                )\n                return r\n            ie_result['entries'] = [\n                self.process_ie_result(_fixup(r), download, extra_info)\n                for r in ie_result['entries']\n            ]\n            return ie_result\n        else:\n            raise Exception('Invalid result type: %s' % result_type)",
        "begin_line": 697,
        "end_line": 859,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.iter_playlistitems#760",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.iter_playlistitems(format)",
        "snippet": "                def iter_playlistitems(format):\n                    for string_segment in format.split(','):\n                        if '-' in string_segment:\n                            start, end = string_segment.split('-')\n                            for item in range(int(start), int(end) + 1):\n                                yield int(item)\n                        else:\n                            yield int(string_segment)",
        "begin_line": 760,
        "end_line": 767,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._build_format_filter#861",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._build_format_filter(self, filter_spec)",
        "snippet": "    def _build_format_filter(self, filter_spec):\n        \" Returns a function to filter the formats according to the filter_spec \"\n\n        OPERATORS = {\n            '<': operator.lt,\n            '<=': operator.le,\n            '>': operator.gt,\n            '>=': operator.ge,\n            '=': operator.eq,\n            '!=': operator.ne,\n        }\n        operator_rex = re.compile(r'''(?x)\\s*\n            (?P<key>width|height|tbr|abr|vbr|asr|filesize|fps)\n            \\s*(?P<op>%s)(?P<none_inclusive>\\s*\\?)?\\s*\n            (?P<value>[0-9.]+(?:[kKmMgGtTpPeEzZyY]i?[Bb]?)?)\n            $\n            ''' % '|'.join(map(re.escape, OPERATORS.keys())))\n        m = operator_rex.search(filter_spec)\n        if m:\n            try:\n                comparison_value = int(m.group('value'))\n            except ValueError:\n                comparison_value = parse_filesize(m.group('value'))\n                if comparison_value is None:\n                    comparison_value = parse_filesize(m.group('value') + 'B')\n                if comparison_value is None:\n                    raise ValueError(\n                        'Invalid value %r in format specification %r' % (\n                            m.group('value'), filter_spec))\n            op = OPERATORS[m.group('op')]\n\n        if not m:\n            STR_OPERATORS = {\n                '=': operator.eq,\n                '!=': operator.ne,\n            }\n            str_operator_rex = re.compile(r'''(?x)\n                \\s*(?P<key>ext|acodec|vcodec|container|protocol)\n                \\s*(?P<op>%s)(?P<none_inclusive>\\s*\\?)?\n                \\s*(?P<value>[a-zA-Z0-9_-]+)\n                \\s*$\n                ''' % '|'.join(map(re.escape, STR_OPERATORS.keys())))\n            m = str_operator_rex.search(filter_spec)\n            if m:\n                comparison_value = m.group('value')\n                op = STR_OPERATORS[m.group('op')]\n\n        if not m:\n            raise ValueError('Invalid filter specification %r' % filter_spec)\n\n        def _filter(f):\n            actual_value = f.get(m.group('key'))\n            if actual_value is None:\n                return m.group('none_inclusive')\n            return op(actual_value, comparison_value)\n        return _filter",
        "begin_line": 861,
        "end_line": 916,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._filter#911",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._filter(f)",
        "snippet": "        def _filter(f):\n            actual_value = f.get(m.group('key'))\n            if actual_value is None:\n                return m.group('none_inclusive')\n            return op(actual_value, comparison_value)",
        "begin_line": 911,
        "end_line": 915,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.build_format_selector#918",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.build_format_selector(self, format_spec)",
        "snippet": "    def build_format_selector(self, format_spec):\n        def syntax_error(note, start):\n            message = (\n                'Invalid format specification: '\n                '{0}\\n\\t{1}\\n\\t{2}^'.format(note, format_spec, ' ' * start[1]))\n            return SyntaxError(message)\n\n        PICKFIRST = 'PICKFIRST'\n        MERGE = 'MERGE'\n        SINGLE = 'SINGLE'\n        GROUP = 'GROUP'\n        FormatSelector = collections.namedtuple('FormatSelector', ['type', 'selector', 'filters'])\n\n        def _parse_filter(tokens):\n            filter_parts = []\n            for type, string, start, _, _ in tokens:\n                if type == tokenize.OP and string == ']':\n                    return ''.join(filter_parts)\n                else:\n                    filter_parts.append(string)\n\n        def _remove_unused_ops(tokens):\n            # Remove operators that we don't use and join them with the sourrounding strings\n            # for example: 'mp4' '-' 'baseline' '-' '16x9' is converted to 'mp4-baseline-16x9'\n            ALLOWED_OPS = ('/', '+', ',', '(', ')')\n            last_string, last_start, last_end, last_line = None, None, None, None\n            for type, string, start, end, line in tokens:\n                if type == tokenize.OP and string == '[':\n                    if last_string:\n                        yield tokenize.NAME, last_string, last_start, last_end, last_line\n                        last_string = None\n                    yield type, string, start, end, line\n                    # everything inside brackets will be handled by _parse_filter\n                    for type, string, start, end, line in tokens:\n                        yield type, string, start, end, line\n                        if type == tokenize.OP and string == ']':\n                            break\n                elif type == tokenize.OP and string in ALLOWED_OPS:\n                    if last_string:\n                        yield tokenize.NAME, last_string, last_start, last_end, last_line\n                        last_string = None\n                    yield type, string, start, end, line\n                elif type in [tokenize.NAME, tokenize.NUMBER, tokenize.OP]:\n                    if not last_string:\n                        last_string = string\n                        last_start = start\n                        last_end = end\n                    else:\n                        last_string += string\n            if last_string:\n                yield tokenize.NAME, last_string, last_start, last_end, last_line\n\n        def _parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False):\n            selectors = []\n            current_selector = None\n            for type, string, start, _, _ in tokens:\n                # ENCODING is only defined in python 3.x\n                if type == getattr(tokenize, 'ENCODING', None):\n                    continue\n                elif type in [tokenize.NAME, tokenize.NUMBER]:\n                    current_selector = FormatSelector(SINGLE, string, [])\n                elif type == tokenize.OP:\n                    if string == ')':\n                        if not inside_group:\n                            # ')' will be handled by the parentheses group\n                            tokens.restore_last_token()\n                        break\n                    elif inside_merge and string in ['/', ',']:\n                        tokens.restore_last_token()\n                        break\n                    elif inside_choice and string == ',':\n                        tokens.restore_last_token()\n                        break\n                    elif string == ',':\n                        if not current_selector:\n                            raise syntax_error('\",\" must follow a format selector', start)\n                        selectors.append(current_selector)\n                        current_selector = None\n                    elif string == '/':\n                        if not current_selector:\n                            raise syntax_error('\"/\" must follow a format selector', start)\n                        first_choice = current_selector\n                        second_choice = _parse_format_selection(tokens, inside_choice=True)\n                        current_selector = FormatSelector(PICKFIRST, (first_choice, second_choice), [])\n                    elif string == '[':\n                        if not current_selector:\n                            current_selector = FormatSelector(SINGLE, 'best', [])\n                        format_filter = _parse_filter(tokens)\n                        current_selector.filters.append(format_filter)\n                    elif string == '(':\n                        if current_selector:\n                            raise syntax_error('Unexpected \"(\"', start)\n                        group = _parse_format_selection(tokens, inside_group=True)\n                        current_selector = FormatSelector(GROUP, group, [])\n                    elif string == '+':\n                        video_selector = current_selector\n                        audio_selector = _parse_format_selection(tokens, inside_merge=True)\n                        if not video_selector or not audio_selector:\n                            raise syntax_error('\"+\" must be between two format selectors', start)\n                        current_selector = FormatSelector(MERGE, (video_selector, audio_selector), [])\n                    else:\n                        raise syntax_error('Operator not recognized: \"{0}\"'.format(string), start)\n                elif type == tokenize.ENDMARKER:\n                    break\n            if current_selector:\n                selectors.append(current_selector)\n            return selectors\n\n        def _build_selector_function(selector):\n            if isinstance(selector, list):\n                fs = [_build_selector_function(s) for s in selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        for format in f(formats):\n                            yield format\n                return selector_function\n            elif selector.type == GROUP:\n                selector_function = _build_selector_function(selector.selector)\n            elif selector.type == PICKFIRST:\n                fs = [_build_selector_function(s) for s in selector.selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        picked_formats = list(f(formats))\n                        if picked_formats:\n                            return picked_formats\n                    return []\n            elif selector.type == SINGLE:\n                format_spec = selector.selector\n\n                def selector_function(formats):\n                    formats = list(formats)\n                    if not formats:\n                        return\n                    if format_spec == 'all':\n                        for f in formats:\n                            yield f\n                    elif format_spec in ['best', 'worst', None]:\n                        format_idx = 0 if format_spec == 'worst' else -1\n                        audiovideo_formats = [\n                            f for f in formats\n                            if f.get('vcodec') != 'none' and f.get('acodec') != 'none']\n                        if audiovideo_formats:\n                            yield audiovideo_formats[format_idx]\n                        # for audio only (soundcloud) or video only (imgur) urls, select the best/worst audio format\n                        elif (all(f.get('acodec') != 'none' for f in formats) or\n                              all(f.get('vcodec') != 'none' for f in formats)):\n                            yield formats[format_idx]\n                    elif format_spec == 'bestaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[-1]\n                    elif format_spec == 'worstaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[0]\n                    elif format_spec == 'bestvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[-1]\n                    elif format_spec == 'worstvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[0]\n                    else:\n                        extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a', 'mp3', 'ogg', 'aac', 'wav']\n                        if format_spec in extensions:\n                            filter_f = lambda f: f['ext'] == format_spec\n                        else:\n                            filter_f = lambda f: f['format_id'] == format_spec\n                        matches = list(filter(filter_f, formats))\n                        if matches:\n                            yield matches[-1]\n            elif selector.type == MERGE:\n                def _merge(formats_info):\n                    format_1, format_2 = [f['format_id'] for f in formats_info]\n                    # The first format must contain the video and the\n                    # second the audio\n                    if formats_info[0].get('vcodec') == 'none':\n                        self.report_error('The first format must '\n                                          'contain the video, try using '\n                                          '\"-f %s+%s\"' % (format_2, format_1))\n                        return\n                    output_ext = (\n                        formats_info[0]['ext']\n                        if self.params.get('merge_output_format') is None\n                        else self.params['merge_output_format'])\n                    return {\n                        'requested_formats': formats_info,\n                        'format': '%s+%s' % (formats_info[0].get('format'),\n                                             formats_info[1].get('format')),\n                        'format_id': '%s+%s' % (formats_info[0].get('format_id'),\n                                                formats_info[1].get('format_id')),\n                        'width': formats_info[0].get('width'),\n                        'height': formats_info[0].get('height'),\n                        'resolution': formats_info[0].get('resolution'),\n                        'fps': formats_info[0].get('fps'),\n                        'vcodec': formats_info[0].get('vcodec'),\n                        'vbr': formats_info[0].get('vbr'),\n                        'stretched_ratio': formats_info[0].get('stretched_ratio'),\n                        'acodec': formats_info[1].get('acodec'),\n                        'abr': formats_info[1].get('abr'),\n                        'ext': output_ext,\n                    }\n                video_selector, audio_selector = map(_build_selector_function, selector.selector)\n\n                def selector_function(formats):\n                    formats = list(formats)\n                    for pair in itertools.product(video_selector(formats), audio_selector(formats)):\n                        yield _merge(pair)\n\n            filters = [self._build_format_filter(f) for f in selector.filters]\n\n            def final_selector(formats):\n                for _filter in filters:\n                    formats = list(filter(_filter, formats))\n                return selector_function(formats)\n            return final_selector\n\n        stream = io.BytesIO(format_spec.encode('utf-8'))\n        try:\n            tokens = list(_remove_unused_ops(compat_tokenize_tokenize(stream.readline)))\n        except tokenize.TokenError:\n            raise syntax_error('Missing closing/opening brackets or parenthesis', (0, len(format_spec)))\n\n        class TokenIterator(object):\n            def __init__(self, tokens):\n                self.tokens = tokens\n                self.counter = 0\n\n            def __iter__(self):\n                return self\n\n            def __next__(self):\n                if self.counter >= len(self.tokens):\n                    raise StopIteration()\n                value = self.tokens[self.counter]\n                self.counter += 1\n                return value\n\n            next = __next__\n\n            def restore_last_token(self):\n                self.counter -= 1\n\n        parsed_selector = _parse_format_selection(iter(TokenIterator(tokens)))\n        return _build_selector_function(parsed_selector)",
        "begin_line": 918,
        "end_line": 1173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.875968992248062e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.syntax_error#919",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.syntax_error(note, start)",
        "snippet": "        def syntax_error(note, start):\n            message = (\n                'Invalid format specification: '\n                '{0}\\n\\t{1}\\n\\t{2}^'.format(note, format_spec, ' ' * start[1]))\n            return SyntaxError(message)",
        "begin_line": 919,
        "end_line": 923,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._parse_filter#931",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._parse_filter(tokens)",
        "snippet": "        def _parse_filter(tokens):\n            filter_parts = []\n            for type, string, start, _, _ in tokens:\n                if type == tokenize.OP and string == ']':\n                    return ''.join(filter_parts)\n                else:\n                    filter_parts.append(string)",
        "begin_line": 931,
        "end_line": 937,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._remove_unused_ops#939",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._remove_unused_ops(tokens)",
        "snippet": "        def _remove_unused_ops(tokens):\n            # Remove operators that we don't use and join them with the sourrounding strings\n            # for example: 'mp4' '-' 'baseline' '-' '16x9' is converted to 'mp4-baseline-16x9'\n            ALLOWED_OPS = ('/', '+', ',', '(', ')')\n            last_string, last_start, last_end, last_line = None, None, None, None\n            for type, string, start, end, line in tokens:\n                if type == tokenize.OP and string == '[':\n                    if last_string:\n                        yield tokenize.NAME, last_string, last_start, last_end, last_line\n                        last_string = None\n                    yield type, string, start, end, line\n                    # everything inside brackets will be handled by _parse_filter\n                    for type, string, start, end, line in tokens:\n                        yield type, string, start, end, line\n                        if type == tokenize.OP and string == ']':\n                            break\n                elif type == tokenize.OP and string in ALLOWED_OPS:\n                    if last_string:\n                        yield tokenize.NAME, last_string, last_start, last_end, last_line\n                        last_string = None\n                    yield type, string, start, end, line\n                elif type in [tokenize.NAME, tokenize.NUMBER, tokenize.OP]:\n                    if not last_string:\n                        last_string = string\n                        last_start = start\n                        last_end = end\n                    else:\n                        last_string += string\n            if last_string:\n                yield tokenize.NAME, last_string, last_start, last_end, last_line",
        "begin_line": 939,
        "end_line": 968,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._parse_format_selection#970",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False)",
        "snippet": "        def _parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False):\n            selectors = []\n            current_selector = None\n            for type, string, start, _, _ in tokens:\n                # ENCODING is only defined in python 3.x\n                if type == getattr(tokenize, 'ENCODING', None):\n                    continue\n                elif type in [tokenize.NAME, tokenize.NUMBER]:\n                    current_selector = FormatSelector(SINGLE, string, [])\n                elif type == tokenize.OP:\n                    if string == ')':\n                        if not inside_group:\n                            # ')' will be handled by the parentheses group\n                            tokens.restore_last_token()\n                        break\n                    elif inside_merge and string in ['/', ',']:\n                        tokens.restore_last_token()\n                        break\n                    elif inside_choice and string == ',':\n                        tokens.restore_last_token()\n                        break\n                    elif string == ',':\n                        if not current_selector:\n                            raise syntax_error('\",\" must follow a format selector', start)\n                        selectors.append(current_selector)\n                        current_selector = None\n                    elif string == '/':\n                        if not current_selector:\n                            raise syntax_error('\"/\" must follow a format selector', start)\n                        first_choice = current_selector\n                        second_choice = _parse_format_selection(tokens, inside_choice=True)\n                        current_selector = FormatSelector(PICKFIRST, (first_choice, second_choice), [])\n                    elif string == '[':\n                        if not current_selector:\n                            current_selector = FormatSelector(SINGLE, 'best', [])\n                        format_filter = _parse_filter(tokens)\n                        current_selector.filters.append(format_filter)\n                    elif string == '(':\n                        if current_selector:\n                            raise syntax_error('Unexpected \"(\"', start)\n                        group = _parse_format_selection(tokens, inside_group=True)\n                        current_selector = FormatSelector(GROUP, group, [])\n                    elif string == '+':\n                        video_selector = current_selector\n                        audio_selector = _parse_format_selection(tokens, inside_merge=True)\n                        if not video_selector or not audio_selector:\n                            raise syntax_error('\"+\" must be between two format selectors', start)\n                        current_selector = FormatSelector(MERGE, (video_selector, audio_selector), [])\n                    else:\n                        raise syntax_error('Operator not recognized: \"{0}\"'.format(string), start)\n                elif type == tokenize.ENDMARKER:\n                    break\n            if current_selector:\n                selectors.append(current_selector)\n            return selectors",
        "begin_line": 970,
        "end_line": 1024,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._build_selector_function#1026",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._build_selector_function(selector)",
        "snippet": "        def _build_selector_function(selector):\n            if isinstance(selector, list):\n                fs = [_build_selector_function(s) for s in selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        for format in f(formats):\n                            yield format\n                return selector_function\n            elif selector.type == GROUP:\n                selector_function = _build_selector_function(selector.selector)\n            elif selector.type == PICKFIRST:\n                fs = [_build_selector_function(s) for s in selector.selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        picked_formats = list(f(formats))\n                        if picked_formats:\n                            return picked_formats\n                    return []\n            elif selector.type == SINGLE:\n                format_spec = selector.selector\n\n                def selector_function(formats):\n                    formats = list(formats)\n                    if not formats:\n                        return\n                    if format_spec == 'all':\n                        for f in formats:\n                            yield f\n                    elif format_spec in ['best', 'worst', None]:\n                        format_idx = 0 if format_spec == 'worst' else -1\n                        audiovideo_formats = [\n                            f for f in formats\n                            if f.get('vcodec') != 'none' and f.get('acodec') != 'none']\n                        if audiovideo_formats:\n                            yield audiovideo_formats[format_idx]\n                        # for audio only (soundcloud) or video only (imgur) urls, select the best/worst audio format\n                        elif (all(f.get('acodec') != 'none' for f in formats) or\n                              all(f.get('vcodec') != 'none' for f in formats)):\n                            yield formats[format_idx]\n                    elif format_spec == 'bestaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[-1]\n                    elif format_spec == 'worstaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[0]\n                    elif format_spec == 'bestvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[-1]\n                    elif format_spec == 'worstvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[0]\n                    else:\n                        extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a', 'mp3', 'ogg', 'aac', 'wav']\n                        if format_spec in extensions:\n                            filter_f = lambda f: f['ext'] == format_spec\n                        else:\n                            filter_f = lambda f: f['format_id'] == format_spec\n                        matches = list(filter(filter_f, formats))\n                        if matches:\n                            yield matches[-1]\n            elif selector.type == MERGE:\n                def _merge(formats_info):\n                    format_1, format_2 = [f['format_id'] for f in formats_info]\n                    # The first format must contain the video and the\n                    # second the audio\n                    if formats_info[0].get('vcodec') == 'none':\n                        self.report_error('The first format must '\n                                          'contain the video, try using '\n                                          '\"-f %s+%s\"' % (format_2, format_1))\n                        return\n                    output_ext = (\n                        formats_info[0]['ext']\n                        if self.params.get('merge_output_format') is None\n                        else self.params['merge_output_format'])\n                    return {\n                        'requested_formats': formats_info,\n                        'format': '%s+%s' % (formats_info[0].get('format'),\n                                             formats_info[1].get('format')),\n                        'format_id': '%s+%s' % (formats_info[0].get('format_id'),\n                                                formats_info[1].get('format_id')),\n                        'width': formats_info[0].get('width'),\n                        'height': formats_info[0].get('height'),\n                        'resolution': formats_info[0].get('resolution'),\n                        'fps': formats_info[0].get('fps'),\n                        'vcodec': formats_info[0].get('vcodec'),\n                        'vbr': formats_info[0].get('vbr'),\n                        'stretched_ratio': formats_info[0].get('stretched_ratio'),\n                        'acodec': formats_info[1].get('acodec'),\n                        'abr': formats_info[1].get('abr'),\n                        'ext': output_ext,\n                    }\n                video_selector, audio_selector = map(_build_selector_function, selector.selector)\n\n                def selector_function(formats):\n                    formats = list(formats)\n                    for pair in itertools.product(video_selector(formats), audio_selector(formats)):\n                        yield _merge(pair)\n\n            filters = [self._build_format_filter(f) for f in selector.filters]\n\n            def final_selector(formats):\n                for _filter in filters:\n                    formats = list(filter(_filter, formats))\n                return selector_function(formats)\n            return final_selector",
        "begin_line": 1026,
        "end_line": 1144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.selector_function#1030",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.selector_function(formats)",
        "snippet": "                def selector_function(formats):\n                    for f in fs:\n                        for format in f(formats):\n                            yield format",
        "begin_line": 1030,
        "end_line": 1033,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.selector_function#1040",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.selector_function(formats)",
        "snippet": "                def selector_function(formats):\n                    for f in fs:\n                        picked_formats = list(f(formats))\n                        if picked_formats:\n                            return picked_formats\n                    return []",
        "begin_line": 1040,
        "end_line": 1045,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.selector_function#1049",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.selector_function(formats)",
        "snippet": "                def selector_function(formats):\n                    formats = list(formats)\n                    if not formats:\n                        return\n                    if format_spec == 'all':\n                        for f in formats:\n                            yield f\n                    elif format_spec in ['best', 'worst', None]:\n                        format_idx = 0 if format_spec == 'worst' else -1\n                        audiovideo_formats = [\n                            f for f in formats\n                            if f.get('vcodec') != 'none' and f.get('acodec') != 'none']\n                        if audiovideo_formats:\n                            yield audiovideo_formats[format_idx]\n                        # for audio only (soundcloud) or video only (imgur) urls, select the best/worst audio format\n                        elif (all(f.get('acodec') != 'none' for f in formats) or\n                              all(f.get('vcodec') != 'none' for f in formats)):\n                            yield formats[format_idx]\n                    elif format_spec == 'bestaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[-1]\n                    elif format_spec == 'worstaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[0]\n                    elif format_spec == 'bestvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[-1]\n                    elif format_spec == 'worstvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[0]\n                    else:\n                        extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a', 'mp3', 'ogg', 'aac', 'wav']\n                        if format_spec in extensions:\n                            filter_f = lambda f: f['ext'] == format_spec\n                        else:\n                            filter_f = lambda f: f['format_id'] == format_spec\n                        matches = list(filter(filter_f, formats))\n                        if matches:\n                            yield matches[-1]",
        "begin_line": 1049,
        "end_line": 1099,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._merge#1101",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._merge(formats_info)",
        "snippet": "                def _merge(formats_info):\n                    format_1, format_2 = [f['format_id'] for f in formats_info]\n                    # The first format must contain the video and the\n                    # second the audio\n                    if formats_info[0].get('vcodec') == 'none':\n                        self.report_error('The first format must '\n                                          'contain the video, try using '\n                                          '\"-f %s+%s\"' % (format_2, format_1))\n                        return\n                    output_ext = (\n                        formats_info[0]['ext']\n                        if self.params.get('merge_output_format') is None\n                        else self.params['merge_output_format'])\n                    return {\n                        'requested_formats': formats_info,\n                        'format': '%s+%s' % (formats_info[0].get('format'),\n                                             formats_info[1].get('format')),\n                        'format_id': '%s+%s' % (formats_info[0].get('format_id'),\n                                                formats_info[1].get('format_id')),\n                        'width': formats_info[0].get('width'),\n                        'height': formats_info[0].get('height'),\n                        'resolution': formats_info[0].get('resolution'),\n                        'fps': formats_info[0].get('fps'),\n                        'vcodec': formats_info[0].get('vcodec'),\n                        'vbr': formats_info[0].get('vbr'),\n                        'stretched_ratio': formats_info[0].get('stretched_ratio'),\n                        'acodec': formats_info[1].get('acodec'),\n                        'abr': formats_info[1].get('abr'),\n                        'ext': output_ext,\n                    }",
        "begin_line": 1101,
        "end_line": 1130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.selector_function#1133",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.selector_function(formats)",
        "snippet": "                def selector_function(formats):\n                    formats = list(formats)\n                    for pair in itertools.product(video_selector(formats), audio_selector(formats)):\n                        yield _merge(pair)",
        "begin_line": 1133,
        "end_line": 1136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.final_selector#1140",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.final_selector(formats)",
        "snippet": "            def final_selector(formats):\n                for _filter in filters:\n                    formats = list(filter(_filter, formats))\n                return selector_function(formats)",
        "begin_line": 1140,
        "end_line": 1143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.TokenIterator.build_format_selector#918",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.TokenIterator",
        "signature": "youtube_dl.YoutubeDL.TokenIterator.build_format_selector(self, format_spec)",
        "snippet": "    def build_format_selector(self, format_spec):\n        def syntax_error(note, start):\n            message = (\n                'Invalid format specification: '\n                '{0}\\n\\t{1}\\n\\t{2}^'.format(note, format_spec, ' ' * start[1]))\n            return SyntaxError(message)\n\n        PICKFIRST = 'PICKFIRST'\n        MERGE = 'MERGE'\n        SINGLE = 'SINGLE'\n        GROUP = 'GROUP'\n        FormatSelector = collections.namedtuple('FormatSelector', ['type', 'selector', 'filters'])\n\n        def _parse_filter(tokens):\n            filter_parts = []\n            for type, string, start, _, _ in tokens:\n                if type == tokenize.OP and string == ']':\n                    return ''.join(filter_parts)\n                else:\n                    filter_parts.append(string)\n\n        def _remove_unused_ops(tokens):\n            # Remove operators that we don't use and join them with the sourrounding strings\n            # for example: 'mp4' '-' 'baseline' '-' '16x9' is converted to 'mp4-baseline-16x9'\n            ALLOWED_OPS = ('/', '+', ',', '(', ')')\n            last_string, last_start, last_end, last_line = None, None, None, None\n            for type, string, start, end, line in tokens:\n                if type == tokenize.OP and string == '[':\n                    if last_string:\n                        yield tokenize.NAME, last_string, last_start, last_end, last_line\n                        last_string = None\n                    yield type, string, start, end, line\n                    # everything inside brackets will be handled by _parse_filter\n                    for type, string, start, end, line in tokens:\n                        yield type, string, start, end, line\n                        if type == tokenize.OP and string == ']':\n                            break\n                elif type == tokenize.OP and string in ALLOWED_OPS:\n                    if last_string:\n                        yield tokenize.NAME, last_string, last_start, last_end, last_line\n                        last_string = None\n                    yield type, string, start, end, line\n                elif type in [tokenize.NAME, tokenize.NUMBER, tokenize.OP]:\n                    if not last_string:\n                        last_string = string\n                        last_start = start\n                        last_end = end\n                    else:\n                        last_string += string\n            if last_string:\n                yield tokenize.NAME, last_string, last_start, last_end, last_line\n\n        def _parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False):\n            selectors = []\n            current_selector = None\n            for type, string, start, _, _ in tokens:\n                # ENCODING is only defined in python 3.x\n                if type == getattr(tokenize, 'ENCODING', None):\n                    continue\n                elif type in [tokenize.NAME, tokenize.NUMBER]:\n                    current_selector = FormatSelector(SINGLE, string, [])\n                elif type == tokenize.OP:\n                    if string == ')':\n                        if not inside_group:\n                            # ')' will be handled by the parentheses group\n                            tokens.restore_last_token()\n                        break\n                    elif inside_merge and string in ['/', ',']:\n                        tokens.restore_last_token()\n                        break\n                    elif inside_choice and string == ',':\n                        tokens.restore_last_token()\n                        break\n                    elif string == ',':\n                        if not current_selector:\n                            raise syntax_error('\",\" must follow a format selector', start)\n                        selectors.append(current_selector)\n                        current_selector = None\n                    elif string == '/':\n                        if not current_selector:\n                            raise syntax_error('\"/\" must follow a format selector', start)\n                        first_choice = current_selector\n                        second_choice = _parse_format_selection(tokens, inside_choice=True)\n                        current_selector = FormatSelector(PICKFIRST, (first_choice, second_choice), [])\n                    elif string == '[':\n                        if not current_selector:\n                            current_selector = FormatSelector(SINGLE, 'best', [])\n                        format_filter = _parse_filter(tokens)\n                        current_selector.filters.append(format_filter)\n                    elif string == '(':\n                        if current_selector:\n                            raise syntax_error('Unexpected \"(\"', start)\n                        group = _parse_format_selection(tokens, inside_group=True)\n                        current_selector = FormatSelector(GROUP, group, [])\n                    elif string == '+':\n                        video_selector = current_selector\n                        audio_selector = _parse_format_selection(tokens, inside_merge=True)\n                        if not video_selector or not audio_selector:\n                            raise syntax_error('\"+\" must be between two format selectors', start)\n                        current_selector = FormatSelector(MERGE, (video_selector, audio_selector), [])\n                    else:\n                        raise syntax_error('Operator not recognized: \"{0}\"'.format(string), start)\n                elif type == tokenize.ENDMARKER:\n                    break\n            if current_selector:\n                selectors.append(current_selector)\n            return selectors\n\n        def _build_selector_function(selector):\n            if isinstance(selector, list):\n                fs = [_build_selector_function(s) for s in selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        for format in f(formats):\n                            yield format\n                return selector_function\n            elif selector.type == GROUP:\n                selector_function = _build_selector_function(selector.selector)\n            elif selector.type == PICKFIRST:\n                fs = [_build_selector_function(s) for s in selector.selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        picked_formats = list(f(formats))\n                        if picked_formats:\n                            return picked_formats\n                    return []\n            elif selector.type == SINGLE:\n                format_spec = selector.selector\n\n                def selector_function(formats):\n                    formats = list(formats)\n                    if not formats:\n                        return\n                    if format_spec == 'all':\n                        for f in formats:\n                            yield f\n                    elif format_spec in ['best', 'worst', None]:\n                        format_idx = 0 if format_spec == 'worst' else -1\n                        audiovideo_formats = [\n                            f for f in formats\n                            if f.get('vcodec') != 'none' and f.get('acodec') != 'none']\n                        if audiovideo_formats:\n                            yield audiovideo_formats[format_idx]\n                        # for audio only (soundcloud) or video only (imgur) urls, select the best/worst audio format\n                        elif (all(f.get('acodec') != 'none' for f in formats) or\n                              all(f.get('vcodec') != 'none' for f in formats)):\n                            yield formats[format_idx]\n                    elif format_spec == 'bestaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[-1]\n                    elif format_spec == 'worstaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[0]\n                    elif format_spec == 'bestvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[-1]\n                    elif format_spec == 'worstvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[0]\n                    else:\n                        extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a', 'mp3', 'ogg', 'aac', 'wav']\n                        if format_spec in extensions:\n                            filter_f = lambda f: f['ext'] == format_spec\n                        else:\n                            filter_f = lambda f: f['format_id'] == format_spec\n                        matches = list(filter(filter_f, formats))\n                        if matches:\n                            yield matches[-1]\n            elif selector.type == MERGE:\n                def _merge(formats_info):\n                    format_1, format_2 = [f['format_id'] for f in formats_info]\n                    # The first format must contain the video and the\n                    # second the audio\n                    if formats_info[0].get('vcodec') == 'none':\n                        self.report_error('The first format must '\n                                          'contain the video, try using '\n                                          '\"-f %s+%s\"' % (format_2, format_1))\n                        return\n                    output_ext = (\n                        formats_info[0]['ext']\n                        if self.params.get('merge_output_format') is None\n                        else self.params['merge_output_format'])\n                    return {\n                        'requested_formats': formats_info,\n                        'format': '%s+%s' % (formats_info[0].get('format'),\n                                             formats_info[1].get('format')),\n                        'format_id': '%s+%s' % (formats_info[0].get('format_id'),\n                                                formats_info[1].get('format_id')),\n                        'width': formats_info[0].get('width'),\n                        'height': formats_info[0].get('height'),\n                        'resolution': formats_info[0].get('resolution'),\n                        'fps': formats_info[0].get('fps'),\n                        'vcodec': formats_info[0].get('vcodec'),\n                        'vbr': formats_info[0].get('vbr'),\n                        'stretched_ratio': formats_info[0].get('stretched_ratio'),\n                        'acodec': formats_info[1].get('acodec'),\n                        'abr': formats_info[1].get('abr'),\n                        'ext': output_ext,\n                    }\n                video_selector, audio_selector = map(_build_selector_function, selector.selector)\n\n                def selector_function(formats):\n                    formats = list(formats)\n                    for pair in itertools.product(video_selector(formats), audio_selector(formats)):\n                        yield _merge(pair)\n\n            filters = [self._build_format_filter(f) for f in selector.filters]\n\n            def final_selector(formats):\n                for _filter in filters:\n                    formats = list(filter(_filter, formats))\n                return selector_function(formats)\n            return final_selector\n\n        stream = io.BytesIO(format_spec.encode('utf-8'))\n        try:\n            tokens = list(_remove_unused_ops(compat_tokenize_tokenize(stream.readline)))\n        except tokenize.TokenError:\n            raise syntax_error('Missing closing/opening brackets or parenthesis', (0, len(format_spec)))\n\n        class TokenIterator(object):\n            def __init__(self, tokens):\n                self.tokens = tokens\n                self.counter = 0\n\n            def __iter__(self):\n                return self\n\n            def __next__(self):\n                if self.counter >= len(self.tokens):\n                    raise StopIteration()\n                value = self.tokens[self.counter]\n                self.counter += 1\n                return value\n\n            next = __next__\n\n            def restore_last_token(self):\n                self.counter -= 1\n\n        parsed_selector = _parse_format_selection(iter(TokenIterator(tokens)))\n        return _build_selector_function(parsed_selector)",
        "begin_line": 918,
        "end_line": 1173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.865630677645058e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.TokenIterator.__init__#1153",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.TokenIterator",
        "signature": "youtube_dl.YoutubeDL.TokenIterator.__init__(self, tokens)",
        "snippet": "            def __init__(self, tokens):\n                self.tokens = tokens\n                self.counter = 0",
        "begin_line": 1153,
        "end_line": 1155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.865630677645058e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.TokenIterator.__iter__#1157",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.TokenIterator",
        "signature": "youtube_dl.YoutubeDL.TokenIterator.__iter__(self)",
        "snippet": "            def __iter__(self):\n                return self",
        "begin_line": 1157,
        "end_line": 1158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.865630677645058e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.TokenIterator.__next__#1160",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.TokenIterator",
        "signature": "youtube_dl.YoutubeDL.TokenIterator.__next__(self)",
        "snippet": "            def __next__(self):\n                if self.counter >= len(self.tokens):\n                    raise StopIteration()\n                value = self.tokens[self.counter]\n                self.counter += 1\n                return value",
        "begin_line": 1160,
        "end_line": 1165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.865630677645058e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.TokenIterator.restore_last_token#1169",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.TokenIterator",
        "signature": "youtube_dl.YoutubeDL.TokenIterator.restore_last_token(self)",
        "snippet": "            def restore_last_token(self):\n                self.counter -= 1",
        "begin_line": 1169,
        "end_line": 1170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._calc_headers#1175",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._calc_headers(self, info_dict)",
        "snippet": "    def _calc_headers(self, info_dict):\n        res = std_headers.copy()\n\n        add_headers = info_dict.get('http_headers')\n        if add_headers:\n            res.update(add_headers)\n\n        cookies = self._calc_cookies(info_dict)\n        if cookies:\n            res['Cookie'] = cookies\n\n        return res",
        "begin_line": 1175,
        "end_line": 1186,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.88621172081455e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._calc_cookies#1188",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._calc_cookies(self, info_dict)",
        "snippet": "    def _calc_cookies(self, info_dict):\n        pr = compat_urllib_request.Request(info_dict['url'])\n        self.cookiejar.add_cookie_header(pr)\n        return pr.get_header('Cookie')",
        "begin_line": 1188,
        "end_line": 1191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.865630677645058e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_video_result#1193",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_video_result(self, info_dict, download=True)",
        "snippet": "    def process_video_result(self, info_dict, download=True):\n        assert info_dict.get('_type', 'video') == 'video'\n\n        if 'id' not in info_dict:\n            raise ExtractorError('Missing \"id\" field in extractor result')\n        if 'title' not in info_dict:\n            raise ExtractorError('Missing \"title\" field in extractor result')\n\n        if 'playlist' not in info_dict:\n            # It isn't part of a playlist\n            info_dict['playlist'] = None\n            info_dict['playlist_index'] = None\n\n        thumbnails = info_dict.get('thumbnails')\n        if thumbnails is None:\n            thumbnail = info_dict.get('thumbnail')\n            if thumbnail:\n                info_dict['thumbnails'] = thumbnails = [{'url': thumbnail}]\n        if thumbnails:\n            thumbnails.sort(key=lambda t: (\n                t.get('preference'), t.get('width'), t.get('height'),\n                t.get('id'), t.get('url')))\n            for i, t in enumerate(thumbnails):\n                if t.get('width') and t.get('height'):\n                    t['resolution'] = '%dx%d' % (t['width'], t['height'])\n                if t.get('id') is None:\n                    t['id'] = '%d' % i\n\n        if thumbnails and 'thumbnail' not in info_dict:\n            info_dict['thumbnail'] = thumbnails[-1]['url']\n\n        if 'display_id' not in info_dict and 'id' in info_dict:\n            info_dict['display_id'] = info_dict['id']\n\n        if info_dict.get('upload_date') is None and info_dict.get('timestamp') is not None:\n            # Working around out-of-range timestamp values (e.g. negative ones on Windows,\n            # see http://bugs.python.org/issue1646728)\n            try:\n                upload_date = datetime.datetime.utcfromtimestamp(info_dict['timestamp'])\n                info_dict['upload_date'] = upload_date.strftime('%Y%m%d')\n            except (ValueError, OverflowError, OSError):\n                pass\n\n        subtitles = info_dict.get('subtitles')\n        if subtitles:\n            for _, subtitle in subtitles.items():\n                for subtitle_format in subtitle:\n                    if 'ext' not in subtitle_format:\n                        subtitle_format['ext'] = determine_ext(subtitle_format['url']).lower()\n\n        if self.params.get('listsubtitles', False):\n            if 'automatic_captions' in info_dict:\n                self.list_subtitles(info_dict['id'], info_dict.get('automatic_captions'), 'automatic captions')\n            self.list_subtitles(info_dict['id'], subtitles, 'subtitles')\n            return\n        info_dict['requested_subtitles'] = self.process_subtitles(\n            info_dict['id'], subtitles,\n            info_dict.get('automatic_captions'))\n\n        # We now pick which formats have to be downloaded\n        if info_dict.get('formats') is None:\n            # There's only one format available\n            formats = [info_dict]\n        else:\n            formats = info_dict['formats']\n\n        if not formats:\n            raise ExtractorError('No video formats found!')\n\n        formats_dict = {}\n\n        # We check that all the formats have the format and format_id fields\n        for i, format in enumerate(formats):\n            if 'url' not in format:\n                raise ExtractorError('Missing \"url\" key in result (index %d)' % i)\n\n            if format.get('format_id') is None:\n                format['format_id'] = compat_str(i)\n            format_id = format['format_id']\n            if format_id not in formats_dict:\n                formats_dict[format_id] = []\n            formats_dict[format_id].append(format)\n\n        # Make sure all formats have unique format_id\n        for format_id, ambiguous_formats in formats_dict.items():\n            if len(ambiguous_formats) > 1:\n                for i, format in enumerate(ambiguous_formats):\n                    format['format_id'] = '%s-%d' % (format_id, i)\n\n        for i, format in enumerate(formats):\n            if format.get('format') is None:\n                format['format'] = '{id} - {res}{note}'.format(\n                    id=format['format_id'],\n                    res=self.format_resolution(format),\n                    note=' ({0})'.format(format['format_note']) if format.get('format_note') is not None else '',\n                )\n            # Automatically determine file extension if missing\n            if 'ext' not in format:\n                format['ext'] = determine_ext(format['url']).lower()\n            # Add HTTP headers, so that external programs can use them from the\n            # json output\n            full_format_info = info_dict.copy()\n            full_format_info.update(format)\n            format['http_headers'] = self._calc_headers(full_format_info)\n\n        # TODO Central sorting goes here\n\n        if formats[0] is not info_dict:\n            # only set the 'formats' fields if the original info_dict list them\n            # otherwise we end up with a circular reference, the first (and unique)\n            # element in the 'formats' field in info_dict is info_dict itself,\n            # wich can't be exported to json\n            info_dict['formats'] = formats\n        if self.params.get('listformats'):\n            self.list_formats(info_dict)\n            return\n        if self.params.get('list_thumbnails'):\n            self.list_thumbnails(info_dict)\n            return\n\n        req_format = self.params.get('format')\n        if req_format is None:\n            req_format_list = []\n            if (self.params.get('outtmpl', DEFAULT_OUTTMPL) != '-' and\n                    info_dict['extractor'] in ['youtube', 'ted'] and\n                    not info_dict.get('is_live')):\n                merger = FFmpegMergerPP(self)\n                if merger.available and merger.can_merge():\n                    req_format_list.append('bestvideo+bestaudio')\n            req_format_list.append('best')\n            req_format = '/'.join(req_format_list)\n        format_selector = self.build_format_selector(req_format)\n        formats_to_download = list(format_selector(formats))\n        if not formats_to_download:\n            raise ExtractorError('requested format not available',\n                                 expected=True)\n\n        if download:\n            if len(formats_to_download) > 1:\n                self.to_screen('[info] %s: downloading video in %s formats' % (info_dict['id'], len(formats_to_download)))\n            for format in formats_to_download:\n                new_info = dict(info_dict)\n                new_info.update(format)\n                self.process_info(new_info)\n        # We update the info dict with the best quality format (backwards compatibility)\n        info_dict.update(formats_to_download[-1])\n        return info_dict",
        "begin_line": 1193,
        "end_line": 1339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_subtitles#1341",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_subtitles(self, video_id, normal_subtitles, automatic_captions)",
        "snippet": "    def process_subtitles(self, video_id, normal_subtitles, automatic_captions):\n        \"\"\"Select the requested subtitles and their format\"\"\"\n        available_subs = {}\n        if normal_subtitles and self.params.get('writesubtitles'):\n            available_subs.update(normal_subtitles)\n        if automatic_captions and self.params.get('writeautomaticsub'):\n            for lang, cap_info in automatic_captions.items():\n                if lang not in available_subs:\n                    available_subs[lang] = cap_info\n\n        if (not self.params.get('writesubtitles') and not\n                self.params.get('writeautomaticsub') or not\n                available_subs):\n            return None\n\n        if self.params.get('allsubtitles', False):\n            requested_langs = available_subs.keys()\n        else:\n            if self.params.get('subtitleslangs', False):\n                requested_langs = self.params.get('subtitleslangs')\n            elif 'en' in available_subs:\n                requested_langs = ['en']\n            else:\n                requested_langs = [list(available_subs.keys())[0]]\n\n        formats_query = self.params.get('subtitlesformat', 'best')\n        formats_preference = formats_query.split('/') if formats_query else []\n        subs = {}\n        for lang in requested_langs:\n            formats = available_subs.get(lang)\n            if formats is None:\n                self.report_warning('%s subtitles not available for %s' % (lang, video_id))\n                continue\n            for ext in formats_preference:\n                if ext == 'best':\n                    f = formats[-1]\n                    break\n                matches = list(filter(lambda f: f['ext'] == ext, formats))\n                if matches:\n                    f = matches[-1]\n                    break\n            else:\n                f = formats[-1]\n                self.report_warning(\n                    'No subtitle format found matching \"%s\" for language %s, '\n                    'using %s' % (formats_query, lang, f['ext']))\n            subs[lang] = f\n        return subs",
        "begin_line": 1341,
        "end_line": 1388,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_info#1390",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_info(self, info_dict)",
        "snippet": "    def process_info(self, info_dict):\n        \"\"\"Process a single resolved IE result.\"\"\"\n\n        assert info_dict.get('_type', 'video') == 'video'\n\n        max_downloads = self.params.get('max_downloads')\n        if max_downloads is not None:\n            if self._num_downloads >= int(max_downloads):\n                raise MaxDownloadsReached()\n\n        info_dict['fulltitle'] = info_dict['title']\n        if len(info_dict['title']) > 200:\n            info_dict['title'] = info_dict['title'][:197] + '...'\n\n        if 'format' not in info_dict:\n            info_dict['format'] = info_dict['ext']\n\n        reason = self._match_entry(info_dict, incomplete=False)\n        if reason is not None:\n            self.to_screen('[download] ' + reason)\n            return\n\n        self._num_downloads += 1\n\n        info_dict['_filename'] = filename = self.prepare_filename(info_dict)\n\n        # Forced printings\n        if self.params.get('forcetitle', False):\n            self.to_stdout(info_dict['fulltitle'])\n        if self.params.get('forceid', False):\n            self.to_stdout(info_dict['id'])\n        if self.params.get('forceurl', False):\n            if info_dict.get('requested_formats') is not None:\n                for f in info_dict['requested_formats']:\n                    self.to_stdout(f['url'] + f.get('play_path', ''))\n            else:\n                # For RTMP URLs, also include the playpath\n                self.to_stdout(info_dict['url'] + info_dict.get('play_path', ''))\n        if self.params.get('forcethumbnail', False) and info_dict.get('thumbnail') is not None:\n            self.to_stdout(info_dict['thumbnail'])\n        if self.params.get('forcedescription', False) and info_dict.get('description') is not None:\n            self.to_stdout(info_dict['description'])\n        if self.params.get('forcefilename', False) and filename is not None:\n            self.to_stdout(filename)\n        if self.params.get('forceduration', False) and info_dict.get('duration') is not None:\n            self.to_stdout(formatSeconds(info_dict['duration']))\n        if self.params.get('forceformat', False):\n            self.to_stdout(info_dict['format'])\n        if self.params.get('forcejson', False):\n            self.to_stdout(json.dumps(info_dict))\n\n        # Do nothing else if in simulate mode\n        if self.params.get('simulate', False):\n            return\n\n        if filename is None:\n            return\n\n        try:\n            dn = os.path.dirname(sanitize_path(encodeFilename(filename)))\n            if dn and not os.path.exists(dn):\n                os.makedirs(dn)\n        except (OSError, IOError) as err:\n            self.report_error('unable to create directory ' + compat_str(err))\n            return\n\n        if self.params.get('writedescription', False):\n            descfn = replace_extension(filename, 'description', info_dict.get('ext'))\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(descfn)):\n                self.to_screen('[info] Video description is already present')\n            elif info_dict.get('description') is None:\n                self.report_warning('There\\'s no description to write.')\n            else:\n                try:\n                    self.to_screen('[info] Writing video description to: ' + descfn)\n                    with io.open(encodeFilename(descfn), 'w', encoding='utf-8') as descfile:\n                        descfile.write(info_dict['description'])\n                except (OSError, IOError):\n                    self.report_error('Cannot write description file ' + descfn)\n                    return\n\n        if self.params.get('writeannotations', False):\n            annofn = replace_extension(filename, 'annotations.xml', info_dict.get('ext'))\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(annofn)):\n                self.to_screen('[info] Video annotations are already present')\n            else:\n                try:\n                    self.to_screen('[info] Writing video annotations to: ' + annofn)\n                    with io.open(encodeFilename(annofn), 'w', encoding='utf-8') as annofile:\n                        annofile.write(info_dict['annotations'])\n                except (KeyError, TypeError):\n                    self.report_warning('There are no annotations to write.')\n                except (OSError, IOError):\n                    self.report_error('Cannot write annotations file: ' + annofn)\n                    return\n\n        subtitles_are_requested = any([self.params.get('writesubtitles', False),\n                                       self.params.get('writeautomaticsub')])\n\n        if subtitles_are_requested and info_dict.get('requested_subtitles'):\n            # subtitles download errors are already managed as troubles in relevant IE\n            # that way it will silently go on when used with unsupporting IE\n            subtitles = info_dict['requested_subtitles']\n            ie = self.get_info_extractor(info_dict['extractor_key'])\n            for sub_lang, sub_info in subtitles.items():\n                sub_format = sub_info['ext']\n                if sub_info.get('data') is not None:\n                    sub_data = sub_info['data']\n                else:\n                    try:\n                        sub_data = ie._download_webpage(\n                            sub_info['url'], info_dict['id'], note=False)\n                    except ExtractorError as err:\n                        self.report_warning('Unable to download subtitle for \"%s\": %s' %\n                                            (sub_lang, compat_str(err.cause)))\n                        continue\n                try:\n                    sub_filename = subtitles_filename(filename, sub_lang, sub_format)\n                    if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(sub_filename)):\n                        self.to_screen('[info] Video subtitle %s.%s is already_present' % (sub_lang, sub_format))\n                    else:\n                        self.to_screen('[info] Writing video subtitles to: ' + sub_filename)\n                        with io.open(encodeFilename(sub_filename), 'w', encoding='utf-8') as subfile:\n                            subfile.write(sub_data)\n                except (OSError, IOError):\n                    self.report_error('Cannot write subtitles file ' + sub_filename)\n                    return\n\n        if self.params.get('writeinfojson', False):\n            infofn = replace_extension(filename, 'info.json', info_dict.get('ext'))\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(infofn)):\n                self.to_screen('[info] Video description metadata is already present')\n            else:\n                self.to_screen('[info] Writing video description metadata as JSON to: ' + infofn)\n                try:\n                    write_json_file(self.filter_requested_info(info_dict), infofn)\n                except (OSError, IOError):\n                    self.report_error('Cannot write metadata to JSON file ' + infofn)\n                    return\n\n        self._write_thumbnails(info_dict, filename)\n\n        if not self.params.get('skip_download', False):\n            try:\n                def dl(name, info):\n                    fd = get_suitable_downloader(info, self.params)(self, self.params)\n                    for ph in self._progress_hooks:\n                        fd.add_progress_hook(ph)\n                    if self.params.get('verbose'):\n                        self.to_stdout('[debug] Invoking downloader on %r' % info.get('url'))\n                    return fd.download(name, info)\n\n                if info_dict.get('requested_formats') is not None:\n                    downloaded = []\n                    success = True\n                    merger = FFmpegMergerPP(self)\n                    if not merger.available:\n                        postprocessors = []\n                        self.report_warning('You have requested multiple '\n                                            'formats but ffmpeg or avconv are not installed.'\n                                            ' The formats won\\'t be merged.')\n                    else:\n                        postprocessors = [merger]\n\n                    def compatible_formats(formats):\n                        video, audio = formats\n                        # Check extension\n                        video_ext, audio_ext = audio.get('ext'), video.get('ext')\n                        if video_ext and audio_ext:\n                            COMPATIBLE_EXTS = (\n                                ('mp3', 'mp4', 'm4a', 'm4p', 'm4b', 'm4r', 'm4v'),\n                                ('webm')\n                            )\n                            for exts in COMPATIBLE_EXTS:\n                                if video_ext in exts and audio_ext in exts:\n                                    return True\n                        # TODO: Check acodec/vcodec\n                        return False\n\n                    filename_real_ext = os.path.splitext(filename)[1][1:]\n                    filename_wo_ext = (\n                        os.path.splitext(filename)[0]\n                        if filename_real_ext == info_dict['ext']\n                        else filename)\n                    requested_formats = info_dict['requested_formats']\n                    if self.params.get('merge_output_format') is None and not compatible_formats(requested_formats):\n                        info_dict['ext'] = 'mkv'\n                        self.report_warning(\n                            'Requested formats are incompatible for merge and will be merged into mkv.')\n                    # Ensure filename always has a correct extension for successful merge\n                    filename = '%s.%s' % (filename_wo_ext, info_dict['ext'])\n                    if os.path.exists(encodeFilename(filename)):\n                        self.to_screen(\n                            '[download] %s has already been downloaded and '\n                            'merged' % filename)\n                    else:\n                        for f in requested_formats:\n                            new_info = dict(info_dict)\n                            new_info.update(f)\n                            fname = self.prepare_filename(new_info)\n                            fname = prepend_extension(fname, 'f%s' % f['format_id'], new_info['ext'])\n                            downloaded.append(fname)\n                            partial_success = dl(fname, new_info)\n                            success = success and partial_success\n                        info_dict['__postprocessors'] = postprocessors\n                        info_dict['__files_to_merge'] = downloaded\n                else:\n                    # Just a single file\n                    success = dl(filename, info_dict)\n            except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n                self.report_error('unable to download video data: %s' % str(err))\n                return\n            except (OSError, IOError) as err:\n                raise UnavailableVideoError(err)\n            except (ContentTooShortError, ) as err:\n                self.report_error('content too short (expected %s bytes and served %s)' % (err.expected, err.downloaded))\n                return\n\n            if success:\n                # Fixup content\n                fixup_policy = self.params.get('fixup')\n                if fixup_policy is None:\n                    fixup_policy = 'detect_or_warn'\n\n                stretched_ratio = info_dict.get('stretched_ratio')\n                if stretched_ratio is not None and stretched_ratio != 1:\n                    if fixup_policy == 'warn':\n                        self.report_warning('%s: Non-uniform pixel ratio (%s)' % (\n                            info_dict['id'], stretched_ratio))\n                    elif fixup_policy == 'detect_or_warn':\n                        stretched_pp = FFmpegFixupStretchedPP(self)\n                        if stretched_pp.available:\n                            info_dict.setdefault('__postprocessors', [])\n                            info_dict['__postprocessors'].append(stretched_pp)\n                        else:\n                            self.report_warning(\n                                '%s: Non-uniform pixel ratio (%s). Install ffmpeg or avconv to fix this automatically.' % (\n                                    info_dict['id'], stretched_ratio))\n                    else:\n                        assert fixup_policy in ('ignore', 'never')\n\n                if info_dict.get('requested_formats') is None and info_dict.get('container') == 'm4a_dash':\n                    if fixup_policy == 'warn':\n                        self.report_warning('%s: writing DASH m4a. Only some players support this container.' % (\n                            info_dict['id']))\n                    elif fixup_policy == 'detect_or_warn':\n                        fixup_pp = FFmpegFixupM4aPP(self)\n                        if fixup_pp.available:\n                            info_dict.setdefault('__postprocessors', [])\n                            info_dict['__postprocessors'].append(fixup_pp)\n                        else:\n                            self.report_warning(\n                                '%s: writing DASH m4a. Only some players support this container. Install ffmpeg or avconv to fix this automatically.' % (\n                                    info_dict['id']))\n                    else:\n                        assert fixup_policy in ('ignore', 'never')\n\n                try:\n                    self.post_process(filename, info_dict)\n                except (PostProcessingError) as err:\n                    self.report_error('postprocessing: %s' % str(err))\n                    return\n                self.record_download_archive(info_dict)",
        "begin_line": 1390,
        "end_line": 1652,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.dl#1534",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.dl(name, info)",
        "snippet": "                def dl(name, info):\n                    fd = get_suitable_downloader(info, self.params)(self, self.params)\n                    for ph in self._progress_hooks:\n                        fd.add_progress_hook(ph)\n                    if self.params.get('verbose'):\n                        self.to_stdout('[debug] Invoking downloader on %r' % info.get('url'))\n                    return fd.download(name, info)",
        "begin_line": 1534,
        "end_line": 1540,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.download#1654",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.download(self, url_list)",
        "snippet": "    def download(self, url_list):\n        \"\"\"Download a given list of URLs.\"\"\"\n        outtmpl = self.params.get('outtmpl', DEFAULT_OUTTMPL)\n        if (len(url_list) > 1 and\n                '%' not in outtmpl and\n                self.params.get('max_downloads') != 1):\n            raise SameFileError(outtmpl)\n\n        for url in url_list:\n            try:\n                # It also downloads the videos\n                res = self.extract_info(\n                    url, force_generic_extractor=self.params.get('force_generic_extractor', False))\n            except UnavailableVideoError:\n                self.report_error('unable to download video')\n            except MaxDownloadsReached:\n                self.to_screen('[info] Maximum number of downloaded files reached.')\n                raise\n            else:\n                if self.params.get('dump_single_json', False):\n                    self.to_stdout(json.dumps(res))\n\n        return self._download_retcode",
        "begin_line": 1654,
        "end_line": 1676,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.download_with_info_file#1678",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.download_with_info_file(self, info_filename)",
        "snippet": "    def download_with_info_file(self, info_filename):\n        with contextlib.closing(fileinput.FileInput(\n                [info_filename], mode='r',\n                openhook=fileinput.hook_encoded('utf-8'))) as f:\n            # FileInput doesn't have a read method, we can't call json.load\n            info = self.filter_requested_info(json.loads('\\n'.join(f)))\n        try:\n            self.process_ie_result(info, download=True)\n        except DownloadError:\n            webpage_url = info.get('webpage_url')\n            if webpage_url is not None:\n                self.report_warning('The info failed to download, trying with \"%s\"' % webpage_url)\n                return self.download([webpage_url])\n            else:\n                raise\n        return self._download_retcode",
        "begin_line": 1678,
        "end_line": 1693,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.filter_requested_info#1696",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.filter_requested_info(info_dict)",
        "snippet": "    def filter_requested_info(info_dict):\n        return dict(\n            (k, v) for k, v in info_dict.items()\n            if k not in ['requested_formats', 'requested_subtitles'])",
        "begin_line": 1696,
        "end_line": 1699,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.post_process#1701",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.post_process(self, filename, ie_info)",
        "snippet": "    def post_process(self, filename, ie_info):\n        \"\"\"Run all the postprocessors on the given file.\"\"\"\n        info = dict(ie_info)\n        info['filepath'] = filename\n        pps_chain = []\n        if ie_info.get('__postprocessors') is not None:\n            pps_chain.extend(ie_info['__postprocessors'])\n        pps_chain.extend(self._pps)\n        for pp in pps_chain:\n            files_to_delete = []\n            try:\n                files_to_delete, info = pp.run(info)\n            except PostProcessingError as e:\n                self.report_error(e.msg)\n            if files_to_delete and not self.params.get('keepvideo', False):\n                for old_filename in files_to_delete:\n                    self.to_screen('Deleting original file %s (pass -k to keep)' % old_filename)\n                    try:\n                        os.remove(encodeFilename(old_filename))\n                    except (IOError, OSError):\n                        self.report_warning('Unable to remove downloaded original file')",
        "begin_line": 1701,
        "end_line": 1721,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._make_archive_id#1723",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._make_archive_id(self, info_dict)",
        "snippet": "    def _make_archive_id(self, info_dict):\n        # Future-proof against any change in case\n        # and backwards compatibility with prior versions\n        extractor = info_dict.get('extractor_key')\n        if extractor is None:\n            if 'id' in info_dict:\n                extractor = info_dict.get('ie_key')  # key in a playlist\n        if extractor is None:\n            return None  # Incomplete video information\n        return extractor.lower() + ' ' + info_dict['id']",
        "begin_line": 1723,
        "end_line": 1732,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.in_download_archive#1734",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.in_download_archive(self, info_dict)",
        "snippet": "    def in_download_archive(self, info_dict):\n        fn = self.params.get('download_archive')\n        if fn is None:\n            return False\n\n        vid_id = self._make_archive_id(info_dict)\n        if vid_id is None:\n            return False  # Incomplete video information\n\n        try:\n            with locked_file(fn, 'r', encoding='utf-8') as archive_file:\n                for line in archive_file:\n                    if line.strip() == vid_id:\n                        return True\n        except IOError as ioe:\n            if ioe.errno != errno.ENOENT:\n                raise\n        return False",
        "begin_line": 1734,
        "end_line": 1751,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.record_download_archive#1753",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.record_download_archive(self, info_dict)",
        "snippet": "    def record_download_archive(self, info_dict):\n        fn = self.params.get('download_archive')\n        if fn is None:\n            return\n        vid_id = self._make_archive_id(info_dict)\n        assert vid_id\n        with locked_file(fn, 'a', encoding='utf-8') as archive_file:\n            archive_file.write(vid_id + '\\n')",
        "begin_line": 1753,
        "end_line": 1760,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.format_resolution#1763",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.format_resolution(format, default='unknown')",
        "snippet": "    def format_resolution(format, default='unknown'):\n        if format.get('vcodec') == 'none':\n            return 'audio only'\n        if format.get('resolution') is not None:\n            return format['resolution']\n        if format.get('height') is not None:\n            if format.get('width') is not None:\n                res = '%sx%s' % (format['width'], format['height'])\n            else:\n                res = '%sp' % format['height']\n        elif format.get('width') is not None:\n            res = '?x%d' % format['width']\n        else:\n            res = default\n        return res",
        "begin_line": 1763,
        "end_line": 1777,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._format_note#1779",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._format_note(self, fdict)",
        "snippet": "    def _format_note(self, fdict):\n        res = ''\n        if fdict.get('ext') in ['f4f', 'f4m']:\n            res += '(unsupported) '\n        if fdict.get('format_note') is not None:\n            res += fdict['format_note'] + ' '\n        if fdict.get('tbr') is not None:\n            res += '%4dk ' % fdict['tbr']\n        if fdict.get('container') is not None:\n            if res:\n                res += ', '\n            res += '%s container' % fdict['container']\n        if (fdict.get('vcodec') is not None and\n                fdict.get('vcodec') != 'none'):\n            if res:\n                res += ', '\n            res += fdict['vcodec']\n            if fdict.get('vbr') is not None:\n                res += '@'\n        elif fdict.get('vbr') is not None and fdict.get('abr') is not None:\n            res += 'video@'\n        if fdict.get('vbr') is not None:\n            res += '%4dk' % fdict['vbr']\n        if fdict.get('fps') is not None:\n            res += ', %sfps' % fdict['fps']\n        if fdict.get('acodec') is not None:\n            if res:\n                res += ', '\n            if fdict['acodec'] == 'none':\n                res += 'video only'\n            else:\n                res += '%-5s' % fdict['acodec']\n        elif fdict.get('abr') is not None:\n            if res:\n                res += ', '\n            res += 'audio'\n        if fdict.get('abr') is not None:\n            res += '@%3dk' % fdict['abr']\n        if fdict.get('asr') is not None:\n            res += ' (%5dHz)' % fdict['asr']\n        if fdict.get('filesize') is not None:\n            if res:\n                res += ', '\n            res += format_bytes(fdict['filesize'])\n        elif fdict.get('filesize_approx') is not None:\n            if res:\n                res += ', '\n            res += '~' + format_bytes(fdict['filesize_approx'])\n        return res",
        "begin_line": 1779,
        "end_line": 1827,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.list_formats#1829",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.list_formats(self, info_dict)",
        "snippet": "    def list_formats(self, info_dict):\n        formats = info_dict.get('formats', [info_dict])\n        table = [\n            [f['format_id'], f['ext'], self.format_resolution(f), self._format_note(f)]\n            for f in formats\n            if f.get('preference') is None or f['preference'] >= -1000]\n        if len(formats) > 1:\n            table[-1][-1] += (' ' if table[-1][-1] else '') + '(best)'\n\n        header_line = ['format code', 'extension', 'resolution', 'note']\n        self.to_screen(\n            '[info] Available formats for %s:\\n%s' %\n            (info_dict['id'], render_table(header_line, table)))",
        "begin_line": 1829,
        "end_line": 1841,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.list_thumbnails#1843",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.list_thumbnails(self, info_dict)",
        "snippet": "    def list_thumbnails(self, info_dict):\n        thumbnails = info_dict.get('thumbnails')\n        if not thumbnails:\n            tn_url = info_dict.get('thumbnail')\n            if tn_url:\n                thumbnails = [{'id': '0', 'url': tn_url}]\n            else:\n                self.to_screen(\n                    '[info] No thumbnails present for %s' % info_dict['id'])\n                return\n\n        self.to_screen(\n            '[info] Thumbnails for %s:' % info_dict['id'])\n        self.to_screen(render_table(\n            ['ID', 'width', 'height', 'URL'],\n            [[t['id'], t.get('width', 'unknown'), t.get('height', 'unknown'), t['url']] for t in thumbnails]))",
        "begin_line": 1843,
        "end_line": 1858,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.list_subtitles#1860",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.list_subtitles(self, video_id, subtitles, name='subtitles')",
        "snippet": "    def list_subtitles(self, video_id, subtitles, name='subtitles'):\n        if not subtitles:\n            self.to_screen('%s has no %s' % (video_id, name))\n            return\n        self.to_screen(\n            'Available %s for %s:' % (name, video_id))\n        self.to_screen(render_table(\n            ['Language', 'formats'],\n            [[lang, ', '.join(f['ext'] for f in reversed(formats))]\n                for lang, formats in subtitles.items()]))",
        "begin_line": 1860,
        "end_line": 1869,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.urlopen#1871",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.urlopen(self, req)",
        "snippet": "    def urlopen(self, req):\n        \"\"\" Start an HTTP download \"\"\"\n        return self._opener.open(req, timeout=self._socket_timeout)",
        "begin_line": 1871,
        "end_line": 1873,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.037037037037037035,
            "pseudo_dstar_susp": 0.038461538461538464,
            "pseudo_tarantula_susp": 0.0015432098765432098,
            "pseudo_op2_susp": 0.038461538461538464,
            "pseudo_barinel_susp": 0.0015432098765432098
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.print_debug_header#1875",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.print_debug_header(self)",
        "snippet": "    def print_debug_header(self):\n        if not self.params.get('verbose'):\n            return\n\n        if type('') is not compat_str:\n            # Python 2.6 on SLES11 SP1 (https://github.com/rg3/youtube-dl/issues/3326)\n            self.report_warning(\n                'Your Python is broken! Update to a newer and supported version')\n\n        stdout_encoding = getattr(\n            sys.stdout, 'encoding', 'missing (%s)' % type(sys.stdout).__name__)\n        encoding_str = (\n            '[debug] Encodings: locale %s, fs %s, out %s, pref %s\\n' % (\n                locale.getpreferredencoding(),\n                sys.getfilesystemencoding(),\n                stdout_encoding,\n                self.get_encoding()))\n        write_string(encoding_str, encoding=None)\n\n        self._write_string('[debug] youtube-dl version ' + __version__ + '\\n')\n        try:\n            sp = subprocess.Popen(\n                ['git', 'rev-parse', '--short', 'HEAD'],\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n                cwd=os.path.dirname(os.path.abspath(__file__)))\n            out, err = sp.communicate()\n            out = out.decode().strip()\n            if re.match('[0-9a-f]+', out):\n                self._write_string('[debug] Git HEAD: ' + out + '\\n')\n        except Exception:\n            try:\n                sys.exc_clear()\n            except Exception:\n                pass\n        self._write_string('[debug] Python version %s - %s\\n' % (\n            platform.python_version(), platform_name()))\n\n        exe_versions = FFmpegPostProcessor.get_versions(self)\n        exe_versions['rtmpdump'] = rtmpdump_version()\n        exe_str = ', '.join(\n            '%s %s' % (exe, v)\n            for exe, v in sorted(exe_versions.items())\n            if v\n        )\n        if not exe_str:\n            exe_str = 'none'\n        self._write_string('[debug] exe versions: %s\\n' % exe_str)\n\n        proxy_map = {}\n        for handler in self._opener.handlers:\n            if hasattr(handler, 'proxies'):\n                proxy_map.update(handler.proxies)\n        self._write_string('[debug] Proxy map: ' + compat_str(proxy_map) + '\\n')\n\n        if self.params.get('call_home', False):\n            ipaddr = self.urlopen('https://yt-dl.org/ip').read().decode('utf-8')\n            self._write_string('[debug] Public IP address: %s\\n' % ipaddr)\n            latest_version = self.urlopen(\n                'https://yt-dl.org/latest/version').read().decode('utf-8')\n            if version_tuple(latest_version) > version_tuple(__version__):\n                self.report_warning(\n                    'You are using an outdated version (newest version: %s)! '\n                    'See https://yt-dl.org/update if you need help updating.' %\n                    latest_version)",
        "begin_line": 1875,
        "end_line": 1938,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._setup_opener#1940",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._setup_opener(self)",
        "snippet": "    def _setup_opener(self):\n        timeout_val = self.params.get('socket_timeout')\n        self._socket_timeout = 600 if timeout_val is None else float(timeout_val)\n\n        opts_cookiefile = self.params.get('cookiefile')\n        opts_proxy = self.params.get('proxy')\n\n        if opts_cookiefile is None:\n            self.cookiejar = compat_cookiejar.CookieJar()\n        else:\n            self.cookiejar = compat_cookiejar.MozillaCookieJar(\n                opts_cookiefile)\n            if os.access(opts_cookiefile, os.R_OK):\n                self.cookiejar.load()\n\n        cookie_processor = YoutubeDLCookieProcessor(self.cookiejar)\n        if opts_proxy is not None:\n            if opts_proxy == '':\n                proxies = {}\n            else:\n                proxies = {'http': opts_proxy, 'https': opts_proxy}\n        else:\n            proxies = compat_urllib_request.getproxies()\n            # Set HTTPS proxy to HTTP one if given (https://github.com/rg3/youtube-dl/issues/805)\n            if 'http' in proxies and 'https' not in proxies:\n                proxies['https'] = proxies['http']\n        proxy_handler = PerRequestProxyHandler(proxies)\n\n        debuglevel = 1 if self.params.get('debug_printtraffic') else 0\n        https_handler = make_HTTPS_handler(self.params, debuglevel=debuglevel)\n        ydlh = YoutubeDLHandler(self.params, debuglevel=debuglevel)\n        data_handler = compat_urllib_request_DataHandler()\n        opener = compat_urllib_request.build_opener(\n            proxy_handler, https_handler, cookie_processor, ydlh, data_handler)\n\n        # Delete the default user-agent header, which would otherwise apply in\n        # cases where our custom HTTP handler doesn't come into play\n        # (See https://github.com/rg3/youtube-dl/issues/1309 for details)\n        opener.addheaders = []\n        self._opener = opener",
        "begin_line": 1940,
        "end_line": 1979,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005235602094240838,
            "pseudo_dstar_susp": 0.01694915254237288,
            "pseudo_tarantula_susp": 0.001098901098901099,
            "pseudo_op2_susp": 0.01694915254237288,
            "pseudo_barinel_susp": 0.001098901098901099
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.encode#1981",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.encode(self, s)",
        "snippet": "    def encode(self, s):\n        if isinstance(s, bytes):\n            return s  # Already encoded\n\n        try:\n            return s.encode(self.get_encoding())\n        except UnicodeEncodeError as err:\n            err.reason = err.reason + '. Check your system encoding configuration or use the --encoding option.'\n            raise",
        "begin_line": 1981,
        "end_line": 1989,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.get_encoding#1991",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.get_encoding(self)",
        "snippet": "    def get_encoding(self):\n        encoding = self.params.get('encoding')\n        if encoding is None:\n            encoding = preferredencoding()\n        return encoding",
        "begin_line": 1991,
        "end_line": 1995,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._write_thumbnails#1997",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._write_thumbnails(self, info_dict, filename)",
        "snippet": "    def _write_thumbnails(self, info_dict, filename):\n        if self.params.get('writethumbnail', False):\n            thumbnails = info_dict.get('thumbnails')\n            if thumbnails:\n                thumbnails = [thumbnails[-1]]\n        elif self.params.get('write_all_thumbnails', False):\n            thumbnails = info_dict.get('thumbnails')\n        else:\n            return\n\n        if not thumbnails:\n            # No thumbnails present, so return immediately\n            return\n\n        for t in thumbnails:\n            thumb_ext = determine_ext(t['url'], 'jpg')\n            suffix = '_%s' % t['id'] if len(thumbnails) > 1 else ''\n            thumb_display_id = '%s ' % t['id'] if len(thumbnails) > 1 else ''\n            t['filename'] = thumb_filename = os.path.splitext(filename)[0] + suffix + '.' + thumb_ext\n\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(thumb_filename)):\n                self.to_screen('[%s] %s: Thumbnail %sis already present' %\n                               (info_dict['extractor'], info_dict['id'], thumb_display_id))\n            else:\n                self.to_screen('[%s] %s: Downloading thumbnail %s...' %\n                               (info_dict['extractor'], info_dict['id'], thumb_display_id))\n                try:\n                    uf = self.urlopen(t['url'])\n                    with open(encodeFilename(thumb_filename), 'wb') as thumbf:\n                        shutil.copyfileobj(uf, thumbf)\n                    self.to_screen('[%s] %s: Writing thumbnail %sto: %s' %\n                                   (info_dict['extractor'], info_dict['id'], thumb_display_id, thumb_filename))\n                except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n                    self.report_warning('Unable to download thumbnail \"%s\": %s' %\n                                        (t['url'], compat_str(err)))",
        "begin_line": 1997,
        "end_line": 2031,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._login#71",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._login(self)",
        "snippet": "    def _login(self):\n        (useremail, password) = self._get_login_info()\n        if useremail is None:\n            return\n\n        login_page_req = compat_urllib_request.Request(self._LOGIN_URL)\n        login_page_req.add_header('Cookie', 'locale=en_US')\n        login_page = self._download_webpage(login_page_req, None,\n                                            note='Downloading login page',\n                                            errnote='Unable to download login page')\n        lsd = self._search_regex(\n            r'<input type=\"hidden\" name=\"lsd\" value=\"([^\"]*)\"',\n            login_page, 'lsd')\n        lgnrnd = self._search_regex(r'name=\"lgnrnd\" value=\"([^\"]*?)\"', login_page, 'lgnrnd')\n\n        login_form = {\n            'email': useremail,\n            'pass': password,\n            'lsd': lsd,\n            'lgnrnd': lgnrnd,\n            'next': 'http://facebook.com/home.php',\n            'default_persistent': '0',\n            'legacy_return': '1',\n            'timezone': '-60',\n            'trynum': '1',\n        }\n        request = compat_urllib_request.Request(self._LOGIN_URL, urlencode_postdata(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        try:\n            login_results = self._download_webpage(request, None,\n                                                   note='Logging in', errnote='unable to fetch login page')\n            if re.search(r'<form(.*)name=\"login\"(.*)</form>', login_results) is not None:\n                self._downloader.report_warning('unable to log in: bad username/password, or exceded login rate limit (~3/min). Check credentials or wait.')\n                return\n\n            check_form = {\n                'fb_dtsg': self._search_regex(r'name=\"fb_dtsg\" value=\"(.+?)\"', login_results, 'fb_dtsg'),\n                'h': self._search_regex(\n                    r'name=\"h\"\\s+(?:\\w+=\"[^\"]+\"\\s+)*?value=\"([^\"]+)\"', login_results, 'h'),\n                'name_action_selected': 'dont_save',\n            }\n            check_req = compat_urllib_request.Request(self._CHECKPOINT_URL, urlencode_postdata(check_form))\n            check_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            check_response = self._download_webpage(check_req, None,\n                                                    note='Confirming login')\n            if re.search(r'id=\"checkpointSubmitButton\"', check_response) is not None:\n                self._downloader.report_warning('Unable to confirm login, you have to login in your brower and authorize the login.')\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            self._downloader.report_warning('unable to log in: %s' % compat_str(err))\n            return",
        "begin_line": 71,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._real_initialize#122",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 122,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._real_extract#125",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        url = 'https://www.facebook.com/video/video.php?v=%s' % video_id\n        webpage = self._download_webpage(url, video_id)\n\n        BEFORE = '{swf.addParam(param[0], param[1]);});\\n'\n        AFTER = '.forEach(function(variable) {swf.addVariable(variable[0], variable[1]);});'\n        m = re.search(re.escape(BEFORE) + '(.*?)' + re.escape(AFTER), webpage)\n        if not m:\n            m_msg = re.search(r'class=\"[^\"]*uiInterstitialContent[^\"]*\"><div>(.*?)</div>', webpage)\n            if m_msg is not None:\n                raise ExtractorError(\n                    'The video is not available, Facebook said: \"%s\"' % m_msg.group(1),\n                    expected=True)\n            else:\n                raise ExtractorError('Cannot parse data')\n        data = dict(json.loads(m.group(1)))\n        params_raw = compat_urllib_parse_unquote(data['params'])\n        params = json.loads(params_raw)\n\n        formats = []\n        for format_id, f in params['video_data'].items():\n            if not f or not isinstance(f, list):\n                continue\n            for quality in ('sd', 'hd'):\n                for src_type in ('src', 'src_no_ratelimit'):\n                    src = f[0].get('%s_%s' % (quality, src_type))\n                    if src:\n                        formats.append({\n                            'format_id': '%s_%s_%s' % (format_id, quality, src_type),\n                            'url': src,\n                            'preference': -10 if format_id == 'progressive' else 0,\n                        })\n        if not formats:\n            raise ExtractorError('Cannot find video formats')\n\n        video_title = self._html_search_regex(\n            r'<h2\\s+[^>]*class=\"uiHeaderTitle\"[^>]*>([^<]*)</h2>', webpage, 'title',\n            default=None)\n        if not video_title:\n            video_title = self._html_search_regex(\n                r'(?s)<span class=\"fbPhotosPhotoCaption\".*?id=\"fbPhotoPageCaption\"><span class=\"hasCaption\">(.*?)</span>',\n                webpage, 'alternative title', fatal=False)\n            video_title = limit_length(video_title, 80)\n        if not video_title:\n            video_title = 'Facebook video #%s' % video_id\n        uploader = clean_html(get_element_by_id('fbPhotoPageAuthorName', webpage))\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'uploader': uploader,\n        }",
        "begin_line": 125,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamIE._real_extract#46",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamIE",
        "signature": "youtube_dl.extractor.ustream.UstreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        # some sites use this embed format (see: http://github.com/rg3/youtube-dl/issues/2990)\n        if m.group('type') == 'embed/recorded':\n            video_id = m.group('id')\n            desktop_url = 'http://www.ustream.tv/recorded/' + video_id\n            return self.url_result(desktop_url, 'Ustream')\n        if m.group('type') == 'embed':\n            video_id = m.group('id')\n            webpage = self._download_webpage(url, video_id)\n            desktop_video_id = self._html_search_regex(\n                r'ContentVideoIds=\\[\"([^\"]*?)\"\\]', webpage, 'desktop_video_id')\n            desktop_url = 'http://www.ustream.tv/recorded/' + desktop_video_id\n            return self.url_result(desktop_url, 'Ustream')\n\n        params = self._download_json(\n            'https://api.ustream.tv/videos/%s.json' % video_id, video_id)\n\n        error = params.get('error')\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error), expected=True)\n\n        video = params['video']\n\n        title = video['title']\n        filesize = float_or_none(video.get('file_size'))\n\n        formats = [{\n            'id': video_id,\n            'url': video_url,\n            'ext': format_id,\n            'filesize': filesize,\n        } for format_id, video_url in video['media_urls'].items()]\n        self._sort_formats(formats)\n\n        description = video.get('description')\n        timestamp = int_or_none(video.get('created_at'))\n        duration = float_or_none(video.get('length'))\n        view_count = int_or_none(video.get('views'))\n\n        uploader = video.get('owner', {}).get('username')\n        uploader_id = video.get('owner', {}).get('id')\n\n        thumbnails = [{\n            'id': thumbnail_id,\n            'url': thumbnail_url,\n        } for thumbnail_id, thumbnail_url in video.get('thumbnail', {}).items()]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': view_count,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'formats': formats,\n        }",
        "begin_line": 46,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamChannelIE._real_extract#122",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamChannelIE",
        "signature": "youtube_dl.extractor.ustream.UstreamChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        display_id = m.group('slug')\n        webpage = self._download_webpage(url, display_id)\n        channel_id = self._html_search_meta('ustream:channel_id', webpage)\n\n        BASE = 'http://www.ustream.tv'\n        next_url = '/ajax/socialstream/videos/%s/1.json' % channel_id\n        video_ids = []\n        while next_url:\n            reply = self._download_json(\n                compat_urlparse.urljoin(BASE, next_url), display_id,\n                note='Downloading video information (next: %d)' % (len(video_ids) + 1))\n            video_ids.extend(re.findall(r'data-content-id=\"(\\d.*)\"', reply['data']))\n            next_url = reply['nextUrl']\n\n        entries = [\n            self.url_result('http://www.ustream.tv/recorded/' + vid, 'Ustream')\n            for vid in video_ids]\n        return {\n            '_type': 'playlist',\n            'id': channel_id,\n            'display_id': display_id,\n            'entries': entries,\n        }",
        "begin_line": 122,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.giantbomb.GiantBombIE._real_extract#30",
        "src_path": "youtube_dl/extractor/giantbomb.py",
        "class_name": "youtube_dl.extractor.giantbomb.GiantBombIE",
        "signature": "youtube_dl.extractor.giantbomb.GiantBombIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        video = json.loads(unescapeHTML(self._search_regex(\n            r'data-video=\"([^\"]+)\"', webpage, 'data-video')))\n\n        duration = int_or_none(video.get('lengthSeconds'))\n\n        quality = qualities([\n            'f4m_low', 'progressive_low', 'f4m_high',\n            'progressive_high', 'f4m_hd', 'progressive_hd'])\n\n        formats = []\n        for format_id, video_url in video['videoStreams'].items():\n            if format_id == 'f4m_stream':\n                continue\n            if video_url.endswith('.f4m'):\n                f4m_formats = self._extract_f4m_formats(video_url + '?hdcore=3.3.1', display_id)\n                if f4m_formats:\n                    f4m_formats[0]['quality'] = quality(format_id)\n                    formats.extend(f4m_formats)\n            else:\n                formats.append({\n                    'url': video_url,\n                    'format_id': format_id,\n                    'quality': quality(format_id),\n                })\n\n        if not formats:\n            youtube_id = video.get('youtubeID')\n            if youtube_id:\n                return self.url_result(youtube_id, 'Youtube')\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.breakcom.BreakIE._real_extract#28",
        "src_path": "youtube_dl/extractor/breakcom.py",
        "class_name": "youtube_dl.extractor.breakcom.BreakIE",
        "signature": "youtube_dl.extractor.breakcom.BreakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            'http://www.break.com/embed/%s' % video_id, video_id)\n        info = json.loads(self._search_regex(\n            r'var embedVars = ({.*})\\s*?</script>',\n            webpage, 'info json', flags=re.DOTALL))\n\n        youtube_id = info.get('youtubeId')\n        if youtube_id:\n            return self.url_result(youtube_id, 'Youtube')\n\n        formats = [{\n            'url': media['uri'] + '?' + info['AuthToken'],\n            'tbr': media['bitRate'],\n            'width': media['width'],\n            'height': media['height'],\n        } for media in info['media'] if media.get('mediaPurpose') == 'play']\n\n        if not formats:\n            formats.append({\n                'url': info['videoUri']\n            })\n\n        self._sort_formats(formats)\n\n        duration = int_or_none(info.get('videoLengthInSeconds'))\n        age_limit = parse_age_limit(info.get('audienceRating'))\n\n        return {\n            'id': video_id,\n            'title': info['contentName'],\n            'thumbnail': info['thumbUri'],\n            'duration': duration,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._find_video_id#77",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._find_video_id(self, webpage)",
        "snippet": "    def _find_video_id(self, webpage):\n        res_id = [\n            r'\"video_id\"\\s*:\\s*\"(.*?)\"',\n            r'class=\"hero-poster[^\"]*?\"[^>]*id=\"(.+?)\"',\n            r'data-video-id=\"(.+?)\"',\n            r'<object id=\"vid_(.+?)\"',\n            r'<meta name=\"og:image\" content=\".*/(.+?)-(.+?)/.+.jpg\"',\n        ]\n        return self._search_regex(res_id, webpage, 'video id')",
        "begin_line": 77,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._real_extract#87",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name_or_id = mobj.group('name_or_id')\n        page_type = mobj.group('type')\n        webpage = self._download_webpage(url, name_or_id)\n        if page_type != 'video':\n            multiple_urls = re.findall(\n                '<param name=\"flashvars\"[^>]*value=\"[^\"]*?url=(https?://www\\.ign\\.com/videos/.*?)[\"&]',\n                webpage)\n            if multiple_urls:\n                entries = [self.url_result(u, ie='IGN') for u in multiple_urls]\n                return {\n                    '_type': 'playlist',\n                    'id': name_or_id,\n                    'entries': entries,\n                }\n\n        video_id = self._find_video_id(webpage)\n        result = self._get_video_info(video_id)\n        description = self._html_search_regex(self._DESCRIPTION_RE,\n                                              webpage, 'video description', flags=re.DOTALL)\n        result['description'] = description\n        return result",
        "begin_line": 87,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._get_video_info#111",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._get_video_info(self, video_id)",
        "snippet": "    def _get_video_info(self, video_id):\n        config_url = self._CONFIG_URL_TEMPLATE % video_id\n        config = self._download_json(config_url, video_id)\n        media = config['playlist']['media']\n\n        return {\n            'id': media['metadata']['videoId'],\n            'url': media['url'],\n            'title': media['metadata']['title'],\n            'thumbnail': media['poster'][0]['url'].replace('{size}', 'grande'),\n        }",
        "begin_line": 111,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ign.OneUPIE._real_extract#141",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.OneUPIE",
        "signature": "youtube_dl.extractor.ign.OneUPIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        result = super(OneUPIE, self)._real_extract(url)\n        result['id'] = mobj.group('name_or_id')\n        return result",
        "begin_line": 141,
        "end_line": 145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE._real_extract#27",
        "src_path": "youtube_dl/extractor/stanfordoc.py",
        "class_name": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE",
        "signature": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        if mobj.group('course') and mobj.group('video'):  # A specific video\n            course = mobj.group('course')\n            video = mobj.group('video')\n            info = {\n                'id': course + '_' + video,\n                'uploader': None,\n                'upload_date': None,\n            }\n\n            baseUrl = 'http://openclassroom.stanford.edu/MainFolder/courses/' + course + '/videos/'\n            xmlUrl = baseUrl + video + '.xml'\n            mdoc = self._download_xml(xmlUrl, info['id'])\n            try:\n                info['title'] = mdoc.findall('./title')[0].text\n                info['url'] = baseUrl + mdoc.findall('./videoFile')[0].text\n            except IndexError:\n                raise ExtractorError('Invalid metadata XML file')\n            return info\n        elif mobj.group('course'):  # A course page\n            course = mobj.group('course')\n            info = {\n                'id': course,\n                '_type': 'playlist',\n                'uploader': None,\n                'upload_date': None,\n            }\n\n            coursepage = self._download_webpage(\n                url, info['id'],\n                note='Downloading course info page',\n                errnote='Unable to download course info page')\n\n            info['title'] = self._html_search_regex(\n                r'<h1>([^<]+)</h1>', coursepage, 'title', default=info['id'])\n\n            info['description'] = self._html_search_regex(\n                r'(?s)<description>([^<]+)</description>',\n                coursepage, 'description', fatal=False)\n\n            links = orderedSet(re.findall('<a href=\"(VideoPage.php\\?[^\"]+)\">', coursepage))\n            info['entries'] = [self.url_result(\n                'http://openclassroom.stanford.edu/MainFolder/%s' % unescapeHTML(l)\n            ) for l in links]\n            return info\n        else:  # Root page\n            info = {\n                'id': 'Stanford OpenClassroom',\n                '_type': 'playlist',\n                'uploader': None,\n                'upload_date': None,\n            }\n            info['title'] = info['id']\n\n            rootURL = 'http://openclassroom.stanford.edu/MainFolder/HomePage.php'\n            rootpage = self._download_webpage(rootURL, info['id'],\n                                              errnote='Unable to download course info page')\n\n            links = orderedSet(re.findall('<a href=\"(CoursePage.php\\?[^\"]+)\">', rootpage))\n            info['entries'] = [self.url_result(\n                'http://openclassroom.stanford.edu/MainFolder/%s' % unescapeHTML(l)\n            ) for l in links]\n            return info",
        "begin_line": 27,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_mp4#59",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_mp4(self, xml_description)",
        "snippet": "    def _parse_mp4(self, xml_description):\n        video_formats = []\n        mp4_video = xml_description.find('./metadata/mp4video')\n        if mp4_video is None:\n            return None\n\n        mobj = re.match(r'(?P<root>https?://.*?/).*', mp4_video.text)\n        video_root = mobj.group('root')\n        formats = xml_description.findall('./metadata/MBRVideos/MBRVideo')\n        for format in formats:\n            mobj = re.match(r'mp4\\:(?P<path>.*)', format.find('streamName').text)\n            url = video_root + mobj.group('path')\n            vbr = format.find('bitrate').text\n            video_formats.append({\n                'url': url,\n                'vbr': int(vbr),\n            })\n        return video_formats",
        "begin_line": 59,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_flv#78",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_flv(self, xml_description)",
        "snippet": "    def _parse_flv(self, xml_description):\n        formats = []\n        akamai_url = xml_description.find('./metadata/akamaiHost').text\n        audios = xml_description.find('./metadata/audios')\n        if audios is not None:\n            for audio in audios:\n                formats.append({\n                    'url': 'rtmp://%s/ondemand?ovpfv=1.1' % akamai_url,\n                    'play_path': remove_end(audio.get('url'), '.flv'),\n                    'ext': 'flv',\n                    'vcodec': 'none',\n                    'format_id': audio.get('code'),\n                })\n        slide_video_path = xml_description.find('./metadata/slideVideo').text\n        formats.append({\n            'url': 'rtmp://%s/ondemand?ovpfv=1.1' % akamai_url,\n            'play_path': remove_end(slide_video_path, '.flv'),\n            'ext': 'flv',\n            'format_note': 'slide deck video',\n            'quality': -2,\n            'preference': -2,\n            'format_id': 'slides',\n        })\n        speaker_video_path = xml_description.find('./metadata/speakerVideo').text\n        formats.append({\n            'url': 'rtmp://%s/ondemand?ovpfv=1.1' % akamai_url,\n            'play_path': remove_end(speaker_video_path, '.flv'),\n            'ext': 'flv',\n            'format_note': 'speaker video',\n            'quality': -1,\n            'preference': -1,\n            'format_id': 'speaker',\n        })\n        return formats",
        "begin_line": 78,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._login#113",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._login(self, webpage_url, display_id)",
        "snippet": "    def _login(self, webpage_url, display_id):\n        (username, password) = self._get_login_info()\n        if username is None or password is None:\n            self.report_warning('It looks like ' + webpage_url + ' requires a login. Try specifying a username and password and try again.')\n            return None\n\n        mobj = re.match(r'(?P<root_url>https?://.*?/).*', webpage_url)\n        login_url = mobj.group('root_url') + 'api/login.php'\n        logout_url = mobj.group('root_url') + 'logout'\n\n        login_form = {\n            'email': username,\n            'password': password,\n        }\n\n        request = compat_urllib_request.Request(login_url, compat_urllib_parse.urlencode(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        self._download_webpage(request, display_id, 'Logging in')\n        start_page = self._download_webpage(webpage_url, display_id, 'Getting authenticated video page')\n        self._download_webpage(logout_url, display_id, 'Logging out')\n\n        return start_page",
        "begin_line": 113,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._real_extract#136",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        display_id = mobj.group('name') or video_id\n\n        webpage_url = 'http://www.gdcvault.com/play/' + video_id\n        start_page = self._download_webpage(webpage_url, display_id)\n\n        direct_url = self._search_regex(\n            r's1\\.addVariable\\(\"file\",\\s*encodeURIComponent\\(\"(/[^\"]+)\"\\)\\);',\n            start_page, 'url', default=None)\n        if direct_url:\n            title = self._html_search_regex(\n                r'<td><strong>Session Name</strong></td>\\s*<td>(.*?)</td>',\n                start_page, 'title')\n            video_url = 'http://www.gdcvault.com' + direct_url\n            # resolve the url so that we can detect the correct extension\n            head = self._request_webpage(HEADRequest(video_url), video_id)\n            video_url = head.geturl()\n\n            return {\n                'id': video_id,\n                'display_id': display_id,\n                'url': video_url,\n                'title': title,\n            }\n\n        xml_root = self._html_search_regex(\n            r'<iframe src=\"(?P<xml_root>.*?)player.html.*?\".*?</iframe>',\n            start_page, 'xml root', default=None)\n        if xml_root is None:\n            # Probably need to authenticate\n            login_res = self._login(webpage_url, display_id)\n            if login_res is None:\n                self.report_warning('Could not login.')\n            else:\n                start_page = login_res\n                # Grab the url from the authenticated page\n                xml_root = self._html_search_regex(\n                    r'<iframe src=\"(.*?)player.html.*?\".*?</iframe>',\n                    start_page, 'xml root')\n\n        xml_name = self._html_search_regex(\n            r'<iframe src=\".*?\\?xml=(.+?\\.xml).*?\".*?</iframe>',\n            start_page, 'xml filename', default=None)\n        if xml_name is None:\n            # Fallback to the older format\n            xml_name = self._html_search_regex(r'<iframe src=\".*?\\?xmlURL=xml/(?P<xml_file>.+?\\.xml).*?\".*?</iframe>', start_page, 'xml filename')\n\n        xml_description_url = xml_root + 'xml/' + xml_name\n        xml_description = self._download_xml(xml_description_url, display_id)\n\n        video_title = xml_description.find('./metadata/title').text\n        video_formats = self._parse_mp4(xml_description)\n        if video_formats is None:\n            video_formats = self._parse_flv(xml_description)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': video_title,\n            'formats': video_formats,\n        }",
        "begin_line": 136,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sina.SinaIE._extract_video#43",
        "src_path": "youtube_dl/extractor/sina.py",
        "class_name": "youtube_dl.extractor.sina.SinaIE",
        "signature": "youtube_dl.extractor.sina.SinaIE._extract_video(self, video_id)",
        "snippet": "    def _extract_video(self, video_id):\n        data = compat_urllib_parse.urlencode({'vid': video_id})\n        url_doc = self._download_xml('http://v.iask.com/v_play.php?%s' % data,\n                                     video_id, 'Downloading video url')\n        image_page = self._download_webpage(\n            'http://interface.video.sina.com.cn/interface/common/getVideoImage.php?%s' % data,\n            video_id, 'Downloading thumbnail info')\n\n        return {'id': video_id,\n                'url': url_doc.find('./durl/url').text,\n                'ext': 'flv',\n                'title': url_doc.find('./vname').text,\n                'thumbnail': image_page.split('=')[1],\n                }",
        "begin_line": 43,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sina.SinaIE._real_extract#58",
        "src_path": "youtube_dl/extractor/sina.py",
        "class_name": "youtube_dl.extractor.sina.SinaIE",
        "signature": "youtube_dl.extractor.sina.SinaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        if mobj.group('token') is not None:\n            # The video id is in the redirected url\n            self.to_screen('Getting video id')\n            request = compat_urllib_request.Request(url)\n            request.get_method = lambda: 'HEAD'\n            (_, urlh) = self._download_webpage_handle(request, 'NA', False)\n            return self._real_extract(urlh.geturl())\n        elif video_id is None:\n            pseudo_id = mobj.group('pseudo_id')\n            webpage = self._download_webpage(url, pseudo_id)\n            video_id = self._search_regex(r'vid:\\'(\\d+?)\\'', webpage, 'video id')\n\n        return self._extract_video(video_id)",
        "begin_line": 58,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nosvideo.NosVideoIE._real_extract#36",
        "src_path": "youtube_dl/extractor/nosvideo.py",
        "class_name": "youtube_dl.extractor.nosvideo.NosVideoIE",
        "signature": "youtube_dl.extractor.nosvideo.NosVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        fields = {\n            'id': video_id,\n            'op': 'download1',\n            'method_free': 'Continue to Video',\n        }\n        req = compat_urllib_request.Request(url, urlencode_postdata(fields))\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n        webpage = self._download_webpage(req, video_id,\n                                         'Downloading download page')\n        if re.search(self._FILE_DELETED_REGEX, webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id,\n                                 expected=True)\n\n        xml_id = self._search_regex(r'php\\|([^\\|]+)\\|', webpage, 'XML ID')\n        playlist_url = self._PLAYLIST_URL.format(xml_id=xml_id)\n        playlist = self._download_xml(playlist_url, video_id)\n\n        track = playlist.find(_x('.//xspf:track'))\n        if track is None:\n            raise ExtractorError(\n                'XML playlist is missing the \\'track\\' element',\n                expected=True)\n        title = xpath_text(track, _x('./xspf:title'), 'title')\n        url = xpath_text(track, _x('./xspf:file'), 'URL', fatal=True)\n        thumbnail = xpath_text(track, _x('./xspf:image'), 'thumbnail')\n        if title is not None:\n            title = title.strip()\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 36,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.zapiks.ZapiksIE._real_extract#49",
        "src_path": "youtube_dl/extractor/zapiks.py",
        "class_name": "youtube_dl.extractor.zapiks.ZapiksIE",
        "signature": "youtube_dl.extractor.zapiks.ZapiksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        if not video_id:\n            video_id = self._search_regex(\n                r'data-media-id=\"(\\d+)\"', webpage, 'video id')\n\n        playlist = self._download_xml(\n            'http://www.zapiks.fr/view/index.php?action=playlist&media_id=%s&lang=en' % video_id,\n            display_id)\n\n        NS_MAP = {\n            'jwplayer': 'http://rss.jwpcdn.com/'\n        }\n\n        def ns(path):\n            return xpath_with_ns(path, NS_MAP)\n\n        item = playlist.find('./channel/item')\n\n        title = xpath_text(item, 'title', 'title') or self._og_search_title(webpage)\n        description = self._og_search_description(webpage, default=None)\n        thumbnail = xpath_text(\n            item, ns('./jwplayer:image'), 'thumbnail') or self._og_search_thumbnail(webpage, default=None)\n        duration = parse_duration(self._html_search_meta(\n            'duration', webpage, 'duration', default=None))\n        timestamp = parse_iso8601(self._html_search_meta(\n            'uploadDate', webpage, 'upload date', default=None), ' ')\n\n        view_count = int_or_none(self._search_regex(\n            r'UserPlays:(\\d+)', webpage, 'view count', default=None))\n        comment_count = int_or_none(self._search_regex(\n            r'UserComments:(\\d+)', webpage, 'comment count', default=None))\n\n        formats = []\n        for source in item.findall(ns('./jwplayer:source')):\n            format_id = source.attrib['label']\n            f = {\n                'url': source.attrib['file'],\n                'format_id': format_id,\n            }\n            m = re.search(r'^(?P<height>\\d+)[pP]', format_id)\n            if m:\n                f['height'] = int(m.group('height'))\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n        }",
        "begin_line": 49,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tv4.TV4IE._real_extract#64",
        "src_path": "youtube_dl/extractor/tv4.py",
        "class_name": "youtube_dl.extractor.tv4.TV4IE",
        "signature": "youtube_dl.extractor.tv4.TV4IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_json(\n            'http://www.tv4play.se/player/assets/%s.json' % video_id, video_id, 'Downloading video info JSON')\n\n        # If is_geo_restricted is true, it doesn't neceserally mean we can't download it\n        if info['is_geo_restricted']:\n            self.report_warning('This content might not be available in your country due to licensing restrictions.')\n        if info['requires_subscription']:\n            raise ExtractorError('This content requires subscription.', expected=True)\n\n        sources_data = self._download_json(\n            'https://prima.tv4play.se/api/web/asset/%s/play.json?protocol=http&videoFormat=MP4' % video_id, video_id, 'Downloading sources JSON')\n        sources = sources_data['playback']\n\n        formats = []\n        for item in sources.get('items', {}).get('item', []):\n            ext, bitrate = item['mediaFormat'], item['bitrate']\n            formats.append({\n                'format_id': '%s_%s' % (ext, bitrate),\n                'tbr': bitrate,\n                'ext': ext,\n                'url': item['url'],\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'formats': formats,\n            'description': info.get('description'),\n            'timestamp': parse_iso8601(info.get('broadcast_date_time')),\n            'duration': info.get('duration'),\n            'thumbnail': info.get('image'),\n            'is_live': sources.get('live'),\n        }",
        "begin_line": 64,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.playwire.PlaywireIE._real_extract#36",
        "src_path": "youtube_dl/extractor/playwire.py",
        "class_name": "youtube_dl.extractor.playwire.PlaywireIE",
        "signature": "youtube_dl.extractor.playwire.PlaywireIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        publisher_id, video_id = mobj.group('publisher_id'), mobj.group('id')\n\n        player = self._download_json(\n            'http://config.playwire.com/%s/videos/v2/%s/zeus.json' % (publisher_id, video_id),\n            video_id)\n\n        title = player['settings']['title']\n        duration = float_or_none(player.get('duration'), 1000)\n\n        content = player['content']\n        thumbnail = content.get('poster')\n        src = content['media']['f4m']\n\n        f4m = self._download_xml(src, video_id)\n        base_url = xpath_text(f4m, './{http://ns.adobe.com/f4m/1.0}baseURL', 'base url', fatal=True)\n        formats = []\n        for media in f4m.findall('./{http://ns.adobe.com/f4m/1.0}media'):\n            media_url = media.get('url')\n            if not media_url:\n                continue\n            tbr = int_or_none(media.get('bitrate'))\n            width = int_or_none(media.get('width'))\n            height = int_or_none(media.get('height'))\n            f = {\n                'url': '%s/%s' % (base_url, media.attrib['url']),\n                'tbr': tbr,\n                'width': width,\n                'height': height,\n            }\n            if not (tbr or width or height):\n                f['quality'] = 1 if '-hd.' in media_url else 0\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 36,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.macgamestore.MacGameStoreIE._real_extract#22",
        "src_path": "youtube_dl/extractor/macgamestore.py",
        "class_name": "youtube_dl.extractor.macgamestore.MacGameStoreIE",
        "signature": "youtube_dl.extractor.macgamestore.MacGameStoreIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, video_id, 'Downloading trailer page')\n\n        if '>Missing Media<' in webpage:\n            raise ExtractorError(\n                'Trailer %s does not exist' % video_id, expected=True)\n\n        video_title = self._html_search_regex(\n            r'<title>MacGameStore: (.*?) Trailer</title>', webpage, 'title')\n\n        video_url = self._html_search_regex(\n            r'(?s)<div\\s+id=\"video-player\".*?href=\"([^\"]+)\"\\s*>',\n            webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title\n        }",
        "begin_line": 22,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.dash.DashSegmentsFD.real_download#13",
        "src_path": "youtube_dl/downloader/dash.py",
        "class_name": "youtube_dl.downloader.dash.DashSegmentsFD",
        "signature": "youtube_dl.downloader.dash.DashSegmentsFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n        base_url = info_dict['url']\n        segment_urls = info_dict['segment_urls']\n\n        is_test = self.params.get('test', False)\n        remaining_bytes = self._TEST_FILE_SIZE if is_test else None\n        byte_counter = 0\n\n        def append_url_to_file(outf, target_url, target_name, remaining_bytes=None):\n            self.to_screen('[DashSegments] %s: Downloading %s' % (info_dict['id'], target_name))\n            req = compat_urllib_request.Request(target_url)\n            if remaining_bytes is not None:\n                req.add_header('Range', 'bytes=0-%d' % (remaining_bytes - 1))\n\n            data = self.ydl.urlopen(req).read()\n\n            if remaining_bytes is not None:\n                data = data[:remaining_bytes]\n\n            outf.write(data)\n            return len(data)\n\n        def combine_url(base_url, target_url):\n            if re.match(r'^https?://', target_url):\n                return target_url\n            return '%s%s%s' % (base_url, '' if base_url.endswith('/') else '/', target_url)\n\n        with open(tmpfilename, 'wb') as outf:\n            append_url_to_file(\n                outf, combine_url(base_url, info_dict['initialization_url']),\n                'initialization segment')\n            for i, segment_url in enumerate(segment_urls):\n                segment_len = append_url_to_file(\n                    outf, combine_url(base_url, segment_url),\n                    'segment %d / %d' % (i + 1, len(segment_urls)),\n                    remaining_bytes)\n                byte_counter += segment_len\n                if remaining_bytes is not None:\n                    remaining_bytes -= segment_len\n                    if remaining_bytes <= 0:\n                        break\n\n        self.try_rename(tmpfilename, filename)\n\n        self._hook_progress({\n            'downloaded_bytes': byte_counter,\n            'total_bytes': byte_counter,\n            'filename': filename,\n            'status': 'finished',\n        })\n\n        return True",
        "begin_line": 13,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.syfy.SyfyIE._real_extract#33",
        "src_path": "youtube_dl/extractor/syfy.py",
        "class_name": "youtube_dl.extractor.syfy.SyfyIE",
        "signature": "youtube_dl.extractor.syfy.SyfyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_name = mobj.group('video_name')\n        if video_name:\n            generic_webpage = self._download_webpage(url, video_name)\n            video_id = self._search_regex(\n                r'<iframe.*?class=\"video_iframe_page\"\\s+src=\"/_utils/video/thP_video_controller.php.*?_vid([0-9]+)\">',\n                generic_webpage, 'video ID')\n            url = 'http://www.syfy.com/videos/%s/%s/vid:%s' % (\n                video_name, video_name, video_id)\n        else:\n            video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        return self.url_result(self._og_search_video_url(webpage))",
        "begin_line": 33,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE._real_extract#40",
        "src_path": "youtube_dl/extractor/everyonesmixtape.py",
        "class_name": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE",
        "signature": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        pllist_url = 'http://everyonesmixtape.com/mixtape.php?a=getMixes&u=-1&linked=%s&explore=' % playlist_id\n        pllist_req = compat_urllib_request.Request(pllist_url)\n        pllist_req.add_header('X-Requested-With', 'XMLHttpRequest')\n\n        playlist_list = self._download_json(\n            pllist_req, playlist_id, note='Downloading playlist metadata')\n        try:\n            playlist_no = next(playlist['id']\n                               for playlist in playlist_list\n                               if playlist['code'] == playlist_id)\n        except StopIteration:\n            raise ExtractorError('Playlist id not found')\n\n        pl_url = 'http://everyonesmixtape.com/mixtape.php?a=getMix&id=%s&userId=null&code=' % playlist_no\n        pl_req = compat_urllib_request.Request(pl_url)\n        pl_req.add_header('X-Requested-With', 'XMLHttpRequest')\n        playlist = self._download_json(\n            pl_req, playlist_id, note='Downloading playlist info')\n\n        entries = [{\n            '_type': 'url',\n            'url': t['url'],\n            'title': t['title'],\n        } for t in playlist['tracks']]\n\n        if mobj.group('songnr'):\n            songnr = int(mobj.group('songnr')) - 1\n            return entries[songnr]\n\n        playlist_title = playlist['mixData']['name']\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_title,\n            'entries': entries,\n        }",
        "begin_line": 40,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.clubic.ClubicIE._real_extract#32",
        "src_path": "youtube_dl/extractor/clubic.py",
        "class_name": "youtube_dl.extractor.clubic.ClubicIE",
        "signature": "youtube_dl.extractor.clubic.ClubicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        player_url = 'http://player.m6web.fr/v1/player/clubic/%s.html' % video_id\n        player_page = self._download_webpage(player_url, video_id)\n\n        config_json = self._search_regex(\n            r'(?m)M6\\.Player\\.config\\s*=\\s*(\\{.+?\\});$', player_page,\n            'configuration')\n        config = json.loads(config_json)\n\n        video_info = config['videoInfo']\n        sources = config['sources']\n        quality_order = qualities(['sd', 'hq'])\n\n        formats = [{\n            'format_id': src['streamQuality'],\n            'url': src['src'],\n            'quality': quality_order(src['streamQuality']),\n        } for src in sources]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_info['title'],\n            'formats': formats,\n            'description': clean_html(video_info.get('description')),\n            'thumbnail': config.get('poster'),\n        }",
        "begin_line": 32,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youporn.YouPornIE._real_extract#61",
        "src_path": "youtube_dl/extractor/youporn.py",
        "class_name": "youtube_dl.extractor.youporn.YouPornIE",
        "signature": "youtube_dl.extractor.youporn.YouPornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        request = compat_urllib_request.Request(url)\n        request.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(request, display_id)\n\n        title = self._search_regex(\n            [r'(?:video_titles|videoTitle)\\s*[:=]\\s*([\"\\'])(?P<title>.+?)\\1',\n             r'<h1[^>]+class=[\"\\']heading\\d?[\"\\'][^>]*>([^<])<'],\n            webpage, 'title', group='title')\n\n        links = []\n\n        sources = self._search_regex(\n            r'sources\\s*:\\s*({.+?})', webpage, 'sources', default=None)\n        if sources:\n            for _, link in re.findall(r'[^:]+\\s*:\\s*([\"\\'])(http.+?)\\1', sources):\n                links.append(link)\n\n        # Fallback #1\n        for _, link in re.findall(\n                r'(?:videoUrl|videoSrc|videoIpadUrl|html5PlayerSrc)\\s*[:=]\\s*([\"\\'])(http.+?)\\1', webpage):\n            links.append(link)\n\n        # Fallback #2, this also contains extra low quality 180p format\n        for _, link in re.findall(r'<a[^>]+href=([\"\\'])(http.+?)\\1[^>]+title=[\"\\']Download [Vv]ideo', webpage):\n            links.append(link)\n\n        # Fallback #3, encrypted links\n        for _, encrypted_link in re.findall(\n                r'encryptedQuality\\d{3,4}URL\\s*=\\s*([\"\\'])([\\da-zA-Z+/=]+)\\1', webpage):\n            links.append(aes_decrypt_text(encrypted_link, title, 32).decode('utf-8'))\n\n        formats = []\n        for video_url in set(unescapeHTML(link) for link in links):\n            f = {\n                'url': video_url,\n            }\n            # Video URL's path looks like this:\n            #  /201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4\n            # We will benefit from it by extracting some metadata\n            mobj = re.search(r'/(?P<height>\\d{3,4})[pP]_(?P<bitrate>\\d+)[kK]_\\d+/', video_url)\n            if mobj:\n                height = int(mobj.group('height'))\n                bitrate = int(mobj.group('bitrate'))\n                f.update({\n                    'format_id': '%dp-%dk' % (height, bitrate),\n                    'height': height,\n                    'tbr': bitrate,\n                })\n            formats.append(f)\n        self._sort_formats(formats)\n\n        description = self._html_search_regex(\n            r'(?s)<div[^>]+class=[\"\\']video-description[\"\\'][^>]*>(.+?)</div>',\n            webpage, 'description', default=None)\n        thumbnail = self._search_regex(\n            r'(?:imageurl\\s*=|poster\\s*:)\\s*([\"\\'])(?P<thumbnail>.+?)\\1',\n            webpage, 'thumbnail', fatal=False, group='thumbnail')\n\n        uploader = self._html_search_regex(\n            r'(?s)<div[^>]+class=[\"\\']videoInfoBy[\"\\'][^>]*>\\s*By:\\s*</div>(.+?)</(?:a|div)>',\n            webpage, 'uploader', fatal=False)\n        upload_date = unified_strdate(self._html_search_regex(\n            r'(?s)<div[^>]+class=[\"\\']videoInfoTime[\"\\'][^>]*>(.+?)</div>',\n            webpage, 'upload date', fatal=False))\n\n        age_limit = self._rta_search(webpage)\n\n        average_rating = int_or_none(self._search_regex(\n            r'<div[^>]+class=[\"\\']videoInfoRating[\"\\'][^>]*>\\s*<div[^>]+class=[\"\\']videoRatingPercentage[\"\\'][^>]*>(\\d+)%</div>',\n            webpage, 'average rating', fatal=False))\n\n        view_count = str_to_int(self._search_regex(\n            r'(?s)<div[^>]+class=[\"\\']videoInfoViews[\"\\'][^>]*>.*?([\\d,.]+)\\s*</div>',\n            webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._search_regex(\n            r'>All [Cc]omments? \\(([\\d,.]+)\\)',\n            webpage, 'comment count', fatal=False))\n\n        def extract_tag_box(title):\n            tag_box = self._search_regex(\n                (r'<div[^>]+class=[\"\\']tagBoxTitle[\"\\'][^>]*>\\s*%s\\b.*?</div>\\s*'\n                 '<div[^>]+class=[\"\\']tagBoxContent[\"\\']>(.+?)</div>') % re.escape(title),\n                webpage, '%s tag box' % title, default=None)\n            if not tag_box:\n                return []\n            return re.findall(r'<a[^>]+href=[^>]+>([^<]+)', tag_box)\n\n        categories = extract_tag_box('Category')\n        tags = extract_tag_box('Tags')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'average_rating': average_rating,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'categories': categories,\n            'tags': tags,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 61,
        "end_line": 171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.moniker.MonikerIE._real_extract#63",
        "src_path": "youtube_dl/extractor/moniker.py",
        "class_name": "youtube_dl.extractor.moniker.MonikerIE",
        "signature": "youtube_dl.extractor.moniker.MonikerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        orig_video_id = self._match_id(url)\n        video_id = remove_start(orig_video_id, 'embed-')\n        url = url.replace(orig_video_id, video_id)\n        assert re.match(self._VALID_URL, url) is not None\n        orig_webpage = self._download_webpage(url, video_id)\n\n        if '>File Not Found<' in orig_webpage:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        error = self._search_regex(\n            r'class=\"err\">([^<]+)<', orig_webpage, 'error', default=None)\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error), expected=True)\n\n        builtin_url = self._search_regex(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>.+?/builtin-.+?)\\1',\n            orig_webpage, 'builtin URL', default=None, group='url')\n\n        if builtin_url:\n            req = compat_urllib_request.Request(builtin_url)\n            req.add_header('Referer', url)\n            webpage = self._download_webpage(req, video_id, 'Downloading builtin page')\n            title = self._og_search_title(orig_webpage).strip()\n            description = self._og_search_description(orig_webpage).strip()\n        else:\n            fields = re.findall(r'type=\"hidden\" name=\"(.+?)\"\\s* value=\"?(.+?)\">', orig_webpage)\n            data = dict(fields)\n\n            post = compat_urllib_parse.urlencode(data)\n            headers = {\n                b'Content-Type': b'application/x-www-form-urlencoded',\n            }\n            req = compat_urllib_request.Request(url, post, headers)\n            webpage = self._download_webpage(\n                req, video_id, note='Downloading video page ...')\n\n            title = os.path.splitext(data['fname'])[0]\n            description = None\n\n        # Could be several links with different quality\n        links = re.findall(r'\"file\" : \"?(.+?)\",', webpage)\n        # Assume the links are ordered in quality\n        formats = [{\n            'url': l,\n            'quality': i,\n        } for i, l in enumerate(links)]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n        }",
        "begin_line": 63,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sbs.SBSIE._real_extract#32",
        "src_path": "youtube_dl/extractor/sbs.py",
        "class_name": "youtube_dl.extractor.sbs.SBSIE",
        "signature": "youtube_dl.extractor.sbs.SBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.sbs.com.au/ondemand/video/single/%s?context=web' % video_id, video_id)\n\n        player_params = self._parse_json(\n            self._search_regex(\n                r'(?s)var\\s+playerParams\\s*=\\s*({.+?});', webpage, 'playerParams'),\n            video_id)\n\n        urls = player_params['releaseUrls']\n        theplatform_url = (urls.get('progressive') or urls.get('standard') or\n                           urls.get('html') or player_params['relatedItemsURL'])\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': theplatform_url,\n        }",
        "begin_line": 32,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.scivee.SciVeeIE._real_extract#23",
        "src_path": "youtube_dl/extractor/scivee.py",
        "class_name": "youtube_dl.extractor.scivee.SciVeeIE",
        "signature": "youtube_dl.extractor.scivee.SciVeeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        # annotations XML is malformed\n        annotations = self._download_webpage(\n            'http://www.scivee.tv/assets/annotations/%s' % video_id, video_id, 'Downloading annotations')\n\n        title = self._html_search_regex(r'<title>([^<]+)</title>', annotations, 'title')\n        description = self._html_search_regex(r'<abstract>([^<]+)</abstract>', annotations, 'abstract', fatal=False)\n        filesize = int_or_none(self._html_search_regex(\n            r'<filesize>([^<]+)</filesize>', annotations, 'filesize', fatal=False))\n\n        formats = [\n            {\n                'url': 'http://www.scivee.tv/assets/audio/%s' % video_id,\n                'ext': 'mp3',\n                'format_id': 'audio',\n            },\n            {\n                'url': 'http://www.scivee.tv/assets/video/%s' % video_id,\n                'ext': 'mp4',\n                'format_id': 'video',\n                'filesize': filesize,\n            },\n        ]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': 'http://www.scivee.tv/assets/videothumb/%s' % video_id,\n            'formats': formats,\n        }",
        "begin_line": 23,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ssa.SSAIE._real_extract#28",
        "src_path": "youtube_dl/extractor/ssa.py",
        "class_name": "youtube_dl.extractor.ssa.SSAIE",
        "signature": "youtube_dl.extractor.ssa.SSAIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        streamer = self._search_regex(\n            r\"'streamer'\\s*,\\S*'(rtmp[^']+)'\", webpage, 'streamer')\n        play_path = self._search_regex(\n            r\"'file'\\s*,\\s*'([^']+)'\", webpage, 'file').rpartition('.')[0]\n\n        def search_field(field_name, fatal=False):\n            return self._search_regex(\n                r'<span\\s+class=\"field_title\">%s:</span>\\s*<span\\s+class=\"field_content\">([^<]+)</span>' % field_name,\n                webpage, 'title', fatal=fatal)\n\n        title = unescapeHTML(search_field('Title', fatal=True)).strip('()[]')\n        description = unescapeHTML(search_field('Description'))\n        duration = parse_duration(search_field('Running time'))\n        thumbnail = self._search_regex(\n            r\"'image'\\s*,\\s*'([^']+)'\", webpage, 'thumbnails', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': streamer,\n            'play_path': play_path,\n            'ext': 'flv',\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 28,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.kankan.KankanIE._real_extract#25",
        "src_path": "youtube_dl/extractor/kankan.py",
        "class_name": "youtube_dl.extractor.kankan.KankanIE",
        "signature": "youtube_dl.extractor.kankan.KankanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._search_regex(r'(?:G_TITLE=|G_MOVIE_TITLE = )[\\'\"](.+?)[\\'\"]', webpage, 'video title')\n        surls = re.search(r'surls:\\[\\'.+?\\'\\]|lurl:\\'.+?\\.flv\\'', webpage).group(0)\n        gcids = re.findall(r\"http://.+?/.+?/(.+?)/\", surls)\n        gcid = gcids[-1]\n\n        info_url = 'http://p2s.cl.kankan.com/getCdnresource_flv?gcid=%s' % gcid\n        video_info_page = self._download_webpage(\n            info_url, video_id, 'Downloading video url info')\n        ip = self._search_regex(r'ip:\"(.+?)\"', video_info_page, 'video url ip')\n        path = self._search_regex(r'path:\"(.+?)\"', video_info_page, 'video url path')\n        param1 = self._search_regex(r'param1:(\\d+)', video_info_page, 'param1')\n        param2 = self._search_regex(r'param2:(\\d+)', video_info_page, 'param2')\n        key = _md5('xl_mp43651' + param1 + param2)\n        video_url = 'http://%s%s?key=%s&key1=%s' % (ip, path, key, param2)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 25,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.walla.WallaIE._real_extract#36",
        "src_path": "youtube_dl/extractor/walla.py",
        "class_name": "youtube_dl.extractor.walla.WallaIE",
        "signature": "youtube_dl.extractor.walla.WallaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        video = self._download_xml(\n            'http://video2.walla.co.il/?w=null/null/%s/@@/video/flv_pl' % video_id,\n            display_id)\n\n        item = video.find('./items/item')\n\n        title = xpath_text(item, './title', 'title')\n        description = xpath_text(item, './synopsis', 'description')\n        thumbnail = xpath_text(item, './preview_pic', 'thumbnail')\n        duration = int_or_none(xpath_text(item, './duration', 'duration'))\n\n        subtitles = {}\n        for subtitle in item.findall('./subtitles/subtitle'):\n            lang = xpath_text(subtitle, './title')\n            subtitles[self._SUBTITLE_LANGS.get(lang, lang)] = [{\n                'ext': 'srt',\n                'url': xpath_text(subtitle, './src'),\n            }]\n\n        formats = []\n        for quality in item.findall('./qualities/quality'):\n            format_id = xpath_text(quality, './title')\n            fmt = {\n                'url': 'rtmp://wafla.walla.co.il/vod',\n                'play_path': xpath_text(quality, './src'),\n                'player_url': 'http://isc.walla.co.il/w9/swf/video_swf/vod/WallaMediaPlayerAvod.swf',\n                'page_url': url,\n                'ext': 'flv',\n                'format_id': xpath_text(quality, './title'),\n            }\n            m = re.search(r'^(?P<height>\\d+)[Pp]', format_id)\n            if m:\n                fmt['height'] = int(m.group('height'))\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 36,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE._real_extract#28",
        "src_path": "youtube_dl/extractor/clipsyndicate.py",
        "class_name": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE",
        "signature": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        js_player = self._download_webpage(\n            'http://eplayer.clipsyndicate.com/embed/player.js?va_id=%s' % video_id,\n            video_id, 'Downlaoding player')\n        # it includes a required token\n        flvars = self._search_regex(r'flvars: \"(.*?)\"', js_player, 'flvars')\n\n        pdoc = self._download_xml(\n            'http://eplayer.clipsyndicate.com/osmf/playlist?%s' % flvars,\n            video_id, 'Downloading video info',\n            transform_source=fix_xml_ampersands)\n\n        track_doc = pdoc.find('trackList/track')\n\n        def find_param(name):\n            node = find_xpath_attr(track_doc, './/param', 'name', name)\n            if node is not None:\n                return node.attrib['value']\n\n        return {\n            'id': video_id,\n            'title': find_param('title'),\n            'url': track_doc.find('location').text,\n            'thumbnail': find_param('thumbnail'),\n            'duration': int(find_param('duration')),\n        }",
        "begin_line": 28,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vrt.VRTIE._real_extract#57",
        "src_path": "youtube_dl/extractor/vrt.py",
        "class_name": "youtube_dl.extractor.vrt.VRTIE",
        "signature": "youtube_dl.extractor.vrt.VRTIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_id = self._search_regex(\n            r'data-video-id=\"([^\"]+)_[^\"]+\"', webpage, 'video id', fatal=False)\n\n        formats = []\n        mobj = re.search(\n            r'data-video-iphone-server=\"(?P<server>[^\"]+)\"\\s+data-video-iphone-path=\"(?P<path>[^\"]+)\"',\n            webpage)\n        if mobj:\n            formats.extend(self._extract_m3u8_formats(\n                '%s/%s' % (mobj.group('server'), mobj.group('path')),\n                video_id, 'mp4'))\n        mobj = re.search(r'data-video-src=\"(?P<src>[^\"]+)\"', webpage)\n        if mobj:\n            formats.extend(self._extract_f4m_formats(\n                '%s/manifest.f4m' % mobj.group('src'), video_id))\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage, default=None)\n        thumbnail = self._og_search_thumbnail(webpage)\n        timestamp = float_or_none(self._search_regex(\n            r'data-video-sitestat-pubdate=\"(\\d+)\"', webpage, 'timestamp', fatal=False), 1000)\n        duration = float_or_none(self._search_regex(\n            r'data-video-duration=\"(\\d+)\"', webpage, 'duration', fatal=False), 1000)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 57,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.teletask.TeleTaskIE._real_extract#36",
        "src_path": "youtube_dl/extractor/teletask.py",
        "class_name": "youtube_dl.extractor.teletask.TeleTaskIE",
        "signature": "youtube_dl.extractor.teletask.TeleTaskIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        lecture_id = self._match_id(url)\n        webpage = self._download_webpage(url, lecture_id)\n\n        title = self._html_search_regex(\n            r'itemprop=\"name\">([^<]+)</a>', webpage, 'title')\n        upload_date = unified_strdate(self._html_search_regex(\n            r'Date:</td><td>([^<]+)</td>', webpage, 'date', fatal=False))\n\n        entries = [{\n            'id': '%s-%s' % (lecture_id, format_id),\n            'url': video_url,\n            'title': title,\n            'upload_date': upload_date,\n        } for format_id, video_url in re.findall(\n            r'<video class=\"([^\"]+)\"[^>]*>\\s*<source src=\"([^\"]+)\"', webpage)]\n\n        return self.playlist_result(entries, lecture_id, title)",
        "begin_line": 36,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.godtube.GodTubeIE._real_extract#31",
        "src_path": "youtube_dl/extractor/godtube.py",
        "class_name": "youtube_dl.extractor.godtube.GodTubeIE",
        "signature": "youtube_dl.extractor.godtube.GodTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        config = self._download_xml(\n            'http://www.godtube.com/resource/mediaplayer/%s.xml' % video_id.lower(),\n            video_id, 'Downloading player config XML')\n\n        video_url = config.find('file').text\n        uploader = config.find('author').text\n        timestamp = parse_iso8601(config.find('date').text)\n        duration = parse_duration(config.find('duration').text)\n        thumbnail = config.find('image').text\n\n        media = self._download_xml(\n            'http://www.godtube.com/media/xml/?v=%s' % video_id, video_id, 'Downloading media XML')\n\n        title = media.find('title').text\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'duration': duration,\n        }",
        "begin_line": 31,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.freespeech.FreespeechIE._real_extract#26",
        "src_path": "youtube_dl/extractor/freespeech.py",
        "class_name": "youtube_dl.extractor.freespeech.FreespeechIE",
        "signature": "youtube_dl.extractor.freespeech.FreespeechIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        info_json = self._search_regex(r'jQuery.extend\\(Drupal.settings, ({.*?})\\);', webpage, 'info')\n        info = json.loads(info_json)\n\n        return {\n            '_type': 'url',\n            'url': info['jw_player']['basic_video_node_player']['file'],\n            'ie_key': 'Youtube',\n        }",
        "begin_line": 26,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._handle_error#35",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._handle_error(self, response)",
        "snippet": "    def _handle_error(self, response):\n        if not isinstance(response, dict):\n            return\n        error = response.get('error')\n        if error:\n            error_str = 'Udemy returned error #%s: %s' % (error.get('code'), error.get('message'))\n            error_data = error.get('data')\n            if error_data:\n                error_str += ' - %s' % error_data.get('formErrors')\n            raise ExtractorError(error_str, expected=True)",
        "begin_line": 35,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._download_json#46",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._download_json(self, url_or_request, video_id, note='Downloading JSON metadata')",
        "snippet": "    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata'):\n        headers = {\n            'X-Udemy-Snail-Case': 'true',\n            'X-Requested-With': 'XMLHttpRequest',\n        }\n        for cookie in self._downloader.cookiejar:\n            if cookie.name == 'client_id':\n                headers['X-Udemy-Client-Id'] = cookie.value\n            elif cookie.name == 'access_token':\n                headers['X-Udemy-Bearer-Token'] = cookie.value\n\n        if isinstance(url_or_request, compat_urllib_request.Request):\n            for header, value in headers.items():\n                url_or_request.add_header(header, value)\n        else:\n            url_or_request = compat_urllib_request.Request(url_or_request, headers=headers)\n\n        response = super(UdemyIE, self)._download_json(url_or_request, video_id, note)\n        self._handle_error(response)\n        return response",
        "begin_line": 46,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._real_initialize#67",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 67,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._login#70",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            self.raise_login_required('Udemy account is required')\n\n        login_popup = self._download_webpage(\n            self._LOGIN_URL, None, 'Downloading login popup')\n\n        def is_logged(webpage):\n            return any(p in webpage for p in ['href=\"https://www.udemy.com/user/logout/', '>Logout<'])\n\n        # already logged in\n        if is_logged(login_popup):\n            return\n\n        login_form = self._form_hidden_inputs('login-form', login_popup)\n\n        login_form.update({\n            'email': username.encode('utf-8'),\n            'password': password.encode('utf-8'),\n        })\n\n        request = compat_urllib_request.Request(\n            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))\n        request.add_header('Referer', self._ORIGIN_URL)\n        request.add_header('Origin', self._ORIGIN_URL)\n\n        response = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        if not is_logged(response):\n            error = self._html_search_regex(\n                r'(?s)<div[^>]+class=\"form-errors[^\"]*\">(.+?)</div>',\n                response, 'error message', default=None)\n            if error:\n                raise ExtractorError('Unable to login: %s' % error, expected=True)\n            raise ExtractorError('Unable to log in')",
        "begin_line": 70,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._real_extract#108",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        lecture_id = self._match_id(url)\n\n        lecture = self._download_json(\n            'https://www.udemy.com/api-1.1/lectures/%s' % lecture_id,\n            lecture_id, 'Downloading lecture JSON')\n\n        asset_type = lecture.get('assetType') or lecture.get('asset_type')\n        if asset_type != 'Video':\n            raise ExtractorError(\n                'Lecture %s is not a video' % lecture_id, expected=True)\n\n        asset = lecture['asset']\n\n        stream_url = asset.get('streamUrl') or asset.get('stream_url')\n        mobj = re.search(r'(https?://www\\.youtube\\.com/watch\\?v=.*)', stream_url)\n        if mobj:\n            return self.url_result(mobj.group(1), 'Youtube')\n\n        video_id = asset['id']\n        thumbnail = asset.get('thumbnailUrl') or asset.get('thumbnail_url')\n        duration = asset['data']['duration']\n\n        download_url = asset.get('downloadUrl') or asset.get('download_url')\n\n        video = download_url.get('Video') or download_url.get('video')\n        video_480p = download_url.get('Video480p') or download_url.get('video_480p')\n\n        formats = [\n            {\n                'url': video_480p[0],\n                'format_id': '360p',\n            },\n            {\n                'url': video[0],\n                'format_id': '720p',\n            },\n        ]\n\n        title = lecture['title']\n        description = lecture['description']\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats\n        }",
        "begin_line": 108,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyCourseIE.suitable#168",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyCourseIE",
        "signature": "youtube_dl.extractor.udemy.UdemyCourseIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if UdemyIE.suitable(url) else super(UdemyCourseIE, cls).suitable(url)",
        "begin_line": 168,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009225092250922509,
            "pseudo_dstar_susp": 0.0009225092250922509,
            "pseudo_tarantula_susp": 0.0009233610341643582,
            "pseudo_op2_susp": 0.0009225092250922509,
            "pseudo_barinel_susp": 0.0009233610341643582
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyCourseIE._real_extract#171",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyCourseIE",
        "signature": "youtube_dl.extractor.udemy.UdemyCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_path = mobj.group('coursepath')\n\n        response = self._download_json(\n            'https://www.udemy.com/api-1.1/courses/%s' % course_path,\n            course_path, 'Downloading course JSON')\n\n        course_id = int(response['id'])\n        course_title = response['title']\n\n        webpage = self._download_webpage(\n            'https://www.udemy.com/course/subscribe/?courseId=%s' % course_id,\n            course_id, 'Enrolling in the course')\n\n        if self._SUCCESSFULLY_ENROLLED in webpage:\n            self.to_screen('%s: Successfully enrolled in' % course_id)\n        elif self._ALREADY_ENROLLED in webpage:\n            self.to_screen('%s: Already enrolled in' % course_id)\n\n        response = self._download_json(\n            'https://www.udemy.com/api-1.1/courses/%s/curriculum' % course_id,\n            course_id, 'Downloading course curriculum')\n\n        entries = [\n            self.url_result(\n                'https://www.udemy.com/%s/#/lecture/%s' % (course_path, asset['id']), 'Udemy')\n            for asset in response if asset.get('assetType') or asset.get('asset_type') == 'Video'\n        ]\n\n        return self.playlist_result(entries, course_id, course_title)",
        "begin_line": 171,
        "end_line": 201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.quickvid.QuickVidIE._real_extract#30",
        "src_path": "youtube_dl/extractor/quickvid.py",
        "class_name": "youtube_dl.extractor.quickvid.QuickVidIE",
        "signature": "youtube_dl.extractor.quickvid.QuickVidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(r'<h2>(.*?)</h2>', webpage, 'title')\n        view_count = int_or_none(self._html_search_regex(\n            r'(?s)<div id=\"views\">(.*?)</div>',\n            webpage, 'view count', fatal=False))\n        video_code = self._search_regex(\n            r'(?s)<video id=\"video\"[^>]*>(.*?)</video>', webpage, 'video code')\n        formats = [\n            {\n                'url': compat_urlparse.urljoin(url, src),\n                'format_id': determine_ext(src, None),\n            } for src in re.findall('<source\\s+src=\"([^\"]+)\"', video_code)\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'view_count': view_count,\n        }",
        "begin_line": 30,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.thesixtyone.TheSixtyOneIE._real_extract#69",
        "src_path": "youtube_dl/extractor/thesixtyone.py",
        "class_name": "youtube_dl.extractor.thesixtyone.TheSixtyOneIE",
        "signature": "youtube_dl.extractor.thesixtyone.TheSixtyOneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            self._SONG_URL_TEMPLATE.format(song_id), song_id)\n\n        song_data = self._parse_json(self._search_regex(\n            r'\"%s\":\\s(\\{.*?\\})' % song_id, webpage, 'song_data'), song_id)\n\n        if self._search_regex(r'(t61\\.s3_audio_load\\s*=\\s*1\\.0;)', webpage, 's3_audio_load marker', default=None):\n            song_data['audio_server'] = 's3.amazonaws.com'\n        else:\n            song_data['audio_server'] = song_data['audio_server'] + '.thesixtyone.com'\n\n        keys = [self._DECODE_MAP.get(s, s) for s in song_data['key']]\n        url = self._SONG_FILE_URL_TEMPLATE.format(\n            \"\".join(reversed(keys)), **song_data)\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n            'ext': 'mp3',\n        }]\n\n        return {\n            'id': song_id,\n            'title': '{artist:} - {name:}'.format(**song_data),\n            'formats': formats,\n            'comment_count': song_data.get('comments_count'),\n            'duration': song_data.get('play_time'),\n            'like_count': song_data.get('score'),\n            'thumbnail': self._THUMBNAIL_URL_TEMPLATE.format(**song_data),\n            'upload_date': unified_strdate(song_data.get('publish_date')),\n        }",
        "begin_line": 69,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.miomio.MioMioIE._real_extract#44",
        "src_path": "youtube_dl/extractor/miomio.py",
        "class_name": "youtube_dl.extractor.miomio.MioMioIE",
        "signature": "youtube_dl.extractor.miomio.MioMioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta(\n            'description', webpage, 'title', fatal=True)\n\n        mioplayer_path = self._search_regex(\n            r'src=\"(/mioplayer/[^\"]+)\"', webpage, 'ref_path')\n\n        xml_config = self._search_regex(\n            r'flashvars=\"type=(?:sina|video)&amp;(.+?)&amp;',\n            webpage, 'xml config')\n\n        # skipping the following page causes lags and eventually connection drop-outs\n        self._request_webpage(\n            'http://www.miomio.tv/mioplayer/mioplayerconfigfiles/xml.php?id=%s&r=%s' % (id, random.randint(100, 999)),\n            video_id)\n\n        # the following xml contains the actual configuration information on the video file(s)\n        vid_config = self._download_xml(\n            'http://www.miomio.tv/mioplayer/mioplayerconfigfiles/sina.php?{0}'.format(xml_config),\n            video_id)\n\n        http_headers = {\n            'Referer': 'http://www.miomio.tv%s' % mioplayer_path,\n        }\n\n        if not int_or_none(xpath_text(vid_config, 'timelength')):\n            raise ExtractorError('Unable to load videos!', expected=True)\n\n        entries = []\n        for f in vid_config.findall('./durl'):\n            segment_url = xpath_text(f, 'url', 'video url')\n            if not segment_url:\n                continue\n            order = xpath_text(f, 'order', 'order')\n            segment_id = video_id\n            segment_title = title\n            if order:\n                segment_id += '-%s' % order\n                segment_title += ' part %s' % order\n            entries.append({\n                'id': segment_id,\n                'url': segment_url,\n                'title': segment_title,\n                'duration': int_or_none(xpath_text(f, 'length', 'duration'), 1000),\n                'http_headers': http_headers,\n            })\n\n        if len(entries) == 1:\n            segment = entries[0]\n            segment['id'] = video_id\n            segment['title'] = title\n            return segment\n\n        return {\n            '_type': 'multi_video',\n            'id': video_id,\n            'entries': entries,\n            'title': title,\n            'http_headers': http_headers,\n        }",
        "begin_line": 44,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tubitv.TubiTvIE._login#37",
        "src_path": "youtube_dl/extractor/tubitv.py",
        "class_name": "youtube_dl.extractor.tubitv.TubiTvIE",
        "signature": "youtube_dl.extractor.tubitv.TubiTvIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n        self.report_login()\n        form_data = {\n            'username': username,\n            'password': password,\n        }\n        payload = compat_urllib_parse.urlencode(form_data).encode('utf-8')\n        request = compat_urllib_request.Request(self._LOGIN_URL, payload)\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        login_page = self._download_webpage(\n            request, None, False, 'Wrong login info')\n        if not re.search(r'id=\"tubi-logout\"', login_page):\n            raise ExtractorError(\n                'Login failed (invalid username/password)', expected=True)",
        "begin_line": 37,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tubitv.TubiTvIE._real_initialize#55",
        "src_path": "youtube_dl/extractor/tubitv.py",
        "class_name": "youtube_dl.extractor.tubitv.TubiTvIE",
        "signature": "youtube_dl.extractor.tubitv.TubiTvIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 55,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tubitv.TubiTvIE._real_extract#58",
        "src_path": "youtube_dl/extractor/tubitv.py",
        "class_name": "youtube_dl.extractor.tubitv.TubiTvIE",
        "signature": "youtube_dl.extractor.tubitv.TubiTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        if re.search(r\"<(?:DIV|div) class='login-required-screen'>\", webpage):\n            self.raise_login_required('This video requires login')\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        duration = int_or_none(self._html_search_meta(\n            'video:duration', webpage, 'duration'))\n\n        apu = self._search_regex(r\"apu='([^']+)'\", webpage, 'apu')\n        m3u8_url = codecs.decode(apu, 'rot_13')[::-1]\n        formats = self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n        }",
        "begin_line": 58,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.spike.SpikeIE._real_extract#25",
        "src_path": "youtube_dl/extractor/spike.py",
        "class_name": "youtube_dl.extractor.spike.SpikeIE",
        "signature": "youtube_dl.extractor.spike.SpikeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobile_id = self._match_id(url)\n        if mobile_id:\n            url = 'http://www.spike.com/video-clips/%s' % mobile_id\n        return super(SpikeIE, self)._real_extract(url)",
        "begin_line": 25,
        "end_line": 29,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xtube.XTubeIE._real_extract#32",
        "src_path": "youtube_dl/extractor/xtube.py",
        "class_name": "youtube_dl.extractor.xtube.XTubeIE",
        "signature": "youtube_dl.extractor.xtube.XTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(\n            r'<p class=\"title\">([^<]+)', webpage, 'title')\n        video_uploader = self._html_search_regex(\n            [r\"var\\s+contentOwnerId\\s*=\\s*'([^']+)\",\n             r'By:\\s*<a href=\"/community/profile\\.php\\?user=([^\"]+)'],\n            webpage, 'uploader', fatal=False)\n        video_description = self._html_search_regex(\n            r'<p class=\"fieldsDesc\">([^<]+)',\n            webpage, 'description', fatal=False)\n        duration = parse_duration(self._html_search_regex(\n            r'<span class=\"bold\">Runtime:</span> ([^<]+)</p>',\n            webpage, 'duration', fatal=False))\n        view_count = str_to_int(self._html_search_regex(\n            r'<span class=\"bold\">Views:</span> ([\\d,\\.]+)</p>',\n            webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r'<div id=\"commentBar\">([\\d,\\.]+) Comments</div>',\n            webpage, 'comment count', fatal=False))\n\n        formats = []\n        for format_id, video_url in re.findall(\n                r'flashvars\\.quality_(.+?)\\s*=\\s*\"([^\"]+)\"', webpage):\n            fmt = {\n                'url': compat_urllib_parse_unquote(video_url),\n                'format_id': format_id,\n            }\n            m = re.search(r'^(?P<height>\\d+)[pP]', format_id)\n            if m:\n                fmt['height'] = int(m.group('height'))\n            formats.append(fmt)\n\n        if not formats:\n            video_url = compat_urllib_parse_unquote(self._search_regex(\n                r'flashvars\\.video_url\\s*=\\s*\"([^\"]+)\"',\n                webpage, 'video URL'))\n            formats.append({'url': video_url})\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'uploader': video_uploader,\n            'description': video_description,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 32,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xtube.XTubeUserIE._real_extract#103",
        "src_path": "youtube_dl/extractor/xtube.py",
        "class_name": "youtube_dl.extractor.xtube.XTubeUserIE",
        "signature": "youtube_dl.extractor.xtube.XTubeUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        username = mobj.group('username')\n\n        profile_page = self._download_webpage(\n            url, username, note='Retrieving profile page')\n\n        video_count = int(self._search_regex(\n            r'<strong>%s\\'s Videos \\(([0-9]+)\\)</strong>' % username, profile_page,\n            'video count'))\n\n        PAGE_SIZE = 25\n        urls = []\n        page_count = (video_count + PAGE_SIZE + 1) // PAGE_SIZE\n        for n in range(1, page_count + 1):\n            lpage_url = 'http://www.xtube.com/user_videos.php?page=%d&u=%s' % (n, username)\n            lpage = self._download_webpage(\n                lpage_url, username,\n                note='Downloading page %d/%d' % (n, page_count))\n            urls.extend(\n                re.findall(r'addthis:url=\"([^\"]+)\"', lpage))\n\n        return {\n            '_type': 'playlist',\n            'id': username,\n            'age_limit': 18,\n            'entries': [{\n                '_type': 'url',\n                'url': eurl,\n                'ie_key': 'XTube',\n            } for eurl in urls]\n        }",
        "begin_line": 103,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.espn.ESPNIE._real_extract#38",
        "src_path": "youtube_dl/extractor/espn.py",
        "class_name": "youtube_dl.extractor.espn.ESPNIE",
        "signature": "youtube_dl.extractor.espn.ESPNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_id = self._search_regex(\n            r'class=\"video-play-button\"[^>]+data-id=\"(\\d+)',\n            webpage, 'video id')\n\n        player = self._download_webpage(\n            'https://espn.go.com/video/iframe/twitter/?id=%s' % video_id, video_id)\n\n        pcode = self._search_regex(\n            r'[\"\\']pcode=([^\"\\']+)[\"\\']', player, 'pcode')\n\n        return self.url_result(\n            'ooyalaexternal:espn:%s:%s' % (video_id, pcode),\n            'OoyalaExternal')",
        "begin_line": 38,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtp.RTPIE._real_extract#30",
        "src_path": "youtube_dl/extractor/rtp.py",
        "class_name": "youtube_dl.extractor.rtp.RTPIE",
        "signature": "youtube_dl.extractor.rtp.RTPIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_meta(\n            'twitter:title', webpage, display_name='title', fatal=True)\n        description = self._html_search_meta('description', webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        player_config = self._search_regex(\n            r'(?s)RTPPLAY\\.player\\.newPlayer\\(\\s*(\\{.*?\\})\\s*\\)', webpage, 'player config')\n        config = self._parse_json(player_config, video_id)\n\n        path, ext = config.get('file').rsplit('.', 1)\n        formats = [{\n            'format_id': 'rtmp',\n            'ext': ext,\n            'vcodec': config.get('type') == 'audio' and 'none' or None,\n            'preference': -2,\n            'url': 'rtmp://{streamer:s}/{application:s}'.format(**config),\n            'app': config.get('application'),\n            'play_path': '{ext:s}:{path:s}'.format(ext=ext, path=path),\n            'page_url': url,\n            'rtmp_live': config.get('live', False),\n            'player_url': 'http://programas.rtp.pt/play/player.swf?v3',\n            'rtmp_real_time': True,\n        }]\n\n        # Construct regular HTTP download URLs\n        replacements = {\n            'audio': {\n                'format_id': 'mp3',\n                'pattern': r'^nas2\\.share/wavrss/',\n                'repl': 'http://rsspod.rtp.pt/podcasts/',\n                'vcodec': 'none',\n            },\n            'video': {\n                'format_id': 'mp4_h264',\n                'pattern': r'^nas2\\.share/h264/',\n                'repl': 'http://rsspod.rtp.pt/videocasts/',\n                'vcodec': 'h264',\n            },\n        }\n        r = replacements[config['type']]\n        if re.match(r['pattern'], config['file']) is not None:\n            formats.append({\n                'format_id': r['format_id'],\n                'url': re.sub(r['pattern'], r['repl'], config['file']),\n                'vcodec': r['vcodec'],\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 30,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.muzu.MuzuTVIE._real_extract#25",
        "src_path": "youtube_dl/extractor/muzu.py",
        "class_name": "youtube_dl.extractor.muzu.MuzuTVIE",
        "signature": "youtube_dl.extractor.muzu.MuzuTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info_data = compat_urllib_parse.urlencode({\n            'format': 'json',\n            'url': url,\n        })\n        info = self._download_json(\n            'http://www.muzu.tv/api/oembed/?%s' % info_data,\n            video_id, 'Downloading video info')\n\n        player_info = self._download_json(\n            'http://player.muzu.tv/player/playerInit?ai=%s' % video_id,\n            video_id, 'Downloading player info')\n        video_info = player_info['videos'][0]\n        for quality in ['1080', '720', '480', '360']:\n            if video_info.get('v%s' % quality):\n                break\n\n        data = compat_urllib_parse.urlencode({\n            'ai': video_id,\n            # Even if each time you watch a video the hash changes,\n            # it seems to work for different videos, and it will work\n            # even if you use any non empty string as a hash\n            'viewhash': 'VBNff6djeV4HV5TRPW5kOHub2k',\n            'device': 'web',\n            'qv': quality,\n        })\n        video_url_info = self._download_json(\n            'http://player.muzu.tv/player/requestVideo?%s' % data,\n            video_id, 'Downloading video url')\n        video_url = video_url_info['url']\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'url': video_url,\n            'thumbnail': info['thumbnail_url'],\n            'description': info['description'],\n            'uploader': info['author_name'],\n        }",
        "begin_line": 25,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.hitbox.HitboxIE._extract_metadata#43",
        "src_path": "youtube_dl/extractor/hitbox.py",
        "class_name": "youtube_dl.extractor.hitbox.HitboxIE",
        "signature": "youtube_dl.extractor.hitbox.HitboxIE._extract_metadata(self, url, video_id)",
        "snippet": "    def _extract_metadata(self, url, video_id):\n        thumb_base = 'https://edge.sf.hitbox.tv'\n        metadata = self._download_json(\n            '%s/%s' % (url, video_id), video_id,\n            'Downloading metadata JSON')\n\n        date = 'media_live_since'\n        media_type = 'livestream'\n        if metadata.get('media_type') == 'video':\n            media_type = 'video'\n            date = 'media_date_added'\n\n        video_meta = metadata.get(media_type, [])[0]\n        title = video_meta.get('media_status')\n        alt_title = video_meta.get('media_title')\n        description = clean_html(\n            video_meta.get('media_description') or\n            video_meta.get('media_description_md'))\n        duration = float_or_none(video_meta.get('media_duration'))\n        uploader = video_meta.get('media_user_name')\n        views = int_or_none(video_meta.get('media_views'))\n        timestamp = parse_iso8601(video_meta.get(date), ' ')\n        categories = [video_meta.get('category_name')]\n        thumbs = [\n            {'url': thumb_base + video_meta.get('media_thumbnail'),\n             'width': 320,\n             'height': 180},\n            {'url': thumb_base + video_meta.get('media_thumbnail_large'),\n             'width': 768,\n             'height': 432},\n        ]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'alt_title': alt_title,\n            'description': description,\n            'ext': 'mp4',\n            'thumbnails': thumbs,\n            'duration': duration,\n            'uploader': uploader,\n            'view_count': views,\n            'timestamp': timestamp,\n            'categories': categories,\n        }",
        "begin_line": 43,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.hitbox.HitboxIE._real_extract#89",
        "src_path": "youtube_dl/extractor/hitbox.py",
        "class_name": "youtube_dl.extractor.hitbox.HitboxIE",
        "signature": "youtube_dl.extractor.hitbox.HitboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        player_config = self._download_json(\n            'https://www.hitbox.tv/api/player/config/video/%s' % video_id,\n            video_id, 'Downloading video JSON')\n\n        formats = []\n        for video in player_config['clip']['bitrates']:\n            label = video.get('label')\n            if label == 'Auto':\n                continue\n            video_url = video.get('url')\n            if not video_url:\n                continue\n            bitrate = int_or_none(video.get('bitrate'))\n            if determine_ext(video_url) == 'm3u8':\n                if not video_url.startswith('http'):\n                    continue\n                formats.append({\n                    'url': video_url,\n                    'ext': 'mp4',\n                    'tbr': bitrate,\n                    'format_note': label,\n                    'protocol': 'm3u8_native',\n                })\n            else:\n                formats.append({\n                    'url': video_url,\n                    'tbr': bitrate,\n                    'format_note': label,\n                })\n        self._sort_formats(formats)\n\n        metadata = self._extract_metadata(\n            'https://www.hitbox.tv/api/media/video',\n            video_id)\n        metadata['formats'] = formats\n\n        return metadata",
        "begin_line": 89,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.hitbox.HitboxLiveIE._real_extract#151",
        "src_path": "youtube_dl/extractor/hitbox.py",
        "class_name": "youtube_dl.extractor.hitbox.HitboxLiveIE",
        "signature": "youtube_dl.extractor.hitbox.HitboxLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        player_config = self._download_json(\n            'https://www.hitbox.tv/api/player/config/live/%s' % video_id,\n            video_id)\n\n        formats = []\n        cdns = player_config.get('cdns')\n        servers = []\n        for cdn in cdns:\n            base_url = cdn.get('netConnectionUrl')\n            host = re.search('.+\\.([^\\.]+\\.[^\\./]+)/.+', base_url).group(1)\n            if base_url not in servers:\n                servers.append(base_url)\n                for stream in cdn.get('bitrates'):\n                    label = stream.get('label')\n                    if label == 'Auto':\n                        continue\n                    stream_url = stream.get('url')\n                    if not stream_url:\n                        continue\n                    bitrate = int_or_none(stream.get('bitrate'))\n                    if stream.get('provider') == 'hls' or determine_ext(stream_url) == 'm3u8':\n                        if not stream_url.startswith('http'):\n                            continue\n                        formats.append({\n                            'url': stream_url,\n                            'ext': 'mp4',\n                            'tbr': bitrate,\n                            'format_note': label,\n                            'rtmp_live': True,\n                        })\n                    else:\n                        formats.append({\n                            'url': '%s/%s' % (base_url, stream_url),\n                            'ext': 'mp4',\n                            'tbr': bitrate,\n                            'rtmp_live': True,\n                            'format_note': host,\n                            'page_url': url,\n                            'player_url': 'http://www.hitbox.tv/static/player/flowplayer/flowplayer.commercial-3.2.16.swf',\n                        })\n        self._sort_formats(formats)\n\n        metadata = self._extract_metadata(\n            'https://www.hitbox.tv/api/media/live',\n            video_id)\n        metadata['formats'] = formats\n        metadata['is_live'] = True\n        metadata['title'] = self._live_title(metadata.get('title'))\n\n        return metadata",
        "begin_line": 151,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.motherless.MotherlessIE._real_extract#60",
        "src_path": "youtube_dl/extractor/motherless.py",
        "class_name": "youtube_dl.extractor.motherless.MotherlessIE",
        "signature": "youtube_dl.extractor.motherless.MotherlessIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'id=\"view-upload-title\">\\s+([^<]+)<', webpage, 'title')\n        video_url = self._html_search_regex(\n            r'setup\\(\\{\\s+\"file\".+: \"([^\"]+)\",', webpage, 'video URL')\n        age_limit = self._rta_search(webpage)\n        view_count = str_to_int(self._html_search_regex(\n            r'<strong>Views</strong>\\s+([^<]+)<',\n            webpage, 'view count', fatal=False))\n        like_count = str_to_int(self._html_search_regex(\n            r'<strong>Favorited</strong>\\s+([^<]+)<',\n            webpage, 'like count', fatal=False))\n\n        upload_date = self._html_search_regex(\n            r'<strong>Uploaded</strong>\\s+([^<]+)<', webpage, 'upload date')\n        if 'Ago' in upload_date:\n            days = int(re.search(r'([0-9]+)', upload_date).group(1))\n            upload_date = (datetime.datetime.now() - datetime.timedelta(days=days)).strftime('%Y%m%d')\n        else:\n            upload_date = unified_strdate(upload_date)\n\n        comment_count = webpage.count('class=\"media-comment-contents\"')\n        uploader_id = self._html_search_regex(\n            r'\"thumb-member-username\">\\s+<a href=\"/m/([^\"]+)\"',\n            webpage, 'uploader_id')\n\n        categories = self._html_search_meta('keywords', webpage)\n        if categories:\n            categories = [cat.strip() for cat in categories.split(',')]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'categories': categories,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'age_limit': age_limit,\n            'url': video_url,\n        }",
        "begin_line": 60,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.hls.HlsFD.real_download#20",
        "src_path": "youtube_dl/downloader/hls.py",
        "class_name": "youtube_dl.downloader.hls.HlsFD",
        "signature": "youtube_dl.downloader.hls.HlsFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n\n        ffpp = FFmpegPostProcessor(downloader=self)\n        if not ffpp.available:\n            self.report_error('m3u8 download detected but ffmpeg or avconv could not be found. Please install one.')\n            return False\n        ffpp.check_version()\n\n        args = [ffpp.executable, '-y']\n\n        if info_dict['http_headers'] and re.match(r'^https?://', url):\n            # Trailing \\r\\n after each HTTP header is important to prevent warning from ffmpeg/avconv:\n            # [http @ 00000000003d2fa0] No trailing CRLF found in HTTP header.\n            args += [\n                '-headers',\n                ''.join('%s: %s\\r\\n' % (key, val) for key, val in info_dict['http_headers'].items())]\n\n        args += ['-i', url, '-f', 'mp4', '-c', 'copy', '-bsf:a', 'aac_adtstoasc']\n\n        args = [encodeArgument(opt) for opt in args]\n        args.append(encodeFilename(ffpp._ffmpeg_filename_argument(tmpfilename), True))\n\n        self._debug_cmd(args)\n\n        retval = subprocess.call(args)\n        if retval == 0:\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('\\r[%s] %s bytes' % (args[0], fsize))\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr('\\n')\n            self.report_error('%s exited with code %d' % (ffpp.basename, retval))\n            return False",
        "begin_line": 20,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.hls.NativeHlsFD.real_download#70",
        "src_path": "youtube_dl/downloader/hls.py",
        "class_name": "youtube_dl.downloader.hls.NativeHlsFD",
        "signature": "youtube_dl.downloader.hls.NativeHlsFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        man_url = info_dict['url']\n        self.to_screen('[%s] Downloading m3u8 manifest' % self.FD_NAME)\n        manifest = self.ydl.urlopen(man_url).read()\n\n        s = manifest.decode('utf-8', 'ignore')\n        fragment_urls = []\n        for line in s.splitlines():\n            line = line.strip()\n            if line and not line.startswith('#'):\n                segment_url = (\n                    line\n                    if re.match(r'^https?://', line)\n                    else compat_urlparse.urljoin(man_url, line))\n                fragment_urls.append(segment_url)\n                # We only download the first fragment during the test\n                if self.params.get('test', False):\n                    break\n\n        ctx = {\n            'filename': filename,\n            'total_frags': len(fragment_urls),\n        }\n\n        self._prepare_and_start_frag_download(ctx)\n\n        frags_filenames = []\n        for i, frag_url in enumerate(fragment_urls):\n            frag_filename = '%s-Frag%d' % (ctx['tmpfilename'], i)\n            success = ctx['dl'].download(frag_filename, {'url': frag_url})\n            if not success:\n                return False\n            down, frag_sanitized = sanitize_open(frag_filename, 'rb')\n            ctx['dest_stream'].write(down.read())\n            down.close()\n            frags_filenames.append(frag_sanitized)\n\n        self._finish_frag_download(ctx)\n\n        for frag_file in frags_filenames:\n            os.remove(encodeFilename(frag_file))\n\n        return True",
        "begin_line": 70,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.telegraaf.TelegraafIE._real_extract#23",
        "src_path": "youtube_dl/extractor/telegraaf.py",
        "class_name": "youtube_dl.extractor.telegraaf.TelegraafIE",
        "signature": "youtube_dl.extractor.telegraaf.TelegraafIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        playlist_url = self._search_regex(\n            r\"iframe\\.loadPlayer\\('([^']+)'\", webpage, 'player')\n\n        entries = self._extract_xspf_playlist(playlist_url, playlist_id)\n        title = remove_end(self._og_search_title(webpage), ' - VIDEO')\n        description = self._og_search_description(webpage)\n\n        return self.playlist_result(entries, playlist_id, title, description)",
        "begin_line": 23,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.eroprofile.EroProfileIE._login#41",
        "src_path": "youtube_dl/extractor/eroprofile.py",
        "class_name": "youtube_dl.extractor.eroprofile.EroProfileIE",
        "signature": "youtube_dl.extractor.eroprofile.EroProfileIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        query = compat_urllib_parse.urlencode({\n            'username': username,\n            'password': password,\n            'url': 'http://www.eroprofile.com/',\n        })\n        login_url = self._LOGIN_URL + query\n        login_page = self._download_webpage(login_url, None, False)\n\n        m = re.search(r'Your username or password was incorrect\\.', login_page)\n        if m:\n            raise ExtractorError(\n                'Wrong username and/or password.', expected=True)\n\n        self.report_login()\n        redirect_url = self._search_regex(\n            r'<script[^>]+?src=\"([^\"]+)\"', login_page, 'login redirect url')\n        self._download_webpage(redirect_url, None, False)",
        "begin_line": 41,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.eroprofile.EroProfileIE._real_initialize#64",
        "src_path": "youtube_dl/extractor/eroprofile.py",
        "class_name": "youtube_dl.extractor.eroprofile.EroProfileIE",
        "signature": "youtube_dl.extractor.eroprofile.EroProfileIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 64,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.eroprofile.EroProfileIE._real_extract#67",
        "src_path": "youtube_dl/extractor/eroprofile.py",
        "class_name": "youtube_dl.extractor.eroprofile.EroProfileIE",
        "signature": "youtube_dl.extractor.eroprofile.EroProfileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        m = re.search(r'You must be logged in to view this video\\.', webpage)\n        if m:\n            self.raise_login_required('This video requires login')\n\n        video_id = self._search_regex(\n            [r\"glbUpdViews\\s*\\('\\d*','(\\d+)'\", r'p/report/video/(\\d+)'],\n            webpage, 'video id', default=None)\n\n        video_url = unescapeHTML(self._search_regex(\n            r'<source src=\"([^\"]+)', webpage, 'video url'))\n        title = self._html_search_regex(\n            r'Title:</th><td>([^<]+)</td>', webpage, 'title')\n        thumbnail = self._search_regex(\n            r'onclick=\"showVideoPlayer\\(\\)\"><img src=\"([^\"]+)',\n            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 67,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ringtv.RingTVIE._real_extract#21",
        "src_path": "youtube_dl/extractor/ringtv.py",
        "class_name": "youtube_dl.extractor.ringtv.RingTVIE",
        "signature": "youtube_dl.extractor.ringtv.RingTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id').split('-')[0]\n        webpage = self._download_webpage(url, video_id)\n\n        if mobj.group('type') == 'news':\n            video_id = self._search_regex(\n                r'''(?x)<iframe[^>]+src=\"http://cms\\.springboardplatform\\.com/\n                        embed_iframe/[0-9]+/video/([0-9]+)/''',\n                webpage, 'real video ID')\n        title = self._og_search_title(webpage)\n        description = self._html_search_regex(\n            r'addthis:description=\"([^\"]+)\"',\n            webpage, 'description', fatal=False)\n        final_url = \"http://ringtv.craveonline.springboardplatform.com/storage/ringtv.craveonline.com/conversion/%s.mp4\" % video_id\n        thumbnail_url = \"http://ringtv.craveonline.springboardplatform.com/storage/ringtv.craveonline.com/snapshots/%s.jpg\" % video_id\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': thumbnail_url,\n            'description': description,\n        }",
        "begin_line": 21,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.wrzuta.WrzutaIE._real_extract#42",
        "src_path": "youtube_dl/extractor/wrzuta.py",
        "class_name": "youtube_dl.extractor.wrzuta.WrzutaIE",
        "signature": "youtube_dl.extractor.wrzuta.WrzutaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        typ = mobj.group('typ')\n        uploader = mobj.group('uploader')\n\n        webpage = self._download_webpage(url, video_id)\n\n        quality = qualities(['SD', 'MQ', 'HQ', 'HD'])\n\n        audio_table = {'flv': 'mp3', 'webm': 'ogg', '???': 'mp3'}\n\n        embedpage = self._download_json('http://www.wrzuta.pl/npp/embed/%s/%s' % (uploader, video_id), video_id)\n\n        formats = []\n        for media in embedpage['url']:\n            fmt = media['type'].split('@')[0]\n            if typ == 'audio':\n                ext = audio_table.get(fmt, fmt)\n            else:\n                ext = fmt\n\n            formats.append({\n                'format_id': '%s_%s' % (ext, media['quality'].lower()),\n                'url': media['url'],\n                'ext': ext,\n                'quality': quality(media['quality']),\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'duration': int_or_none(embedpage['duration']),\n            'uploader_id': uploader,\n            'description': self._og_search_description(webpage),\n            'age_limit': embedpage.get('minimalAge', 0),\n        }",
        "begin_line": 42,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.hentaistigma.HentaiStigmaIE._real_extract#19",
        "src_path": "youtube_dl/extractor/hentaistigma.py",
        "class_name": "youtube_dl.extractor.hentaistigma.HentaiStigmaIE",
        "signature": "youtube_dl.extractor.hentaistigma.HentaiStigmaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h2[^>]+class=\"posttitle\"[^>]*><a[^>]*>([^<]+)</a>',\n            webpage, 'title')\n        wrap_url = self._html_search_regex(\n            r'<iframe[^>]+src=\"([^\"]+mp4)\"', webpage, 'wrapper url')\n        wrap_webpage = self._download_webpage(wrap_url, video_id)\n\n        video_url = self._html_search_regex(\n            r'file\\s*:\\s*\"([^\"]+)\"', wrap_webpage, 'video url')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'age_limit': 18,\n        }",
        "begin_line": 19,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.eitb.EitbIE._real_extract#32",
        "src_path": "youtube_dl/extractor/eitb.py",
        "class_name": "youtube_dl.extractor.eitb.EitbIE",
        "signature": "youtube_dl.extractor.eitb.EitbIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://mam.eitb.eus/mam/REST/ServiceMultiweb/Video/MULTIWEBTV/%s/' % video_id,\n            video_id, 'Downloading video JSON')\n\n        media = video['web_media'][0]\n\n        formats = []\n        for rendition in media['RENDITIONS']:\n            video_url = rendition.get('PMD_URL')\n            if not video_url:\n                continue\n            tbr = float_or_none(rendition.get('ENCODING_RATE'), 1000)\n            format_id = 'http'\n            if tbr:\n                format_id += '-%d' % int(tbr)\n            formats.append({\n                'url': rendition['PMD_URL'],\n                'format_id': format_id,\n                'width': int_or_none(rendition.get('FRAME_WIDTH')),\n                'height': int_or_none(rendition.get('FRAME_HEIGHT')),\n                'tbr': tbr,\n            })\n\n        hls_url = media.get('HLS_SURL')\n        if hls_url:\n            request = compat_urllib_request.Request(\n                'http://mam.eitb.eus/mam/REST/ServiceMultiweb/DomainRestrictedSecurity/TokenAuth/',\n                headers={'Referer': url})\n            token_data = self._download_json(\n                request, video_id, 'Downloading auth token', fatal=False)\n            if token_data:\n                token = token_data.get('token')\n                if token:\n                    m3u8_formats = self._extract_m3u8_formats(\n                        '%s?hdnts=%s' % (hls_url, token), video_id, m3u8_id='hls', fatal=False)\n                    if m3u8_formats:\n                        formats.extend(m3u8_formats)\n\n        hds_url = media.get('HDS_SURL')\n        if hds_url:\n            f4m_formats = self._extract_f4m_formats(\n                '%s?hdcore=3.7.0' % hds_url.replace('euskalsvod', 'euskalvod'),\n                video_id, f4m_id='hds', fatal=False)\n            if f4m_formats:\n                formats.extend(f4m_formats)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': media.get('NAME_ES') or media.get('name') or media['NAME_EU'],\n            'description': media.get('SHORT_DESC_ES') or video.get('desc_group') or media.get('SHORT_DESC_EU'),\n            'thumbnail': media.get('STILL_URL') or media.get('THUMBNAIL_URL'),\n            'duration': float_or_none(media.get('LENGTH'), 1000),\n            'timestamp': parse_iso8601(media.get('BROADCST_DATE'), ' '),\n            'tags': media.get('TAGS'),\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.fivetv.FiveTVIE._real_extract#66",
        "src_path": "youtube_dl/extractor/fivetv.py",
        "class_name": "youtube_dl.extractor.fivetv.FiveTVIE",
        "signature": "youtube_dl.extractor.fivetv.FiveTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id') or mobj.group('path')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(\n            r'<a[^>]+?href=\"([^\"]+)\"[^>]+?class=\"videoplayer\"',\n            webpage, 'video url')\n\n        title = self._og_search_title(webpage, default=None) or self._search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title')\n        duration = int_or_none(self._og_search_property(\n            'video:duration', webpage, 'duration', default=None))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': self._og_search_description(webpage, default=None),\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'duration': duration,\n        }",
        "begin_line": 66,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.engadget.EngadgetIE._real_extract#28",
        "src_path": "youtube_dl/extractor/engadget.py",
        "class_name": "youtube_dl.extractor.engadget.EngadgetIE",
        "signature": "youtube_dl.extractor.engadget.EngadgetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        if video_id is not None:\n            return self.url_result('5min:%s' % video_id)\n        else:\n            title = url_basename(url)\n            webpage = self._download_webpage(url, title)\n            ids = re.findall(r'<iframe[^>]+?playList=(\\d+)', webpage)\n            return {\n                '_type': 'playlist',\n                'title': title,\n                'entries': [self.url_result('5min:%s' % vid) for vid in ids]\n            }",
        "begin_line": 28,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.camdemy.CamdemyIE._real_extract#64",
        "src_path": "youtube_dl/extractor/camdemy.py",
        "class_name": "youtube_dl.extractor.camdemy.CamdemyIE",
        "signature": "youtube_dl.extractor.camdemy.CamdemyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        page = self._download_webpage(url, video_id)\n\n        src_from = self._html_search_regex(\n            r\"<div class='srcFrom'>Source: <a title='([^']+)'\", page,\n            'external source', default=None)\n        if src_from:\n            return self.url_result(src_from)\n\n        oembed_obj = self._download_json(\n            'http://www.camdemy.com/oembed/?format=json&url=' + url, video_id)\n\n        thumb_url = oembed_obj['thumbnail_url']\n        video_folder = compat_urlparse.urljoin(thumb_url, 'video/')\n        file_list_doc = self._download_xml(\n            compat_urlparse.urljoin(video_folder, 'fileList.xml'),\n            video_id, 'Filelist XML')\n        file_name = file_list_doc.find('./video/item/fileName').text\n        video_url = compat_urlparse.urljoin(video_folder, file_name)\n\n        timestamp = parse_iso8601(self._html_search_regex(\n            r\"<div class='title'>Posted\\s*:</div>\\s*<div class='value'>([^<>]+)<\",\n            page, 'creation time', fatal=False),\n            delimiter=' ', timezone=datetime.timedelta(hours=8))\n        view_count = str_to_int(self._html_search_regex(\n            r\"<div class='title'>Views\\s*:</div>\\s*<div class='value'>([^<>]+)<\",\n            page, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': oembed_obj['title'],\n            'thumbnail': thumb_url,\n            'description': self._html_search_meta('description', page),\n            'creator': oembed_obj['author_name'],\n            'duration': oembed_obj['duration'],\n            'timestamp': timestamp,\n            'view_count': view_count,\n        }",
        "begin_line": 64,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.camdemy.CamdemyFolderIE._real_extract#135",
        "src_path": "youtube_dl/extractor/camdemy.py",
        "class_name": "youtube_dl.extractor.camdemy.CamdemyFolderIE",
        "signature": "youtube_dl.extractor.camdemy.CamdemyFolderIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        folder_id = self._match_id(url)\n\n        # Add displayMode=list so that all links are displayed in a single page\n        parsed_url = list(compat_urlparse.urlparse(url))\n        query = dict(compat_urlparse.parse_qsl(parsed_url[4]))\n        query.update({'displayMode': 'list'})\n        parsed_url[4] = compat_urllib_parse.urlencode(query)\n        final_url = compat_urlparse.urlunparse(parsed_url)\n\n        page = self._download_webpage(final_url, folder_id)\n        matches = re.findall(r\"href='(/media/\\d+/?)'\", page)\n\n        entries = [self.url_result('http://www.camdemy.com' + media_path)\n                   for media_path in matches]\n\n        folder_title = self._html_search_meta('keywords', page)\n\n        return self.playlist_result(entries, folder_id, folder_title)",
        "begin_line": 135,
        "end_line": 153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.http.HttpFD.real_download#22",
        "src_path": "youtube_dl/downloader/http.py",
        "class_name": "youtube_dl.downloader.http.HttpFD",
        "signature": "youtube_dl.downloader.http.HttpFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        tmpfilename = self.temp_name(filename)\n        stream = None\n\n        # Do not include the Accept-Encoding header\n        headers = {'Youtubedl-no-compression': 'True'}\n        add_headers = info_dict.get('http_headers')\n        if add_headers:\n            headers.update(add_headers)\n        basic_request = compat_urllib_request.Request(url, None, headers)\n        request = compat_urllib_request.Request(url, None, headers)\n\n        is_test = self.params.get('test', False)\n\n        if is_test:\n            request.add_header('Range', 'bytes=0-%s' % str(self._TEST_FILE_SIZE - 1))\n\n        # Establish possible resume length\n        if os.path.isfile(encodeFilename(tmpfilename)):\n            resume_len = os.path.getsize(encodeFilename(tmpfilename))\n        else:\n            resume_len = 0\n\n        open_mode = 'wb'\n        if resume_len != 0:\n            if self.params.get('continuedl', True):\n                self.report_resuming_byte(resume_len)\n                request.add_header('Range', 'bytes=%d-' % resume_len)\n                open_mode = 'ab'\n            else:\n                resume_len = 0\n\n        count = 0\n        retries = self.params.get('retries', 0)\n        while count <= retries:\n            # Establish connection\n            try:\n                data = self.ydl.urlopen(request)\n                # When trying to resume, Content-Range HTTP header of response has to be checked\n                # to match the value of requested Range HTTP header. This is due to a webservers\n                # that don't support resuming and serve a whole file with no Content-Range\n                # set in response despite of requested Range (see\n                # https://github.com/rg3/youtube-dl/issues/6057#issuecomment-126129799)\n                if resume_len > 0:\n                    content_range = data.headers.get('Content-Range')\n                    if content_range:\n                        content_range_m = re.search(r'bytes (\\d+)-', content_range)\n                        # Content-Range is present and matches requested Range, resume is possible\n                        if content_range_m and resume_len == int(content_range_m.group(1)):\n                            break\n                    # Content-Range is either not present or invalid. Assuming remote webserver is\n                    # trying to send the whole file, resume is not possible, so wiping the local file\n                    # and performing entire redownload\n                    self.report_unable_to_resume()\n                    resume_len = 0\n                    open_mode = 'wb'\n                break\n            except (compat_urllib_error.HTTPError, ) as err:\n                if (err.code < 500 or err.code >= 600) and err.code != 416:\n                    # Unexpected HTTP error\n                    raise\n                elif err.code == 416:\n                    # Unable to resume (requested range not satisfiable)\n                    try:\n                        # Open the connection again without the range header\n                        data = self.ydl.urlopen(basic_request)\n                        content_length = data.info()['Content-Length']\n                    except (compat_urllib_error.HTTPError, ) as err:\n                        if err.code < 500 or err.code >= 600:\n                            raise\n                    else:\n                        # Examine the reported length\n                        if (content_length is not None and\n                                (resume_len - 100 < int(content_length) < resume_len + 100)):\n                            # The file had already been fully downloaded.\n                            # Explanation to the above condition: in issue #175 it was revealed that\n                            # YouTube sometimes adds or removes a few bytes from the end of the file,\n                            # changing the file size slightly and causing problems for some users. So\n                            # I decided to implement a suggested change and consider the file\n                            # completely downloaded if the file size differs less than 100 bytes from\n                            # the one in the hard drive.\n                            self.report_file_already_downloaded(filename)\n                            self.try_rename(tmpfilename, filename)\n                            self._hook_progress({\n                                'filename': filename,\n                                'status': 'finished',\n                                'downloaded_bytes': resume_len,\n                                'total_bytes': resume_len,\n                            })\n                            return True\n                        else:\n                            # The length does not match, we start the download over\n                            self.report_unable_to_resume()\n                            resume_len = 0\n                            open_mode = 'wb'\n                            break\n            except socket.error as e:\n                if e.errno != errno.ECONNRESET:\n                    # Connection reset is no problem, just retry\n                    raise\n\n            # Retry\n            count += 1\n            if count <= retries:\n                self.report_retry(count, retries)\n\n        if count > retries:\n            self.report_error('giving up after %s retries' % retries)\n            return False\n\n        data_len = data.info().get('Content-length', None)\n\n        # Range HTTP header may be ignored/unsupported by a webserver\n        # (e.g. extractor/scivee.py, extractor/bambuser.py).\n        # However, for a test we still would like to download just a piece of a file.\n        # To achieve this we limit data_len to _TEST_FILE_SIZE and manually control\n        # block size when downloading a file.\n        if is_test and (data_len is None or int(data_len) > self._TEST_FILE_SIZE):\n            data_len = self._TEST_FILE_SIZE\n\n        if data_len is not None:\n            data_len = int(data_len) + resume_len\n            min_data_len = self.params.get(\"min_filesize\", None)\n            max_data_len = self.params.get(\"max_filesize\", None)\n            if min_data_len is not None and data_len < min_data_len:\n                self.to_screen('\\r[download] File is smaller than min-filesize (%s bytes < %s bytes). Aborting.' % (data_len, min_data_len))\n                return False\n            if max_data_len is not None and data_len > max_data_len:\n                self.to_screen('\\r[download] File is larger than max-filesize (%s bytes > %s bytes). Aborting.' % (data_len, max_data_len))\n                return False\n\n        byte_counter = 0 + resume_len\n        block_size = self.params.get('buffersize', 1024)\n        start = time.time()\n\n        # measure time over whole while-loop, so slow_down() and best_block_size() work together properly\n        now = None  # needed for slow_down() in the first loop run\n        before = start  # start measuring\n        while True:\n\n            # Download and write\n            data_block = data.read(block_size if not is_test else min(block_size, data_len - byte_counter))\n            byte_counter += len(data_block)\n\n            # exit loop when download is finished\n            if len(data_block) == 0:\n                break\n\n            # Open destination file just in time\n            if stream is None:\n                try:\n                    (stream, tmpfilename) = sanitize_open(tmpfilename, open_mode)\n                    assert stream is not None\n                    filename = self.undo_temp_name(tmpfilename)\n                    self.report_destination(filename)\n                except (OSError, IOError) as err:\n                    self.report_error('unable to open for writing: %s' % str(err))\n                    return False\n\n                if self.params.get('xattr_set_filesize', False) and data_len is not None:\n                    try:\n                        import xattr\n                        xattr.setxattr(tmpfilename, 'user.ytdl.filesize', str(data_len))\n                    except(OSError, IOError, ImportError) as err:\n                        self.report_error('unable to set filesize xattr: %s' % str(err))\n\n            try:\n                stream.write(data_block)\n            except (IOError, OSError) as err:\n                self.to_stderr('\\n')\n                self.report_error('unable to write data: %s' % str(err))\n                return False\n\n            # Apply rate limit\n            self.slow_down(start, now, byte_counter - resume_len)\n\n            # end measuring of one loop run\n            now = time.time()\n            after = now\n\n            # Adjust block size\n            if not self.params.get('noresizebuffer', False):\n                block_size = self.best_block_size(after - before, len(data_block))\n\n            before = after\n\n            # Progress message\n            speed = self.calc_speed(start, now, byte_counter - resume_len)\n            if data_len is None:\n                eta = None\n            else:\n                eta = self.calc_eta(start, time.time(), data_len - resume_len, byte_counter - resume_len)\n\n            self._hook_progress({\n                'status': 'downloading',\n                'downloaded_bytes': byte_counter,\n                'total_bytes': data_len,\n                'tmpfilename': tmpfilename,\n                'filename': filename,\n                'eta': eta,\n                'speed': speed,\n                'elapsed': now - start,\n            })\n\n            if is_test and byte_counter == data_len:\n                break\n\n        if stream is None:\n            self.to_stderr('\\n')\n            self.report_error('Did not get any data blocks')\n            return False\n        if tmpfilename != '-':\n            stream.close()\n\n        if data_len is not None and byte_counter != data_len:\n            raise ContentTooShortError(byte_counter, int(data_len))\n        self.try_rename(tmpfilename, filename)\n\n        # Update file modification time\n        if self.params.get('updatetime', True):\n            info_dict['filetime'] = self.try_utime(filename, data.info().get('last-modified', None))\n\n        self._hook_progress({\n            'downloaded_bytes': byte_counter,\n            'total_bytes': byte_counter,\n            'filename': filename,\n            'status': 'finished',\n            'elapsed': time.time() - start,\n        })\n\n        return True",
        "begin_line": 22,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.podomatic.PodomaticIE._real_extract#41",
        "src_path": "youtube_dl/extractor/podomatic.py",
        "class_name": "youtube_dl.extractor.podomatic.PodomaticIE",
        "signature": "youtube_dl.extractor.podomatic.PodomaticIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        channel = mobj.group('channel')\n\n        json_url = (('%s://%s.podomatic.com/entry/embed_params/%s' +\n                     '?permalink=true&rtmp=0') %\n                    (mobj.group('proto'), channel, video_id))\n        data_json = self._download_webpage(\n            json_url, video_id, 'Downloading video info')\n        data = json.loads(data_json)\n\n        video_url = data['downloadLink']\n        if not video_url:\n            video_url = '%s/%s' % (data['streamer'].replace('rtmp', 'http'), data['mediaLocation'])\n        uploader = data['podcast']\n        title = data['title']\n        thumbnail = data['imageLocation']\n        duration = int_or_none(data.get('length'), 1000)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'uploader': uploader,\n            'uploader_id': channel,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 41,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rds.RDSIE._real_extract#35",
        "src_path": "youtube_dl/extractor/rds.py",
        "class_name": "youtube_dl.extractor.rds.RDSIE",
        "signature": "youtube_dl.extractor.rds.RDSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        # TODO: extract f4m from 9c9media.com\n        video_url = self._search_regex(\n            r'<span[^>]+itemprop=\"contentURL\"[^>]+content=\"([^\"]+)\"',\n            webpage, 'video url')\n\n        title = self._og_search_title(webpage) or self._html_search_meta(\n            'title', webpage, 'title', fatal=True)\n        description = self._og_search_description(webpage) or self._html_search_meta(\n            'description', webpage, 'description')\n        thumbnail = self._og_search_thumbnail(webpage) or self._search_regex(\n            [r'<link[^>]+itemprop=\"thumbnailUrl\"[^>]+href=\"([^\"]+)\"',\n             r'<span[^>]+itemprop=\"thumbnailUrl\"[^>]+content=\"([^\"]+)\"'],\n            webpage, 'thumbnail', fatal=False)\n        timestamp = parse_iso8601(self._search_regex(\n            r'<span[^>]+itemprop=\"uploadDate\"[^>]+content=\"([^\"]+)\"',\n            webpage, 'upload date', fatal=False))\n        duration = parse_duration(self._search_regex(\n            r'<span[^>]+itemprop=\"duration\"[^>]+content=\"([^\"]+)\"',\n            webpage, 'duration', fatal=False))\n        age_limit = self._family_friendly_search(webpage)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'age_limit': age_limit,\n        }",
        "begin_line": 35,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.infoq.InfoQIE._real_extract#29",
        "src_path": "youtube_dl/extractor/infoq.py",
        "class_name": "youtube_dl.extractor.infoq.InfoQIE",
        "signature": "youtube_dl.extractor.infoq.InfoQIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._html_search_regex(r'<title>(.*?)</title>', webpage, 'title')\n        video_description = self._html_search_meta('description', webpage, 'description')\n\n        # The server URL is hardcoded\n        video_url = 'rtmpe://video.infoq.com/cfx/st/'\n\n        # Extract video URL\n        encoded_id = self._search_regex(\n            r\"jsclassref\\s*=\\s*'([^']*)'\", webpage, 'encoded id')\n        real_id = compat_urllib_parse_unquote(base64.b64decode(encoded_id.encode('ascii')).decode('utf-8'))\n        playpath = 'mp4:' + real_id\n\n        video_filename = playpath.split('/')[-1]\n        video_id, extension = video_filename.split('.')\n\n        http_base = self._search_regex(\n            r'EXPRESSINSTALL_SWF\\s*=\\s*[^\"]*\"((?:https?:)?//[^/\"]+/)', webpage,\n            'HTTP base URL')\n\n        formats = [{\n            'format_id': 'rtmp',\n            'url': video_url,\n            'ext': extension,\n            'play_path': playpath,\n        }, {\n            'format_id': 'http',\n            'url': compat_urlparse.urljoin(url, http_base) + real_id,\n        }]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': video_description,\n            'formats': formats,\n        }",
        "begin_line": 29,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtve._decrypt_url#19",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve",
        "signature": "youtube_dl.extractor.rtve._decrypt_url(png)",
        "snippet": "def _decrypt_url(png):\n    encrypted_data = base64.b64decode(png.encode('utf-8'))\n    text_index = encrypted_data.find(b'tEXt')\n    text_chunk = encrypted_data[text_index - 4:]\n    length = struct_unpack('!I', text_chunk[:4])[0]\n    # Use bytearray to get integers when iterating in both python 2.x and 3.x\n    data = bytearray(text_chunk[8:8 + length])\n    data = [chr(b) for b in data if b != 0]\n    hash_index = data.index('#')\n    alphabet_data = data[:hash_index]\n    url_data = data[hash_index + 1:]\n\n    alphabet = []\n    e = 0\n    d = 0\n    for l in alphabet_data:\n        if d == 0:\n            alphabet.append(l)\n            d = e = (e + 1) % 4\n        else:\n            d -= 1\n    url = ''\n    f = 0\n    e = 3\n    b = 1\n    for letter in url_data:\n        if f == 0:\n            l = int(letter) * 10\n            f = 1\n        else:\n            if e == 0:\n                l += int(letter)\n                url += alphabet[l]\n                e = (b + 3) % 4\n                f = 0\n                b += 1\n            else:\n                e -= 1\n\n    return url",
        "begin_line": 19,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVEALaCartaIE._real_initialize#89",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVEALaCartaIE",
        "signature": "youtube_dl.extractor.rtve.RTVEALaCartaIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        user_agent_b64 = base64.b64encode(std_headers['User-Agent'].encode('utf-8')).decode('utf-8')\n        manager_info = self._download_json(\n            'http://www.rtve.es/odin/loki/' + user_agent_b64,\n            None, 'Fetching manager info')\n        self._manager = manager_info['manager']",
        "begin_line": 89,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVEALaCartaIE._real_extract#96",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVEALaCartaIE",
        "signature": "youtube_dl.extractor.rtve.RTVEALaCartaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        info = self._download_json(\n            'http://www.rtve.es/api/videos/%s/config/alacarta_videos.json' % video_id,\n            video_id)['page']['items'][0]\n        if info['state'] == 'DESPU':\n            raise ExtractorError('The video is no longer available', expected=True)\n        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/%s/videos/%s.png' % (self._manager, video_id)\n        png_request = compat_urllib_request.Request(png_url)\n        png_request.add_header('Referer', url)\n        png = self._download_webpage(png_request, video_id, 'Downloading url information')\n        video_url = _decrypt_url(png)\n        if not video_url.endswith('.f4m'):\n            auth_url = video_url.replace(\n                'resources/', 'auth/resources/'\n            ).replace('.net.rtve', '.multimedia.cdn.rtve')\n            video_path = self._download_webpage(\n                auth_url, video_id, 'Getting video url')\n            # Use mvod1.akcdn instead of flash.akamaihd.multimedia.cdn to get\n            # the right Content-Length header and the mp4 format\n            video_url = compat_urlparse.urljoin(\n                'http://mvod1.akcdn.rtve.es/', video_path)\n\n        subtitles = None\n        if info.get('sbtFile') is not None:\n            subtitles = self.extract_subtitles(video_id, info['sbtFile'])\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'url': video_url,\n            'thumbnail': info.get('image'),\n            'page_url': url,\n            'subtitles': subtitles,\n            'duration': float_or_none(info.get('duration'), scale=1000),\n        }",
        "begin_line": 96,
        "end_line": 132,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVEALaCartaIE._get_subtitles#134",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVEALaCartaIE",
        "signature": "youtube_dl.extractor.rtve.RTVEALaCartaIE._get_subtitles(self, video_id, sub_file)",
        "snippet": "    def _get_subtitles(self, video_id, sub_file):\n        subs = self._download_json(\n            sub_file + '.json', video_id,\n            'Downloading subtitles info')['page']['items']\n        return dict(\n            (s['lang'], [{'ext': 'vtt', 'url': s['src']}])\n            for s in subs)",
        "begin_line": 134,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVEInfantilIE._real_extract#160",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVEInfantilIE",
        "signature": "youtube_dl.extractor.rtve.RTVEInfantilIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        info = self._download_json(\n            'http://www.rtve.es/api/videos/%s/config/alacarta_videos.json' % video_id,\n            video_id)['page']['items'][0]\n\n        webpage = self._download_webpage(url, video_id)\n        vidplayer_id = self._search_regex(\n            r' id=\"vidplayer([0-9]+)\"', webpage, 'internal video ID')\n\n        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/default/videos/%s.png' % vidplayer_id\n        png = self._download_webpage(png_url, video_id, 'Downloading url information')\n        video_url = _decrypt_url(png)\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'title': info['title'],\n            'url': video_url,\n            'thumbnail': info.get('image'),\n            'duration': float_or_none(info.get('duration'), scale=1000),\n        }",
        "begin_line": 160,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVELiveIE._real_extract#201",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVELiveIE",
        "signature": "youtube_dl.extractor.rtve.RTVELiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        start_time = time.gmtime()\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        player_url = self._search_regex(\n            r'<param name=\"movie\" value=\"([^\"]+)\"/>', webpage, 'player URL')\n        title = remove_end(self._og_search_title(webpage), ' en directo')\n        title += ' ' + time.strftime('%Y-%m-%dZ%H%M%S', start_time)\n\n        vidplayer_id = self._search_regex(\n            r' id=\"vidplayer([0-9]+)\"', webpage, 'internal video ID')\n        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/default/videos/%s.png' % vidplayer_id\n        png = self._download_webpage(png_url, video_id, 'Downloading url information')\n        video_url = _decrypt_url(png)\n\n        return {\n            'id': video_id,\n            'ext': 'flv',\n            'title': title,\n            'url': video_url,\n            'app': 'rtve-live-live?ovpfv=2.1.2',\n            'player_url': player_url,\n            'rtmp_live': True,\n        }",
        "begin_line": 201,
        "end_line": 226,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.orf.ORFTVthekIE._real_extract#56",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFTVthekIE",
        "signature": "youtube_dl.extractor.orf.ORFTVthekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n\n        data_json = self._search_regex(\n            r'initializeAdworx\\((.+?)\\);\\n', webpage, 'video info')\n        all_data = json.loads(data_json)\n\n        def get_segments(all_data):\n            for data in all_data:\n                if data['name'] in (\n                        'Tracker::EPISODE_DETAIL_PAGE_OVER_PROGRAM',\n                        'Tracker::EPISODE_DETAIL_PAGE_OVER_TOPIC'):\n                    return data['values']['segments']\n\n        sdata = get_segments(all_data)\n        if not sdata:\n            raise ExtractorError('Unable to extract segments')\n\n        def quality_to_int(s):\n            m = re.search('([0-9]+)', s)\n            if m is None:\n                return -1\n            return int(m.group(1))\n\n        entries = []\n        for sd in sdata:\n            video_id = sd['id']\n            formats = [{\n                'preference': -10 if fd['delivery'] == 'hls' else None,\n                'format_id': '%s-%s-%s' % (\n                    fd['delivery'], fd['quality'], fd['quality_string']),\n                'url': fd['src'],\n                'protocol': fd['protocol'],\n                'quality': quality_to_int(fd['quality']),\n            } for fd in sd['playlist_item_array']['sources']]\n\n            # Check for geoblocking.\n            # There is a property is_geoprotection, but that's always false\n            geo_str = sd.get('geoprotection_string')\n            if geo_str:\n                try:\n                    http_url = next(\n                        f['url']\n                        for f in formats\n                        if re.match(r'^https?://.*\\.mp4$', f['url']))\n                except StopIteration:\n                    pass\n                else:\n                    req = HEADRequest(http_url)\n                    self._request_webpage(\n                        req, video_id,\n                        note='Testing for geoblocking',\n                        errnote=((\n                            'This video seems to be blocked outside of %s. '\n                            'You may want to try the streaming-* formats.')\n                            % geo_str),\n                        fatal=False)\n\n            self._sort_formats(formats)\n\n            upload_date = unified_strdate(sd['created_date'])\n            entries.append({\n                '_type': 'video',\n                'id': video_id,\n                'title': sd['header'],\n                'formats': formats,\n                'description': sd.get('description'),\n                'duration': int(sd['duration_in_seconds']),\n                'upload_date': upload_date,\n                'thumbnail': sd.get('image_full_url'),\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': playlist_id,\n        }",
        "begin_line": 56,
        "end_line": 133,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.orf.ORFOE1IE._real_extract#147",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFOE1IE",
        "signature": "youtube_dl.extractor.orf.ORFOE1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_id = self._match_id(url)\n        data = self._download_json(\n            'http://oe1.orf.at/programm/%s/konsole' % show_id,\n            show_id\n        )\n\n        timestamp = datetime.datetime.strptime('%s %s' % (\n            data['item']['day_label'],\n            data['item']['time']\n        ), '%d.%m.%Y %H:%M')\n        unix_timestamp = calendar.timegm(timestamp.utctimetuple())\n\n        return {\n            'id': show_id,\n            'title': data['item']['title'],\n            'url': data['item']['url_stream'],\n            'ext': 'mp3',\n            'description': data['item'].get('info'),\n            'timestamp': unix_timestamp\n        }",
        "begin_line": 147,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.orf.ORFFM4IE._real_extract#175",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFFM4IE",
        "signature": "youtube_dl.extractor.orf.ORFFM4IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        show_date = mobj.group('date')\n        show_id = mobj.group('show')\n\n        data = self._download_json(\n            'http://audioapi.orf.at/fm4/json/2.0/broadcasts/%s/4%s' % (show_date, show_id),\n            show_id\n        )\n\n        def extract_entry_dict(info, title, subtitle):\n            return {\n                'id': info['loopStreamId'].replace('.mp3', ''),\n                'url': 'http://loopstream01.apa.at/?channel=fm4&id=%s' % info['loopStreamId'],\n                'title': title,\n                'description': subtitle,\n                'duration': (info['end'] - info['start']) / 1000,\n                'timestamp': info['start'] / 1000,\n                'ext': 'mp3'\n            }\n\n        entries = [extract_entry_dict(t, data['title'], data['subtitle']) for t in data['streams']]\n\n        return {\n            '_type': 'playlist',\n            'id': show_id,\n            'title': data['title'],\n            'description': data['subtitle'],\n            'entries': entries\n        }",
        "begin_line": 175,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.orf.ORFIPTVIE._real_extract#226",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFIPTVIE",
        "signature": "youtube_dl.extractor.orf.ORFIPTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        story_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://iptv.orf.at/stories/%s' % story_id, story_id)\n\n        video_id = self._search_regex(\n            r'data-video(?:id)?=\"(\\d+)\"', webpage, 'video id')\n\n        data = self._download_json(\n            'http://bits.orf.at/filehandler/static-api/json/current/data.json?file=%s' % video_id,\n            video_id)[0]\n\n        duration = float_or_none(data['duration'], 1000)\n\n        video = data['sources']['default']\n        load_balancer_url = video['loadBalancerUrl']\n        abr = int_or_none(video.get('audioBitrate'))\n        vbr = int_or_none(video.get('bitrate'))\n        fps = int_or_none(video.get('videoFps'))\n        width = int_or_none(video.get('videoWidth'))\n        height = int_or_none(video.get('videoHeight'))\n        thumbnail = video.get('preview')\n\n        rendition = self._download_json(\n            load_balancer_url, video_id, transform_source=strip_jsonp)\n\n        f = {\n            'abr': abr,\n            'vbr': vbr,\n            'fps': fps,\n            'width': width,\n            'height': height,\n        }\n\n        formats = []\n        for format_id, format_url in rendition['redirect'].items():\n            if format_id == 'rtmp':\n                ff = f.copy()\n                ff.update({\n                    'url': format_url,\n                    'format_id': format_id,\n                })\n                formats.append(ff)\n            elif determine_ext(format_url) == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    format_url, video_id, f4m_id=format_id))\n            elif determine_ext(format_url) == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', m3u8_id=format_id))\n            else:\n                continue\n        self._sort_formats(formats)\n\n        title = remove_end(self._og_search_title(webpage), ' - iptv.ORF.at')\n        description = self._og_search_description(webpage)\n        upload_date = unified_strdate(self._html_search_meta(\n            'dc.date', webpage, 'upload date'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 226,
        "end_line": 293,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKIE._real_extract#44",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKIE",
        "signature": "youtube_dl.extractor.nrk.NRKIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data = self._download_json(\n            'http://v8.psapi.nrk.no/mediaelement/%s' % video_id,\n            video_id, 'Downloading media JSON')\n\n        if data['usageRights']['isGeoBlocked']:\n            raise ExtractorError(\n                'NRK har ikke rettigheter til \u00e5 vise dette programmet utenfor Norge',\n                expected=True)\n\n        video_url = data['mediaUrl'] + '?hdcore=3.5.0&plugin=aasp-3.5.0.151.81'\n\n        duration = parse_duration(data.get('duration'))\n\n        images = data.get('images')\n        if images:\n            thumbnails = images['webImages']\n            thumbnails.sort(key=lambda image: image['pixelWidth'])\n            thumbnail = thumbnails[-1]['imageUrl']\n        else:\n            thumbnail = None\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'flv',\n            'title': data['title'],\n            'description': data['description'],\n            'duration': duration,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 44,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKPlaylistIE._real_extract#100",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKPlaylistIE",
        "signature": "youtube_dl.extractor.nrk.NRKPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = [\n            self.url_result('nrk:%s' % video_id, 'NRK')\n            for video_id in re.findall(\n                r'class=\"[^\"]*\\brich\\b[^\"]*\"[^>]+data-video-id=\"([^\"]+)\"',\n                webpage)\n        ]\n\n        playlist_title = self._og_search_title(webpage)\n        playlist_description = self._og_search_description(webpage)\n\n        return self.playlist_result(\n            entries, playlist_id, playlist_title, playlist_description)",
        "begin_line": 100,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKTVIE._extract_f4m#200",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKTVIE",
        "signature": "youtube_dl.extractor.nrk.NRKTVIE._extract_f4m(self, manifest_url, video_id)",
        "snippet": "    def _extract_f4m(self, manifest_url, video_id):\n        return self._extract_f4m_formats(\n            manifest_url + '?hdcore=3.1.1&plugin=aasp-3.1.1.69.124', video_id, f4m_id='hds')",
        "begin_line": 200,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKTVIE._real_extract#204",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKTVIE",
        "signature": "youtube_dl.extractor.nrk.NRKTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        part_id = mobj.group('part_id')\n        base_url = mobj.group('baseurl')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta(\n            'title', webpage, 'title')\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n\n        thumbnail = self._html_search_regex(\n            r'data-posterimage=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n        upload_date = unified_strdate(self._html_search_meta(\n            'rightsfrom', webpage, 'upload date', fatal=False))\n        duration = float_or_none(self._html_search_regex(\n            r'data-duration=\"([^\"]+)\"',\n            webpage, 'duration', fatal=False))\n\n        # playlist\n        parts = re.findall(\n            r'<a href=\"#del=(\\d+)\"[^>]+data-argument=\"([^\"]+)\">([^<]+)</a>', webpage)\n        if parts:\n            entries = []\n            for current_part_id, stream_url, part_title in parts:\n                if part_id and current_part_id != part_id:\n                    continue\n                video_part_id = '%s-part%s' % (video_id, current_part_id)\n                formats = self._extract_f4m(stream_url, video_part_id)\n                entries.append({\n                    'id': video_part_id,\n                    'title': part_title,\n                    'description': description,\n                    'thumbnail': thumbnail,\n                    'upload_date': upload_date,\n                    'formats': formats,\n                })\n            if part_id:\n                if entries:\n                    return entries[0]\n            else:\n                playlist = self.playlist_result(entries, video_id, title, description)\n                playlist.update({\n                    'thumbnail': thumbnail,\n                    'upload_date': upload_date,\n                    'duration': duration,\n                })\n                return playlist\n\n        formats = []\n\n        f4m_url = re.search(r'data-media=\"([^\"]+)\"', webpage)\n        if f4m_url:\n            formats.extend(self._extract_f4m(f4m_url.group(1), video_id))\n\n        m3u8_url = re.search(r'data-hls-media=\"([^\"]+)\"', webpage)\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(m3u8_url.group(1), video_id, 'mp4', m3u8_id='hls'))\n        self._sort_formats(formats)\n\n        subtitles_url = self._html_search_regex(\n            r'data-subtitlesurl\\s*=\\s*([\"\\'])(?P<url>.+?)\\1',\n            webpage, 'subtitle URL', default=None, group='url')\n        subtitles = {}\n        if subtitles_url:\n            subtitles['no'] = [{\n                'ext': 'ttml',\n                'url': compat_urlparse.urljoin(base_url, subtitles_url),\n            }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 204,
        "end_line": 286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.bpb.BpbIE._real_extract#22",
        "src_path": "youtube_dl/extractor/bpb.py",
        "class_name": "youtube_dl.extractor.bpb.BpbIE",
        "signature": "youtube_dl.extractor.bpb.BpbIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h2 class=\"white\">(.*?)</h2>', webpage, 'title')\n        video_url = self._html_search_regex(\n            r'(http://film\\.bpb\\.de/player/dokument_[0-9]+\\.mp4)',\n            webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 22,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vh1.VH1IE._real_extract#111",
        "src_path": "youtube_dl/extractor/vh1.py",
        "class_name": "youtube_dl.extractor.vh1.VH1IE",
        "signature": "youtube_dl.extractor.vh1.VH1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj.group('music_id'):\n            id_field = 'vid'\n            video_id = mobj.group('music_id')\n        else:\n            video_id = mobj.group('playlist_id') or mobj.group('video_id')\n            id_field = 'id'\n        doc_url = '%s?%s=%s' % (self._FEED_URL, id_field, video_id)\n\n        idoc = self._download_xml(\n            doc_url, video_id,\n            'Downloading info', transform_source=fix_xml_ampersands)\n        return self.playlist_result(\n            [self._get_video_info(item) for item in idoc.findall('.//item')],\n            playlist_id=video_id,\n        )",
        "begin_line": 111,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.faz.FazIE._real_extract#36",
        "src_path": "youtube_dl/extractor/faz.py",
        "class_name": "youtube_dl.extractor.faz.FazIE",
        "signature": "youtube_dl.extractor.faz.FazIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        config_xml_url = self._search_regex(\n            r'writeFLV\\(\\'(.+?)\\',', webpage, 'config xml url')\n        config = self._download_xml(\n            config_xml_url, video_id, 'Downloading config xml')\n\n        encodings = config.find('ENCODINGS')\n        formats = []\n        for pref, code in enumerate(['LOW', 'HIGH', 'HQ']):\n            encoding = encodings.find(code)\n            if encoding is None:\n                continue\n            encoding_url = encoding.find('FILENAME').text\n            formats.append({\n                'url': encoding_url,\n                'format_id': code.lower(),\n                'quality': pref,\n            })\n        self._sort_formats(formats)\n\n        descr = self._html_search_regex(\n            r'<p class=\"Content Copy\">(.*?)</p>', webpage, 'description', fatal=False)\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': descr,\n            'thumbnail': config.find('STILL/STILL_BIG').text,\n        }",
        "begin_line": 36,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.testurl.TestURLIE._real_extract#15",
        "src_path": "youtube_dl/extractor/testurl.py",
        "class_name": "youtube_dl.extractor.testurl.TestURLIE",
        "signature": "youtube_dl.extractor.testurl.TestURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        from ..extractor import gen_extractors\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        extractor_id = mobj.group('extractor')\n        all_extractors = gen_extractors()\n\n        rex = re.compile(extractor_id, flags=re.IGNORECASE)\n        matching_extractors = [\n            e for e in all_extractors if rex.search(e.IE_NAME)]\n\n        if len(matching_extractors) == 0:\n            raise ExtractorError(\n                'No extractors matching %r found' % extractor_id,\n                expected=True)\n        elif len(matching_extractors) > 1:\n            # Is it obvious which one to pick?\n            try:\n                extractor = next(\n                    ie for ie in matching_extractors\n                    if ie.IE_NAME.lower() == extractor_id.lower())\n            except StopIteration:\n                raise ExtractorError(\n                    ('Found multiple matching extractors: %s' %\n                        ' '.join(ie.IE_NAME for ie in matching_extractors)),\n                    expected=True)\n        else:\n            extractor = matching_extractors[0]\n\n        num_str = mobj.group('num')\n        num = int(num_str) if num_str else 0\n\n        testcases = []\n        t = getattr(extractor, '_TEST', None)\n        if t:\n            testcases.append(t)\n        testcases.extend(getattr(extractor, '_TESTS', []))\n\n        try:\n            tc = testcases[num]\n        except IndexError:\n            raise ExtractorError(\n                ('Test case %d not found, got only %d tests' %\n                    (num, len(testcases))),\n                expected=True)\n\n        self.to_screen('Test URL: %s' % tc['url'])\n\n        return {\n            '_type': 'url',\n            'url': tc['url'],\n            'id': video_id,\n        }",
        "begin_line": 15,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.byutv.BYUtvIE._real_extract#26",
        "src_path": "youtube_dl/extractor/byutv.py",
        "class_name": "youtube_dl.extractor.byutv.BYUtvIE",
        "signature": "youtube_dl.extractor.byutv.BYUtvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        webpage = self._download_webpage(url, video_id)\n        episode_code = self._search_regex(\n            r'(?s)episode:(.*?\\}),\\s*\\n', webpage, 'episode information')\n        episode_json = re.sub(\n            r'(\\n\\s+)([a-zA-Z]+):\\s+\\'(.*?)\\'', r'\\1\"\\2\": \"\\3\"', episode_code)\n        ep = json.loads(episode_json)\n\n        if ep['providerType'] == 'Ooyala':\n            return {\n                '_type': 'url_transparent',\n                'ie_key': 'Ooyala',\n                'url': 'ooyala:%s' % ep['providerId'],\n                'id': video_id,\n                'title': ep['title'],\n                'description': ep.get('description'),\n                'thumbnail': ep.get('imageThumbnail'),\n            }\n        else:\n            raise ExtractorError('Unsupported provider %s' % ep['provider'])",
        "begin_line": 26,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._get_consumer_secret#30",
        "src_path": "youtube_dl/extractor/dramafever.py",
        "class_name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE",
        "signature": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._get_consumer_secret(self)",
        "snippet": "    def _get_consumer_secret(self):\n        mainjs = self._download_webpage(\n            'http://www.dramafever.com/static/51afe95/df2014/scripts/main.js',\n            None, 'Downloading main.js', fatal=False)\n        if not mainjs:\n            return self._CONSUMER_SECRET\n        return self._search_regex(\n            r\"var\\s+cs\\s*=\\s*'([^']+)'\", mainjs,\n            'consumer secret', default=self._CONSUMER_SECRET)",
        "begin_line": 30,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._real_initialize#40",
        "src_path": "youtube_dl/extractor/dramafever.py",
        "class_name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE",
        "signature": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()\n        self._consumer_secret = self._get_consumer_secret()",
        "begin_line": 40,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._login#44",
        "src_path": "youtube_dl/extractor/dramafever.py",
        "class_name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE",
        "signature": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'username': username,\n            'password': password,\n        }\n\n        request = compat_urllib_request.Request(\n            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))\n        response = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        if all(logout_pattern not in response\n               for logout_pattern in ['href=\"/accounts/logout/\"', '>Log out<']):\n            error = self._html_search_regex(\n                r'(?s)class=\"hidden-xs prompt\"[^>]*>(.+?)<',\n                response, 'error message', default=None)\n            if error:\n                raise ExtractorError('Unable to login: %s' % error, expected=True)\n            raise ExtractorError('Unable to log in')",
        "begin_line": 44,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dramafever.DramaFeverIE._real_extract#86",
        "src_path": "youtube_dl/extractor/dramafever.py",
        "class_name": "youtube_dl.extractor.dramafever.DramaFeverIE",
        "signature": "youtube_dl.extractor.dramafever.DramaFeverIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url).replace('/', '.')\n\n        try:\n            feed = self._download_json(\n                'http://www.dramafever.com/amp/episode/feed.json?guid=%s' % video_id,\n                video_id, 'Downloading episode JSON')['channel']['item']\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError):\n                raise ExtractorError(\n                    'Currently unavailable in your country.', expected=True)\n            raise\n\n        media_group = feed.get('media-group', {})\n\n        formats = []\n        for media_content in media_group['media-content']:\n            src = media_content.get('@attributes', {}).get('url')\n            if not src:\n                continue\n            ext = determine_ext(src)\n            if ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    src, video_id, f4m_id='hds'))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    src, video_id, 'mp4', m3u8_id='hls'))\n            else:\n                formats.append({\n                    'url': src,\n                })\n        self._sort_formats(formats)\n\n        title = media_group.get('media-title')\n        description = media_group.get('media-description')\n        duration = int_or_none(media_group['media-content'][0].get('@attributes', {}).get('duration'))\n        thumbnail = self._proto_relative_url(\n            media_group.get('media-thumbnail', {}).get('@attributes', {}).get('url'))\n        timestamp = parse_iso8601(feed.get('pubDate'), ' ')\n\n        subtitles = {}\n        for media_subtitle in media_group.get('media-subTitle', []):\n            lang = media_subtitle.get('@attributes', {}).get('lang')\n            href = media_subtitle.get('@attributes', {}).get('href')\n            if not lang or not href:\n                continue\n            subtitles[lang] = [{\n                'ext': 'ttml',\n                'url': href,\n            }]\n\n        series_id, episode_number = video_id.split('.')\n        episode_info = self._download_json(\n            # We only need a single episode info, so restricting page size to one episode\n            # and dealing with page number as with episode number\n            r'http://www.dramafever.com/api/4/episode/series/?cs=%s&series_id=%s&page_number=%s&page_size=1'\n            % (self._consumer_secret, series_id, episode_number),\n            video_id, 'Downloading episode info JSON', fatal=False)\n        if episode_info:\n            value = episode_info.get('value')\n            if value:\n                subfile = value[0].get('subfile') or value[0].get('new_subfile')\n                if subfile and subfile != 'http://www.dramafever.com/st/':\n                    subtitles.setdefault('English', []).append({\n                        'ext': 'srt',\n                        'url': subfile,\n                    })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 86,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dramafever.DramaFeverSeriesIE._real_extract#189",
        "src_path": "youtube_dl/extractor/dramafever.py",
        "class_name": "youtube_dl.extractor.dramafever.DramaFeverSeriesIE",
        "signature": "youtube_dl.extractor.dramafever.DramaFeverSeriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        series_id = self._match_id(url)\n\n        series = self._download_json(\n            'http://www.dramafever.com/api/4/series/query/?cs=%s&series_id=%s'\n            % (self._consumer_secret, series_id),\n            series_id, 'Downloading series JSON')['series'][series_id]\n\n        title = clean_html(series['name'])\n        description = clean_html(series.get('description') or series.get('description_short'))\n\n        entries = []\n        for page_num in itertools.count(1):\n            episodes = self._download_json(\n                'http://www.dramafever.com/api/4/episode/series/?cs=%s&series_id=%s&page_size=%d&page_number=%d'\n                % (self._consumer_secret, series_id, self._PAGE_SIZE, page_num),\n                series_id, 'Downloading episodes JSON page #%d' % page_num)\n            for episode in episodes.get('value', []):\n                episode_url = episode.get('episode_url')\n                if not episode_url:\n                    continue\n                entries.append(self.url_result(\n                    compat_urlparse.urljoin(url, episode_url),\n                    'DramaFever', episode.get('guid')))\n            if page_num == episodes['num_pages']:\n                break\n\n        return self.playlist_result(entries, series_id, title, description)",
        "begin_line": 189,
        "end_line": 216,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.videopremium.VideoPremiumIE._real_extract#24",
        "src_path": "youtube_dl/extractor/videopremium.py",
        "class_name": "youtube_dl.extractor.videopremium.VideoPremiumIE",
        "signature": "youtube_dl.extractor.videopremium.VideoPremiumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage_url = 'http://videopremium.tv/' + video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        if re.match(r\"^<html><head><script[^>]*>window.location\\s*=\", webpage):\n            # Download again, we need a cookie\n            webpage = self._download_webpage(\n                webpage_url, video_id,\n                note='Downloading webpage again (with cookie)')\n\n        video_title = self._html_search_regex(\n            r'<h2(?:.*?)>\\s*(.+?)\\s*<', webpage, 'video title')\n\n        return {\n            'id': video_id,\n            'url': \"rtmp://e%d.md.iplay.md/play\" % random.randint(1, 16),\n            'play_path': \"mp4:%s.f4v\" % video_id,\n            'page_url': \"http://videopremium.tv/\" + video_id,\n            'player_url': \"http://videopremium.tv/uplayer/uppod.swf\",\n            'ext': 'f4v',\n            'title': video_title,\n        }",
        "begin_line": 24,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.primesharetv.PrimeShareTVIE._real_extract#24",
        "src_path": "youtube_dl/extractor/primesharetv.py",
        "class_name": "youtube_dl.extractor.primesharetv.PrimeShareTVIE",
        "signature": "youtube_dl.extractor.primesharetv.PrimeShareTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        if '>File not exist<' in webpage:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        fields = self._hidden_inputs(webpage)\n\n        headers = {\n            'Referer': url,\n            'Content-Type': 'application/x-www-form-urlencoded',\n        }\n\n        wait_time = int(self._search_regex(\n            r'var\\s+cWaitTime\\s*=\\s*(\\d+)',\n            webpage, 'wait time', default=7)) + 1\n        self._sleep(wait_time, video_id)\n\n        req = compat_urllib_request.Request(\n            url, compat_urllib_parse.urlencode(fields), headers)\n        video_page = self._download_webpage(\n            req, video_id, 'Downloading video page')\n\n        video_url = self._search_regex(\n            r\"url\\s*:\\s*'([^']+\\.primeshare\\.tv(?::443)?/file/[^']+)'\",\n            video_page, 'video url')\n\n        title = self._html_search_regex(\n            r'<h1>Watch\\s*(?:&nbsp;)?\\s*\\((.+?)(?:\\s*\\[\\.\\.\\.\\])?\\)\\s*(?:&nbsp;)?\\s*<strong>',\n            video_page, 'title')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'ext': 'mp4',\n        }",
        "begin_line": 24,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sapo.SapoIE._real_extract#65",
        "src_path": "youtube_dl/extractor/sapo.py",
        "class_name": "youtube_dl.extractor.sapo.SapoIE",
        "signature": "youtube_dl.extractor.sapo.SapoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        item = self._download_xml(\n            'http://rd3.videos.sapo.pt/%s/rss2' % video_id, video_id).find('./channel/item')\n\n        title = item.find('./title').text\n        description = item.find('./{http://videos.sapo.pt/mrss/}synopse').text\n        thumbnail = item.find('./{http://search.yahoo.com/mrss/}content').get('url')\n        duration = parse_duration(item.find('./{http://videos.sapo.pt/mrss/}time').text)\n        uploader = item.find('./{http://videos.sapo.pt/mrss/}author').text\n        upload_date = unified_strdate(item.find('./pubDate').text)\n        view_count = int(item.find('./{http://videos.sapo.pt/mrss/}views').text)\n        comment_count = int(item.find('./{http://videos.sapo.pt/mrss/}comment_count').text)\n        tags = item.find('./{http://videos.sapo.pt/mrss/}tags').text\n        categories = tags.split() if tags else []\n        age_limit = 18 if item.find('./{http://videos.sapo.pt/mrss/}m18').text == 'true' else 0\n\n        video_url = item.find('./{http://videos.sapo.pt/mrss/}videoFile').text\n        video_size = item.find('./{http://videos.sapo.pt/mrss/}videoSize').text.split('x')\n\n        formats = [{\n            'url': video_url,\n            'ext': 'mp4',\n            'format_id': 'sd',\n            'width': int(video_size[0]),\n            'height': int(video_size[1]),\n        }]\n\n        if item.find('./{http://videos.sapo.pt/mrss/}HD').text == 'true':\n            formats.append({\n                'url': re.sub(r'/mov/1$', '/mov/39', video_url),\n                'ext': 'mp4',\n                'format_id': 'hd',\n                'width': 1280,\n                'height': 720,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'categories': categories,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 65,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.wsj.WSJIE._real_extract#29",
        "src_path": "youtube_dl/extractor/wsj.py",
        "class_name": "youtube_dl.extractor.wsj.WSJIE",
        "signature": "youtube_dl.extractor.wsj.WSJIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        bitrates = [128, 174, 264, 320, 464, 664, 1264]\n        api_url = (\n            'http://video-api.wsj.com/api-video/find_all_videos.asp?'\n            'type=guid&count=1&query=%s&'\n            'fields=hls,adZone,thumbnailList,guid,state,secondsUntilStartTime,'\n            'author,description,name,linkURL,videoStillURL,duration,videoURL,'\n            'adCategory,catastrophic,linkShortURL,doctypeID,youtubeID,'\n            'titletag,rssURL,wsj-section,wsj-subsection,allthingsd-section,'\n            'allthingsd-subsection,sm-section,sm-subsection,provider,'\n            'formattedCreationDate,keywords,keywordsOmniture,column,editor,'\n            'emailURL,emailPartnerID,showName,omnitureProgramName,'\n            'omnitureVideoFormat,linkRelativeURL,touchCastID,'\n            'omniturePublishDate,%s') % (\n                video_id, ','.join('video%dkMP4Url' % br for br in bitrates))\n        info = self._download_json(api_url, video_id)['items'][0]\n\n        # Thumbnails are conveniently in the correct format already\n        thumbnails = info.get('thumbnailList')\n        creator = info.get('author')\n        uploader_id = info.get('editor')\n        categories = info.get('keywords')\n        duration = int_or_none(info.get('duration'))\n        upload_date = unified_strdate(\n            info.get('formattedCreationDate'), day_first=False)\n        title = info.get('name', info.get('titletag'))\n\n        formats = [{\n            'format_id': 'f4m',\n            'format_note': 'f4m (meta URL)',\n            'url': info['videoURL'],\n        }]\n        if info.get('hls'):\n            formats.extend(self._extract_m3u8_formats(\n                info['hls'], video_id, ext='mp4',\n                preference=0, entry_protocol='m3u8_native'))\n        for br in bitrates:\n            field = 'video%dkMP4Url' % br\n            if info.get(field):\n                formats.append({\n                    'format_id': 'mp4-%d' % br,\n                    'container': 'mp4',\n                    'tbr': br,\n                    'url': info[field],\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'thumbnails': thumbnails,\n            'creator': creator,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'upload_date': upload_date,\n            'title': title,\n            'formats': formats,\n            'categories': categories,\n        }",
        "begin_line": 29,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.extremetube.ExtremeTubeIE._real_extract#34",
        "src_path": "youtube_dl/extractor/extremetube.py",
        "class_name": "youtube_dl.extractor.extremetube.ExtremeTubeIE",
        "signature": "youtube_dl.extractor.extremetube.ExtremeTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(\n            r'<h1 [^>]*?title=\"([^\"]+)\"[^>]*>', webpage, 'title')\n        uploader = self._html_search_regex(\n            r'Uploaded by:\\s*</strong>\\s*(.+?)\\s*</div>',\n            webpage, 'uploader', fatal=False)\n        view_count = str_to_int(self._html_search_regex(\n            r'Views:\\s*</strong>\\s*<span>([\\d,\\.]+)</span>',\n            webpage, 'view count', fatal=False))\n\n        flash_vars = compat_parse_qs(self._search_regex(\n            r'<param[^>]+?name=\"flashvars\"[^>]+?value=\"([^\"]+)\"', webpage, 'flash vars'))\n\n        formats = []\n        quality = qualities(['180p', '240p', '360p', '480p', '720p', '1080p'])\n        for k, vals in flash_vars.items():\n            m = re.match(r'quality_(?P<quality>[0-9]+p)$', k)\n            if m is not None:\n                formats.append({\n                    'format_id': m.group('quality'),\n                    'quality': quality(m.group('quality')),\n                    'url': vals[0],\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'uploader': uploader,\n            'view_count': view_count,\n            'age_limit': 18,\n        }",
        "begin_line": 34,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.iprima.IPrimaIE._real_extract#49",
        "src_path": "youtube_dl/extractor/iprima.py",
        "class_name": "youtube_dl.extractor.iprima.IPrimaIE",
        "signature": "youtube_dl.extractor.iprima.IPrimaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        if re.search(r'Nem\u00e1te opr\u00e1vn\u011bn\u00ed p\u0159istupovat na tuto str\u00e1nku\\.\\s*</div>', webpage):\n            raise ExtractorError(\n                '%s said: You do not have permission to access this page' % self.IE_NAME, expected=True)\n\n        player_url = (\n            'http://embed.livebox.cz/iprimaplay/player-embed-v2.js?__tok%s__=%s' %\n            (floor(random() * 1073741824), floor(random() * 1073741824))\n        )\n\n        req = compat_urllib_request.Request(player_url)\n        req.add_header('Referer', url)\n        playerpage = self._download_webpage(req, video_id)\n\n        base_url = ''.join(re.findall(r\"embed\\['stream'\\] = '(.+?)'.+'(\\?auth=)'.+'(.+?)';\", playerpage)[1])\n\n        zoneGEO = self._html_search_regex(r'\"zoneGEO\":(.+?),', webpage, 'zoneGEO')\n        if zoneGEO != '0':\n            base_url = base_url.replace('token', 'token_' + zoneGEO)\n\n        formats = []\n        for format_id in ['lq', 'hq', 'hd']:\n            filename = self._html_search_regex(\n                r'\"%s_id\":(.+?),' % format_id, webpage, 'filename')\n\n            if filename == 'null':\n                continue\n\n            real_id = self._search_regex(\n                r'Prima-(?:[0-9]{10}|WEB)-([0-9]+)[-_]',\n                filename, 'real video id')\n\n            if format_id == 'lq':\n                quality = 0\n            elif format_id == 'hq':\n                quality = 1\n            elif format_id == 'hd':\n                quality = 2\n                filename = 'hq/' + filename\n\n            formats.append({\n                'format_id': format_id,\n                'url': base_url,\n                'quality': quality,\n                'play_path': 'mp4:' + filename.replace('\"', '')[:-4],\n                'rtmp_live': True,\n                'ext': 'flv',\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': real_id,\n            'title': remove_end(self._og_search_title(webpage), ' | Prima PLAY'),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'description': self._search_regex(\n                r'<p[^>]+itemprop=\"description\"[^>]*>([^<]+)',\n                webpage, 'description', default=None),\n        }",
        "begin_line": 49,
        "end_line": 113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tumblr.TumblrIE._real_extract#72",
        "src_path": "youtube_dl/extractor/tumblr.py",
        "class_name": "youtube_dl.extractor.tumblr.TumblrIE",
        "signature": "youtube_dl.extractor.tumblr.TumblrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m_url = re.match(self._VALID_URL, url)\n        video_id = m_url.group('id')\n        blog = m_url.group('blog_name')\n\n        url = 'http://%s.tumblr.com/post/%s/' % (blog, video_id)\n        webpage, urlh = self._download_webpage_handle(url, video_id)\n\n        iframe_url = self._search_regex(\n            r'src=\\'(https?://www\\.tumblr\\.com/video/[^\\']+)\\'',\n            webpage, 'iframe url', default=None)\n        if iframe_url is None:\n            return self.url_result(urlh.geturl(), 'Generic')\n\n        iframe = self._download_webpage(iframe_url, video_id, 'Downloading iframe page')\n\n        duration = None\n        sources = []\n\n        sd_url = self._search_regex(\n            r'<source[^>]+src=([\"\\'])(?P<url>.+?)\\1', iframe,\n            'sd video url', default=None, group='url')\n        if sd_url:\n            sources.append((sd_url, 'sd'))\n\n        options = self._parse_json(\n            self._search_regex(\n                r'data-crt-options=([\"\\'])(?P<options>.+?)\\1', iframe,\n                'hd video url', default='', group='options'),\n            video_id, fatal=False)\n        if options:\n            duration = int_or_none(options.get('duration'))\n            hd_url = options.get('hdUrl')\n            if hd_url:\n                sources.append((hd_url, 'hd'))\n\n        formats = [{\n            'url': video_url,\n            'ext': 'mp4',\n            'format_id': format_id,\n            'height': int_or_none(self._search_regex(\n                r'/(\\d{3,4})$', video_url, 'height', default=None)),\n            'quality': quality,\n        } for quality, (video_url, format_id) in enumerate(sources)]\n\n        self._sort_formats(formats)\n\n        # The only place where you can get a title, it's not complete,\n        # but searching in other places doesn't work for all videos\n        video_title = self._html_search_regex(\n            r'(?s)<title>(?P<title>.*?)(?: \\| Tumblr)?</title>',\n            webpage, 'title')\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': self._og_search_description(webpage, default=None),\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 72,
        "end_line": 132,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.dhm.DHMIE._real_extract#33",
        "src_path": "youtube_dl/extractor/dhm.py",
        "class_name": "youtube_dl.extractor.dhm.DHMIE",
        "signature": "youtube_dl.extractor.dhm.DHMIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        playlist_url = self._search_regex(\n            r\"file\\s*:\\s*'([^']+)'\", webpage, 'playlist url')\n\n        entries = self._extract_xspf_playlist(playlist_url, playlist_id)\n\n        title = self._search_regex(\n            [r'dc:title=\"([^\"]+)\"', r'<title> &raquo;([^<]+)</title>'],\n            webpage, 'title').strip()\n        description = self._html_search_regex(\n            r'<p><strong>Description:</strong>(.+?)</p>',\n            webpage, 'description', default=None)\n        duration = parse_duration(self._search_regex(\n            r'<em>Length\\s*</em>\\s*:\\s*</strong>([^<]+)',\n            webpage, 'duration', default=None))\n\n        entries[0].update({\n            'title': title,\n            'description': description,\n            'duration': duration,\n        })\n\n        return self.playlist_result(entries, playlist_id)",
        "begin_line": 33,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.washingtonpost.WashingtonPostIE._real_extract#66",
        "src_path": "youtube_dl/extractor/washingtonpost.py",
        "class_name": "youtube_dl.extractor.washingtonpost.WashingtonPostIE",
        "signature": "youtube_dl.extractor.washingtonpost.WashingtonPostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n        webpage = self._download_webpage(url, page_id)\n\n        title = self._og_search_title(webpage)\n\n        uuids = re.findall(r'''(?x)\n            (?:\n                <div\\s+class=\"posttv-video-embed[^>]*?data-uuid=|\n                data-video-uuid=\n            )\"([^\"]+)\"''', webpage)\n        entries = []\n        for i, uuid in enumerate(uuids, start=1):\n            vinfo_all = self._download_json(\n                'http://www.washingtonpost.com/posttv/c/videojson/%s?resType=jsonp' % uuid,\n                page_id,\n                transform_source=strip_jsonp,\n                note='Downloading information of video %d/%d' % (i, len(uuids))\n            )\n            vinfo = vinfo_all[0]['contentConfig']\n            uploader = vinfo.get('credits', {}).get('source')\n            timestamp = int_or_none(\n                vinfo.get('dateConfig', {}).get('dateFirstPublished'), 1000)\n\n            formats = [{\n                'format_id': (\n                    '%s-%s-%s' % (s.get('type'), s.get('width'), s.get('bitrate'))\n                    if s.get('width')\n                    else s.get('type')),\n                'vbr': s.get('bitrate') if s.get('width') != 0 else None,\n                'width': s.get('width'),\n                'height': s.get('height'),\n                'acodec': s.get('audioCodec'),\n                'vcodec': s.get('videoCodec') if s.get('width') != 0 else 'none',\n                'filesize': s.get('fileSize'),\n                'url': s.get('url'),\n                'ext': 'mp4',\n                'preference': -100 if s.get('type') == 'smil' else None,\n                'protocol': {\n                    'MP4': 'http',\n                    'F4F': 'f4m',\n                }.get(s.get('type')),\n            } for s in vinfo.get('streams', [])]\n            source_media_url = vinfo.get('sourceMediaURL')\n            if source_media_url:\n                formats.append({\n                    'format_id': 'source_media',\n                    'url': source_media_url,\n                })\n            self._sort_formats(formats)\n            entries.append({\n                'id': uuid,\n                'title': vinfo['title'],\n                'description': vinfo.get('blurb'),\n                'uploader': uploader,\n                'formats': formats,\n                'duration': int_or_none(vinfo.get('videoDuration'), 100),\n                'timestamp': timestamp,\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': page_id,\n            'title': title,\n        }",
        "begin_line": 66,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._build_brighcove_url#106",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._build_brighcove_url(cls, object_str)",
        "snippet": "    def _build_brighcove_url(cls, object_str):\n        \"\"\"\n        Build a Brightcove url from a xml string containing\n        <object class=\"BrightcoveExperience\">{params}</object>\n        \"\"\"\n\n        # Fix up some stupid HTML, see https://github.com/rg3/youtube-dl/issues/1553\n        object_str = re.sub(r'(<param(?:\\s+[a-zA-Z0-9_]+=\"[^\"]*\")*)>',\n                            lambda m: m.group(1) + '/>', object_str)\n        # Fix up some stupid XML, see https://github.com/rg3/youtube-dl/issues/1608\n        object_str = object_str.replace('<--', '<!--')\n        # remove namespace to simplify extraction\n        object_str = re.sub(r'(<object[^>]*)(xmlns=\".*?\")', r'\\1', object_str)\n        object_str = fix_xml_ampersands(object_str)\n\n        try:\n            object_doc = compat_etree_fromstring(object_str.encode('utf-8'))\n        except compat_xml_parse_error:\n            return\n\n        fv_el = find_xpath_attr(object_doc, './param', 'name', 'flashVars')\n        if fv_el is not None:\n            flashvars = dict(\n                (k, v[0])\n                for k, v in compat_parse_qs(fv_el.attrib['value']).items())\n        else:\n            flashvars = {}\n\n        def find_param(name):\n            if name in flashvars:\n                return flashvars[name]\n            node = find_xpath_attr(object_doc, './param', 'name', name)\n            if node is not None:\n                return node.attrib['value']\n            return None\n\n        params = {}\n\n        playerID = find_param('playerID')\n        if playerID is None:\n            raise ExtractorError('Cannot find player ID')\n        params['playerID'] = playerID\n\n        playerKey = find_param('playerKey')\n        # Not all pages define this value\n        if playerKey is not None:\n            params['playerKey'] = playerKey\n        # The three fields hold the id of the video\n        videoPlayer = find_param('@videoPlayer') or find_param('videoId') or find_param('videoID')\n        if videoPlayer is not None:\n            params['@videoPlayer'] = videoPlayer\n        linkBase = find_param('linkBaseURL')\n        if linkBase is not None:\n            params['linkBaseURL'] = linkBase\n        return cls._make_brightcove_url(params)",
        "begin_line": 106,
        "end_line": 160,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._build_brighcove_url_from_js#163",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._build_brighcove_url_from_js(cls, object_js)",
        "snippet": "    def _build_brighcove_url_from_js(cls, object_js):\n        # The layout of JS is as follows:\n        # customBC.createVideo = function (width, height, playerID, playerKey, videoPlayer, VideoRandomID) {\n        #   // build Brightcove <object /> XML\n        # }\n        m = re.search(\n            r'''(?x)customBC.\\createVideo\\(\n                .*?                                                  # skipping width and height\n                [\"\\'](?P<playerID>\\d+)[\"\\']\\s*,\\s*                   # playerID\n                [\"\\'](?P<playerKey>AQ[^\"\\']{48})[^\"\\']*[\"\\']\\s*,\\s*  # playerKey begins with AQ and is 50 characters\n                                                                     # in length, however it's appended to itself\n                                                                     # in places, so truncate\n                [\"\\'](?P<videoID>\\d+)[\"\\']                           # @videoPlayer\n            ''', object_js)\n        if m:\n            return cls._make_brightcove_url(m.groupdict())",
        "begin_line": 163,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._make_brightcove_url#181",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._make_brightcove_url(cls, params)",
        "snippet": "    def _make_brightcove_url(cls, params):\n        data = compat_urllib_parse.urlencode(params)\n        return cls._FEDERATED_URL_TEMPLATE % data",
        "begin_line": 181,
        "end_line": 183,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_brightcove_url#186",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_brightcove_url(cls, webpage)",
        "snippet": "    def _extract_brightcove_url(cls, webpage):\n        \"\"\"Try to extract the brightcove url from the webpage, returns None\n        if it can't be found\n        \"\"\"\n        urls = cls._extract_brightcove_urls(webpage)\n        return urls[0] if urls else None",
        "begin_line": 186,
        "end_line": 191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_brightcove_urls#194",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_brightcove_urls(cls, webpage)",
        "snippet": "    def _extract_brightcove_urls(cls, webpage):\n        \"\"\"Return a list of all Brightcove URLs from the webpage \"\"\"\n\n        url_m = re.search(\n            r'<meta\\s+property=[\\'\"]og:video[\\'\"]\\s+content=[\\'\"](https?://(?:secure|c)\\.brightcove.com/[^\\'\"]+)[\\'\"]',\n            webpage)\n        if url_m:\n            url = unescapeHTML(url_m.group(1))\n            # Some sites don't add it, we can't download with this url, for example:\n            # http://www.ktvu.com/videos/news/raw-video-caltrain-releases-video-of-man-almost/vCTZdY/\n            if 'playerKey' in url or 'videoId' in url:\n                return [url]\n\n        matches = re.findall(\n            r'''(?sx)<object\n            (?:\n                [^>]+?class=[\\'\"][^>]*?BrightcoveExperience.*?[\\'\"] |\n                [^>]*?>\\s*<param\\s+name=\"movie\"\\s+value=\"https?://[^/]*brightcove\\.com/\n            ).+?>\\s*</object>''',\n            webpage)\n        if matches:\n            return list(filter(None, [cls._build_brighcove_url(m) for m in matches]))\n\n        return list(filter(None, [\n            cls._build_brighcove_url_from_js(custom_bc)\n            for custom_bc in re.findall(r'(customBC\\.createVideo\\(.+?\\);)', webpage)]))",
        "begin_line": 194,
        "end_line": 219,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._real_extract#221",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        # Change the 'videoId' and others field to '@videoPlayer'\n        url = re.sub(r'(?<=[?&])(videoI(d|D)|bctid)', '%40videoPlayer', url)\n        # Change bckey (used by bcove.me urls) to playerKey\n        url = re.sub(r'(?<=[?&])bckey', 'playerKey', url)\n        mobj = re.match(self._VALID_URL, url)\n        query_str = mobj.group('query')\n        query = compat_urlparse.parse_qs(query_str)\n\n        videoPlayer = query.get('@videoPlayer')\n        if videoPlayer:\n            # We set the original url as the default 'Referer' header\n            referer = smuggled_data.get('Referer', url)\n            return self._get_video_info(\n                videoPlayer[0], query_str, query, referer=referer)\n        elif 'playerKey' in query:\n            player_key = query['playerKey']\n            return self._get_playlist_info(player_key[0])\n        else:\n            raise ExtractorError(\n                'Cannot find playerKey= variable. Did you forget quotes in a shell invocation?',\n                expected=True)",
        "begin_line": 221,
        "end_line": 244,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._get_video_info#246",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._get_video_info(self, video_id, query_str, query, referer=None)",
        "snippet": "    def _get_video_info(self, video_id, query_str, query, referer=None):\n        request_url = self._FEDERATED_URL_TEMPLATE % query_str\n        req = compat_urllib_request.Request(request_url)\n        linkBase = query.get('linkBaseURL')\n        if linkBase is not None:\n            referer = linkBase[0]\n        if referer is not None:\n            req.add_header('Referer', referer)\n        webpage = self._download_webpage(req, video_id)\n\n        error_msg = self._html_search_regex(\n            r\"<h1>We're sorry.</h1>([\\s\\n]*<p>.*?</p>)+\", webpage,\n            'error message', default=None)\n        if error_msg is not None:\n            raise ExtractorError(\n                'brightcove said: %s' % error_msg, expected=True)\n\n        self.report_extraction(video_id)\n        info = self._search_regex(r'var experienceJSON = ({.*});', webpage, 'json')\n        info = json.loads(info)['data']\n        video_info = info['programmedContent']['videoPlayer']['mediaDTO']\n        video_info['_youtubedl_adServerURL'] = info.get('adServerURL')\n\n        return self._extract_video_info(video_info)",
        "begin_line": 246,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._get_playlist_info#271",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._get_playlist_info(self, player_key)",
        "snippet": "    def _get_playlist_info(self, player_key):\n        info_url = 'http://c.brightcove.com/services/json/experience/runtime/?command=get_programming_for_experience&playerKey=%s' % player_key\n        playlist_info = self._download_webpage(\n            info_url, player_key, 'Downloading playlist information')\n\n        json_data = json.loads(playlist_info)\n        if 'videoList' not in json_data:\n            raise ExtractorError('Empty playlist')\n        playlist_info = json_data['videoList']\n        videos = [self._extract_video_info(video_info) for video_info in playlist_info['mediaCollectionDTO']['videoDTOs']]\n\n        return self.playlist_result(videos, playlist_id='%s' % playlist_info['id'],\n                                    playlist_title=playlist_info['mediaCollectionDTO']['displayName'])",
        "begin_line": 271,
        "end_line": 283,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_video_info#285",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_video_info(self, video_info)",
        "snippet": "    def _extract_video_info(self, video_info):\n        info = {\n            'id': compat_str(video_info['id']),\n            'title': video_info['displayName'].strip(),\n            'description': video_info.get('shortDescription'),\n            'thumbnail': video_info.get('videoStillURL') or video_info.get('thumbnailURL'),\n            'uploader': video_info.get('publisherName'),\n        }\n\n        renditions = video_info.get('renditions')\n        if renditions:\n            formats = []\n            for rend in renditions:\n                url = rend['defaultURL']\n                if not url:\n                    continue\n                ext = None\n                if rend['remote']:\n                    url_comp = compat_urllib_parse_urlparse(url)\n                    if url_comp.path.endswith('.m3u8'):\n                        formats.extend(\n                            self._extract_m3u8_formats(url, info['id'], 'mp4'))\n                        continue\n                    elif 'akamaihd.net' in url_comp.netloc:\n                        # This type of renditions are served through\n                        # akamaihd.net, but they don't use f4m manifests\n                        url = url.replace('control/', '') + '?&v=3.3.0&fp=13&r=FEEFJ&g=RTSJIMBMPFPB'\n                        ext = 'flv'\n                if ext is None:\n                    ext = determine_ext(url)\n                size = rend.get('size')\n                formats.append({\n                    'url': url,\n                    'ext': ext,\n                    'height': rend.get('frameHeight'),\n                    'width': rend.get('frameWidth'),\n                    'filesize': size if size != 0 else None,\n                })\n            self._sort_formats(formats)\n            info['formats'] = formats\n        elif video_info.get('FLVFullLengthURL') is not None:\n            info.update({\n                'url': video_info['FLVFullLengthURL'],\n            })\n\n        if self._downloader.params.get('include_ads', False):\n            adServerURL = video_info.get('_youtubedl_adServerURL')\n            if adServerURL:\n                ad_info = {\n                    '_type': 'url',\n                    'url': adServerURL,\n                }\n                if 'url' in info:\n                    return {\n                        '_type': 'playlist',\n                        'title': info['title'],\n                        'entries': [ad_info, info],\n                    }\n                else:\n                    return ad_info\n\n        if 'url' not in info and not info.get('formats'):\n            raise ExtractorError('Unable to extract video url for %s' % info['id'])\n        return info",
        "begin_line": 285,
        "end_line": 348,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ina.InaIE._real_extract#21",
        "src_path": "youtube_dl/extractor/ina.py",
        "class_name": "youtube_dl.extractor.ina.InaIE",
        "signature": "youtube_dl.extractor.ina.InaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        mrss_url = 'http://player.ina.fr/notices/%s.mrss' % video_id\n        info_doc = self._download_xml(mrss_url, video_id)\n\n        self.report_extraction(video_id)\n\n        video_url = info_doc.find('.//{http://search.yahoo.com/mrss/}player').attrib['url']\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': info_doc.find('.//title').text,\n        }",
        "begin_line": 21,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterIE._real_extract#47",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        def extract_video_url(webpage, name):\n            return self._search_regex(\n                [r'''file\\s*:\\s*(?P<q>[\"'])(?P<mp4>.+?)(?P=q)''',\n                 r'''<a\\s+href=(?P<q>[\"'])(?P<mp4>.+?)(?P=q)\\s+class=[\"']mp4Thumb''',\n                 r'''<video[^>]+file=(?P<q>[\"'])(?P<mp4>.+?)(?P=q)[^>]*>'''],\n                webpage, name, group='mp4')\n\n        def is_hd(webpage):\n            return '<div class=\\'icon iconHD\\'' in webpage\n\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        seo = mobj.group('seo')\n        proto = mobj.group('proto')\n        mrss_url = '%s://xhamster.com/movies/%s/%s.html' % (proto, video_id, seo)\n        webpage = self._download_webpage(mrss_url, video_id)\n\n        title = self._html_search_regex(\n            [r'<title>(?P<title>.+?)(?:, (?:[^,]+? )?Porn: xHamster| - xHamster\\.com)</title>',\n             r'<h1>([^<]+)</h1>'], webpage, 'title')\n\n        # Only a few videos have an description\n        mobj = re.search(r'<span>Description: </span>([^<]+)', webpage)\n        description = mobj.group(1) if mobj else None\n\n        upload_date = self._html_search_regex(r'hint=\\'(\\d{4}-\\d{2}-\\d{2}) \\d{2}:\\d{2}:\\d{2} [A-Z]{3,4}\\'',\n                                              webpage, 'upload date', fatal=False)\n        if upload_date:\n            upload_date = unified_strdate(upload_date)\n\n        uploader = self._html_search_regex(\n            r\"<a href='[^']+xhamster\\.com/user/[^>]+>(?P<uploader>[^<]+)\",\n            webpage, 'uploader', default='anonymous')\n\n        thumbnail = self._search_regex(\n            [r'''thumb\\s*:\\s*(?P<q>[\"'])(?P<thumbnail>.+?)(?P=q)''',\n             r'''<video[^>]+poster=(?P<q>[\"'])(?P<thumbnail>.+?)(?P=q)[^>]*>'''],\n            webpage, 'thumbnail', fatal=False, group='thumbnail')\n\n        duration = parse_duration(self._html_search_regex(r'<span>Runtime:</span> (\\d+:\\d+)</div>',\n                                                          webpage, 'duration', fatal=False))\n\n        view_count = self._html_search_regex(r'<span>Views:</span> ([^<]+)</div>', webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = str_to_int(view_count)\n\n        mobj = re.search(r\"hint='(?P<likecount>\\d+) Likes / (?P<dislikecount>\\d+) Dislikes'\", webpage)\n        (like_count, dislike_count) = (mobj.group('likecount'), mobj.group('dislikecount')) if mobj else (None, None)\n\n        mobj = re.search(r'</label>Comments \\((?P<commentcount>\\d+)\\)</div>', webpage)\n        comment_count = mobj.group('commentcount') if mobj else 0\n\n        age_limit = self._rta_search(webpage)\n\n        hd = is_hd(webpage)\n\n        format_id = 'hd' if hd else 'sd'\n\n        video_url = extract_video_url(webpage, format_id)\n        formats = [{\n            'url': video_url,\n            'format_id': 'hd' if hd else 'sd',\n            'preference': 1,\n        }]\n\n        if not hd:\n            mrss_url = self._search_regex(r'<link rel=\"canonical\" href=\"([^\"]+)', webpage, 'mrss_url')\n            webpage = self._download_webpage(mrss_url + '?hd', video_id, note='Downloading HD webpage')\n            if is_hd(webpage):\n                video_url = extract_video_url(webpage, 'hd')\n                formats.append({\n                    'url': video_url,\n                    'format_id': 'hd',\n                    'preference': 2,\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'upload_date': upload_date,\n            'uploader': uploader,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': int_or_none(like_count),\n            'dislike_count': int_or_none(dislike_count),\n            'comment_count': int_or_none(comment_count),\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 47,
        "end_line": 141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterEmbedIE._extract_urls#160",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterEmbedIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterEmbedIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [url for _, url in re.findall(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?xhamster\\.com/xembed\\.php\\?video=\\d+)\\1',\n            webpage)]",
        "begin_line": 160,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterEmbedIE._real_extract#165",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterEmbedIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(\n            r'href=\"(https?://xhamster\\.com/movies/%s/[^\"]+\\.html[^\"]*)\"' % video_id,\n            webpage, 'xhamster url')\n\n        return self.url_result(video_url, 'XHamster')",
        "begin_line": 165,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.abc7news.Abc7NewsIE._real_extract#36",
        "src_path": "youtube_dl/extractor/abc7news.py",
        "class_name": "youtube_dl.extractor.abc7news.Abc7NewsIE",
        "signature": "youtube_dl.extractor.abc7news.Abc7NewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        m3u8 = self._html_search_meta(\n            'contentURL', webpage, 'm3u8 url', fatal=True)\n\n        formats = self._extract_m3u8_formats(m3u8, display_id, 'mp4')\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage).strip()\n        description = self._og_search_description(webpage).strip()\n        thumbnail = self._og_search_thumbnail(webpage)\n        timestamp = parse_iso8601(self._search_regex(\n            r'<div class=\"meta\">\\s*<time class=\"timeago\" datetime=\"([^\"]+)\">',\n            webpage, 'upload date', fatal=False))\n        uploader = self._search_regex(\n            r'rel=\"author\">([^<]+)</a>',\n            webpage, 'uploader', default=None)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'formats': formats,\n        }",
        "begin_line": 36,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.cbssports.CBSSportsIE._real_extract#21",
        "src_path": "youtube_dl/extractor/cbssports.py",
        "class_name": "youtube_dl.extractor.cbssports.CBSSportsIE",
        "signature": "youtube_dl.extractor.cbssports.CBSSportsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        section = mobj.group('section')\n        video_id = mobj.group('id')\n        all_videos = self._download_json(\n            'http://www.cbssports.com/data/video/player/getVideos/%s?as=json' % section,\n            video_id)\n        # The json file contains the info of all the videos in the section\n        video_info = next(v for v in all_videos if v['pcid'] == video_id)\n        return self.url_result('theplatform:%s' % video_info['pid'], 'ThePlatform')",
        "begin_line": 21,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.myspass.MySpassIE._real_extract#26",
        "src_path": "youtube_dl/extractor/myspass.py",
        "class_name": "youtube_dl.extractor.myspass.MySpassIE",
        "signature": "youtube_dl.extractor.myspass.MySpassIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        META_DATA_URL_TEMPLATE = 'http://www.myspass.de/myspass/includes/apps/video/getvideometadataxml.php?id=%s'\n\n        # video id is the last path element of the URL\n        # usually there is a trailing slash, so also try the second but last\n        url_path = compat_urllib_parse_urlparse(url).path\n        url_parent_path, video_id = os.path.split(url_path)\n        if not video_id:\n            _, video_id = os.path.split(url_parent_path)\n\n        # get metadata\n        metadata_url = META_DATA_URL_TEMPLATE % video_id\n        metadata = self._download_xml(\n            metadata_url, video_id, transform_source=lambda s: s.strip())\n\n        # extract values from metadata\n        url_flv_el = metadata.find('url_flv')\n        if url_flv_el is None:\n            raise ExtractorError('Unable to extract download url')\n        video_url = url_flv_el.text\n        title_el = metadata.find('title')\n        if title_el is None:\n            raise ExtractorError('Unable to extract title')\n        title = title_el.text\n        format_id_el = metadata.find('format_id')\n        if format_id_el is None:\n            format = 'mp4'\n        else:\n            format = format_id_el.text\n        description_el = metadata.find('description')\n        if description_el is not None:\n            description = description_el.text\n        else:\n            description = None\n        imagePreview_el = metadata.find('imagePreview')\n        if imagePreview_el is not None:\n            thumbnail = imagePreview_el.text\n        else:\n            thumbnail = None\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'format': format,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 26,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtbf.RTBFIE._real_extract#31",
        "src_path": "youtube_dl/extractor/rtbf.py",
        "class_name": "youtube_dl.extractor.rtbf.RTBFIE",
        "signature": "youtube_dl.extractor.rtbf.RTBFIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.rtbf.be/video/embed?id=%s' % video_id, video_id)\n\n        data = self._parse_json(\n            unescapeHTML(self._search_regex(\n                r'data-media=\"([^\"]+)\"', webpage, 'data video')),\n            video_id)\n\n        if data.get('provider').lower() == 'youtube':\n            video_url = data.get('downloadUrl') or data.get('url')\n            return self.url_result(video_url, 'Youtube')\n        formats = []\n        for key, format_id in self._QUALITIES:\n            format_url = data['sources'].get(key)\n            if format_url:\n                formats.append({\n                    'format_id': format_id,\n                    'url': format_url,\n                })\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': data['title'],\n            'description': data.get('description') or data.get('subtitle'),\n            'thumbnail': data.get('thumbnail'),\n            'duration': data.get('duration') or data.get('realDuration'),\n            'timestamp': int_or_none(data.get('created')),\n            'view_count': int_or_none(data.get('viewCount')),\n        }",
        "begin_line": 31,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rts.RTSIE._real_extract#149",
        "src_path": "youtube_dl/extractor/rts.py",
        "class_name": "youtube_dl.extractor.rts.RTSIE",
        "signature": "youtube_dl.extractor.rts.RTSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('rts_id') or m.group('id') or m.group('id_new')\n        display_id = m.group('display_id') or m.group('display_id_new')\n\n        def download_json(internal_id):\n            return self._download_json(\n                'http://www.rts.ch/a/%s.html?f=json/article' % internal_id,\n                display_id)\n\n        all_info = download_json(video_id)\n\n        # video_id extracted out of URL is not always a real id\n        if 'video' not in all_info and 'audio' not in all_info:\n            page = self._download_webpage(url, display_id)\n\n            # article with videos on rhs\n            videos = re.findall(\n                r'<article[^>]+class=\"content-item\"[^>]*>\\s*<a[^>]+data-video-urn=\"urn:rts:video:(\\d+)\"',\n                page)\n            if videos:\n                entries = [self.url_result('rts:%s' % video_urn, 'RTS') for video_urn in videos]\n                return self.playlist_result(entries, video_id, self._og_search_title(page))\n\n            internal_id = self._html_search_regex(\n                r'<(?:video|audio) data-id=\"([0-9]+)\"', page,\n                'internal video id')\n            all_info = download_json(internal_id)\n\n        info = all_info['video']['JSONinfo'] if 'video' in all_info else all_info['audio']\n\n        upload_timestamp = parse_iso8601(info.get('broadcast_date'))\n        duration = info.get('duration') or info.get('cutout') or info.get('cutduration')\n        if isinstance(duration, compat_str):\n            duration = parse_duration(duration)\n        view_count = info.get('plays')\n        thumbnail = unescapeHTML(info.get('preview_image_url'))\n\n        def extract_bitrate(url):\n            return int_or_none(self._search_regex(\n                r'-([0-9]+)k\\.', url, 'bitrate', default=None))\n\n        formats = []\n        for format_id, format_url in info['streams'].items():\n            if format_url.endswith('.f4m'):\n                token = self._download_xml(\n                    'http://tp.srgssr.ch/token/akahd.xml?stream=%s/*' % compat_urllib_parse_urlparse(format_url).path,\n                    video_id, 'Downloading %s token' % format_id)\n                auth_params = xpath_text(token, './/authparams', 'auth params')\n                if not auth_params:\n                    continue\n                formats.extend(self._extract_f4m_formats(\n                    '%s?%s&hdcore=3.4.0&plugin=aasp-3.4.0.132.66' % (format_url, auth_params),\n                    video_id, f4m_id=format_id))\n            elif format_url.endswith('.m3u8'):\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', m3u8_id=format_id))\n            else:\n                formats.append({\n                    'format_id': format_id,\n                    'url': format_url,\n                    'tbr': extract_bitrate(format_url),\n                })\n\n        if 'media' in info:\n            formats.extend([{\n                'format_id': '%s-%sk' % (media['ext'], media['rate']),\n                'url': 'http://download-video.rts.ch/%s' % media['url'],\n                'tbr': media['rate'] or extract_bitrate(media['url']),\n            } for media in info['media'] if media.get('rate')])\n\n        self._check_formats(formats, video_id)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'formats': formats,\n            'title': info['title'],\n            'description': info.get('intro'),\n            'duration': duration,\n            'view_count': view_count,\n            'uploader': info.get('programName'),\n            'timestamp': upload_timestamp,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 149,
        "end_line": 234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.urort.UrortIE._real_extract#34",
        "src_path": "youtube_dl/extractor/urort.py",
        "class_name": "youtube_dl.extractor.urort.UrortIE",
        "signature": "youtube_dl.extractor.urort.UrortIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        fstr = compat_urllib_parse.quote(\"InternalBandUrl eq '%s'\" % playlist_id)\n        json_url = 'http://urort.p3.no/breeze/urort/TrackDTOViews?$filter=%s&$orderby=Released%%20desc&$expand=Tags%%2CFiles' % fstr\n        songs = self._download_json(json_url, playlist_id)\n        entries = []\n        for s in songs:\n            formats = [{\n                'tbr': f.get('Quality'),\n                'ext': f['FileType'],\n                'format_id': '%s-%s' % (f['FileType'], f.get('Quality', '')),\n                'url': 'http://p3urort.blob.core.windows.net/tracks/%s' % f['FileRef'],\n                'preference': 3 if f['FileType'] == 'mp3' else 2,\n            } for f in s['Files']]\n            self._sort_formats(formats)\n            e = {\n                'id': '%d-%s' % (s['BandId'], s['$id']),\n                'title': s['Title'],\n                'uploader_id': playlist_id,\n                'uploader': s.get('BandName', playlist_id),\n                'thumbnail': 'http://urort.p3.no/cloud/images/%s' % s['Image'],\n                'upload_date': unified_strdate(s.get('Released')),\n                'formats': formats,\n            }\n            entries.append(e)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_id,\n            'entries': entries,\n        }",
        "begin_line": 34,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.preferredencoding#74",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.preferredencoding()",
        "snippet": "def preferredencoding():\n    \"\"\"Get preferred encoding.\n\n    Returns the best encoding scheme for the system, based on\n    locale.getpreferredencoding() and some further tweaks.\n    \"\"\"\n    try:\n        pref = locale.getpreferredencoding()\n        'TEST'.encode(pref)\n    except Exception:\n        pref = 'UTF-8'\n\n    return pref",
        "begin_line": 74,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.write_json_file#89",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_json_file(obj, fn)",
        "snippet": "def write_json_file(obj, fn):\n    \"\"\" Encode obj as JSON and write it to fn, atomically if possible \"\"\"\n\n    fn = encodeFilename(fn)\n    if sys.version_info < (3, 0) and sys.platform != 'win32':\n        encoding = get_filesystem_encoding()\n        # os.path.basename returns a bytes object, but NamedTemporaryFile\n        # will fail if the filename contains non ascii characters unless we\n        # use a unicode object\n        path_basename = lambda f: os.path.basename(fn).decode(encoding)\n        # the same for os.path.dirname\n        path_dirname = lambda f: os.path.dirname(fn).decode(encoding)\n    else:\n        path_basename = os.path.basename\n        path_dirname = os.path.dirname\n\n    args = {\n        'suffix': '.tmp',\n        'prefix': path_basename(fn) + '.',\n        'dir': path_dirname(fn),\n        'delete': False,\n    }\n\n    # In Python 2.x, json.dump expects a bytestream.\n    # In Python 3.x, it writes to a character stream\n    if sys.version_info < (3, 0):\n        args['mode'] = 'wb'\n    else:\n        args.update({\n            'mode': 'w',\n            'encoding': 'utf-8',\n        })\n\n    tf = tempfile.NamedTemporaryFile(**compat_kwargs(args))\n\n    try:\n        with tf:\n            json.dump(obj, tf)\n        if sys.platform == 'win32':\n            # Need to remove existing file on Windows, else os.rename raises\n            # WindowsError or FileExistsError.\n            try:\n                os.unlink(fn)\n            except OSError:\n                pass\n        os.rename(tf.name, fn)\n    except Exception:\n        try:\n            os.remove(tf.name)\n        except OSError:\n            pass\n        raise",
        "begin_line": 89,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.find_xpath_attr#144",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.find_xpath_attr(node, xpath, key, val=None)",
        "snippet": "    def find_xpath_attr(node, xpath, key, val=None):\n        \"\"\" Find the xpath xpath[@key=val] \"\"\"\n        assert re.match(r'^[a-zA-Z_-]+$', key)\n        if val:\n            assert re.match(r'^[a-zA-Z0-9@\\s:._-]*$', val)\n        expr = xpath + ('[@%s]' % key if val is None else \"[@%s='%s']\" % (key, val))\n        return node.find(expr)",
        "begin_line": 144,
        "end_line": 150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.xpath_with_ns#169",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_with_ns(path, ns_map)",
        "snippet": "def xpath_with_ns(path, ns_map):\n    components = [c.split(':') for c in path.split('/')]\n    replaced = []\n    for c in components:\n        if len(c) == 1:\n            replaced.append(c[0])\n        else:\n            ns, tag = c\n            replaced.append('{%s}%s' % (ns_map[ns], tag))\n    return '/'.join(replaced)",
        "begin_line": 169,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.xpath_element#181",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_element(node, xpath, name=None, fatal=False, default=NO_DEFAULT)",
        "snippet": "def xpath_element(node, xpath, name=None, fatal=False, default=NO_DEFAULT):\n    def _find_xpath(xpath):\n        if sys.version_info < (2, 7):  # Crazy 2.6\n            xpath = xpath.encode('ascii')\n        return node.find(xpath)\n\n    if isinstance(xpath, (str, compat_str)):\n        n = _find_xpath(xpath)\n    else:\n        for xp in xpath:\n            n = _find_xpath(xp)\n            if n is not None:\n                break\n\n    if n is None:\n        if default is not NO_DEFAULT:\n            return default\n        elif fatal:\n            name = xpath if name is None else name\n            raise ExtractorError('Could not find XML element %s' % name)\n        else:\n            return None\n    return n",
        "begin_line": 181,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils._find_xpath#182",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._find_xpath(xpath)",
        "snippet": "    def _find_xpath(xpath):\n        if sys.version_info < (2, 7):  # Crazy 2.6\n            xpath = xpath.encode('ascii')\n        return node.find(xpath)",
        "begin_line": 182,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.xpath_text#206",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_text(node, xpath, name=None, fatal=False, default=NO_DEFAULT)",
        "snippet": "def xpath_text(node, xpath, name=None, fatal=False, default=NO_DEFAULT):\n    n = xpath_element(node, xpath, name, fatal=fatal, default=default)\n    if n is None or n == default:\n        return n\n    if n.text is None:\n        if default is not NO_DEFAULT:\n            return default\n        elif fatal:\n            name = xpath if name is None else name\n            raise ExtractorError('Could not find XML element\\'s text %s' % name)\n        else:\n            return None\n    return n.text",
        "begin_line": 206,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.xpath_attr#221",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_attr(node, xpath, key, name=None, fatal=False, default=NO_DEFAULT)",
        "snippet": "def xpath_attr(node, xpath, key, name=None, fatal=False, default=NO_DEFAULT):\n    n = find_xpath_attr(node, xpath, key)\n    if n is None:\n        if default is not NO_DEFAULT:\n            return default\n        elif fatal:\n            name = '%s[@%s]' % (xpath, key) if name is None else name\n            raise ExtractorError('Could not find XML attribute %s' % name)\n        else:\n            return None\n    return n.attrib[key]",
        "begin_line": 221,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.get_element_by_id#234",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_element_by_id(id, html)",
        "snippet": "def get_element_by_id(id, html):\n    \"\"\"Return the content of the tag with the specified ID in the passed HTML document\"\"\"\n    return get_element_by_attribute(\"id\", id, html)",
        "begin_line": 234,
        "end_line": 236,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.get_element_by_attribute#239",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_element_by_attribute(attribute, value, html)",
        "snippet": "def get_element_by_attribute(attribute, value, html):\n    \"\"\"Return the content of the tag with the specified attribute in the passed HTML document\"\"\"\n\n    m = re.search(r'''(?xs)\n        <([a-zA-Z0-9:._-]+)\n         (?:\\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]+|=\"[^\"]+\"|='[^']+'))*?\n         \\s+%s=['\"]?%s['\"]?\n         (?:\\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]+|=\"[^\"]+\"|='[^']+'))*?\n        \\s*>\n        (?P<content>.*?)\n        </\\1>\n    ''' % (re.escape(attribute), re.escape(value)), html)\n\n    if not m:\n        return None\n    res = m.group('content')\n\n    if res.startswith('\"') or res.startswith(\"'\"):\n        res = res[1:-1]\n\n    return unescapeHTML(res)",
        "begin_line": 239,
        "end_line": 259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.clean_html#262",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.clean_html(html)",
        "snippet": "def clean_html(html):\n    \"\"\"Clean an HTML snippet into a readable string\"\"\"\n\n    if html is None:  # Convenience for sanitizing descriptions etc.\n        return html\n\n    # Newline vs <br />\n    html = html.replace('\\n', ' ')\n    html = re.sub(r'\\s*<\\s*br\\s*/?\\s*>\\s*', '\\n', html)\n    html = re.sub(r'<\\s*/\\s*p\\s*>\\s*<\\s*p[^>]*>', '\\n', html)\n    # Strip html tags\n    html = re.sub('<.*?>', '', html)\n    # Replace html entities\n    html = unescapeHTML(html)\n    return html.strip()",
        "begin_line": 262,
        "end_line": 276,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002824858757062147,
            "pseudo_dstar_susp": 0.0032679738562091504,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0032679738562091504,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.sanitize_open#279",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_open(filename, open_mode)",
        "snippet": "def sanitize_open(filename, open_mode):\n    \"\"\"Try to open the given filename, and slightly tweak it if this fails.\n\n    Attempts to open the given filename. If this fails, it tries to change\n    the filename slightly, step by step, until it's either able to open it\n    or it fails and raises a final exception, like the standard open()\n    function.\n\n    It returns the tuple (stream, definitive_file_name).\n    \"\"\"\n    try:\n        if filename == '-':\n            if sys.platform == 'win32':\n                import msvcrt\n                msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)\n            return (sys.stdout.buffer if hasattr(sys.stdout, 'buffer') else sys.stdout, filename)\n        stream = open(encodeFilename(filename), open_mode)\n        return (stream, filename)\n    except (IOError, OSError) as err:\n        if err.errno in (errno.EACCES,):\n            raise\n\n        # In case of error, try to remove win32 forbidden chars\n        alt_filename = sanitize_path(filename)\n        if alt_filename == filename:\n            raise\n        else:\n            # An exception here should be caught in the caller\n            stream = open(encodeFilename(alt_filename), open_mode)\n            return (stream, alt_filename)",
        "begin_line": 279,
        "end_line": 308,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.timeconvert#311",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.timeconvert(timestr)",
        "snippet": "def timeconvert(timestr):\n    \"\"\"Convert RFC 2822 defined time string into system timestamp\"\"\"\n    timestamp = None\n    timetuple = email.utils.parsedate_tz(timestr)\n    if timetuple is not None:\n        timestamp = email.utils.mktime_tz(timetuple)\n    return timestamp",
        "begin_line": 311,
        "end_line": 317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.sanitize_filename#320",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_filename(s, restricted=False, is_id=False)",
        "snippet": "def sanitize_filename(s, restricted=False, is_id=False):\n    \"\"\"Sanitizes a string so it could be used as part of a filename.\n    If restricted is set, use a stricter subset of allowed characters.\n    Set is_id if this is not an arbitrary string, but an ID that should be kept if possible\n    \"\"\"\n    def replace_insane(char):\n        if char == '?' or ord(char) < 32 or ord(char) == 127:\n            return ''\n        elif char == '\"':\n            return '' if restricted else '\\''\n        elif char == ':':\n            return '_-' if restricted else ' -'\n        elif char in '\\\\/|*<>':\n            return '_'\n        if restricted and (char in '!&\\'()[]{}$;`^,#' or char.isspace()):\n            return '_'\n        if restricted and ord(char) > 127:\n            return '_'\n        return char\n\n    # Handle timestamps\n    s = re.sub(r'[0-9]+(?::[0-9]+)+', lambda m: m.group(0).replace(':', '_'), s)\n    result = ''.join(map(replace_insane, s))\n    if not is_id:\n        while '__' in result:\n            result = result.replace('__', '_')\n        result = result.strip('_')\n        # Common case of \"Foreign band name - English song title\"\n        if restricted and result.startswith('-_'):\n            result = result[2:]\n        if result.startswith('-'):\n            result = '_' + result[len('-'):]\n        result = result.lstrip('.')\n        if not result:\n            result = '_'\n    return result",
        "begin_line": 320,
        "end_line": 355,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.replace_insane#325",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.replace_insane(char)",
        "snippet": "    def replace_insane(char):\n        if char == '?' or ord(char) < 32 or ord(char) == 127:\n            return ''\n        elif char == '\"':\n            return '' if restricted else '\\''\n        elif char == ':':\n            return '_-' if restricted else ' -'\n        elif char in '\\\\/|*<>':\n            return '_'\n        if restricted and (char in '!&\\'()[]{}$;`^,#' or char.isspace()):\n            return '_'\n        if restricted and ord(char) > 127:\n            return '_'\n        return char",
        "begin_line": 325,
        "end_line": 338,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.sanitize_path#358",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_path(s)",
        "snippet": "def sanitize_path(s):\n    \"\"\"Sanitizes and normalizes path on Windows\"\"\"\n    if sys.platform != 'win32':\n        return s\n    drive_or_unc, _ = os.path.splitdrive(s)\n    if sys.version_info < (2, 7) and not drive_or_unc:\n        drive_or_unc, _ = os.path.splitunc(s)\n    norm_path = os.path.normpath(remove_start(s, drive_or_unc)).split(os.path.sep)\n    if drive_or_unc:\n        norm_path.pop(0)\n    sanitized_path = [\n        path_part if path_part in ['.', '..'] else re.sub('(?:[/<>:\"\\\\|\\\\\\\\?\\\\*]|[\\s.]$)', '#', path_part)\n        for path_part in norm_path]\n    if drive_or_unc:\n        sanitized_path.insert(0, drive_or_unc + os.path.sep)\n    return os.path.join(*sanitized_path)",
        "begin_line": 358,
        "end_line": 373,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.orderedSet#376",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.orderedSet(iterable)",
        "snippet": "def orderedSet(iterable):\n    \"\"\" Remove all duplicates from the input iterable \"\"\"\n    res = []\n    for el in iterable:\n        if el not in res:\n            res.append(el)\n    return res",
        "begin_line": 376,
        "end_line": 382,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009930486593843098,
            "pseudo_dstar_susp": 0.000992063492063492,
            "pseudo_tarantula_susp": 0.0011337868480725624,
            "pseudo_op2_susp": 0.000992063492063492,
            "pseudo_barinel_susp": 0.0011337868480725624
        }
    },
    {
        "name": "youtube_dl.utils._htmlentity_transform#385",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._htmlentity_transform(entity)",
        "snippet": "def _htmlentity_transform(entity):\n    \"\"\"Transforms an HTML entity to a character.\"\"\"\n    # Known non-numeric HTML entity\n    if entity in compat_html_entities.name2codepoint:\n        return compat_chr(compat_html_entities.name2codepoint[entity])\n\n    mobj = re.match(r'#(x[0-9a-fA-F]+|[0-9]+)', entity)\n    if mobj is not None:\n        numstr = mobj.group(1)\n        if numstr.startswith('x'):\n            base = 16\n            numstr = '0%s' % numstr\n        else:\n            base = 10\n        return compat_chr(int(numstr, base))\n\n    # Unknown entity in name, return its literal representation\n    return ('&%s;' % entity)",
        "begin_line": 385,
        "end_line": 402,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0015060240963855422,
            "pseudo_dstar_susp": 0.0019723865877712033,
            "pseudo_tarantula_susp": 0.001226993865030675,
            "pseudo_op2_susp": 0.0019723865877712033,
            "pseudo_barinel_susp": 0.0012254901960784314
        }
    },
    {
        "name": "youtube_dl.utils.unescapeHTML#405",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unescapeHTML(s)",
        "snippet": "def unescapeHTML(s):\n    if s is None:\n        return None\n    assert type(s) == compat_str\n\n    return re.sub(\n        r'&([^;]+);', lambda m: _htmlentity_transform(m.group(1)), s)",
        "begin_line": 405,
        "end_line": 411,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0028653295128939827,
            "pseudo_dstar_susp": 0.003472222222222222,
            "pseudo_tarantula_susp": 0.0011641443538998836,
            "pseudo_op2_susp": 0.003472222222222222,
            "pseudo_barinel_susp": 0.0011641443538998836
        }
    },
    {
        "name": "youtube_dl.utils.get_subprocess_encoding#414",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_subprocess_encoding()",
        "snippet": "def get_subprocess_encoding():\n    if sys.platform == 'win32' and sys.getwindowsversion()[0] >= 5:\n        # For subprocess calls, encode with locale encoding\n        # Refer to http://stackoverflow.com/a/9951851/35070\n        encoding = preferredencoding()\n    else:\n        encoding = sys.getfilesystemencoding()\n    if encoding is None:\n        encoding = 'utf-8'\n    return encoding",
        "begin_line": 414,
        "end_line": 423,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.encodeFilename#426",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encodeFilename(s, for_subprocess=False)",
        "snippet": "def encodeFilename(s, for_subprocess=False):\n    \"\"\"\n    @param s The name of the file\n    \"\"\"\n\n    assert type(s) == compat_str\n\n    # Python 3 has a Unicode API\n    if sys.version_info >= (3, 0):\n        return s\n\n    # Pass '' directly to use Unicode APIs on Windows 2000 and up\n    # (Detecting Windows NT 4 is tricky because 'major >= 4' would\n    # match Windows 9x series as well. Besides, NT 4 is obsolete.)\n    if not for_subprocess and sys.platform == 'win32' and sys.getwindowsversion()[0] >= 5:\n        return s\n\n    return s.encode(get_subprocess_encoding(), 'ignore')",
        "begin_line": 426,
        "end_line": 443,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009372071227741331,
            "pseudo_dstar_susp": 0.0009363295880149813,
            "pseudo_tarantula_susp": 0.0009389671361502347,
            "pseudo_op2_susp": 0.0009363295880149813,
            "pseudo_barinel_susp": 0.0009389671361502347
        }
    },
    {
        "name": "youtube_dl.utils.decodeFilename#446",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decodeFilename(b, for_subprocess=False)",
        "snippet": "def decodeFilename(b, for_subprocess=False):\n\n    if sys.version_info >= (3, 0):\n        return b\n\n    if not isinstance(b, bytes):\n        return b\n\n    return b.decode(get_subprocess_encoding(), 'ignore')",
        "begin_line": 446,
        "end_line": 454,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.encodeArgument#457",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encodeArgument(s)",
        "snippet": "def encodeArgument(s):\n    if not isinstance(s, compat_str):\n        # Legacy code that uses byte strings\n        # Uncomment the following line after fixing all post processors\n        # assert False, 'Internal error: %r should be of type %r, is %r' % (s, compat_str, type(s))\n        s = s.decode('ascii')\n    return encodeFilename(s, True)",
        "begin_line": 457,
        "end_line": 463,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009930486593843098,
            "pseudo_dstar_susp": 0.000992063492063492,
            "pseudo_tarantula_susp": 0.0011337868480725624,
            "pseudo_op2_susp": 0.000992063492063492,
            "pseudo_barinel_susp": 0.0011337868480725624
        }
    },
    {
        "name": "youtube_dl.utils.decodeArgument#466",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decodeArgument(b)",
        "snippet": "def decodeArgument(b):\n    return decodeFilename(b, True)",
        "begin_line": 466,
        "end_line": 467,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.decodeOption#470",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decodeOption(optval)",
        "snippet": "def decodeOption(optval):\n    if optval is None:\n        return optval\n    if isinstance(optval, bytes):\n        optval = optval.decode(preferredencoding())\n\n    assert isinstance(optval, compat_str)\n    return optval",
        "begin_line": 470,
        "end_line": 477,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.formatSeconds#480",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.formatSeconds(secs)",
        "snippet": "def formatSeconds(secs):\n    if secs > 3600:\n        return '%d:%02d:%02d' % (secs // 3600, (secs % 3600) // 60, secs % 60)\n    elif secs > 60:\n        return '%d:%02d' % (secs // 60, secs % 60)\n    else:\n        return '%d' % secs",
        "begin_line": 480,
        "end_line": 486,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.make_HTTPS_handler#489",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.make_HTTPS_handler(params, **kwargs)",
        "snippet": "def make_HTTPS_handler(params, **kwargs):\n    opts_no_check_certificate = params.get('nocheckcertificate', False)\n    if hasattr(ssl, 'create_default_context'):  # Python >= 3.4 or 2.7.9\n        context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n        if opts_no_check_certificate:\n            context.check_hostname = False\n            context.verify_mode = ssl.CERT_NONE\n        try:\n            return YoutubeDLHTTPSHandler(params, context=context, **kwargs)\n        except TypeError:\n            # Python 2.7.8\n            # (create_default_context present but HTTPSHandler has no context=)\n            pass\n\n    if sys.version_info < (3, 2):\n        return YoutubeDLHTTPSHandler(params, **kwargs)\n    else:  # Python < 3.4\n        context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n        context.verify_mode = (ssl.CERT_NONE\n                               if opts_no_check_certificate\n                               else ssl.CERT_REQUIRED)\n        context.set_default_verify_paths()\n        return YoutubeDLHTTPSHandler(params, context=context, **kwargs)",
        "begin_line": 489,
        "end_line": 511,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004424778761061947,
            "pseudo_dstar_susp": 0.011494252873563218,
            "pseudo_tarantula_susp": 0.0010660980810234541,
            "pseudo_op2_susp": 0.011494252873563218,
            "pseudo_barinel_susp": 0.0010660980810234541
        }
    },
    {
        "name": "youtube_dl.utils.bug_reports_message#514",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.bug_reports_message()",
        "snippet": "def bug_reports_message():\n    if ytdl_is_updateable():\n        update_cmd = 'type  youtube-dl -U  to update'\n    else:\n        update_cmd = 'see  https://yt-dl.org/update  on how to update'\n    msg = '; please report this issue on https://yt-dl.org/bug .'\n    msg += ' Make sure you are using the latest version; %s.' % update_cmd\n    msg += ' Be sure to call youtube-dl with the --verbose flag and include its complete output.'\n    return msg",
        "begin_line": 514,
        "end_line": 522,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.007633587786259542,
            "pseudo_dstar_susp": 0.004672897196261682,
            "pseudo_tarantula_susp": 0.0014858841010401188,
            "pseudo_op2_susp": 0.004672897196261682,
            "pseudo_barinel_susp": 0.0014858841010401188
        }
    },
    {
        "name": "youtube_dl.utils.ExtractorError.__init__#528",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ExtractorError",
        "signature": "youtube_dl.utils.ExtractorError.__init__(self, msg, tb=None, expected=False, cause=None, video_id=None)",
        "snippet": "    def __init__(self, msg, tb=None, expected=False, cause=None, video_id=None):\n        \"\"\" tb, if given, is the original traceback (so that it can be printed out).\n        If expected is set, this is a normal error message and most likely not a bug in youtube-dl.\n        \"\"\"\n\n        if sys.exc_info()[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError):\n            expected = True\n        if video_id is not None:\n            msg = video_id + ': ' + msg\n        if cause:\n            msg += ' (caused by %r)' % cause\n        if not expected:\n            msg += bug_reports_message()\n        super(ExtractorError, self).__init__(msg)\n\n        self.traceback = tb\n        self.exc_info = sys.exc_info()  # preserve original exception\n        self.cause = cause\n        self.video_id = video_id",
        "begin_line": 528,
        "end_line": 546,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.009259259259259259,
            "pseudo_dstar_susp": 0.006134969325153374,
            "pseudo_tarantula_susp": 0.0017123287671232876,
            "pseudo_op2_susp": 0.006134969325153374,
            "pseudo_barinel_susp": 0.0017123287671232876
        }
    },
    {
        "name": "youtube_dl.utils.ExtractorError.format_traceback#548",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ExtractorError",
        "signature": "youtube_dl.utils.ExtractorError.format_traceback(self)",
        "snippet": "    def format_traceback(self):\n        if self.traceback is None:\n            return None\n        return ''.join(traceback.format_tb(self.traceback))",
        "begin_line": 548,
        "end_line": 551,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.011904761904761904,
            "pseudo_dstar_susp": 0.005291005291005291,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.005291005291005291,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.UnsupportedError.__init__#555",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.UnsupportedError",
        "signature": "youtube_dl.utils.UnsupportedError.__init__(self, url)",
        "snippet": "    def __init__(self, url):\n        super(UnsupportedError, self).__init__(\n            'Unsupported URL: %s' % url, expected=True)\n        self.url = url",
        "begin_line": 555,
        "end_line": 558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.DownloadError.__init__#574",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DownloadError",
        "signature": "youtube_dl.utils.DownloadError.__init__(self, msg, exc_info=None)",
        "snippet": "    def __init__(self, msg, exc_info=None):\n        \"\"\" exc_info, if given, is the original exception that caused the trouble (as returned by sys.exc_info()). \"\"\"\n        super(DownloadError, self).__init__(msg)\n        self.exc_info = exc_info",
        "begin_line": 574,
        "end_line": 577,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009930486593843098,
            "pseudo_dstar_susp": 0.000992063492063492,
            "pseudo_tarantula_susp": 0.0011337868480725624,
            "pseudo_op2_susp": 0.000992063492063492,
            "pseudo_barinel_susp": 0.0011337868480725624
        }
    },
    {
        "name": "youtube_dl.utils.PostProcessingError.__init__#596",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PostProcessingError",
        "signature": "youtube_dl.utils.PostProcessingError.__init__(self, msg)",
        "snippet": "    def __init__(self, msg):\n        self.msg = msg",
        "begin_line": 596,
        "end_line": 597,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.ContentTooShortError.__init__#622",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ContentTooShortError",
        "signature": "youtube_dl.utils.ContentTooShortError.__init__(self, downloaded, expected)",
        "snippet": "    def __init__(self, downloaded, expected):\n        # Both in bytes\n        self.downloaded = downloaded\n        self.expected = expected",
        "begin_line": 622,
        "end_line": 625,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils._create_http_connection#628",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._create_http_connection(ydl_handler, http_class, is_https, *args, **kwargs)",
        "snippet": "def _create_http_connection(ydl_handler, http_class, is_https, *args, **kwargs):\n    # Working around python 2 bug (see http://bugs.python.org/issue17849) by limiting\n    # expected HTTP responses to meet HTTP/1.0 or later (see also\n    # https://github.com/rg3/youtube-dl/issues/6727)\n    if sys.version_info < (3, 0):\n        kwargs[b'strict'] = True\n    hc = http_class(*args, **kwargs)\n    source_address = ydl_handler._params.get('source_address')\n    if source_address is not None:\n        sa = (source_address, 0)\n        if hasattr(hc, 'source_address'):  # Python 2.7+\n            hc.source_address = sa\n        else:  # Python 2.6\n            def _hc_connect(self, *args, **kwargs):\n                sock = compat_socket_create_connection(\n                    (self.host, self.port), self.timeout, sa)\n                if is_https:\n                    self.sock = ssl.wrap_socket(\n                        sock, self.key_file, self.cert_file,\n                        ssl_version=ssl.PROTOCOL_TLSv1)\n                else:\n                    self.sock = sock\n            hc.connect = functools.partial(_hc_connect, hc)\n\n    return hc",
        "begin_line": 628,
        "end_line": 652,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.037037037037037035,
            "pseudo_dstar_susp": 0.038461538461538464,
            "pseudo_tarantula_susp": 0.0015432098765432098,
            "pseudo_op2_susp": 0.038461538461538464,
            "pseudo_barinel_susp": 0.0015432098765432098
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.__init__#673",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.__init__(self, params, *args, **kwargs)",
        "snippet": "    def __init__(self, params, *args, **kwargs):\n        compat_urllib_request.HTTPHandler.__init__(self, *args, **kwargs)\n        self._params = params",
        "begin_line": 673,
        "end_line": 675,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004424778761061947,
            "pseudo_dstar_susp": 0.011494252873563218,
            "pseudo_tarantula_susp": 0.0010660980810234541,
            "pseudo_op2_susp": 0.011494252873563218,
            "pseudo_barinel_susp": 0.0010660980810234541
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_open#677",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_open(self, req)",
        "snippet": "    def http_open(self, req):\n        return self.do_open(functools.partial(\n            _create_http_connection, self, compat_http_client.HTTPConnection, False),\n            req)",
        "begin_line": 677,
        "end_line": 680,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003745318352059925,
            "pseudo_dstar_susp": 0.003676470588235294,
            "pseudo_tarantula_susp": 0.0014577259475218659,
            "pseudo_op2_susp": 0.003676470588235294,
            "pseudo_barinel_susp": 0.0014577259475218659
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.deflate#683",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.deflate(data)",
        "snippet": "    def deflate(data):\n        try:\n            return zlib.decompress(data, -zlib.MAX_WBITS)\n        except zlib.error:\n            return zlib.decompress(data)",
        "begin_line": 683,
        "end_line": 687,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.addinfourl_wrapper#690",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.addinfourl_wrapper(stream, headers, url, code)",
        "snippet": "    def addinfourl_wrapper(stream, headers, url, code):\n        if hasattr(compat_urllib_request.addinfourl, 'getcode'):\n            return compat_urllib_request.addinfourl(stream, headers, url, code)\n        ret = compat_urllib_request.addinfourl(stream, headers, url)\n        ret.code = code\n        return ret",
        "begin_line": 690,
        "end_line": 695,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.010416666666666666,
            "pseudo_dstar_susp": 0.004901960784313725,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.004901960784313725,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_request#697",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_request(self, req)",
        "snippet": "    def http_request(self, req):\n        # According to RFC 3986, URLs can not contain non-ASCII characters, however this is not\n        # always respected by websites, some tend to give out URLs with non percent-encoded\n        # non-ASCII characters (see telemb.py, ard.py [#3412])\n        # urllib chokes on URLs with non-ASCII characters (see http://bugs.python.org/issue3991)\n        # To work around aforementioned issue we will replace request's original URL with\n        # percent-encoded one\n        # Since redirects are also affected (e.g. http://www.southpark.de/alle-episoden/s18e09)\n        # the code of this workaround has been moved here from YoutubeDL.urlopen()\n        url = req.get_full_url()\n        url_escaped = escape_url(url)\n\n        # Substitute URL if any change after escaping\n        if url != url_escaped:\n            req_type = HEADRequest if req.get_method() == 'HEAD' else compat_urllib_request.Request\n            new_req = req_type(\n                url_escaped, data=req.data, headers=req.headers,\n                origin_req_host=req.origin_req_host, unverifiable=req.unverifiable)\n            new_req.timeout = req.timeout\n            req = new_req\n\n        for h, v in std_headers.items():\n            # Capitalize is needed because of Python bug 2275: http://bugs.python.org/issue2275\n            # The dict keys are capitalized because of this bug by urllib\n            if h.capitalize() not in req.headers:\n                req.add_header(h, v)\n        if 'Youtubedl-no-compression' in req.headers:\n            if 'Accept-encoding' in req.headers:\n                del req.headers['Accept-encoding']\n            del req.headers['Youtubedl-no-compression']\n\n        if sys.version_info < (2, 7) and '#' in req.get_full_url():\n            # Python 2.6 is brain-dead when it comes to fragments\n            req._Request__original = req._Request__original.partition('#')[0]\n            req._Request__r_type = req._Request__r_type.partition('#')[0]\n\n        return req",
        "begin_line": 697,
        "end_line": 733,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.037037037037037035,
            "pseudo_dstar_susp": 0.038461538461538464,
            "pseudo_tarantula_susp": 0.0015432098765432098,
            "pseudo_op2_susp": 0.038461538461538464,
            "pseudo_barinel_susp": 0.0015432098765432098
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_response#735",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_response(self, req, resp)",
        "snippet": "    def http_response(self, req, resp):\n        old_resp = resp\n        # gzip\n        if resp.headers.get('Content-encoding', '') == 'gzip':\n            content = resp.read()\n            gz = gzip.GzipFile(fileobj=io.BytesIO(content), mode='rb')\n            try:\n                uncompressed = io.BytesIO(gz.read())\n            except IOError as original_ioerror:\n                # There may be junk add the end of the file\n                # See http://stackoverflow.com/q/4928560/35070 for details\n                for i in range(1, 1024):\n                    try:\n                        gz = gzip.GzipFile(fileobj=io.BytesIO(content[:-i]), mode='rb')\n                        uncompressed = io.BytesIO(gz.read())\n                    except IOError:\n                        continue\n                    break\n                else:\n                    raise original_ioerror\n            resp = self.addinfourl_wrapper(uncompressed, old_resp.headers, old_resp.url, old_resp.code)\n            resp.msg = old_resp.msg\n        # deflate\n        if resp.headers.get('Content-encoding', '') == 'deflate':\n            gz = io.BytesIO(self.deflate(resp.read()))\n            resp = self.addinfourl_wrapper(gz, old_resp.headers, old_resp.url, old_resp.code)\n            resp.msg = old_resp.msg\n        # Percent-encode redirect URL of Location HTTP header to satisfy RFC 3986 (see\n        # https://github.com/rg3/youtube-dl/issues/6457).\n        if 300 <= resp.code < 400:\n            location = resp.headers.get('Location')\n            if location:\n                # As of RFC 2616 default charset is iso-8859-1 that is respected by python 3\n                if sys.version_info >= (3, 0):\n                    location = location.encode('iso-8859-1').decode('utf-8')\n                location_escaped = escape_url(location)\n                if location != location_escaped:\n                    del resp.headers['Location']\n                    resp.headers['Location'] = location_escaped\n        return resp",
        "begin_line": 735,
        "end_line": 774,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0136986301369863,
            "pseudo_dstar_susp": 0.0064516129032258064,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0064516129032258064,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHTTPSHandler.__init__#781",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHTTPSHandler",
        "signature": "youtube_dl.utils.YoutubeDLHTTPSHandler.__init__(self, params, https_conn_class=None, *args, **kwargs)",
        "snippet": "    def __init__(self, params, https_conn_class=None, *args, **kwargs):\n        compat_urllib_request.HTTPSHandler.__init__(self, *args, **kwargs)\n        self._https_conn_class = https_conn_class or compat_http_client.HTTPSConnection\n        self._params = params",
        "begin_line": 781,
        "end_line": 784,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004424778761061947,
            "pseudo_dstar_susp": 0.011494252873563218,
            "pseudo_tarantula_susp": 0.0010660980810234541,
            "pseudo_op2_susp": 0.011494252873563218,
            "pseudo_barinel_susp": 0.0010660980810234541
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHTTPSHandler.https_open#786",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHTTPSHandler",
        "signature": "youtube_dl.utils.YoutubeDLHTTPSHandler.https_open(self, req)",
        "snippet": "    def https_open(self, req):\n        kwargs = {}\n        if hasattr(self, '_context'):  # python > 2.6\n            kwargs['context'] = self._context\n        if hasattr(self, '_check_hostname'):  # python 3.x\n            kwargs['check_hostname'] = self._check_hostname\n        return self.do_open(functools.partial(\n            _create_http_connection, self, self._https_conn_class, True),\n            req, **kwargs)",
        "begin_line": 786,
        "end_line": 794,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.011904761904761904,
            "pseudo_dstar_susp": 0.005291005291005291,
            "pseudo_tarantula_susp": 0.001763668430335097,
            "pseudo_op2_susp": 0.005291005291005291,
            "pseudo_barinel_susp": 0.001763668430335097
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLCookieProcessor.__init__#798",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLCookieProcessor",
        "signature": "youtube_dl.utils.YoutubeDLCookieProcessor.__init__(self, cookiejar=None)",
        "snippet": "    def __init__(self, cookiejar=None):\n        compat_urllib_request.HTTPCookieProcessor.__init__(self, cookiejar)",
        "begin_line": 798,
        "end_line": 799,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004424778761061947,
            "pseudo_dstar_susp": 0.011494252873563218,
            "pseudo_tarantula_susp": 0.0010660980810234541,
            "pseudo_op2_susp": 0.011494252873563218,
            "pseudo_barinel_susp": 0.0010660980810234541
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLCookieProcessor.http_response#801",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLCookieProcessor",
        "signature": "youtube_dl.utils.YoutubeDLCookieProcessor.http_response(self, request, response)",
        "snippet": "    def http_response(self, request, response):\n        # Python 2 will choke on next HTTP request in row if there are non-ASCII\n        # characters in Set-Cookie HTTP header of last response (see\n        # https://github.com/rg3/youtube-dl/issues/6769).\n        # In order to at least prevent crashing we will percent encode Set-Cookie\n        # header before HTTPCookieProcessor starts processing it.\n        # if sys.version_info < (3, 0) and response.headers:\n        #     for set_cookie_header in ('Set-Cookie', 'Set-Cookie2'):\n        #         set_cookie = response.headers.get(set_cookie_header)\n        #         if set_cookie:\n        #             set_cookie_escaped = compat_urllib_parse.quote(set_cookie, b\"%/;:@&=+$,!~*'()?#[] \")\n        #             if set_cookie != set_cookie_escaped:\n        #                 del response.headers[set_cookie_header]\n        #                 response.headers[set_cookie_header] = set_cookie_escaped\n        return compat_urllib_request.HTTPCookieProcessor.http_response(self, request, response)",
        "begin_line": 801,
        "end_line": 815,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0136986301369863,
            "pseudo_dstar_susp": 0.0064516129032258064,
            "pseudo_tarantula_susp": 0.0015037593984962407,
            "pseudo_op2_susp": 0.0064516129032258064,
            "pseudo_barinel_susp": 0.0015037593984962407
        }
    },
    {
        "name": "youtube_dl.utils.parse_iso8601#821",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_iso8601(date_str, delimiter='T', timezone=None)",
        "snippet": "def parse_iso8601(date_str, delimiter='T', timezone=None):\n    \"\"\" Return a UNIX timestamp from the given date \"\"\"\n\n    if date_str is None:\n        return None\n\n    date_str = re.sub(r'\\.[0-9]+', '', date_str)\n\n    if timezone is None:\n        m = re.search(\n            r'(?:Z$| ?(?P<sign>\\+|-)(?P<hours>[0-9]{2}):?(?P<minutes>[0-9]{2})$)',\n            date_str)\n        if not m:\n            timezone = datetime.timedelta()\n        else:\n            date_str = date_str[:-len(m.group(0))]\n            if not m.group('sign'):\n                timezone = datetime.timedelta()\n            else:\n                sign = 1 if m.group('sign') == '+' else -1\n                timezone = datetime.timedelta(\n                    hours=sign * int(m.group('hours')),\n                    minutes=sign * int(m.group('minutes')))\n    try:\n        date_format = '%Y-%m-%d{0}%H:%M:%S'.format(delimiter)\n        dt = datetime.datetime.strptime(date_str, date_format) - timezone\n        return calendar.timegm(dt.timetuple())\n    except ValueError:\n        pass",
        "begin_line": 821,
        "end_line": 849,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001445086705202312,
            "pseudo_dstar_susp": 0.00141643059490085,
            "pseudo_tarantula_susp": 0.001226993865030675,
            "pseudo_op2_susp": 0.00141643059490085,
            "pseudo_barinel_susp": 0.0012254901960784314
        }
    },
    {
        "name": "youtube_dl.utils.unified_strdate#852",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unified_strdate(date_str, day_first=True)",
        "snippet": "def unified_strdate(date_str, day_first=True):\n    \"\"\"Return a string with the date in the format YYYYMMDD\"\"\"\n\n    if date_str is None:\n        return None\n    upload_date = None\n    # Replace commas\n    date_str = date_str.replace(',', ' ')\n    # %z (UTC offset) is only supported in python>=3.2\n    if not re.match(r'^[0-9]{1,2}-[0-9]{1,2}-[0-9]{4}$', date_str):\n        date_str = re.sub(r' ?(\\+|-)[0-9]{2}:?[0-9]{2}$', '', date_str)\n    # Remove AM/PM + timezone\n    date_str = re.sub(r'(?i)\\s*(?:AM|PM)(?:\\s+[A-Z]+)?', '', date_str)\n\n    format_expressions = [\n        '%d %B %Y',\n        '%d %b %Y',\n        '%B %d %Y',\n        '%b %d %Y',\n        '%b %dst %Y %I:%M%p',\n        '%b %dnd %Y %I:%M%p',\n        '%b %dth %Y %I:%M%p',\n        '%Y %m %d',\n        '%Y-%m-%d',\n        '%Y/%m/%d',\n        '%Y/%m/%d %H:%M:%S',\n        '%Y-%m-%d %H:%M:%S',\n        '%Y-%m-%d %H:%M:%S.%f',\n        '%d.%m.%Y %H:%M',\n        '%d.%m.%Y %H.%M',\n        '%Y-%m-%dT%H:%M:%SZ',\n        '%Y-%m-%dT%H:%M:%S.%fZ',\n        '%Y-%m-%dT%H:%M:%S.%f0Z',\n        '%Y-%m-%dT%H:%M:%S',\n        '%Y-%m-%dT%H:%M:%S.%f',\n        '%Y-%m-%dT%H:%M',\n    ]\n    if day_first:\n        format_expressions.extend([\n            '%d-%m-%Y',\n            '%d.%m.%Y',\n            '%d/%m/%Y',\n            '%d/%m/%y',\n            '%d/%m/%Y %H:%M:%S',\n        ])\n    else:\n        format_expressions.extend([\n            '%m-%d-%Y',\n            '%m.%d.%Y',\n            '%m/%d/%Y',\n            '%m/%d/%y',\n            '%m/%d/%Y %H:%M:%S',\n        ])\n    for expression in format_expressions:\n        try:\n            upload_date = datetime.datetime.strptime(date_str, expression).strftime('%Y%m%d')\n        except ValueError:\n            pass\n    if upload_date is None:\n        timetuple = email.utils.parsedate_tz(date_str)\n        if timetuple:\n            upload_date = datetime.datetime(*timetuple[:6]).strftime('%Y%m%d')\n    return compat_str(upload_date)",
        "begin_line": 852,
        "end_line": 914,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.002564102564102564,
            "pseudo_dstar_susp": 0.0024813895781637717,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0024813895781637717,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.determine_ext#917",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.determine_ext(url, default_ext='unknown_video')",
        "snippet": "def determine_ext(url, default_ext='unknown_video'):\n    if url is None:\n        return default_ext\n    guess = url.partition('?')[0].rpartition('.')[2]\n    if re.match(r'^[A-Za-z0-9]+$', guess):\n        return guess\n    else:\n        return default_ext",
        "begin_line": 917,
        "end_line": 924,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 4.118446521971912e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.subtitles_filename#927",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.subtitles_filename(filename, sub_lang, sub_format)",
        "snippet": "def subtitles_filename(filename, sub_lang, sub_format):\n    return filename.rsplit('.', 1)[0] + '.' + sub_lang + '.' + sub_format",
        "begin_line": 927,
        "end_line": 928,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.date_from_str#931",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.date_from_str(date_str)",
        "snippet": "def date_from_str(date_str):\n    \"\"\"\n    Return a datetime object from a string in the format YYYYMMDD or\n    (now|today)[+-][0-9](day|week|month|year)(s)?\"\"\"\n    today = datetime.date.today()\n    if date_str in ('now', 'today'):\n        return today\n    if date_str == 'yesterday':\n        return today - datetime.timedelta(days=1)\n    match = re.match('(now|today)(?P<sign>[+-])(?P<time>\\d+)(?P<unit>day|week|month|year)(s)?', date_str)\n    if match is not None:\n        sign = match.group('sign')\n        time = int(match.group('time'))\n        if sign == '-':\n            time = -time\n        unit = match.group('unit')\n        # A bad aproximation?\n        if unit == 'month':\n            unit = 'day'\n            time *= 30\n        elif unit == 'year':\n            unit = 'day'\n            time *= 365\n        unit += 's'\n        delta = datetime.timedelta(**{unit: time})\n        return today + delta\n    return datetime.datetime.strptime(date_str, \"%Y%m%d\").date()",
        "begin_line": 931,
        "end_line": 957,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.hyphenate_date#960",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.hyphenate_date(date_str)",
        "snippet": "def hyphenate_date(date_str):\n    \"\"\"\n    Convert a date in 'YYYYMMDD' format to 'YYYY-MM-DD' format\"\"\"\n    match = re.match(r'^(\\d\\d\\d\\d)(\\d\\d)(\\d\\d)$', date_str)\n    if match is not None:\n        return '-'.join(match.groups())\n    else:\n        return date_str",
        "begin_line": 960,
        "end_line": 967,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__init__#973",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__init__(self, start=None, end=None)",
        "snippet": "    def __init__(self, start=None, end=None):\n        \"\"\"start and end must be strings in the format accepted by date\"\"\"\n        if start is not None:\n            self.start = date_from_str(start)\n        else:\n            self.start = datetime.datetime.min.date()\n        if end is not None:\n            self.end = date_from_str(end)\n        else:\n            self.end = datetime.datetime.max.date()\n        if self.start > self.end:\n            raise ValueError('Date range: \"%s\" , the start date must be before the end date' % self)",
        "begin_line": 973,
        "end_line": 984,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.day#987",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.day(cls, day)",
        "snippet": "    def day(cls, day):\n        \"\"\"Returns a range that only contains the given day\"\"\"\n        return cls(day, day)",
        "begin_line": 987,
        "end_line": 989,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__contains__#991",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__contains__(self, date)",
        "snippet": "    def __contains__(self, date):\n        \"\"\"Check if the date is in the range\"\"\"\n        if not isinstance(date, datetime.date):\n            date = date_from_str(date)\n        return self.start <= date <= self.end",
        "begin_line": 991,
        "end_line": 995,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__str__#997",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__str__(self)",
        "snippet": "    def __str__(self):\n        return '%s - %s' % (self.start.isoformat(), self.end.isoformat())",
        "begin_line": 997,
        "end_line": 998,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.platform_name#1001",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.platform_name()",
        "snippet": "def platform_name():\n    \"\"\" Returns the platform name as a compat_str \"\"\"\n    res = platform.platform()\n    if isinstance(res, bytes):\n        res = res.decode(preferredencoding())\n\n    assert isinstance(res, compat_str)\n    return res",
        "begin_line": 1001,
        "end_line": 1008,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils._windows_write_string#1011",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._windows_write_string(s, out)",
        "snippet": "def _windows_write_string(s, out):\n    \"\"\" Returns True if the string was written using special methods,\n    False if it has yet to be written out.\"\"\"\n    # Adapted from http://stackoverflow.com/a/3259271/35070\n\n    import ctypes\n    import ctypes.wintypes\n\n    WIN_OUTPUT_IDS = {\n        1: -11,\n        2: -12,\n    }\n\n    try:\n        fileno = out.fileno()\n    except AttributeError:\n        # If the output stream doesn't have a fileno, it's virtual\n        return False\n    except io.UnsupportedOperation:\n        # Some strange Windows pseudo files?\n        return False\n    if fileno not in WIN_OUTPUT_IDS:\n        return False\n\n    GetStdHandle = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.HANDLE, ctypes.wintypes.DWORD)(\n        (b\"GetStdHandle\", ctypes.windll.kernel32))\n    h = GetStdHandle(WIN_OUTPUT_IDS[fileno])\n\n    WriteConsoleW = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.BOOL, ctypes.wintypes.HANDLE, ctypes.wintypes.LPWSTR,\n        ctypes.wintypes.DWORD, ctypes.POINTER(ctypes.wintypes.DWORD),\n        ctypes.wintypes.LPVOID)((b\"WriteConsoleW\", ctypes.windll.kernel32))\n    written = ctypes.wintypes.DWORD(0)\n\n    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)((b\"GetFileType\", ctypes.windll.kernel32))\n    FILE_TYPE_CHAR = 0x0002\n    FILE_TYPE_REMOTE = 0x8000\n    GetConsoleMode = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.BOOL, ctypes.wintypes.HANDLE,\n        ctypes.POINTER(ctypes.wintypes.DWORD))(\n        (b\"GetConsoleMode\", ctypes.windll.kernel32))\n    INVALID_HANDLE_VALUE = ctypes.wintypes.DWORD(-1).value\n\n    def not_a_console(handle):\n        if handle == INVALID_HANDLE_VALUE or handle is None:\n            return True\n        return ((GetFileType(handle) & ~FILE_TYPE_REMOTE) != FILE_TYPE_CHAR or\n                GetConsoleMode(handle, ctypes.byref(ctypes.wintypes.DWORD())) == 0)\n\n    if not_a_console(h):\n        return False\n\n    def next_nonbmp_pos(s):\n        try:\n            return next(i for i, c in enumerate(s) if ord(c) > 0xffff)\n        except StopIteration:\n            return len(s)\n\n    while s:\n        count = min(next_nonbmp_pos(s), 1024)\n\n        ret = WriteConsoleW(\n            h, s, count if count else 2, ctypes.byref(written), None)\n        if ret == 0:\n            raise OSError('Failed to write string')\n        if not count:  # We just wrote a non-BMP character\n            assert written.value == 2\n            s = s[1:]\n        else:\n            assert written.value > 0\n            s = s[written.value:]\n    return True",
        "begin_line": 1011,
        "end_line": 1083,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.write_string#1086",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_string(s, out=None, encoding=None)",
        "snippet": "def write_string(s, out=None, encoding=None):\n    if out is None:\n        out = sys.stderr\n    assert type(s) == compat_str\n\n    if sys.platform == 'win32' and encoding is None and hasattr(out, 'fileno'):\n        if _windows_write_string(s, out):\n            return\n\n    if ('b' in getattr(out, 'mode', '') or\n            sys.version_info[0] < 3):  # Python 2 lies about mode of sys.stderr\n        byt = s.encode(encoding or preferredencoding(), 'ignore')\n        out.write(byt)\n    elif hasattr(out, 'buffer'):\n        enc = encoding or getattr(out, 'encoding', None) or preferredencoding()\n        byt = s.encode(enc, 'ignore')\n        out.buffer.write(byt)\n    else:\n        out.write(s)\n    out.flush()",
        "begin_line": 1086,
        "end_line": 1105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024691358024691358,
            "pseudo_dstar_susp": 0.002421307506053269,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.002421307506053269,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.bytes_to_intlist#1108",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.bytes_to_intlist(bs)",
        "snippet": "def bytes_to_intlist(bs):\n    if not bs:\n        return []\n    if isinstance(bs[0], int):  # Python 3\n        return list(bs)\n    else:\n        return [ord(c) for c in bs]",
        "begin_line": 1108,
        "end_line": 1114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.intlist_to_bytes#1117",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.intlist_to_bytes(xs)",
        "snippet": "def intlist_to_bytes(xs):\n    if not xs:\n        return b''\n    return struct_pack('%dB' % len(xs), *xs)",
        "begin_line": 1117,
        "end_line": 1120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils._lock_file#1181",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._lock_file(f, exclusive)",
        "snippet": "    def _lock_file(f, exclusive):\n        fcntl.flock(f, fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH)",
        "begin_line": 1181,
        "end_line": 1182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils._unlock_file#1184",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._unlock_file(f)",
        "snippet": "    def _unlock_file(f):\n        fcntl.flock(f, fcntl.LOCK_UN)",
        "begin_line": 1184,
        "end_line": 1185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__init__#1189",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__init__(self, filename, mode, encoding=None)",
        "snippet": "    def __init__(self, filename, mode, encoding=None):\n        assert mode in ['r', 'a', 'w']\n        self.f = io.open(filename, mode, encoding=encoding)\n        self.mode = mode",
        "begin_line": 1189,
        "end_line": 1192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__enter__#1194",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__enter__(self)",
        "snippet": "    def __enter__(self):\n        exclusive = self.mode != 'r'\n        try:\n            _lock_file(self.f, exclusive)\n        except IOError:\n            self.f.close()\n            raise\n        return self",
        "begin_line": 1194,
        "end_line": 1201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__exit__#1203",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__exit__(self, etype, value, traceback)",
        "snippet": "    def __exit__(self, etype, value, traceback):\n        try:\n            _unlock_file(self.f)\n        finally:\n            self.f.close()",
        "begin_line": 1203,
        "end_line": 1207,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__iter__#1209",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return iter(self.f)",
        "begin_line": 1209,
        "end_line": 1210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.write#1212",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.write(self, *args)",
        "snippet": "    def write(self, *args):\n        return self.f.write(*args)",
        "begin_line": 1212,
        "end_line": 1213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.read#1215",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.read(self, *args)",
        "snippet": "    def read(self, *args):\n        return self.f.read(*args)",
        "begin_line": 1215,
        "end_line": 1216,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.get_filesystem_encoding#1219",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_filesystem_encoding()",
        "snippet": "def get_filesystem_encoding():\n    encoding = sys.getfilesystemencoding()\n    return encoding if encoding is not None else 'utf-8'",
        "begin_line": 1219,
        "end_line": 1221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.shell_quote#1224",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.shell_quote(args)",
        "snippet": "def shell_quote(args):\n    quoted_args = []\n    encoding = get_filesystem_encoding()\n    for a in args:\n        if isinstance(a, bytes):\n            # We may get a filename encoded with 'encodeFilename'\n            a = a.decode(encoding)\n        quoted_args.append(pipes.quote(a))\n    return ' '.join(quoted_args)",
        "begin_line": 1224,
        "end_line": 1232,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.smuggle_url#1235",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.smuggle_url(url, data)",
        "snippet": "def smuggle_url(url, data):\n    \"\"\" Pass additional data in a URL for internal use. \"\"\"\n\n    sdata = compat_urllib_parse.urlencode(\n        {'__youtubedl_smuggle': json.dumps(data)})\n    return url + '#' + sdata",
        "begin_line": 1235,
        "end_line": 1240,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.unsmuggle_url#1243",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unsmuggle_url(smug_url, default=None)",
        "snippet": "def unsmuggle_url(smug_url, default=None):\n    if '#__youtubedl_smuggle' not in smug_url:\n        return smug_url, default\n    url, _, sdata = smug_url.rpartition('#')\n    jsond = compat_parse_qs(sdata)['__youtubedl_smuggle'][0]\n    data = json.loads(jsond)\n    return url, data",
        "begin_line": 1243,
        "end_line": 1249,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0029154518950437317,
            "pseudo_dstar_susp": 0.003355704697986577,
            "pseudo_tarantula_susp": 0.0013003901170351106,
            "pseudo_op2_susp": 0.003355704697986577,
            "pseudo_barinel_susp": 0.0013003901170351106
        }
    },
    {
        "name": "youtube_dl.utils.format_bytes#1252",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.format_bytes(bytes)",
        "snippet": "def format_bytes(bytes):\n    if bytes is None:\n        return 'N/A'\n    if type(bytes) is str:\n        bytes = float(bytes)\n    if bytes == 0.0:\n        exponent = 0\n    else:\n        exponent = int(math.log(bytes, 1024.0))\n    suffix = ['B', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB', 'EiB', 'ZiB', 'YiB'][exponent]\n    converted = float(bytes) / float(1024 ** exponent)\n    return '%.2f%s' % (converted, suffix)",
        "begin_line": 1252,
        "end_line": 1263,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.parse_filesize#1266",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_filesize(s)",
        "snippet": "def parse_filesize(s):\n    if s is None:\n        return None\n\n    # The lower-case forms are of course incorrect and inofficial,\n    # but we support those too\n    _UNIT_TABLE = {\n        'B': 1,\n        'b': 1,\n        'KiB': 1024,\n        'KB': 1000,\n        'kB': 1024,\n        'Kb': 1000,\n        'MiB': 1024 ** 2,\n        'MB': 1000 ** 2,\n        'mB': 1024 ** 2,\n        'Mb': 1000 ** 2,\n        'GiB': 1024 ** 3,\n        'GB': 1000 ** 3,\n        'gB': 1024 ** 3,\n        'Gb': 1000 ** 3,\n        'TiB': 1024 ** 4,\n        'TB': 1000 ** 4,\n        'tB': 1024 ** 4,\n        'Tb': 1000 ** 4,\n        'PiB': 1024 ** 5,\n        'PB': 1000 ** 5,\n        'pB': 1024 ** 5,\n        'Pb': 1000 ** 5,\n        'EiB': 1024 ** 6,\n        'EB': 1000 ** 6,\n        'eB': 1024 ** 6,\n        'Eb': 1000 ** 6,\n        'ZiB': 1024 ** 7,\n        'ZB': 1000 ** 7,\n        'zB': 1024 ** 7,\n        'Zb': 1000 ** 7,\n        'YiB': 1024 ** 8,\n        'YB': 1000 ** 8,\n        'yB': 1024 ** 8,\n        'Yb': 1000 ** 8,\n    }\n\n    units_re = '|'.join(re.escape(u) for u in _UNIT_TABLE)\n    m = re.match(\n        r'(?P<num>[0-9]+(?:[,.][0-9]*)?)\\s*(?P<unit>%s)' % units_re, s)\n    if not m:\n        return None\n\n    num_str = m.group('num').replace(',', '.')\n    mult = _UNIT_TABLE[m.group('unit')]\n    return int(float(num_str) * mult)",
        "begin_line": 1266,
        "end_line": 1317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.month_by_name#1320",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.month_by_name(name)",
        "snippet": "def month_by_name(name):\n    \"\"\" Return the number of a month by (locale-independently) English name \"\"\"\n\n    try:\n        return ENGLISH_MONTH_NAMES.index(name) + 1\n    except ValueError:\n        return None",
        "begin_line": 1320,
        "end_line": 1326,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.month_by_abbreviation#1329",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.month_by_abbreviation(abbrev)",
        "snippet": "def month_by_abbreviation(abbrev):\n    \"\"\" Return the number of a month by (locale-independently) English\n        abbreviations \"\"\"\n\n    try:\n        return [s[:3] for s in ENGLISH_MONTH_NAMES].index(abbrev) + 1\n    except ValueError:\n        return None",
        "begin_line": 1329,
        "end_line": 1336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.fix_xml_ampersands#1339",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fix_xml_ampersands(xml_str)",
        "snippet": "def fix_xml_ampersands(xml_str):\n    \"\"\"Replace all the '&' by '&amp;' in XML\"\"\"\n    return re.sub(\n        r'&(?!amp;|lt;|gt;|apos;|quot;|#x[0-9a-fA-F]{,4};|#[0-9]{,4};)',\n        '&amp;',\n        xml_str)",
        "begin_line": 1339,
        "end_line": 1344,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.setproctitle#1347",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.setproctitle(title)",
        "snippet": "def setproctitle(title):\n    assert isinstance(title, compat_str)\n    try:\n        libc = ctypes.cdll.LoadLibrary(\"libc.so.6\")\n    except OSError:\n        return\n    title_bytes = title.encode('utf-8')\n    buf = ctypes.create_string_buffer(len(title_bytes))\n    buf.value = title_bytes\n    try:\n        libc.prctl(15, buf, 0, 0, 0)\n    except AttributeError:\n        return  # Strange libc, just skip this",
        "begin_line": 1347,
        "end_line": 1359,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.remove_start#1362",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.remove_start(s, start)",
        "snippet": "def remove_start(s, start):\n    if s.startswith(start):\n        return s[len(start):]\n    return s",
        "begin_line": 1362,
        "end_line": 1365,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.remove_end#1368",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.remove_end(s, end)",
        "snippet": "def remove_end(s, end):\n    if s.endswith(end):\n        return s[:-len(end)]\n    return s",
        "begin_line": 1368,
        "end_line": 1371,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.url_basename#1374",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.url_basename(url)",
        "snippet": "def url_basename(url):\n    path = compat_urlparse.urlparse(url).path\n    return path.strip('/').split('/')[-1]",
        "begin_line": 1374,
        "end_line": 1376,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009596928982725527,
            "pseudo_dstar_susp": 0.0009587727708533077,
            "pseudo_tarantula_susp": 0.0009624639076034649,
            "pseudo_op2_susp": 0.0009587727708533077,
            "pseudo_barinel_susp": 0.0009624639076034649
        }
    },
    {
        "name": "youtube_dl.utils.HEADRequest.get_method#1380",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.HEADRequest",
        "signature": "youtube_dl.utils.HEADRequest.get_method(self)",
        "snippet": "    def get_method(self):\n        return \"HEAD\"",
        "begin_line": 1380,
        "end_line": 1381,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.int_or_none#1384",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.int_or_none(v, scale=1, default=None, get_attr=None, invscale=1)",
        "snippet": "def int_or_none(v, scale=1, default=None, get_attr=None, invscale=1):\n    if get_attr:\n        if v is not None:\n            v = getattr(v, get_attr, None)\n    if v == '':\n        v = None\n    if v is None:\n        return default\n    try:\n        return int(v) * invscale // scale\n    except ValueError:\n        return default",
        "begin_line": 1384,
        "end_line": 1395,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024691358024691358,
            "pseudo_dstar_susp": 0.002421307506053269,
            "pseudo_tarantula_susp": 0.0013774104683195593,
            "pseudo_op2_susp": 0.002421307506053269,
            "pseudo_barinel_susp": 0.0013774104683195593
        }
    },
    {
        "name": "youtube_dl.utils.str_or_none#1398",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.str_or_none(v, default=None)",
        "snippet": "def str_or_none(v, default=None):\n    return default if v is None else compat_str(v)",
        "begin_line": 1398,
        "end_line": 1399,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.str_to_int#1402",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.str_to_int(int_str)",
        "snippet": "def str_to_int(int_str):\n    \"\"\" A more relaxed version of int_or_none \"\"\"\n    if int_str is None:\n        return None\n    int_str = re.sub(r'[,\\.\\+]', '', int_str)\n    return int(int_str)",
        "begin_line": 1402,
        "end_line": 1407,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.float_or_none#1410",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.float_or_none(v, scale=1, invscale=1, default=None)",
        "snippet": "def float_or_none(v, scale=1, invscale=1, default=None):\n    if v is None:\n        return default\n    try:\n        return float(v) * invscale / scale\n    except ValueError:\n        return default",
        "begin_line": 1410,
        "end_line": 1416,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.parse_duration#1419",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_duration(s)",
        "snippet": "def parse_duration(s):\n    if not isinstance(s, compat_basestring):\n        return None\n\n    s = s.strip()\n\n    m = re.match(\n        r'''(?ix)(?:P?T)?\n        (?:\n            (?P<only_mins>[0-9.]+)\\s*(?:mins?\\.?|minutes?)\\s*|\n            (?P<only_hours>[0-9.]+)\\s*(?:hours?)|\n\n            \\s*(?P<hours_reversed>[0-9]+)\\s*(?:[:h]|hours?)\\s*(?P<mins_reversed>[0-9]+)\\s*(?:[:m]|mins?\\.?|minutes?)\\s*|\n            (?:\n                (?:\n                    (?:(?P<days>[0-9]+)\\s*(?:[:d]|days?)\\s*)?\n                    (?P<hours>[0-9]+)\\s*(?:[:h]|hours?)\\s*\n                )?\n                (?P<mins>[0-9]+)\\s*(?:[:m]|mins?|minutes?)\\s*\n            )?\n            (?P<secs>[0-9]+)(?P<ms>\\.[0-9]+)?\\s*(?:s|secs?|seconds?)?\n        )$''', s)\n    if not m:\n        return None\n    res = 0\n    if m.group('only_mins'):\n        return float_or_none(m.group('only_mins'), invscale=60)\n    if m.group('only_hours'):\n        return float_or_none(m.group('only_hours'), invscale=60 * 60)\n    if m.group('secs'):\n        res += int(m.group('secs'))\n    if m.group('mins_reversed'):\n        res += int(m.group('mins_reversed')) * 60\n    if m.group('mins'):\n        res += int(m.group('mins')) * 60\n    if m.group('hours'):\n        res += int(m.group('hours')) * 60 * 60\n    if m.group('hours_reversed'):\n        res += int(m.group('hours_reversed')) * 60 * 60\n    if m.group('days'):\n        res += int(m.group('days')) * 24 * 60 * 60\n    if m.group('ms'):\n        res += float(m.group('ms'))\n    return res",
        "begin_line": 1419,
        "end_line": 1462,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.prepend_extension#1465",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.prepend_extension(filename, ext, expected_real_ext=None)",
        "snippet": "def prepend_extension(filename, ext, expected_real_ext=None):\n    name, real_ext = os.path.splitext(filename)\n    return (\n        '{0}.{1}{2}'.format(name, ext, real_ext)\n        if not expected_real_ext or real_ext[1:] == expected_real_ext\n        else '{0}.{1}'.format(filename, ext))",
        "begin_line": 1465,
        "end_line": 1470,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.replace_extension#1473",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.replace_extension(filename, ext, expected_real_ext=None)",
        "snippet": "def replace_extension(filename, ext, expected_real_ext=None):\n    name, real_ext = os.path.splitext(filename)\n    return '{0}.{1}'.format(\n        name if not expected_real_ext or real_ext[1:] == expected_real_ext else filename,\n        ext)",
        "begin_line": 1473,
        "end_line": 1477,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.check_executable#1480",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.check_executable(exe, args=[])",
        "snippet": "def check_executable(exe, args=[]):\n    \"\"\" Checks if the given binary is installed somewhere in PATH, and returns its name.\n    args can be a list of arguments for a short output (like -version) \"\"\"\n    try:\n        subprocess.Popen([exe] + args, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n    except OSError:\n        return False\n    return exe",
        "begin_line": 1480,
        "end_line": 1487,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.get_exe_version#1490",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_exe_version(exe, args=['--version'], version_re=None, unrecognized='present')",
        "snippet": "def get_exe_version(exe, args=['--version'],\n                    version_re=None, unrecognized='present'):\n    \"\"\" Returns the version of the specified executable,\n    or False if the executable is not present \"\"\"\n    try:\n        out, _ = subprocess.Popen(\n            [encodeArgument(exe)] + args,\n            stdout=subprocess.PIPE, stderr=subprocess.STDOUT).communicate()\n    except OSError:\n        return False\n    if isinstance(out, bytes):  # Python 2.x\n        out = out.decode('ascii', 'ignore')\n    return detect_exe_version(out, version_re, unrecognized)",
        "begin_line": 1490,
        "end_line": 1502,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011750881316098707,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.utils.detect_exe_version#1505",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.detect_exe_version(output, version_re=None, unrecognized='present')",
        "snippet": "def detect_exe_version(output, version_re=None, unrecognized='present'):\n    assert isinstance(output, compat_str)\n    if version_re is None:\n        version_re = r'version\\s+([-0-9._a-zA-Z]+)'\n    m = re.search(version_re, output)\n    if m:\n        return m.group(1)\n    else:\n        return unrecognized",
        "begin_line": 1505,
        "end_line": 1513,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.PagedList.__len__#1517",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PagedList",
        "signature": "youtube_dl.utils.PagedList.__len__(self)",
        "snippet": "    def __len__(self):\n        # This is only useful for tests\n        return len(self.getslice())",
        "begin_line": 1517,
        "end_line": 1519,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.OnDemandPagedList.__init__#1523",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.OnDemandPagedList",
        "signature": "youtube_dl.utils.OnDemandPagedList.__init__(self, pagefunc, pagesize)",
        "snippet": "    def __init__(self, pagefunc, pagesize):\n        self._pagefunc = pagefunc\n        self._pagesize = pagesize",
        "begin_line": 1523,
        "end_line": 1525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.OnDemandPagedList.getslice#1527",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.OnDemandPagedList",
        "signature": "youtube_dl.utils.OnDemandPagedList.getslice(self, start=0, end=None)",
        "snippet": "    def getslice(self, start=0, end=None):\n        res = []\n        for pagenum in itertools.count(start // self._pagesize):\n            firstid = pagenum * self._pagesize\n            nextfirstid = pagenum * self._pagesize + self._pagesize\n            if start >= nextfirstid:\n                continue\n\n            page_results = list(self._pagefunc(pagenum))\n\n            startv = (\n                start % self._pagesize\n                if firstid <= start < nextfirstid\n                else 0)\n\n            endv = (\n                ((end - 1) % self._pagesize) + 1\n                if (end is not None and firstid <= end <= nextfirstid)\n                else None)\n\n            if startv != 0 or endv is not None:\n                page_results = page_results[startv:endv]\n            res.extend(page_results)\n\n            # A little optimization - if current page is not \"full\", ie. does\n            # not contain page_size videos then we can assume that this page\n            # is the last one - there are no more ids on further pages -\n            # i.e. no need to query again.\n            if len(page_results) + startv < self._pagesize:\n                break\n\n            # If we got the whole page, but the next page is not interesting,\n            # break out early as well\n            if end == nextfirstid:\n                break\n        return res",
        "begin_line": 1527,
        "end_line": 1562,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.InAdvancePagedList.__init__#1566",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.InAdvancePagedList",
        "signature": "youtube_dl.utils.InAdvancePagedList.__init__(self, pagefunc, pagecount, pagesize)",
        "snippet": "    def __init__(self, pagefunc, pagecount, pagesize):\n        self._pagefunc = pagefunc\n        self._pagecount = pagecount\n        self._pagesize = pagesize",
        "begin_line": 1566,
        "end_line": 1569,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.InAdvancePagedList.getslice#1571",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.InAdvancePagedList",
        "signature": "youtube_dl.utils.InAdvancePagedList.getslice(self, start=0, end=None)",
        "snippet": "    def getslice(self, start=0, end=None):\n        res = []\n        start_page = start // self._pagesize\n        end_page = (\n            self._pagecount if end is None else (end // self._pagesize + 1))\n        skip_elems = start - start_page * self._pagesize\n        only_more = None if end is None else end - start\n        for pagenum in range(start_page, end_page):\n            page = list(self._pagefunc(pagenum))\n            if skip_elems:\n                page = page[skip_elems:]\n                skip_elems = None\n            if only_more is not None:\n                if len(page) < only_more:\n                    only_more -= len(page)\n                else:\n                    page = page[:only_more]\n                    res.extend(page)\n                    break\n            res.extend(page)\n        return res",
        "begin_line": 1571,
        "end_line": 1591,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.uppercase_escape#1594",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.uppercase_escape(s)",
        "snippet": "def uppercase_escape(s):\n    unicode_escape = codecs.getdecoder('unicode_escape')\n    return re.sub(\n        r'\\\\U[0-9a-fA-F]{8}',\n        lambda m: unicode_escape(m.group(0))[0],\n        s)",
        "begin_line": 1594,
        "end_line": 1599,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.lowercase_escape#1602",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.lowercase_escape(s)",
        "snippet": "def lowercase_escape(s):\n    unicode_escape = codecs.getdecoder('unicode_escape')\n    return re.sub(\n        r'\\\\u[0-9a-fA-F]{4}',\n        lambda m: unicode_escape(m.group(0))[0],\n        s)",
        "begin_line": 1602,
        "end_line": 1607,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.escape_rfc3986#1610",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.escape_rfc3986(s)",
        "snippet": "def escape_rfc3986(s):\n    \"\"\"Escape non-ASCII characters as suggested by RFC 3986\"\"\"\n    if sys.version_info < (3, 0) and isinstance(s, compat_str):\n        s = s.encode('utf-8')\n    return compat_urllib_parse.quote(s, b\"%/;:@&=+$,!~*'()?#[]\")",
        "begin_line": 1610,
        "end_line": 1614,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0196078431372549,
            "pseudo_dstar_susp": 0.021739130434782608,
            "pseudo_tarantula_susp": 0.001451378809869376,
            "pseudo_op2_susp": 0.021739130434782608,
            "pseudo_barinel_susp": 0.001451378809869376
        }
    },
    {
        "name": "youtube_dl.utils.escape_url#1617",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.escape_url(url)",
        "snippet": "def escape_url(url):\n    \"\"\"Escape URL as suggested by RFC 3986\"\"\"\n    url_parsed = compat_urllib_parse_urlparse(url)\n    return url_parsed._replace(\n        path=escape_rfc3986(url_parsed.path),\n        params=escape_rfc3986(url_parsed.params),\n        query=escape_rfc3986(url_parsed.query),\n        fragment=escape_rfc3986(url_parsed.fragment)\n    ).geturl()",
        "begin_line": 1617,
        "end_line": 1625,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023255813953488372,
            "pseudo_dstar_susp": 0.024390243902439025,
            "pseudo_tarantula_susp": 0.0014684287812041115,
            "pseudo_op2_susp": 0.024390243902439025,
            "pseudo_barinel_susp": 0.0014684287812041115
        }
    },
    {
        "name": "youtube_dl.utils.read_batch_urls#1645",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.read_batch_urls(batch_fd)",
        "snippet": "def read_batch_urls(batch_fd):\n    def fixup(url):\n        if not isinstance(url, compat_str):\n            url = url.decode('utf-8', 'replace')\n        BOM_UTF8 = '\\xef\\xbb\\xbf'\n        if url.startswith(BOM_UTF8):\n            url = url[len(BOM_UTF8):]\n        url = url.strip()\n        if url.startswith(('#', ';', ']')):\n            return False\n        return url\n\n    with contextlib.closing(batch_fd) as fd:\n        return [url for url in map(fixup, fd) if url]",
        "begin_line": 1645,
        "end_line": 1658,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.fixup#1646",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fixup(url)",
        "snippet": "    def fixup(url):\n        if not isinstance(url, compat_str):\n            url = url.decode('utf-8', 'replace')\n        BOM_UTF8 = '\\xef\\xbb\\xbf'\n        if url.startswith(BOM_UTF8):\n            url = url[len(BOM_UTF8):]\n        url = url.strip()\n        if url.startswith(('#', ';', ']')):\n            return False\n        return url",
        "begin_line": 1646,
        "end_line": 1655,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.urlencode_postdata#1661",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.urlencode_postdata(*args, **kargs)",
        "snippet": "def urlencode_postdata(*args, **kargs):\n    return compat_urllib_parse.urlencode(*args, **kargs).encode('ascii')",
        "begin_line": 1661,
        "end_line": 1662,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.encode_dict#1665",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encode_dict(d, encoding='utf-8')",
        "snippet": "def encode_dict(d, encoding='utf-8'):\n    return dict((k.encode(encoding), v.encode(encoding)) for k, v in d.items())",
        "begin_line": 1665,
        "end_line": 1666,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.parse_age_limit#1678",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_age_limit(s)",
        "snippet": "def parse_age_limit(s):\n    if s is None:\n        return None\n    m = re.match(r'^(?P<age>\\d{1,2})\\+?$', s)\n    return int(m.group('age')) if m else US_RATINGS.get(s, None)",
        "begin_line": 1678,
        "end_line": 1682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.strip_jsonp#1685",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.strip_jsonp(code)",
        "snippet": "def strip_jsonp(code):\n    return re.sub(\n        r'(?s)^[a-zA-Z0-9_]+\\s*\\(\\s*(.*)\\);?\\s*?(?://[^\\n]*)*$', r'\\1', code)",
        "begin_line": 1685,
        "end_line": 1687,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.js_to_json#1690",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.js_to_json(code)",
        "snippet": "def js_to_json(code):\n    def fix_kv(m):\n        v = m.group(0)\n        if v in ('true', 'false', 'null'):\n            return v\n        if v.startswith('\"'):\n            v = re.sub(r\"\\\\'\", \"'\", v[1:-1])\n        elif v.startswith(\"'\"):\n            v = v[1:-1]\n            v = re.sub(r\"\\\\\\\\|\\\\'|\\\"\", lambda m: {\n                '\\\\\\\\': '\\\\\\\\',\n                \"\\\\'\": \"'\",\n                '\"': '\\\\\"',\n            }[m.group(0)], v)\n        return '\"%s\"' % v\n\n    res = re.sub(r'''(?x)\n        \"(?:[^\"\\\\]*(?:\\\\\\\\|\\\\['\"nu]))*[^\"\\\\]*\"|\n        '(?:[^'\\\\]*(?:\\\\\\\\|\\\\['\"nu]))*[^'\\\\]*'|\n        [a-zA-Z_][.a-zA-Z_0-9]*\n        ''', fix_kv, code)\n    res = re.sub(r',(\\s*[\\]}])', lambda m: m.group(1), res)\n    return res",
        "begin_line": 1690,
        "end_line": 1712,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.fix_kv#1691",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fix_kv(m)",
        "snippet": "    def fix_kv(m):\n        v = m.group(0)\n        if v in ('true', 'false', 'null'):\n            return v\n        if v.startswith('\"'):\n            v = re.sub(r\"\\\\'\", \"'\", v[1:-1])\n        elif v.startswith(\"'\"):\n            v = v[1:-1]\n            v = re.sub(r\"\\\\\\\\|\\\\'|\\\"\", lambda m: {\n                '\\\\\\\\': '\\\\\\\\',\n                \"\\\\'\": \"'\",\n                '\"': '\\\\\"',\n            }[m.group(0)], v)\n        return '\"%s\"' % v",
        "begin_line": 1691,
        "end_line": 1704,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.qualities#1715",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.qualities(quality_ids)",
        "snippet": "def qualities(quality_ids):\n    \"\"\" Get a numeric quality value out of a list of possible values \"\"\"\n    def q(qid):\n        try:\n            return quality_ids.index(qid)\n        except ValueError:\n            return -1\n    return q",
        "begin_line": 1715,
        "end_line": 1722,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.limit_length#1728",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.limit_length(s, length)",
        "snippet": "def limit_length(s, length):\n    \"\"\" Add ellipses to overly long strings \"\"\"\n    if s is None:\n        return None\n    ELLIPSES = '...'\n    if len(s) > length:\n        return s[:length - len(ELLIPSES)] + ELLIPSES\n    return s",
        "begin_line": 1728,
        "end_line": 1735,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.version_tuple#1738",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.version_tuple(v)",
        "snippet": "def version_tuple(v):\n    return tuple(int(e) for e in re.split(r'[-.]', v))",
        "begin_line": 1738,
        "end_line": 1739,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.is_outdated_version#1742",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.is_outdated_version(version, limit, assume_new=True)",
        "snippet": "def is_outdated_version(version, limit, assume_new=True):\n    if not version:\n        return not assume_new\n    try:\n        return version_tuple(version) < version_tuple(limit)\n    except ValueError:\n        return not assume_new",
        "begin_line": 1742,
        "end_line": 1748,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.ytdl_is_updateable#1751",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.ytdl_is_updateable()",
        "snippet": "def ytdl_is_updateable():\n    \"\"\" Returns if youtube-dl can be updated with -U \"\"\"\n    from zipimport import zipimporter\n\n    return isinstance(globals().get('__loader__'), zipimporter) or hasattr(sys, 'frozen')",
        "begin_line": 1751,
        "end_line": 1755,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.007633587786259542,
            "pseudo_dstar_susp": 0.004672897196261682,
            "pseudo_tarantula_susp": 0.0014858841010401188,
            "pseudo_op2_susp": 0.004672897196261682,
            "pseudo_barinel_susp": 0.0014858841010401188
        }
    },
    {
        "name": "youtube_dl.utils.args_to_str#1758",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.args_to_str(args)",
        "snippet": "def args_to_str(args):\n    # Get a short string representation for a subprocess command\n    return ' '.join(shlex_quote(a) for a in args)",
        "begin_line": 1758,
        "end_line": 1760,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.mimetype2ext#1763",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.mimetype2ext(mt)",
        "snippet": "def mimetype2ext(mt):\n    _, _, res = mt.rpartition('/')\n\n    return {\n        'x-ms-wmv': 'wmv',\n        'x-mp4-fragmented': 'mp4',\n        'ttml+xml': 'ttml',\n    }.get(res, res)",
        "begin_line": 1763,
        "end_line": 1770,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.urlhandle_detect_ext#1773",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.urlhandle_detect_ext(url_handle)",
        "snippet": "def urlhandle_detect_ext(url_handle):\n    try:\n        url_handle.headers\n        getheader = lambda h: url_handle.headers[h]\n    except AttributeError:  # Python < 3\n        getheader = url_handle.info().getheader\n\n    cd = getheader('Content-Disposition')\n    if cd:\n        m = re.match(r'attachment;\\s*filename=\"(?P<filename>[^\"]+)\"', cd)\n        if m:\n            e = determine_ext(m.group('filename'), default_ext=None)\n            if e:\n                return e\n\n    return mimetype2ext(getheader('Content-Type'))",
        "begin_line": 1773,
        "end_line": 1788,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.encode_data_uri#1791",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encode_data_uri(data, mime_type)",
        "snippet": "def encode_data_uri(data, mime_type):\n    return 'data:%s;base64,%s' % (mime_type, base64.b64encode(data).decode('ascii'))",
        "begin_line": 1791,
        "end_line": 1792,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.age_restricted#1795",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.age_restricted(content_limit, age_limit)",
        "snippet": "def age_restricted(content_limit, age_limit):\n    \"\"\" Returns True iff the content should be blocked \"\"\"\n\n    if age_limit is None:  # No limit set\n        return False\n    if content_limit is None:\n        return False  # Content available for everyone\n    return age_limit < content_limit",
        "begin_line": 1795,
        "end_line": 1802,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.is_html#1805",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.is_html(first_bytes)",
        "snippet": "def is_html(first_bytes):\n    \"\"\" Detect whether a file contains HTML by examining its first bytes. \"\"\"\n\n    BOMS = [\n        (b'\\xef\\xbb\\xbf', 'utf-8'),\n        (b'\\x00\\x00\\xfe\\xff', 'utf-32-be'),\n        (b'\\xff\\xfe\\x00\\x00', 'utf-32-le'),\n        (b'\\xff\\xfe', 'utf-16-le'),\n        (b'\\xfe\\xff', 'utf-16-be'),\n    ]\n    for bom, enc in BOMS:\n        if first_bytes.startswith(bom):\n            s = first_bytes[len(bom):].decode(enc, 'replace')\n            break\n    else:\n        s = first_bytes.decode('utf-8', 'replace')\n\n    return re.match(r'^\\s*<', s)",
        "begin_line": 1805,
        "end_line": 1822,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.determine_protocol#1825",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.determine_protocol(info_dict)",
        "snippet": "def determine_protocol(info_dict):\n    protocol = info_dict.get('protocol')\n    if protocol is not None:\n        return protocol\n\n    url = info_dict['url']\n    if url.startswith('rtmp'):\n        return 'rtmp'\n    elif url.startswith('mms'):\n        return 'mms'\n    elif url.startswith('rtsp'):\n        return 'rtsp'\n\n    ext = determine_ext(url)\n    if ext == 'm3u8':\n        return 'm3u8'\n    elif ext == 'f4m':\n        return 'f4m'\n\n    return compat_urllib_parse_urlparse(url).scheme",
        "begin_line": 1825,
        "end_line": 1844,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.render_table#1847",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.render_table(header_row, data)",
        "snippet": "def render_table(header_row, data):\n    \"\"\" Render a list of rows, each as a list of values \"\"\"\n    table = [header_row] + data\n    max_lens = [max(len(compat_str(v)) for v in col) for col in zip(*table)]\n    format_str = ' '.join('%-' + compat_str(ml + 1) + 's' for ml in max_lens[:-1]) + '%s'\n    return '\\n'.join(format_str % tuple(row) for row in table)",
        "begin_line": 1847,
        "end_line": 1852,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils._match_one#1855",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._match_one(filter_part, dct)",
        "snippet": "def _match_one(filter_part, dct):\n    COMPARISON_OPERATORS = {\n        '<': operator.lt,\n        '<=': operator.le,\n        '>': operator.gt,\n        '>=': operator.ge,\n        '=': operator.eq,\n        '!=': operator.ne,\n    }\n    operator_rex = re.compile(r'''(?x)\\s*\n        (?P<key>[a-z_]+)\n        \\s*(?P<op>%s)(?P<none_inclusive>\\s*\\?)?\\s*\n        (?:\n            (?P<intval>[0-9.]+(?:[kKmMgGtTpPeEzZyY]i?[Bb]?)?)|\n            (?P<strval>(?![0-9.])[a-z0-9A-Z]*)\n        )\n        \\s*$\n        ''' % '|'.join(map(re.escape, COMPARISON_OPERATORS.keys())))\n    m = operator_rex.search(filter_part)\n    if m:\n        op = COMPARISON_OPERATORS[m.group('op')]\n        if m.group('strval') is not None:\n            if m.group('op') not in ('=', '!='):\n                raise ValueError(\n                    'Operator %s does not support string values!' % m.group('op'))\n            comparison_value = m.group('strval')\n        else:\n            try:\n                comparison_value = int(m.group('intval'))\n            except ValueError:\n                comparison_value = parse_filesize(m.group('intval'))\n                if comparison_value is None:\n                    comparison_value = parse_filesize(m.group('intval') + 'B')\n                if comparison_value is None:\n                    raise ValueError(\n                        'Invalid integer value %r in filter part %r' % (\n                            m.group('intval'), filter_part))\n        actual_value = dct.get(m.group('key'))\n        if actual_value is None:\n            return m.group('none_inclusive')\n        return op(actual_value, comparison_value)\n\n    UNARY_OPERATORS = {\n        '': lambda v: v is not None,\n        '!': lambda v: v is None,\n    }\n    operator_rex = re.compile(r'''(?x)\\s*\n        (?P<op>%s)\\s*(?P<key>[a-z_]+)\n        \\s*$\n        ''' % '|'.join(map(re.escape, UNARY_OPERATORS.keys())))\n    m = operator_rex.search(filter_part)\n    if m:\n        op = UNARY_OPERATORS[m.group('op')]\n        actual_value = dct.get(m.group('key'))\n        return op(actual_value)\n\n    raise ValueError('Invalid filter part %r' % filter_part)",
        "begin_line": 1855,
        "end_line": 1911,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.match_str#1914",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.match_str(filter_str, dct)",
        "snippet": "def match_str(filter_str, dct):\n    \"\"\" Filter a dictionary with a simple string syntax. Returns True (=passes filter) or false \"\"\"\n\n    return all(\n        _match_one(filter_part, dct) for filter_part in filter_str.split('&'))",
        "begin_line": 1914,
        "end_line": 1918,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.match_filter_func#1921",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.match_filter_func(filter_str)",
        "snippet": "def match_filter_func(filter_str):\n    def _match_func(info_dict):\n        if match_str(filter_str, info_dict):\n            return None\n        else:\n            video_title = info_dict.get('title', info_dict.get('id', 'video'))\n            return '%s does not pass filter %s, skipping ..' % (video_title, filter_str)\n    return _match_func",
        "begin_line": 1921,
        "end_line": 1928,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils._match_func#1922",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._match_func(info_dict)",
        "snippet": "    def _match_func(info_dict):\n        if match_str(filter_str, info_dict):\n            return None\n        else:\n            video_title = info_dict.get('title', info_dict.get('id', 'video'))\n            return '%s does not pass filter %s, skipping ..' % (video_title, filter_str)",
        "begin_line": 1922,
        "end_line": 1927,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.parse_dfxp_time_expr#1931",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_dfxp_time_expr(time_expr)",
        "snippet": "def parse_dfxp_time_expr(time_expr):\n    if not time_expr:\n        return 0.0\n\n    mobj = re.match(r'^(?P<time_offset>\\d+(?:\\.\\d+)?)s?$', time_expr)\n    if mobj:\n        return float(mobj.group('time_offset'))\n\n    mobj = re.match(r'^(\\d+):(\\d\\d):(\\d\\d(?:\\.\\d+)?)$', time_expr)\n    if mobj:\n        return 3600 * int(mobj.group(1)) + 60 * int(mobj.group(2)) + float(mobj.group(3))",
        "begin_line": 1931,
        "end_line": 1941,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.srt_subtitles_timecode#1944",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.srt_subtitles_timecode(seconds)",
        "snippet": "def srt_subtitles_timecode(seconds):\n    return '%02d:%02d:%02d,%03d' % (seconds / 3600, (seconds % 3600) / 60, seconds % 60, (seconds % 1) * 1000)",
        "begin_line": 1944,
        "end_line": 1945,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.dfxp2srt#1948",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.dfxp2srt(dfxp_data)",
        "snippet": "def dfxp2srt(dfxp_data):\n    _x = functools.partial(xpath_with_ns, ns_map={\n        'ttml': 'http://www.w3.org/ns/ttml',\n        'ttaf1': 'http://www.w3.org/2006/10/ttaf1',\n    })\n\n    def parse_node(node):\n        str_or_empty = functools.partial(str_or_none, default='')\n\n        out = str_or_empty(node.text)\n\n        for child in node:\n            if child.tag in (_x('ttml:br'), _x('ttaf1:br'), 'br'):\n                out += '\\n' + str_or_empty(child.tail)\n            elif child.tag in (_x('ttml:span'), _x('ttaf1:span'), 'span'):\n                out += str_or_empty(parse_node(child))\n            else:\n                out += str_or_empty(xml.etree.ElementTree.tostring(child))\n\n        return out\n\n    dfxp = compat_etree_fromstring(dfxp_data.encode('utf-8'))\n    out = []\n    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall(_x('.//ttaf1:p')) or dfxp.findall('.//p')\n\n    if not paras:\n        raise ValueError('Invalid dfxp/TTML subtitle')\n\n    for para, index in zip(paras, itertools.count(1)):\n        begin_time = parse_dfxp_time_expr(para.attrib['begin'])\n        end_time = parse_dfxp_time_expr(para.attrib.get('end'))\n        if not end_time:\n            end_time = begin_time + parse_dfxp_time_expr(para.attrib['dur'])\n        out.append('%d\\n%s --> %s\\n%s\\n\\n' % (\n            index,\n            srt_subtitles_timecode(begin_time),\n            srt_subtitles_timecode(end_time),\n            parse_node(para)))\n\n    return ''.join(out)",
        "begin_line": 1948,
        "end_line": 1987,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.parse_node#1954",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_node(node)",
        "snippet": "    def parse_node(node):\n        str_or_empty = functools.partial(str_or_none, default='')\n\n        out = str_or_empty(node.text)\n\n        for child in node:\n            if child.tag in (_x('ttml:br'), _x('ttaf1:br'), 'br'):\n                out += '\\n' + str_or_empty(child.tail)\n            elif child.tag in (_x('ttml:span'), _x('ttaf1:span'), 'span'):\n                out += str_or_empty(parse_node(child))\n            else:\n                out += str_or_empty(xml.etree.ElementTree.tostring(child))\n\n        return out",
        "begin_line": 1954,
        "end_line": 1967,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.cli_option#1990",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.cli_option(params, command_option, param)",
        "snippet": "def cli_option(params, command_option, param):\n    param = params.get(param)\n    return [command_option, param] if param is not None else []",
        "begin_line": 1990,
        "end_line": 1992,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.cli_bool_option#1995",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.cli_bool_option(params, command_option, param, true_value='true', false_value='false', separator=None)",
        "snippet": "def cli_bool_option(params, command_option, param, true_value='true', false_value='false', separator=None):\n    param = params.get(param)\n    assert isinstance(param, bool)\n    if separator:\n        return [command_option + separator + (true_value if param else false_value)]\n    return [command_option, true_value if param else false_value]",
        "begin_line": 1995,
        "end_line": 2000,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.cli_valueless_option#2003",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.cli_valueless_option(params, command_option, param, expected_value=True)",
        "snippet": "def cli_valueless_option(params, command_option, param, expected_value=True):\n    param = params.get(param)\n    return [command_option] if param == expected_value else []",
        "begin_line": 2003,
        "end_line": 2005,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.cli_configuration_args#2008",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.cli_configuration_args(params, param, default=[])",
        "snippet": "def cli_configuration_args(params, param, default=[]):\n    ex_args = params.get(param)\n    if ex_args is None:\n        return default\n    assert isinstance(ex_args, list)\n    return ex_args",
        "begin_line": 2008,
        "end_line": 2013,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.ISO639Utils.short2long#2206",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ISO639Utils",
        "signature": "youtube_dl.utils.ISO639Utils.short2long(cls, code)",
        "snippet": "    def short2long(cls, code):\n        \"\"\"Convert language code from ISO 639-1 to ISO 639-2/T\"\"\"\n        return cls._lang_map.get(code[:2])",
        "begin_line": 2206,
        "end_line": 2208,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.ISO639Utils.long2short#2211",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ISO639Utils",
        "signature": "youtube_dl.utils.ISO639Utils.long2short(cls, code)",
        "snippet": "    def long2short(cls, code):\n        \"\"\"Convert language code from ISO 639-2/T to ISO 639-1\"\"\"\n        for short_name, long_name in cls._lang_map.items():\n            if long_name == code:\n                return short_name",
        "begin_line": 2211,
        "end_line": 2215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.ISO3166Utils.short2full#2473",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ISO3166Utils",
        "signature": "youtube_dl.utils.ISO3166Utils.short2full(cls, code)",
        "snippet": "    def short2full(cls, code):\n        \"\"\"Convert an ISO 3166-2 country code to the corresponding full name\"\"\"\n        return cls._country_map.get(code.upper())",
        "begin_line": 2473,
        "end_line": 2475,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.utils.PerRequestProxyHandler.__init__#2479",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PerRequestProxyHandler",
        "signature": "youtube_dl.utils.PerRequestProxyHandler.__init__(self, proxies=None)",
        "snippet": "    def __init__(self, proxies=None):\n        # Set default handlers\n        for type in ('http', 'https'):\n            setattr(self, '%s_open' % type,\n                    lambda r, proxy='__noproxy__', type=type, meth=self.proxy_open:\n                        meth(r, proxy, type))\n        return compat_urllib_request.ProxyHandler.__init__(self, proxies)",
        "begin_line": 2479,
        "end_line": 2485,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 1.0,
            "pseudo_dstar_susp": 1.0,
            "pseudo_tarantula_susp": 0.0016835016835016834,
            "pseudo_op2_susp": 1.0,
            "pseudo_barinel_susp": 0.0016835016835016834
        }
    },
    {
        "name": "youtube_dl.utils.PerRequestProxyHandler.proxy_open#2487",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PerRequestProxyHandler",
        "signature": "youtube_dl.utils.PerRequestProxyHandler.proxy_open(self, req, proxy, type)",
        "snippet": "    def proxy_open(self, req, proxy, type):\n        req_proxy = req.headers.get('Ytdl-request-proxy')\n        if req_proxy is not None:\n            proxy = req_proxy\n            del req.headers['Ytdl-request-proxy']\n\n        if proxy == '__noproxy__':\n            return None  # No Proxy\n        return compat_urllib_request.ProxyHandler.proxy_open(\n            self, req, proxy, type)",
        "begin_line": 2487,
        "end_line": 2496,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.09090909090909091,
            "pseudo_dstar_susp": 0.09090909090909091,
            "pseudo_tarantula_susp": 0.0016835016835016834,
            "pseudo_op2_susp": 0.09090909090909091,
            "pseudo_barinel_susp": 0.0016835016835016834
        }
    },
    {
        "name": "youtube_dl.extractor.eighttracks.EightTracksIE._real_extract#104",
        "src_path": "youtube_dl/extractor/eighttracks.py",
        "class_name": "youtube_dl.extractor.eighttracks.EightTracksIE",
        "signature": "youtube_dl.extractor.eighttracks.EightTracksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        data = self._parse_json(\n            self._search_regex(\n                r\"(?s)PAGE\\.mix\\s*=\\s*({.+?});\\n\", webpage, 'trax information'),\n            playlist_id)\n\n        session = str(random.randint(0, 1000000000))\n        mix_id = data['id']\n        track_count = data['tracks_count']\n        duration = data['duration']\n        avg_song_duration = float(duration) / track_count\n        # duration is sometimes negative, use predefined avg duration\n        if avg_song_duration <= 0:\n            avg_song_duration = 300\n        first_url = 'http://8tracks.com/sets/%s/play?player=sm&mix_id=%s&format=jsonh' % (session, mix_id)\n        next_url = first_url\n        entries = []\n\n        for i in range(track_count):\n            api_json = None\n            download_tries = 0\n\n            while api_json is None:\n                try:\n                    api_json = self._download_webpage(\n                        next_url, playlist_id,\n                        note='Downloading song information %d/%d' % (i + 1, track_count),\n                        errnote='Failed to download song information')\n                except ExtractorError:\n                    if download_tries > 3:\n                        raise\n                    else:\n                        download_tries += 1\n                        self._sleep(avg_song_duration, playlist_id)\n\n            api_data = json.loads(api_json)\n            track_data = api_data['set']['track']\n            info = {\n                'id': compat_str(track_data['id']),\n                'url': track_data['track_file_stream_url'],\n                'title': track_data['performer'] + ' - ' + track_data['name'],\n                'raw_title': track_data['name'],\n                'uploader_id': data['user']['login'],\n                'ext': 'm4a',\n            }\n            entries.append(info)\n\n            next_url = 'http://8tracks.com/sets/%s/next?player=sm&mix_id=%s&format=jsonh&track_id=%s' % (\n                session, mix_id, track_data['id'])\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': compat_str(mix_id),\n            'display_id': playlist_id,\n            'title': data.get('name'),\n            'description': data.get('description'),\n        }",
        "begin_line": 104,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.redtube.RedTubeIE._real_extract#20",
        "src_path": "youtube_dl/extractor/redtube.py",
        "class_name": "youtube_dl.extractor.redtube.RedTubeIE",
        "signature": "youtube_dl.extractor.redtube.RedTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        if any(s in webpage for s in ['video-deleted-info', '>This video has been removed']):\n            raise ExtractorError('Video %s has been removed' % video_id, expected=True)\n\n        video_url = self._html_search_regex(\n            r'<source src=\"(.+?)\" type=\"video/mp4\">', webpage, 'video URL')\n        video_title = self._html_search_regex(\n            r'<h1 class=\"videoTitle[^\"]*\">(.+?)</h1>',\n            webpage, 'title')\n        video_thumbnail = self._og_search_thumbnail(webpage)\n\n        # No self-labeling, but they describe themselves as\n        # \"Home of Videos Porno\"\n        age_limit = 18\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'age_limit': age_limit,\n        }",
        "begin_line": 20,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.addanime.AddAnimeIE._real_extract#34",
        "src_path": "youtube_dl/extractor/addanime.py",
        "class_name": "youtube_dl.extractor.addanime.AddAnimeIE",
        "signature": "youtube_dl.extractor.addanime.AddAnimeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        try:\n            webpage = self._download_webpage(url, video_id)\n        except ExtractorError as ee:\n            if not isinstance(ee.cause, compat_HTTPError) or \\\n               ee.cause.code != 503:\n                raise\n\n            redir_webpage = ee.cause.read().decode('utf-8')\n            action = self._search_regex(\n                r'<form id=\"challenge-form\" action=\"([^\"]+)\"',\n                redir_webpage, 'Redirect form')\n            vc = self._search_regex(\n                r'<input type=\"hidden\" name=\"jschl_vc\" value=\"([^\"]+)\"/>',\n                redir_webpage, 'redirect vc value')\n            av = re.search(\n                r'a\\.value = ([0-9]+)[+]([0-9]+)[*]([0-9]+);',\n                redir_webpage)\n            if av is None:\n                raise ExtractorError('Cannot find redirect math task')\n            av_res = int(av.group(1)) + int(av.group(2)) * int(av.group(3))\n\n            parsed_url = compat_urllib_parse_urlparse(url)\n            av_val = av_res + len(parsed_url.netloc)\n            confirm_url = (\n                parsed_url.scheme + '://' + parsed_url.netloc +\n                action + '?' +\n                compat_urllib_parse.urlencode({\n                    'jschl_vc': vc, 'jschl_answer': compat_str(av_val)}))\n            self._download_webpage(\n                confirm_url, video_id,\n                note='Confirming after redirect')\n            webpage = self._download_webpage(url, video_id)\n\n        FORMATS = ('normal', 'hq')\n        quality = qualities(FORMATS)\n        formats = []\n        for format_id in FORMATS:\n            rex = r\"var %s_video_file = '(.*?)';\" % re.escape(format_id)\n            video_url = self._search_regex(rex, webpage, 'video file URLx',\n                                           fatal=False)\n            if not video_url:\n                continue\n            formats.append({\n                'format_id': format_id,\n                'url': video_url,\n                'quality': quality(format_id),\n            })\n        self._sort_formats(formats)\n        video_title = self._og_search_title(webpage)\n        video_description = self._og_search_description(webpage)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'formats': formats,\n            'title': video_title,\n            'description': video_description\n        }",
        "begin_line": 34,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.viddler.ViddlerIE._real_extract#61",
        "src_path": "youtube_dl/extractor/viddler.py",
        "class_name": "youtube_dl.extractor.viddler.ViddlerIE",
        "signature": "youtube_dl.extractor.viddler.ViddlerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        json_url = (\n            'http://api.viddler.com/api/v2/viddler.videos.getPlaybackDetails.json?video_id=%s&key=v0vhrt7bg2xq1vyxhkct' %\n            video_id)\n        headers = {'Referer': 'http://static.cdn-ec.viddler.com/js/arpeggio/v2/embed.html'}\n        request = compat_urllib_request.Request(json_url, None, headers)\n        data = self._download_json(request, video_id)['video']\n\n        formats = []\n        for filed in data['files']:\n            if filed.get('status', 'ready') != 'ready':\n                continue\n            format_id = filed.get('profile_id') or filed['profile_name']\n            f = {\n                'format_id': format_id,\n                'format_note': filed['profile_name'],\n                'url': self._proto_relative_url(filed['url']),\n                'width': int_or_none(filed.get('width')),\n                'height': int_or_none(filed.get('height')),\n                'filesize': int_or_none(filed.get('size')),\n                'ext': filed.get('ext'),\n                'source_preference': -1,\n            }\n            formats.append(f)\n\n            if filed.get('cdn_url'):\n                f = f.copy()\n                f['url'] = self._proto_relative_url(filed['cdn_url'], 'http:')\n                f['format_id'] = format_id + '-cdn'\n                f['source_preference'] = 1\n                formats.append(f)\n\n            if filed.get('html5_video_source'):\n                f = f.copy()\n                f['url'] = self._proto_relative_url(filed['html5_video_source'])\n                f['format_id'] = format_id + '-html5'\n                f['source_preference'] = 0\n                formats.append(f)\n        self._sort_formats(formats)\n\n        categories = [\n            t.get('text') for t in data.get('tags', []) if 'text' in t]\n\n        return {\n            'id': video_id,\n            'title': data['title'],\n            'formats': formats,\n            'description': data.get('description'),\n            'timestamp': int_or_none(data.get('upload_time')),\n            'thumbnail': self._proto_relative_url(data.get('thumbnail_url')),\n            'uploader': data.get('author'),\n            'duration': float_or_none(data.get('length')),\n            'view_count': int_or_none(data.get('view_count')),\n            'comment_count': int_or_none(data.get('comment_count')),\n            'categories': categories,\n        }",
        "begin_line": 61,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.giga.GigaIE._real_extract#45",
        "src_path": "youtube_dl/extractor/giga.py",
        "class_name": "youtube_dl.extractor.giga.GigaIE",
        "signature": "youtube_dl.extractor.giga.GigaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            [r'data-video-id=\"(\\d+)\"', r'/api/video/jwplayer/#v=(\\d+)'],\n            webpage, 'video id')\n\n        playlist = self._download_json(\n            'http://www.giga.de/api/syndication/video/video_id/%s/playlist.json?content=syndication/key/368b5f151da4ae05ced7fa296bdff65a/'\n            % video_id, video_id)[0]\n\n        quality = qualities(['normal', 'hd720'])\n\n        formats = []\n        for format_id in itertools.count(0):\n            fmt = playlist.get(compat_str(format_id))\n            if not fmt:\n                break\n            formats.append({\n                'url': fmt['src'],\n                'format_id': '%s-%s' % (fmt['quality'], fmt['type'].split('/')[-1]),\n                'quality': quality(fmt['quality']),\n            })\n        self._sort_formats(formats)\n\n        title = self._html_search_meta(\n            'title', webpage, 'title', fatal=True)\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        duration = parse_duration(self._search_regex(\n            r'(?s)(?:data-video-id=\"{0}\"|data-video=\"[^\"]*/api/video/jwplayer/#v={0}[^\"]*\")[^>]*>.+?<span class=\"duration\">([^<]+)</span>'.format(video_id),\n            webpage, 'duration', fatal=False))\n\n        timestamp = parse_iso8601(self._search_regex(\n            r'datetime=\"([^\"]+)\"', webpage, 'upload date', fatal=False))\n        uploader = self._search_regex(\n            r'class=\"author\">([^<]+)</a>', webpage, 'uploader', fatal=False)\n\n        view_count = str_to_int(self._search_regex(\n            r'<span class=\"views\"><strong>([\\d.,]+)</strong>',\n            webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.golem.GolemIE._real_extract#30",
        "src_path": "youtube_dl/extractor/golem.py",
        "class_name": "youtube_dl.extractor.golem.GolemIE",
        "signature": "youtube_dl.extractor.golem.GolemIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        config = self._download_xml(\n            'https://video.golem.de/xml/{0}.xml'.format(video_id), video_id)\n\n        info = {\n            'id': video_id,\n            'title': config.findtext('./title', 'golem'),\n            'duration': self._float(config.findtext('./playtime'), 'duration'),\n        }\n\n        formats = []\n        for e in config:\n            url = e.findtext('./url')\n            if not url:\n                continue\n\n            formats.append({\n                'format_id': e.tag,\n                'url': compat_urlparse.urljoin(self._PREFIX, url),\n                'height': self._int(e.get('height'), 'height'),\n                'width': self._int(e.get('width'), 'width'),\n                'filesize': self._int(e.findtext('filesize'), 'filesize'),\n                'ext': determine_ext(e.findtext('./filename')),\n            })\n        self._sort_formats(formats)\n        info['formats'] = formats\n\n        thumbnails = []\n        for e in config.findall('.//teaser'):\n            url = e.findtext('./url')\n            if not url:\n                continue\n            thumbnails.append({\n                'url': compat_urlparse.urljoin(self._PREFIX, url),\n                'width': self._int(e.get('width'), 'thumbnail width'),\n                'height': self._int(e.get('height'), 'thumbnail height'),\n            })\n        info['thumbnails'] = thumbnails\n\n        return info",
        "begin_line": 30,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vidme.VidmeIE._real_extract#131",
        "src_path": "youtube_dl/extractor/vidme.py",
        "class_name": "youtube_dl.extractor.vidme.VidmeIE",
        "signature": "youtube_dl.extractor.vidme.VidmeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        try:\n            response = self._download_json(\n                'https://api.vid.me/videoByUrl/%s' % video_id, video_id)\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 400:\n                response = self._parse_json(e.cause.read(), video_id)\n            else:\n                raise\n\n        error = response.get('error')\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error), expected=True)\n\n        video = response['video']\n\n        if video.get('state') == 'deleted':\n            raise ExtractorError(\n                'Vidme said: Sorry, this video has been deleted.',\n                expected=True)\n\n        if video.get('state') in ('user-disabled', 'suspended'):\n            raise ExtractorError(\n                'Vidme said: This video has been suspended either due to a copyright claim, '\n                'or for violating the terms of use.',\n                expected=True)\n\n        formats = [{\n            'format_id': f.get('type'),\n            'url': f['uri'],\n            'width': int_or_none(f.get('width')),\n            'height': int_or_none(f.get('height')),\n            'preference': 0 if f.get('type', '').endswith('clip') else 1,\n        } for f in video.get('formats', []) if f.get('uri')]\n\n        if not formats and video.get('complete_url'):\n            formats.append({\n                'url': video.get('complete_url'),\n                'width': int_or_none(video.get('width')),\n                'height': int_or_none(video.get('height')),\n            })\n\n        self._sort_formats(formats)\n\n        title = video['title']\n        description = video.get('description')\n        thumbnail = video.get('thumbnail_url')\n        timestamp = parse_iso8601(video.get('date_created'), ' ')\n        uploader = video.get('user', {}).get('username')\n        uploader_id = video.get('user', {}).get('user_id')\n        age_limit = 18 if video.get('nsfw') is True else 0\n        duration = float_or_none(video.get('duration'))\n        view_count = int_or_none(video.get('view_count'))\n        like_count = int_or_none(video.get('likes_count'))\n        comment_count = int_or_none(video.get('comment_count'))\n\n        return {\n            'id': video_id,\n            'title': title or 'Video upload (%s)' % video_id,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'age_limit': age_limit,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'formats': formats,\n        }",
        "begin_line": 131,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.aol.AolIE._real_extract#41",
        "src_path": "youtube_dl/extractor/aol.py",
        "class_name": "youtube_dl.extractor.aol.AolIE",
        "signature": "youtube_dl.extractor.aol.AolIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        playlist_id = mobj.group('playlist_id')\n        if not playlist_id or self._downloader.params.get('noplaylist'):\n            return self.url_result('5min:%s' % video_id)\n\n        self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))\n\n        webpage = self._download_webpage(url, playlist_id)\n        title = self._html_search_regex(\n            r'<h1 class=\"video-title[^\"]*\">(.+?)</h1>', webpage, 'title')\n        playlist_html = self._search_regex(\n            r\"(?s)<ul\\s+class='video-related[^']*'>(.*?)</ul>\", webpage,\n            'playlist HTML')\n        entries = [{\n            '_type': 'url',\n            'url': 'aol-video:%s' % m.group('id'),\n            'ie_key': 'Aol',\n        } for m in re.finditer(\n            r\"<a\\s+href='.*videoid=(?P<id>[0-9]+)'\\s+class='video-thumb'>\",\n            playlist_html)]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'display_id': mobj.group('playlist_display_id'),\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 41,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._formats_from_html#74",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._formats_from_html(self, html)",
        "snippet": "    def _formats_from_html(self, html):\n        FORMAT_REGEX = r'''\n            (?x)\n            <a\\s+href=\"(?P<url>[^\"]+)\">(?P<quality>[^<]+)</a>\\s*\n            <span\\s+class=\"usage\">\\((?P<note>[^\\)]+)\\)</span>\\s*\n            (?:<div\\s+class=\"popup\\s+rounded\">\\s*\n            <h3>File\\s+size</h3>\\s*(?P<filesize>.*?)\\s*\n            </div>)?                                                # File size part may be missing\n        '''\n        quality = qualities((\n            'MP3', 'MP4',\n            'Low Quality WMV', 'Low Quality MP4',\n            'Mid Quality WMV', 'Mid Quality MP4',\n            'High Quality WMV', 'High Quality MP4'))\n        formats = [{\n            'url': x.group('url'),\n            'format_id': x.group('quality'),\n            'format_note': x.group('note'),\n            'format': '%s (%s)' % (x.group('quality'), x.group('note')),\n            'filesize_approx': parse_filesize(x.group('filesize')),\n            'quality': quality(x.group('quality')),\n            'vcodec': 'none' if x.group('note') == 'Audio only' else None,\n        } for x in list(re.finditer(FORMAT_REGEX, html))]\n\n        self._sort_formats(formats)\n\n        return formats",
        "begin_line": 74,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_title#102",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_title(self, html)",
        "snippet": "    def _extract_title(self, html):\n        title = self._html_search_meta('title', html, 'title')\n        if title is None:\n            title = self._og_search_title(html)\n            TITLE_SUFFIX = ' (Channel 9)'\n            if title is not None and title.endswith(TITLE_SUFFIX):\n                title = title[:-len(TITLE_SUFFIX)]\n        return title",
        "begin_line": 102,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_description#111",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_description(self, html)",
        "snippet": "    def _extract_description(self, html):\n        DESCRIPTION_REGEX = r'''(?sx)\n            <div\\s+class=\"entry-content\">\\s*\n            <div\\s+id=\"entry-body\">\\s*\n            (?P<description>.+?)\\s*\n            </div>\\s*\n            </div>\n        '''\n        m = re.search(DESCRIPTION_REGEX, html)\n        if m is not None:\n            return m.group('description')\n        return self._html_search_meta('description', html, 'description')",
        "begin_line": 111,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_duration#124",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_duration(self, html)",
        "snippet": "    def _extract_duration(self, html):\n        m = re.search(r'\"length\": *\"(?P<hours>\\d{2}):(?P<minutes>\\d{2}):(?P<seconds>\\d{2})\"', html)\n        return ((int(m.group('hours')) * 60 * 60) + (int(m.group('minutes')) * 60) + int(m.group('seconds'))) if m else None",
        "begin_line": 124,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_slides#128",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_slides(self, html)",
        "snippet": "    def _extract_slides(self, html):\n        m = re.search(r'<a href=\"(?P<slidesurl>[^\"]+)\" class=\"slides\">Slides</a>', html)\n        return m.group('slidesurl') if m is not None else None",
        "begin_line": 128,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_zip#132",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_zip(self, html)",
        "snippet": "    def _extract_zip(self, html):\n        m = re.search(r'<a href=\"(?P<zipurl>[^\"]+)\" class=\"zip\">Zip</a>', html)\n        return m.group('zipurl') if m is not None else None",
        "begin_line": 132,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_avg_rating#136",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_avg_rating(self, html)",
        "snippet": "    def _extract_avg_rating(self, html):\n        m = re.search(r'<p class=\"avg-rating\">Avg Rating: <span>(?P<avgrating>[^<]+)</span></p>', html)\n        return float(m.group('avgrating')) if m is not None else 0",
        "begin_line": 136,
        "end_line": 138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_rating_count#140",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_rating_count(self, html)",
        "snippet": "    def _extract_rating_count(self, html):\n        m = re.search(r'<div class=\"rating-count\">\\((?P<ratingcount>[^<]+)\\)</div>', html)\n        return int(self._fix_count(m.group('ratingcount'))) if m is not None else 0",
        "begin_line": 140,
        "end_line": 142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_view_count#144",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_view_count(self, html)",
        "snippet": "    def _extract_view_count(self, html):\n        m = re.search(r'<li class=\"views\">\\s*<span class=\"count\">(?P<viewcount>[^<]+)</span> Views\\s*</li>', html)\n        return int(self._fix_count(m.group('viewcount'))) if m is not None else 0",
        "begin_line": 144,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_comment_count#148",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_comment_count(self, html)",
        "snippet": "    def _extract_comment_count(self, html):\n        m = re.search(r'<li class=\"comments\">\\s*<a href=\"#comments\">\\s*<span class=\"count\">(?P<commentcount>[^<]+)</span> Comments\\s*</a>\\s*</li>', html)\n        return int(self._fix_count(m.group('commentcount'))) if m is not None else 0",
        "begin_line": 148,
        "end_line": 150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._fix_count#152",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._fix_count(self, count)",
        "snippet": "    def _fix_count(self, count):\n        return int(str(count).replace(',', '')) if count is not None else None",
        "begin_line": 152,
        "end_line": 153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_authors#155",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_authors(self, html)",
        "snippet": "    def _extract_authors(self, html):\n        m = re.search(r'(?s)<li class=\"author\">(.*?)</li>', html)\n        if m is None:\n            return None\n        return re.findall(r'<a href=\"/Niners/[^\"]+\">([^<]+)</a>', m.group(1))",
        "begin_line": 155,
        "end_line": 159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_code#161",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_code(self, html)",
        "snippet": "    def _extract_session_code(self, html):\n        m = re.search(r'<li class=\"code\">\\s*(?P<code>.+?)\\s*</li>', html)\n        return m.group('code') if m is not None else None",
        "begin_line": 161,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_day#165",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_day(self, html)",
        "snippet": "    def _extract_session_day(self, html):\n        m = re.search(r'<li class=\"day\">\\s*<a href=\"/Events/[^\"]+\">(?P<day>[^<]+)</a>\\s*</li>', html)\n        return m.group('day').strip() if m is not None else None",
        "begin_line": 165,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_room#169",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_room(self, html)",
        "snippet": "    def _extract_session_room(self, html):\n        m = re.search(r'<li class=\"room\">\\s*(?P<room>.+?)\\s*</li>', html)\n        return m.group('room') if m is not None else None",
        "begin_line": 169,
        "end_line": 171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_speakers#173",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_speakers(self, html)",
        "snippet": "    def _extract_session_speakers(self, html):\n        return re.findall(r'<a href=\"/Events/Speakers/[^\"]+\">([^<]+)</a>', html)",
        "begin_line": 173,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_content#176",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_content(self, html, content_path)",
        "snippet": "    def _extract_content(self, html, content_path):\n        # Look for downloadable content\n        formats = self._formats_from_html(html)\n        slides = self._extract_slides(html)\n        zip_ = self._extract_zip(html)\n\n        # Nothing to download\n        if len(formats) == 0 and slides is None and zip_ is None:\n            self._downloader.report_warning('None of recording, slides or zip are available for %s' % content_path)\n            return\n\n        # Extract meta\n        title = self._extract_title(html)\n        description = self._extract_description(html)\n        thumbnail = self._og_search_thumbnail(html)\n        duration = self._extract_duration(html)\n        avg_rating = self._extract_avg_rating(html)\n        rating_count = self._extract_rating_count(html)\n        view_count = self._extract_view_count(html)\n        comment_count = self._extract_comment_count(html)\n\n        common = {\n            '_type': 'video',\n            'id': content_path,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'avg_rating': avg_rating,\n            'rating_count': rating_count,\n            'view_count': view_count,\n            'comment_count': comment_count,\n        }\n\n        result = []\n\n        if slides is not None:\n            d = common.copy()\n            d.update({'title': title + '-Slides', 'url': slides})\n            result.append(d)\n\n        if zip_ is not None:\n            d = common.copy()\n            d.update({'title': title + '-Zip', 'url': zip_})\n            result.append(d)\n\n        if len(formats) > 0:\n            d = common.copy()\n            d.update({'title': title, 'formats': formats})\n            result.append(d)\n\n        return result",
        "begin_line": 176,
        "end_line": 226,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_entry_item#228",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_entry_item(self, html, content_path)",
        "snippet": "    def _extract_entry_item(self, html, content_path):\n        contents = self._extract_content(html, content_path)\n        if contents is None:\n            return contents\n\n        if len(contents) > 1:\n            raise ExtractorError('Got more than one entry')\n        result = contents[0]\n        result['authors'] = self._extract_authors(html)\n\n        return result",
        "begin_line": 228,
        "end_line": 238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session#240",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session(self, html, content_path)",
        "snippet": "    def _extract_session(self, html, content_path):\n        contents = self._extract_content(html, content_path)\n        if contents is None:\n            return contents\n\n        session_meta = {\n            'session_code': self._extract_session_code(html),\n            'session_day': self._extract_session_day(html),\n            'session_room': self._extract_session_room(html),\n            'session_speakers': self._extract_session_speakers(html),\n        }\n\n        for content in contents:\n            content.update(session_meta)\n\n        return self.playlist_result(contents)",
        "begin_line": 240,
        "end_line": 255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_list#257",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_list(self, content_path)",
        "snippet": "    def _extract_list(self, content_path):\n        rss = self._download_xml(self._RSS_URL % content_path, content_path, 'Downloading RSS')\n        entries = [self.url_result(session_url.text, 'Channel9')\n                   for session_url in rss.findall('./channel/item/link')]\n        title_text = rss.find('./channel/title').text\n        return self.playlist_result(entries, content_path, title_text)",
        "begin_line": 257,
        "end_line": 262,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._real_extract#264",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        content_path = mobj.group('contentpath')\n\n        webpage = self._download_webpage(url, content_path, 'Downloading web page')\n\n        page_type_m = re.search(r'<meta name=\"WT.entryid\" content=\"(?P<pagetype>[^:]+)[^\"]+\"/>', webpage)\n        if page_type_m is not None:\n            page_type = page_type_m.group('pagetype')\n            if page_type == 'Entry':      # Any 'item'-like page, may contain downloadable content\n                return self._extract_entry_item(webpage, content_path)\n            elif page_type == 'Session':  # Event session page, may contain downloadable content\n                return self._extract_session(webpage, content_path)\n            elif page_type == 'Event':\n                return self._extract_list(content_path)\n            else:\n                raise ExtractorError('Unexpected WT.entryid %s' % page_type, expected=True)\n\n        else:  # Assuming list\n            return self._extract_list(content_path)",
        "begin_line": 264,
        "end_line": 283,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.clyp.ClypIE._real_extract#26",
        "src_path": "youtube_dl/extractor/clyp.py",
        "class_name": "youtube_dl.extractor.clyp.ClypIE",
        "signature": "youtube_dl.extractor.clyp.ClypIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        audio_id = self._match_id(url)\n\n        metadata = self._download_json(\n            'https://api.clyp.it/%s' % audio_id, audio_id)\n\n        formats = []\n        for secure in ('', 'Secure'):\n            for ext in ('Ogg', 'Mp3'):\n                format_id = '%s%s' % (secure, ext)\n                format_url = metadata.get('%sUrl' % format_id)\n                if format_url:\n                    formats.append({\n                        'url': format_url,\n                        'format_id': format_id,\n                        'vcodec': 'none',\n                    })\n        self._sort_formats(formats)\n\n        title = metadata['Title']\n        description = metadata.get('Description')\n        duration = float_or_none(metadata.get('Duration'))\n        timestamp = parse_iso8601(metadata.get('DateCreated'))\n\n        return {\n            'id': audio_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.fktv.FKTVIE._real_extract#28",
        "src_path": "youtube_dl/extractor/fktv.py",
        "class_name": "youtube_dl.extractor.fktv.FKTVIE",
        "signature": "youtube_dl.extractor.fktv.FKTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        episode = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://fernsehkritik.tv/folge-%s/play' % episode, episode)\n        title = clean_html(self._html_search_regex(\n            '<h3>([^<]+)</h3>', webpage, 'title'))\n        matches = re.search(\n            r'(?s)<video(?:(?!poster)[^>])+(?:poster=\"([^\"]+)\")?[^>]*>(.*)</video>',\n            webpage)\n        if matches is None:\n            raise ExtractorError('Unable to extract the video')\n\n        poster, sources = matches.groups()\n        if poster is None:\n            self.report_warning('unable to extract thumbnail')\n\n        urls = re.findall(r'<source[^>]+src=\"([^\"]+)\"', sources)\n        formats = [{\n            'url': furl,\n            'format_id': determine_ext(furl),\n        } for furl in urls]\n        return {\n            'id': episode,\n            'title': title,\n            'formats': formats,\n            'thumbnail': poster,\n        }",
        "begin_line": 28,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightIE._real_initialize#38",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 38,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightIE._login#41",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            self.raise_login_required('Pluralsight account is required')\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None, 'Downloading login page')\n\n        login_form = self._hidden_inputs(login_page)\n\n        login_form.update({\n            'Username': username.encode('utf-8'),\n            'Password': password.encode('utf-8'),\n        })\n\n        post_url = self._search_regex(\n            r'<form[^>]+action=([\"\\'])(?P<url>.+?)\\1', login_page,\n            'post url', default=self._LOGIN_URL, group='url')\n\n        if not post_url.startswith('http'):\n            post_url = compat_urlparse.urljoin(self._LOGIN_URL, post_url)\n\n        request = compat_urllib_request.Request(\n            post_url, compat_urllib_parse.urlencode(login_form).encode('utf-8'))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n\n        response = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        error = self._search_regex(\n            r'<span[^>]+class=\"field-validation-error\"[^>]*>([^<]+)</span>',\n            response, 'error message', default=None)\n        if error:\n            raise ExtractorError('Unable to login: %s' % error, expected=True)",
        "begin_line": 41,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightIE._real_extract#76",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        author = mobj.group('author')\n        name = mobj.group('name')\n        clip_id = mobj.group('clip')\n        course = mobj.group('course')\n\n        display_id = '%s-%s' % (name, clip_id)\n\n        webpage = self._download_webpage(url, display_id)\n\n        collection = self._parse_json(\n            self._search_regex(\n                r'moduleCollection\\s*:\\s*new\\s+ModuleCollection\\((\\[.+?\\])\\s*,\\s*\\$rootScope\\)',\n                webpage, 'modules'),\n            display_id)\n\n        module, clip = None, None\n\n        for module_ in collection:\n            if module_.get('moduleName') == name:\n                module = module_\n                for clip_ in module_.get('clips', []):\n                    clip_index = clip_.get('clipIndex')\n                    if clip_index is None:\n                        continue\n                    if compat_str(clip_index) == clip_id:\n                        clip = clip_\n                        break\n\n        if not clip:\n            raise ExtractorError('Unable to resolve clip')\n\n        QUALITIES = {\n            'low': {'width': 640, 'height': 480},\n            'medium': {'width': 848, 'height': 640},\n            'high': {'width': 1024, 'height': 768},\n        }\n\n        ALLOWED_QUALITIES = (\n            ('webm', ('high',)),\n            ('mp4', ('low', 'medium', 'high',)),\n        )\n\n        formats = []\n        for ext, qualities in ALLOWED_QUALITIES:\n            for quality in qualities:\n                f = QUALITIES[quality].copy()\n                clip_post = {\n                    'a': author,\n                    'cap': 'false',\n                    'cn': clip_id,\n                    'course': course,\n                    'lc': 'en',\n                    'm': name,\n                    'mt': ext,\n                    'q': '%dx%d' % (f['width'], f['height']),\n                }\n                request = compat_urllib_request.Request(\n                    'http://www.pluralsight.com/training/Player/ViewClip',\n                    json.dumps(clip_post).encode('utf-8'))\n                request.add_header('Content-Type', 'application/json;charset=utf-8')\n                format_id = '%s-%s' % (ext, quality)\n                clip_url = self._download_webpage(\n                    request, display_id, 'Downloading %s URL' % format_id, fatal=False)\n                if not clip_url:\n                    continue\n                f.update({\n                    'url': clip_url,\n                    'ext': ext,\n                    'format_id': format_id,\n                })\n                formats.append(f)\n        self._sort_formats(formats)\n\n        # TODO: captions\n        # http://www.pluralsight.com/training/Player/ViewClip + cap = true\n        # or\n        # http://www.pluralsight.com/training/Player/Captions\n        # { a = author, cn = clip_id, lc = end, m = name }\n\n        return {\n            'id': clip['clipName'],\n            'title': '%s - %s' % (module['title'], clip['title']),\n            'duration': int_or_none(clip.get('duration')) or parse_duration(clip.get('formattedDuration')),\n            'creator': author,\n            'formats': formats\n        }",
        "begin_line": 76,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightCourseIE._real_extract#181",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightCourseIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        course_id = self._match_id(url)\n\n        # TODO: PSM cookie\n\n        course = self._download_json(\n            'http://www.pluralsight.com/data/course/%s' % course_id,\n            course_id, 'Downloading course JSON')\n\n        title = course['title']\n        description = course.get('description') or course.get('shortDescription')\n\n        course_data = self._download_json(\n            'http://www.pluralsight.com/data/course/content/%s' % course_id,\n            course_id, 'Downloading course data JSON')\n\n        entries = []\n        for module in course_data:\n            for clip in module.get('clips', []):\n                player_parameters = clip.get('playerParameters')\n                if not player_parameters:\n                    continue\n                entries.append(self.url_result(\n                    'http://www.pluralsight.com/training/player?%s' % player_parameters,\n                    'Pluralsight'))\n\n        return self.playlist_result(entries, course_id, title, description)",
        "begin_line": 181,
        "end_line": 207,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._real_extract#27",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        news_id = self._match_id(url)\n        page = self._download_webpage(url, news_id)\n        return self._extract_from_nextmedia_page(news_id, url, page)",
        "begin_line": 27,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._extract_from_nextmedia_page#32",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._extract_from_nextmedia_page(self, news_id, url, page)",
        "snippet": "    def _extract_from_nextmedia_page(self, news_id, url, page):\n        title = self._fetch_title(page)\n        video_url = self._search_regex(self._URL_PATTERN, page, 'video url')\n\n        attrs = {\n            'id': news_id,\n            'title': title,\n            'url': video_url,  # ext can be inferred from url\n            'thumbnail': self._fetch_thumbnail(page),\n            'description': self._fetch_description(page),\n        }\n\n        timestamp = self._fetch_timestamp(page)\n        if timestamp:\n            attrs['timestamp'] = timestamp\n        else:\n            attrs['upload_date'] = self._fetch_upload_date(url)\n\n        return attrs",
        "begin_line": 32,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_title#52",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_title(self, page)",
        "snippet": "    def _fetch_title(self, page):\n        return self._og_search_title(page)",
        "begin_line": 52,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_thumbnail#55",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_thumbnail(self, page)",
        "snippet": "    def _fetch_thumbnail(self, page):\n        return self._og_search_thumbnail(page)",
        "begin_line": 55,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_timestamp#58",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_timestamp(self, page)",
        "snippet": "    def _fetch_timestamp(self, page):\n        dateCreated = self._search_regex('\"dateCreated\":\"([^\"]+)\"', page, 'created time')\n        return parse_iso8601(dateCreated)",
        "begin_line": 58,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_upload_date#62",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_upload_date(self, url)",
        "snippet": "    def _fetch_upload_date(self, url):\n        return self._search_regex(self._VALID_URL, url, 'upload date', group='date')",
        "begin_line": 62,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_description#65",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_description(self, page)",
        "snippet": "    def _fetch_description(self, page):\n        return self._og_search_property('description', page)",
        "begin_line": 65,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaActionNewsIE._real_extract#86",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaActionNewsIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaActionNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        news_id = self._match_id(url)\n        actionnews_page = self._download_webpage(url, news_id)\n        article_url = self._og_search_url(actionnews_page)\n        article_page = self._download_webpage(article_url, news_id)\n        return self._extract_from_nextmedia_page(news_id, url, article_page)",
        "begin_line": 86,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_title#161",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.AppleDailyIE",
        "signature": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_title(self, page)",
        "snippet": "    def _fetch_title(self, page):\n        return (self._html_search_regex(r'<h1 id=\"h1\">([^<>]+)</h1>', page, 'news title', default=None) or\n                self._html_search_meta('description', page, 'news title'))",
        "begin_line": 161,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_thumbnail#165",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.AppleDailyIE",
        "signature": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_thumbnail(self, page)",
        "snippet": "    def _fetch_thumbnail(self, page):\n        return self._html_search_regex(r\"setInitialImage\\(\\'([^']+)'\\)\", page, 'video thumbnail', fatal=False)",
        "begin_line": 165,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_timestamp#168",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.AppleDailyIE",
        "signature": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_timestamp(self, page)",
        "snippet": "    def _fetch_timestamp(self, page):\n        return None",
        "begin_line": 168,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_description#171",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.AppleDailyIE",
        "signature": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_description(self, page)",
        "snippet": "    def _fetch_description(self, page):\n        return self._html_search_meta('description', page, 'news description')",
        "begin_line": 171,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ir90tv.Ir90TvIE._real_extract#24",
        "src_path": "youtube_dl/extractor/ir90tv.py",
        "class_name": "youtube_dl.extractor.ir90tv.Ir90TvIE",
        "signature": "youtube_dl.extractor.ir90tv.Ir90TvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = remove_start(self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title'), '90tv.ir :: ')\n\n        video_url = self._search_regex(\n            r'<source[^>]+src=\"([^\"]+)\"', webpage, 'video url')\n\n        thumbnail = self._search_regex(r'poster=\"([^\"]+)\"', webpage, 'thumbnail url', fatal=False)\n\n        return {\n            'url': video_url,\n            'id': video_id,\n            'title': title,\n            'video_url': video_url,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 24,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ro220.Ro220IE._real_extract#21",
        "src_path": "youtube_dl/extractor/ro220.py",
        "class_name": "youtube_dl.extractor.ro220.Ro220IE",
        "signature": "youtube_dl.extractor.ro220.Ro220IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        url = compat_urllib_parse_unquote(self._search_regex(\n            r'(?s)clip\\s*:\\s*{.*?url\\s*:\\s*\\'([^\\']+)\\'', webpage, 'url'))\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n            'ext': 'mp4',\n        }]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 21,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE._encrypt#24",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE._encrypt(cls, dfsid)",
        "snippet": "    def _encrypt(cls, dfsid):\n        salt_bytes = bytearray(cls._NETEASE_SALT.encode('utf-8'))\n        string_bytes = bytearray(compat_str(dfsid).encode('ascii'))\n        salt_len = len(salt_bytes)\n        for i in range(len(string_bytes)):\n            string_bytes[i] = string_bytes[i] ^ salt_bytes[i % salt_len]\n        m = md5()\n        m.update(bytes(string_bytes))\n        result = b64encode(m.digest()).decode('ascii')\n        return result.replace('/', '_').replace('+', '-')",
        "begin_line": 24,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.extract_formats#36",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.extract_formats(cls, info)",
        "snippet": "    def extract_formats(cls, info):\n        formats = []\n        for song_format in cls._FORMATS:\n            details = info.get(song_format)\n            if not details:\n                continue\n            formats.append({\n                'url': 'http://m1.music.126.net/%s/%s.%s' %\n                       (cls._encrypt(details['dfsId']), details['dfsId'],\n                        details['extension']),\n                'ext': details.get('extension'),\n                'abr': details.get('bitrate', 0) / 1000,\n                'format_id': song_format,\n                'filesize': details.get('size'),\n                'asr': details.get('sr')\n            })\n        return formats",
        "begin_line": 36,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.convert_milliseconds#55",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.convert_milliseconds(cls, ms)",
        "snippet": "    def convert_milliseconds(cls, ms):\n        return int(round(ms / 1000.0))",
        "begin_line": 55,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.query_api#58",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.query_api(self, endpoint, video_id, note)",
        "snippet": "    def query_api(self, endpoint, video_id, note):\n        req = compat_urllib_request.Request('%s%s' % (self._API_BASE, endpoint))\n        req.add_header('Referer', self._API_BASE)\n        return self._download_json(req, video_id, note)",
        "begin_line": 58,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE._process_lyrics#118",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE._process_lyrics(self, lyrics_info)",
        "snippet": "    def _process_lyrics(self, lyrics_info):\n        original = lyrics_info.get('lrc', {}).get('lyric')\n        translated = lyrics_info.get('tlyric', {}).get('lyric')\n\n        if not translated:\n            return original\n\n        lyrics_expr = r'(\\[[0-9]{2}:[0-9]{2}\\.[0-9]{2,}\\])([^\\n]+)'\n        original_ts_texts = re.findall(lyrics_expr, original)\n        translation_ts_dict = dict(\n            (time_stamp, text) for time_stamp, text in re.findall(lyrics_expr, translated)\n        )\n        lyrics = '\\n'.join([\n            '%s%s / %s' % (time_stamp, text, translation_ts_dict.get(time_stamp, ''))\n            for time_stamp, text in original_ts_texts\n        ])\n        return lyrics",
        "begin_line": 118,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE._real_extract#136",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n\n        params = {\n            'id': song_id,\n            'ids': '[%s]' % song_id\n        }\n        info = self.query_api(\n            'song/detail?' + compat_urllib_parse.urlencode(params),\n            song_id, 'Downloading song info')['songs'][0]\n\n        formats = self.extract_formats(info)\n        self._sort_formats(formats)\n\n        lyrics_info = self.query_api(\n            'song/lyric?id=%s&lv=-1&tv=-1' % song_id,\n            song_id, 'Downloading lyrics data')\n        lyrics = self._process_lyrics(lyrics_info)\n\n        alt_title = None\n        if info.get('transNames'):\n            alt_title = '/'.join(info.get('transNames'))\n\n        return {\n            'id': song_id,\n            'title': info['name'],\n            'alt_title': alt_title,\n            'creator': ' / '.join([artist['name'] for artist in info.get('artists', [])]),\n            'timestamp': self.convert_milliseconds(info.get('album', {}).get('publishTime')),\n            'thumbnail': info.get('album', {}).get('picUrl'),\n            'duration': self.convert_milliseconds(info.get('duration', 0)),\n            'description': lyrics,\n            'formats': formats,\n        }",
        "begin_line": 136,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicAlbumIE._real_extract#185",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicAlbumIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        album_id = self._match_id(url)\n\n        info = self.query_api(\n            'album/%s?id=%s' % (album_id, album_id),\n            album_id, 'Downloading album data')['album']\n\n        name = info['name']\n        desc = info.get('description')\n        entries = [\n            self.url_result('http://music.163.com/#/song?id=%s' % song['id'],\n                            'NetEaseMusic', song['id'])\n            for song in info['songs']\n        ]\n        return self.playlist_result(entries, album_id, name, desc)",
        "begin_line": 185,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicSingerIE._real_extract#224",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicSingerIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicSingerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        singer_id = self._match_id(url)\n\n        info = self.query_api(\n            'artist/%s?id=%s' % (singer_id, singer_id),\n            singer_id, 'Downloading singer data')\n\n        name = info['artist']['name']\n        if info['artist']['trans']:\n            name = '%s - %s' % (name, info['artist']['trans'])\n        if info['artist']['alias']:\n            name = '%s - %s' % (name, ';'.join(info['artist']['alias']))\n\n        entries = [\n            self.url_result('http://music.163.com/#/song?id=%s' % song['id'],\n                            'NetEaseMusic', song['id'])\n            for song in info['hotSongs']\n        ]\n        return self.playlist_result(entries, singer_id, name)",
        "begin_line": 224,
        "end_line": 242,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicListIE._real_extract#268",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicListIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n\n        info = self.query_api(\n            'playlist/detail?id=%s&lv=-1&tv=-1' % list_id,\n            list_id, 'Downloading playlist data')['result']\n\n        name = info['name']\n        desc = info.get('description')\n\n        if info.get('specialType') == 10:  # is a chart/toplist\n            datestamp = datetime.fromtimestamp(\n                self.convert_milliseconds(info['updateTime'])).strftime('%Y-%m-%d')\n            name = '%s %s' % (name, datestamp)\n\n        entries = [\n            self.url_result('http://music.163.com/#/song?id=%s' % song['id'],\n                            'NetEaseMusic', song['id'])\n            for song in info['tracks']\n        ]\n        return self.playlist_result(entries, list_id, name, desc)",
        "begin_line": 268,
        "end_line": 288,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicMvIE._real_extract#307",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicMvIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicMvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mv_id = self._match_id(url)\n\n        info = self.query_api(\n            'mv/detail?id=%s&type=mp4' % mv_id,\n            mv_id, 'Downloading mv info')['data']\n\n        formats = [\n            {'url': mv_url, 'ext': 'mp4', 'format_id': '%sp' % brs, 'height': int(brs)}\n            for brs, mv_url in info['brs'].items()\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': mv_id,\n            'title': info['name'],\n            'description': info.get('desc') or info.get('briefDesc'),\n            'creator': info['artistName'],\n            'upload_date': info['publishTime'].replace('-', ''),\n            'formats': formats,\n            'thumbnail': info.get('cover'),\n            'duration': self.convert_milliseconds(info.get('duration', 0)),\n        }",
        "begin_line": 307,
        "end_line": 329,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicProgramIE._real_extract#373",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicProgramIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicProgramIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        program_id = self._match_id(url)\n\n        info = self.query_api(\n            'dj/program/detail?id=%s' % program_id,\n            program_id, 'Downloading program info')['program']\n\n        name = info['name']\n        description = info['description']\n\n        if not info['songs'] or self._downloader.params.get('noplaylist'):\n            if info['songs']:\n                self.to_screen(\n                    'Downloading just the main audio %s because of --no-playlist'\n                    % info['mainSong']['id'])\n\n            formats = self.extract_formats(info['mainSong'])\n            self._sort_formats(formats)\n\n            return {\n                'id': program_id,\n                'title': name,\n                'description': description,\n                'creator': info['dj']['brand'],\n                'timestamp': self.convert_milliseconds(info['createTime']),\n                'thumbnail': info['coverUrl'],\n                'duration': self.convert_milliseconds(info.get('duration', 0)),\n                'formats': formats,\n            }\n\n        self.to_screen(\n            'Downloading playlist %s - add --no-playlist to just download the main audio %s'\n            % (program_id, info['mainSong']['id']))\n\n        song_ids = [info['mainSong']['id']]\n        song_ids.extend([song['id'] for song in info['songs']])\n        entries = [\n            self.url_result('http://music.163.com/#/song?id=%s' % song_id,\n                            'NetEaseMusic', song_id)\n            for song_id in song_ids\n        ]\n        return self.playlist_result(entries, program_id, name, description)",
        "begin_line": 373,
        "end_line": 414,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicDjRadioIE._real_extract#432",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicDjRadioIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicDjRadioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        dj_id = self._match_id(url)\n\n        name = None\n        desc = None\n        entries = []\n        for offset in compat_itertools_count(start=0, step=self._PAGE_SIZE):\n            info = self.query_api(\n                'dj/program/byradio?asc=false&limit=%d&radioId=%s&offset=%d'\n                % (self._PAGE_SIZE, dj_id, offset),\n                dj_id, 'Downloading dj programs - %d' % offset)\n\n            entries.extend([\n                self.url_result(\n                    'http://music.163.com/#/program?id=%s' % program['id'],\n                    'NetEaseMusicProgram', program['id'])\n                for program in info['programs']\n            ])\n\n            if name is None:\n                radio = info['programs'][0]['radio']\n                name = radio['name']\n                desc = radio['desc']\n\n            if not info['more']:\n                break\n\n        return self.playlist_result(entries, dj_id, name, desc)",
        "begin_line": 432,
        "end_line": 459,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.khanacademy.KhanAcademyIE._real_extract#39",
        "src_path": "youtube_dl/extractor/khanacademy.py",
        "class_name": "youtube_dl.extractor.khanacademy.KhanAcademyIE",
        "signature": "youtube_dl.extractor.khanacademy.KhanAcademyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        if m.group('key') == 'video':\n            data = self._download_json(\n                'http://api.khanacademy.org/api/v1/videos/' + video_id,\n                video_id, 'Downloading video info')\n\n            upload_date = unified_strdate(data['date_added'])\n            uploader = ', '.join(data['author_names'])\n            return {\n                '_type': 'url_transparent',\n                'url': data['url'],\n                'id': video_id,\n                'title': data['title'],\n                'thumbnail': data['image_url'],\n                'duration': data['duration'],\n                'description': data['description'],\n                'uploader': uploader,\n                'upload_date': upload_date,\n            }\n        else:\n            # topic\n            data = self._download_json(\n                'http://api.khanacademy.org/api/v1/topic/' + video_id,\n                video_id, 'Downloading topic info')\n\n            entries = [\n                {\n                    '_type': 'url',\n                    'url': c['url'],\n                    'id': c['id'],\n                    'title': c['title'],\n                }\n                for c in data['children'] if c['kind'] in ('Video', 'Topic')]\n\n            return {\n                '_type': 'playlist',\n                'id': video_id,\n                'title': data['title'],\n                'description': data['description'],\n                'entries': entries,\n            }",
        "begin_line": 39,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ku6.Ku6IE._real_extract#18",
        "src_path": "youtube_dl/extractor/ku6.py",
        "class_name": "youtube_dl.extractor.ku6.Ku6IE",
        "signature": "youtube_dl.extractor.ku6.Ku6IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h1 title=.*>(.*?)</h1>', webpage, 'title')\n        dataUrl = 'http://v.ku6.com/fetchVideo4Player/%s.html' % video_id\n        jsonData = self._download_json(dataUrl, video_id)\n        downloadUrl = jsonData['data']['f']\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': downloadUrl\n        }",
        "begin_line": 18,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubIE._extract_url#43",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?pornhub\\.com/embed/\\d+)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 43,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubIE._extract_count#49",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubIE._extract_count(self, pattern, webpage, name)",
        "snippet": "    def _extract_count(self, pattern, webpage, name):\n        return str_to_int(self._search_regex(\n            pattern, webpage, '%s count' % name, fatal=False))",
        "begin_line": 49,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubIE._real_extract#53",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        req = compat_urllib_request.Request(\n            'http://www.pornhub.com/view_video.php?viewkey=%s' % video_id)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        error_msg = self._html_search_regex(\n            r'(?s)<div class=\"userMessageSection[^\"]*\".*?>(.*?)</div>',\n            webpage, 'error message', default=None)\n        if error_msg:\n            error_msg = re.sub(r'\\s+', ' ', error_msg)\n            raise ExtractorError(\n                'PornHub said: %s' % error_msg,\n                expected=True, video_id=video_id)\n\n        video_title = self._html_search_regex(r'<h1 [^>]+>([^<]+)', webpage, 'title')\n        video_uploader = self._html_search_regex(\n            r'(?s)From:&nbsp;.+?<(?:a href=\"/users/|a href=\"/channels/|span class=\"username)[^>]+>(.+?)<',\n            webpage, 'uploader', fatal=False)\n        thumbnail = self._html_search_regex(r'\"image_url\":\"([^\"]+)', webpage, 'thumbnail', fatal=False)\n        if thumbnail:\n            thumbnail = compat_urllib_parse_unquote(thumbnail)\n\n        view_count = self._extract_count(\n            r'<span class=\"count\">([\\d,\\.]+)</span> views', webpage, 'view')\n        like_count = self._extract_count(\n            r'<span class=\"votesUp\">([\\d,\\.]+)</span>', webpage, 'like')\n        dislike_count = self._extract_count(\n            r'<span class=\"votesDown\">([\\d,\\.]+)</span>', webpage, 'dislike')\n        comment_count = self._extract_count(\n            r'All Comments\\s*<span>\\(([\\d,.]+)\\)', webpage, 'comment')\n\n        video_urls = list(map(compat_urllib_parse_unquote, re.findall(r\"player_quality_[0-9]{3}p\\s*=\\s*'([^']+)'\", webpage)))\n        if webpage.find('\"encrypted\":true') != -1:\n            password = compat_urllib_parse_unquote_plus(\n                self._search_regex(r'\"video_title\":\"([^\"]+)', webpage, 'password'))\n            video_urls = list(map(lambda s: aes_decrypt_text(s, password, 32).decode('utf-8'), video_urls))\n\n        formats = []\n        for video_url in video_urls:\n            path = compat_urllib_parse_urlparse(video_url).path\n            extension = os.path.splitext(path)[1][1:]\n            format = path.split('/')[5].split('_')[:2]\n            format = \"-\".join(format)\n\n            m = re.match(r'^(?P<height>[0-9]+)[pP]-(?P<tbr>[0-9]+)[kK]$', format)\n            if m is None:\n                height = None\n                tbr = None\n            else:\n                height = int(m.group('height'))\n                tbr = int(m.group('tbr'))\n\n            formats.append({\n                'url': video_url,\n                'ext': extension,\n                'format': format,\n                'format_id': format,\n                'tbr': tbr,\n                'height': height,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 53,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubPlaylistIE._real_extract#143",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubPlaylistIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = [\n            self.url_result('http://www.pornhub.com/%s' % video_url, 'PornHub')\n            for video_url in set(re.findall('href=\"/?(view_video\\.php\\?viewkey=\\d+[^\"]*)\"', webpage))\n        ]\n\n        playlist = self._parse_json(\n            self._search_regex(\n                r'playlistObject\\s*=\\s*({.+?});', webpage, 'playlist'),\n            playlist_id)\n\n        return self.playlist_result(\n            entries, playlist_id, playlist.get('title'), playlist.get('description'))",
        "begin_line": 143,
        "end_line": 159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.snagfilms.SnagFilmsEmbedIE._extract_url#41",
        "src_path": "youtube_dl/extractor/snagfilms.py",
        "class_name": "youtube_dl.extractor.snagfilms.SnagFilmsEmbedIE",
        "signature": "youtube_dl.extractor.snagfilms.SnagFilmsEmbedIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:embed\\.)?snagfilms\\.com/embed/player.+?)\\1',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 41,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.snagfilms.SnagFilmsEmbedIE._real_extract#48",
        "src_path": "youtube_dl/extractor/snagfilms.py",
        "class_name": "youtube_dl.extractor.snagfilms.SnagFilmsEmbedIE",
        "signature": "youtube_dl.extractor.snagfilms.SnagFilmsEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        if '>This film is not playable in your area.<' in webpage:\n            raise ExtractorError(\n                'Film %s is not playable in your area.' % video_id, expected=True)\n\n        formats = []\n        for source in self._parse_json(js_to_json(self._search_regex(\n                r'(?s)sources:\\s*(\\[.+?\\]),', webpage, 'json')), video_id):\n            file_ = source.get('file')\n            if not file_:\n                continue\n            type_ = source.get('type')\n            ext = determine_ext(file_)\n            format_id = source.get('label') or ext\n            if all(v == 'm3u8' for v in (type_, ext)):\n                formats.extend(self._extract_m3u8_formats(\n                    file_, video_id, 'mp4', m3u8_id='hls'))\n            else:\n                bitrate = int_or_none(self._search_regex(\n                    [r'(\\d+)kbps', r'_\\d{1,2}x\\d{1,2}_(\\d{3,})\\.%s' % ext],\n                    file_, 'bitrate', default=None))\n                height = int_or_none(self._search_regex(\n                    r'^(\\d+)[pP]$', format_id, 'height', default=None))\n                formats.append({\n                    'url': file_,\n                    'format_id': format_id,\n                    'tbr': bitrate,\n                    'height': height,\n                })\n        self._sort_formats(formats)\n\n        title = self._search_regex(\n            [r\"title\\s*:\\s*'([^']+)'\", r'<title>([^<]+)</title>'],\n            webpage, 'title')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n        }",
        "begin_line": 48,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.snagfilms.SnagFilmsIE._real_extract#132",
        "src_path": "youtube_dl/extractor/snagfilms.py",
        "class_name": "youtube_dl.extractor.snagfilms.SnagFilmsIE",
        "signature": "youtube_dl.extractor.snagfilms.SnagFilmsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        if \">Sorry, the Film you're looking for is not available.<\" in webpage:\n            raise ExtractorError(\n                'Film %s is not available.' % display_id, expected=True)\n\n        film_id = self._search_regex(r'filmId=([\\da-f-]{36})\"', webpage, 'film id')\n\n        snag = self._parse_json(\n            self._search_regex(\n                'Snag\\.page\\.data\\s*=\\s*(\\[.+?\\]);', webpage, 'snag'),\n            display_id)\n\n        for item in snag:\n            if item.get('data', {}).get('film', {}).get('id') == film_id:\n                data = item['data']['film']\n                title = data['title']\n                description = clean_html(data.get('synopsis'))\n                thumbnail = data.get('image')\n                duration = int_or_none(data.get('duration') or data.get('runtime'))\n                categories = [\n                    category['title'] for category in data.get('categories', [])\n                    if category.get('title')]\n                break\n        else:\n            title = self._search_regex(\n                r'itemprop=\"title\">([^<]+)<', webpage, 'title')\n            description = self._html_search_regex(\n                r'(?s)<div itemprop=\"description\" class=\"film-synopsis-inner \">(.+?)</div>',\n                webpage, 'description', default=None) or self._og_search_description(webpage)\n            thumbnail = self._og_search_thumbnail(webpage)\n            duration = parse_duration(self._search_regex(\n                r'<span itemprop=\"duration\" class=\"film-duration strong\">([^<]+)<',\n                webpage, 'duration', fatal=False))\n            categories = re.findall(r'<a href=\"/movies/[^\"]+\">([^<]+)</a>', webpage)\n\n        return {\n            '_type': 'url_transparent',\n            'url': 'http://embed.snagfilms.com/embed/player?filmId=%s' % film_id,\n            'id': film_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'categories': categories,\n        }",
        "begin_line": 132,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mlb.MLBIE._real_extract#124",
        "src_path": "youtube_dl/extractor/mlb.py",
        "class_name": "youtube_dl.extractor.mlb.MLBIE",
        "signature": "youtube_dl.extractor.mlb.MLBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        if not video_id:\n            video_path = mobj.group('path')\n            webpage = self._download_webpage(url, video_path)\n            video_id = self._search_regex(\n                [r'data-video-?id=\"(\\d+)\"', r'content_id=(\\d+)'], webpage, 'video id')\n\n        detail = self._download_xml(\n            'http://m.mlb.com/gen/multimedia/detail/%s/%s/%s/%s.xml'\n            % (video_id[-3], video_id[-2], video_id[-1], video_id), video_id)\n\n        title = detail.find('./headline').text\n        description = detail.find('./big-blurb').text\n        duration = parse_duration(detail.find('./duration').text)\n        timestamp = parse_iso8601(detail.attrib['date'][:-5])\n\n        thumbnails = [{\n            'url': thumbnail.text,\n        } for thumbnail in detail.findall('./thumbnailScenarios/thumbnailScenario')]\n\n        formats = []\n        for media_url in detail.findall('./url'):\n            playback_scenario = media_url.attrib['playback_scenario']\n            fmt = {\n                'url': media_url.text,\n                'format_id': playback_scenario,\n            }\n            m = re.search(r'(?P<vbr>\\d+)K_(?P<width>\\d+)X(?P<height>\\d+)', playback_scenario)\n            if m:\n                fmt.update({\n                    'vbr': int(m.group('vbr')) * 1000,\n                    'width': int(m.group('width')),\n                    'height': int(m.group('height')),\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 124,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.gamespot.GameSpotIE._real_extract#37",
        "src_path": "youtube_dl/extractor/gamespot.py",
        "class_name": "youtube_dl.extractor.gamespot.GameSpotIE",
        "signature": "youtube_dl.extractor.gamespot.GameSpotIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n        webpage = self._download_webpage(url, page_id)\n        data_video_json = self._search_regex(\n            r'data-video=[\"\\'](.*?)[\"\\']', webpage, 'data video')\n        data_video = json.loads(unescapeHTML(data_video_json))\n        streams = data_video['videoStreams']\n\n        formats = []\n        f4m_url = streams.get('f4m_stream')\n        if f4m_url is not None:\n            # Transform the manifest url to a link to the mp4 files\n            # they are used in mobile devices.\n            f4m_path = compat_urlparse.urlparse(f4m_url).path\n            QUALITIES_RE = r'((,\\d+)+,?)'\n            qualities = self._search_regex(QUALITIES_RE, f4m_path, 'qualities').strip(',').split(',')\n            http_path = f4m_path[1:].split('/', 1)[1]\n            http_template = re.sub(QUALITIES_RE, r'%s', http_path)\n            http_template = http_template.replace('.csmil/manifest.f4m', '')\n            http_template = compat_urlparse.urljoin(\n                'http://video.gamespotcdn.com/', http_template)\n            for q in qualities:\n                formats.append({\n                    'url': http_template % q,\n                    'ext': 'mp4',\n                    'format_id': q,\n                })\n        else:\n            for quality in ['sd', 'hd']:\n                # It's actually a link to a flv file\n                flv_url = streams.get('f4m_{0}'.format(quality))\n                if flv_url is not None:\n                    formats.append({\n                        'url': flv_url,\n                        'ext': 'flv',\n                        'format_id': quality,\n                    })\n\n        return {\n            'id': data_video['guid'],\n            'display_id': page_id,\n            'title': compat_urllib_parse_unquote(data_video['title']),\n            'formats': formats,\n            'description': self._html_search_meta('description', webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 37,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sportdeutschland.SportDeutschlandIE._real_extract#50",
        "src_path": "youtube_dl/extractor/sportdeutschland.py",
        "class_name": "youtube_dl.extractor.sportdeutschland.SportDeutschlandIE",
        "signature": "youtube_dl.extractor.sportdeutschland.SportDeutschlandIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        sport_id = mobj.group('sport')\n\n        api_url = 'http://proxy.vidibusdynamic.net/sportdeutschland.tv/api/permalinks/%s/%s?access_token=true' % (\n            sport_id, video_id)\n        req = compat_urllib_request.Request(api_url, headers={\n            'Accept': 'application/vnd.vidibus.v2.html+json',\n            'Referer': url,\n        })\n        data = self._download_json(req, video_id)\n\n        asset = data['asset']\n        categories = [data['section']['title']]\n\n        formats = []\n        smil_url = asset['video']\n        if '.smil' in smil_url:\n            m3u8_url = smil_url.replace('.smil', '.m3u8')\n            formats.extend(\n                self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4'))\n\n            smil_doc = self._download_xml(\n                smil_url, video_id, note='Downloading SMIL metadata')\n            base_url = smil_doc.find('./head/meta').attrib['base']\n            formats.extend([{\n                'format_id': 'rmtp',\n                'url': base_url,\n                'play_path': n.attrib['src'],\n                'ext': 'flv',\n                'preference': -100,\n                'format_note': 'Seems to fail at example stream',\n            } for n in smil_doc.findall('./body/video')])\n        else:\n            formats.append({'url': smil_url})\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': asset['title'],\n            'thumbnail': asset.get('image'),\n            'description': asset.get('teaser'),\n            'duration': asset.get('duration'),\n            'categories': categories,\n            'view_count': asset.get('views'),\n            'rtmp_live': asset.get('live'),\n            'timestamp': parse_iso8601(asset.get('date')),\n        }",
        "begin_line": 50,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sohu.SohuIE._real_extract#91",
        "src_path": "youtube_dl/extractor/sohu.py",
        "class_name": "youtube_dl.extractor.sohu.SohuIE",
        "signature": "youtube_dl.extractor.sohu.SohuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n\n        def _fetch_data(vid_id, mytv=False):\n            if mytv:\n                base_data_url = 'http://my.tv.sohu.com/play/videonew.do?vid='\n            else:\n                base_data_url = 'http://hot.vrs.sohu.com/vrs_flash.action?vid='\n\n            req = compat_urllib_request.Request(base_data_url + vid_id)\n\n            cn_verification_proxy = self._downloader.params.get('cn_verification_proxy')\n            if cn_verification_proxy:\n                req.add_header('Ytdl-request-proxy', cn_verification_proxy)\n\n            return self._download_json(\n                req, video_id,\n                'Downloading JSON data for %s' % vid_id)\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        mytv = mobj.group('mytv') is not None\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = re.sub(r' - \u641c\u72d0\u89c6\u9891$', '', self._og_search_title(webpage))\n\n        vid = self._html_search_regex(\n            r'var vid ?= ?[\"\\'](\\d+)[\"\\']',\n            webpage, 'video path')\n        vid_data = _fetch_data(vid, mytv)\n        if vid_data['play'] != 1:\n            if vid_data.get('status') == 12:\n                raise ExtractorError(\n                    'Sohu said: There\\'s something wrong in the video.',\n                    expected=True)\n            else:\n                raise ExtractorError(\n                    'Sohu said: The video is only licensed to users in Mainland China.',\n                    expected=True)\n\n        formats_json = {}\n        for format_id in ('nor', 'high', 'super', 'ori', 'h2644k', 'h2654k'):\n            vid_id = vid_data['data'].get('%sVid' % format_id)\n            if not vid_id:\n                continue\n            vid_id = compat_str(vid_id)\n            formats_json[format_id] = vid_data if vid == vid_id else _fetch_data(vid_id, mytv)\n\n        part_count = vid_data['data']['totalBlocks']\n\n        playlist = []\n        for i in range(part_count):\n            formats = []\n            for format_id, format_data in formats_json.items():\n                allot = format_data['allot']\n\n                data = format_data['data']\n                clips_url = data['clipsURL']\n                su = data['su']\n\n                video_url = 'newflv.sohu.ccgslb.net'\n                cdnId = None\n                retries = 0\n\n                while 'newflv.sohu.ccgslb.net' in video_url:\n                    params = {\n                        'prot': 9,\n                        'file': clips_url[i],\n                        'new': su[i],\n                        'prod': 'flash',\n                    }\n\n                    if cdnId is not None:\n                        params['idc'] = cdnId\n\n                    download_note = 'Downloading %s video URL part %d of %d' % (\n                        format_id, i + 1, part_count)\n\n                    if retries > 0:\n                        download_note += ' (retry #%d)' % retries\n                    part_info = self._parse_json(self._download_webpage(\n                        'http://%s/?%s' % (allot, compat_urllib_parse.urlencode(params)),\n                        video_id, download_note), video_id)\n\n                    video_url = part_info['url']\n                    cdnId = part_info.get('nid')\n\n                    retries += 1\n                    if retries > 5:\n                        raise ExtractorError('Failed to get video URL')\n\n                formats.append({\n                    'url': video_url,\n                    'format_id': format_id,\n                    'filesize': data['clipsBytes'][i],\n                    'width': data['width'],\n                    'height': data['height'],\n                    'fps': data['fps'],\n                })\n            self._sort_formats(formats)\n\n            playlist.append({\n                'id': '%s_part%d' % (video_id, i + 1),\n                'title': title,\n                'duration': vid_data['data']['clipsDuration'][i],\n                'formats': formats,\n            })\n\n        if len(playlist) == 1:\n            info = playlist[0]\n            info['id'] = video_id\n        else:\n            info = {\n                '_type': 'multi_video',\n                'entries': playlist,\n                'id': video_id,\n                'title': title,\n            }\n\n        return info",
        "begin_line": 91,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.instagram.InstagramIE._real_extract#26",
        "src_path": "youtube_dl/extractor/instagram.py",
        "class_name": "youtube_dl.extractor.instagram.InstagramIE",
        "signature": "youtube_dl.extractor.instagram.InstagramIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        uploader_id = self._search_regex(r'\"owner\":{\"username\":\"(.+?)\"',\n                                         webpage, 'uploader id', fatal=False)\n        desc = self._search_regex(r'\"caption\":\"(.*?)\"', webpage, 'description',\n                                  fatal=False)\n\n        return {\n            'id': video_id,\n            'url': self._og_search_video_url(webpage, secure=False),\n            'ext': 'mp4',\n            'title': 'Video by %s' % uploader_id,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader_id': uploader_id,\n            'description': desc,\n        }",
        "begin_line": 26,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.instagram.InstagramUserIE._real_extract#75",
        "src_path": "youtube_dl/extractor/instagram.py",
        "class_name": "youtube_dl.extractor.instagram.InstagramUserIE",
        "signature": "youtube_dl.extractor.instagram.InstagramUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader_id = mobj.group('username')\n\n        entries = []\n        page_count = 0\n        media_url = 'http://instagram.com/%s/media' % uploader_id\n        while True:\n            page = self._download_json(\n                media_url, uploader_id,\n                note='Downloading page %d ' % (page_count + 1),\n            )\n            page_count += 1\n\n            for it in page['items']:\n                if it.get('type') != 'video':\n                    continue\n                like_count = int_or_none(it.get('likes', {}).get('count'))\n                user = it.get('user', {})\n\n                formats = [{\n                    'format_id': k,\n                    'height': v.get('height'),\n                    'width': v.get('width'),\n                    'url': v['url'],\n                } for k, v in it['videos'].items()]\n                self._sort_formats(formats)\n\n                thumbnails_el = it.get('images', {})\n                thumbnail = thumbnails_el.get('thumbnail', {}).get('url')\n\n                # In some cases caption is null, which corresponds to None\n                # in python. As a result, it.get('caption', {}) gives None\n                title = (it.get('caption') or {}).get('text', it['id'])\n\n                entries.append({\n                    'id': it['id'],\n                    'title': limit_length(title, 80),\n                    'formats': formats,\n                    'thumbnail': thumbnail,\n                    'webpage_url': it.get('link'),\n                    'uploader': user.get('full_name'),\n                    'uploader_id': user.get('username'),\n                    'like_count': like_count,\n                    'timestamp': int_or_none(it.get('created_time')),\n                })\n\n            if not page['items']:\n                break\n            max_id = page['items'][-1]['id']\n            media_url = (\n                'http://instagram.com/%s/media?max_id=%s' % (\n                    uploader_id, max_id))\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': uploader_id,\n            'title': uploader_id,\n        }",
        "begin_line": 75,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vice.ViceIE._real_extract#29",
        "src_path": "youtube_dl/extractor/vice.py",
        "class_name": "youtube_dl.extractor.vice.ViceIE",
        "signature": "youtube_dl.extractor.vice.ViceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        try:\n            embed_code = self._search_regex(\n                r'embedCode=([^&\\'\"]+)', webpage,\n                'ooyala embed code')\n            ooyala_url = OoyalaIE._url_for_embed_code(embed_code)\n        except ExtractorError:\n            raise ExtractorError('The page doesn\\'t contain a video', expected=True)\n        return self.url_result(ooyala_url, ie='Ooyala')",
        "begin_line": 29,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._login#170",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_page = self._download_webpage(\n            'https://vk.com', None, 'Downloading login page')\n\n        login_form = self._hidden_inputs(login_page)\n\n        login_form.update({\n            'email': username.encode('cp1251'),\n            'pass': password.encode('cp1251'),\n        })\n\n        request = compat_urllib_request.Request(\n            'https://login.vk.com/?act=login',\n            compat_urllib_parse.urlencode(login_form).encode('utf-8'))\n        login_page = self._download_webpage(\n            request, None, note='Logging in as %s' % username)\n\n        if re.search(r'onLoginFailed', login_page):\n            raise ExtractorError(\n                'Unable to login, incorrect username and/or password', expected=True)",
        "begin_line": 170,
        "end_line": 193,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._real_initialize#195",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 195,
        "end_line": 196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._real_extract#198",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        if not video_id:\n            video_id = '%s_%s' % (mobj.group('oid'), mobj.group('id'))\n\n        info_url = 'https://vk.com/al_video.php?act=show&al=1&module=video&video=%s' % video_id\n\n        # Some videos (removed?) can only be downloaded with list id specified\n        list_id = mobj.group('list_id')\n        if list_id:\n            info_url += '&list=%s' % list_id\n\n        info_page = self._download_webpage(info_url, video_id)\n\n        error_message = self._html_search_regex(\n            r'(?s)<!><div[^>]+class=\"video_layer_message\"[^>]*>(.+?)</div>',\n            info_page, 'error message', default=None)\n        if error_message:\n            raise ExtractorError(error_message, expected=True)\n\n        if re.search(r'<!>/login\\.php\\?.*\\bact=security_check', info_page):\n            raise ExtractorError(\n                'You are trying to log in from an unusual location. You should confirm ownership at vk.com to log in with this IP.',\n                expected=True)\n\n        ERRORS = {\n            r'>\u0412\u0438\u0434\u0435\u043e\u0437\u0430\u043f\u0438\u0441\u044c .*? \u0431\u044b\u043b\u0430 \u0438\u0437\u044a\u044f\u0442\u0430 \u0438\u0437 \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u043e\u0433\u043e \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u0432 \u0441\u0432\u044f\u0437\u0438 \u0441 \u043e\u0431\u0440\u0430\u0449\u0435\u043d\u0438\u0435\u043c \u043f\u0440\u0430\u0432\u043e\u043e\u0431\u043b\u0430\u0434\u0430\u0442\u0435\u043b\u044f.<':\n            'Video %s has been removed from public access due to rightholder complaint.',\n\n            r'<!>Please log in or <':\n            'Video %s is only available for registered users, '\n            'use --username and --password options to provide account credentials.',\n\n            r'<!>Unknown error':\n            'Video %s does not exist.',\n\n            r'<!>\u0412\u0438\u0434\u0435\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u043e \u043d\u0435\u0434\u043e\u0441\u0442\u0443\u043f\u043d\u043e':\n            'Video %s is temporarily unavailable.',\n\n            r'<!>Access denied':\n            'Access denied to video %s.',\n        }\n\n        for error_re, error_msg in ERRORS.items():\n            if re.search(error_re, info_page):\n                raise ExtractorError(error_msg % video_id, expected=True)\n\n        youtube_url = self._search_regex(\n            r'<iframe[^>]+src=\"((?:https?:)?//www.youtube.com/embed/[^\"]+)\"',\n            info_page, 'youtube iframe', default=None)\n        if youtube_url:\n            return self.url_result(youtube_url, 'Youtube')\n\n        vimeo_url = VimeoIE._extract_vimeo_url(url, info_page)\n        if vimeo_url is not None:\n            return self.url_result(vimeo_url)\n\n        m_rutube = re.search(\n            r'\\ssrc=\"((?:https?:)?//rutube\\.ru\\\\?/video\\\\?/embed(?:.*?))\\\\?\"', info_page)\n        if m_rutube is not None:\n            self.to_screen('rutube video detected')\n            rutube_url = self._proto_relative_url(\n                m_rutube.group(1).replace('\\\\', ''))\n            return self.url_result(rutube_url)\n\n        m_opts = re.search(r'(?s)var\\s+opts\\s*=\\s*({.+?});', info_page)\n        if m_opts:\n            m_opts_url = re.search(r\"url\\s*:\\s*'((?!/\\b)[^']+)\", m_opts.group(1))\n            if m_opts_url:\n                opts_url = m_opts_url.group(1)\n                if opts_url.startswith('//'):\n                    opts_url = 'http:' + opts_url\n                return self.url_result(opts_url)\n\n        data_json = self._search_regex(r'var\\s+vars\\s*=\\s*({.+?});', info_page, 'vars')\n        data = json.loads(data_json)\n\n        # Extract upload date\n        upload_date = None\n        mobj = re.search(r'id=\"mv_date(?:_views)?_wrap\"[^>]*>([a-zA-Z]+ [0-9]+), ([0-9]+) at', info_page)\n        if mobj is not None:\n            mobj.group(1) + ' ' + mobj.group(2)\n            upload_date = unified_strdate(mobj.group(1) + ' ' + mobj.group(2))\n\n        view_count = str_to_int(self._search_regex(\n            r'\"mv_views_count_number\"[^>]*>([\\d,.]+) views<',\n            info_page, 'view count', fatal=False))\n\n        formats = [{\n            'format_id': k,\n            'url': v,\n            'width': int(k[len('url'):]),\n        } for k, v in data.items()\n            if k.startswith('url')]\n        self._sort_formats(formats)\n\n        return {\n            'id': compat_str(data['vid']),\n            'formats': formats,\n            'title': unescapeHTML(data['md_title']),\n            'thumbnail': data.get('jpg'),\n            'uploader': data.get('md_author'),\n            'duration': data.get('duration'),\n            'upload_date': upload_date,\n            'view_count': view_count,\n        }",
        "begin_line": 198,
        "end_line": 305,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKUserVideosIE._real_extract#325",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKUserVideosIE",
        "signature": "youtube_dl.extractor.vk.VKUserVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, page_id)\n\n        entries = [\n            self.url_result(\n                'http://vk.com/video' + video_id, 'VK', video_id=video_id)\n            for video_id in orderedSet(re.findall(r'href=\"/video(-?[0-9_]+)\"', webpage))]\n\n        title = unescapeHTML(self._search_regex(\n            r'<title>\\s*([^<]+?)\\s+\\|\\s+\\d+\\s+videos',\n            webpage, 'title', default=page_id))\n\n        return self.playlist_result(entries, page_id, title)",
        "begin_line": 325,
        "end_line": 339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE._extract_thumbnails#31",
        "src_path": "youtube_dl/extractor/tnaflix.py",
        "class_name": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE",
        "signature": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE._extract_thumbnails(self, flix_xml)",
        "snippet": "    def _extract_thumbnails(self, flix_xml):\n\n        def get_child(elem, names):\n            for name in names:\n                child = elem.find(name)\n                if child is not None:\n                    return child\n\n        timeline = get_child(flix_xml, ['timeline', 'rolloverBarImage'])\n        if timeline is None:\n            return\n\n        pattern_el = get_child(timeline, ['imagePattern', 'pattern'])\n        if pattern_el is None or not pattern_el.text:\n            return\n\n        first_el = get_child(timeline, ['imageFirst', 'first'])\n        last_el = get_child(timeline, ['imageLast', 'last'])\n        if first_el is None or last_el is None:\n            return\n\n        first_text = first_el.text\n        last_text = last_el.text\n        if not first_text.isdigit() or not last_text.isdigit():\n            return\n\n        first = int(first_text)\n        last = int(last_text)\n        if first > last:\n            return\n\n        width = int_or_none(xpath_text(timeline, './imageWidth', 'thumbnail width'))\n        height = int_or_none(xpath_text(timeline, './imageHeight', 'thumbnail height'))\n\n        return [{\n            'url': self._proto_relative_url(pattern_el.text.replace('#', compat_str(i)), 'http:'),\n            'width': width,\n            'height': height,\n        } for i in range(first, last + 1)]",
        "begin_line": 31,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE._real_extract#71",
        "src_path": "youtube_dl/extractor/tnaflix.py",
        "class_name": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE",
        "signature": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        cfg_url = self._proto_relative_url(self._html_search_regex(\n            self._CONFIG_REGEX, webpage, 'flashvars.config'), 'http:')\n\n        cfg_xml = self._download_xml(\n            cfg_url, display_id, 'Downloading metadata',\n            transform_source=fix_xml_ampersands)\n\n        formats = []\n\n        def extract_video_url(vl):\n            return re.sub('speed=\\d+', 'speed=', vl.text)\n\n        video_link = cfg_xml.find('./videoLink')\n        if video_link is not None:\n            formats.append({\n                'url': extract_video_url(video_link),\n                'ext': xpath_text(cfg_xml, './videoConfig/type', 'type', default='flv'),\n            })\n\n        for item in cfg_xml.findall('./quality/item'):\n            video_link = item.find('./videoLink')\n            if video_link is None:\n                continue\n            res = item.find('res')\n            format_id = None if res is None else res.text\n            height = int_or_none(self._search_regex(\n                r'^(\\d+)[pP]', format_id, 'height', default=None))\n            formats.append({\n                'url': self._proto_relative_url(extract_video_url(video_link), 'http:'),\n                'format_id': format_id,\n                'height': height,\n            })\n\n        self._sort_formats(formats)\n\n        thumbnail = self._proto_relative_url(\n            xpath_text(cfg_xml, './startThumb', 'thumbnail'), 'http:')\n        thumbnails = self._extract_thumbnails(cfg_xml)\n\n        title = self._html_search_regex(\n            self._TITLE_REGEX, webpage, 'title') if self._TITLE_REGEX else self._og_search_title(webpage)\n\n        age_limit = self._rta_search(webpage)\n\n        duration = parse_duration(self._html_search_meta(\n            'duration', webpage, 'duration', default=None))\n\n        def extract_field(pattern, name):\n            return self._html_search_regex(pattern, webpage, name, default=None) if pattern else None\n\n        description = extract_field(self._DESCRIPTION_REGEX, 'description')\n        uploader = extract_field(self._UPLOADER_REGEX, 'uploader')\n        view_count = str_to_int(extract_field(self._VIEW_COUNT_REGEX, 'view count'))\n        comment_count = str_to_int(extract_field(self._COMMENT_COUNT_REGEX, 'comment count'))\n        average_rating = float_or_none(extract_field(self._AVERAGE_RATING_REGEX, 'average rating'))\n\n        categories_str = extract_field(self._CATEGORIES_REGEX, 'categories')\n        categories = categories_str.split(', ') if categories_str is not None else []\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'thumbnails': thumbnails,\n            'duration': duration,\n            'age_limit': age_limit,\n            'uploader': uploader,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'average_rating': average_rating,\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 71,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.rtl2.RTL2IE._real_extract#36",
        "src_path": "youtube_dl/extractor/rtl2.py",
        "class_name": "youtube_dl.extractor.rtl2.RTL2IE",
        "signature": "youtube_dl.extractor.rtl2.RTL2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Some rtl2 urls have no slash at the end, so append it.\n        if not url.endswith('/'):\n            url += '/'\n\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        mobj = re.search(\n            r'<div[^>]+data-collection=\"(?P<vico_id>\\d+)\"[^>]+data-video=\"(?P<vivi_id>\\d+)\"',\n            webpage)\n        if mobj:\n            vico_id = mobj.group('vico_id')\n            vivi_id = mobj.group('vivi_id')\n        else:\n            vico_id = self._html_search_regex(\n                r'vico_id\\s*:\\s*([0-9]+)', webpage, 'vico_id')\n            vivi_id = self._html_search_regex(\n                r'vivi_id\\s*:\\s*([0-9]+)', webpage, 'vivi_id')\n        info_url = 'http://www.rtl2.de/video/php/get_video.php?vico_id=' + vico_id + '&vivi_id=' + vivi_id\n\n        info = self._download_json(info_url, video_id)\n        video_info = info['video']\n        title = video_info['titel']\n        description = video_info.get('beschreibung')\n        thumbnail = video_info.get('image')\n\n        download_url = video_info['streamurl']\n        download_url = download_url.replace('\\\\', '')\n        stream_url = 'mp4:' + self._html_search_regex(r'ondemand/(.*)', download_url, 'stream URL')\n        rtmp_conn = [\"S:connect\", \"O:1\", \"NS:pageUrl:\" + url, \"NB:fpad:0\", \"NN:videoFunction:1\", \"O:0\"]\n\n        formats = [{\n            'url': download_url,\n            'play_path': stream_url,\n            'player_url': 'http://www.rtl2.de/flashplayer/vipo_player.swf',\n            'page_url': url,\n            'flash_version': 'LNX 11,2,202,429',\n            'rtmp_conn': rtmp_conn,\n            'no_resume': True,\n        }]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n            'formats': formats,\n        }",
        "begin_line": 36,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.__init__#55",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.__init__(self, ydl, params)",
        "snippet": "    def __init__(self, ydl, params):\n        \"\"\"Create a FileDownloader object with the given options.\"\"\"\n        self.ydl = ydl\n        self._progress_hooks = []\n        self.params = params\n        self.add_progress_hook(self.report_progress)",
        "begin_line": 55,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_seconds#63",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_seconds(seconds)",
        "snippet": "    def format_seconds(seconds):\n        (mins, secs) = divmod(seconds, 60)\n        (hours, mins) = divmod(mins, 60)\n        if hours > 99:\n            return '--:--:--'\n        if hours == 0:\n            return '%02d:%02d' % (mins, secs)\n        else:\n            return '%02d:%02d:%02d' % (hours, mins, secs)",
        "begin_line": 63,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_percent#74",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_percent(byte_counter, data_len)",
        "snippet": "    def calc_percent(byte_counter, data_len):\n        if data_len is None:\n            return None\n        return float(byte_counter) / float(data_len) * 100.0",
        "begin_line": 74,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_percent#80",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_percent(percent)",
        "snippet": "    def format_percent(percent):\n        if percent is None:\n            return '---.-%'\n        return '%6s' % ('%3.1f%%' % percent)",
        "begin_line": 80,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_eta#86",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_eta(start, now, total, current)",
        "snippet": "    def calc_eta(start, now, total, current):\n        if total is None:\n            return None\n        if now is None:\n            now = time.time()\n        dif = now - start\n        if current == 0 or dif < 0.001:  # One millisecond\n            return None\n        rate = float(current) / dif\n        return int((float(total) - float(current)) / rate)",
        "begin_line": 86,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_eta#98",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_eta(eta)",
        "snippet": "    def format_eta(eta):\n        if eta is None:\n            return '--:--'\n        return FileDownloader.format_seconds(eta)",
        "begin_line": 98,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_speed#104",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_speed(start, now, bytes)",
        "snippet": "    def calc_speed(start, now, bytes):\n        dif = now - start\n        if bytes == 0 or dif < 0.001:  # One millisecond\n            return None\n        return float(bytes) / dif",
        "begin_line": 104,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_speed#111",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_speed(speed)",
        "snippet": "    def format_speed(speed):\n        if speed is None:\n            return '%10s' % '---b/s'\n        return '%10s' % ('%s/s' % format_bytes(speed))",
        "begin_line": 111,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.best_block_size#117",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.best_block_size(elapsed_time, bytes)",
        "snippet": "    def best_block_size(elapsed_time, bytes):\n        new_min = max(bytes / 2.0, 1.0)\n        new_max = min(max(bytes * 2.0, 1.0), 4194304)  # Do not surpass 4 MB\n        if elapsed_time < 0.001:\n            return int(new_max)\n        rate = bytes / elapsed_time\n        if rate > new_max:\n            return int(new_max)\n        if rate < new_min:\n            return int(new_min)\n        return int(rate)",
        "begin_line": 117,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.parse_bytes#130",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.parse_bytes(bytestr)",
        "snippet": "    def parse_bytes(bytestr):\n        \"\"\"Parse a string indicating a byte quantity into an integer.\"\"\"\n        matchobj = re.match(r'(?i)^(\\d+(?:\\.\\d+)?)([kMGTPEZY]?)$', bytestr)\n        if matchobj is None:\n            return None\n        number = float(matchobj.group(1))\n        multiplier = 1024.0 ** 'bkmgtpezy'.index(matchobj.group(2).lower())\n        return int(round(number * multiplier))",
        "begin_line": 130,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_screen#139",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_screen(self, *args, **kargs)",
        "snippet": "    def to_screen(self, *args, **kargs):\n        self.ydl.to_screen(*args, **kargs)",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_stderr#142",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_stderr(self, message)",
        "snippet": "    def to_stderr(self, message):\n        self.ydl.to_screen(message)",
        "begin_line": 142,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_console_title#145",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_console_title(self, message)",
        "snippet": "    def to_console_title(self, message):\n        self.ydl.to_console_title(message)",
        "begin_line": 145,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.trouble#148",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.trouble(self, *args, **kargs)",
        "snippet": "    def trouble(self, *args, **kargs):\n        self.ydl.trouble(*args, **kargs)",
        "begin_line": 148,
        "end_line": 149,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_warning#151",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_warning(self, *args, **kargs)",
        "snippet": "    def report_warning(self, *args, **kargs):\n        self.ydl.report_warning(*args, **kargs)",
        "begin_line": 151,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_error#154",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_error(self, *args, **kargs)",
        "snippet": "    def report_error(self, *args, **kargs):\n        self.ydl.report_error(*args, **kargs)",
        "begin_line": 154,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.slow_down#157",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.slow_down(self, start_time, now, byte_counter)",
        "snippet": "    def slow_down(self, start_time, now, byte_counter):\n        \"\"\"Sleep if the download speed is over the rate limit.\"\"\"\n        rate_limit = self.params.get('ratelimit', None)\n        if rate_limit is None or byte_counter == 0:\n            return\n        if now is None:\n            now = time.time()\n        elapsed = now - start_time\n        if elapsed <= 0.0:\n            return\n        speed = float(byte_counter) / elapsed\n        if speed > rate_limit:\n            time.sleep(max((byte_counter // rate_limit) - elapsed, 0))",
        "begin_line": 157,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.temp_name#171",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.temp_name(self, filename)",
        "snippet": "    def temp_name(self, filename):\n        \"\"\"Returns a temporary filename for the given filename.\"\"\"\n        if self.params.get('nopart', False) or filename == '-' or \\\n                (os.path.exists(encodeFilename(filename)) and not os.path.isfile(encodeFilename(filename))):\n            return filename\n        return filename + '.part'",
        "begin_line": 171,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.undo_temp_name#178",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.undo_temp_name(self, filename)",
        "snippet": "    def undo_temp_name(self, filename):\n        if filename.endswith('.part'):\n            return filename[:-len('.part')]\n        return filename",
        "begin_line": 178,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.try_rename#183",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.try_rename(self, old_filename, new_filename)",
        "snippet": "    def try_rename(self, old_filename, new_filename):\n        try:\n            if old_filename == new_filename:\n                return\n            os.rename(encodeFilename(old_filename), encodeFilename(new_filename))\n        except (IOError, OSError) as err:\n            self.report_error('unable to rename file: %s' % compat_str(err))",
        "begin_line": 183,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.try_utime#191",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.try_utime(self, filename, last_modified_hdr)",
        "snippet": "    def try_utime(self, filename, last_modified_hdr):\n        \"\"\"Try to set the last-modified time of the given file.\"\"\"\n        if last_modified_hdr is None:\n            return\n        if not os.path.isfile(encodeFilename(filename)):\n            return\n        timestr = last_modified_hdr\n        if timestr is None:\n            return\n        filetime = timeconvert(timestr)\n        if filetime is None:\n            return filetime\n        # Ignore obviously invalid dates\n        if filetime == 0:\n            return\n        try:\n            os.utime(filename, (time.time(), filetime))\n        except Exception:\n            pass\n        return filetime",
        "begin_line": 191,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_destination#212",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_destination(self, filename)",
        "snippet": "    def report_destination(self, filename):\n        \"\"\"Report destination filename.\"\"\"\n        self.to_screen('[download] Destination: ' + filename)",
        "begin_line": 212,
        "end_line": 214,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._report_progress_status#216",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._report_progress_status(self, msg, is_last_line=False)",
        "snippet": "    def _report_progress_status(self, msg, is_last_line=False):\n        fullmsg = '[download] ' + msg\n        if self.params.get('progress_with_newline', False):\n            self.to_screen(fullmsg)\n        else:\n            if os.name == 'nt':\n                prev_len = getattr(self, '_report_progress_prev_line_length',\n                                   0)\n                if prev_len > len(fullmsg):\n                    fullmsg += ' ' * (prev_len - len(fullmsg))\n                self._report_progress_prev_line_length = len(fullmsg)\n                clear_line = '\\r'\n            else:\n                clear_line = ('\\r\\x1b[K' if sys.stderr.isatty() else '\\r')\n            self.to_screen(clear_line + fullmsg, skip_eol=not is_last_line)\n        self.to_console_title('youtube-dl ' + msg)",
        "begin_line": 216,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_progress#233",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_progress(self, s)",
        "snippet": "    def report_progress(self, s):\n        if s['status'] == 'finished':\n            if self.params.get('noprogress', False):\n                self.to_screen('[download] Download completed')\n            else:\n                s['_total_bytes_str'] = format_bytes(s['total_bytes'])\n                if s.get('elapsed') is not None:\n                    s['_elapsed_str'] = self.format_seconds(s['elapsed'])\n                    msg_template = '100%% of %(_total_bytes_str)s in %(_elapsed_str)s'\n                else:\n                    msg_template = '100%% of %(_total_bytes_str)s'\n                self._report_progress_status(\n                    msg_template % s, is_last_line=True)\n\n        if self.params.get('noprogress'):\n            return\n\n        if s['status'] != 'downloading':\n            return\n\n        if s.get('eta') is not None:\n            s['_eta_str'] = self.format_eta(s['eta'])\n        else:\n            s['_eta_str'] = 'Unknown ETA'\n\n        if s.get('total_bytes') and s.get('downloaded_bytes') is not None:\n            s['_percent_str'] = self.format_percent(100 * s['downloaded_bytes'] / s['total_bytes'])\n        elif s.get('total_bytes_estimate') and s.get('downloaded_bytes') is not None:\n            s['_percent_str'] = self.format_percent(100 * s['downloaded_bytes'] / s['total_bytes_estimate'])\n        else:\n            if s.get('downloaded_bytes') == 0:\n                s['_percent_str'] = self.format_percent(0)\n            else:\n                s['_percent_str'] = 'Unknown %'\n\n        if s.get('speed') is not None:\n            s['_speed_str'] = self.format_speed(s['speed'])\n        else:\n            s['_speed_str'] = 'Unknown speed'\n\n        if s.get('total_bytes') is not None:\n            s['_total_bytes_str'] = format_bytes(s['total_bytes'])\n            msg_template = '%(_percent_str)s of %(_total_bytes_str)s at %(_speed_str)s ETA %(_eta_str)s'\n        elif s.get('total_bytes_estimate') is not None:\n            s['_total_bytes_estimate_str'] = format_bytes(s['total_bytes_estimate'])\n            msg_template = '%(_percent_str)s of ~%(_total_bytes_estimate_str)s at %(_speed_str)s ETA %(_eta_str)s'\n        else:\n            if s.get('downloaded_bytes') is not None:\n                s['_downloaded_bytes_str'] = format_bytes(s['downloaded_bytes'])\n                if s.get('elapsed'):\n                    s['_elapsed_str'] = self.format_seconds(s['elapsed'])\n                    msg_template = '%(_downloaded_bytes_str)s at %(_speed_str)s (%(_elapsed_str)s)'\n                else:\n                    msg_template = '%(_downloaded_bytes_str)s at %(_speed_str)s'\n            else:\n                msg_template = '%(_percent_str)s % at %(_speed_str)s ETA %(_eta_str)s'\n\n        self._report_progress_status(msg_template % s)",
        "begin_line": 233,
        "end_line": 290,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_resuming_byte#292",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_resuming_byte(self, resume_len)",
        "snippet": "    def report_resuming_byte(self, resume_len):\n        \"\"\"Report attempt to resume at given byte.\"\"\"\n        self.to_screen('[download] Resuming download at byte %s' % resume_len)",
        "begin_line": 292,
        "end_line": 294,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_retry#296",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_retry(self, count, retries)",
        "snippet": "    def report_retry(self, count, retries):\n        \"\"\"Report retry in case of HTTP error 5xx\"\"\"\n        self.to_screen('[download] Got server HTTP error. Retrying (attempt %d of %d)...' % (count, retries))",
        "begin_line": 296,
        "end_line": 298,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_file_already_downloaded#300",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_file_already_downloaded(self, file_name)",
        "snippet": "    def report_file_already_downloaded(self, file_name):\n        \"\"\"Report file has already been fully downloaded.\"\"\"\n        try:\n            self.to_screen('[download] %s has already been downloaded' % file_name)\n        except UnicodeEncodeError:\n            self.to_screen('[download] The file has already been downloaded')",
        "begin_line": 300,
        "end_line": 305,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_unable_to_resume#307",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_unable_to_resume(self)",
        "snippet": "    def report_unable_to_resume(self):\n        \"\"\"Report it was impossible to resume download.\"\"\"\n        self.to_screen('[download] Unable to resume')",
        "begin_line": 307,
        "end_line": 309,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.download#311",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.download(self, filename, info_dict)",
        "snippet": "    def download(self, filename, info_dict):\n        \"\"\"Download to a filename using the info from info_dict\n        Return True on success and False otherwise\n        \"\"\"\n\n        nooverwrites_and_exists = (\n            self.params.get('nooverwrites', False) and\n            os.path.exists(encodeFilename(filename))\n        )\n\n        continuedl_and_exists = (\n            self.params.get('continuedl', True) and\n            os.path.isfile(encodeFilename(filename)) and\n            not self.params.get('nopart', False)\n        )\n\n        # Check file already present\n        if filename != '-' and (nooverwrites_and_exists or continuedl_and_exists):\n            self.report_file_already_downloaded(filename)\n            self._hook_progress({\n                'filename': filename,\n                'status': 'finished',\n                'total_bytes': os.path.getsize(encodeFilename(filename)),\n            })\n            return True\n\n        sleep_interval = self.params.get('sleep_interval')\n        if sleep_interval:\n            self.to_screen('[download] Sleeping %s seconds...' % sleep_interval)\n            time.sleep(sleep_interval)\n\n        return self.real_download(filename, info_dict)",
        "begin_line": 311,
        "end_line": 342,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.real_download#344",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        \"\"\"Real download process. Redefine in subclasses.\"\"\"\n        raise NotImplementedError('This method must be implemented by subclasses')",
        "begin_line": 344,
        "end_line": 346,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._hook_progress#348",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._hook_progress(self, status)",
        "snippet": "    def _hook_progress(self, status):\n        for ph in self._progress_hooks:\n            ph(status)",
        "begin_line": 348,
        "end_line": 350,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.add_progress_hook#352",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.add_progress_hook(self, ph)",
        "snippet": "    def add_progress_hook(self, ph):\n        # See YoutubeDl.py (search for progress_hooks) for a description of\n        # this interface\n        self._progress_hooks.append(ph)",
        "begin_line": 352,
        "end_line": 355,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._debug_cmd#357",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._debug_cmd(self, args, exe=None)",
        "snippet": "    def _debug_cmd(self, args, exe=None):\n        if not self.params.get('verbose', False):\n            return\n\n        str_args = [decodeArgument(a) for a in args]\n\n        if exe is None:\n            exe = os.path.basename(str_args[0])\n\n        try:\n            import pipes\n            shell_quote = lambda args: ' '.join(map(pipes.quote, str_args))\n        except ImportError:\n            shell_quote = repr\n        self.to_screen('[debug] %s command line: %s' % (\n            exe, shell_quote(str_args)))",
        "begin_line": 357,
        "end_line": 372,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.novamov.NovaMovIE._real_extract#40",
        "src_path": "youtube_dl/extractor/novamov.py",
        "class_name": "youtube_dl.extractor.novamov.NovaMovIE",
        "signature": "youtube_dl.extractor.novamov.NovaMovIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(\n            'http://%s/video/%s' % (self._HOST, video_id), video_id, 'Downloading video page')\n\n        if re.search(self._FILE_DELETED_REGEX, page) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        filekey = self._search_regex(self._FILEKEY_REGEX, page, 'filekey')\n\n        title = self._html_search_regex(self._TITLE_REGEX, page, 'title', fatal=False)\n        description = self._html_search_regex(self._DESCRIPTION_REGEX, page, 'description', default='', fatal=False)\n\n        api_response = self._download_webpage(\n            'http://%s/api/player.api.php?key=%s&file=%s' % (self._HOST, filekey, video_id), video_id,\n            'Downloading video api response')\n\n        response = compat_urlparse.parse_qs(api_response)\n\n        if 'error_msg' in response:\n            raise ExtractorError('%s returned error: %s' % (self.IE_NAME, response['error_msg'][0]), expected=True)\n\n        video_url = response['url'][0]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description\n        }",
        "begin_line": 40,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._extract_info#18",
        "src_path": "youtube_dl/extractor/twentytwotracks.py",
        "class_name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE",
        "signature": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._extract_info(self, city, genre_name, track_id=None)",
        "snippet": "    def _extract_info(self, city, genre_name, track_id=None):\n        item_id = track_id if track_id else genre_name\n\n        cities = self._download_json(\n            '%s/cities' % self._API_BASE, item_id,\n            'Downloading cities info',\n            'Unable to download cities info')\n        city_id = [x['id'] for x in cities if x['slug'] == city][0]\n\n        genres = self._download_json(\n            '%s/genres/%s' % (self._API_BASE, city_id), item_id,\n            'Downloading %s genres info' % city,\n            'Unable to download %s genres info' % city)\n        genre = [x for x in genres if x['slug'] == genre_name][0]\n        genre_id = genre['id']\n\n        tracks = self._download_json(\n            '%s/tracks/%s' % (self._API_BASE, genre_id), item_id,\n            'Downloading %s genre tracks info' % genre_name,\n            'Unable to download track info')\n\n        return [x for x in tracks if x['id'] == item_id][0] if track_id else [genre['title'], tracks]",
        "begin_line": 18,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._get_track_url#41",
        "src_path": "youtube_dl/extractor/twentytwotracks.py",
        "class_name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE",
        "signature": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._get_track_url(self, filename, track_id)",
        "snippet": "    def _get_track_url(self, filename, track_id):\n        token = self._download_json(\n            'http://22tracks.com/token.php?desktop=true&u=/128/%s' % filename,\n            track_id, 'Downloading token', 'Unable to download token')\n        return 'http://audio.22tracks.com%s?st=%s&e=%d' % (token['filename'], token['st'], token['e'])",
        "begin_line": 41,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._extract_track_info#47",
        "src_path": "youtube_dl/extractor/twentytwotracks.py",
        "class_name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE",
        "signature": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._extract_track_info(self, track_info, track_id)",
        "snippet": "    def _extract_track_info(self, track_info, track_id):\n        download_url = self._get_track_url(track_info['filename'], track_id)\n        title = '%s - %s' % (track_info['artist'].strip(), track_info['title'].strip())\n        return {\n            'id': track_id,\n            'url': download_url,\n            'ext': 'mp3',\n            'title': title,\n            'duration': int_or_none(track_info.get('duration')),\n            'timestamp': int_or_none(track_info.get('published_at') or track_info.get('created'))\n        }",
        "begin_line": 47,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._real_extract#59",
        "src_path": "youtube_dl/extractor/twentytwotracks.py",
        "class_name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE",
        "signature": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        city = mobj.group('city')\n        genre = mobj.group('genre')\n        track_id = mobj.group('id')\n\n        track_info = self._extract_info(city, genre, track_id)\n        return self._extract_track_info(track_info, track_id)",
        "begin_line": 59,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksGenreIE._real_extract#74",
        "src_path": "youtube_dl/extractor/twentytwotracks.py",
        "class_name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksGenreIE",
        "signature": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksGenreIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        city = mobj.group('city')\n        genre = mobj.group('genre')\n\n        genre_title, tracks = self._extract_info(city, genre)\n\n        entries = [\n            self._extract_track_info(track_info, track_info['id'])\n            for track_info in tracks]\n\n        return self.playlist_result(entries, genre, genre_title)",
        "begin_line": 74,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE.construct_video_urls#65",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE.construct_video_urls(self, data1, data2)",
        "snippet": "    def construct_video_urls(self, data1, data2):\n        # get sid, token\n        def yk_t(s1, s2):\n            ls = list(range(256))\n            t = 0\n            for i in range(256):\n                t = (t + ls[i] + compat_ord(s1[i % len(s1)])) % 256\n                ls[i], ls[t] = ls[t], ls[i]\n            s = bytearray()\n            x, y = 0, 0\n            for i in range(len(s2)):\n                y = (y + 1) % 256\n                x = (x + ls[y]) % 256\n                ls[x], ls[y] = ls[y], ls[x]\n                s.append(compat_ord(s2[i]) ^ ls[(ls[x] + ls[y]) % 256])\n            return bytes(s)\n\n        sid, token = yk_t(\n            b'becaf9be', base64.b64decode(data2['ep'].encode('ascii'))\n        ).decode('ascii').split('_')\n\n        # get oip\n        oip = data2['ip']\n\n        # get fileid\n        string_ls = list(\n            'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ/\\:._-1234567890')\n        shuffled_string_ls = []\n        seed = data1['seed']\n        N = len(string_ls)\n        for ii in range(N):\n            seed = (seed * 0xd3 + 0x754f) % 0x10000\n            idx = seed * len(string_ls) // 0x10000\n            shuffled_string_ls.append(string_ls[idx])\n            del string_ls[idx]\n\n        fileid_dict = {}\n        for format in data1['streamtypes']:\n            streamfileid = [\n                int(i) for i in data1['streamfileids'][format].strip('*').split('*')]\n            fileid = ''.join(\n                [shuffled_string_ls[i] for i in streamfileid])\n            fileid_dict[format] = fileid[:8] + '%s' + fileid[10:]\n\n        def get_fileid(format, n):\n            fileid = fileid_dict[format] % hex(int(n))[2:].upper().zfill(2)\n            return fileid\n\n        # get ep\n        def generate_ep(format, n):\n            fileid = get_fileid(format, n)\n            ep_t = yk_t(\n                b'bf7e5f01',\n                ('%s_%s_%s' % (sid, fileid, token)).encode('ascii')\n            )\n            ep = base64.b64encode(ep_t).decode('ascii')\n            return ep\n\n        # generate video_urls\n        video_urls_dict = {}\n        for format in data1['streamtypes']:\n            video_urls = []\n            for dt in data1['segs'][format]:\n                n = str(int(dt['no']))\n                param = {\n                    'K': dt['k'],\n                    'hd': self.get_hd(format),\n                    'myp': 0,\n                    'ts': dt['seconds'],\n                    'ypp': 0,\n                    'ctype': 12,\n                    'ev': 1,\n                    'token': token,\n                    'oip': oip,\n                    'ep': generate_ep(format, n)\n                }\n                video_url = \\\n                    'http://k.youku.com/player/getFlvPath/' + \\\n                    'sid/' + sid + \\\n                    '_' + str(int(n) + 1).zfill(2) + \\\n                    '/st/' + self.parse_ext_l(format) + \\\n                    '/fileid/' + get_fileid(format, n) + '?' + \\\n                    compat_urllib_parse.urlencode(param)\n                video_urls.append(video_url)\n            video_urls_dict[format] = video_urls\n\n        return video_urls_dict",
        "begin_line": 65,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE.get_hd#153",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE.get_hd(self, fm)",
        "snippet": "    def get_hd(self, fm):\n        hd_id_dict = {\n            'flv': '0',\n            'mp4': '1',\n            'hd2': '2',\n            'hd3': '3',\n            '3gp': '0',\n            '3gphd': '1'\n        }\n        return hd_id_dict[fm]",
        "begin_line": 153,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE.parse_ext_l#164",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE.parse_ext_l(self, fm)",
        "snippet": "    def parse_ext_l(self, fm):\n        ext_dict = {\n            'flv': 'flv',\n            'mp4': 'mp4',\n            'hd2': 'flv',\n            'hd3': 'flv',\n            '3gp': 'flv',\n            '3gphd': 'mp4'\n        }\n        return ext_dict[fm]",
        "begin_line": 164,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE.get_format_name#175",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE.get_format_name(self, fm)",
        "snippet": "    def get_format_name(self, fm):\n        _dict = {\n            '3gp': 'h6',\n            '3gphd': 'h5',\n            'flv': 'h4',\n            'mp4': 'h3',\n            'hd2': 'h2',\n            'hd3': 'h1'\n        }\n        return _dict[fm]",
        "begin_line": 175,
        "end_line": 184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE._real_extract#186",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        def retrieve_data(req_url, note):\n            req = compat_urllib_request.Request(req_url)\n\n            cn_verification_proxy = self._downloader.params.get('cn_verification_proxy')\n            if cn_verification_proxy:\n                req.add_header('Ytdl-request-proxy', cn_verification_proxy)\n\n            raw_data = self._download_json(req, video_id, note=note)\n            return raw_data['data'][0]\n\n        video_password = self._downloader.params.get('videopassword', None)\n\n        # request basic data\n        basic_data_url = 'http://v.youku.com/player/getPlayList/VideoIDS/%s' % video_id\n        if video_password:\n            basic_data_url += '?password=%s' % video_password\n\n        data1 = retrieve_data(\n            basic_data_url,\n            'Downloading JSON metadata 1')\n        data2 = retrieve_data(\n            'http://v.youku.com/player/getPlayList/VideoIDS/%s/Pf/4/ctype/12/ev/1' % video_id,\n            'Downloading JSON metadata 2')\n\n        error_code = data1.get('error_code')\n        if error_code:\n            error = data1.get('error')\n            if error is not None and '\u56e0\u7248\u6743\u539f\u56e0\u65e0\u6cd5\u89c2\u770b\u6b64\u89c6\u9891' in error:\n                raise ExtractorError(\n                    'Youku said: Sorry, this video is available in China only', expected=True)\n            else:\n                msg = 'Youku server reported error %i' % error_code\n                if error is not None:\n                    msg += ': ' + error\n                raise ExtractorError(msg)\n\n        title = data1['title']\n\n        # generate video_urls_dict\n        video_urls_dict = self.construct_video_urls(data1, data2)\n\n        # construct info\n        entries = [{\n            'id': '%s_part%d' % (video_id, i + 1),\n            'title': title,\n            'formats': [],\n            # some formats are not available for all parts, we have to detect\n            # which one has all\n        } for i in range(max(len(v) for v in data1['segs'].values()))]\n        for fm in data1['streamtypes']:\n            video_urls = video_urls_dict[fm]\n            for video_url, seg, entry in zip(video_urls, data1['segs'][fm], entries):\n                entry['formats'].append({\n                    'url': video_url,\n                    'format_id': self.get_format_name(fm),\n                    'ext': self.parse_ext_l(fm),\n                    'filesize': int(seg['size']),\n                })\n\n        return {\n            '_type': 'multi_video',\n            'id': video_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 186,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.aes_ctr_decrypt#11",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_ctr_decrypt(data, key, counter)",
        "snippet": "def aes_ctr_decrypt(data, key, counter):\n    \"\"\"\n    Decrypt with aes in counter mode\n\n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {instance} counter  Instance whose next_value function (@returns {int[]}  16-Byte block)\n                               returns the next counter block\n    @returns {int[]}           decrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n\n    decrypted_data = []\n    for i in range(block_count):\n        counter_block = counter.next_value()\n        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]\n        block += [0] * (BLOCK_SIZE_BYTES - len(block))\n\n        cipher_counter_block = aes_encrypt(counter_block, expanded_key)\n        decrypted_data += xor(block, cipher_counter_block)\n    decrypted_data = decrypted_data[:len(data)]\n\n    return decrypted_data",
        "begin_line": 11,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.aes_cbc_decrypt#37",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_cbc_decrypt(data, key, iv)",
        "snippet": "def aes_cbc_decrypt(data, key, iv):\n    \"\"\"\n    Decrypt with aes in CBC mode\n\n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {int[]} iv          16-Byte IV\n    @returns {int[]}           decrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n\n    decrypted_data = []\n    previous_cipher_block = iv\n    for i in range(block_count):\n        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]\n        block += [0] * (BLOCK_SIZE_BYTES - len(block))\n\n        decrypted_block = aes_decrypt(block, expanded_key)\n        decrypted_data += xor(decrypted_block, previous_cipher_block)\n        previous_cipher_block = block\n    decrypted_data = decrypted_data[:len(data)]\n\n    return decrypted_data",
        "begin_line": 37,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.key_expansion#63",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.key_expansion(data)",
        "snippet": "def key_expansion(data):\n    \"\"\"\n    Generate key schedule\n\n    @param {int[]} data  16/24/32-Byte cipher key\n    @returns {int[]}     176/208/240-Byte expanded key\n    \"\"\"\n    data = data[:]  # copy\n    rcon_iteration = 1\n    key_size_bytes = len(data)\n    expanded_key_size_bytes = (key_size_bytes // 4 + 7) * BLOCK_SIZE_BYTES\n\n    while len(data) < expanded_key_size_bytes:\n        temp = data[-4:]\n        temp = key_schedule_core(temp, rcon_iteration)\n        rcon_iteration += 1\n        data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        for _ in range(3):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        if key_size_bytes == 32:\n            temp = data[-4:]\n            temp = sub_bytes(temp)\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        for _ in range(3 if key_size_bytes == 32 else 2 if key_size_bytes == 24 else 0):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n    data = data[:expanded_key_size_bytes]\n\n    return data",
        "begin_line": 63,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.aes_encrypt#98",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_encrypt(data, expanded_key)",
        "snippet": "def aes_encrypt(data, expanded_key):\n    \"\"\"\n    Encrypt one block with aes\n\n    @param {int[]} data          16-Byte state\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte cipher\n    \"\"\"\n    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n    for i in range(1, rounds + 1):\n        data = sub_bytes(data)\n        data = shift_rows(data)\n        if i != rounds:\n            data = mix_columns(data)\n        data = xor(data, expanded_key[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES])\n\n    return data",
        "begin_line": 98,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.aes_decrypt#119",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_decrypt(data, expanded_key)",
        "snippet": "def aes_decrypt(data, expanded_key):\n    \"\"\"\n    Decrypt one block with aes\n\n    @param {int[]} data          16-Byte cipher\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte state\n    \"\"\"\n    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n\n    for i in range(rounds, 0, -1):\n        data = xor(data, expanded_key[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES])\n        if i != rounds:\n            data = mix_columns_inv(data)\n        data = shift_rows_inv(data)\n        data = sub_bytes_inv(data)\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n\n    return data",
        "begin_line": 119,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.aes_decrypt_text#140",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_decrypt_text(data, password, key_size_bytes)",
        "snippet": "def aes_decrypt_text(data, password, key_size_bytes):\n    \"\"\"\n    Decrypt text\n    - The first 8 Bytes of decoded 'data' are the 8 high Bytes of the counter\n    - The cipher key is retrieved by encrypting the first 16 Byte of 'password'\n      with the first 'key_size_bytes' Bytes from 'password' (if necessary filled with 0's)\n    - Mode of operation is 'counter'\n\n    @param {str} data                    Base64 encoded string\n    @param {str,unicode} password        Password (will be encoded with utf-8)\n    @param {int} key_size_bytes          Possible values: 16 for 128-Bit, 24 for 192-Bit or 32 for 256-Bit\n    @returns {str}                       Decrypted data\n    \"\"\"\n    NONCE_LENGTH_BYTES = 8\n\n    data = bytes_to_intlist(base64.b64decode(data.encode('utf-8')))\n    password = bytes_to_intlist(password.encode('utf-8'))\n\n    key = password[:key_size_bytes] + [0] * (key_size_bytes - len(password))\n    key = aes_encrypt(key[:BLOCK_SIZE_BYTES], key_expansion(key)) * (key_size_bytes // BLOCK_SIZE_BYTES)\n\n    nonce = data[:NONCE_LENGTH_BYTES]\n    cipher = data[NONCE_LENGTH_BYTES:]\n\n    class Counter:\n        __value = nonce + [0] * (BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)\n\n        def next_value(self):\n            temp = self.__value\n            self.__value = inc(self.__value)\n            return temp\n\n    decrypted_data = aes_ctr_decrypt(cipher, key, Counter())\n    plaintext = intlist_to_bytes(decrypted_data)\n\n    return plaintext",
        "begin_line": 140,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.Counter.aes_decrypt_text#140",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes.Counter",
        "signature": "youtube_dl.aes.Counter.aes_decrypt_text(data, password, key_size_bytes)",
        "snippet": "def aes_decrypt_text(data, password, key_size_bytes):\n    \"\"\"\n    Decrypt text\n    - The first 8 Bytes of decoded 'data' are the 8 high Bytes of the counter\n    - The cipher key is retrieved by encrypting the first 16 Byte of 'password'\n      with the first 'key_size_bytes' Bytes from 'password' (if necessary filled with 0's)\n    - Mode of operation is 'counter'\n\n    @param {str} data                    Base64 encoded string\n    @param {str,unicode} password        Password (will be encoded with utf-8)\n    @param {int} key_size_bytes          Possible values: 16 for 128-Bit, 24 for 192-Bit or 32 for 256-Bit\n    @returns {str}                       Decrypted data\n    \"\"\"\n    NONCE_LENGTH_BYTES = 8\n\n    data = bytes_to_intlist(base64.b64decode(data.encode('utf-8')))\n    password = bytes_to_intlist(password.encode('utf-8'))\n\n    key = password[:key_size_bytes] + [0] * (key_size_bytes - len(password))\n    key = aes_encrypt(key[:BLOCK_SIZE_BYTES], key_expansion(key)) * (key_size_bytes // BLOCK_SIZE_BYTES)\n\n    nonce = data[:NONCE_LENGTH_BYTES]\n    cipher = data[NONCE_LENGTH_BYTES:]\n\n    class Counter:\n        __value = nonce + [0] * (BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)\n\n        def next_value(self):\n            temp = self.__value\n            self.__value = inc(self.__value)\n            return temp\n\n    decrypted_data = aes_ctr_decrypt(cipher, key, Counter())\n    plaintext = intlist_to_bytes(decrypted_data)\n\n    return plaintext",
        "begin_line": 140,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.Counter.next_value#167",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes.Counter",
        "signature": "youtube_dl.aes.Counter.next_value(self)",
        "snippet": "        def next_value(self):\n            temp = self.__value\n            self.__value = inc(self.__value)\n            return temp",
        "begin_line": 167,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.sub_bytes#252",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.sub_bytes(data)",
        "snippet": "def sub_bytes(data):\n    return [SBOX[x] for x in data]",
        "begin_line": 252,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.sub_bytes_inv#256",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.sub_bytes_inv(data)",
        "snippet": "def sub_bytes_inv(data):\n    return [SBOX_INV[x] for x in data]",
        "begin_line": 256,
        "end_line": 257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.rotate#260",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.rotate(data)",
        "snippet": "def rotate(data):\n    return data[1:] + [data[0]]",
        "begin_line": 260,
        "end_line": 261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.key_schedule_core#264",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.key_schedule_core(data, rcon_iteration)",
        "snippet": "def key_schedule_core(data, rcon_iteration):\n    data = rotate(data)\n    data = sub_bytes(data)\n    data[0] = data[0] ^ RCON[rcon_iteration]\n\n    return data",
        "begin_line": 264,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.xor#272",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.xor(data1, data2)",
        "snippet": "def xor(data1, data2):\n    return [x ^ y for x, y in zip(data1, data2)]",
        "begin_line": 272,
        "end_line": 273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 4.118446521971912e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.rijndael_mul#276",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.rijndael_mul(a, b)",
        "snippet": "def rijndael_mul(a, b):\n    if(a == 0 or b == 0):\n        return 0\n    return RIJNDAEL_EXP_TABLE[(RIJNDAEL_LOG_TABLE[a] + RIJNDAEL_LOG_TABLE[b]) % 0xFF]",
        "begin_line": 276,
        "end_line": 279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.mix_column#282",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_column(data, matrix)",
        "snippet": "def mix_column(data, matrix):\n    data_mixed = []\n    for row in range(4):\n        mixed = 0\n        for column in range(4):\n            # xor is (+) and (-)\n            mixed ^= rijndael_mul(data[column], matrix[row][column])\n        data_mixed.append(mixed)\n    return data_mixed",
        "begin_line": 282,
        "end_line": 290,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.mix_columns#293",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_columns(data, matrix=MIX_COLUMN_MATRIX)",
        "snippet": "def mix_columns(data, matrix=MIX_COLUMN_MATRIX):\n    data_mixed = []\n    for i in range(4):\n        column = data[i * 4: (i + 1) * 4]\n        data_mixed += mix_column(column, matrix)\n    return data_mixed",
        "begin_line": 293,
        "end_line": 298,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0003866976024748647,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.mix_columns_inv#301",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_columns_inv(data)",
        "snippet": "def mix_columns_inv(data):\n    return mix_columns(data, MIX_COLUMN_MATRIX_INV)",
        "begin_line": 301,
        "end_line": 302,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.shift_rows#305",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.shift_rows(data)",
        "snippet": "def shift_rows(data):\n    data_shifted = []\n    for column in range(4):\n        for row in range(4):\n            data_shifted.append(data[((column + row) & 0b11) * 4 + row])\n    return data_shifted",
        "begin_line": 305,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.shift_rows_inv#313",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.shift_rows_inv(data)",
        "snippet": "def shift_rows_inv(data):\n    data_shifted = []\n    for column in range(4):\n        for row in range(4):\n            data_shifted.append(data[((column - row) & 0b11) * 4 + row])\n    return data_shifted",
        "begin_line": 313,
        "end_line": 318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.aes.inc#321",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.inc(data)",
        "snippet": "def inc(data):\n    data = data[:]  # copy\n    for i in range(len(data) - 1, -1, -1):\n        if data[i] == 255:\n            data[i] = 0\n        else:\n            data[i] = data[i] + 1\n            break\n    return data",
        "begin_line": 321,
        "end_line": 329,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.goshgay.GoshgayIE._real_extract#28",
        "src_path": "youtube_dl/extractor/goshgay.py",
        "class_name": "youtube_dl.extractor.goshgay.GoshgayIE",
        "signature": "youtube_dl.extractor.goshgay.GoshgayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h2>(.*?)<', webpage, 'title')\n        duration = parse_duration(self._html_search_regex(\n            r'<span class=\"duration\">\\s*-?\\s*(.*?)</span>',\n            webpage, 'duration', fatal=False))\n\n        flashvars = compat_parse_qs(self._html_search_regex(\n            r'<embed.+?id=\"flash-player-embed\".+?flashvars=\"([^\"]+)\"',\n            webpage, 'flashvars'))\n        thumbnail = flashvars.get('url_bigthumb', [None])[0]\n        video_url = flashvars['flv_url'][0]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': self._family_friendly_search(webpage),\n        }",
        "begin_line": 28,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ndr.NDRBaseIE._real_extract#16",
        "src_path": "youtube_dl/extractor/ndr.py",
        "class_name": "youtube_dl.extractor.ndr.NDRBaseIE",
        "signature": "youtube_dl.extractor.ndr.NDRBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = next(group for group in mobj.groups() if group)\n        webpage = self._download_webpage(url, display_id)\n        return self._extract_embed(webpage, display_id)",
        "begin_line": 16,
        "end_line": 20,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ndr.NDRIE._extract_embed#83",
        "src_path": "youtube_dl/extractor/ndr.py",
        "class_name": "youtube_dl.extractor.ndr.NDRIE",
        "signature": "youtube_dl.extractor.ndr.NDRIE._extract_embed(self, webpage, display_id)",
        "snippet": "    def _extract_embed(self, webpage, display_id):\n        embed_url = self._html_search_meta(\n            'embedURL', webpage, 'embed URL', fatal=True)\n        description = self._search_regex(\n            r'<p[^>]+itemprop=\"description\">([^<]+)</p>',\n            webpage, 'description', fatal=False)\n        timestamp = parse_iso8601(\n            self._search_regex(\n                r'<span itemprop=\"datePublished\" content=\"([^\"]+)\">',\n                webpage, 'upload date', fatal=False))\n        return {\n            '_type': 'url_transparent',\n            'url': embed_url,\n            'display_id': display_id,\n            'description': description,\n            'timestamp': timestamp,\n        }",
        "begin_line": 83,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ndr.NJoyIE._extract_embed#145",
        "src_path": "youtube_dl/extractor/ndr.py",
        "class_name": "youtube_dl.extractor.ndr.NJoyIE",
        "signature": "youtube_dl.extractor.ndr.NJoyIE._extract_embed(self, webpage, display_id)",
        "snippet": "    def _extract_embed(self, webpage, display_id):\n        video_id = self._search_regex(\n            r'<iframe[^>]+id=\"pp_([\\da-z]+)\"', webpage, 'embed id')\n        description = self._search_regex(\n            r'<div[^>]+class=\"subline\"[^>]*>[^<]+</div>\\s*<p>([^<]+)</p>',\n            webpage, 'description', fatal=False)\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'NDREmbedBase',\n            'url': 'ndr:%s' % video_id,\n            'display_id': display_id,\n            'description': description,\n        }",
        "begin_line": 145,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ndr.NDREmbedBaseIE._real_extract#171",
        "src_path": "youtube_dl/extractor/ndr.py",
        "class_name": "youtube_dl.extractor.ndr.NDREmbedBaseIE",
        "signature": "youtube_dl.extractor.ndr.NDREmbedBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id') or mobj.group('id_s')\n\n        ppjson = self._download_json(\n            'http://www.ndr.de/%s-ppjson.json' % video_id, video_id)\n\n        playlist = ppjson['playlist']\n\n        formats = []\n        quality_key = qualities(('xs', 's', 'm', 'l', 'xl'))\n\n        for format_id, f in playlist.items():\n            src = f.get('src')\n            if not src:\n                continue\n            ext = determine_ext(src, None)\n            if ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    src + '?hdcore=3.7.0&plugin=aasp-3.7.0.39.44', video_id, f4m_id='hds'))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    src, video_id, m3u8_id='hls', entry_protocol='m3u8_native'))\n            else:\n                quality = f.get('quality')\n                ff = {\n                    'url': src,\n                    'format_id': quality or format_id,\n                    'quality': quality_key(quality),\n                }\n                type_ = f.get('type')\n                if type_ and type_.split('/')[0] == 'audio':\n                    ff['vcodec'] = 'none'\n                    ff['ext'] = ext or 'mp3'\n                formats.append(ff)\n        self._sort_formats(formats)\n\n        config = playlist['config']\n\n        live = playlist.get('config', {}).get('streamType') in ['httpVideoLive', 'httpAudioLive']\n        title = config['title']\n        if live:\n            title = self._live_title(title)\n        uploader = ppjson.get('config', {}).get('branding')\n        upload_date = ppjson.get('config', {}).get('publicationDate')\n        duration = int_or_none(config.get('duration'))\n\n        thumbnails = [{\n            'id': thumbnail.get('quality') or thumbnail_id,\n            'url': thumbnail['src'],\n            'preference': quality_key(thumbnail.get('quality')),\n        } for thumbnail_id, thumbnail in config.get('poster', {}).items() if thumbnail.get('src')]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'is_live': live,\n            'uploader': uploader if uploader != '-' else None,\n            'upload_date': upload_date[0:8] if upload_date else None,\n            'duration': duration,\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 171,
        "end_line": 233,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sportbox.SportBoxIE._real_extract#38",
        "src_path": "youtube_dl/extractor/sportbox.py",
        "class_name": "youtube_dl.extractor.sportbox.SportBoxIE",
        "signature": "youtube_dl.extractor.sportbox.SportBoxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        player = self._search_regex(\n            r'src=\"/?(vdl/player/[^\"]+)\"', webpage, 'player')\n\n        title = self._html_search_regex(\n            [r'\"nodetitle\"\\s*:\\s*\"([^\"]+)\"', r'class=\"node-header_{1,2}title\">([^<]+)'],\n            webpage, 'title')\n        description = self._og_search_description(webpage) or self._html_search_meta(\n            'description', webpage, 'description')\n        thumbnail = self._og_search_thumbnail(webpage)\n        upload_date = unified_strdate(self._html_search_meta(\n            'dateCreated', webpage, 'upload date'))\n\n        return {\n            '_type': 'url_transparent',\n            'url': compat_urlparse.urljoin(url, '/%s' % player),\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 38,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sportbox.SportBoxEmbedIE._extract_urls#87",
        "src_path": "youtube_dl/extractor/sportbox.py",
        "class_name": "youtube_dl.extractor.sportbox.SportBoxEmbedIE",
        "signature": "youtube_dl.extractor.sportbox.SportBoxEmbedIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe[^>]+src=\"(https?://news\\.sportbox\\.ru/vdl/player[^\"]+)\"',\n            webpage)",
        "begin_line": 87,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sportbox.SportBoxEmbedIE._real_extract#92",
        "src_path": "youtube_dl/extractor/sportbox.py",
        "class_name": "youtube_dl.extractor.sportbox.SportBoxEmbedIE",
        "signature": "youtube_dl.extractor.sportbox.SportBoxEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        hls = self._search_regex(\n            r\"sportboxPlayer\\.jwplayer_common_params\\.file\\s*=\\s*['\\\"]([^'\\\"]+)['\\\"]\",\n            webpage, 'hls file')\n\n        formats = self._extract_m3u8_formats(hls, video_id, 'mp4')\n\n        title = self._search_regex(\n            r'sportboxPlayer\\.node_title\\s*=\\s*\"([^\"]+)\"', webpage, 'title')\n\n        thumbnail = self._search_regex(\n            r'sportboxPlayer\\.jwplayer_common_params\\.image\\s*=\\s*\"([^\"]+)\"',\n            webpage, 'thumbnail', default=None)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 92,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.canal13cl.Canal13clIE._real_extract#23",
        "src_path": "youtube_dl/extractor/canal13cl.py",
        "class_name": "youtube_dl.extractor.canal13cl.Canal13clIE",
        "signature": "youtube_dl.extractor.canal13cl.Canal13clIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._html_search_meta(\n            'twitter:title', webpage, 'title', fatal=True)\n        description = self._html_search_meta(\n            'twitter:description', webpage, 'description')\n        url = self._html_search_regex(\n            r'articuloVideo = \\\"(.*?)\\\"', webpage, 'url')\n        real_id = self._search_regex(\n            r'[^0-9]([0-9]{7,})[^0-9]', url, 'id', default=display_id)\n        thumbnail = self._html_search_regex(\n            r'articuloImagen = \\\"(.*?)\\\"', webpage, 'thumbnail')\n\n        return {\n            'id': real_id,\n            'display_id': display_id,\n            'url': url,\n            'title': title,\n            'description': description,\n            'ext': 'mp4',\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 23,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.downloader.__init__.get_suitable_downloader#28",
        "src_path": "youtube_dl/downloader/__init__.py",
        "class_name": "youtube_dl.downloader.__init__",
        "signature": "youtube_dl.downloader.__init__.get_suitable_downloader(info_dict, params={})",
        "snippet": "def get_suitable_downloader(info_dict, params={}):\n    \"\"\"Get the downloader class that can handle the info dict.\"\"\"\n    protocol = determine_protocol(info_dict)\n    info_dict['protocol'] = protocol\n\n    external_downloader = params.get('external_downloader')\n    if external_downloader is not None:\n        ed = get_external_downloader(external_downloader)\n        if ed.supports(info_dict):\n            return ed\n\n    if protocol == 'm3u8' and params.get('hls_prefer_native'):\n        return NativeHlsFD\n\n    return PROTOCOL_MAP.get(protocol, HttpFD)",
        "begin_line": 28,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nuvid.NuvidIE._real_extract#30",
        "src_path": "youtube_dl/extractor/nuvid.py",
        "class_name": "youtube_dl.extractor.nuvid.NuvidIE",
        "signature": "youtube_dl.extractor.nuvid.NuvidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        formats = []\n\n        for dwnld_speed, format_id in [(0, '3gp'), (5, 'mp4')]:\n            request = compat_urllib_request.Request(\n                'http://m.nuvid.com/play/%s' % video_id)\n            request.add_header('Cookie', 'skip_download_page=1; dwnld_speed=%d; adv_show=1' % dwnld_speed)\n            webpage = self._download_webpage(\n                request, video_id, 'Downloading %s page' % format_id)\n            video_url = self._html_search_regex(\n                r'<a\\s+href=\"([^\"]+)\"\\s+class=\"b_link\">', webpage, '%s video URL' % format_id, fatal=False)\n            if not video_url:\n                continue\n            formats.append({\n                'url': video_url,\n                'format_id': format_id,\n            })\n\n        webpage = self._download_webpage(\n            'http://m.nuvid.com/video/%s' % video_id, video_id, 'Downloading video page')\n        title = self._html_search_regex(\n            [r'<span title=\"([^\"]+)\">',\n             r'<div class=\"thumb-holder video\">\\s*<h5[^>]*>([^<]+)</h5>'], webpage, 'title').strip()\n        thumbnails = [\n            {\n                'url': thumb_url,\n            } for thumb_url in re.findall(r'<img src=\"([^\"]+)\" alt=\"\" />', webpage)\n        ]\n        thumbnail = thumbnails[0]['url'] if thumbnails else None\n        duration = parse_duration(self._html_search_regex(\n            r'<i class=\"fa fa-clock-o\"></i>\\s*(\\d{2}:\\d{2})', webpage, 'duration', fatal=False))\n        upload_date = unified_strdate(self._html_search_regex(\n            r'<i class=\"fa fa-user\"></i>\\s*(\\d{4}-\\d{2}-\\d{2})', webpage, 'upload date', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnails': thumbnails,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'upload_date': upload_date,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.playfm.PlayFMIE._real_extract#37",
        "src_path": "youtube_dl/extractor/playfm.py",
        "class_name": "youtube_dl.extractor.playfm.PlayFMIE",
        "signature": "youtube_dl.extractor.playfm.PlayFMIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        slug = mobj.group('slug')\n\n        recordings = self._download_json(\n            'http://v2api.play.fm/recordings/slug/%s' % slug, video_id)\n\n        error = recordings.get('error')\n        if isinstance(error, dict):\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error.get('message')),\n                expected=True)\n\n        audio_url = recordings['audio']\n        video_id = compat_str(recordings.get('id') or video_id)\n        title = recordings['title']\n        description = recordings.get('description')\n        duration = int_or_none(recordings.get('recordingDuration'))\n        timestamp = parse_iso8601(recordings.get('created_at'))\n        uploader = recordings.get('page', {}).get('title')\n        uploader_id = compat_str(recordings.get('page', {}).get('id'))\n        view_count = int_or_none(recordings.get('playCount'))\n        comment_count = int_or_none(recordings.get('commentCount'))\n        categories = [tag['name'] for tag in recordings.get('tags', []) if tag.get('name')]\n\n        return {\n            'id': video_id,\n            'url': audio_url,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'categories': categories,\n        }",
        "begin_line": 37,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.collegehumor.CollegeHumorIE._real_extract#55",
        "src_path": "youtube_dl/extractor/collegehumor.py",
        "class_name": "youtube_dl.extractor.collegehumor.CollegeHumorIE",
        "signature": "youtube_dl.extractor.collegehumor.CollegeHumorIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        jsonUrl = 'http://www.collegehumor.com/moogaloop/video/' + video_id + '.json'\n        data = json.loads(self._download_webpage(\n            jsonUrl, video_id, 'Downloading info JSON'))\n        vdata = data['video']\n        if vdata.get('youtubeId') is not None:\n            return {\n                '_type': 'url',\n                'url': vdata['youtubeId'],\n                'ie_key': 'Youtube',\n            }\n\n        AGE_LIMITS = {'nc17': 18, 'r': 18, 'pg13': 13, 'pg': 10, 'g': 0}\n        rating = vdata.get('rating')\n        if rating:\n            age_limit = AGE_LIMITS.get(rating.lower())\n        else:\n            age_limit = None  # None = No idea\n\n        PREFS = {'high_quality': 2, 'low_quality': 0}\n        formats = []\n        for format_key in ('mp4', 'webm'):\n            for qname, qurl in vdata.get(format_key, {}).items():\n                formats.append({\n                    'format_id': format_key + '_' + qname,\n                    'url': qurl,\n                    'format': format_key,\n                    'preference': PREFS.get(qname),\n                })\n        self._sort_formats(formats)\n\n        duration = int_or_none(vdata.get('duration'), 1000)\n        like_count = int_or_none(vdata.get('likes'))\n\n        return {\n            'id': video_id,\n            'title': vdata['title'],\n            'description': vdata.get('description'),\n            'thumbnail': vdata.get('thumbnail'),\n            'formats': formats,\n            'age_limit': age_limit,\n            'duration': duration,\n            'like_count': like_count,\n        }",
        "begin_line": 55,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE.__rc4crypt#37",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE.__rc4crypt(self, data, key)",
        "snippet": "    def __rc4crypt(self, data, key):\n        x = 0\n        box = list(range(256))\n        for i in list(range(256)):\n            x = (x + box[i] + compat_ord(key[i % len(key)])) % 256\n            box[i], box[x] = box[x], box[i]\n        x = 0\n        y = 0\n        out = ''\n        for char in data:\n            x = (x + 1) % 256\n            y = (y + box[x]) % 256\n            box[x], box[y] = box[y], box[x]\n            out += chr(compat_ord(char) ^ box[(box[x] + box[y]) % 256])\n        return out",
        "begin_line": 37,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE.__md5#53",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE.__md5(self, s)",
        "snippet": "    def __md5(self, s):\n        return hashlib.md5(s).hexdigest().encode()",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE._real_extract#56",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        GK = (\n            b'WXpnME1EZGhNRGhpTTJNM01XVmhOREU0WldNNVpHTTJOakpt'\n            b'TW1FMU5tVTBNR05pWkRaa05XRXhNVFJoWVRVd1ptSXhaVEV3'\n            b'TnpsbA0KTVRkbU1tSTRNdz09'\n        )\n\n        # Get video webpage\n        webpage_url = 'http://www.myvideo.de/watch/%s' % video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        mobj = re.search('source src=\\'(.+?)[.]([^.]+)\\'', webpage)\n        if mobj is not None:\n            self.report_extraction(video_id)\n            video_url = mobj.group(1) + '.flv'\n\n            video_title = self._html_search_regex('<title>([^<]+)</title>',\n                                                  webpage, 'title')\n\n            return {\n                'id': video_id,\n                'url': video_url,\n                'title': video_title,\n            }\n\n        mobj = re.search(r'data-video-service=\"/service/data/video/%s/config' % video_id, webpage)\n        if mobj is not None:\n            request = compat_urllib_request.Request('http://www.myvideo.de/service/data/video/%s/config' % video_id, '')\n            response = self._download_webpage(request, video_id,\n                                              'Downloading video info')\n            info = json.loads(base64.b64decode(response).decode('utf-8'))\n            return {\n                'id': video_id,\n                'title': info['title'],\n                'url': info['streaming_url'].replace('rtmpe', 'rtmpt'),\n                'play_path': info['filename'],\n                'ext': 'flv',\n                'thumbnail': info['thumbnail'][0]['url'],\n            }\n\n        # try encxml\n        mobj = re.search('var flashvars={(.+?)}', webpage)\n        if mobj is None:\n            raise ExtractorError('Unable to extract video')\n\n        params = {}\n        encxml = ''\n        sec = mobj.group(1)\n        for (a, b) in re.findall('(.+?):\\'(.+?)\\',?', sec):\n            if not a == '_encxml':\n                params[a] = b\n            else:\n                encxml = compat_urllib_parse_unquote(b)\n        if not params.get('domain'):\n            params['domain'] = 'www.myvideo.de'\n        xmldata_url = '%s?%s' % (encxml, compat_urllib_parse.urlencode(params))\n        if 'flash_playertype=MTV' in xmldata_url:\n            self._downloader.report_warning('avoiding MTV player')\n            xmldata_url = (\n                'http://www.myvideo.de/dynamic/get_player_video_xml.php'\n                '?flash_playertype=D&ID=%s&_countlimit=4&autorun=yes'\n            ) % video_id\n\n        # get enc data\n        enc_data = self._download_webpage(xmldata_url, video_id).split('=')[1]\n        enc_data_b = binascii.unhexlify(enc_data)\n        sk = self.__md5(\n            base64.b64decode(base64.b64decode(GK)) +\n            self.__md5(\n                str(video_id).encode('utf-8')\n            )\n        )\n        dec_data = self.__rc4crypt(enc_data_b, sk)\n\n        # extracting infos\n        self.report_extraction(video_id)\n\n        video_url = None\n        mobj = re.search('connectionurl=\\'(.*?)\\'', dec_data)\n        if mobj:\n            video_url = compat_urllib_parse_unquote(mobj.group(1))\n            if 'myvideo2flash' in video_url:\n                self.report_warning(\n                    'Rewriting URL to use unencrypted rtmp:// ...',\n                    video_id)\n                video_url = video_url.replace('rtmpe://', 'rtmp://')\n\n        if not video_url:\n            # extract non rtmp videos\n            mobj = re.search('path=\\'(http.*?)\\' source=\\'(.*?)\\'', dec_data)\n            if mobj is None:\n                raise ExtractorError('unable to extract url')\n            video_url = compat_urllib_parse_unquote(mobj.group(1)) + compat_urllib_parse_unquote(mobj.group(2))\n\n        video_file = self._search_regex('source=\\'(.*?)\\'', dec_data, 'video file')\n        video_file = compat_urllib_parse_unquote(video_file)\n\n        if not video_file.endswith('f4m'):\n            ppath, prefix = video_file.split('.')\n            video_playpath = '%s:%s' % (prefix, ppath)\n        else:\n            video_playpath = ''\n\n        video_swfobj = self._search_regex('swfobject.embedSWF\\(\\'(.+?)\\'', webpage, 'swfobj')\n        video_swfobj = compat_urllib_parse_unquote(video_swfobj)\n\n        video_title = self._html_search_regex(\"<h1(?: class='globalHd')?>(.*?)</h1>\",\n                                              webpage, 'title')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'tc_url': video_url,\n            'title': video_title,\n            'ext': 'flv',\n            'play_path': video_playpath,\n            'player_url': video_swfobj,\n        }",
        "begin_line": 56,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.anitube.AnitubeIE._real_extract#24",
        "src_path": "youtube_dl/extractor/anitube.py",
        "class_name": "youtube_dl.extractor.anitube.AnitubeIE",
        "signature": "youtube_dl.extractor.anitube.AnitubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        key = self._search_regex(\n            r'src=[\"\\']https?://[^/]+/embed/([A-Za-z0-9_-]+)', webpage, 'key')\n\n        config_xml = self._download_xml(\n            'http://www.anitube.se/nuevo/econfig.php?key=%s' % key, key)\n\n        video_title = config_xml.find('title').text\n        thumbnail = config_xml.find('image').text\n        duration = float(config_xml.find('duration').text)\n\n        formats = []\n        video_url = config_xml.find('file')\n        if video_url is not None:\n            formats.append({\n                'format_id': 'sd',\n                'url': video_url.text,\n            })\n        video_url = config_xml.find('filehd')\n        if video_url is not None:\n            formats.append({\n                'format_id': 'hd',\n                'url': video_url.text,\n            })\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats\n        }",
        "begin_line": 24,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.myvi.MyviIE._extract_url#48",
        "src_path": "youtube_dl/extractor/myvi.py",
        "class_name": "youtube_dl.extractor.myvi.MyviIE",
        "signature": "youtube_dl.extractor.myvi.MyviIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//myvi\\.(?:ru/player|tv)/(?:embed/html|flash)/[^\"]+)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 48,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.myvi.MyviIE._real_extract#54",
        "src_path": "youtube_dl/extractor/myvi.py",
        "class_name": "youtube_dl.extractor.myvi.MyviIE",
        "signature": "youtube_dl.extractor.myvi.MyviIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        spruto = self._download_json(\n            'http://myvi.ru/player/api/Video/Get/%s?sig' % video_id, video_id)['sprutoData']\n\n        return self._extract_spruto(spruto, video_id)",
        "begin_line": 54,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.fourtube.FourTubeIE._real_extract#39",
        "src_path": "youtube_dl/extractor/fourtube.py",
        "class_name": "youtube_dl.extractor.fourtube.FourTubeIE",
        "signature": "youtube_dl.extractor.fourtube.FourTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta('name', webpage)\n        timestamp = parse_iso8601(self._html_search_meta(\n            'uploadDate', webpage))\n        thumbnail = self._html_search_meta('thumbnailUrl', webpage)\n        uploader_id = self._html_search_regex(\n            r'<a class=\"img-avatar\" href=\"[^\"]+/channels/([^/\"]+)\" title=\"Go to [^\"]+ page\">',\n            webpage, 'uploader id', fatal=False)\n        uploader = self._html_search_regex(\n            r'<a class=\"img-avatar\" href=\"[^\"]+/channels/[^/\"]+\" title=\"Go to ([^\"]+) page\">',\n            webpage, 'uploader', fatal=False)\n\n        categories_html = self._search_regex(\n            r'(?s)><i class=\"icon icon-tag\"></i>\\s*Categories / Tags\\s*.*?<ul class=\"list\">(.*?)</ul>',\n            webpage, 'categories', fatal=False)\n        categories = None\n        if categories_html:\n            categories = [\n                c.strip() for c in re.findall(\n                    r'(?s)<li><a.*?>(.*?)</a>', categories_html)]\n\n        view_count = str_to_int(self._search_regex(\n            r'<meta itemprop=\"interactionCount\" content=\"UserPlays:([0-9,]+)\">',\n            webpage, 'view count', fatal=False))\n        like_count = str_to_int(self._search_regex(\n            r'<meta itemprop=\"interactionCount\" content=\"UserLikes:([0-9,]+)\">',\n            webpage, 'like count', fatal=False))\n        duration = parse_duration(self._html_search_meta('duration', webpage))\n\n        media_id = self._search_regex(\n            r'<button[^>]+data-id=([\"\\'])(?P<id>\\d+)\\1[^>]+data-quality=', webpage,\n            'media id', default=None, group='id')\n        sources = [\n            quality\n            for _, quality in re.findall(r'<button[^>]+data-quality=([\"\\'])(.+?)\\1', webpage)]\n        if not (media_id and sources):\n            player_js = self._download_webpage(\n                self._search_regex(\n                    r'<script[^>]id=([\"\\'])playerembed\\1[^>]+src=([\"\\'])(?P<url>.+?)\\2',\n                    webpage, 'player JS', group='url'),\n                video_id, 'Downloading player JS')\n            params_js = self._search_regex(\n                r'\\$\\.ajax\\(url,\\ opts\\);\\s*\\}\\s*\\}\\)\\(([0-9,\\[\\] ]+)\\)',\n                player_js, 'initialization parameters')\n            params = self._parse_json('[%s]' % params_js, video_id)\n            media_id = params[0]\n            sources = ['%s' % p for p in params[2]]\n\n        token_url = 'http://tkn.4tube.com/{0}/desktop/{1}'.format(\n            media_id, '+'.join(sources))\n        headers = {\n            b'Content-Type': b'application/x-www-form-urlencoded',\n            b'Origin': b'http://www.4tube.com',\n        }\n        token_req = compat_urllib_request.Request(token_url, b'{}', headers)\n        tokens = self._download_json(token_req, video_id)\n        formats = [{\n            'url': tokens[format]['token'],\n            'format_id': format + 'p',\n            'resolution': format + 'p',\n            'quality': int(format),\n        } for format in sources]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'categories': categories,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'timestamp': timestamp,\n            'like_count': like_count,\n            'view_count': view_count,\n            'duration': duration,\n            'age_limit': 18,\n        }",
        "begin_line": 39,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.libsyn.LibsynIE._real_extract#36",
        "src_path": "youtube_dl/extractor/libsyn.py",
        "class_name": "youtube_dl.extractor.libsyn.LibsynIE",
        "signature": "youtube_dl.extractor.libsyn.LibsynIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n        url = m.group('mainurl')\n        webpage = self._download_webpage(url, video_id)\n\n        formats = [{\n            'url': media_url,\n        } for media_url in set(re.findall('var\\s+mediaURL(?:Libsyn)?\\s*=\\s*\"([^\"]+)\"', webpage))]\n\n        podcast_title = self._search_regex(\n            r'<h2>([^<]+)</h2>', webpage, 'podcast title', default=None)\n        episode_title = self._search_regex(\n            r'(?:<div class=\"episode-title\">|<h3>)([^<]+)</', webpage, 'episode title')\n\n        title = '%s - %s' % (podcast_title, episode_title) if podcast_title else episode_title\n\n        description = self._html_search_regex(\n            r'<div id=\"info_text_body\">(.+?)</div>', webpage,\n            'description', default=None)\n        thumbnail = self._search_regex(\n            r'<img[^>]+class=\"info-show-icon\"[^>]+src=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n        release_date = unified_strdate(self._search_regex(\n            r'<div class=\"release_date\">Released: ([^<]+)<', webpage, 'release date', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': release_date,\n            'formats': formats,\n        }",
        "begin_line": 36,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.einthusan.EinthusanIE._real_extract#36",
        "src_path": "youtube_dl/extractor/einthusan.py",
        "class_name": "youtube_dl.extractor.einthusan.EinthusanIE",
        "signature": "youtube_dl.extractor.einthusan.EinthusanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._html_search_regex(\n            r'<h1><a class=\"movie-title\".*?>(.*?)</a></h1>', webpage, 'title')\n\n        video_url = self._html_search_regex(\n            r'''(?s)jwplayer\\(\"mediaplayer\"\\)\\.setup\\({.*?'file': '([^']+)'.*?}\\);''',\n            webpage, 'video url')\n\n        description = self._html_search_meta('description', webpage)\n        thumbnail = self._html_search_regex(\n            r'''<a class=\"movie-cover-wrapper\".*?><img src=[\"'](.*?)[\"'].*?/></a>''',\n            webpage, \"thumbnail url\", fatal=False)\n        if thumbnail is not None:\n            thumbnail = thumbnail.replace('..', 'http://www.einthusan.com')\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 36,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.krasview.KrasViewIE._real_extract#33",
        "src_path": "youtube_dl/extractor/krasview.py",
        "class_name": "youtube_dl.extractor.krasview.KrasViewIE",
        "signature": "youtube_dl.extractor.krasview.KrasViewIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        flashvars = json.loads(js_to_json(self._search_regex(\n            r'video_Init\\(({.+?})', webpage, 'flashvars')))\n\n        video_url = flashvars['url']\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage, default=None)\n        thumbnail = flashvars.get('image') or self._og_search_thumbnail(webpage)\n        duration = int_or_none(flashvars.get('duration'))\n        width = int_or_none(self._og_search_property(\n            'video:width', webpage, 'video width', default=None))\n        height = int_or_none(self._og_search_property(\n            'video:height', webpage, 'video height', default=None))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'width': width,\n            'height': height,\n        }",
        "begin_line": 33,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vuclip.VuClipIE._real_extract#29",
        "src_path": "youtube_dl/extractor/vuclip.py",
        "class_name": "youtube_dl.extractor.vuclip.VuClipIE",
        "signature": "youtube_dl.extractor.vuclip.VuClipIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        ad_m = re.search(\n            r'''value=\"No.*?\" onClick=\"location.href='([^\"']+)'\"''', webpage)\n        if ad_m:\n            urlr = compat_urllib_parse_urlparse(url)\n            adfree_url = urlr.scheme + '://' + urlr.netloc + ad_m.group(1)\n            webpage = self._download_webpage(\n                adfree_url, video_id, note='Download post-ad page')\n\n        error_msg = self._html_search_regex(\n            r'<p class=\"message\">(.*?)</p>', webpage, 'error message',\n            default=None)\n        if error_msg:\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, error_msg), expected=True)\n\n        # These clowns alternate between two page types\n        links_code = self._search_regex(\n            r'''(?xs)\n                (?:\n                    <img\\s+src=\"[^\"]*/play.gif\".*?>|\n                    <!--\\ player\\ end\\ -->\\s*</div><!--\\ thumb\\ end-->\n                )\n                (.*?)\n                (?:\n                    <a\\s+href=\"fblike|<div\\s+class=\"social\">\n                )\n            ''', webpage, 'links')\n        title = self._html_search_regex(\n            r'<title>(.*?)-\\s*Vuclip</title>', webpage, 'title').strip()\n\n        quality_order = qualities(['Reg', 'Hi'])\n        formats = []\n        for url, q in re.findall(\n                r'<a\\s+href=\"(?P<url>[^\"]+)\".*?>(?:<button[^>]*>)?(?P<q>[^<]+)(?:</button>)?</a>', links_code):\n            format_id = compat_urllib_parse_urlparse(url).scheme + '-' + q\n            formats.append({\n                'format_id': format_id,\n                'url': url,\n                'quality': quality_order(q),\n            })\n        self._sort_formats(formats)\n\n        duration = parse_duration(self._search_regex(\n            r'\\(([0-9:]+)\\)</span>', webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'duration': duration,\n        }",
        "begin_line": 29,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.defense.DefenseGouvFrIE._real_extract#20",
        "src_path": "youtube_dl/extractor/defense.py",
        "class_name": "youtube_dl.extractor.defense.DefenseGouvFrIE",
        "signature": "youtube_dl.extractor.defense.DefenseGouvFrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = self._match_id(url)\n        webpage = self._download_webpage(url, title)\n\n        video_id = self._search_regex(\n            r\"flashvars.pvg_id=\\\"(\\d+)\\\";\",\n            webpage, 'ID')\n\n        json_url = (\n            'http://static.videos.gouv.fr/brightcovehub/export/json/%s' %\n            video_id)\n        info = self._download_json(json_url, title, 'Downloading JSON config')\n        video_url = info['renditions'][0]['url']\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'url': video_url,\n            'title': title,\n        }",
        "begin_line": 20,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.atttechchannel.ATTTechChannelIE._real_extract#26",
        "src_path": "youtube_dl/extractor/atttechchannel.py",
        "class_name": "youtube_dl.extractor.atttechchannel.ATTTechChannelIE",
        "signature": "youtube_dl.extractor.atttechchannel.ATTTechChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._search_regex(\n            r\"url\\s*:\\s*'(rtmp://[^']+)'\",\n            webpage, 'video URL')\n\n        video_id = self._search_regex(\n            r'mediaid\\s*=\\s*(\\d+)',\n            webpage, 'video id', fatal=False)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        upload_date = unified_strdate(self._search_regex(\n            r'[Rr]elease\\s+date:\\s*(\\d{1,2}/\\d{1,2}/\\d{4})',\n            webpage, 'upload date', fatal=False), False)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'ext': 'flv',\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 26,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.compat.compat_ord#322",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat.compat_ord(c)",
        "snippet": "def compat_ord(c):\n    if type(c) is int:\n        return c\n    else:\n        return ord(c)",
        "begin_line": 322,
        "end_line": 326,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.compat.compat_print#410",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat.compat_print(s)",
        "snippet": "    def compat_print(s):\n        assert isinstance(s, compat_str)\n        print(s)",
        "begin_line": 410,
        "end_line": 412,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.compat._testfunc#438",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat._testfunc(x)",
        "snippet": "    def _testfunc(x):\n        pass",
        "begin_line": 438,
        "end_line": 439,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.compat.workaround_optparse_bug9161#476",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat.workaround_optparse_bug9161()",
        "snippet": "def workaround_optparse_bug9161():\n    op = optparse.OptionParser()\n    og = optparse.OptionGroup(op, 'foo')\n    try:\n        og.add_option('-t')\n    except TypeError:\n        real_add_option = optparse.OptionGroup.add_option\n\n        def _compat_add_option(self, *args, **kwargs):\n            enc = lambda v: (\n                v.encode('ascii', 'replace') if isinstance(v, compat_str)\n                else v)\n            bargs = [enc(a) for a in args]\n            bkwargs = dict(\n                (k, enc(v)) for k, v in kwargs.items())\n            return real_add_option(self, *bargs, **bkwargs)\n        optparse.OptionGroup.add_option = _compat_add_option",
        "begin_line": 476,
        "end_line": 492,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.radiofrance.RadioFranceIE._real_extract#25",
        "src_path": "youtube_dl/extractor/radiofrance.py",
        "class_name": "youtube_dl.extractor.radiofrance.RadioFranceIE",
        "signature": "youtube_dl.extractor.radiofrance.RadioFranceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<h1>(.*?)</h1>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"bloc_page_wrapper\"><div class=\"text\">(.*?)</div>',\n            webpage, 'description', fatal=False)\n        uploader = self._html_search_regex(\n            r'<div class=\"credit\">&nbsp;&nbsp;&copy;&nbsp;(.*?)</div>',\n            webpage, 'uploader', fatal=False)\n\n        formats_str = self._html_search_regex(\n            r'class=\"jp-jplayer[^\"]*\" data-source=\"([^\"]+)\">',\n            webpage, 'audio URLs')\n        formats = [\n            {\n                'format_id': fm[0],\n                'url': fm[1],\n                'vcodec': 'none',\n                'preference': i,\n            }\n            for i, fm in\n            enumerate(re.findall(r\"([a-z0-9]+)\\s*:\\s*'([^']+)'\", formats_str))\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'uploader': uploader,\n        }",
        "begin_line": 25,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.bilibili.BiliBiliIE._real_extract#42",
        "src_path": "youtube_dl/extractor/bilibili.py",
        "class_name": "youtube_dl.extractor.bilibili.BiliBiliIE",
        "signature": "youtube_dl.extractor.bilibili.BiliBiliIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        if '(\u6b64\u89c6\u9891\u4e0d\u5b58\u5728\u6216\u88ab\u5220\u9664)' in webpage:\n            raise ExtractorError(\n                'The video does not exist or was deleted', expected=True)\n\n        if '>\u4f60\u6ca1\u6709\u6743\u9650\u6d4f\u89c8\uff01 \u7531\u4e8e\u7248\u6743\u76f8\u5173\u95ee\u9898 \u6211\u4eec\u4e0d\u5bf9\u60a8\u6240\u5728\u7684\u5730\u533a\u63d0\u4f9b\u670d\u52a1<' in webpage:\n            raise ExtractorError(\n                'The video is not available in your region due to copyright reasons',\n                expected=True)\n\n        video_code = self._search_regex(\n            r'(?s)<div itemprop=\"video\".*?>(.*?)</div>', webpage, 'video code')\n\n        title = self._html_search_meta(\n            'media:title', video_code, 'title', fatal=True)\n        duration_str = self._html_search_meta(\n            'duration', video_code, 'duration')\n        if duration_str is None:\n            duration = None\n        else:\n            duration_mobj = re.match(\n                r'^T(?:(?P<hours>[0-9]+)H)?(?P<minutes>[0-9]+)M(?P<seconds>[0-9]+)S$',\n                duration_str)\n            duration = (\n                int_or_none(duration_mobj.group('hours'), default=0) * 3600 +\n                int(duration_mobj.group('minutes')) * 60 +\n                int(duration_mobj.group('seconds')))\n        upload_date = unified_strdate(self._html_search_meta(\n            'uploadDate', video_code, fatal=False))\n        thumbnail = self._html_search_meta(\n            'thumbnailUrl', video_code, 'thumbnail', fatal=False)\n\n        cid = self._search_regex(r'cid=(\\d+)', webpage, 'cid')\n\n        entries = []\n\n        lq_page = self._download_webpage(\n            'http://interface.bilibili.com/v_cdn_play?appkey=1&cid=%s' % cid,\n            video_id,\n            note='Downloading LQ video info'\n        )\n        try:\n            err_info = json.loads(lq_page)\n            raise ExtractorError(\n                'BiliBili said: ' + err_info['error_text'], expected=True)\n        except ValueError:\n            pass\n\n        lq_doc = compat_etree_fromstring(lq_page)\n        lq_durls = lq_doc.findall('./durl')\n\n        hq_doc = self._download_xml(\n            'http://interface.bilibili.com/playurl?appkey=1&cid=%s' % cid,\n            video_id,\n            note='Downloading HQ video info',\n            fatal=False,\n        )\n        if hq_doc is not False:\n            hq_durls = hq_doc.findall('./durl')\n            assert len(lq_durls) == len(hq_durls)\n        else:\n            hq_durls = itertools.repeat(None)\n\n        i = 1\n        for lq_durl, hq_durl in zip(lq_durls, hq_durls):\n            formats = [{\n                'format_id': 'lq',\n                'quality': 1,\n                'url': lq_durl.find('./url').text,\n                'filesize': int_or_none(\n                    lq_durl.find('./size'), get_attr='text'),\n            }]\n            if hq_durl is not None:\n                formats.append({\n                    'format_id': 'hq',\n                    'quality': 2,\n                    'ext': 'flv',\n                    'url': hq_durl.find('./url').text,\n                    'filesize': int_or_none(\n                        hq_durl.find('./size'), get_attr='text'),\n                })\n            self._sort_formats(formats)\n\n            entries.append({\n                'id': '%s_part%d' % (video_id, i),\n                'title': title,\n                'formats': formats,\n                'duration': duration,\n                'upload_date': upload_date,\n                'thumbnail': thumbnail,\n            })\n\n            i += 1\n\n        return {\n            '_type': 'multi_video',\n            'entries': entries,\n            'id': video_id,\n            'title': title\n        }",
        "begin_line": 42,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vgtv.VGTVIE._real_extract#88",
        "src_path": "youtube_dl/extractor/vgtv.py",
        "class_name": "youtube_dl.extractor.vgtv.VGTVIE",
        "signature": "youtube_dl.extractor.vgtv.VGTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        host = mobj.group('host')\n\n        HOST_WEBSITES = {\n            'vgtv': 'vgtv',\n            'bt': 'bttv',\n        }\n\n        data = self._download_json(\n            'http://svp.vg.no/svp/api/v1/%s/assets/%s?appName=%s-website'\n            % (host, video_id, HOST_WEBSITES[host]),\n            video_id, 'Downloading media JSON')\n\n        if data.get('status') == 'inactive':\n            raise ExtractorError(\n                'Video %s is no longer available' % video_id, expected=True)\n\n        streams = data['streamUrls']\n        stream_type = data.get('streamType')\n\n        formats = []\n\n        hls_url = streams.get('hls')\n        if hls_url:\n            formats.extend(self._extract_m3u8_formats(\n                hls_url, video_id, 'mp4', m3u8_id='hls'))\n\n        hds_url = streams.get('hds')\n        # wasLive hds are always 404\n        if hds_url and stream_type != 'wasLive':\n            formats.extend(self._extract_f4m_formats(\n                hds_url + '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18',\n                video_id, f4m_id='hds'))\n\n        mp4_url = streams.get('mp4')\n        if mp4_url:\n            _url = hls_url or hds_url\n            MP4_URL_TEMPLATE = '%s/%%s.%s' % (mp4_url.rpartition('/')[0], mp4_url.rpartition('.')[-1])\n            for mp4_format in _url.split(','):\n                m = re.search('(?P<width>\\d+)_(?P<height>\\d+)_(?P<vbr>\\d+)', mp4_format)\n                if not m:\n                    continue\n                width = int(m.group('width'))\n                height = int(m.group('height'))\n                vbr = int(m.group('vbr'))\n                formats.append({\n                    'url': MP4_URL_TEMPLATE % mp4_format,\n                    'format_id': 'mp4-%s' % vbr,\n                    'width': width,\n                    'height': height,\n                    'vbr': vbr,\n                    'preference': 1,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._live_title(data['title']),\n            'description': data['description'],\n            'thumbnail': data['images']['main'] + '?t[]=900x506q80',\n            'timestamp': data['published'],\n            'duration': float_or_none(data['duration'], 1000),\n            'view_count': data['displays'],\n            'formats': formats,\n            'is_live': True if stream_type == 'live' else False,\n        }",
        "begin_line": 88,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vgtv.BTArticleIE._real_extract#178",
        "src_path": "youtube_dl/extractor/vgtv.py",
        "class_name": "youtube_dl.extractor.vgtv.BTArticleIE",
        "signature": "youtube_dl.extractor.vgtv.BTArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, self._match_id(url))\n        video_id = self._search_regex(\n            r'SVP\\.Player\\.load\\(\\s*(\\d+)', webpage, 'video id')\n        return self.url_result('vgtv:bt:%s' % video_id, 'VGTV')",
        "begin_line": 178,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vgtv.BTVestlendingenIE._real_extract#202",
        "src_path": "youtube_dl/extractor/vgtv.py",
        "class_name": "youtube_dl.extractor.vgtv.BTVestlendingenIE",
        "signature": "youtube_dl.extractor.vgtv.BTVestlendingenIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self.url_result('xstream:btno:%s' % self._match_id(url), 'Xstream')",
        "begin_line": 202,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vulture.VultureIE._real_extract#33",
        "src_path": "youtube_dl/extractor/vulture.py",
        "class_name": "youtube_dl.extractor.vulture.VultureIE",
        "signature": "youtube_dl.extractor.vulture.VultureIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n        query_string = self._search_regex(\n            r\"queryString\\s*=\\s*'([^']+)'\", webpage, 'query string')\n        video_id = self._search_regex(\n            r'content=([^&]+)', query_string, 'video ID')\n        query_url = 'http://video.vulture.com/embed/player/container/1000/1000/?%s' % query_string\n\n        query_webpage = self._download_webpage(\n            query_url, display_id, note='Downloading query page')\n        params_json = self._search_regex(\n            r'(?sm)new MagnifyEmbeddablePlayer\\({.*?contentItem:\\s*(\\{.*?\\})\\n?,\\n',\n            query_webpage,\n            'player params')\n        params = json.loads(params_json)\n\n        upload_timestamp = parse_iso8601(params['posted'].replace(' ', 'T'))\n        uploader_id = params.get('user', {}).get('handle')\n\n        media_item = params['media_item']\n        title = os.path.splitext(media_item['title'])[0]\n        duration = int_or_none(media_item.get('duration_seconds'))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': media_item['pipeline_xid'],\n            'title': title,\n            'timestamp': upload_timestamp,\n            'thumbnail': params.get('thumbnail_url'),\n            'uploader_id': uploader_id,\n            'description': params.get('description'),\n            'duration': duration,\n        }",
        "begin_line": 33,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.tagesschau.TagesschauIE._real_extract#72",
        "src_path": "youtube_dl/extractor/tagesschau.py",
        "class_name": "youtube_dl.extractor.tagesschau.TagesschauIE",
        "signature": "youtube_dl.extractor.tagesschau.TagesschauIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        display_id = video_id.lstrip('-')\n        webpage = self._download_webpage(url, display_id)\n\n        player_url = self._html_search_meta(\n            'twitter:player', webpage, 'player URL', default=None)\n        if player_url:\n            playerpage = self._download_webpage(\n                player_url, display_id, 'Downloading player page')\n\n            formats = []\n            for media in re.finditer(\n                    r'''(?x)\n                        (?P<q_url>[\"\\'])(?P<url>http://media.+?)(?P=q_url)\n                        ,\\s*type:(?P<q_type>[\"\\'])(?P<type>video|audio)/(?P<ext>.+?)(?P=q_type)\n                        (?:,\\s*quality:(?P<q_quality>[\"\\'])(?P<quality>.+?)(?P=q_quality))?\n                    ''', playerpage):\n                url = media.group('url')\n                type_ = media.group('type')\n                ext = media.group('ext')\n                res = media.group('quality')\n                f = {\n                    'format_id': '%s_%s' % (res, ext) if res else ext,\n                    'url': url,\n                    'ext': ext,\n                    'vcodec': 'none' if type_ == 'audio' else None,\n                }\n                f.update(self._FORMATS.get(res, {}))\n                formats.append(f)\n            thumbnail = self._og_search_thumbnail(playerpage)\n            title = self._og_search_title(webpage).strip()\n            description = self._og_search_description(webpage).strip()\n        else:\n            download_text = self._search_regex(\n                r'(?s)<p>Wir bieten dieses Video in folgenden Formaten zum Download an:</p>\\s*<div class=\"controls\">(.*?)</div>\\s*<p>',\n                webpage, 'download links')\n            links = re.finditer(\n                r'<div class=\"button\" title=\"(?P<title>[^\"]*)\"><a href=\"(?P<url>[^\"]+)\">(?P<name>.+?)</a></div>',\n                download_text)\n            formats = []\n            for l in links:\n                format_id = self._search_regex(\n                    r'.*/[^/.]+\\.([^/]+)\\.[^/.]+', l.group('url'), 'format ID')\n                format = {\n                    'format_id': format_id,\n                    'url': l.group('url'),\n                    'format_name': l.group('name'),\n                }\n                m = re.match(\n                    r'''(?x)\n                        Video:\\s*(?P<vcodec>[a-zA-Z0-9/._-]+)\\s*&\\#10;\n                        (?P<width>[0-9]+)x(?P<height>[0-9]+)px&\\#10;\n                        (?P<vbr>[0-9]+)kbps&\\#10;\n                        Audio:\\s*(?P<abr>[0-9]+)kbps,\\s*(?P<audio_desc>[A-Za-z\\.0-9]+)&\\#10;\n                        Gr&ouml;&szlig;e:\\s*(?P<filesize_approx>[0-9.,]+\\s+[a-zA-Z]*B)''',\n                    l.group('title'))\n                if m:\n                    format.update({\n                        'format_note': m.group('audio_desc'),\n                        'vcodec': m.group('vcodec'),\n                        'width': int(m.group('width')),\n                        'height': int(m.group('height')),\n                        'abr': int(m.group('abr')),\n                        'vbr': int(m.group('vbr')),\n                        'filesize_approx': parse_filesize(m.group('filesize_approx')),\n                    })\n                formats.append(format)\n            thumbnail = self._og_search_thumbnail(webpage)\n            description = self._html_search_regex(\n                r'(?s)<p class=\"teasertext\">(.*?)</p>',\n                webpage, 'description', default=None)\n            title = self._html_search_regex(\n                r'<span class=\"headline\".*?>(.*?)</span>', webpage, 'title')\n\n        self._sort_formats(formats)\n\n        return {\n            'id': display_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n            'description': description,\n        }",
        "begin_line": 72,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.trutube.TruTubeIE._real_extract#23",
        "src_path": "youtube_dl/extractor/trutube.py",
        "class_name": "youtube_dl.extractor.trutube.TruTubeIE",
        "signature": "youtube_dl.extractor.trutube.TruTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        config = self._download_xml(\n            'https://trutube.tv/nuevo/player/config.php?v=%s' % video_id,\n            video_id, transform_source=lambda s: s.strip())\n\n        # filehd is always 404\n        video_url = xpath_text(config, './file', 'video URL', fatal=True)\n        title = xpath_text(config, './title', 'title').strip()\n        thumbnail = xpath_text(config, './image', ' thumbnail')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 23,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.wayofthemaster.WayOfTheMasterIE._real_extract#21",
        "src_path": "youtube_dl/extractor/wayofthemaster.py",
        "class_name": "youtube_dl.extractor.wayofthemaster.WayOfTheMasterIE",
        "signature": "youtube_dl.extractor.wayofthemaster.WayOfTheMasterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._search_regex(\n            r'<img src=\"images/title_[^\"]+\".*?alt=\"([^\"]+)\"',\n            webpage, 'title', default=None)\n        if title is None:\n            title = self._html_search_regex(\n                r'<title>(.*?)</title>', webpage, 'page title')\n\n        url_base = self._search_regex(\n            r'<param\\s+name=\"?movie\"?\\s+value=\".*?/wotm_videoplayer_highlow[0-9]*\\.swf\\?vid=([^\"]+)\"',\n            webpage, 'URL base')\n        formats = [{\n            'format_id': 'low',\n            'quality': 1,\n            'url': url_base + '_low.mp4',\n        }, {\n            'format_id': 'high',\n            'quality': 2,\n            'url': url_base + '_high.mp4',\n        }]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n        }",
        "begin_line": 21,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.spankbang.SpankBangIE._real_extract#24",
        "src_path": "youtube_dl/extractor/spankbang.py",
        "class_name": "youtube_dl.extractor.spankbang.SpankBangIE",
        "signature": "youtube_dl.extractor.spankbang.SpankBangIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        stream_key = self._html_search_regex(\n            r'''var\\s+stream_key\\s*=\\s*['\"](.+?)['\"]''',\n            webpage, 'stream key')\n\n        formats = [{\n            'url': 'http://spankbang.com/_%s/%s/title/%sp__mp4' % (video_id, stream_key, height),\n            'ext': 'mp4',\n            'format_id': '%sp' % height,\n            'height': int(height),\n        } for height in re.findall(r'<span[^>]+q_(\\d+)p', webpage)]\n        self._sort_formats(formats)\n\n        title = self._html_search_regex(\n            r'(?s)<h1>(.+?)</h1>', webpage, 'title')\n        description = self._search_regex(\n            r'class=\"desc\"[^>]*>([^<]+)',\n            webpage, 'description', default=None)\n        thumbnail = self._og_search_thumbnail(webpage)\n        uploader = self._search_regex(\n            r'class=\"user\"[^>]*>([^<]+)',\n            webpage, 'uploader', fatal=False)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'formats': formats,\n            'age_limit': age_limit,\n        }",
        "begin_line": 24,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.moviezine.MoviezineIE._real_extract#23",
        "src_path": "youtube_dl/extractor/moviezine.py",
        "class_name": "youtube_dl.extractor.moviezine.MoviezineIE",
        "signature": "youtube_dl.extractor.moviezine.MoviezineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        jsplayer = self._download_webpage('http://www.moviezine.se/api/player.js?video=%s' % video_id, video_id, 'Downloading js api player')\n\n        formats = [{\n            'format_id': 'sd',\n            'url': self._html_search_regex(r'file: \"(.+?)\",', jsplayer, 'file'),\n            'quality': 0,\n            'ext': 'mp4',\n        }]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._search_regex(r'title: \"(.+?)\",', jsplayer, 'title'),\n            'thumbnail': self._search_regex(r'image: \"(.+?)\",', jsplayer, 'image'),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 23,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mwave.MwaveIE._real_extract#27",
        "src_path": "youtube_dl/extractor/mwave.py",
        "class_name": "youtube_dl.extractor.mwave.MwaveIE",
        "signature": "youtube_dl.extractor.mwave.MwaveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        vod_info = self._download_json(\n            'http://mwave.interest.me/onair/vod_info.m?vodtype=CL&sectorid=&endinfo=Y&id=%s' % video_id,\n            video_id, 'Download vod JSON')\n\n        formats = []\n        for num, cdn_info in enumerate(vod_info['cdn']):\n            stream_url = cdn_info.get('url')\n            if not stream_url:\n                continue\n            stream_name = cdn_info.get('name') or compat_str(num)\n            f4m_stream = self._download_json(\n                stream_url, video_id,\n                'Download %s stream JSON' % stream_name)\n            f4m_url = f4m_stream.get('fileurl')\n            if not f4m_url:\n                continue\n            formats.extend(\n                self._extract_f4m_formats(f4m_url + '&hdcore=3.0.3', video_id, f4m_id=stream_name))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': vod_info['title'],\n            'thumbnail': vod_info.get('cover'),\n            'uploader': vod_info.get('program_title'),\n            'duration': parse_duration(vod_info.get('time')),\n            'view_count': int_or_none(vod_info.get('hit')),\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.anysex.AnySexIE._real_extract#28",
        "src_path": "youtube_dl/extractor/anysex.py",
        "class_name": "youtube_dl.extractor.anysex.AnySexIE",
        "signature": "youtube_dl.extractor.anysex.AnySexIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(r\"video_url\\s*:\\s*'([^']+)'\", webpage, 'video URL')\n\n        title = self._html_search_regex(r'<title>(.*?)</title>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"description\"[^>]*>([^<]+)</div>', webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'preview_url\\s*:\\s*\\'(.*?)\\'', webpage, 'thumbnail', fatal=False)\n\n        categories = re.findall(\n            r'<a href=\"http://anysex\\.com/categories/[^\"]+\" title=\"[^\"]*\">([^<]+)</a>', webpage)\n\n        duration = parse_duration(self._search_regex(\n            r'<b>Duration:</b> (?:<q itemprop=\"duration\">)?(\\d+:\\d+)', webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'<b>Views:</b> (\\d+)', webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'duration': duration,\n            'view_count': view_count,\n            'age_limit': 18,\n        }",
        "begin_line": 28,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.freevideo.FreeVideoIE._real_extract#21",
        "src_path": "youtube_dl/extractor/freevideo.py",
        "class_name": "youtube_dl.extractor.freevideo.FreeVideoIE",
        "signature": "youtube_dl.extractor.freevideo.FreeVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage, handle = self._download_webpage_handle(url, video_id)\n        if '//www.czechav.com/' in handle.geturl():\n            raise ExtractorError(\n                'Access to freevideo is blocked from your location',\n                expected=True)\n\n        video_url = self._search_regex(\n            r'\\s+url: \"(http://[a-z0-9-]+.cdn.freevideo.cz/stream/.*?/video.mp4)\"',\n            webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_id,\n            'age_limit': 18,\n        }",
        "begin_line": 21,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.canalc2.Canalc2IE._real_extract#28",
        "src_path": "youtube_dl/extractor/canalc2.py",
        "class_name": "youtube_dl.extractor.canalc2.Canalc2IE",
        "signature": "youtube_dl.extractor.canalc2.Canalc2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(\n            r'jwplayer\\(([\"\\'])Player\\1\\)\\.setup\\({[^}]*file\\s*:\\s*([\"\\'])(?P<file>.+?)\\2',\n            webpage, 'video_url', group='file')\n        formats = [{'url': video_url}]\n        if video_url.startswith('rtmp://'):\n            rtmp = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+/))(?P<play_path>mp4:.+)$', video_url)\n            formats[0].update({\n                'url': rtmp.group('url'),\n                'ext': 'flv',\n                'app': rtmp.group('app'),\n                'play_path': rtmp.group('play_path'),\n                'page_url': url,\n            })\n\n        title = self._html_search_regex(\n            r'(?s)class=\"[^\"]*col_description[^\"]*\">.*?<h3>(.*?)</h3>', webpage, 'title')\n        duration = parse_duration(self._search_regex(\n            r'id=[\"\\']video_duree[\"\\'][^>]*>([^<]+)',\n            webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.radiobremen.RadioBremenIE._real_extract#28",
        "src_path": "youtube_dl/extractor/radiobremen.py",
        "class_name": "youtube_dl.extractor.radiobremen.RadioBremenIE",
        "signature": "youtube_dl.extractor.radiobremen.RadioBremenIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        meta_url = \"http://www.radiobremen.de/apps/php/mediathek/metadaten.php?id=%s\" % video_id\n        meta_doc = self._download_webpage(\n            meta_url, video_id, 'Downloading metadata')\n        title = self._html_search_regex(\n            r\"<h1.*>(?P<title>.+)</h1>\", meta_doc, \"title\")\n        description = self._html_search_regex(\n            r\"<p>(?P<description>.*)</p>\", meta_doc, \"description\", fatal=False)\n        duration = parse_duration(self._html_search_regex(\n            r\"L&auml;nge:</td>\\s+<td>(?P<duration>[0-9]+:[0-9]+)</td>\",\n            meta_doc, \"duration\", fatal=False))\n\n        page_doc = self._download_webpage(\n            url, video_id, 'Downloading video information')\n        mobj = re.search(\n            r\"ardformatplayerclassic\\(\\'playerbereich\\',\\'(?P<width>[0-9]+)\\',\\'.*\\',\\'(?P<video_id>[0-9]+)\\',\\'(?P<secret>[0-9]+)\\',\\'(?P<thumbnail>.+)\\',\\'\\'\\)\",\n            page_doc)\n        video_url = (\n            \"http://dl-ondemand.radiobremen.de/mediabase/%s/%s_%s_%s.mp4\" %\n            (video_id, video_id, mobj.group(\"secret\"), mobj.group('width')))\n\n        formats = [{\n            'url': video_url,\n            'ext': 'mp4',\n            'width': int(mobj.group(\"width\")),\n        }]\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n            'thumbnail': mobj.group('thumbnail'),\n        }",
        "begin_line": 28,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.screenwavemedia.ScreenwaveMediaIE._real_extract#22",
        "src_path": "youtube_dl/extractor/screenwavemedia.py",
        "class_name": "youtube_dl.extractor.screenwavemedia.ScreenwaveMediaIE",
        "signature": "youtube_dl.extractor.screenwavemedia.ScreenwaveMediaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        playerdata = self._download_webpage(\n            'http://player.screenwavemedia.com/player.php?id=%s' % video_id,\n            video_id, 'Downloading player webpage')\n\n        vidtitle = self._search_regex(\n            r'\\'vidtitle\\'\\s*:\\s*\"([^\"]+)\"', playerdata, 'vidtitle').replace('\\\\/', '/')\n\n        playerconfig = self._download_webpage(\n            'http://player.screenwavemedia.com/player.js',\n            video_id, 'Downloading playerconfig webpage')\n\n        videoserver = self._search_regex(r'SWMServer\\s*=\\s*\"([\\d\\.]+)\"', playerdata, 'videoserver')\n\n        sources = self._parse_json(\n            js_to_json(\n                re.sub(\n                    r'(?s)/\\*.*?\\*/', '',\n                    self._search_regex(\n                        r\"sources\\s*:\\s*(\\[[^\\]]+?\\])\", playerconfig,\n                        'sources',\n                    ).replace(\n                        \"' + thisObj.options.videoserver + '\",\n                        videoserver\n                    ).replace(\n                        \"' + playerVidId + '\",\n                        video_id\n                    )\n                )\n            ),\n            video_id, fatal=False\n        )\n\n        # Fallback to hardcoded sources if JS changes again\n        if not sources:\n            self.report_warning('Falling back to a hardcoded list of streams')\n            sources = [{\n                'file': 'http://%s/vod/%s_%s.mp4' % (videoserver, video_id, format_id),\n                'type': 'mp4',\n                'label': format_label,\n            } for format_id, format_label in (\n                ('low', '144p Low'), ('med', '160p Med'), ('high', '360p High'), ('hd1', '720p HD1'))]\n            sources.append({\n                'file': 'http://%s/vod/smil:%s.smil/playlist.m3u8' % (videoserver, video_id),\n                'type': 'hls',\n            })\n\n        formats = []\n        for source in sources:\n            if source['type'] == 'hls':\n                formats.extend(self._extract_m3u8_formats(source['file'], video_id))\n            else:\n                file_ = source.get('file')\n                if not file_:\n                    continue\n                format_label = source.get('label')\n                format_id = self._search_regex(\n                    r'_(.+?)\\.[^.]+$', file_, 'format id', default=None)\n                height = int_or_none(self._search_regex(\n                    r'^(\\d+)[pP]', format_label, 'height', default=None))\n                formats.append({\n                    'url': source['file'],\n                    'format_id': format_id,\n                    'format': format_label,\n                    'ext': source.get('type'),\n                    'height': height,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': vidtitle,\n            'formats': formats,\n        }",
        "begin_line": 22,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.screenwavemedia.TeamFourIE._real_extract#113",
        "src_path": "youtube_dl/extractor/screenwavemedia.py",
        "class_name": "youtube_dl.extractor.screenwavemedia.TeamFourIE",
        "signature": "youtube_dl.extractor.screenwavemedia.TeamFourIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        playerdata_url = self._search_regex(\n            r'src=\"(http://player\\d?\\.screenwavemedia\\.com/(?:play/)?[a-zA-Z]+\\.php\\?[^\"]*\\bid=.+?)\"',\n            webpage, 'player data URL')\n\n        video_title = self._html_search_regex(\n            r'<div class=\"heroheadingtitle\">(?P<title>.+?)</div>',\n            webpage, 'title')\n        video_date = unified_strdate(self._html_search_regex(\n            r'<div class=\"heroheadingdate\">(?P<date>.+?)</div>',\n            webpage, 'date', fatal=False))\n        video_description = self._html_search_regex(\n            r'(?s)<div class=\"postcontent\">(?P<description>.+?)</div>',\n            webpage, 'description', fatal=False)\n        video_thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            '_type': 'url_transparent',\n            'display_id': display_id,\n            'title': video_title,\n            'description': video_description,\n            'upload_date': video_date,\n            'thumbnail': video_thumbnail,\n            'url': playerdata_url,\n        }",
        "begin_line": 113,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.jove.JoveIE._real_extract#43",
        "src_path": "youtube_dl/extractor/jove.py",
        "class_name": "youtube_dl.extractor.jove.JoveIE",
        "signature": "youtube_dl.extractor.jove.JoveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        chapters_id = self._html_search_regex(\n            r'/video-chapters\\?videoid=([0-9]+)', webpage, 'chapters id')\n\n        chapters_xml = self._download_xml(\n            self._CHAPTERS_URL.format(video_id=chapters_id),\n            video_id, note='Downloading chapters XML',\n            errnote='Failed to download chapters XML')\n\n        video_url = chapters_xml.attrib.get('video')\n        if not video_url:\n            raise ExtractorError('Failed to get the video URL')\n\n        title = self._html_search_meta('citation_title', webpage, 'title')\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._html_search_regex(\n            r'<div id=\"section_body_summary\"><p class=\"jove_content\">(.+?)</p>',\n            webpage, 'description', fatal=False)\n        publish_date = unified_strdate(self._html_search_meta(\n            'citation_publication_date', webpage, 'publish date', fatal=False))\n        comment_count = self._html_search_regex(\n            r'<meta name=\"num_comments\" content=\"(\\d+) Comments?\"',\n            webpage, 'comment count', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'description': description,\n            'upload_date': publish_date,\n            'comment_count': comment_count,\n        }",
        "begin_line": 43,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE._real_extract#28",
        "src_path": "youtube_dl/extractor/hotnewhiphop.py",
        "class_name": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE",
        "signature": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url_base64 = self._search_regex(\n            r'data-path=\"(.*?)\"', webpage, 'video URL', default=None)\n\n        if video_url_base64 is None:\n            video_url = self._search_regex(\n                r'\"contentUrl\" content=\"(.*?)\"', webpage, 'content URL')\n            return self.url_result(video_url, ie='Youtube')\n\n        reqdata = compat_urllib_parse.urlencode([\n            ('mediaType', 's'),\n            ('mediaId', video_id),\n        ])\n        r = compat_urllib_request.Request(\n            'http://www.hotnewhiphop.com/ajax/media/getActions/', data=reqdata)\n        r.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        mkd = self._download_json(\n            r, video_id, note='Requesting media key',\n            errnote='Could not download media key')\n        if 'mediaKey' not in mkd:\n            raise ExtractorError('Did not get a media key')\n\n        redirect_url = base64.b64decode(video_url_base64).decode('utf-8')\n        redirect_req = HEADRequest(redirect_url)\n        req = self._request_webpage(\n            redirect_req, video_id,\n            note='Resolving final URL', errnote='Could not resolve final URL')\n        video_url = req.geturl()\n        if video_url.endswith('.html'):\n            raise ExtractorError('Redirect failed')\n\n        video_title = self._og_search_title(webpage).strip()\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 28,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.sharesix.ShareSixIE._real_extract#45",
        "src_path": "youtube_dl/extractor/sharesix.py",
        "class_name": "youtube_dl.extractor.sharesix.ShareSixIE",
        "signature": "youtube_dl.extractor.sharesix.ShareSixIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        fields = {\n            'method_free': 'Free'\n        }\n        post = compat_urllib_parse.urlencode(fields)\n        req = compat_urllib_request.Request(url, post)\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n        webpage = self._download_webpage(req, video_id,\n                                         'Downloading video page')\n\n        video_url = self._search_regex(\n            r\"var\\slnk1\\s=\\s'([^']+)'\", webpage, 'video URL')\n        title = self._html_search_regex(\n            r'(?s)<dt>Filename:</dt>.+?<dd>(.+?)</dd>', webpage, 'title')\n        duration = parse_duration(\n            self._search_regex(\n                r'(?s)<dt>Length:</dt>.+?<dd>(.+?)</dd>',\n                webpage,\n                'duration',\n                fatal=False\n            )\n        )\n\n        m = re.search(\n            r'''(?xs)<dt>Width\\sx\\sHeight</dt>.+?\n                     <dd>(?P<width>\\d+)\\sx\\s(?P<height>\\d+)</dd>''',\n            webpage\n        )\n        width = height = None\n        if m:\n            width, height = int(m.group('width')), int(m.group('height'))\n\n        formats = [{\n            'format_id': 'sd',\n            'url': video_url,\n            'width': width,\n            'height': height,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ndtv.NDTVIE._real_extract#29",
        "src_path": "youtube_dl/extractor/ndtv.py",
        "class_name": "youtube_dl.extractor.ndtv.NDTVIE",
        "signature": "youtube_dl.extractor.ndtv.NDTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        filename = self._search_regex(\n            r\"__filename='([^']+)'\", webpage, 'video filename')\n        video_url = ('http://bitcast-b.bitgravity.com/ndtvod/23372/ndtv/%s' %\n                     filename)\n\n        duration = int_or_none(self._search_regex(\n            r\"__duration='([^']+)'\", webpage, 'duration', fatal=False))\n\n        date_m = re.search(r'''(?x)\n            <p\\s+class=\"vod_dateline\">\\s*\n                Published\\s+On:\\s*\n                (?P<monthname>[A-Za-z]+)\\s+(?P<day>[0-9]+),\\s*(?P<year>[0-9]+)\n            ''', webpage)\n        upload_date = None\n\n        if date_m is not None:\n            month = month_by_name(date_m.group('monthname'))\n            if month is not None:\n                upload_date = '%s%02d%02d' % (\n                    date_m.group('year'), month, int(date_m.group('day')))\n\n        description = self._og_search_description(webpage)\n        READ_MORE = ' (Read more)'\n        if description.endswith(READ_MORE):\n            description = description[:-len(READ_MORE)]\n\n        title = self._og_search_title(webpage)\n        TITLE_SUFFIX = ' - NDTV'\n        if title.endswith(TITLE_SUFFIX):\n            title = title[:-len(TITLE_SUFFIX)]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'duration': duration,\n            'upload_date': upload_date,\n        }",
        "begin_line": 29,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.lnkgo.LnkGoIE._real_extract#52",
        "src_path": "youtube_dl/extractor/lnkgo.py",
        "class_name": "youtube_dl.extractor.lnkgo.LnkGoIE",
        "signature": "youtube_dl.extractor.lnkgo.LnkGoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            url, display_id, 'Downloading player webpage')\n\n        video_id = self._search_regex(\n            r'data-ep=\"([^\"]+)\"', webpage, 'video ID')\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        upload_date = unified_strdate(self._search_regex(\n            r'class=\"[^\"]*meta-item[^\"]*air-time[^\"]*\">.*?<strong>([^<]+)</strong>', webpage, 'upload date', fatal=False))\n\n        thumbnail_w = int_or_none(\n            self._og_search_property('image:width', webpage, 'thumbnail width', fatal=False))\n        thumbnail_h = int_or_none(\n            self._og_search_property('image:height', webpage, 'thumbnail height', fatal=False))\n        thumbnail = {\n            'url': self._og_search_thumbnail(webpage),\n        }\n        if thumbnail_w and thumbnail_h:\n            thumbnail.update({\n                'width': thumbnail_w,\n                'height': thumbnail_h,\n            })\n\n        config = self._parse_json(self._search_regex(\n            r'episodePlayer\\((\\{.*?\\}),\\s*\\{', webpage, 'sources'), video_id)\n\n        if config.get('pGeo'):\n            self.report_warning(\n                'This content might not be available in your country due to copyright reasons')\n\n        formats = [{\n            'format_id': 'hls',\n            'ext': 'mp4',\n            'url': config['EpisodeVideoLink_HLS'],\n        }]\n\n        m = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<play_path>.+)$', config['EpisodeVideoLink'])\n        if m:\n            formats.append({\n                'format_id': 'rtmp',\n                'ext': 'flv',\n                'url': m.group('url'),\n                'play_path': m.group('play_path'),\n                'page_url': url,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'formats': formats,\n            'thumbnails': [thumbnail],\n            'duration': int_or_none(config.get('VideoTime')),\n            'description': description,\n            'age_limit': self._AGE_LIMITS.get(config.get('PGRating'), 0),\n            'upload_date': upload_date,\n        }",
        "begin_line": 52,
        "end_line": 113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.fczenit.FczenitIE._real_extract#21",
        "src_path": "youtube_dl/extractor/fczenit.py",
        "class_name": "youtube_dl.extractor.fczenit.FczenitIE",
        "signature": "youtube_dl.extractor.fczenit.FczenitIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._html_search_regex(r'<div class=\\\"photoalbum__title\\\">([^<]+)', webpage, 'title')\n\n        bitrates_raw = self._html_search_regex(r'bitrates:.*\\n(.*)\\]', webpage, 'video URL')\n        bitrates = re.findall(r'url:.?\\'(.+?)\\'.*?bitrate:.?([0-9]{3}?)', bitrates_raw)\n\n        formats = [{\n            'url': furl,\n            'tbr': tbr,\n        } for furl, tbr in bitrates]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n        }",
        "begin_line": 21,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.vporn.VpornIE._real_extract#51",
        "src_path": "youtube_dl/extractor/vporn.py",
        "class_name": "youtube_dl.extractor.vporn.VpornIE",
        "signature": "youtube_dl.extractor.vporn.VpornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._html_search_regex(\n            r'videoname\\s*=\\s*\\'([^\\']+)\\'', webpage, 'title').strip()\n        description = self._html_search_regex(\n            r'class=\"(?:descr|description_txt)\">(.*?)</div>',\n            webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'flashvars\\.imageUrl\\s*=\\s*\"([^\"]+)\"', webpage, 'description', fatal=False, default=None)\n        if thumbnail:\n            thumbnail = 'http://www.vporn.com' + thumbnail\n\n        uploader = self._html_search_regex(\n            r'(?s)Uploaded by:.*?<a href=\"/user/[^\"]+\"[^>]*>(.+?)</a>',\n            webpage, 'uploader', fatal=False)\n\n        categories = re.findall(r'<a href=\"/cat/[^\"]+\"[^>]*>([^<]+)</a>', webpage)\n\n        duration = parse_duration(self._search_regex(\n            r'Runtime:\\s*</span>\\s*(\\d+ min \\d+ sec)',\n            webpage, 'duration', fatal=False))\n\n        view_count = str_to_int(self._search_regex(\n            r'class=\"views\">([\\d,\\.]+) [Vv]iews<',\n            webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r\"'Comments \\(([\\d,\\.]+)\\)'\",\n            webpage, 'comment count', default=None))\n\n        formats = []\n\n        for video in re.findall(r'flashvars\\.videoUrl([^=]+?)\\s*=\\s*\"(https?://[^\"]+)\"', webpage):\n            video_url = video[1]\n            fmt = {\n                'url': video_url,\n                'format_id': video[0],\n            }\n            m = re.search(r'_(?P<width>\\d+)x(?P<height>\\d+)_(?P<vbr>\\d+)k\\.mp4$', video_url)\n            if m:\n                fmt.update({\n                    'width': int(m.group('width')),\n                    'height': int(m.group('height')),\n                    'vbr': int(m.group('vbr')),\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'categories': categories,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 51,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.pornoxo.PornoXOIE._real_extract#27",
        "src_path": "youtube_dl/extractor/pornoxo.py",
        "class_name": "youtube_dl.extractor.pornoxo.PornoXOIE",
        "signature": "youtube_dl.extractor.pornoxo.PornoXOIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'\\'file\\'\\s*:\\s*\"([^\"]+)\"', webpage, 'video_url')\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)\\s*-\\s*PornoXO', webpage, 'title')\n\n        description = self._html_search_regex(\n            r'<meta name=\"description\" content=\"([^\"]+)\\s*featuring',\n            webpage, 'description', fatal=False)\n\n        thumbnail = self._html_search_regex(\n            r'\\'image\\'\\s*:\\s*\"([^\"]+)\"', webpage, 'thumbnail', fatal=False)\n\n        view_count = str_to_int(self._html_search_regex(\n            r'[vV]iews:\\s*([0-9,]+)', webpage, 'view count', fatal=False))\n\n        categories_str = self._html_search_regex(\n            r'<meta name=\"description\" content=\".*featuring\\s*([^\"]+)\"',\n            webpage, 'categories', fatal=False)\n        categories = (\n            None if categories_str is None\n            else categories_str.split(','))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'view_count': view_count,\n            'age_limit': 18,\n        }",
        "begin_line": 27,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVIE._real_extract#28",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://widgets.ellentube.com/videos/%s' % video_id,\n            video_id)\n\n        partner_id = self._search_regex(\n            r\"var\\s+partnerId\\s*=\\s*'([^']+)\", webpage, 'partner id')\n\n        kaltura_id = self._search_regex(\n            [r'id=\"kaltura_player_([^\"]+)\"',\n             r\"_wb_entry_id\\s*:\\s*'([^']+)\",\n             r'data-kaltura-entry-id=\"([^\"]+)'],\n            webpage, 'kaltura id')\n\n        return self.url_result('kaltura:%s:%s' % (partner_id, kaltura_id), 'Kaltura')",
        "begin_line": 28,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVClipsIE._real_extract#59",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVClipsIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n        playlist = self._extract_playlist(webpage)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': self._og_search_title(webpage),\n            'entries': self._extract_entries(playlist)\n        }",
        "begin_line": 59,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_playlist#72",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVClipsIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_playlist(self, webpage)",
        "snippet": "    def _extract_playlist(self, webpage):\n        json_string = self._search_regex(r'playerView.addClips\\(\\[\\{(.*?)\\}\\]\\);', webpage, 'json')\n        try:\n            return json.loads(\"[{\" + json_string + \"}]\")\n        except ValueError as ve:\n            raise ExtractorError('Failed to download JSON', cause=ve)",
        "begin_line": 72,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_entries#79",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVClipsIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_entries(self, playlist)",
        "snippet": "    def _extract_entries(self, playlist):\n        return [\n            self.url_result(\n                'kaltura:%s:%s' % (item['kaltura_partner_id'], item['kaltura_entry_id']),\n                'Kaltura')\n            for item in playlist]",
        "begin_line": 79,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.onionstudios.OnionStudiosIE._extract_url#31",
        "src_path": "youtube_dl/extractor/onionstudios.py",
        "class_name": "youtube_dl.extractor.onionstudios.OnionStudiosIE",
        "signature": "youtube_dl.extractor.onionstudios.OnionStudiosIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?onionstudios\\.com/embed.+?)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 31,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.onionstudios.OnionStudiosIE._real_extract#37",
        "src_path": "youtube_dl/extractor/onionstudios.py",
        "class_name": "youtube_dl.extractor.onionstudios.OnionStudiosIE",
        "signature": "youtube_dl.extractor.onionstudios.OnionStudiosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.onionstudios.com/embed?id=%s' % video_id, video_id)\n\n        formats = []\n        for src in re.findall(r'<source[^>]+src=\"([^\"]+)\"', webpage):\n            if determine_ext(src) != 'm3u8':  # m3u8 always results in 403\n                formats.append({\n                    'url': src,\n                })\n        self._sort_formats(formats)\n\n        title = self._search_regex(\n            r'share_title\\s*=\\s*([\"\\'])(?P<title>[^\\1]+?)\\1',\n            webpage, 'title', group='title')\n        description = self._search_regex(\n            r'share_description\\s*=\\s*([\"\\'])(?P<description>[^\\1]+?)\\1',\n            webpage, 'description', default=None, group='description')\n        thumbnail = self._search_regex(\n            r'poster\\s*=\\s*([\"\\'])(?P<thumbnail>[^\\1]+?)\\1',\n            webpage, 'thumbnail', default=False, group='thumbnail')\n\n        uploader_id = self._search_regex(\n            r'twitter_handle\\s*=\\s*([\"\\'])(?P<uploader_id>[^\\1]+?)\\1',\n            webpage, 'uploader id', fatal=False, group='uploader_id')\n        uploader = self._search_regex(\n            r'window\\.channelName\\s*=\\s*([\"\\'])Embedded:(?P<uploader>[^\\1]+?)\\1',\n            webpage, 'uploader', default=False, group='uploader')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'formats': formats,\n        }",
        "begin_line": 37,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._set_language#56",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._set_language(self)",
        "snippet": "    def _set_language(self):\n        self._set_cookie(\n            '.youtube.com', 'PREF', 'f1=50000000&hl=en',\n            # YouTube sets the expire time to about two months\n            expire_time=time.time() + 2 * 30 * 24 * 3600)",
        "begin_line": 56,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031746031746031746,
            "pseudo_dstar_susp": 0.0029850746268656717,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0029850746268656717,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._ids_to_results#62",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._ids_to_results(self, ids)",
        "snippet": "    def _ids_to_results(self, ids):\n        return [\n            self.url_result(vid_id, 'Youtube', video_id=vid_id)\n            for vid_id in ids]",
        "begin_line": 62,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._login#67",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._login(self)",
        "snippet": "    def _login(self):\n        \"\"\"\n        Attempt to log in to YouTube.\n        True is returned if successful or skipped.\n        False is returned if login failed.\n\n        If _LOGIN_REQUIRED is set and no authentication was provided, an error is raised.\n        \"\"\"\n        (username, password) = self._get_login_info()\n        # No authentication to be performed\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return True\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None,\n            note='Downloading login page',\n            errnote='unable to fetch login page', fatal=False)\n        if login_page is False:\n            return\n\n        galx = self._search_regex(r'(?s)<input.+?name=\"GALX\".+?value=\"(.+?)\"',\n                                  login_page, 'Login GALX parameter')\n\n        # Log in\n        login_form_strs = {\n            'continue': 'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',\n            'Email': username,\n            'GALX': galx,\n            'Passwd': password,\n\n            'PersistentCookie': 'yes',\n            '_utf8': '\u9731',\n            'bgresponse': 'js_disabled',\n            'checkConnection': '',\n            'checkedDomains': 'youtube',\n            'dnConn': '',\n            'pstMsg': '0',\n            'rmShown': '1',\n            'secTok': '',\n            'signIn': 'Sign in',\n            'timeStmp': '',\n            'service': 'youtube',\n            'uilel': '3',\n            'hl': 'en_US',\n        }\n\n        login_data = compat_urllib_parse.urlencode(encode_dict(login_form_strs)).encode('ascii')\n\n        req = compat_urllib_request.Request(self._LOGIN_URL, login_data)\n        login_results = self._download_webpage(\n            req, None,\n            note='Logging in', errnote='unable to log in', fatal=False)\n        if login_results is False:\n            return False\n\n        if re.search(r'id=\"errormsg_0_Passwd\"', login_results) is not None:\n            raise ExtractorError('Please use your account password and a two-factor code instead of an application-specific password.', expected=True)\n\n        # Two-Factor\n        # TODO add SMS and phone call support - these require making a request and then prompting the user\n\n        if re.search(r'(?i)<form[^>]* id=\"challenge\"', login_results) is not None:\n            tfa_code = self._get_tfa_info('2-step verification code')\n\n            if not tfa_code:\n                self._downloader.report_warning(\n                    'Two-factor authentication required. Provide it either interactively or with --twofactor <code>'\n                    '(Note that only TOTP (Google Authenticator App) codes work at this time.)')\n                return False\n\n            tfa_code = remove_start(tfa_code, 'G-')\n\n            tfa_form_strs = self._form_hidden_inputs('challenge', login_results)\n\n            tfa_form_strs.update({\n                'Pin': tfa_code,\n                'TrustDevice': 'on',\n            })\n\n            tfa_data = compat_urllib_parse.urlencode(encode_dict(tfa_form_strs)).encode('ascii')\n\n            tfa_req = compat_urllib_request.Request(self._TWOFACTOR_URL, tfa_data)\n            tfa_results = self._download_webpage(\n                tfa_req, None,\n                note='Submitting TFA code', errnote='unable to submit tfa', fatal=False)\n\n            if tfa_results is False:\n                return False\n\n            if re.search(r'(?i)<form[^>]* id=\"challenge\"', tfa_results) is not None:\n                self._downloader.report_warning('Two-factor code expired or invalid. Please try again, or use a one-use backup code instead.')\n                return False\n            if re.search(r'(?i)<form[^>]* id=\"gaia_loginform\"', tfa_results) is not None:\n                self._downloader.report_warning('unable to log in - did the page structure change?')\n                return False\n            if re.search(r'smsauth-interstitial-reviewsettings', tfa_results) is not None:\n                self._downloader.report_warning('Your Google account has a security notice. Please log in on your web browser, resolve the notice, and try again.')\n                return False\n\n        if re.search(r'(?i)<form[^>]* id=\"gaia_loginform\"', login_results) is not None:\n            self._downloader.report_warning('unable to log in: bad username or password')\n            return False\n        return True",
        "begin_line": 67,
        "end_line": 171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0036231884057971015,
            "pseudo_dstar_susp": 0.0035335689045936395,
            "pseudo_tarantula_susp": 0.0015822784810126582,
            "pseudo_op2_susp": 0.0035335689045936395,
            "pseudo_barinel_susp": 0.0015822784810126582
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._real_initialize#173",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        if self._downloader is None:\n            return\n        self._set_language()\n        if not self._login():\n            return",
        "begin_line": 173,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031746031746031746,
            "pseudo_dstar_susp": 0.0029850746268656717,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0029850746268656717,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor._entries#183",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor._entries(self, page, playlist_id)",
        "snippet": "    def _entries(self, page, playlist_id):\n        more_widget_html = content_html = page\n        for page_num in itertools.count(1):\n            for video_id, video_title in self.extract_videos_from_page(content_html):\n                yield self.url_result(\n                    video_id, 'Youtube', video_id=video_id,\n                    video_title=video_title)\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), playlist_id,\n                'Downloading page #%s' % page_num,\n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            if not content_html.strip():\n                # Some webpages show a \"Load more\" button but they don't\n                # have more videos\n                break\n            more_widget_html = more['load_more_widget_html']",
        "begin_line": 183,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor.extract_videos_from_page#206",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor.extract_videos_from_page(self, page)",
        "snippet": "    def extract_videos_from_page(self, page):\n        ids_in_page = []\n        titles_in_page = []\n        for mobj in re.finditer(self._VIDEO_RE, page):\n            # The link with index 0 is not the first video of the playlist (not sure if still actual)\n            if 'index' in mobj.groupdict() and mobj.group('id') == '0':\n                continue\n            video_id = mobj.group('id')\n            video_title = unescapeHTML(mobj.group('title'))\n            if video_title:\n                video_title = video_title.strip()\n            try:\n                idx = ids_in_page.index(video_id)\n                if video_title and not titles_in_page[idx]:\n                    titles_in_page[idx] = video_title\n            except ValueError:\n                ids_in_page.append(video_id)\n                titles_in_page.append(video_title)\n        return zip(ids_in_page, titles_in_page)",
        "begin_line": 206,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.__init__#680",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        super(YoutubeIE, self).__init__(*args, **kwargs)\n        self._player_cache = {}",
        "begin_line": 680,
        "end_line": 682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013966480446927375,
            "pseudo_dstar_susp": 0.0025974025974025974,
            "pseudo_tarantula_susp": 0.0009389671361502347,
            "pseudo_op2_susp": 0.0025974025974025974,
            "pseudo_barinel_susp": 0.0009389671361502347
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_video_info_webpage_download#684",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_video_info_webpage_download(self, video_id)",
        "snippet": "    def report_video_info_webpage_download(self, video_id):\n        \"\"\"Report attempt to download video info webpage.\"\"\"\n        self.to_screen('%s: Downloading video info webpage' % video_id)",
        "begin_line": 684,
        "end_line": 686,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031746031746031746,
            "pseudo_dstar_susp": 0.0029850746268656717,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0029850746268656717,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_information_extraction#688",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_information_extraction(self, video_id)",
        "snippet": "    def report_information_extraction(self, video_id):\n        \"\"\"Report attempt to extract video information.\"\"\"\n        self.to_screen('%s: Extracting video information' % video_id)",
        "begin_line": 688,
        "end_line": 690,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_unavailable_format#692",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_unavailable_format(self, video_id, format)",
        "snippet": "    def report_unavailable_format(self, video_id, format):\n        \"\"\"Report extracted video URL.\"\"\"\n        self.to_screen('%s: Format %s not available' % (video_id, format))",
        "begin_line": 692,
        "end_line": 694,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_rtmp_download#696",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_rtmp_download(self)",
        "snippet": "    def report_rtmp_download(self):\n        \"\"\"Indicate the download will use the RTMP protocol.\"\"\"\n        self.to_screen('RTMP download detected')",
        "begin_line": 696,
        "end_line": 698,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._signature_cache_id#700",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._signature_cache_id(self, example_sig)",
        "snippet": "    def _signature_cache_id(self, example_sig):\n        \"\"\" Return a string representation of a signature \"\"\"\n        return '.'.join(compat_str(len(part)) for part in example_sig.split('.'))",
        "begin_line": 700,
        "end_line": 702,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_signature_function#704",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_signature_function(self, video_id, player_url, example_sig)",
        "snippet": "    def _extract_signature_function(self, video_id, player_url, example_sig):\n        id_m = re.match(\n            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player(?:-new)?)?\\.(?P<ext>[a-z]+)$',\n            player_url)\n        if not id_m:\n            raise ExtractorError('Cannot identify player %r' % player_url)\n        player_type = id_m.group('ext')\n        player_id = id_m.group('id')\n\n        # Read from filesystem cache\n        func_id = '%s_%s_%s' % (\n            player_type, player_id, self._signature_cache_id(example_sig))\n        assert os.path.basename(func_id) == func_id\n\n        cache_spec = self._downloader.cache.load('youtube-sigfuncs', func_id)\n        if cache_spec is not None:\n            return lambda s: ''.join(s[i] for i in cache_spec)\n\n        download_note = (\n            'Downloading player %s' % player_url\n            if self._downloader.params.get('verbose') else\n            'Downloading %s player %s' % (player_type, player_id)\n        )\n        if player_type == 'js':\n            code = self._download_webpage(\n                player_url, video_id,\n                note=download_note,\n                errnote='Download of %s failed' % player_url)\n            res = self._parse_sig_js(code)\n        elif player_type == 'swf':\n            urlh = self._request_webpage(\n                player_url, video_id,\n                note=download_note,\n                errnote='Download of %s failed' % player_url)\n            code = urlh.read()\n            res = self._parse_sig_swf(code)\n        else:\n            assert False, 'Invalid player type %r' % player_type\n\n        test_string = ''.join(map(compat_chr, range(len(example_sig))))\n        cache_res = res(test_string)\n        cache_spec = [ord(c) for c in cache_res]\n\n        self._downloader.cache.store('youtube-sigfuncs', func_id, cache_spec)\n        return res",
        "begin_line": 704,
        "end_line": 748,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._print_sig_code#750",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._print_sig_code(self, func, example_sig)",
        "snippet": "    def _print_sig_code(self, func, example_sig):\n        def gen_sig_code(idxs):\n            def _genslice(start, end, step):\n                starts = '' if start == 0 else str(start)\n                ends = (':%d' % (end + step)) if end + step >= 0 else ':'\n                steps = '' if step == 1 else (':%d' % step)\n                return 's[%s%s%s]' % (starts, ends, steps)\n\n            step = None\n            # Quelch pyflakes warnings - start will be set when step is set\n            start = '(Never used)'\n            for i, prev in zip(idxs[1:], idxs[:-1]):\n                if step is not None:\n                    if i - prev == step:\n                        continue\n                    yield _genslice(start, prev, step)\n                    step = None\n                    continue\n                if i - prev in [-1, 1]:\n                    step = i - prev\n                    start = prev\n                    continue\n                else:\n                    yield 's[%d]' % prev\n            if step is None:\n                yield 's[%d]' % i\n            else:\n                yield _genslice(start, i, step)\n\n        test_string = ''.join(map(compat_chr, range(len(example_sig))))\n        cache_res = func(test_string)\n        cache_spec = [ord(c) for c in cache_res]\n        expr_code = ' + '.join(gen_sig_code(cache_spec))\n        signature_id_tuple = '(%s)' % (\n            ', '.join(compat_str(len(p)) for p in example_sig.split('.')))\n        code = ('if tuple(len(p) for p in s.split(\\'.\\')) == %s:\\n'\n                '    return %s\\n') % (signature_id_tuple, expr_code)\n        self.to_screen('Extracted signature function:\\n' + code)",
        "begin_line": 750,
        "end_line": 787,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_js#789",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_js(self, jscode)",
        "snippet": "    def _parse_sig_js(self, jscode):\n        funcname = self._search_regex(\n            r'\\.sig\\|\\|([a-zA-Z0-9$]+)\\(', jscode,\n            'Initial JS player signature function name')\n\n        jsi = JSInterpreter(jscode)\n        initial_function = jsi.extract_function(funcname)\n        return lambda s: initial_function([s])",
        "begin_line": 789,
        "end_line": 796,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 3.88621172081455e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_swf#798",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_swf(self, file_contents)",
        "snippet": "    def _parse_sig_swf(self, file_contents):\n        swfi = SWFInterpreter(file_contents)\n        TARGET_CLASSNAME = 'SignatureDecipher'\n        searched_class = swfi.extract_class(TARGET_CLASSNAME)\n        initial_function = swfi.extract_function(searched_class, 'decipher')\n        return lambda s: initial_function([s])",
        "begin_line": 798,
        "end_line": 803,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._decrypt_signature#805",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._decrypt_signature(self, s, video_id, player_url, age_gate=False)",
        "snippet": "    def _decrypt_signature(self, s, video_id, player_url, age_gate=False):\n        \"\"\"Turn the encrypted s field into a working signature\"\"\"\n\n        if player_url is None:\n            raise ExtractorError('Cannot decrypt signature without player_url')\n\n        if player_url.startswith('//'):\n            player_url = 'https:' + player_url\n        try:\n            player_id = (player_url, self._signature_cache_id(s))\n            if player_id not in self._player_cache:\n                func = self._extract_signature_function(\n                    video_id, player_url, s\n                )\n                self._player_cache[player_id] = func\n            func = self._player_cache[player_id]\n            if self._downloader.params.get('youtube_print_sig_code'):\n                self._print_sig_code(func, s)\n            return func(s)\n        except Exception as e:\n            tb = traceback.format_exc()\n            raise ExtractorError(\n                'Signature extraction failed: ' + tb, cause=e)",
        "begin_line": 805,
        "end_line": 827,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._get_subtitles#829",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._get_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_subtitles(self, video_id, webpage):\n        try:\n            subs_doc = self._download_xml(\n                'https://video.google.com/timedtext?hl=en&type=list&v=%s' % video_id,\n                video_id, note=False)\n        except ExtractorError as err:\n            self._downloader.report_warning('unable to download video subtitles: %s' % compat_str(err))\n            return {}\n\n        sub_lang_list = {}\n        for track in subs_doc.findall('track'):\n            lang = track.attrib['lang_code']\n            if lang in sub_lang_list:\n                continue\n            sub_formats = []\n            for ext in ['sbv', 'vtt', 'srt']:\n                params = compat_urllib_parse.urlencode({\n                    'lang': lang,\n                    'v': video_id,\n                    'fmt': ext,\n                    'name': track.attrib['name'].encode('utf-8'),\n                })\n                sub_formats.append({\n                    'url': 'https://www.youtube.com/api/timedtext?' + params,\n                    'ext': ext,\n                })\n            sub_lang_list[lang] = sub_formats\n        if not sub_lang_list:\n            self._downloader.report_warning('video doesn\\'t have subtitles')\n            return {}\n        return sub_lang_list",
        "begin_line": 829,
        "end_line": 859,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._get_automatic_captions#861",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._get_automatic_captions(self, video_id, webpage)",
        "snippet": "    def _get_automatic_captions(self, video_id, webpage):\n        \"\"\"We need the webpage for getting the captions url, pass it as an\n           argument to speed up the process.\"\"\"\n        self.to_screen('%s: Looking for automatic captions' % video_id)\n        mobj = re.search(r';ytplayer.config = ({.*?});', webpage)\n        err_msg = 'Couldn\\'t find automatic captions for %s' % video_id\n        if mobj is None:\n            self._downloader.report_warning(err_msg)\n            return {}\n        player_config = json.loads(mobj.group(1))\n        try:\n            args = player_config['args']\n            caption_url = args['ttsurl']\n            timestamp = args['timestamp']\n            # We get the available subtitles\n            list_params = compat_urllib_parse.urlencode({\n                'type': 'list',\n                'tlangs': 1,\n                'asrs': 1,\n            })\n            list_url = caption_url + '&' + list_params\n            caption_list = self._download_xml(list_url, video_id)\n            original_lang_node = caption_list.find('track')\n            if original_lang_node is None:\n                self._downloader.report_warning('Video doesn\\'t have automatic captions')\n                return {}\n            original_lang = original_lang_node.attrib['lang_code']\n            caption_kind = original_lang_node.attrib.get('kind', '')\n\n            sub_lang_list = {}\n            for lang_node in caption_list.findall('target'):\n                sub_lang = lang_node.attrib['lang_code']\n                sub_formats = []\n                for ext in ['sbv', 'vtt', 'srt']:\n                    params = compat_urllib_parse.urlencode({\n                        'lang': original_lang,\n                        'tlang': sub_lang,\n                        'fmt': ext,\n                        'ts': timestamp,\n                        'kind': caption_kind,\n                    })\n                    sub_formats.append({\n                        'url': caption_url + '&' + params,\n                        'ext': ext,\n                    })\n                sub_lang_list[sub_lang] = sub_formats\n            return sub_lang_list\n        # An extractor error can be raise by the download process if there are\n        # no automatic captions but there are subtitles\n        except (KeyError, ExtractorError):\n            self._downloader.report_warning(err_msg)\n            return {}",
        "begin_line": 861,
        "end_line": 912,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.extract_id#915",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.extract_id(cls, url)",
        "snippet": "    def extract_id(cls, url):\n        mobj = re.match(cls._VALID_URL, url, re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        video_id = mobj.group(2)\n        return video_id",
        "begin_line": 915,
        "end_line": 920,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002849002849002849,
            "pseudo_dstar_susp": 0.0027472527472527475,
            "pseudo_tarantula_susp": 0.0013386880856760374,
            "pseudo_op2_susp": 0.0027472527472527475,
            "pseudo_barinel_susp": 0.0013386880856760374
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_from_m3u8#922",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_from_m3u8(self, manifest_url, video_id)",
        "snippet": "    def _extract_from_m3u8(self, manifest_url, video_id):\n        url_map = {}\n\n        def _get_urls(_manifest):\n            lines = _manifest.split('\\n')\n            urls = filter(lambda l: l and not l.startswith('#'),\n                          lines)\n            return urls\n        manifest = self._download_webpage(manifest_url, video_id, 'Downloading formats manifest')\n        formats_urls = _get_urls(manifest)\n        for format_url in formats_urls:\n            itag = self._search_regex(r'itag/(\\d+?)/', format_url, 'itag')\n            url_map[itag] = format_url\n        return url_map",
        "begin_line": 922,
        "end_line": 935,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_annotations#937",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_annotations(self, video_id)",
        "snippet": "    def _extract_annotations(self, video_id):\n        url = 'https://www.youtube.com/annotations_invideo?features=1&legacy=1&video_id=%s' % video_id\n        return self._download_webpage(url, video_id, note='Searching for annotations.', errnote='Unable to download video annotations.')",
        "begin_line": 937,
        "end_line": 939,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._parse_dash_manifest#941",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._parse_dash_manifest(self, video_id, dash_manifest_url, player_url, age_gate, fatal=True)",
        "snippet": "    def _parse_dash_manifest(\n            self, video_id, dash_manifest_url, player_url, age_gate, fatal=True):\n        def decrypt_sig(mobj):\n            s = mobj.group(1)\n            dec_s = self._decrypt_signature(s, video_id, player_url, age_gate)\n            return '/signature/%s' % dec_s\n        dash_manifest_url = re.sub(r'/s/([a-fA-F0-9\\.]+)', decrypt_sig, dash_manifest_url)\n        dash_doc = self._download_xml(\n            dash_manifest_url, video_id,\n            note='Downloading DASH manifest',\n            errnote='Could not download DASH manifest',\n            fatal=fatal)\n\n        if dash_doc is False:\n            return []\n\n        formats = []\n        for a in dash_doc.findall('.//{urn:mpeg:DASH:schema:MPD:2011}AdaptationSet'):\n            mime_type = a.attrib.get('mimeType')\n            for r in a.findall('{urn:mpeg:DASH:schema:MPD:2011}Representation'):\n                url_el = r.find('{urn:mpeg:DASH:schema:MPD:2011}BaseURL')\n                if url_el is None:\n                    continue\n                if mime_type == 'text/vtt':\n                    # TODO implement WebVTT downloading\n                    pass\n                elif mime_type.startswith('audio/') or mime_type.startswith('video/'):\n                    segment_list = r.find('{urn:mpeg:DASH:schema:MPD:2011}SegmentList')\n                    format_id = r.attrib['id']\n                    video_url = url_el.text\n                    filesize = int_or_none(url_el.attrib.get('{http://youtube.com/yt/2012/10/10}contentLength'))\n                    f = {\n                        'format_id': format_id,\n                        'url': video_url,\n                        'width': int_or_none(r.attrib.get('width')),\n                        'height': int_or_none(r.attrib.get('height')),\n                        'tbr': int_or_none(r.attrib.get('bandwidth'), 1000),\n                        'asr': int_or_none(r.attrib.get('audioSamplingRate')),\n                        'filesize': filesize,\n                        'fps': int_or_none(r.attrib.get('frameRate')),\n                    }\n                    if segment_list is not None:\n                        f.update({\n                            'initialization_url': segment_list.find('{urn:mpeg:DASH:schema:MPD:2011}Initialization').attrib['sourceURL'],\n                            'segment_urls': [segment.attrib.get('media') for segment in segment_list.findall('{urn:mpeg:DASH:schema:MPD:2011}SegmentURL')],\n                            'protocol': 'http_dash_segments',\n                        })\n                    try:\n                        existing_format = next(\n                            fo for fo in formats\n                            if fo['format_id'] == format_id)\n                    except StopIteration:\n                        full_info = self._formats.get(format_id, {}).copy()\n                        full_info.update(f)\n                        codecs = r.attrib.get('codecs')\n                        if codecs:\n                            if full_info.get('acodec') == 'none' and 'vcodec' not in full_info:\n                                full_info['vcodec'] = codecs\n                            elif full_info.get('vcodec') == 'none' and 'acodec' not in full_info:\n                                full_info['acodec'] = codecs\n                        formats.append(full_info)\n                    else:\n                        existing_format.update(f)\n                else:\n                    self.report_warning('Unknown MIME type %s in DASH manifest' % mime_type)\n        return formats",
        "begin_line": 941,
        "end_line": 1006,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._real_extract#1008",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        proto = (\n            'http' if self._downloader.params.get('prefer_insecure', False)\n            else 'https')\n\n        start_time = None\n        end_time = None\n        parsed_url = compat_urllib_parse_urlparse(url)\n        for component in [parsed_url.fragment, parsed_url.query]:\n            query = compat_parse_qs(component)\n            if start_time is None and 't' in query:\n                start_time = parse_duration(query['t'][0])\n            if start_time is None and 'start' in query:\n                start_time = parse_duration(query['start'][0])\n            if end_time is None and 'end' in query:\n                end_time = parse_duration(query['end'][0])\n\n        # Extract original video URL from URL with redirection, like age verification, using next_url parameter\n        mobj = re.search(self._NEXT_URL_RE, url)\n        if mobj:\n            url = proto + '://www.youtube.com/' + compat_urllib_parse_unquote(mobj.group(1)).lstrip('/')\n        video_id = self.extract_id(url)\n\n        # Get video webpage\n        url = proto + '://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1&bpctr=9999999999' % video_id\n        video_webpage = self._download_webpage(url, video_id)\n\n        # Attempt to extract SWF player URL\n        mobj = re.search(r'swfConfig.*?\"(https?:\\\\/\\\\/.*?watch.*?-.*?\\.swf)\"', video_webpage)\n        if mobj is not None:\n            player_url = re.sub(r'\\\\(.)', r'\\1', mobj.group(1))\n        else:\n            player_url = None\n\n        dash_mpds = []\n\n        def add_dash_mpd(video_info):\n            dash_mpd = video_info.get('dashmpd')\n            if dash_mpd and dash_mpd[0] not in dash_mpds:\n                dash_mpds.append(dash_mpd[0])\n\n        # Get video info\n        embed_webpage = None\n        is_live = None\n        if re.search(r'player-age-gate-content\">', video_webpage) is not None:\n            age_gate = True\n            # We simulate the access to the video from www.youtube.com/v/{video_id}\n            # this can be viewed without login into Youtube\n            url = proto + '://www.youtube.com/embed/%s' % video_id\n            embed_webpage = self._download_webpage(url, video_id, 'Downloading embed webpage')\n            data = compat_urllib_parse.urlencode({\n                'video_id': video_id,\n                'eurl': 'https://youtube.googleapis.com/v/' + video_id,\n                'sts': self._search_regex(\n                    r'\"sts\"\\s*:\\s*(\\d+)', embed_webpage, 'sts', default=''),\n            })\n            video_info_url = proto + '://www.youtube.com/get_video_info?' + data\n            video_info_webpage = self._download_webpage(\n                video_info_url, video_id,\n                note='Refetching age-gated info webpage',\n                errnote='unable to download video info webpage')\n            video_info = compat_parse_qs(video_info_webpage)\n            add_dash_mpd(video_info)\n        else:\n            age_gate = False\n            video_info = None\n            # Try looking directly into the video webpage\n            mobj = re.search(r';ytplayer\\.config\\s*=\\s*({.*?});', video_webpage)\n            if mobj:\n                json_code = uppercase_escape(mobj.group(1))\n                ytplayer_config = json.loads(json_code)\n                args = ytplayer_config['args']\n                if args.get('url_encoded_fmt_stream_map'):\n                    # Convert to the same format returned by compat_parse_qs\n                    video_info = dict((k, [v]) for k, v in args.items())\n                    add_dash_mpd(video_info)\n                if args.get('livestream') == '1' or args.get('live_playback') == 1:\n                    is_live = True\n            if not video_info or self._downloader.params.get('youtube_include_dash_manifest', True):\n                # We also try looking in get_video_info since it may contain different dashmpd\n                # URL that points to a DASH manifest with possibly different itag set (some itags\n                # are missing from DASH manifest pointed by webpage's dashmpd, some - from DASH\n                # manifest pointed by get_video_info's dashmpd).\n                # The general idea is to take a union of itags of both DASH manifests (for example\n                # video with such 'manifest behavior' see https://github.com/rg3/youtube-dl/issues/6093)\n                self.report_video_info_webpage_download(video_id)\n                for el_type in ['&el=info', '&el=embedded', '&el=detailpage', '&el=vevo', '']:\n                    video_info_url = (\n                        '%s://www.youtube.com/get_video_info?&video_id=%s%s&ps=default&eurl=&gl=US&hl=en'\n                        % (proto, video_id, el_type))\n                    video_info_webpage = self._download_webpage(\n                        video_info_url,\n                        video_id, note=False,\n                        errnote='unable to download video info webpage')\n                    get_video_info = compat_parse_qs(video_info_webpage)\n                    if get_video_info.get('use_cipher_signature') != ['True']:\n                        add_dash_mpd(get_video_info)\n                    if not video_info:\n                        video_info = get_video_info\n                    if 'token' in get_video_info:\n                        break\n        if 'token' not in video_info:\n            if 'reason' in video_info:\n                if 'The uploader has not made this video available in your country.' in video_info['reason']:\n                    regions_allowed = self._html_search_meta('regionsAllowed', video_webpage, default=None)\n                    if regions_allowed:\n                        raise ExtractorError('YouTube said: This video is available in %s only' % (\n                            ', '.join(map(ISO3166Utils.short2full, regions_allowed.split(',')))),\n                            expected=True)\n                raise ExtractorError(\n                    'YouTube said: %s' % video_info['reason'][0],\n                    expected=True, video_id=video_id)\n            else:\n                raise ExtractorError(\n                    '\"token\" parameter not in video info for unknown reason',\n                    video_id=video_id)\n\n        # title\n        if 'title' in video_info:\n            video_title = video_info['title'][0]\n        else:\n            self._downloader.report_warning('Unable to extract video title')\n            video_title = '_'\n\n        # description\n        video_description = get_element_by_id(\"eow-description\", video_webpage)\n        if video_description:\n            video_description = re.sub(r'''(?x)\n                <a\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?\n                    title=\"([^\"]+)\"\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?\n                    class=\"yt-uix-redirect-link\"\\s*>\n                [^<]+\n                </a>\n            ''', r'\\1', video_description)\n            video_description = clean_html(video_description)\n        else:\n            fd_mobj = re.search(r'<meta name=\"description\" content=\"([^\"]+)\"', video_webpage)\n            if fd_mobj:\n                video_description = unescapeHTML(fd_mobj.group(1))\n            else:\n                video_description = ''\n\n        if 'multifeed_metadata_list' in video_info and not smuggled_data.get('force_singlefeed', False):\n            if not self._downloader.params.get('noplaylist'):\n                entries = []\n                feed_ids = []\n                multifeed_metadata_list = compat_urllib_parse_unquote_plus(video_info['multifeed_metadata_list'][0])\n                for feed in multifeed_metadata_list.split(','):\n                    feed_data = compat_parse_qs(feed)\n                    entries.append({\n                        '_type': 'url_transparent',\n                        'ie_key': 'Youtube',\n                        'url': smuggle_url(\n                            '%s://www.youtube.com/watch?v=%s' % (proto, feed_data['id'][0]),\n                            {'force_singlefeed': True}),\n                        'title': '%s (%s)' % (video_title, feed_data['title'][0]),\n                    })\n                    feed_ids.append(feed_data['id'][0])\n                self.to_screen(\n                    'Downloading multifeed video (%s) - add --no-playlist to just download video %s'\n                    % (', '.join(feed_ids), video_id))\n                return self.playlist_result(entries, video_id, video_title, video_description)\n            self.to_screen('Downloading just video %s because of --no-playlist' % video_id)\n\n        if 'view_count' in video_info:\n            view_count = int(video_info['view_count'][0])\n        else:\n            view_count = None\n\n        # Check for \"rental\" videos\n        if 'ypc_video_rental_bar_text' in video_info and 'author' not in video_info:\n            raise ExtractorError('\"rental\" videos not supported')\n\n        # Start extracting information\n        self.report_information_extraction(video_id)\n\n        # uploader\n        if 'author' not in video_info:\n            raise ExtractorError('Unable to extract uploader name')\n        video_uploader = compat_urllib_parse_unquote_plus(video_info['author'][0])\n\n        # uploader_id\n        video_uploader_id = None\n        mobj = re.search(r'<link itemprop=\"url\" href=\"http://www.youtube.com/(?:user|channel)/([^\"]+)\">', video_webpage)\n        if mobj is not None:\n            video_uploader_id = mobj.group(1)\n        else:\n            self._downloader.report_warning('unable to extract uploader nickname')\n\n        # thumbnail image\n        # We try first to get a high quality image:\n        m_thumb = re.search(r'<span itemprop=\"thumbnail\".*?href=\"(.*?)\">',\n                            video_webpage, re.DOTALL)\n        if m_thumb is not None:\n            video_thumbnail = m_thumb.group(1)\n        elif 'thumbnail_url' not in video_info:\n            self._downloader.report_warning('unable to extract video thumbnail')\n            video_thumbnail = None\n        else:   # don't panic if we can't find it\n            video_thumbnail = compat_urllib_parse_unquote_plus(video_info['thumbnail_url'][0])\n\n        # upload date\n        upload_date = self._html_search_meta(\n            'datePublished', video_webpage, 'upload date', default=None)\n        if not upload_date:\n            upload_date = self._search_regex(\n                [r'(?s)id=\"eow-date.*?>(.*?)</span>',\n                 r'id=\"watch-uploader-info\".*?>.*?(?:Published|Uploaded|Streamed live|Started) on (.+?)</strong>'],\n                video_webpage, 'upload date', default=None)\n            if upload_date:\n                upload_date = ' '.join(re.sub(r'[/,-]', r' ', mobj.group(1)).split())\n        upload_date = unified_strdate(upload_date)\n\n        m_cat_container = self._search_regex(\n            r'(?s)<h4[^>]*>\\s*Category\\s*</h4>\\s*<ul[^>]*>(.*?)</ul>',\n            video_webpage, 'categories', default=None)\n        if m_cat_container:\n            category = self._html_search_regex(\n                r'(?s)<a[^<]+>(.*?)</a>', m_cat_container, 'category',\n                default=None)\n            video_categories = None if category is None else [category]\n        else:\n            video_categories = None\n\n        video_tags = [\n            unescapeHTML(m.group('content'))\n            for m in re.finditer(self._meta_regex('og:video:tag'), video_webpage)]\n\n        def _extract_count(count_name):\n            return str_to_int(self._search_regex(\n                r'-%s-button[^>]+><span[^>]+class=\"yt-uix-button-content\"[^>]*>([\\d,]+)</span>'\n                % re.escape(count_name),\n                video_webpage, count_name, default=None))\n\n        like_count = _extract_count('like')\n        dislike_count = _extract_count('dislike')\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, video_webpage)\n        automatic_captions = self.extract_automatic_captions(video_id, video_webpage)\n\n        if 'length_seconds' not in video_info:\n            self._downloader.report_warning('unable to extract video duration')\n            video_duration = None\n        else:\n            video_duration = int(compat_urllib_parse_unquote_plus(video_info['length_seconds'][0]))\n\n        # annotations\n        video_annotations = None\n        if self._downloader.params.get('writeannotations', False):\n            video_annotations = self._extract_annotations(video_id)\n\n        def _map_to_format_list(urlmap):\n            formats = []\n            for itag, video_real_url in urlmap.items():\n                dct = {\n                    'format_id': itag,\n                    'url': video_real_url,\n                    'player_url': player_url,\n                }\n                if itag in self._formats:\n                    dct.update(self._formats[itag])\n                formats.append(dct)\n            return formats\n\n        if 'conn' in video_info and video_info['conn'][0].startswith('rtmp'):\n            self.report_rtmp_download()\n            formats = [{\n                'format_id': '_rtmp',\n                'protocol': 'rtmp',\n                'url': video_info['conn'][0],\n                'player_url': player_url,\n            }]\n        elif len(video_info.get('url_encoded_fmt_stream_map', [''])[0]) >= 1 or len(video_info.get('adaptive_fmts', [''])[0]) >= 1:\n            encoded_url_map = video_info.get('url_encoded_fmt_stream_map', [''])[0] + ',' + video_info.get('adaptive_fmts', [''])[0]\n            if 'rtmpe%3Dyes' in encoded_url_map:\n                raise ExtractorError('rtmpe downloads are not supported, see https://github.com/rg3/youtube-dl/issues/343 for more information.', expected=True)\n            formats = []\n            for url_data_str in encoded_url_map.split(','):\n                url_data = compat_parse_qs(url_data_str)\n                if 'itag' not in url_data or 'url' not in url_data:\n                    continue\n                format_id = url_data['itag'][0]\n                url = url_data['url'][0]\n\n                if 'sig' in url_data:\n                    url += '&signature=' + url_data['sig'][0]\n                elif 's' in url_data:\n                    encrypted_sig = url_data['s'][0]\n                    ASSETS_RE = r'\"assets\":.+?\"js\":\\s*(\"[^\"]+\")'\n\n                    jsplayer_url_json = self._search_regex(\n                        ASSETS_RE,\n                        embed_webpage if age_gate else video_webpage,\n                        'JS player URL (1)', default=None)\n                    if not jsplayer_url_json and not age_gate:\n                        # We need the embed website after all\n                        if embed_webpage is None:\n                            embed_url = proto + '://www.youtube.com/embed/%s' % video_id\n                            embed_webpage = self._download_webpage(\n                                embed_url, video_id, 'Downloading embed webpage')\n                        jsplayer_url_json = self._search_regex(\n                            ASSETS_RE, embed_webpage, 'JS player URL')\n\n                    player_url = json.loads(jsplayer_url_json)\n                    if player_url is None:\n                        player_url_json = self._search_regex(\n                            r'ytplayer\\.config.*?\"url\"\\s*:\\s*(\"[^\"]+\")',\n                            video_webpage, 'age gate player URL')\n                        player_url = json.loads(player_url_json)\n\n                    if self._downloader.params.get('verbose'):\n                        if player_url is None:\n                            player_version = 'unknown'\n                            player_desc = 'unknown'\n                        else:\n                            if player_url.endswith('swf'):\n                                player_version = self._search_regex(\n                                    r'-(.+?)(?:/watch_as3)?\\.swf$', player_url,\n                                    'flash player', fatal=False)\n                                player_desc = 'flash player %s' % player_version\n                            else:\n                                player_version = self._search_regex(\n                                    r'html5player-([^/]+?)(?:/html5player(?:-new)?)?\\.js',\n                                    player_url,\n                                    'html5 player', fatal=False)\n                                player_desc = 'html5 player %s' % player_version\n\n                        parts_sizes = self._signature_cache_id(encrypted_sig)\n                        self.to_screen('{%s} signature length %s, %s' %\n                                       (format_id, parts_sizes, player_desc))\n\n                    signature = self._decrypt_signature(\n                        encrypted_sig, video_id, player_url, age_gate)\n                    url += '&signature=' + signature\n                if 'ratebypass' not in url:\n                    url += '&ratebypass=yes'\n\n                # Some itags are not included in DASH manifest thus corresponding formats will\n                # lack metadata (see https://github.com/rg3/youtube-dl/pull/5993).\n                # Trying to extract metadata from url_encoded_fmt_stream_map entry.\n                mobj = re.search(r'^(?P<width>\\d+)[xX](?P<height>\\d+)$', url_data.get('size', [''])[0])\n                width, height = (int(mobj.group('width')), int(mobj.group('height'))) if mobj else (None, None)\n                dct = {\n                    'format_id': format_id,\n                    'url': url,\n                    'player_url': player_url,\n                    'filesize': int_or_none(url_data.get('clen', [None])[0]),\n                    'tbr': float_or_none(url_data.get('bitrate', [None])[0], 1000),\n                    'width': width,\n                    'height': height,\n                    'fps': int_or_none(url_data.get('fps', [None])[0]),\n                    'format_note': url_data.get('quality_label', [None])[0] or url_data.get('quality', [None])[0],\n                }\n                type_ = url_data.get('type', [None])[0]\n                if type_:\n                    type_split = type_.split(';')\n                    kind_ext = type_split[0].split('/')\n                    if len(kind_ext) == 2:\n                        kind, ext = kind_ext\n                        dct['ext'] = ext\n                        if kind in ('audio', 'video'):\n                            codecs = None\n                            for mobj in re.finditer(\n                                    r'(?P<key>[a-zA-Z_-]+)=(?P<quote>[\"\\']?)(?P<val>.+?)(?P=quote)(?:;|$)', type_):\n                                if mobj.group('key') == 'codecs':\n                                    codecs = mobj.group('val')\n                                    break\n                            if codecs:\n                                codecs = codecs.split(',')\n                                if len(codecs) == 2:\n                                    acodec, vcodec = codecs[0], codecs[1]\n                                else:\n                                    acodec, vcodec = (codecs[0], 'none') if kind == 'audio' else ('none', codecs[0])\n                                dct.update({\n                                    'acodec': acodec,\n                                    'vcodec': vcodec,\n                                })\n                if format_id in self._formats:\n                    dct.update(self._formats[format_id])\n                formats.append(dct)\n        elif video_info.get('hlsvp'):\n            manifest_url = video_info['hlsvp'][0]\n            url_map = self._extract_from_m3u8(manifest_url, video_id)\n            formats = _map_to_format_list(url_map)\n        else:\n            raise ExtractorError('no conn, hlsvp or url_encoded_fmt_stream_map information found in video info')\n\n        # Look for the DASH manifest\n        if self._downloader.params.get('youtube_include_dash_manifest', True):\n            dash_mpd_fatal = True\n            for dash_manifest_url in dash_mpds:\n                dash_formats = {}\n                try:\n                    for df in self._parse_dash_manifest(\n                            video_id, dash_manifest_url, player_url, age_gate, dash_mpd_fatal):\n                        # Do not overwrite DASH format found in some previous DASH manifest\n                        if df['format_id'] not in dash_formats:\n                            dash_formats[df['format_id']] = df\n                        # Additional DASH manifests may end up in HTTP Error 403 therefore\n                        # allow them to fail without bug report message if we already have\n                        # some DASH manifest succeeded. This is temporary workaround to reduce\n                        # burst of bug reports until we figure out the reason and whether it\n                        # can be fixed at all.\n                        dash_mpd_fatal = False\n                except (ExtractorError, KeyError) as e:\n                    self.report_warning(\n                        'Skipping DASH manifest: %r' % e, video_id)\n                if dash_formats:\n                    # Remove the formats we found through non-DASH, they\n                    # contain less info and it can be wrong, because we use\n                    # fixed values (for example the resolution). See\n                    # https://github.com/rg3/youtube-dl/issues/5774 for an\n                    # example.\n                    formats = [f for f in formats if f['format_id'] not in dash_formats.keys()]\n                    formats.extend(dash_formats.values())\n\n        # Check for malformed aspect ratio\n        stretched_m = re.search(\n            r'<meta\\s+property=\"og:video:tag\".*?content=\"yt:stretch=(?P<w>[0-9]+):(?P<h>[0-9]+)\">',\n            video_webpage)\n        if stretched_m:\n            ratio = float(stretched_m.group('w')) / float(stretched_m.group('h'))\n            for f in formats:\n                if f.get('vcodec') != 'none':\n                    f['stretched_ratio'] = ratio\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'uploader_id': video_uploader_id,\n            'upload_date': upload_date,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'categories': video_categories,\n            'tags': video_tags,\n            'subtitles': video_subtitles,\n            'automatic_captions': automatic_captions,\n            'duration': video_duration,\n            'age_limit': 18 if age_gate else 0,\n            'annotations': video_annotations,\n            'webpage_url': proto + '://www.youtube.com/watch?v=%s' % video_id,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'average_rating': float_or_none(video_info.get('avg_rating', [None])[0]),\n            'formats': formats,\n            'is_live': is_live,\n            'start_time': start_time,\n            'end_time': end_time,\n        }",
        "begin_line": 1008,
        "end_line": 1465,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031746031746031746,
            "pseudo_dstar_susp": 0.0029850746268656717,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0029850746268656717,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.add_dash_mpd#1046",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.add_dash_mpd(video_info)",
        "snippet": "        def add_dash_mpd(video_info):\n            dash_mpd = video_info.get('dashmpd')\n            if dash_mpd and dash_mpd[0] not in dash_mpds:\n                dash_mpds.append(dash_mpd[0])",
        "begin_line": 1046,
        "end_line": 1049,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031746031746031746,
            "pseudo_dstar_susp": 0.0029850746268656717,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0029850746268656717,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_initialize#1562",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 1562,
        "end_line": 1563,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002061855670103093,
            "pseudo_dstar_susp": 0.002028397565922921,
            "pseudo_tarantula_susp": 0.0013003901170351106,
            "pseudo_op2_susp": 0.002028397565922921,
            "pseudo_barinel_susp": 0.0013003901170351106
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_mix#1565",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_mix(self, playlist_id)",
        "snippet": "    def _extract_mix(self, playlist_id):\n        # The mixes are generated from a single video\n        # the id of the playlist is just 'RD' + video_id\n        url = 'https://youtube.com/watch?v=%s&list=%s' % (playlist_id[-11:], playlist_id)\n        webpage = self._download_webpage(\n            url, playlist_id, 'Downloading Youtube mix')\n        search_title = lambda class_name: get_element_by_attribute('class', class_name, webpage)\n        title_span = (\n            search_title('playlist-title') or\n            search_title('title long-title') or\n            search_title('title'))\n        title = clean_html(title_span)\n        ids = orderedSet(re.findall(\n            r'''(?xs)data-video-username=\".*?\".*?\n                       href=\"/watch\\?v=([0-9A-Za-z_-]{11})&amp;[^\"]*?list=%s''' % re.escape(playlist_id),\n            webpage))\n        url_results = self._ids_to_results(ids)\n\n        return self.playlist_result(url_results, playlist_id, title)",
        "begin_line": 1565,
        "end_line": 1583,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_playlist#1585",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_playlist(self, playlist_id)",
        "snippet": "    def _extract_playlist(self, playlist_id):\n        url = self._TEMPLATE_URL % playlist_id\n        page = self._download_webpage(url, playlist_id)\n\n        for match in re.findall(r'<div class=\"yt-alert-message\">([^<]+)</div>', page):\n            match = match.strip()\n            # Check if the playlist exists or is private\n            if re.match(r'[^<]*(The|This) playlist (does not exist|is private)[^<]*', match):\n                raise ExtractorError(\n                    'The playlist doesn\\'t exist or is private, use --username or '\n                    '--netrc to access it.',\n                    expected=True)\n            elif re.match(r'[^<]*Invalid parameters[^<]*', match):\n                raise ExtractorError(\n                    'Invalid parameters. Maybe URL is incorrect.',\n                    expected=True)\n            elif re.match(r'[^<]*Choose your language[^<]*', match):\n                continue\n            else:\n                self.report_warning('Youtube gives an alert message: ' + match)\n\n        playlist_title = self._html_search_regex(\n            r'(?s)<h1 class=\"pl-header-title[^\"]*\">\\s*(.*?)\\s*</h1>',\n            page, 'title')\n\n        return self.playlist_result(self._entries(page, playlist_id), playlist_id, playlist_title)",
        "begin_line": 1585,
        "end_line": 1610,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017211703958691911,
            "pseudo_dstar_susp": 0.0016638935108153079,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0016638935108153079,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_extract#1612",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract playlist id\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        playlist_id = mobj.group(1) or mobj.group(2)\n\n        # Check if it's a video-specific URL\n        query_dict = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        if 'v' in query_dict:\n            video_id = query_dict['v'][0]\n            if self._downloader.params.get('noplaylist'):\n                self.to_screen('Downloading just video %s because of --no-playlist' % video_id)\n                return self.url_result(video_id, 'Youtube', video_id=video_id)\n            else:\n                self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))\n\n        if playlist_id.startswith('RD') or playlist_id.startswith('UL'):\n            # Mixes require a custom extraction process\n            return self._extract_mix(playlist_id)\n\n        return self._extract_playlist(playlist_id)",
        "begin_line": 1612,
        "end_line": 1633,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0022675736961451248,
            "pseudo_dstar_susp": 0.002207505518763797,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.002207505518763797,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeChannelIE._real_extract#1661",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeChannelIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        url = self._TEMPLATE_URL % channel_id\n\n        # Channel by page listing is restricted to 35 pages of 30 items, i.e. 1050 videos total (see #5778)\n        # Workaround by extracting as a playlist if managed to obtain channel playlist URL\n        # otherwise fallback on channel by page extraction\n        channel_page = self._download_webpage(\n            url + '?view=57', channel_id,\n            'Downloading channel page', fatal=False)\n        if channel_page is False:\n            channel_playlist_id = False\n        else:\n            channel_playlist_id = self._html_search_meta(\n                'channelId', channel_page, 'channel id', default=None)\n            if not channel_playlist_id:\n                channel_playlist_id = self._search_regex(\n                    r'data-(?:channel-external-|yt)id=\"([^\"]+)\"',\n                    channel_page, 'channel id', default=None)\n        if channel_playlist_id and channel_playlist_id.startswith('UC'):\n            playlist_id = 'UU' + channel_playlist_id[2:]\n            return self.url_result(\n                compat_urlparse.urljoin(url, '/playlist?list=%s' % playlist_id), 'YoutubePlaylist')\n\n        channel_page = self._download_webpage(url, channel_id, 'Downloading page #1')\n        autogenerated = re.search(r'''(?x)\n                class=\"[^\"]*?(?:\n                    channel-header-autogenerated-label|\n                    yt-channel-title-autogenerated\n                )[^\"]*\"''', channel_page) is not None\n\n        if autogenerated:\n            # The videos are contained in a single page\n            # the ajax pages can't be used, they are empty\n            entries = [\n                self.url_result(\n                    video_id, 'Youtube', video_id=video_id,\n                    video_title=video_title)\n                for video_id, video_title in self.extract_videos_from_page(channel_page)]\n            return self.playlist_result(entries, channel_id)\n\n        return self.playlist_result(self._entries(channel_page, channel_id), channel_id)",
        "begin_line": 1661,
        "end_line": 1703,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeUserIE.suitable#1724",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeUserIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeUserIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        # Don't return True if the url can be extracted with other youtube\n        # extractor, the regex would is too permissive and it would match.\n        other_ies = iter(klass for (name, klass) in globals().items() if name.endswith('IE') and klass is not cls)\n        if any(ie.suitable(url) for ie in other_ies):\n            return False\n        else:\n            return super(YoutubeUserIE, cls).suitable(url)",
        "begin_line": 1724,
        "end_line": 1731,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSearchIE._get_n_results#1744",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSearchIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        videos = []\n        limit = n\n\n        for pagenum in itertools.count(1):\n            url_query = {\n                'search_query': query.encode('utf-8'),\n                'page': pagenum,\n                'spf': 'navigate',\n            }\n            url_query.update(self._EXTRA_QUERY_ARGS)\n            result_url = 'https://www.youtube.com/results?' + compat_urllib_parse.urlencode(url_query)\n            data = self._download_json(\n                result_url, video_id='query \"%s\"' % query,\n                note='Downloading page %s' % pagenum,\n                errnote='Unable to download API page')\n            html_content = data[1]['body']['content']\n\n            if 'class=\"search-message' in html_content:\n                raise ExtractorError(\n                    '[youtube] No video results', expected=True)\n\n            new_videos = self._ids_to_results(orderedSet(re.findall(\n                r'href=\"/watch\\?v=(.{11})', html_content)))\n            videos += new_videos\n            if not new_videos or len(videos) > limit:\n                break\n\n        if len(videos) > n:\n            videos = videos[:n]\n        return self.playlist_result(videos, query)",
        "begin_line": 1744,
        "end_line": 1776,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSearchURLIE._real_extract#1798",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSearchURLIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSearchURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        query = compat_urllib_parse_unquote_plus(mobj.group('query'))\n\n        webpage = self._download_webpage(url, query)\n        result_code = self._search_regex(\n            r'(?s)<ol[^>]+class=\"item-section\"(.*?)</ol>', webpage, 'result HTML')\n\n        part_codes = re.findall(\n            r'(?s)<h3[^>]+class=\"[^\"]*yt-lockup-title[^\"]*\"[^>]*>(.*?)</h3>', result_code)\n        entries = []\n        for part_code in part_codes:\n            part_title = self._html_search_regex(\n                [r'(?s)title=\"([^\"]+)\"', r'>([^<]+)</a>'], part_code, 'item title', fatal=False)\n            part_url_snippet = self._html_search_regex(\n                r'(?s)href=\"([^\"]+)\"', part_code, 'item URL')\n            part_url = compat_urlparse.urljoin(\n                'https://www.youtube.com/', part_url_snippet)\n            entries.append({\n                '_type': 'url',\n                'url': part_url,\n                'title': part_title,\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'title': query,\n        }",
        "begin_line": 1798,
        "end_line": 1826,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeShowIE._real_extract#1842",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeShowIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        webpage = self._download_webpage(\n            'https://www.youtube.com/show/%s/playlists' % playlist_id, playlist_id, 'Downloading show webpage')\n        # There's one playlist for each season of the show\n        m_seasons = list(re.finditer(r'href=\"(/playlist\\?list=.*?)\"', webpage))\n        self.to_screen('%s: Found %s seasons' % (playlist_id, len(m_seasons)))\n        entries = [\n            self.url_result(\n                'https://www.youtube.com' + season.group(1), 'YoutubePlaylist')\n            for season in m_seasons\n        ]\n        title = self._og_search_title(webpage, fatal=False)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 1842,
        "end_line": 1862,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor.IE_NAME#1873",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor.IE_NAME(self)",
        "snippet": "    def IE_NAME(self):\n        return 'youtube:%s' % self._FEED_NAME",
        "begin_line": 1873,
        "end_line": 1874,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.00032206119162640903,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_initialize#1876",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 1876,
        "end_line": 1877,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_extract#1879",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page = self._download_webpage(\n            'https://www.youtube.com/feed/%s' % self._FEED_NAME, self._PLAYLIST_TITLE)\n\n        # The extraction process is the same as for playlists, but the regex\n        # for the video ids doesn't contain an index\n        ids = []\n        more_widget_html = content_html = page\n        for page_num in itertools.count(1):\n            matches = re.findall(r'href=\"\\s*/watch\\?v=([0-9A-Za-z_-]{11})', content_html)\n\n            # 'recommended' feed has infinite 'load more' and each new portion spins\n            # the same videos in (sometimes) slightly different order, so we'll check\n            # for unicity and break when portion has no new videos\n            new_ids = filter(lambda video_id: video_id not in ids, orderedSet(matches))\n            if not new_ids:\n                break\n\n            ids.extend(new_ids)\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), self._PLAYLIST_TITLE,\n                'Downloading page #%s' % page_num,\n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            more_widget_html = more['load_more_widget_html']\n\n        return self.playlist_result(\n            self._ids_to_results(ids), playlist_title=self._PLAYLIST_TITLE)",
        "begin_line": 1879,
        "end_line": 1911,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeWatchLaterIE._real_extract#1921",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeWatchLaterIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeWatchLaterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_playlist('WL')",
        "begin_line": 1921,
        "end_line": 1922,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFavouritesIE._real_extract#1931",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFavouritesIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeFavouritesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage('https://www.youtube.com/my_favorites', 'Youtube Favourites videos')\n        playlist_id = self._search_regex(r'list=(.+?)[\"&]', webpage, 'favourites playlist id')\n        return self.url_result(playlist_id, 'YoutubePlaylist')",
        "begin_line": 1931,
        "end_line": 1934,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE._real_extract#1997",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        raise ExtractorError(\n            'Did you forget to quote the URL? Remember that & is a meta '\n            'character in most shells, so you want to put the URL in quotes, '\n            'like  youtube-dl '\n            '\"http://www.youtube.com/watch?feature=foo&v=BaW_jenozKc\" '\n            ' or simply  youtube-dl BaW_jenozKc  .',\n            expected=True)",
        "begin_line": 1997,
        "end_line": 2004,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeTruncatedIDIE._real_extract#2017",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeTruncatedIDIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeTruncatedIDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        raise ExtractorError(\n            'Incomplete YouTube ID %s. URL %s looks truncated.' % (video_id, url),\n            expected=True)",
        "begin_line": 2017,
        "end_line": 2021,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xnxx.XNXXIE._real_extract#21",
        "src_path": "youtube_dl/extractor/xnxx.py",
        "class_name": "youtube_dl.extractor.xnxx.XNXXIE",
        "signature": "youtube_dl.extractor.xnxx.XNXXIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(r'flv_url=(.*?)&amp;',\n                                       webpage, 'video URL')\n        video_url = compat_urllib_parse_unquote(video_url)\n\n        video_title = self._html_search_regex(r'<title>(.*?)\\s+-\\s+XNXX.COM',\n                                              webpage, 'title')\n\n        video_thumbnail = self._search_regex(r'url_bigthumb=(.*?)&amp;',\n                                             webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'ext': 'flv',\n            'thumbnail': video_thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 21,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.azubu.AzubuIE._real_extract#48",
        "src_path": "youtube_dl/extractor/azubu.py",
        "class_name": "youtube_dl.extractor.azubu.AzubuIE",
        "signature": "youtube_dl.extractor.azubu.AzubuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data = self._download_json(\n            'http://www.azubu.tv/api/video/%s' % video_id, video_id)['data']\n\n        title = data['title'].strip()\n        description = data['description']\n        thumbnail = data['thumbnail']\n        view_count = data['view_count']\n        uploader = data['user']['username']\n        uploader_id = data['user']['id']\n\n        stream_params = json.loads(data['stream_params'])\n\n        timestamp = float_or_none(stream_params['creationDate'], 1000)\n        duration = float_or_none(stream_params['length'], 1000)\n\n        renditions = stream_params.get('renditions') or []\n        video = stream_params.get('FLVFullLength') or stream_params.get('videoFullLength')\n        if video:\n            renditions.append(video)\n\n        formats = [{\n            'url': fmt['url'],\n            'width': fmt['frameWidth'],\n            'height': fmt['frameHeight'],\n            'vbr': float_or_none(fmt['encodingRate'], 1000),\n            'filesize': fmt['size'],\n            'vcodec': fmt['videoCodec'],\n            'container': fmt['videoContainer'],\n        } for fmt in renditions if fmt['url']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 48,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.foxnews.FoxNewsIE._real_extract#54",
        "src_path": "youtube_dl/extractor/foxnews.py",
        "class_name": "youtube_dl.extractor.foxnews.FoxNewsIE",
        "signature": "youtube_dl.extractor.foxnews.FoxNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        host = mobj.group('host')\n\n        video = self._download_json(\n            'http://%s/v/feed/video/%s.js?template=fox' % (host, video_id), video_id)\n\n        item = video['channel']['item']\n        title = item['title']\n        description = item['description']\n        timestamp = parse_iso8601(item['dc-date'])\n\n        media_group = item['media-group']\n        duration = None\n        formats = []\n        for media in media_group['media-content']:\n            attributes = media['@attributes']\n            video_url = attributes['url']\n            if video_url.endswith('.f4m'):\n                formats.extend(self._extract_f4m_formats(video_url + '?hdcore=3.4.0&plugin=aasp-3.4.0.132.124', video_id))\n            elif video_url.endswith('.m3u8'):\n                formats.extend(self._extract_m3u8_formats(video_url, video_id, 'flv'))\n            elif not video_url.endswith('.smil'):\n                duration = int_or_none(attributes.get('duration'))\n                formats.append({\n                    'url': video_url,\n                    'format_id': media['media-category']['@attributes']['label'],\n                    'preference': 1,\n                    'vbr': int_or_none(attributes.get('bitrate')),\n                    'filesize': int_or_none(attributes.get('fileSize'))\n                })\n        self._sort_formats(formats)\n\n        media_thumbnail = media_group['media-thumbnail']['@attributes']\n        thumbnails = [{\n            'url': media_thumbnail['url'],\n            'width': int_or_none(media_thumbnail.get('width')),\n            'height': int_or_none(media_thumbnail.get('height')),\n        }] if media_thumbnail else []\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 54,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nytimes.NYTimesBaseIE._extract_video_from_id#12",
        "src_path": "youtube_dl/extractor/nytimes.py",
        "class_name": "youtube_dl.extractor.nytimes.NYTimesBaseIE",
        "signature": "youtube_dl.extractor.nytimes.NYTimesBaseIE._extract_video_from_id(self, video_id)",
        "snippet": "    def _extract_video_from_id(self, video_id):\n        video_data = self._download_json(\n            'http://www.nytimes.com/svc/video/api/v2/video/%s' % video_id,\n            video_id, 'Downloading video JSON')\n\n        title = video_data['headline']\n        description = video_data.get('summary')\n        duration = float_or_none(video_data.get('duration'), 1000)\n\n        uploader = video_data['byline']\n        timestamp = parse_iso8601(video_data['publication_date'][:-8])\n\n        def get_file_size(file_size):\n            if isinstance(file_size, int):\n                return file_size\n            elif isinstance(file_size, dict):\n                return int(file_size.get('value', 0))\n            else:\n                return 0\n\n        formats = [\n            {\n                'url': video['url'],\n                'format_id': video.get('type'),\n                'vcodec': video.get('video_codec'),\n                'width': int_or_none(video.get('width')),\n                'height': int_or_none(video.get('height')),\n                'filesize': get_file_size(video.get('fileSize')),\n            } for video in video_data['renditions']\n        ]\n        self._sort_formats(formats)\n\n        thumbnails = [\n            {\n                'url': 'http://www.nytimes.com/%s' % image['url'],\n                'width': int_or_none(image.get('width')),\n                'height': int_or_none(image.get('height')),\n            } for image in video_data['images']\n        ]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'duration': duration,\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 12,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nytimes.NYTimesIE._real_extract#85",
        "src_path": "youtube_dl/extractor/nytimes.py",
        "class_name": "youtube_dl.extractor.nytimes.NYTimesIE",
        "signature": "youtube_dl.extractor.nytimes.NYTimesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        return self._extract_video_from_id(video_id)",
        "begin_line": 85,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.nytimes.NYTimesArticleIE._real_extract#110",
        "src_path": "youtube_dl/extractor/nytimes.py",
        "class_name": "youtube_dl.extractor.nytimes.NYTimesArticleIE",
        "signature": "youtube_dl.extractor.nytimes.NYTimesArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_id = self._html_search_regex(r'data-videoid=\"(\\d+)\"', webpage, 'video id')\n\n        return self._extract_video_from_id(video_id)",
        "begin_line": 110,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mit.TechTVMITIE._real_extract#30",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.TechTVMITIE",
        "signature": "youtube_dl.extractor.mit.TechTVMITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        raw_page = self._download_webpage(\n            'http://techtv.mit.edu/videos/%s' % video_id, video_id)\n        clean_page = re.compile(r'<!--.*?-->', re.S).sub('', raw_page)\n\n        base_url = self._proto_relative_url(self._search_regex(\n            r'ipadUrl: \\'(.+?cloudfront.net/)', raw_page, 'base url'), 'http:')\n        formats_json = self._search_regex(\n            r'bitrates: (\\[.+?\\])', raw_page, 'video formats')\n        formats_mit = json.loads(formats_json)\n        formats = [\n            {\n                'format_id': f['label'],\n                'url': base_url + f['url'].partition(':')[2],\n                'ext': f['url'].partition(':')[0],\n                'format': f['label'],\n                'width': f['width'],\n                'vbr': f['bitrate'],\n            }\n            for f in formats_mit\n        ]\n\n        title = get_element_by_id('edit-title', clean_page)\n        description = clean_html(get_element_by_id('edit-description', clean_page))\n        thumbnail = self._search_regex(\n            r'playlist:.*?url: \\'(.+?)\\'',\n            raw_page, 'thumbnail', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 30,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mit.MITIE._real_extract#83",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.MITIE",
        "signature": "youtube_dl.extractor.mit.MITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n        embed_url = self._search_regex(\n            r'<iframe .*?src=\"(.+?)\"', webpage, 'embed url')\n        return self.url_result(embed_url, ie='TechTVMIT')",
        "begin_line": 83,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.mit.OCWMITIE._real_extract#124",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.OCWMITIE",
        "signature": "youtube_dl.extractor.mit.OCWMITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        topic = mobj.group('topic')\n\n        webpage = self._download_webpage(url, topic)\n        title = self._html_search_meta('WT.cg_s', webpage)\n        description = self._html_search_meta('Description', webpage)\n\n        # search for call to ocw_embed_chapter_media(container_id, media_url, provider, page_url, image_url, start, stop, captions_file)\n        embed_chapter_media = re.search(r'ocw_embed_chapter_media\\((.+?)\\)', webpage)\n        if embed_chapter_media:\n            metadata = re.sub(r'[\\'\"]', '', embed_chapter_media.group(1))\n            metadata = re.split(r', ?', metadata)\n            yt = metadata[1]\n        else:\n            # search for call to ocw_embed_chapter_media(container_id, media_url, provider, page_url, image_url, captions_file)\n            embed_media = re.search(r'ocw_embed_media\\((.+?)\\)', webpage)\n            if embed_media:\n                metadata = re.sub(r'[\\'\"]', '', embed_media.group(1))\n                metadata = re.split(r', ?', metadata)\n                yt = metadata[1]\n            else:\n                raise ExtractorError('Unable to find embedded YouTube video.')\n        video_id = YoutubeIE.extract_id(yt)\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'url': yt,\n            'ie_key': 'Youtube',\n        }",
        "begin_line": 124,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.googleplus.GooglePlusIE._real_extract#26",
        "src_path": "youtube_dl/extractor/googleplus.py",
        "class_name": "youtube_dl.extractor.googleplus.GooglePlusIE",
        "signature": "youtube_dl.extractor.googleplus.GooglePlusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Step 1, Retrieve post webpage to extract further information\n        webpage = self._download_webpage(url, video_id, 'Downloading entry webpage')\n\n        title = self._og_search_description(webpage).splitlines()[0]\n        upload_date = unified_strdate(self._html_search_regex(\n            r'''(?x)<a.+?class=\"o-U-s\\s[^\"]+\"\\s+style=\"display:\\s*none\"\\s*>\n                    ([0-9]{4}-[0-9]{2}-[0-9]{2})</a>''',\n            webpage, 'upload date', fatal=False, flags=re.VERBOSE))\n        uploader = self._html_search_regex(\n            r'rel=\"author\".*?>(.*?)</a>', webpage, 'uploader', fatal=False)\n\n        # Step 2, Simulate clicking the image box to launch video\n        DOMAIN = 'https://plus.google.com/'\n        video_page = self._search_regex(\n            r'<a href=\"((?:%s)?photos/.*?)\"' % re.escape(DOMAIN),\n            webpage, 'video page URL')\n        if not video_page.startswith(DOMAIN):\n            video_page = DOMAIN + video_page\n\n        webpage = self._download_webpage(video_page, video_id, 'Downloading video page')\n\n        def unicode_escape(s):\n            decoder = codecs.getdecoder('unicode_escape')\n            return re.sub(\n                r'\\\\u[0-9a-fA-F]{4,}',\n                lambda m: decoder(m.group(0))[0],\n                s)\n\n        # Extract video links all sizes\n        formats = [{\n            'url': unicode_escape(video_url),\n            'ext': 'flv',\n            'width': int(width),\n            'height': int(height),\n        } for width, height, video_url in re.findall(\n            r'\\d+,(\\d+),(\\d+),\"(https?://redirector\\.googlevideo\\.com.*?)\"', webpage)]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.drtv.DRTVIE._real_extract#28",
        "src_path": "youtube_dl/extractor/drtv.py",
        "class_name": "youtube_dl.extractor.drtv.DRTVIE",
        "signature": "youtube_dl.extractor.drtv.DRTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        if '>Programmet er ikke l\u00e6ngere tilg\u00e6ngeligt' in webpage:\n            raise ExtractorError(\n                'Video %s is not available' % video_id, expected=True)\n\n        video_id = self._search_regex(\n            r'data-(?:material-identifier|episode-slug)=\"([^\"]+)\"',\n            webpage, 'video id')\n\n        programcard = self._download_json(\n            'http://www.dr.dk/mu/programcard/expanded/%s' % video_id,\n            video_id, 'Downloading video JSON')\n        data = programcard['Data'][0]\n\n        title = data['Title']\n        description = data['Description']\n        timestamp = parse_iso8601(data['CreatedTime'])\n\n        thumbnail = None\n        duration = None\n\n        restricted_to_denmark = False\n\n        formats = []\n        subtitles = {}\n\n        for asset in data['Assets']:\n            if asset['Kind'] == 'Image':\n                thumbnail = asset['Uri']\n            elif asset['Kind'] == 'VideoResource':\n                duration = asset['DurationInMilliseconds'] / 1000.0\n                restricted_to_denmark = asset['RestrictedToDenmark']\n                spoken_subtitles = asset['Target'] == 'SpokenSubtitles'\n                for link in asset['Links']:\n                    uri = link['Uri']\n                    target = link['Target']\n                    format_id = target\n                    preference = None\n                    if spoken_subtitles:\n                        preference = -1\n                        format_id += '-spoken-subtitles'\n                    if target == 'HDS':\n                        formats.extend(self._extract_f4m_formats(\n                            uri + '?hdcore=3.3.0&plugin=aasp-3.3.0.99.43',\n                            video_id, preference, f4m_id=format_id))\n                    elif target == 'HLS':\n                        formats.extend(self._extract_m3u8_formats(\n                            uri, video_id, 'mp4', preference=preference,\n                            m3u8_id=format_id))\n                    else:\n                        bitrate = link.get('Bitrate')\n                        if bitrate:\n                            format_id += '-%s' % bitrate\n                        formats.append({\n                            'url': uri,\n                            'format_id': format_id,\n                            'tbr': bitrate,\n                            'ext': link.get('FileFormat'),\n                        })\n                subtitles_list = asset.get('SubtitlesList')\n                if isinstance(subtitles_list, list):\n                    LANGS = {\n                        'Danish': 'dk',\n                    }\n                    for subs in subtitles_list:\n                        lang = subs['Language']\n                        subtitles[LANGS.get(lang, lang)] = [{'url': subs['Uri'], 'ext': 'vtt'}]\n\n        if not formats and restricted_to_denmark:\n            raise ExtractorError(\n                'Unfortunately, DR is not allowed to show this program outside Denmark.', expected=True)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 28,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.jadorecettepub.JadoreCettePubIE._real_extract#25",
        "src_path": "youtube_dl/extractor/jadorecettepub.py",
        "class_name": "youtube_dl.extractor.jadorecettepub.JadoreCettePubIE",
        "signature": "youtube_dl.extractor.jadorecettepub.JadoreCettePubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._html_search_regex(\n            r'<span style=\"font-size: x-large;\"><b>(.*?)</b></span>',\n            webpage, 'title')\n        description = self._html_search_regex(\n            r'(?s)<div id=\"fb-root\">(.*?)<script>', webpage, 'description',\n            fatal=False)\n        real_url = self._search_regex(\n            r'\\[/postlink\\](.*)endofvid', webpage, 'video URL')\n        video_id = YoutubeIE.extract_id(real_url)\n\n        return {\n            '_type': 'url_transparent',\n            'url': real_url,\n            'id': video_id,\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 25,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.fc2.FC2IE._login#46",
        "src_path": "youtube_dl/extractor/fc2.py",
        "class_name": "youtube_dl.extractor.fc2.FC2IE",
        "signature": "youtube_dl.extractor.fc2.FC2IE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None or password is None:\n            return False\n\n        # Log in\n        login_form_strs = {\n            'email': username,\n            'password': password,\n            'done': 'video',\n            'Submit': ' Login ',\n        }\n\n        login_data = compat_urllib_parse.urlencode(encode_dict(login_form_strs)).encode('utf-8')\n        request = compat_urllib_request.Request(\n            'https://secure.id.fc2.com/index.php?mode=login&switch_language=en', login_data)\n\n        login_results = self._download_webpage(request, None, note='Logging in', errnote='Unable to log in')\n        if 'mode=redirect&login=done' not in login_results:\n            self.report_warning('unable to log in: bad username or password')\n            return False\n\n        # this is also needed\n        login_redir = compat_urllib_request.Request('http://id.fc2.com/?mode=redirect&login=done')\n        self._download_webpage(\n            login_redir, None, note='Login redirect', errnote='Login redirect failed')\n\n        return True",
        "begin_line": 46,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.fc2.FC2IE._real_extract#75",
        "src_path": "youtube_dl/extractor/fc2.py",
        "class_name": "youtube_dl.extractor.fc2.FC2IE",
        "signature": "youtube_dl.extractor.fc2.FC2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        self._login()\n        webpage = self._download_webpage(url, video_id)\n        self._downloader.cookiejar.clear_session_cookies()  # must clear\n        self._login()\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        refer = url.replace('/content/', '/a/content/') if '/a/content/' not in url else url\n\n        mimi = hashlib.md5((video_id + '_gGddgPfeaf_gzyr').encode('utf-8')).hexdigest()\n\n        info_url = (\n            \"http://video.fc2.com/ginfo.php?mimi={1:s}&href={2:s}&v={0:s}&fversion=WIN%2011%2C6%2C602%2C180&from=2&otag=0&upid={0:s}&tk=null&\".\n            format(video_id, mimi, compat_urllib_request.quote(refer, safe=b'').replace('.', '%2E')))\n\n        info_webpage = self._download_webpage(\n            info_url, video_id, note='Downloading info page')\n        info = compat_urlparse.parse_qs(info_webpage)\n\n        if 'err_code' in info:\n            # most of the time we can still download wideo even if err_code is 403 or 602\n            self.report_warning(\n                'Error code was: %s... but still trying' % info['err_code'][0])\n\n        if 'filepath' not in info:\n            raise ExtractorError('Cannot download file. Are you logged in?')\n\n        video_url = info['filepath'][0] + '?mid=' + info['mid'][0]\n        title_info = info.get('title')\n        if title_info:\n            title = title_info[0]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'ext': 'flv',\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 75,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.__init__.gen_extractors#845",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.gen_extractors()",
        "snippet": "def gen_extractors():\n    \"\"\" Return a list of an instance of every supported extractor.\n    The order does matter; the first extractor matched is the one handling the URL.\n    \"\"\"\n    return [klass() for klass in _ALL_CLASSES]",
        "begin_line": 845,
        "end_line": 849,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009242144177449168,
            "pseudo_dstar_susp": 0.0013440860215053765,
            "pseudo_tarantula_susp": 0.0009174311926605505,
            "pseudo_op2_susp": 0.0013440860215053765,
            "pseudo_barinel_susp": 0.0009174311926605505
        }
    },
    {
        "name": "youtube_dl.extractor.__init__.list_extractors#852",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.list_extractors(age_limit)",
        "snippet": "def list_extractors(age_limit):\n    \"\"\"\n    Return a list of extractors that are suitable for the given age,\n    sorted by extractor ID.\n    \"\"\"\n\n    return sorted(\n        filter(lambda ie: ie.is_suitable(age_limit), gen_extractors()),\n        key=lambda ie: ie.IE_NAME.lower())",
        "begin_line": 852,
        "end_line": 860,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.__init__.get_info_extractor#863",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.get_info_extractor(ie_name)",
        "snippet": "def get_info_extractor(ie_name):\n    \"\"\"Returns the info extractor class with the given ie_name\"\"\"\n    return globals()[ie_name + 'IE']",
        "begin_line": 863,
        "end_line": 865,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.xboxclips.XboxClipsIE._real_extract#27",
        "src_path": "youtube_dl/extractor/xboxclips.py",
        "class_name": "youtube_dl.extractor.xboxclips.XboxClipsIE",
        "signature": "youtube_dl.extractor.xboxclips.XboxClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'>(?:Link|Download): <a[^>]+href=\"([^\"]+)\"', webpage, 'video URL')\n        title = self._html_search_regex(\n            r'<title>XboxClips \\| ([^<]+)</title>', webpage, 'title')\n        upload_date = unified_strdate(self._html_search_regex(\n            r'>Recorded: ([^<]+)<', webpage, 'upload date', fatal=False))\n        filesize = parse_filesize(self._html_search_regex(\n            r'>Size: ([^<]+)<', webpage, 'file size', fatal=False))\n        duration = int_or_none(self._html_search_regex(\n            r'>Duration: (\\d+) Seconds<', webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'>Views: (\\d+)<', webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'upload_date': upload_date,\n            'filesize_approx': filesize,\n            'duration': duration,\n            'view_count': view_count,\n        }",
        "begin_line": 27,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.imdb.ImdbIE._real_extract#27",
        "src_path": "youtube_dl/extractor/imdb.py",
        "class_name": "youtube_dl.extractor.imdb.ImdbIE",
        "signature": "youtube_dl.extractor.imdb.ImdbIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage('http://www.imdb.com/video/imdb/vi%s' % video_id, video_id)\n        descr = self._html_search_regex(\n            r'(?s)<span itemprop=\"description\">(.*?)</span>',\n            webpage, 'description', fatal=False)\n        player_url = 'http://www.imdb.com/video/imdb/vi%s/imdb/single' % video_id\n        player_page = self._download_webpage(\n            player_url, video_id, 'Downloading player page')\n        # the player page contains the info for the default format, we have to\n        # fetch other pages for the rest of the formats\n        extra_formats = re.findall(r'href=\"(?P<url>%s.*?)\".*?>(?P<name>.*?)<' % re.escape(player_url), player_page)\n        format_pages = [\n            self._download_webpage(\n                f_url, video_id, 'Downloading info for %s format' % f_name)\n            for f_url, f_name in extra_formats]\n        format_pages.append(player_page)\n\n        quality = qualities(['SD', '480p', '720p'])\n        formats = []\n        for format_page in format_pages:\n            json_data = self._search_regex(\n                r'<script[^>]+class=\"imdb-player-data\"[^>]*?>(.*?)</script>',\n                format_page, 'json data', flags=re.DOTALL)\n            info = json.loads(json_data)\n            format_info = info['videoPlayerObject']['video']\n            f_id = format_info['ffname']\n            formats.append({\n                'format_id': f_id,\n                'url': format_info['videoInfoList'][0]['videoUrl'],\n                'quality': quality(f_id),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': descr,\n            'thumbnail': format_info['slate'],\n        }",
        "begin_line": 27,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.imdb.ImdbListIE._real_extract#83",
        "src_path": "youtube_dl/extractor/imdb.py",
        "class_name": "youtube_dl.extractor.imdb.ImdbListIE",
        "signature": "youtube_dl.extractor.imdb.ImdbListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n        webpage = self._download_webpage(url, list_id)\n        entries = [\n            self.url_result('http://www.imdb.com' + m, 'Imdb')\n            for m in re.findall(r'href=\"(/video/imdb/vi[^\"]+)\"\\s+data-type=\"playlist\"', webpage)]\n\n        list_title = self._html_search_regex(\n            r'<h1 class=\"header\">(.*?)</h1>', webpage, 'list title')\n\n        return self.playlist_result(entries, list_id, list_title)",
        "begin_line": 83,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.ruhd.RUHDIE._real_extract#21",
        "src_path": "youtube_dl/extractor/ruhd.py",
        "class_name": "youtube_dl.extractor.ruhd.RUHDIE",
        "signature": "youtube_dl.extractor.ruhd.RUHDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'<param name=\"src\" value=\"([^\"]+)\"', webpage, 'video url')\n        title = self._html_search_regex(\n            r'<title>([^<]+)&nbsp;&nbsp; RUHD.ru - \u0412\u0438\u0434\u0435\u043e \u0412\u044b\u0441\u043e\u043a\u043e\u0433\u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u21161 \u0432 \u0420\u043e\u0441\u0441\u0438\u0438!</title>',\n            webpage, 'title')\n        description = self._html_search_regex(\n            r'(?s)<div id=\"longdesc\">(.+?)<span id=\"showlink\">',\n            webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'<param name=\"previewImage\" value=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n        if thumbnail:\n            thumbnail = 'http://www.ruhd.ru' + thumbnail\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 21,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.xattrpp.XAttrMetadataError.__init__#20",
        "src_path": "youtube_dl/postprocessor/xattrpp.py",
        "class_name": "youtube_dl.postprocessor.xattrpp.XAttrMetadataError",
        "signature": "youtube_dl.postprocessor.xattrpp.XAttrMetadataError.__init__(self, code=None, msg='Unknown error')",
        "snippet": "    def __init__(self, code=None, msg='Unknown error'):\n        super(XAttrMetadataError, self).__init__(msg)\n        self.code = code\n\n        # Parsing code and msg\n        if (self.code in (errno.ENOSPC, errno.EDQUOT) or\n                'No space left' in self.msg or 'Disk quota excedded' in self.msg):\n            self.reason = 'NO_SPACE'\n        elif self.code == errno.E2BIG or 'Argument list too long' in self.msg:\n            self.reason = 'VALUE_TOO_LONG'\n        else:\n            self.reason = 'NOT_SUPPORTED'",
        "begin_line": 20,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP.run#47",
        "src_path": "youtube_dl/postprocessor/xattrpp.py",
        "class_name": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP",
        "signature": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP.run(self, info)",
        "snippet": "    def run(self, info):\n        \"\"\" Set extended attributes on downloaded file (if xattr support is found). \"\"\"\n\n        # This mess below finds the best xattr tool for the job and creates a\n        # \"write_xattr\" function.\n        try:\n            # try the pyxattr module...\n            import xattr\n\n            # Unicode arguments are not supported in python-pyxattr until\n            # version 0.5.0\n            # See https://github.com/rg3/youtube-dl/issues/5498\n            pyxattr_required_version = '0.5.0'\n            if version_tuple(xattr.__version__) < version_tuple(pyxattr_required_version):\n                self._downloader.report_warning(\n                    'python-pyxattr is detected but is too old. '\n                    'youtube-dl requires %s or above while your version is %s. '\n                    'Falling back to other xattr implementations' % (\n                        pyxattr_required_version, xattr.__version__))\n\n                raise ImportError\n\n            def write_xattr(path, key, value):\n                try:\n                    xattr.set(path, key, value)\n                except EnvironmentError as e:\n                    raise XAttrMetadataError(e.errno, e.strerror)\n\n        except ImportError:\n            if os.name == 'nt':\n                # Write xattrs to NTFS Alternate Data Streams:\n                # http://en.wikipedia.org/wiki/NTFS#Alternate_data_streams_.28ADS.29\n                def write_xattr(path, key, value):\n                    assert ':' not in key\n                    assert os.path.exists(path)\n\n                    ads_fn = path + \":\" + key\n                    try:\n                        with open(ads_fn, \"wb\") as f:\n                            f.write(value)\n                    except EnvironmentError as e:\n                        raise XAttrMetadataError(e.errno, e.strerror)\n            else:\n                user_has_setfattr = check_executable(\"setfattr\", ['--version'])\n                user_has_xattr = check_executable(\"xattr\", ['-h'])\n\n                if user_has_setfattr or user_has_xattr:\n\n                    def write_xattr(path, key, value):\n                        value = value.decode('utf-8')\n                        if user_has_setfattr:\n                            executable = 'setfattr'\n                            opts = ['-n', key, '-v', value]\n                        elif user_has_xattr:\n                            executable = 'xattr'\n                            opts = ['-w', key, value]\n\n                        cmd = ([encodeFilename(executable, True)] +\n                               [encodeArgument(o) for o in opts] +\n                               [encodeFilename(path, True)])\n\n                        try:\n                            p = subprocess.Popen(\n                                cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n                        except EnvironmentError as e:\n                            raise XAttrMetadataError(e.errno, e.strerror)\n                        stdout, stderr = p.communicate()\n                        stderr = stderr.decode('utf-8', 'replace')\n                        if p.returncode != 0:\n                            raise XAttrMetadataError(p.returncode, stderr)\n\n                else:\n                    # On Unix, and can't find pyxattr, setfattr, or xattr.\n                    if sys.platform.startswith('linux'):\n                        self._downloader.report_error(\n                            \"Couldn't find a tool to set the xattrs. \"\n                            \"Install either the python 'pyxattr' or 'xattr' \"\n                            \"modules, or the GNU 'attr' package \"\n                            \"(which contains the 'setfattr' tool).\")\n                    else:\n                        self._downloader.report_error(\n                            \"Couldn't find a tool to set the xattrs. \"\n                            \"Install either the python 'xattr' module, \"\n                            \"or the 'xattr' binary.\")\n\n        # Write the metadata to the file's xattrs\n        self._downloader.to_screen('[metadata] Writing metadata to file\\'s xattrs')\n\n        filename = info['filepath']\n\n        try:\n            xattr_mapping = {\n                'user.xdg.referrer.url': 'webpage_url',\n                # 'user.xdg.comment':            'description',\n                'user.dublincore.title': 'title',\n                'user.dublincore.date': 'upload_date',\n                'user.dublincore.description': 'description',\n                'user.dublincore.contributor': 'uploader',\n                'user.dublincore.format': 'format',\n            }\n\n            for xattrname, infoname in xattr_mapping.items():\n\n                value = info.get(infoname)\n\n                if value:\n                    if infoname == \"upload_date\":\n                        value = hyphenate_date(value)\n\n                    byte_value = value.encode('utf-8')\n                    write_xattr(filename, xattrname, byte_value)\n\n            return [], info\n\n        except XAttrMetadataError as e:\n            if e.reason == 'NO_SPACE':\n                self._downloader.report_warning(\n                    'There\\'s no disk space left or disk quota exceeded. ' +\n                    'Extended attributes are not written.')\n            elif e.reason == 'VALUE_TOO_LONG':\n                self._downloader.report_warning(\n                    'Unable to write extended attributes due to too long values.')\n            else:\n                msg = 'This filesystem doesn\\'t support extended attributes. '\n                if os.name == 'nt':\n                    msg += 'You need to use NTFS.'\n                else:\n                    msg += '(You may have to enable them in your /etc/fstab)'\n                self._downloader.report_error(msg)\n            return [], info",
        "begin_line": 47,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.expotv.ExpoTVIE._real_extract#29",
        "src_path": "youtube_dl/extractor/expotv.py",
        "class_name": "youtube_dl.extractor.expotv.ExpoTVIE",
        "signature": "youtube_dl.extractor.expotv.ExpoTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        player_key = self._search_regex(\n            r'<param name=\"playerKey\" value=\"([^\"]+)\"', webpage, 'player key')\n        config = self._download_json(\n            'http://client.expotv.com/video/config/%s/%s' % (video_id, player_key),\n            video_id, 'Downloading video configuration')\n\n        formats = []\n        for fcfg in config['sources']:\n            media_url = fcfg.get('file')\n            if not media_url:\n                continue\n            if fcfg.get('type') == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    media_url, video_id, 'mp4', entry_protocol='m3u8_native', m3u8_id='hls'))\n            else:\n                formats.append({\n                    'url': media_url,\n                    'height': int_or_none(fcfg.get('height')),\n                    'format_id': fcfg.get('label'),\n                    'ext': self._search_regex(\n                        r'filename=.*\\.([a-z0-9_A-Z]+)&', media_url,\n                        'file extension', default=None) or fcfg.get('type'),\n                })\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = config.get('image')\n        view_count = int_or_none(self._search_regex(\n            r'<h5>Plays: ([0-9]+)</h5>', webpage, 'view counts'))\n        uploader = self._search_regex(\n            r'<div class=\"reviewer\">\\s*<img alt=\"([^\"]+)\"', webpage, 'uploader',\n            fatal=False)\n        upload_date = unified_strdate(self._search_regex(\n            r'<h5>Reviewed on ([0-9/.]+)</h5>', webpage, 'upload date',\n            fatal=False))\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'view_count': view_count,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n        }",
        "begin_line": 29,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.buzzfeed.BuzzFeedIE._real_extract#53",
        "src_path": "youtube_dl/extractor/buzzfeed.py",
        "class_name": "youtube_dl.extractor.buzzfeed.BuzzFeedIE",
        "signature": "youtube_dl.extractor.buzzfeed.BuzzFeedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n\n        all_buckets = re.findall(\n            r'(?s)<div class=\"video-embed[^\"]*\"..*?rel:bf_bucket_data=\\'([^\\']+)\\'',\n            webpage)\n\n        entries = []\n        for bd_json in all_buckets:\n            bd = json.loads(bd_json)\n            video = bd.get('video') or bd.get('progload_video')\n            if not video:\n                continue\n            entries.append(self.url_result(video['url']))\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'entries': entries,\n        }",
        "begin_line": 53,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.thisav.ThisAVIE._real_extract#24",
        "src_path": "youtube_dl/extractor/thisav.py",
        "class_name": "youtube_dl.extractor.thisav.ThisAVIE",
        "signature": "youtube_dl.extractor.thisav.ThisAVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<h1>([^<]*)</h1>', webpage, 'title')\n        video_url = self._html_search_regex(\n            r\"addVariable\\('file','([^']+)'\\);\", webpage, 'video url')\n        uploader = self._html_search_regex(\n            r': <a href=\"http://www.thisav.com/user/[0-9]+/(?:[^\"]+)\">([^<]+)</a>',\n            webpage, 'uploader name', fatal=False)\n        uploader_id = self._html_search_regex(\n            r': <a href=\"http://www.thisav.com/user/[0-9]+/([^\"]+)\">(?:[^<]+)</a>',\n            webpage, 'uploader id', fatal=False)\n        ext = determine_ext(video_url)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'title': title,\n            'ext': ext,\n        }",
        "begin_line": 24,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.helsinki.HelsinkiIE._real_extract#25",
        "src_path": "youtube_dl/extractor/helsinki.py",
        "class_name": "youtube_dl.extractor.helsinki.HelsinkiIE",
        "signature": "youtube_dl.extractor.helsinki.HelsinkiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        params = self._parse_json(self._html_search_regex(\n            r'(?s)jwplayer\\(\"player\"\\).setup\\((\\{.*?\\})\\);',\n            webpage, 'player code'), video_id, transform_source=js_to_json)\n        formats = [{\n            'url': s['file'],\n            'ext': 'mp4',\n        } for s in params['sources']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage).replace('Video: ', ''),\n            'description': self._og_search_description(webpage),\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.beeg.BeegIE._real_extract#28",
        "src_path": "youtube_dl/extractor/beeg.py",
        "class_name": "youtube_dl.extractor.beeg.BeegIE",
        "signature": "youtube_dl.extractor.beeg.BeegIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://beeg.com/api/v1/video/%s' % video_id, video_id)\n\n        formats = []\n        for format_id, video_url in video.items():\n            height = self._search_regex(\n                r'^(\\d+)[pP]$', format_id, 'height', default=None)\n            if not height:\n                continue\n            formats.append({\n                'url': self._proto_relative_url(video_url.replace('{DATA_MARKERS}', ''), 'http:'),\n                'format_id': format_id,\n                'height': int(height),\n            })\n        self._sort_formats(formats)\n\n        title = video['title']\n        video_id = video.get('id') or video_id\n        display_id = video.get('code')\n        description = video.get('desc')\n\n        timestamp = parse_iso8601(video.get('date'), ' ')\n        duration = int_or_none(video.get('duration'))\n\n        tags = [tag.strip() for tag in video['tags'].split(',')] if video.get('tags') else None\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'duration': duration,\n            'tags': tags,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 28,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.cache.Cache.__init__#16",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.__init__(self, ydl)",
        "snippet": "    def __init__(self, ydl):\n        self._ydl = ydl",
        "begin_line": 16,
        "end_line": 17,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004424778761061947,
            "pseudo_dstar_susp": 0.011494252873563218,
            "pseudo_tarantula_susp": 0.0010660980810234541,
            "pseudo_op2_susp": 0.011494252873563218,
            "pseudo_barinel_susp": 0.0010660980810234541
        }
    },
    {
        "name": "youtube_dl.cache.Cache._get_root_dir#19",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache._get_root_dir(self)",
        "snippet": "    def _get_root_dir(self):\n        res = self._ydl.params.get('cachedir')\n        if res is None:\n            cache_root = compat_getenv('XDG_CACHE_HOME', '~/.cache')\n            res = os.path.join(cache_root, 'youtube-dl')\n        return compat_expanduser(res)",
        "begin_line": 19,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.cache.Cache._get_cache_fn#26",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache._get_cache_fn(self, section, key, dtype)",
        "snippet": "    def _get_cache_fn(self, section, key, dtype):\n        assert re.match(r'^[a-zA-Z0-9_.-]+$', section), \\\n            'invalid section %r' % section\n        assert re.match(r'^[a-zA-Z0-9_.-]+$', key), 'invalid key %r' % key\n        return os.path.join(\n            self._get_root_dir(), section, '%s.%s' % (key, dtype))",
        "begin_line": 26,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.cache.Cache.enabled#34",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.enabled(self)",
        "snippet": "    def enabled(self):\n        return self._ydl.params.get('cachedir') is not False",
        "begin_line": 34,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.cache.Cache.store#37",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.store(self, section, key, data, dtype='json')",
        "snippet": "    def store(self, section, key, data, dtype='json'):\n        assert dtype in ('json',)\n\n        if not self.enabled:\n            return\n\n        fn = self._get_cache_fn(section, key, dtype)\n        try:\n            try:\n                os.makedirs(os.path.dirname(fn))\n            except OSError as ose:\n                if ose.errno != errno.EEXIST:\n                    raise\n            write_json_file(data, fn)\n        except Exception:\n            tb = traceback.format_exc()\n            self._ydl.report_warning(\n                'Writing cache to %r failed: %s' % (fn, tb))",
        "begin_line": 37,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.cache.Cache.load#56",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.load(self, section, key, dtype='json', default=None)",
        "snippet": "    def load(self, section, key, dtype='json', default=None):\n        assert dtype in ('json',)\n\n        if not self.enabled:\n            return default\n\n        cache_fn = self._get_cache_fn(section, key, dtype)\n        try:\n            try:\n                with io.open(cache_fn, 'r', encoding='utf-8') as cachef:\n                    return json.load(cachef)\n            except ValueError:\n                try:\n                    file_size = os.path.getsize(cache_fn)\n                except (OSError, IOError) as oe:\n                    file_size = str(oe)\n                self._ydl.report_warning(\n                    'Cache retrieval from %s failed (%s)' % (cache_fn, file_size))\n        except IOError:\n            pass  # No cache available\n\n        return default",
        "begin_line": 56,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.cache.Cache.remove#79",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.remove(self)",
        "snippet": "    def remove(self):\n        if not self.enabled:\n            self._ydl.to_screen('Cache is disabled (Did you combine --no-cache-dir and --rm-cache-dir?)')\n            return\n\n        cachedir = self._get_root_dir()\n        if not any((term in cachedir) for term in ('cache', 'tmp')):\n            raise Exception('Not removing directory %s - this does not look like a cache dir' % cachedir)\n\n        self._ydl.to_screen(\n            'Removing cache dir %s .' % cachedir, skip_eol=True)\n        if os.path.exists(cachedir):\n            self._ydl.to_screen('.', skip_eol=True)\n            shutil.rmtree(cachedir)\n        self._ydl.to_screen('.')",
        "begin_line": 79,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 0.0005659309564233164,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.elpais.ElPaisIE._real_extract#24",
        "src_path": "youtube_dl/extractor/elpais.py",
        "class_name": "youtube_dl.extractor.elpais.ElPaisIE",
        "signature": "youtube_dl.extractor.elpais.ElPaisIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        prefix = self._html_search_regex(\n            r'var url_cache = \"([^\"]+)\";', webpage, 'URL prefix')\n        video_suffix = self._search_regex(\n            r\"URLMediaFile = url_cache \\+ '([^']+)'\", webpage, 'video URL')\n        video_url = prefix + video_suffix\n        thumbnail_suffix = self._search_regex(\n            r\"URLMediaStill = url_cache \\+ '([^']+)'\", webpage, 'thumbnail URL',\n            fatal=False)\n        thumbnail = (\n            None if thumbnail_suffix is None\n            else prefix + thumbnail_suffix)\n        title = self._html_search_regex(\n            '<h2 class=\"entry-header entry-title.*?>(.*?)</h2>',\n            webpage, 'title')\n        date_str = self._search_regex(\n            r'<p class=\"date-header date-int updated\"\\s+title=\"([^\"]+)\">',\n            webpage, 'upload date', fatal=False)\n        upload_date = (None if date_str is None else unified_strdate(date_str))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 24,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.voicerepublic.VoiceRepublicIE._real_extract#37",
        "src_path": "youtube_dl/extractor/voicerepublic.py",
        "class_name": "youtube_dl.extractor.voicerepublic.VoiceRepublicIE",
        "signature": "youtube_dl.extractor.voicerepublic.VoiceRepublicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        req = compat_urllib_request.Request(\n            compat_urlparse.urljoin(url, '/talks/%s' % display_id))\n        # Older versions of Firefox get redirected to an \"upgrade browser\" page\n        req.add_header('User-Agent', 'youtube-dl')\n        webpage = self._download_webpage(req, display_id)\n\n        if '>Queued for processing, please stand by...<' in webpage:\n            raise ExtractorError(\n                'Audio is still queued for processing', expected=True)\n\n        config = self._search_regex(\n            r'(?s)return ({.+?});\\s*\\n', webpage,\n            'data', default=None)\n        data = self._parse_json(config, display_id, fatal=False) if config else None\n        if data:\n            title = data['title']\n            description = data.get('teaser')\n            talk_id = data.get('talk_id') or display_id\n            talk = data['talk']\n            duration = int_or_none(talk.get('duration'))\n            formats = [{\n                'url': compat_urlparse.urljoin(url, talk_url),\n                'format_id': format_id,\n                'ext': determine_ext(talk_url) or format_id,\n                'vcodec': 'none',\n            } for format_id, talk_url in talk['links'].items()]\n        else:\n            title = self._og_search_title(webpage)\n            description = self._html_search_regex(\n                r\"(?s)<div class='talk-teaser'[^>]*>(.+?)</div>\",\n                webpage, 'description', fatal=False)\n            talk_id = self._search_regex(\n                [r\"id='jc-(\\d+)'\", r\"data-shareable-id='(\\d+)'\"],\n                webpage, 'talk id', default=None) or display_id\n            duration = None\n            player = self._search_regex(\n                r\"class='vr-player jp-jplayer'([^>]+)>\", webpage, 'player')\n            formats = [{\n                'url': compat_urlparse.urljoin(url, talk_url),\n                'format_id': format_id,\n                'ext': determine_ext(talk_url) or format_id,\n                'vcodec': 'none',\n            } for format_id, talk_url in re.findall(r\"data-([^=]+)='([^']+)'\", player)]\n        self._sort_formats(formats)\n\n        thumbnail = self._og_search_thumbnail(webpage)\n        view_count = int_or_none(self._search_regex(\n            r\"class='play-count[^']*'>\\s*(\\d+) plays\",\n            webpage, 'play count', fatal=False))\n\n        return {\n            'id': talk_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 37,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.alphaporno.AlphaPornoIE._real_extract#33",
        "src_path": "youtube_dl/extractor/alphaporno.py",
        "class_name": "youtube_dl.extractor.alphaporno.AlphaPornoIE",
        "signature": "youtube_dl.extractor.alphaporno.AlphaPornoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            r\"video_id\\s*:\\s*'([^']+)'\", webpage, 'video id', default=None)\n\n        video_url = self._search_regex(\n            r\"video_url\\s*:\\s*'([^']+)'\", webpage, 'video url')\n        ext = self._html_search_meta(\n            'encodingFormat', webpage, 'ext', default='.mp4')[1:]\n\n        title = self._search_regex(\n            [r'<meta content=\"([^\"]+)\" itemprop=\"description\">',\n             r'class=\"title\" itemprop=\"name\">([^<]+)<'],\n            webpage, 'title')\n        thumbnail = self._html_search_meta('thumbnail', webpage, 'thumbnail')\n        timestamp = parse_iso8601(self._html_search_meta(\n            'uploadDate', webpage, 'upload date'))\n        duration = parse_duration(self._html_search_meta(\n            'duration', webpage, 'duration'))\n        filesize_approx = parse_filesize(self._html_search_meta(\n            'contentSize', webpage, 'file size'))\n        bitrate = int_or_none(self._html_search_meta(\n            'bitrate', webpage, 'bitrate'))\n        categories = self._html_search_meta(\n            'keywords', webpage, 'categories', default='').split(',')\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'ext': ext,\n            'title': title,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'filesize_approx': filesize_approx,\n            'tbr': bitrate,\n            'categories': categories,\n            'age_limit': age_limit,\n        }",
        "begin_line": 33,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.indavideo.IndavideoEmbedIE._real_extract#39",
        "src_path": "youtube_dl/extractor/indavideo.py",
        "class_name": "youtube_dl.extractor.indavideo.IndavideoEmbedIE",
        "signature": "youtube_dl.extractor.indavideo.IndavideoEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://amfphp.indavideo.hu/SYm0json.php/player.playerHandler.getVideoData/%s' % video_id,\n            video_id)['data']\n\n        title = video['title']\n\n        video_urls = video.get('video_files', [])\n        video_file = video.get('video_file')\n        if video:\n            video_urls.append(video_file)\n        video_urls = list(set(video_urls))\n\n        video_prefix = video_urls[0].rsplit('/', 1)[0]\n\n        for flv_file in video.get('flv_files', []):\n            flv_url = '%s/%s' % (video_prefix, flv_file)\n            if flv_url not in video_urls:\n                video_urls.append(flv_url)\n\n        formats = [{\n            'url': video_url,\n            'height': self._search_regex(r'\\.(\\d{3,4})\\.mp4$', video_url, 'height', default=None),\n        } for video_url in video_urls]\n        self._sort_formats(formats)\n\n        timestamp = video.get('date')\n        if timestamp:\n            # upload date is in CEST\n            timestamp = parse_iso8601(timestamp + ' +0200', ' ')\n\n        thumbnails = [{\n            'url': self._proto_relative_url(thumbnail)\n        } for thumbnail in video.get('thumbnails', [])]\n\n        tags = [tag['title'] for tag in video.get('tags', [])]\n\n        return {\n            'id': video.get('id') or video_id,\n            'title': title,\n            'description': video.get('description'),\n            'thumbnails': thumbnails,\n            'uploader': video.get('user_name'),\n            'uploader_id': video.get('user_id'),\n            'timestamp': timestamp,\n            'duration': int_or_none(video.get('length')),\n            'age_limit': parse_age_limit(video.get('age_limit')),\n            'tags': tags,\n            'formats': formats,\n        }",
        "begin_line": 39,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.indavideo.IndavideoIE._real_extract#130",
        "src_path": "youtube_dl/extractor/indavideo.py",
        "class_name": "youtube_dl.extractor.indavideo.IndavideoIE",
        "signature": "youtube_dl.extractor.indavideo.IndavideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n        embed_url = self._search_regex(\n            r'<link[^>]+rel=\"video_src\"[^>]+href=\"(.+?)\"', webpage, 'embed url')\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'IndavideoEmbed',\n            'url': embed_url,\n            'display_id': display_id,\n        }",
        "begin_line": 130,
        "end_line": 142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    },
    {
        "name": "youtube_dl.extractor.spiegeltv.SpiegeltvIE._real_extract#32",
        "src_path": "youtube_dl/extractor/spiegeltv.py",
        "class_name": "youtube_dl.extractor.spiegeltv.SpiegeltvIE",
        "signature": "youtube_dl.extractor.spiegeltv.SpiegeltvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        if '/#/' in url:\n            url = url.replace('/#/', '/')\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<h1.*?>(.*?)</h1>', webpage, 'title')\n\n        apihost = 'http://spiegeltv-ivms2-restapi.s3.amazonaws.com'\n        version_json = self._download_json(\n            '%s/version.json' % apihost, video_id,\n            note='Downloading version information')\n        version_name = version_json['version_name']\n\n        slug_json = self._download_json(\n            '%s/%s/restapi/slugs/%s.json' % (apihost, version_name, video_id),\n            video_id,\n            note='Downloading object information')\n        oid = slug_json['object_id']\n\n        media_json = self._download_json(\n            '%s/%s/restapi/media/%s.json' % (apihost, version_name, oid),\n            video_id, note='Downloading media information')\n        uuid = media_json['uuid']\n        is_wide = media_json['is_wide']\n\n        server_json = self._download_json(\n            'http://spiegeltv-prod-static.s3.amazonaws.com/projectConfigs/projectConfig.json',\n            video_id, note='Downloading server information')\n\n        format = '16x9' if is_wide else '4x3'\n\n        formats = []\n        for streamingserver in server_json['streamingserver']:\n            endpoint = streamingserver.get('endpoint')\n            if not endpoint:\n                continue\n            play_path = 'mp4:%s_spiegeltv_0500_%s.m4v' % (uuid, format)\n            if endpoint.startswith('rtmp'):\n                formats.append({\n                    'url': endpoint,\n                    'format_id': 'rtmp',\n                    'app': compat_urllib_parse_urlparse(endpoint).path[1:],\n                    'play_path': play_path,\n                    'player_path': 'http://prod-static.spiegel.tv/frontend-076.swf',\n                    'ext': 'flv',\n                    'rtmp_live': True,\n                })\n            elif determine_ext(endpoint) == 'm3u8':\n                formats.append({\n                    'url': endpoint.replace('[video]', play_path),\n                    'ext': 'm4v',\n                    'format_id': 'hls',  # Prefer hls since it allows to workaround georestriction\n                    'protocol': 'm3u8',\n                    'preference': 1,\n                    'http_headers': {\n                        'Accept-Encoding': 'deflate',  # gzip causes trouble on the server side\n                    },\n                })\n            else:\n                formats.append({\n                    'url': endpoint,\n                })\n        self._check_formats(formats, video_id)\n\n        thumbnails = []\n        for image in media_json['images']:\n            thumbnails.append({\n                'url': image['url'],\n                'width': image['width'],\n                'height': image['height'],\n            })\n\n        description = media_json['subtitle']\n        duration = float_or_none(media_json.get('duration_in_ms'), scale=1000)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 7.37354372511429e-05,
            "pseudo_dstar_susp": 7.37354372511429e-05,
            "pseudo_tarantula_susp": 7.37354372511429e-05,
            "pseudo_op2_susp": 7.24952878062926e-05,
            "pseudo_barinel_susp": 7.37354372511429e-05
        }
    }
]