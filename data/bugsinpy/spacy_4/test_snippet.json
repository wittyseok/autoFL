[
    {
        "name": "spacy.tests.conftest.pytest_runtest_setup#12",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pytest_runtest_setup(item)",
        "snippet": "def pytest_runtest_setup(item):\n    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)\n\n    for opt in [\"slow\"]:\n        if opt in item.keywords and not getopt(opt):\n            pytest.skip(\"need --%s option to run\" % opt)",
        "begin_line": 12,
        "end_line": 24,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.getopt#13",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.getopt(opt)",
        "snippet": "    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)",
        "begin_line": 13,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tokenizer#31",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tokenizer()",
        "snippet": "def tokenizer():\n    return get_lang_class(\"xx\").Defaults.create_tokenizer()",
        "begin_line": 31,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ar_tokenizer#36",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ar_tokenizer()",
        "snippet": "def ar_tokenizer():\n    return get_lang_class(\"ar\").Defaults.create_tokenizer()",
        "begin_line": 36,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.bn_tokenizer#41",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.bn_tokenizer()",
        "snippet": "def bn_tokenizer():\n    return get_lang_class(\"bn\").Defaults.create_tokenizer()",
        "begin_line": 41,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ca_tokenizer#46",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ca_tokenizer()",
        "snippet": "def ca_tokenizer():\n    return get_lang_class(\"ca\").Defaults.create_tokenizer()",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.da_tokenizer#51",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.da_tokenizer()",
        "snippet": "def da_tokenizer():\n    return get_lang_class(\"da\").Defaults.create_tokenizer()",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.de_tokenizer#56",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.de_tokenizer()",
        "snippet": "def de_tokenizer():\n    return get_lang_class(\"de\").Defaults.create_tokenizer()",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.el_tokenizer#61",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.el_tokenizer()",
        "snippet": "def el_tokenizer():\n    return get_lang_class(\"el\").Defaults.create_tokenizer()",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_tokenizer#66",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_tokenizer()",
        "snippet": "def en_tokenizer():\n    return get_lang_class(\"en\").Defaults.create_tokenizer()",
        "begin_line": 66,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_vocab#71",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_vocab()",
        "snippet": "def en_vocab():\n    return get_lang_class(\"en\").Defaults.create_vocab()",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.es_tokenizer#82",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.es_tokenizer()",
        "snippet": "def es_tokenizer():\n    return get_lang_class(\"es\").Defaults.create_tokenizer()",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fi_tokenizer#87",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fi_tokenizer()",
        "snippet": "def fi_tokenizer():\n    return get_lang_class(\"fi\").Defaults.create_tokenizer()",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fr_tokenizer#92",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fr_tokenizer()",
        "snippet": "def fr_tokenizer():\n    return get_lang_class(\"fr\").Defaults.create_tokenizer()",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ga_tokenizer#97",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ga_tokenizer()",
        "snippet": "def ga_tokenizer():\n    return get_lang_class(\"ga\").Defaults.create_tokenizer()",
        "begin_line": 97,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.he_tokenizer#102",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.he_tokenizer()",
        "snippet": "def he_tokenizer():\n    return get_lang_class(\"he\").Defaults.create_tokenizer()",
        "begin_line": 102,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.hu_tokenizer#112",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.hu_tokenizer()",
        "snippet": "def hu_tokenizer():\n    return get_lang_class(\"hu\").Defaults.create_tokenizer()",
        "begin_line": 112,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.id_tokenizer#117",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.id_tokenizer()",
        "snippet": "def id_tokenizer():\n    return get_lang_class(\"id\").Defaults.create_tokenizer()",
        "begin_line": 117,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.it_tokenizer#122",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.it_tokenizer()",
        "snippet": "def it_tokenizer():\n    return get_lang_class(\"it\").Defaults.create_tokenizer()",
        "begin_line": 122,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.lb_tokenizer#139",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.lb_tokenizer()",
        "snippet": "def lb_tokenizer():\n    return get_lang_class(\"lb\").Defaults.create_tokenizer()",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.lt_tokenizer#144",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.lt_tokenizer()",
        "snippet": "def lt_tokenizer():\n    return get_lang_class(\"lt\").Defaults.create_tokenizer()",
        "begin_line": 144,
        "end_line": 145,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nb_tokenizer#149",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nb_tokenizer()",
        "snippet": "def nb_tokenizer():\n    return get_lang_class(\"nb\").Defaults.create_tokenizer()",
        "begin_line": 149,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nl_tokenizer#154",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nl_tokenizer()",
        "snippet": "def nl_tokenizer():\n    return get_lang_class(\"nl\").Defaults.create_tokenizer()",
        "begin_line": 154,
        "end_line": 155,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.pl_tokenizer#159",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pl_tokenizer()",
        "snippet": "def pl_tokenizer():\n    return get_lang_class(\"pl\").Defaults.create_tokenizer()",
        "begin_line": 159,
        "end_line": 160,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ro_tokenizer#169",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ro_tokenizer()",
        "snippet": "def ro_tokenizer():\n    return get_lang_class(\"ro\").Defaults.create_tokenizer()",
        "begin_line": 169,
        "end_line": 170,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sr_tokenizer#186",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sr_tokenizer()",
        "snippet": "def sr_tokenizer():\n    return get_lang_class(\"sr\").Defaults.create_tokenizer()",
        "begin_line": 186,
        "end_line": 187,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sv_tokenizer#191",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sv_tokenizer()",
        "snippet": "def sv_tokenizer():\n    return get_lang_class(\"sv\").Defaults.create_tokenizer()",
        "begin_line": 191,
        "end_line": 192,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tt_tokenizer#207",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tt_tokenizer()",
        "snippet": "def tt_tokenizer():\n    return get_lang_class(\"tt\").Defaults.create_tokenizer()",
        "begin_line": 207,
        "end_line": 208,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ur_tokenizer#219",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ur_tokenizer()",
        "snippet": "def ur_tokenizer():\n    return get_lang_class(\"ur\").Defaults.create_tokenizer()",
        "begin_line": 219,
        "end_line": 220,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.yo_tokenizer#224",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.yo_tokenizer()",
        "snippet": "def yo_tokenizer():\n    return get_lang_class(\"yo\").Defaults.create_tokenizer()",
        "begin_line": 224,
        "end_line": 225,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.regression.test_issue4665.test_issue4665#25",
        "src_path": "spacy/tests/regression/test_issue4665.py",
        "class_name": "spacy.tests.regression.test_issue4665",
        "signature": "spacy.tests.regression.test_issue4665.test_issue4665()",
        "snippet": "def test_issue4665():\n    \"\"\"\n    conllu2json should not raise an exception if the HEAD column contains an\n    underscore\n    \"\"\"\n\n    conllu2json(input_data)",
        "begin_line": 25,
        "end_line": 31,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.make_tempdir#23",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.make_tempdir()",
        "snippet": "def make_tempdir():\n    d = Path(tempfile.mkdtemp())\n    yield d\n    shutil.rmtree(path2str(d))",
        "begin_line": 23,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_doc#29",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None)",
        "snippet": "def get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None):\n    \"\"\"Create Doc object from given vocab, words and annotations.\"\"\"\n    pos = pos or [\"\"] * len(words)\n    tags = tags or [\"\"] * len(words)\n    heads = heads or [0] * len(words)\n    deps = deps or [\"\"] * len(words)\n    for value in deps + tags + pos:\n        vocab.strings.add(value)\n\n    doc = Doc(vocab, words=words)\n    attrs = doc.to_array([POS, HEAD, DEP])\n    for i, (p, head, dep) in enumerate(zip(pos, heads, deps)):\n        attrs[i, 0] = doc.vocab.strings[p]\n        attrs[i, 1] = head\n        attrs[i, 2] = doc.vocab.strings[dep]\n    doc.from_array([POS, HEAD, DEP], attrs)\n    if ents:\n        doc.ents = [\n            Span(doc, start, end, label=doc.vocab.strings[label])\n            for start, end, label in ents\n        ]\n    if tags:\n        for token in doc:\n            token.tag_ = tags[token.i]\n    return doc",
        "begin_line": 29,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.add_vecs_to_vocab#68",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.add_vecs_to_vocab(vocab, vectors)",
        "snippet": "def add_vecs_to_vocab(vocab, vectors):\n    \"\"\"Add list of vector tuples to given vocab. All vectors need to have the\n    same length. Format: [(\"text\", [1, 2, 3])]\"\"\"\n    length = len(vectors[0][1])\n    vocab.reset_vectors(width=length)\n    for word, vec in vectors:\n        vocab.set_vector(word, vector=vec)\n    return vocab",
        "begin_line": 68,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_cosine#78",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_cosine(vec1, vec2)",
        "snippet": "def get_cosine(vec1, vec2):\n    \"\"\"Get cosine for two given vectors\"\"\"\n    return numpy.dot(vec1, vec2) / (numpy.linalg.norm(vec1) * numpy.linalg.norm(vec2))",
        "begin_line": 78,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.assert_docs_equal#83",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.assert_docs_equal(doc1, doc2)",
        "snippet": "def assert_docs_equal(doc1, doc2):\n    \"\"\"Compare two Doc objects and assert that they're equal. Tests for tokens,\n    tags, dependencies and entities.\"\"\"\n    assert [t.orth for t in doc1] == [t.orth for t in doc2]\n\n    assert [t.pos for t in doc1] == [t.pos for t in doc2]\n    assert [t.tag for t in doc1] == [t.tag for t in doc2]\n\n    assert [t.head.i for t in doc1] == [t.head.i for t in doc2]\n    assert [t.dep for t in doc1] == [t.dep for t in doc2]\n    if doc1.is_parsed and doc2.is_parsed:\n        assert [s for s in doc1.sents] == [s for s in doc2.sents]\n\n    assert [t.ent_type for t in doc1] == [t.ent_type for t in doc2]\n    assert [t.ent_iob for t in doc1] == [t.ent_iob for t in doc2]\n    assert [ent for ent in doc1.ents] == [ent for ent in doc2.ents]",
        "begin_line": 83,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    }
]