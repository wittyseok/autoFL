[
    {
        "name": "youtube_dl.extractor.nytimes.NYTimesBaseIE._extract_video_from_id#12",
        "src_path": "youtube_dl/extractor/nytimes.py",
        "class_name": "youtube_dl.extractor.nytimes.NYTimesBaseIE",
        "signature": "youtube_dl.extractor.nytimes.NYTimesBaseIE._extract_video_from_id(self, video_id)",
        "snippet": "    def _extract_video_from_id(self, video_id):\n        video_data = self._download_json(\n            'http://www.nytimes.com/svc/video/api/v2/video/%s' % video_id,\n            video_id, 'Downloading video JSON')\n\n        title = video_data['headline']\n        description = video_data.get('summary')\n        duration = float_or_none(video_data.get('duration'), 1000)\n\n        uploader = video_data['byline']\n        timestamp = parse_iso8601(video_data['publication_date'][:-8])\n\n        def get_file_size(file_size):\n            if isinstance(file_size, int):\n                return file_size\n            elif isinstance(file_size, dict):\n                return int(file_size.get('value', 0))\n            else:\n                return 0\n\n        formats = [\n            {\n                'url': video['url'],\n                'format_id': video.get('type'),\n                'vcodec': video.get('video_codec'),\n                'width': int_or_none(video.get('width')),\n                'height': int_or_none(video.get('height')),\n                'filesize': get_file_size(video.get('fileSize')),\n            } for video in video_data['renditions']\n        ]\n        self._sort_formats(formats)\n\n        thumbnails = [\n            {\n                'url': 'http://www.nytimes.com/%s' % image['url'],\n                'width': int_or_none(image.get('width')),\n                'height': int_or_none(image.get('height')),\n            } for image in video_data['images']\n        ]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'duration': duration,\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 12,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youporn.YouPornIE._real_extract#38",
        "src_path": "youtube_dl/extractor/youporn.py",
        "class_name": "youtube_dl.extractor.youporn.YouPornIE",
        "signature": "youtube_dl.extractor.youporn.YouPornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = mobj.group('proto') + 'www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n        age_limit = self._rta_search(webpage)\n\n        # Get JSON parameters\n        json_params = self._search_regex(\n            [r'videoJa?son\\s*=\\s*({.+})',\n             r'var\\s+currentVideo\\s*=\\s*new\\s+Video\\((.+?)\\)[,;]'],\n            webpage, 'JSON parameters')\n        try:\n            params = json.loads(json_params)\n        except ValueError:\n            raise ExtractorError('Invalid JSON')\n\n        self.report_extraction(video_id)\n        try:\n            video_title = params['title']\n            upload_date = unified_strdate(params['release_date_f'])\n            video_description = params['description']\n            video_uploader = params['submitted_by']\n            thumbnail = params['thumbnails'][0]['image']\n        except KeyError:\n            raise ExtractorError('Missing JSON parameter: ' + sys.exc_info()[1])\n\n        # Get all of the links from the page\n        DOWNLOAD_LIST_RE = r'(?s)<ul class=\"downloadList\">(?P<download_list>.*?)</ul>'\n        download_list_html = self._search_regex(DOWNLOAD_LIST_RE,\n                                                webpage, 'download list').strip()\n        LINK_RE = r'<a href=\"([^\"]+)\">'\n        links = re.findall(LINK_RE, download_list_html)\n\n        # Get all encrypted links\n        encrypted_links = re.findall(r'var encryptedQuality[0-9]{3}URL = \\'([a-zA-Z0-9+/]+={0,2})\\';', webpage)\n        for encrypted_link in encrypted_links:\n            link = aes_decrypt_text(encrypted_link, video_title, 32).decode('utf-8')\n            links.append(link)\n\n        formats = []\n        for link in links:\n            # A link looks like this:\n            # http://cdn1.download.youporn.phncdn.com/201210/31/8004515/480p_370k_8004515/YouPorn%20-%20Nubile%20Films%20The%20Pillow%20Fight.mp4?nvb=20121113051249&nva=20121114051249&ir=1200&sr=1200&hash=014b882080310e95fb6a0\n            # A path looks like this:\n            # /201210/31/8004515/480p_370k_8004515/YouPorn%20-%20Nubile%20Films%20The%20Pillow%20Fight.mp4\n            video_url = unescapeHTML(link)\n            path = compat_urllib_parse_urlparse(video_url).path\n            format_parts = path.split('/')[4].split('_')[:2]\n\n            dn = compat_urllib_parse_urlparse(video_url).netloc.partition('.')[0]\n\n            resolution = format_parts[0]\n            height = int(resolution[:-len('p')])\n            bitrate = int(format_parts[1][:-len('k')])\n            format = '-'.join(format_parts) + '-' + dn\n\n            formats.append({\n                'url': video_url,\n                'format': format,\n                'format_id': format,\n                'height': height,\n                'tbr': bitrate,\n                'resolution': resolution,\n            })\n\n        self._sort_formats(formats)\n\n        if not formats:\n            raise ExtractorError('ERROR: no known formats available for video')\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'upload_date': upload_date,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'description': video_description,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 38,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.__init__#55",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.__init__(self, ydl, params)",
        "snippet": "    def __init__(self, ydl, params):\n        \"\"\"Create a FileDownloader object with the given options.\"\"\"\n        self.ydl = ydl\n        self._progress_hooks = []\n        self.params = params\n        self.add_progress_hook(self.report_progress)",
        "begin_line": 55,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001141552511415525,
            "pseudo_dstar_susp": 0.0026455026455026454,
            "pseudo_tarantula_susp": 0.0010152284263959391,
            "pseudo_op2_susp": 0.0026455026455026454,
            "pseudo_barinel_susp": 0.0010152284263959391
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_seconds#63",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_seconds(seconds)",
        "snippet": "    def format_seconds(seconds):\n        (mins, secs) = divmod(seconds, 60)\n        (hours, mins) = divmod(mins, 60)\n        if hours > 99:\n            return '--:--:--'\n        if hours == 0:\n            return '%02d:%02d' % (mins, secs)\n        else:\n            return '%02d:%02d:%02d' % (hours, mins, secs)",
        "begin_line": 63,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009970089730807576,
            "pseudo_dstar_susp": 0.0016,
            "pseudo_tarantula_susp": 0.0010504201680672268,
            "pseudo_op2_susp": 0.0016,
            "pseudo_barinel_susp": 0.0010515247108307045
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_percent#80",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_percent(percent)",
        "snippet": "    def format_percent(percent):\n        if percent is None:\n            return '---.-%'\n        return '%6s' % ('%3.1f%%' % percent)",
        "begin_line": 80,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009099181073703367,
            "pseudo_dstar_susp": 0.0011961722488038277,
            "pseudo_tarantula_susp": 0.001034126163391934,
            "pseudo_op2_susp": 0.0011961722488038277,
            "pseudo_barinel_susp": 0.001034126163391934
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_eta#86",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_eta(start, now, total, current)",
        "snippet": "    def calc_eta(start, now, total, current):\n        if total is None:\n            return None\n        if now is None:\n            now = time.time()\n        dif = now - start\n        if current == 0 or dif < 0.001:  # One millisecond\n            return None\n        rate = float(current) / dif\n        return int((float(total) - float(current)) / rate)",
        "begin_line": 86,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009699321047526673,
            "pseudo_dstar_susp": 0.0012077294685990338,
            "pseudo_tarantula_susp": 0.0011614401858304297,
            "pseudo_op2_susp": 0.0012077294685990338,
            "pseudo_barinel_susp": 0.0011614401858304297
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_eta#98",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_eta(eta)",
        "snippet": "    def format_eta(eta):\n        if eta is None:\n            return '--:--'\n        return FileDownloader.format_seconds(eta)",
        "begin_line": 98,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.002652519893899204,
            "pseudo_tarantula_susp": 0.001017293997965412,
            "pseudo_op2_susp": 0.002652519893899204,
            "pseudo_barinel_susp": 0.001017293997965412
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_speed#104",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_speed(start, now, bytes)",
        "snippet": "    def calc_speed(start, now, bytes):\n        dif = now - start\n        if bytes == 0 or dif < 0.001:  # One millisecond\n            return None\n        return float(bytes) / dif",
        "begin_line": 104,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00039635354736424893,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.best_block_size#117",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.best_block_size(elapsed_time, bytes)",
        "snippet": "    def best_block_size(elapsed_time, bytes):\n        new_min = max(bytes / 2.0, 1.0)\n        new_max = min(max(bytes * 2.0, 1.0), 4194304)  # Do not surpass 4 MB\n        if elapsed_time < 0.001:\n            return int(new_max)\n        rate = bytes / elapsed_time\n        if rate > new_max:\n            return int(new_max)\n        if rate < new_min:\n            return int(new_min)\n        return int(rate)",
        "begin_line": 117,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_screen#139",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_screen(self, *args, **kargs)",
        "snippet": "    def to_screen(self, *args, **kargs):\n        self.ydl.to_screen(*args, **kargs)",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_console_title#145",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_console_title(self, message)",
        "snippet": "    def to_console_title(self, message):\n        self.ydl.to_console_title(message)",
        "begin_line": 145,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007763975155279503,
            "pseudo_dstar_susp": 0.0025,
            "pseudo_tarantula_susp": 0.0007733952049497294,
            "pseudo_op2_susp": 0.0025,
            "pseudo_barinel_susp": 0.0007733952049497294
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.slow_down#157",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.slow_down(self, start_time, now, byte_counter)",
        "snippet": "    def slow_down(self, start_time, now, byte_counter):\n        \"\"\"Sleep if the download speed is over the rate limit.\"\"\"\n        rate_limit = self.params.get('ratelimit', None)\n        if rate_limit is None or byte_counter == 0:\n            return\n        if now is None:\n            now = time.time()\n        elapsed = now - start_time\n        if elapsed <= 0.0:\n            return\n        speed = float(byte_counter) / elapsed\n        if speed > rate_limit:\n            time.sleep(max((byte_counter // rate_limit) - elapsed, 0))",
        "begin_line": 157,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008771929824561404,
            "pseudo_dstar_susp": 0.0011947431302270011,
            "pseudo_tarantula_susp": 0.00102880658436214,
            "pseudo_op2_susp": 0.0011947431302270011,
            "pseudo_barinel_susp": 0.00102880658436214
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.temp_name#171",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.temp_name(self, filename)",
        "snippet": "    def temp_name(self, filename):\n        \"\"\"Returns a temporary filename for the given filename.\"\"\"\n        if self.params.get('nopart', False) or filename == '-' or \\\n                (os.path.exists(encodeFilename(filename)) and not os.path.isfile(encodeFilename(filename))):\n            return filename\n        return filename + '.part'",
        "begin_line": 171,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008305647840531562,
            "pseudo_dstar_susp": 0.0011876484560570072,
            "pseudo_tarantula_susp": 0.000998003992015968,
            "pseudo_op2_susp": 0.0011876484560570072,
            "pseudo_barinel_susp": 0.000998003992015968
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.undo_temp_name#178",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.undo_temp_name(self, filename)",
        "snippet": "    def undo_temp_name(self, filename):\n        if filename.endswith('.part'):\n            return filename[:-len('.part')]\n        return filename",
        "begin_line": 178,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013227513227513227,
            "pseudo_dstar_susp": 0.0023752969121140144,
            "pseudo_tarantula_susp": 0.001215066828675577,
            "pseudo_op2_susp": 0.0023752969121140144,
            "pseudo_barinel_susp": 0.001215066828675577
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.try_rename#183",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.try_rename(self, old_filename, new_filename)",
        "snippet": "    def try_rename(self, old_filename, new_filename):\n        try:\n            if old_filename == new_filename:\n                return\n            os.rename(encodeFilename(old_filename), encodeFilename(new_filename))\n        except (IOError, OSError) as err:\n            self.report_error('unable to rename file: %s' % compat_str(err))",
        "begin_line": 183,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001326259946949602,
            "pseudo_dstar_susp": 0.0026666666666666666,
            "pseudo_tarantula_susp": 0.0010672358591248667,
            "pseudo_op2_susp": 0.0026666666666666666,
            "pseudo_barinel_susp": 0.0010672358591248667
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.try_utime#191",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.try_utime(self, filename, last_modified_hdr)",
        "snippet": "    def try_utime(self, filename, last_modified_hdr):\n        \"\"\"Try to set the last-modified time of the given file.\"\"\"\n        if last_modified_hdr is None:\n            return\n        if not os.path.isfile(encodeFilename(filename)):\n            return\n        timestr = last_modified_hdr\n        if timestr is None:\n            return\n        filetime = timeconvert(timestr)\n        if filetime is None:\n            return filetime\n        # Ignore obviously invalid dates\n        if filetime == 0:\n            return\n        try:\n            os.utime(filename, (time.time(), filetime))\n        except Exception:\n            pass\n        return filetime",
        "begin_line": 191,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.010101010101010102,
            "pseudo_dstar_susp": 0.002777777777777778,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.002777777777777778,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_destination#212",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_destination(self, filename)",
        "snippet": "    def report_destination(self, filename):\n        \"\"\"Report destination filename.\"\"\"\n        self.to_screen('[download] Destination: ' + filename)",
        "begin_line": 212,
        "end_line": 214,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001002004008016032,
            "pseudo_dstar_susp": 0.0012106537530266344,
            "pseudo_tarantula_susp": 0.0012484394506866417,
            "pseudo_op2_susp": 0.0012106537530266344,
            "pseudo_barinel_susp": 0.0012484394506866417
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._report_progress_status#216",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._report_progress_status(self, msg, is_last_line=False)",
        "snippet": "    def _report_progress_status(self, msg, is_last_line=False):\n        fullmsg = '[download] ' + msg\n        if self.params.get('progress_with_newline', False):\n            self.to_screen(fullmsg)\n        else:\n            if os.name == 'nt':\n                prev_len = getattr(self, '_report_progress_prev_line_length',\n                                   0)\n                if prev_len > len(fullmsg):\n                    fullmsg += ' ' * (prev_len - len(fullmsg))\n                self._report_progress_prev_line_length = len(fullmsg)\n                clear_line = '\\r'\n            else:\n                clear_line = ('\\r\\x1b[K' if sys.stderr.isatty() else '\\r')\n            self.to_screen(clear_line + fullmsg, skip_eol=not is_last_line)\n        self.to_console_title('youtube-dl ' + msg)",
        "begin_line": 216,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001364256480218281,
            "pseudo_dstar_susp": 0.002380952380952381,
            "pseudo_tarantula_susp": 0.0012254901960784314,
            "pseudo_op2_susp": 0.002380952380952381,
            "pseudo_barinel_susp": 0.0012285012285012285
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_progress#233",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_progress(self, s)",
        "snippet": "    def report_progress(self, s):\n        if s['status'] == 'finished':\n            if self.params.get('noprogress', False):\n                self.to_screen('[download] Download completed')\n            else:\n                s['_total_bytes_str'] = format_bytes(s['total_bytes'])\n                if s.get('elapsed') is not None:\n                    s['_elapsed_str'] = self.format_seconds(s['elapsed'])\n                    msg_template = '100%% of %(_total_bytes_str)s in %(_elapsed_str)s'\n                else:\n                    msg_template = '100%% of %(_total_bytes_str)s'\n                self._report_progress_status(\n                    msg_template % s, is_last_line=True)\n\n        if self.params.get('noprogress'):\n            return\n\n        if s['status'] != 'downloading':\n            return\n\n        if s.get('eta') is not None:\n            s['_eta_str'] = self.format_eta(s['eta'])\n        else:\n            s['_eta_str'] = 'Unknown ETA'\n\n        if s.get('total_bytes') and s.get('downloaded_bytes') is not None:\n            s['_percent_str'] = self.format_percent(100 * s['downloaded_bytes'] / s['total_bytes'])\n        elif s.get('total_bytes_estimate') and s.get('downloaded_bytes') is not None:\n            s['_percent_str'] = self.format_percent(100 * s['downloaded_bytes'] / s['total_bytes_estimate'])\n        else:\n            if s.get('downloaded_bytes') == 0:\n                s['_percent_str'] = self.format_percent(0)\n            else:\n                s['_percent_str'] = 'Unknown %'\n\n        if s.get('speed') is not None:\n            s['_speed_str'] = self.format_speed(s['speed'])\n        else:\n            s['_speed_str'] = 'Unknown speed'\n\n        if s.get('total_bytes') is not None:\n            s['_total_bytes_str'] = format_bytes(s['total_bytes'])\n            msg_template = '%(_percent_str)s of %(_total_bytes_str)s at %(_speed_str)s ETA %(_eta_str)s'\n        elif s.get('total_bytes_estimate') is not None:\n            s['_total_bytes_estimate_str'] = format_bytes(s['total_bytes_estimate'])\n            msg_template = '%(_percent_str)s of ~%(_total_bytes_estimate_str)s at %(_speed_str)s ETA %(_eta_str)s'\n        else:\n            if s.get('downloaded_bytes') is not None:\n                s['_downloaded_bytes_str'] = format_bytes(s['downloaded_bytes'])\n                if s.get('elapsed'):\n                    s['_elapsed_str'] = self.format_seconds(s['elapsed'])\n                    msg_template = '%(_downloaded_bytes_str)s at %(_speed_str)s (%(_elapsed_str)s)'\n                else:\n                    msg_template = '%(_downloaded_bytes_str)s at %(_speed_str)s'\n            else:\n                msg_template = '%(_percent_str)s % at %(_speed_str)s ETA %(_eta_str)s'\n\n        self._report_progress_status(msg_template % s)",
        "begin_line": 233,
        "end_line": 290,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.download#311",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.download(self, filename, info_dict)",
        "snippet": "    def download(self, filename, info_dict):\n        \"\"\"Download to a filename using the info from info_dict\n        Return True on success and False otherwise\n        \"\"\"\n\n        nooverwrites_and_exists = (\n            self.params.get('nooverwrites', False) and\n            os.path.exists(encodeFilename(filename))\n        )\n\n        continuedl_and_exists = (\n            self.params.get('continuedl', True) and\n            os.path.isfile(encodeFilename(filename)) and\n            not self.params.get('nopart', False)\n        )\n\n        # Check file already present\n        if filename != '-' and nooverwrites_and_exists or continuedl_and_exists:\n            self.report_file_already_downloaded(filename)\n            self._hook_progress({\n                'filename': filename,\n                'status': 'finished',\n                'total_bytes': os.path.getsize(encodeFilename(filename)),\n            })\n            return True\n\n        sleep_interval = self.params.get('sleep_interval')\n        if sleep_interval:\n            self.to_screen('[download] Sleeping %s seconds...' % sleep_interval)\n            time.sleep(sleep_interval)\n\n        return self.real_download(filename, info_dict)",
        "begin_line": 311,
        "end_line": 342,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014326647564469914,
            "pseudo_dstar_susp": 0.0013404825737265416,
            "pseudo_tarantula_susp": 0.001692047377326565,
            "pseudo_op2_susp": 0.0013404825737265416,
            "pseudo_barinel_susp": 0.001692047377326565
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._hook_progress#348",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._hook_progress(self, status)",
        "snippet": "    def _hook_progress(self, status):\n        for ph in self._progress_hooks:\n            ph(status)",
        "begin_line": 348,
        "end_line": 350,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0014124293785310734,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.0014124293785310734,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.add_progress_hook#352",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.add_progress_hook(self, ph)",
        "snippet": "    def add_progress_hook(self, ph):\n        # See YoutubeDl.py (search for progress_hooks) for a description of\n        # this interface\n        self._progress_hooks.append(ph)",
        "begin_line": 352,
        "end_line": 355,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.0008904719501335708,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.0008904719501335708,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.extractor.defense.DefenseGouvFrIE._real_extract#20",
        "src_path": "youtube_dl/extractor/defense.py",
        "class_name": "youtube_dl.extractor.defense.DefenseGouvFrIE",
        "signature": "youtube_dl.extractor.defense.DefenseGouvFrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = self._match_id(url)\n        webpage = self._download_webpage(url, title)\n\n        video_id = self._search_regex(\n            r\"flashvars.pvg_id=\\\"(\\d+)\\\";\",\n            webpage, 'ID')\n\n        json_url = (\n            'http://static.videos.gouv.fr/brightcovehub/export/json/%s' %\n            video_id)\n        info = self._download_json(json_url, title, 'Downloading JSON config')\n        video_url = info['renditions'][0]['url']\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'url': video_url,\n            'title': title,\n        }",
        "begin_line": 20,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025581990278843696,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__init__#276",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__init__(self, params=None, auto_init=True)",
        "snippet": "    def __init__(self, params=None, auto_init=True):\n        \"\"\"Create a FileDownloader object with the given options.\"\"\"\n        if params is None:\n            params = {}\n        self._ies = []\n        self._ies_instances = {}\n        self._pps = []\n        self._progress_hooks = []\n        self._download_retcode = 0\n        self._num_downloads = 0\n        self._screen_file = [sys.stdout, sys.stderr][params.get('logtostderr', False)]\n        self._err_file = sys.stderr\n        self.params = params\n        self.cache = Cache(self)\n\n        if params.get('bidi_workaround', False):\n            try:\n                import pty\n                master, slave = pty.openpty()\n                width = compat_get_terminal_size().columns\n                if width is None:\n                    width_args = []\n                else:\n                    width_args = ['-w', str(width)]\n                sp_kwargs = dict(\n                    stdin=subprocess.PIPE,\n                    stdout=slave,\n                    stderr=self._err_file)\n                try:\n                    self._output_process = subprocess.Popen(\n                        ['bidiv'] + width_args, **sp_kwargs\n                    )\n                except OSError:\n                    self._output_process = subprocess.Popen(\n                        ['fribidi', '-c', 'UTF-8'] + width_args, **sp_kwargs)\n                self._output_channel = os.fdopen(master, 'rb')\n            except OSError as ose:\n                if ose.errno == 2:\n                    self.report_warning('Could not find fribidi executable, ignoring --bidi-workaround . Make sure that  fribidi  is an executable file in one of the directories in your $PATH.')\n                else:\n                    raise\n\n        if (sys.version_info >= (3,) and sys.platform != 'win32' and\n                sys.getfilesystemencoding() in ['ascii', 'ANSI_X3.4-1968'] and\n                not params.get('restrictfilenames', False)):\n            # On Python 3, the Unicode filesystem API will throw errors (#1474)\n            self.report_warning(\n                'Assuming --restrict-filenames since file system encoding '\n                'cannot encode all characters. '\n                'Set the LC_ALL environment variable to fix this.')\n            self.params['restrictfilenames'] = True\n\n        if isinstance(params.get('outtmpl'), bytes):\n            self.report_warning(\n                'Parameter outtmpl is bytes, but should be a unicode string. '\n                'Put  from __future__ import unicode_literals  at the top of your code file or consider switching to Python 3.x.')\n\n        self._setup_opener()\n\n        if auto_init:\n            self.print_debug_header()\n            self.add_default_info_extractors()\n\n        for pp_def_raw in self.params.get('postprocessors', []):\n            pp_class = get_postprocessor(pp_def_raw['key'])\n            pp_def = dict(pp_def_raw)\n            del pp_def['key']\n            pp = pp_class(self, **compat_kwargs(pp_def))\n            self.add_post_processor(pp)\n\n        for ph in self.params.get('progress_hooks', []):\n            self.add_progress_hook(ph)",
        "begin_line": 276,
        "end_line": 347,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.05,
            "pseudo_dstar_susp": 0.04,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.04,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_info_extractor#365",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_info_extractor(self, ie)",
        "snippet": "    def add_info_extractor(self, ie):\n        \"\"\"Add an InfoExtractor object to the end of the list.\"\"\"\n        self._ies.append(ie)\n        self._ies_instances[ie.ie_key()] = ie\n        ie.set_downloader(self)",
        "begin_line": 365,
        "end_line": 369,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0078125,
            "pseudo_dstar_susp": 0.010309278350515464,
            "pseudo_tarantula_susp": 0.0025188916876574307,
            "pseudo_op2_susp": 0.010309278350515464,
            "pseudo_barinel_susp": 0.0025188916876574307
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.get_info_extractor#371",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.get_info_extractor(self, ie_key)",
        "snippet": "    def get_info_extractor(self, ie_key):\n        \"\"\"\n        Get an instance of an IE with name ie_key, it will try to get one from\n        the _ies list, if there's no instance it will create a new one and add\n        it to the extractor list.\n        \"\"\"\n        ie = self._ies_instances.get(ie_key)\n        if ie is None:\n            ie = get_info_extractor(ie_key)()\n            self.add_info_extractor(ie)\n        return ie",
        "begin_line": 371,
        "end_line": 381,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_default_info_extractors#383",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_default_info_extractors(self)",
        "snippet": "    def add_default_info_extractors(self):\n        \"\"\"\n        Add the InfoExtractors returned by gen_extractors to the end of the list\n        \"\"\"\n        for ie in gen_extractors():\n            self.add_info_extractor(ie)",
        "begin_line": 383,
        "end_line": 388,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004310344827586207,
            "pseudo_dstar_susp": 0.0056179775280898875,
            "pseudo_tarantula_susp": 0.002136752136752137,
            "pseudo_op2_susp": 0.0056179775280898875,
            "pseudo_barinel_susp": 0.002136752136752137
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_post_processor#390",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_post_processor(self, pp)",
        "snippet": "    def add_post_processor(self, pp):\n        \"\"\"Add a PostProcessor object to the end of the chain.\"\"\"\n        self._pps.append(pp)\n        pp.set_downloader(self)",
        "begin_line": 390,
        "end_line": 393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_progress_hook#395",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_progress_hook(self, ph)",
        "snippet": "    def add_progress_hook(self, ph):\n        \"\"\"Add the progress hook (currently only for the file downloader)\"\"\"\n        self._progress_hooks.append(ph)",
        "begin_line": 395,
        "end_line": 397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.004629629629629629,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.004629629629629629,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._bidi_workaround#399",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._bidi_workaround(self, message)",
        "snippet": "    def _bidi_workaround(self, message):\n        if not hasattr(self, '_output_channel'):\n            return message\n\n        assert hasattr(self, '_output_process')\n        assert isinstance(message, compat_str)\n        line_count = message.count('\\n') + 1\n        self._output_process.stdin.write((message + '\\n').encode('utf-8'))\n        self._output_process.stdin.flush()\n        res = ''.join(self._output_channel.readline().decode('utf-8')\n                      for _ in range(line_count))\n        return res[:-len('\\n')]",
        "begin_line": 399,
        "end_line": 410,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0056179775280898875,
            "pseudo_dstar_susp": 0.005235602094240838,
            "pseudo_tarantula_susp": 0.0024813895781637717,
            "pseudo_op2_susp": 0.005235602094240838,
            "pseudo_barinel_susp": 0.0024813895781637717
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_screen#412",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_screen(self, message, skip_eol=False)",
        "snippet": "    def to_screen(self, message, skip_eol=False):\n        \"\"\"Print message to stdout if not in quiet mode.\"\"\"\n        return self.to_stdout(message, skip_eol, check_quiet=True)",
        "begin_line": 412,
        "end_line": 414,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.005154639175257732,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.005154639175257732,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._write_string#416",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._write_string(self, s, out=None)",
        "snippet": "    def _write_string(self, s, out=None):\n        write_string(s, out=out, encoding=self.params.get('encoding'))",
        "begin_line": 416,
        "end_line": 417,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.004901960784313725,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.005,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_stdout#419",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_stdout(self, message, skip_eol=False, check_quiet=False)",
        "snippet": "    def to_stdout(self, message, skip_eol=False, check_quiet=False):\n        \"\"\"Print message to stdout if not in quiet mode.\"\"\"\n        if self.params.get('logger'):\n            self.params['logger'].debug(message)\n        elif not check_quiet or not self.params.get('quiet', False):\n            message = self._bidi_workaround(message)\n            terminator = ['\\n', ''][skip_eol]\n            output = message + terminator\n\n            self._write_string(output, self._screen_file)",
        "begin_line": 419,
        "end_line": 428,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0056179775280898875,
            "pseudo_dstar_susp": 0.005405405405405406,
            "pseudo_tarantula_susp": 0.0024813895781637717,
            "pseudo_op2_susp": 0.005405405405405406,
            "pseudo_barinel_susp": 0.0024813895781637717
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_stderr#430",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_stderr(self, message)",
        "snippet": "    def to_stderr(self, message):\n        \"\"\"Print message to stderr.\"\"\"\n        assert isinstance(message, compat_str)\n        if self.params.get('logger'):\n            self.params['logger'].error(message)\n        else:\n            message = self._bidi_workaround(message)\n            output = message + '\\n'\n            self._write_string(output, self._err_file)",
        "begin_line": 430,
        "end_line": 438,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_console_title#440",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_console_title(self, message)",
        "snippet": "    def to_console_title(self, message):\n        if not self.params.get('consoletitle', False):\n            return\n        if os.name == 'nt' and ctypes.windll.kernel32.GetConsoleWindow():\n            # c_wchar_p() might not be necessary if `message` is\n            # already of type unicode()\n            ctypes.windll.kernel32.SetConsoleTitleW(ctypes.c_wchar_p(message))\n        elif 'TERM' in os.environ:\n            self._write_string('\\033]0;%s\\007' % message, self._screen_file)",
        "begin_line": 440,
        "end_line": 448,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.0008904719501335708,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.0008904719501335708,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.trouble#474",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.trouble(self, message=None, tb=None)",
        "snippet": "    def trouble(self, message=None, tb=None):\n        \"\"\"Determine action to take when a download problem appears.\n\n        Depending on if the downloader has been configured to ignore\n        download errors or not, this method may throw an exception or\n        not when errors are found, after printing the message.\n\n        tb, if given, is additional traceback information.\n        \"\"\"\n        if message is not None:\n            self.to_stderr(message)\n        if self.params.get('verbose'):\n            if tb is None:\n                if sys.exc_info()[0]:  # if .trouble has been called from an except block\n                    tb = ''\n                    if hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:\n                        tb += ''.join(traceback.format_exception(*sys.exc_info()[1].exc_info))\n                    tb += compat_str(traceback.format_exc())\n                else:\n                    tb_data = traceback.format_list(traceback.extract_stack())\n                    tb = ''.join(tb_data)\n            self.to_stderr(tb)\n        if not self.params.get('ignoreerrors', False):\n            if sys.exc_info()[0] and hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:\n                exc_info = sys.exc_info()[1].exc_info\n            else:\n                exc_info = sys.exc_info()\n            raise DownloadError(message, exc_info)\n        self._download_retcode = 1",
        "begin_line": 474,
        "end_line": 502,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.003968253968253968,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.003968253968253968,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_warning#504",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_warning(self, message)",
        "snippet": "    def report_warning(self, message):\n        '''\n        Print the message to stderr, it will be prefixed with 'WARNING:'\n        If stderr is a tty file the 'WARNING:' will be colored\n        '''\n        if self.params.get('logger') is not None:\n            self.params['logger'].warning(message)\n        else:\n            if self.params.get('no_warnings'):\n                return\n            if not self.params.get('no_color') and self._err_file.isatty() and os.name != 'nt':\n                _msg_header = '\\033[0;33mWARNING:\\033[0m'\n            else:\n                _msg_header = 'WARNING:'\n            warning_message = '%s %s' % (_msg_header, message)\n            self.to_stderr(warning_message)",
        "begin_line": 504,
        "end_line": 519,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_error#521",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_error(self, message, tb=None)",
        "snippet": "    def report_error(self, message, tb=None):\n        '''\n        Do the same as trouble, but prefixes the message with 'ERROR:', colored\n        in red if stderr is a tty file.\n        '''\n        if not self.params.get('no_color') and self._err_file.isatty() and os.name != 'nt':\n            _msg_header = '\\033[0;31mERROR:\\033[0m'\n        else:\n            _msg_header = 'ERROR:'\n        error_message = '%s %s' % (_msg_header, message)\n        self.trouble(error_message, tb)",
        "begin_line": 521,
        "end_line": 531,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.00847457627118644,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.00847457627118644,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.prepare_filename#540",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.prepare_filename(self, info_dict)",
        "snippet": "    def prepare_filename(self, info_dict):\n        \"\"\"Generate the output filename.\"\"\"\n        try:\n            template_dict = dict(info_dict)\n\n            template_dict['epoch'] = int(time.time())\n            autonumber_size = self.params.get('autonumber_size')\n            if autonumber_size is None:\n                autonumber_size = 5\n            autonumber_templ = '%0' + str(autonumber_size) + 'd'\n            template_dict['autonumber'] = autonumber_templ % self._num_downloads\n            if template_dict.get('playlist_index') is not None:\n                template_dict['playlist_index'] = '%0*d' % (len(str(template_dict['n_entries'])), template_dict['playlist_index'])\n            if template_dict.get('resolution') is None:\n                if template_dict.get('width') and template_dict.get('height'):\n                    template_dict['resolution'] = '%dx%d' % (template_dict['width'], template_dict['height'])\n                elif template_dict.get('height'):\n                    template_dict['resolution'] = '%sp' % template_dict['height']\n                elif template_dict.get('width'):\n                    template_dict['resolution'] = '?x%d' % template_dict['width']\n\n            sanitize = lambda k, v: sanitize_filename(\n                compat_str(v),\n                restricted=self.params.get('restrictfilenames'),\n                is_id=(k == 'id'))\n            template_dict = dict((k, sanitize(k, v))\n                                 for k, v in template_dict.items()\n                                 if v is not None)\n            template_dict = collections.defaultdict(lambda: 'NA', template_dict)\n\n            outtmpl = sanitize_path(self.params.get('outtmpl', DEFAULT_OUTTMPL))\n            tmpl = compat_expanduser(outtmpl)\n            filename = tmpl % template_dict\n            # Temporary fix for #4787\n            # 'Treat' all problem characters by passing filename through preferredencoding\n            # to workaround encoding issues with subprocess on python2 @ Windows\n            if sys.version_info < (3, 0) and sys.platform == 'win32':\n                filename = encodeFilename(filename, True).decode(preferredencoding())\n            return filename\n        except ValueError as err:\n            self.report_error('Error in output template: ' + str(err) + ' (encoding: ' + repr(preferredencoding()) + ')')\n            return None",
        "begin_line": 540,
        "end_line": 581,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.004830917874396135,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.004830917874396135,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._match_entry#583",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._match_entry(self, info_dict, incomplete)",
        "snippet": "    def _match_entry(self, info_dict, incomplete):\n        \"\"\" Returns None iff the file should be downloaded \"\"\"\n\n        video_title = info_dict.get('title', info_dict.get('id', 'video'))\n        if 'title' in info_dict:\n            # This can happen when we're just evaluating the playlist\n            title = info_dict['title']\n            matchtitle = self.params.get('matchtitle', False)\n            if matchtitle:\n                if not re.search(matchtitle, title, re.IGNORECASE):\n                    return '\"' + title + '\" title did not match pattern \"' + matchtitle + '\"'\n            rejecttitle = self.params.get('rejecttitle', False)\n            if rejecttitle:\n                if re.search(rejecttitle, title, re.IGNORECASE):\n                    return '\"' + title + '\" title matched reject pattern \"' + rejecttitle + '\"'\n        date = info_dict.get('upload_date', None)\n        if date is not None:\n            dateRange = self.params.get('daterange', DateRange())\n            if date not in dateRange:\n                return '%s upload date is not in range %s' % (date_from_str(date).isoformat(), dateRange)\n        view_count = info_dict.get('view_count', None)\n        if view_count is not None:\n            min_views = self.params.get('min_views')\n            if min_views is not None and view_count < min_views:\n                return 'Skipping %s, because it has not reached minimum view count (%d/%d)' % (video_title, view_count, min_views)\n            max_views = self.params.get('max_views')\n            if max_views is not None and view_count > max_views:\n                return 'Skipping %s, because it has exceeded the maximum view count (%d/%d)' % (video_title, view_count, max_views)\n        if age_restricted(info_dict.get('age_limit'), self.params.get('age_limit')):\n            return 'Skipping \"%s\" because it is age restricted' % video_title\n        if self.in_download_archive(info_dict):\n            return '%s has already been recorded in archive' % video_title\n\n        if not incomplete:\n            match_filter = self.params.get('match_filter')\n            if match_filter is not None:\n                ret = match_filter(info_dict)\n                if ret is not None:\n                    return ret\n\n        return None",
        "begin_line": 583,
        "end_line": 623,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0015174506828528073,
            "pseudo_dstar_susp": 0.002028397565922921,
            "pseudo_tarantula_susp": 0.001567398119122257,
            "pseudo_op2_susp": 0.002028397565922921,
            "pseudo_barinel_susp": 0.0015552099533437014
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_extra_info#626",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_extra_info(info_dict, extra_info)",
        "snippet": "    def add_extra_info(info_dict, extra_info):\n        '''Set the keys from extra_info in info dict if they are missing'''\n        for key, value in extra_info.items():\n            info_dict.setdefault(key, value)",
        "begin_line": 626,
        "end_line": 629,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007911392405063291,
            "pseudo_dstar_susp": 0.00078125,
            "pseudo_tarantula_susp": 0.0009871668311944718,
            "pseudo_op2_susp": 0.00078125,
            "pseudo_barinel_susp": 0.0009871668311944718
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.extract_info#631",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.extract_info(self, url, download=True, ie_key=None, extra_info={}, process=True, force_generic_extractor=False)",
        "snippet": "    def extract_info(self, url, download=True, ie_key=None, extra_info={},\n                     process=True, force_generic_extractor=False):\n        '''\n        Returns a list with a dictionary for each video we find.\n        If 'download', also downloads the videos.\n        extra_info is a dict containing the extra values to add to each result\n        '''\n\n        if not ie_key and force_generic_extractor:\n            ie_key = 'Generic'\n\n        if ie_key:\n            ies = [self.get_info_extractor(ie_key)]\n        else:\n            ies = self._ies\n\n        for ie in ies:\n            if not ie.suitable(url):\n                continue\n\n            if not ie.working():\n                self.report_warning('The program functionality for this site has been marked as broken, '\n                                    'and will probably not work.')\n\n            try:\n                ie_result = ie.extract(url)\n                if ie_result is None:  # Finished already (backwards compatibility; listformats and friends should be moved here)\n                    break\n                if isinstance(ie_result, list):\n                    # Backwards compatibility: old IE result format\n                    ie_result = {\n                        '_type': 'compat_list',\n                        'entries': ie_result,\n                    }\n                self.add_default_extra_info(ie_result, ie, url)\n                if process:\n                    return self.process_ie_result(ie_result, download, extra_info)\n                else:\n                    return ie_result\n            except ExtractorError as de:  # An error we somewhat expected\n                self.report_error(compat_str(de), de.format_traceback())\n                break\n            except MaxDownloadsReached:\n                raise\n            except Exception as e:\n                if self.params.get('ignoreerrors', False):\n                    self.report_error(compat_str(e), tb=compat_str(traceback.format_exc()))\n                    break\n                else:\n                    raise\n        else:\n            self.report_error('no suitable InfoExtractor for URL %s' % url)",
        "begin_line": 631,
        "end_line": 682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.1111111111111111,
            "pseudo_dstar_susp": 0.01,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.01,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_default_extra_info#684",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_default_extra_info(self, ie_result, ie, url)",
        "snippet": "    def add_default_extra_info(self, ie_result, ie, url):\n        self.add_extra_info(ie_result, {\n            'extractor': ie.IE_NAME,\n            'webpage_url': url,\n            'webpage_url_basename': url_basename(url),\n            'extractor_key': ie.ie_key(),\n        })",
        "begin_line": 684,
        "end_line": 690,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.0016051364365971107,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_ie_result#692",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_ie_result(self, ie_result, download=True, extra_info={})",
        "snippet": "    def process_ie_result(self, ie_result, download=True, extra_info={}):\n        \"\"\"\n        Take the result of the ie(may be modified) and resolve all unresolved\n        references (URLs, playlist items).\n\n        It will also download the videos if 'download'.\n        Returns the resolved ie_result.\n        \"\"\"\n\n        result_type = ie_result.get('_type', 'video')\n\n        if result_type in ('url', 'url_transparent'):\n            extract_flat = self.params.get('extract_flat', False)\n            if ((extract_flat == 'in_playlist' and 'playlist' in extra_info) or\n                    extract_flat is True):\n                if self.params.get('forcejson', False):\n                    self.to_stdout(json.dumps(ie_result))\n                return ie_result\n\n        if result_type == 'video':\n            self.add_extra_info(ie_result, extra_info)\n            return self.process_video_result(ie_result, download=download)\n        elif result_type == 'url':\n            # We have to add extra_info to the results because it may be\n            # contained in a playlist\n            return self.extract_info(ie_result['url'],\n                                     download,\n                                     ie_key=ie_result.get('ie_key'),\n                                     extra_info=extra_info)\n        elif result_type == 'url_transparent':\n            # Use the information from the embedding page\n            info = self.extract_info(\n                ie_result['url'], ie_key=ie_result.get('ie_key'),\n                extra_info=extra_info, download=False, process=False)\n\n            force_properties = dict(\n                (k, v) for k, v in ie_result.items() if v is not None)\n            for f in ('_type', 'url'):\n                if f in force_properties:\n                    del force_properties[f]\n            new_result = info.copy()\n            new_result.update(force_properties)\n\n            assert new_result.get('_type') != 'url_transparent'\n\n            return self.process_ie_result(\n                new_result, download=download, extra_info=extra_info)\n        elif result_type == 'playlist' or result_type == 'multi_video':\n            # We process each entry in the playlist\n            playlist = ie_result.get('title', None) or ie_result.get('id', None)\n            self.to_screen('[download] Downloading playlist: %s' % playlist)\n\n            playlist_results = []\n\n            playliststart = self.params.get('playliststart', 1) - 1\n            playlistend = self.params.get('playlistend', None)\n            # For backwards compatibility, interpret -1 as whole list\n            if playlistend == -1:\n                playlistend = None\n\n            playlistitems_str = self.params.get('playlist_items', None)\n            playlistitems = None\n            if playlistitems_str is not None:\n                def iter_playlistitems(format):\n                    for string_segment in format.split(','):\n                        if '-' in string_segment:\n                            start, end = string_segment.split('-')\n                            for item in range(int(start), int(end) + 1):\n                                yield int(item)\n                        else:\n                            yield int(string_segment)\n                playlistitems = iter_playlistitems(playlistitems_str)\n\n            ie_entries = ie_result['entries']\n            if isinstance(ie_entries, list):\n                n_all_entries = len(ie_entries)\n                if playlistitems:\n                    entries = [\n                        ie_entries[i - 1] for i in playlistitems\n                        if -n_all_entries <= i - 1 < n_all_entries]\n                else:\n                    entries = ie_entries[playliststart:playlistend]\n                n_entries = len(entries)\n                self.to_screen(\n                    \"[%s] playlist %s: Collected %d video ids (downloading %d of them)\" %\n                    (ie_result['extractor'], playlist, n_all_entries, n_entries))\n            elif isinstance(ie_entries, PagedList):\n                if playlistitems:\n                    entries = []\n                    for item in playlistitems:\n                        entries.extend(ie_entries.getslice(\n                            item - 1, item\n                        ))\n                else:\n                    entries = ie_entries.getslice(\n                        playliststart, playlistend)\n                n_entries = len(entries)\n                self.to_screen(\n                    \"[%s] playlist %s: Downloading %d videos\" %\n                    (ie_result['extractor'], playlist, n_entries))\n            else:  # iterable\n                if playlistitems:\n                    entry_list = list(ie_entries)\n                    entries = [entry_list[i - 1] for i in playlistitems]\n                else:\n                    entries = list(itertools.islice(\n                        ie_entries, playliststart, playlistend))\n                n_entries = len(entries)\n                self.to_screen(\n                    \"[%s] playlist %s: Downloading %d videos\" %\n                    (ie_result['extractor'], playlist, n_entries))\n\n            if self.params.get('playlistreverse', False):\n                entries = entries[::-1]\n\n            for i, entry in enumerate(entries, 1):\n                self.to_screen('[download] Downloading video %s of %s' % (i, n_entries))\n                extra = {\n                    'n_entries': n_entries,\n                    'playlist': playlist,\n                    'playlist_id': ie_result.get('id'),\n                    'playlist_title': ie_result.get('title'),\n                    'playlist_index': i + playliststart,\n                    'extractor': ie_result['extractor'],\n                    'webpage_url': ie_result['webpage_url'],\n                    'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                    'extractor_key': ie_result['extractor_key'],\n                }\n\n                reason = self._match_entry(entry, incomplete=True)\n                if reason is not None:\n                    self.to_screen('[download] ' + reason)\n                    continue\n\n                entry_result = self.process_ie_result(entry,\n                                                      download=download,\n                                                      extra_info=extra)\n                playlist_results.append(entry_result)\n            ie_result['entries'] = playlist_results\n            return ie_result\n        elif result_type == 'compat_list':\n            self.report_warning(\n                'Extractor %s returned a compat_list result. '\n                'It needs to be updated.' % ie_result.get('extractor'))\n\n            def _fixup(r):\n                self.add_extra_info(\n                    r,\n                    {\n                        'extractor': ie_result['extractor'],\n                        'webpage_url': ie_result['webpage_url'],\n                        'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                        'extractor_key': ie_result['extractor_key'],\n                    }\n                )\n                return r\n            ie_result['entries'] = [\n                self.process_ie_result(_fixup(r), download, extra_info)\n                for r in ie_result['entries']\n            ]\n            return ie_result\n        else:\n            raise Exception('Invalid result type: %s' % result_type)",
        "begin_line": 692,
        "end_line": 854,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0014124293785310734,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0014124293785310734,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._build_format_filter#856",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._build_format_filter(self, filter_spec)",
        "snippet": "    def _build_format_filter(self, filter_spec):\n        \" Returns a function to filter the formats according to the filter_spec \"\n\n        OPERATORS = {\n            '<': operator.lt,\n            '<=': operator.le,\n            '>': operator.gt,\n            '>=': operator.ge,\n            '=': operator.eq,\n            '!=': operator.ne,\n        }\n        operator_rex = re.compile(r'''(?x)\\s*\n            (?P<key>width|height|tbr|abr|vbr|asr|filesize|fps)\n            \\s*(?P<op>%s)(?P<none_inclusive>\\s*\\?)?\\s*\n            (?P<value>[0-9.]+(?:[kKmMgGtTpPeEzZyY]i?[Bb]?)?)\n            $\n            ''' % '|'.join(map(re.escape, OPERATORS.keys())))\n        m = operator_rex.search(filter_spec)\n        if m:\n            try:\n                comparison_value = int(m.group('value'))\n            except ValueError:\n                comparison_value = parse_filesize(m.group('value'))\n                if comparison_value is None:\n                    comparison_value = parse_filesize(m.group('value') + 'B')\n                if comparison_value is None:\n                    raise ValueError(\n                        'Invalid value %r in format specification %r' % (\n                            m.group('value'), filter_spec))\n            op = OPERATORS[m.group('op')]\n\n        if not m:\n            STR_OPERATORS = {\n                '=': operator.eq,\n                '!=': operator.ne,\n            }\n            str_operator_rex = re.compile(r'''(?x)\n                \\s*(?P<key>ext|acodec|vcodec|container|protocol)\n                \\s*(?P<op>%s)(?P<none_inclusive>\\s*\\?)?\n                \\s*(?P<value>[a-zA-Z0-9_-]+)\n                \\s*$\n                ''' % '|'.join(map(re.escape, STR_OPERATORS.keys())))\n            m = str_operator_rex.search(filter_spec)\n            if m:\n                comparison_value = m.group('value')\n                op = STR_OPERATORS[m.group('op')]\n\n        if not m:\n            raise ValueError('Invalid filter specification %r' % filter_spec)\n\n        def _filter(f):\n            actual_value = f.get(m.group('key'))\n            if actual_value is None:\n                return m.group('none_inclusive')\n            return op(actual_value, comparison_value)\n        return _filter",
        "begin_line": 856,
        "end_line": 911,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.0008904719501335708,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.0008904719501335708,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._filter#906",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._filter(f)",
        "snippet": "        def _filter(f):\n            actual_value = f.get(m.group('key'))\n            if actual_value is None:\n                return m.group('none_inclusive')\n            return op(actual_value, comparison_value)",
        "begin_line": 906,
        "end_line": 910,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.build_format_selector#913",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.build_format_selector(self, format_spec)",
        "snippet": "    def build_format_selector(self, format_spec):\n        def syntax_error(note, start):\n            message = (\n                'Invalid format specification: '\n                '{0}\\n\\t{1}\\n\\t{2}^'.format(note, format_spec, ' ' * start[1]))\n            return SyntaxError(message)\n\n        PICKFIRST = 'PICKFIRST'\n        MERGE = 'MERGE'\n        SINGLE = 'SINGLE'\n        GROUP = 'GROUP'\n        FormatSelector = collections.namedtuple('FormatSelector', ['type', 'selector', 'filters'])\n\n        def _parse_filter(tokens):\n            filter_parts = []\n            for type, string, start, _, _ in tokens:\n                if type == tokenize.OP and string == ']':\n                    return ''.join(filter_parts)\n                else:\n                    filter_parts.append(string)\n\n        def _parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False):\n            selectors = []\n            current_selector = None\n            for type, string, start, _, _ in tokens:\n                # ENCODING is only defined in python 3.x\n                if type == getattr(tokenize, 'ENCODING', None):\n                    continue\n                elif type in [tokenize.NAME, tokenize.NUMBER]:\n                    current_selector = FormatSelector(SINGLE, string, [])\n                elif type == tokenize.OP:\n                    if string == ')':\n                        if not inside_group:\n                            # ')' will be handled by the parentheses group\n                            tokens.restore_last_token()\n                        break\n                    elif inside_merge and string in ['/', ',']:\n                        tokens.restore_last_token()\n                        break\n                    elif inside_choice and string == ',':\n                        tokens.restore_last_token()\n                        break\n                    elif string == ',':\n                        selectors.append(current_selector)\n                        current_selector = None\n                    elif string == '/':\n                        first_choice = current_selector\n                        second_choice = _parse_format_selection(tokens, inside_choice=True)\n                        current_selector = None\n                        selectors.append(FormatSelector(PICKFIRST, (first_choice, second_choice), []))\n                    elif string == '[':\n                        if not current_selector:\n                            current_selector = FormatSelector(SINGLE, 'best', [])\n                        format_filter = _parse_filter(tokens)\n                        current_selector.filters.append(format_filter)\n                    elif string == '(':\n                        if current_selector:\n                            raise syntax_error('Unexpected \"(\"', start)\n                        group = _parse_format_selection(tokens, inside_group=True)\n                        current_selector = FormatSelector(GROUP, group, [])\n                    elif string == '+':\n                        video_selector = current_selector\n                        audio_selector = _parse_format_selection(tokens, inside_merge=True)\n                        current_selector = FormatSelector(MERGE, (video_selector, audio_selector), [])\n                    else:\n                        raise syntax_error('Operator not recognized: \"{0}\"'.format(string), start)\n                elif type == tokenize.ENDMARKER:\n                    break\n            if current_selector:\n                selectors.append(current_selector)\n            return selectors\n\n        def _build_selector_function(selector):\n            if isinstance(selector, list):\n                fs = [_build_selector_function(s) for s in selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        for format in f(formats):\n                            yield format\n                return selector_function\n            elif selector.type == GROUP:\n                selector_function = _build_selector_function(selector.selector)\n            elif selector.type == PICKFIRST:\n                fs = [_build_selector_function(s) for s in selector.selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        picked_formats = list(f(formats))\n                        if picked_formats:\n                            return picked_formats\n                    return []\n            elif selector.type == SINGLE:\n                format_spec = selector.selector\n\n                def selector_function(formats):\n                    if format_spec == 'all':\n                        for f in formats:\n                            yield f\n                    elif format_spec in ['best', 'worst', None]:\n                        format_idx = 0 if format_spec == 'worst' else -1\n                        audiovideo_formats = [\n                            f for f in formats\n                            if f.get('vcodec') != 'none' and f.get('acodec') != 'none']\n                        if audiovideo_formats:\n                            yield audiovideo_formats[format_idx]\n                        # for audio only (soundcloud) or video only (imgur) urls, select the best/worst audio format\n                        elif (all(f.get('acodec') != 'none' for f in formats) or\n                              all(f.get('vcodec') != 'none' for f in formats)):\n                            yield formats[format_idx]\n                    elif format_spec == 'bestaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[-1]\n                    elif format_spec == 'worstaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[0]\n                    elif format_spec == 'bestvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[-1]\n                    elif format_spec == 'worstvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[0]\n                    else:\n                        extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a', 'mp3', 'ogg', 'aac', 'wav']\n                        if format_spec in extensions:\n                            filter_f = lambda f: f['ext'] == format_spec\n                        else:\n                            filter_f = lambda f: f['format_id'] == format_spec\n                        matches = list(filter(filter_f, formats))\n                        if matches:\n                            yield matches[-1]\n            elif selector.type == MERGE:\n                def _merge(formats_info):\n                    format_1, format_2 = [f['format_id'] for f in formats_info]\n                    # The first format must contain the video and the\n                    # second the audio\n                    if formats_info[0].get('vcodec') == 'none':\n                        self.report_error('The first format must '\n                                          'contain the video, try using '\n                                          '\"-f %s+%s\"' % (format_2, format_1))\n                        return\n                    output_ext = (\n                        formats_info[0]['ext']\n                        if self.params.get('merge_output_format') is None\n                        else self.params['merge_output_format'])\n                    return {\n                        'requested_formats': formats_info,\n                        'format': '%s+%s' % (formats_info[0].get('format'),\n                                             formats_info[1].get('format')),\n                        'format_id': '%s+%s' % (formats_info[0].get('format_id'),\n                                                formats_info[1].get('format_id')),\n                        'width': formats_info[0].get('width'),\n                        'height': formats_info[0].get('height'),\n                        'resolution': formats_info[0].get('resolution'),\n                        'fps': formats_info[0].get('fps'),\n                        'vcodec': formats_info[0].get('vcodec'),\n                        'vbr': formats_info[0].get('vbr'),\n                        'stretched_ratio': formats_info[0].get('stretched_ratio'),\n                        'acodec': formats_info[1].get('acodec'),\n                        'abr': formats_info[1].get('abr'),\n                        'ext': output_ext,\n                    }\n                video_selector, audio_selector = map(_build_selector_function, selector.selector)\n\n                def selector_function(formats):\n                    formats = list(formats)\n                    for pair in itertools.product(video_selector(formats), audio_selector(formats)):\n                        yield _merge(pair)\n\n            filters = [self._build_format_filter(f) for f in selector.filters]\n\n            def final_selector(formats):\n                for _filter in filters:\n                    formats = list(filter(_filter, formats))\n                return selector_function(formats)\n            return final_selector\n\n        stream = io.BytesIO(format_spec.encode('utf-8'))\n        try:\n            tokens = list(compat_tokenize_tokenize(stream.readline))\n        except tokenize.TokenError:\n            raise syntax_error('Missing closing/opening brackets or parenthesis', (0, len(format_spec)))\n\n        class TokenIterator(object):\n            def __init__(self, tokens):\n                self.tokens = tokens\n                self.counter = 0\n\n            def __iter__(self):\n                return self\n\n            def __next__(self):\n                if self.counter >= len(self.tokens):\n                    raise StopIteration()\n                value = self.tokens[self.counter]\n                self.counter += 1\n                return value\n\n            next = __next__\n\n            def restore_last_token(self):\n                self.counter -= 1\n\n        parsed_selector = _parse_format_selection(iter(TokenIterator(tokens)))\n        return _build_selector_function(parsed_selector)",
        "begin_line": 913,
        "end_line": 1129,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.0013020833333333333,
            "pseudo_dstar_susp": 0.0018726591760299626,
            "pseudo_tarantula_susp": 0.0014367816091954023,
            "pseudo_op2_susp": 0.0018726591760299626,
            "pseudo_barinel_susp": 0.0014367816091954023
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.syntax_error#914",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.syntax_error(note, start)",
        "snippet": "        def syntax_error(note, start):\n            message = (\n                'Invalid format specification: '\n                '{0}\\n\\t{1}\\n\\t{2}^'.format(note, format_spec, ' ' * start[1]))\n            return SyntaxError(message)",
        "begin_line": 914,
        "end_line": 918,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010526315789473684,
            "pseudo_dstar_susp": 0.0017035775127768314,
            "pseudo_tarantula_susp": 0.0011135857461024498,
            "pseudo_op2_susp": 0.0017035775127768314,
            "pseudo_barinel_susp": 0.0011135857461024498
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._parse_filter#926",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._parse_filter(tokens)",
        "snippet": "        def _parse_filter(tokens):\n            filter_parts = []\n            for type, string, start, _, _ in tokens:\n                if type == tokenize.OP and string == ']':\n                    return ''.join(filter_parts)\n                else:\n                    filter_parts.append(string)",
        "begin_line": 926,
        "end_line": 932,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031746031746031746,
            "pseudo_dstar_susp": 0.0020833333333333333,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.0020833333333333333,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._parse_format_selection#934",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False)",
        "snippet": "        def _parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False):\n            selectors = []\n            current_selector = None\n            for type, string, start, _, _ in tokens:\n                # ENCODING is only defined in python 3.x\n                if type == getattr(tokenize, 'ENCODING', None):\n                    continue\n                elif type in [tokenize.NAME, tokenize.NUMBER]:\n                    current_selector = FormatSelector(SINGLE, string, [])\n                elif type == tokenize.OP:\n                    if string == ')':\n                        if not inside_group:\n                            # ')' will be handled by the parentheses group\n                            tokens.restore_last_token()\n                        break\n                    elif inside_merge and string in ['/', ',']:\n                        tokens.restore_last_token()\n                        break\n                    elif inside_choice and string == ',':\n                        tokens.restore_last_token()\n                        break\n                    elif string == ',':\n                        selectors.append(current_selector)\n                        current_selector = None\n                    elif string == '/':\n                        first_choice = current_selector\n                        second_choice = _parse_format_selection(tokens, inside_choice=True)\n                        current_selector = None\n                        selectors.append(FormatSelector(PICKFIRST, (first_choice, second_choice), []))\n                    elif string == '[':\n                        if not current_selector:\n                            current_selector = FormatSelector(SINGLE, 'best', [])\n                        format_filter = _parse_filter(tokens)\n                        current_selector.filters.append(format_filter)\n                    elif string == '(':\n                        if current_selector:\n                            raise syntax_error('Unexpected \"(\"', start)\n                        group = _parse_format_selection(tokens, inside_group=True)\n                        current_selector = FormatSelector(GROUP, group, [])\n                    elif string == '+':\n                        video_selector = current_selector\n                        audio_selector = _parse_format_selection(tokens, inside_merge=True)\n                        current_selector = FormatSelector(MERGE, (video_selector, audio_selector), [])\n                    else:\n                        raise syntax_error('Operator not recognized: \"{0}\"'.format(string), start)\n                elif type == tokenize.ENDMARKER:\n                    break\n            if current_selector:\n                selectors.append(current_selector)\n            return selectors",
        "begin_line": 934,
        "end_line": 983,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0017035775127768314,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0017035775127768314,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._build_selector_function#985",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._build_selector_function(selector)",
        "snippet": "        def _build_selector_function(selector):\n            if isinstance(selector, list):\n                fs = [_build_selector_function(s) for s in selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        for format in f(formats):\n                            yield format\n                return selector_function\n            elif selector.type == GROUP:\n                selector_function = _build_selector_function(selector.selector)\n            elif selector.type == PICKFIRST:\n                fs = [_build_selector_function(s) for s in selector.selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        picked_formats = list(f(formats))\n                        if picked_formats:\n                            return picked_formats\n                    return []\n            elif selector.type == SINGLE:\n                format_spec = selector.selector\n\n                def selector_function(formats):\n                    if format_spec == 'all':\n                        for f in formats:\n                            yield f\n                    elif format_spec in ['best', 'worst', None]:\n                        format_idx = 0 if format_spec == 'worst' else -1\n                        audiovideo_formats = [\n                            f for f in formats\n                            if f.get('vcodec') != 'none' and f.get('acodec') != 'none']\n                        if audiovideo_formats:\n                            yield audiovideo_formats[format_idx]\n                        # for audio only (soundcloud) or video only (imgur) urls, select the best/worst audio format\n                        elif (all(f.get('acodec') != 'none' for f in formats) or\n                              all(f.get('vcodec') != 'none' for f in formats)):\n                            yield formats[format_idx]\n                    elif format_spec == 'bestaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[-1]\n                    elif format_spec == 'worstaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[0]\n                    elif format_spec == 'bestvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[-1]\n                    elif format_spec == 'worstvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[0]\n                    else:\n                        extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a', 'mp3', 'ogg', 'aac', 'wav']\n                        if format_spec in extensions:\n                            filter_f = lambda f: f['ext'] == format_spec\n                        else:\n                            filter_f = lambda f: f['format_id'] == format_spec\n                        matches = list(filter(filter_f, formats))\n                        if matches:\n                            yield matches[-1]\n            elif selector.type == MERGE:\n                def _merge(formats_info):\n                    format_1, format_2 = [f['format_id'] for f in formats_info]\n                    # The first format must contain the video and the\n                    # second the audio\n                    if formats_info[0].get('vcodec') == 'none':\n                        self.report_error('The first format must '\n                                          'contain the video, try using '\n                                          '\"-f %s+%s\"' % (format_2, format_1))\n                        return\n                    output_ext = (\n                        formats_info[0]['ext']\n                        if self.params.get('merge_output_format') is None\n                        else self.params['merge_output_format'])\n                    return {\n                        'requested_formats': formats_info,\n                        'format': '%s+%s' % (formats_info[0].get('format'),\n                                             formats_info[1].get('format')),\n                        'format_id': '%s+%s' % (formats_info[0].get('format_id'),\n                                                formats_info[1].get('format_id')),\n                        'width': formats_info[0].get('width'),\n                        'height': formats_info[0].get('height'),\n                        'resolution': formats_info[0].get('resolution'),\n                        'fps': formats_info[0].get('fps'),\n                        'vcodec': formats_info[0].get('vcodec'),\n                        'vbr': formats_info[0].get('vbr'),\n                        'stretched_ratio': formats_info[0].get('stretched_ratio'),\n                        'acodec': formats_info[1].get('acodec'),\n                        'abr': formats_info[1].get('abr'),\n                        'ext': output_ext,\n                    }\n                video_selector, audio_selector = map(_build_selector_function, selector.selector)\n\n                def selector_function(formats):\n                    formats = list(formats)\n                    for pair in itertools.product(video_selector(formats), audio_selector(formats)):\n                        yield _merge(pair)\n\n            filters = [self._build_format_filter(f) for f in selector.filters]\n\n            def final_selector(formats):\n                for _filter in filters:\n                    formats = list(filter(_filter, formats))\n                return selector_function(formats)\n            return final_selector",
        "begin_line": 985,
        "end_line": 1100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0018726591760299626,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0018726591760299626,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.selector_function#989",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.selector_function(formats)",
        "snippet": "                def selector_function(formats):\n                    for f in fs:\n                        for format in f(formats):\n                            yield format",
        "begin_line": 989,
        "end_line": 992,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0019801980198019802,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0019801980198019802,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.selector_function#999",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.selector_function(formats)",
        "snippet": "                def selector_function(formats):\n                    for f in fs:\n                        picked_formats = list(f(formats))\n                        if picked_formats:\n                            return picked_formats\n                    return []",
        "begin_line": 999,
        "end_line": 1004,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0019801980198019802,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0019801980198019802,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.selector_function#1008",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.selector_function(formats)",
        "snippet": "                def selector_function(formats):\n                    if format_spec == 'all':\n                        for f in formats:\n                            yield f\n                    elif format_spec in ['best', 'worst', None]:\n                        format_idx = 0 if format_spec == 'worst' else -1\n                        audiovideo_formats = [\n                            f for f in formats\n                            if f.get('vcodec') != 'none' and f.get('acodec') != 'none']\n                        if audiovideo_formats:\n                            yield audiovideo_formats[format_idx]\n                        # for audio only (soundcloud) or video only (imgur) urls, select the best/worst audio format\n                        elif (all(f.get('acodec') != 'none' for f in formats) or\n                              all(f.get('vcodec') != 'none' for f in formats)):\n                            yield formats[format_idx]\n                    elif format_spec == 'bestaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[-1]\n                    elif format_spec == 'worstaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[0]\n                    elif format_spec == 'bestvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[-1]\n                    elif format_spec == 'worstvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[0]\n                    else:\n                        extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a', 'mp3', 'ogg', 'aac', 'wav']\n                        if format_spec in extensions:\n                            filter_f = lambda f: f['ext'] == format_spec\n                        else:\n                            filter_f = lambda f: f['format_id'] == format_spec\n                        matches = list(filter(filter_f, formats))\n                        if matches:\n                            yield matches[-1]",
        "begin_line": 1008,
        "end_line": 1055,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0019801980198019802,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0019801980198019802,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._merge#1057",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._merge(formats_info)",
        "snippet": "                def _merge(formats_info):\n                    format_1, format_2 = [f['format_id'] for f in formats_info]\n                    # The first format must contain the video and the\n                    # second the audio\n                    if formats_info[0].get('vcodec') == 'none':\n                        self.report_error('The first format must '\n                                          'contain the video, try using '\n                                          '\"-f %s+%s\"' % (format_2, format_1))\n                        return\n                    output_ext = (\n                        formats_info[0]['ext']\n                        if self.params.get('merge_output_format') is None\n                        else self.params['merge_output_format'])\n                    return {\n                        'requested_formats': formats_info,\n                        'format': '%s+%s' % (formats_info[0].get('format'),\n                                             formats_info[1].get('format')),\n                        'format_id': '%s+%s' % (formats_info[0].get('format_id'),\n                                                formats_info[1].get('format_id')),\n                        'width': formats_info[0].get('width'),\n                        'height': formats_info[0].get('height'),\n                        'resolution': formats_info[0].get('resolution'),\n                        'fps': formats_info[0].get('fps'),\n                        'vcodec': formats_info[0].get('vcodec'),\n                        'vbr': formats_info[0].get('vbr'),\n                        'stretched_ratio': formats_info[0].get('stretched_ratio'),\n                        'acodec': formats_info[1].get('acodec'),\n                        'abr': formats_info[1].get('abr'),\n                        'ext': output_ext,\n                    }",
        "begin_line": 1057,
        "end_line": 1086,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.selector_function#1089",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.selector_function(formats)",
        "snippet": "                def selector_function(formats):\n                    formats = list(formats)\n                    for pair in itertools.product(video_selector(formats), audio_selector(formats)):\n                        yield _merge(pair)",
        "begin_line": 1089,
        "end_line": 1092,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0019801980198019802,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0019801980198019802,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.final_selector#1096",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.final_selector(formats)",
        "snippet": "            def final_selector(formats):\n                for _filter in filters:\n                    formats = list(filter(_filter, formats))\n                return selector_function(formats)",
        "begin_line": 1096,
        "end_line": 1099,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0017035775127768314,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.0017035775127768314,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.TokenIterator.build_format_selector#913",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.TokenIterator",
        "signature": "youtube_dl.YoutubeDL.TokenIterator.build_format_selector(self, format_spec)",
        "snippet": "    def build_format_selector(self, format_spec):\n        def syntax_error(note, start):\n            message = (\n                'Invalid format specification: '\n                '{0}\\n\\t{1}\\n\\t{2}^'.format(note, format_spec, ' ' * start[1]))\n            return SyntaxError(message)\n\n        PICKFIRST = 'PICKFIRST'\n        MERGE = 'MERGE'\n        SINGLE = 'SINGLE'\n        GROUP = 'GROUP'\n        FormatSelector = collections.namedtuple('FormatSelector', ['type', 'selector', 'filters'])\n\n        def _parse_filter(tokens):\n            filter_parts = []\n            for type, string, start, _, _ in tokens:\n                if type == tokenize.OP and string == ']':\n                    return ''.join(filter_parts)\n                else:\n                    filter_parts.append(string)\n\n        def _parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False):\n            selectors = []\n            current_selector = None\n            for type, string, start, _, _ in tokens:\n                # ENCODING is only defined in python 3.x\n                if type == getattr(tokenize, 'ENCODING', None):\n                    continue\n                elif type in [tokenize.NAME, tokenize.NUMBER]:\n                    current_selector = FormatSelector(SINGLE, string, [])\n                elif type == tokenize.OP:\n                    if string == ')':\n                        if not inside_group:\n                            # ')' will be handled by the parentheses group\n                            tokens.restore_last_token()\n                        break\n                    elif inside_merge and string in ['/', ',']:\n                        tokens.restore_last_token()\n                        break\n                    elif inside_choice and string == ',':\n                        tokens.restore_last_token()\n                        break\n                    elif string == ',':\n                        selectors.append(current_selector)\n                        current_selector = None\n                    elif string == '/':\n                        first_choice = current_selector\n                        second_choice = _parse_format_selection(tokens, inside_choice=True)\n                        current_selector = None\n                        selectors.append(FormatSelector(PICKFIRST, (first_choice, second_choice), []))\n                    elif string == '[':\n                        if not current_selector:\n                            current_selector = FormatSelector(SINGLE, 'best', [])\n                        format_filter = _parse_filter(tokens)\n                        current_selector.filters.append(format_filter)\n                    elif string == '(':\n                        if current_selector:\n                            raise syntax_error('Unexpected \"(\"', start)\n                        group = _parse_format_selection(tokens, inside_group=True)\n                        current_selector = FormatSelector(GROUP, group, [])\n                    elif string == '+':\n                        video_selector = current_selector\n                        audio_selector = _parse_format_selection(tokens, inside_merge=True)\n                        current_selector = FormatSelector(MERGE, (video_selector, audio_selector), [])\n                    else:\n                        raise syntax_error('Operator not recognized: \"{0}\"'.format(string), start)\n                elif type == tokenize.ENDMARKER:\n                    break\n            if current_selector:\n                selectors.append(current_selector)\n            return selectors\n\n        def _build_selector_function(selector):\n            if isinstance(selector, list):\n                fs = [_build_selector_function(s) for s in selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        for format in f(formats):\n                            yield format\n                return selector_function\n            elif selector.type == GROUP:\n                selector_function = _build_selector_function(selector.selector)\n            elif selector.type == PICKFIRST:\n                fs = [_build_selector_function(s) for s in selector.selector]\n\n                def selector_function(formats):\n                    for f in fs:\n                        picked_formats = list(f(formats))\n                        if picked_formats:\n                            return picked_formats\n                    return []\n            elif selector.type == SINGLE:\n                format_spec = selector.selector\n\n                def selector_function(formats):\n                    if format_spec == 'all':\n                        for f in formats:\n                            yield f\n                    elif format_spec in ['best', 'worst', None]:\n                        format_idx = 0 if format_spec == 'worst' else -1\n                        audiovideo_formats = [\n                            f for f in formats\n                            if f.get('vcodec') != 'none' and f.get('acodec') != 'none']\n                        if audiovideo_formats:\n                            yield audiovideo_formats[format_idx]\n                        # for audio only (soundcloud) or video only (imgur) urls, select the best/worst audio format\n                        elif (all(f.get('acodec') != 'none' for f in formats) or\n                              all(f.get('vcodec') != 'none' for f in formats)):\n                            yield formats[format_idx]\n                    elif format_spec == 'bestaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[-1]\n                    elif format_spec == 'worstaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[0]\n                    elif format_spec == 'bestvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[-1]\n                    elif format_spec == 'worstvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[0]\n                    else:\n                        extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a', 'mp3', 'ogg', 'aac', 'wav']\n                        if format_spec in extensions:\n                            filter_f = lambda f: f['ext'] == format_spec\n                        else:\n                            filter_f = lambda f: f['format_id'] == format_spec\n                        matches = list(filter(filter_f, formats))\n                        if matches:\n                            yield matches[-1]\n            elif selector.type == MERGE:\n                def _merge(formats_info):\n                    format_1, format_2 = [f['format_id'] for f in formats_info]\n                    # The first format must contain the video and the\n                    # second the audio\n                    if formats_info[0].get('vcodec') == 'none':\n                        self.report_error('The first format must '\n                                          'contain the video, try using '\n                                          '\"-f %s+%s\"' % (format_2, format_1))\n                        return\n                    output_ext = (\n                        formats_info[0]['ext']\n                        if self.params.get('merge_output_format') is None\n                        else self.params['merge_output_format'])\n                    return {\n                        'requested_formats': formats_info,\n                        'format': '%s+%s' % (formats_info[0].get('format'),\n                                             formats_info[1].get('format')),\n                        'format_id': '%s+%s' % (formats_info[0].get('format_id'),\n                                                formats_info[1].get('format_id')),\n                        'width': formats_info[0].get('width'),\n                        'height': formats_info[0].get('height'),\n                        'resolution': formats_info[0].get('resolution'),\n                        'fps': formats_info[0].get('fps'),\n                        'vcodec': formats_info[0].get('vcodec'),\n                        'vbr': formats_info[0].get('vbr'),\n                        'stretched_ratio': formats_info[0].get('stretched_ratio'),\n                        'acodec': formats_info[1].get('acodec'),\n                        'abr': formats_info[1].get('abr'),\n                        'ext': output_ext,\n                    }\n                video_selector, audio_selector = map(_build_selector_function, selector.selector)\n\n                def selector_function(formats):\n                    formats = list(formats)\n                    for pair in itertools.product(video_selector(formats), audio_selector(formats)):\n                        yield _merge(pair)\n\n            filters = [self._build_format_filter(f) for f in selector.filters]\n\n            def final_selector(formats):\n                for _filter in filters:\n                    formats = list(filter(_filter, formats))\n                return selector_function(formats)\n            return final_selector\n\n        stream = io.BytesIO(format_spec.encode('utf-8'))\n        try:\n            tokens = list(compat_tokenize_tokenize(stream.readline))\n        except tokenize.TokenError:\n            raise syntax_error('Missing closing/opening brackets or parenthesis', (0, len(format_spec)))\n\n        class TokenIterator(object):\n            def __init__(self, tokens):\n                self.tokens = tokens\n                self.counter = 0\n\n            def __iter__(self):\n                return self\n\n            def __next__(self):\n                if self.counter >= len(self.tokens):\n                    raise StopIteration()\n                value = self.tokens[self.counter]\n                self.counter += 1\n                return value\n\n            next = __next__\n\n            def restore_last_token(self):\n                self.counter -= 1\n\n        parsed_selector = _parse_format_selection(iter(TokenIterator(tokens)))\n        return _build_selector_function(parsed_selector)",
        "begin_line": 913,
        "end_line": 1129,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0017035775127768314,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.0017035775127768314,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.TokenIterator.__init__#1109",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.TokenIterator",
        "signature": "youtube_dl.YoutubeDL.TokenIterator.__init__(self, tokens)",
        "snippet": "            def __init__(self, tokens):\n                self.tokens = tokens\n                self.counter = 0",
        "begin_line": 1109,
        "end_line": 1111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0018726591760299626,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.0018726591760299626,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.TokenIterator.__iter__#1113",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.TokenIterator",
        "signature": "youtube_dl.YoutubeDL.TokenIterator.__iter__(self)",
        "snippet": "            def __iter__(self):\n                return self",
        "begin_line": 1113,
        "end_line": 1114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0017035775127768314,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0017035775127768314,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.TokenIterator.__next__#1116",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.TokenIterator",
        "signature": "youtube_dl.YoutubeDL.TokenIterator.__next__(self)",
        "snippet": "            def __next__(self):\n                if self.counter >= len(self.tokens):\n                    raise StopIteration()\n                value = self.tokens[self.counter]\n                self.counter += 1\n                return value",
        "begin_line": 1116,
        "end_line": 1121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0018726591760299626,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.0018726591760299626,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.TokenIterator.restore_last_token#1125",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.TokenIterator",
        "signature": "youtube_dl.YoutubeDL.TokenIterator.restore_last_token(self)",
        "snippet": "            def restore_last_token(self):\n                self.counter -= 1",
        "begin_line": 1125,
        "end_line": 1126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.0017035775127768314,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0017035775127768314,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._calc_headers#1131",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._calc_headers(self, info_dict)",
        "snippet": "    def _calc_headers(self, info_dict):\n        res = std_headers.copy()\n\n        add_headers = info_dict.get('http_headers')\n        if add_headers:\n            res.update(add_headers)\n\n        cookies = self._calc_cookies(info_dict)\n        if cookies:\n            res['Cookie'] = cookies\n\n        return res",
        "begin_line": 1131,
        "end_line": 1142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013020833333333333,
            "pseudo_dstar_susp": 0.0018726591760299626,
            "pseudo_tarantula_susp": 0.0014367816091954023,
            "pseudo_op2_susp": 0.0018726591760299626,
            "pseudo_barinel_susp": 0.0014367816091954023
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._calc_cookies#1144",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._calc_cookies(self, info_dict)",
        "snippet": "    def _calc_cookies(self, info_dict):\n        pr = compat_urllib_request.Request(info_dict['url'])\n        self.cookiejar.add_cookie_header(pr)\n        return pr.get_header('Cookie')",
        "begin_line": 1144,
        "end_line": 1147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013020833333333333,
            "pseudo_dstar_susp": 0.0018726591760299626,
            "pseudo_tarantula_susp": 0.0014367816091954023,
            "pseudo_op2_susp": 0.0018726591760299626,
            "pseudo_barinel_susp": 0.0014367816091954023
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_video_result#1149",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_video_result(self, info_dict, download=True)",
        "snippet": "    def process_video_result(self, info_dict, download=True):\n        assert info_dict.get('_type', 'video') == 'video'\n\n        if 'id' not in info_dict:\n            raise ExtractorError('Missing \"id\" field in extractor result')\n        if 'title' not in info_dict:\n            raise ExtractorError('Missing \"title\" field in extractor result')\n\n        if 'playlist' not in info_dict:\n            # It isn't part of a playlist\n            info_dict['playlist'] = None\n            info_dict['playlist_index'] = None\n\n        thumbnails = info_dict.get('thumbnails')\n        if thumbnails is None:\n            thumbnail = info_dict.get('thumbnail')\n            if thumbnail:\n                info_dict['thumbnails'] = thumbnails = [{'url': thumbnail}]\n        if thumbnails:\n            thumbnails.sort(key=lambda t: (\n                t.get('preference'), t.get('width'), t.get('height'),\n                t.get('id'), t.get('url')))\n            for i, t in enumerate(thumbnails):\n                if 'width' in t and 'height' in t:\n                    t['resolution'] = '%dx%d' % (t['width'], t['height'])\n                if t.get('id') is None:\n                    t['id'] = '%d' % i\n\n        if thumbnails and 'thumbnail' not in info_dict:\n            info_dict['thumbnail'] = thumbnails[-1]['url']\n\n        if 'display_id' not in info_dict and 'id' in info_dict:\n            info_dict['display_id'] = info_dict['id']\n\n        if info_dict.get('upload_date') is None and info_dict.get('timestamp') is not None:\n            # Working around out-of-range timestamp values (e.g. negative ones on Windows,\n            # see http://bugs.python.org/issue1646728)\n            try:\n                upload_date = datetime.datetime.utcfromtimestamp(info_dict['timestamp'])\n                info_dict['upload_date'] = upload_date.strftime('%Y%m%d')\n            except (ValueError, OverflowError, OSError):\n                pass\n\n        if self.params.get('listsubtitles', False):\n            if 'automatic_captions' in info_dict:\n                self.list_subtitles(info_dict['id'], info_dict.get('automatic_captions'), 'automatic captions')\n            self.list_subtitles(info_dict['id'], info_dict.get('subtitles'), 'subtitles')\n            return\n        info_dict['requested_subtitles'] = self.process_subtitles(\n            info_dict['id'], info_dict.get('subtitles'),\n            info_dict.get('automatic_captions'))\n\n        # We now pick which formats have to be downloaded\n        if info_dict.get('formats') is None:\n            # There's only one format available\n            formats = [info_dict]\n        else:\n            formats = info_dict['formats']\n\n        if not formats:\n            raise ExtractorError('No video formats found!')\n\n        formats_dict = {}\n\n        # We check that all the formats have the format and format_id fields\n        for i, format in enumerate(formats):\n            if 'url' not in format:\n                raise ExtractorError('Missing \"url\" key in result (index %d)' % i)\n\n            if format.get('format_id') is None:\n                format['format_id'] = compat_str(i)\n            format_id = format['format_id']\n            if format_id not in formats_dict:\n                formats_dict[format_id] = []\n            formats_dict[format_id].append(format)\n\n        # Make sure all formats have unique format_id\n        for format_id, ambiguous_formats in formats_dict.items():\n            if len(ambiguous_formats) > 1:\n                for i, format in enumerate(ambiguous_formats):\n                    format['format_id'] = '%s-%d' % (format_id, i)\n\n        for i, format in enumerate(formats):\n            if format.get('format') is None:\n                format['format'] = '{id} - {res}{note}'.format(\n                    id=format['format_id'],\n                    res=self.format_resolution(format),\n                    note=' ({0})'.format(format['format_note']) if format.get('format_note') is not None else '',\n                )\n            # Automatically determine file extension if missing\n            if 'ext' not in format:\n                format['ext'] = determine_ext(format['url']).lower()\n            # Add HTTP headers, so that external programs can use them from the\n            # json output\n            full_format_info = info_dict.copy()\n            full_format_info.update(format)\n            format['http_headers'] = self._calc_headers(full_format_info)\n\n        # TODO Central sorting goes here\n\n        if formats[0] is not info_dict:\n            # only set the 'formats' fields if the original info_dict list them\n            # otherwise we end up with a circular reference, the first (and unique)\n            # element in the 'formats' field in info_dict is info_dict itself,\n            # wich can't be exported to json\n            info_dict['formats'] = formats\n        if self.params.get('listformats'):\n            self.list_formats(info_dict)\n            return\n        if self.params.get('list_thumbnails'):\n            self.list_thumbnails(info_dict)\n            return\n\n        req_format = self.params.get('format')\n        if req_format is None:\n            req_format_list = []\n            if (self.params.get('outtmpl', DEFAULT_OUTTMPL) != '-' and\n                    info_dict['extractor'] in ['youtube', 'ted']):\n                merger = FFmpegMergerPP(self)\n                if merger.available and merger.can_merge():\n                    req_format_list.append('bestvideo+bestaudio')\n            req_format_list.append('best')\n            req_format = '/'.join(req_format_list)\n        format_selector = self.build_format_selector(req_format)\n        formats_to_download = list(format_selector(formats))\n        if not formats_to_download:\n            raise ExtractorError('requested format not available',\n                                 expected=True)\n\n        if download:\n            if len(formats_to_download) > 1:\n                self.to_screen('[info] %s: downloading video in %s formats' % (info_dict['id'], len(formats_to_download)))\n            for format in formats_to_download:\n                new_info = dict(info_dict)\n                new_info.update(format)\n                self.process_info(new_info)\n        # We update the info dict with the best quality format (backwards compatibility)\n        info_dict.update(formats_to_download[-1])\n        return info_dict",
        "begin_line": 1149,
        "end_line": 1287,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014044943820224719,
            "pseudo_dstar_susp": 0.0019880715705765406,
            "pseudo_tarantula_susp": 0.001567398119122257,
            "pseudo_op2_susp": 0.0019880715705765406,
            "pseudo_barinel_susp": 0.0015552099533437014
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_subtitles#1289",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_subtitles(self, video_id, normal_subtitles, automatic_captions)",
        "snippet": "    def process_subtitles(self, video_id, normal_subtitles, automatic_captions):\n        \"\"\"Select the requested subtitles and their format\"\"\"\n        available_subs = {}\n        if normal_subtitles and self.params.get('writesubtitles'):\n            available_subs.update(normal_subtitles)\n        if automatic_captions and self.params.get('writeautomaticsub'):\n            for lang, cap_info in automatic_captions.items():\n                if lang not in available_subs:\n                    available_subs[lang] = cap_info\n\n        if (not self.params.get('writesubtitles') and not\n                self.params.get('writeautomaticsub') or not\n                available_subs):\n            return None\n\n        if self.params.get('allsubtitles', False):\n            requested_langs = available_subs.keys()\n        else:\n            if self.params.get('subtitleslangs', False):\n                requested_langs = self.params.get('subtitleslangs')\n            elif 'en' in available_subs:\n                requested_langs = ['en']\n            else:\n                requested_langs = [list(available_subs.keys())[0]]\n\n        formats_query = self.params.get('subtitlesformat', 'best')\n        formats_preference = formats_query.split('/') if formats_query else []\n        subs = {}\n        for lang in requested_langs:\n            formats = available_subs.get(lang)\n            if formats is None:\n                self.report_warning('%s subtitles not available for %s' % (lang, video_id))\n                continue\n            for ext in formats_preference:\n                if ext == 'best':\n                    f = formats[-1]\n                    break\n                matches = list(filter(lambda f: f['ext'] == ext, formats))\n                if matches:\n                    f = matches[-1]\n                    break\n            else:\n                f = formats[-1]\n                self.report_warning(\n                    'No subtitle format found matching \"%s\" for language %s, '\n                    'using %s' % (formats_query, lang, f['ext']))\n            subs[lang] = f\n        return subs",
        "begin_line": 1289,
        "end_line": 1336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013020833333333333,
            "pseudo_dstar_susp": 0.0018726591760299626,
            "pseudo_tarantula_susp": 0.0014367816091954023,
            "pseudo_op2_susp": 0.0018726591760299626,
            "pseudo_barinel_susp": 0.0014367816091954023
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_info#1338",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_info(self, info_dict)",
        "snippet": "    def process_info(self, info_dict):\n        \"\"\"Process a single resolved IE result.\"\"\"\n\n        assert info_dict.get('_type', 'video') == 'video'\n\n        max_downloads = self.params.get('max_downloads')\n        if max_downloads is not None:\n            if self._num_downloads >= int(max_downloads):\n                raise MaxDownloadsReached()\n\n        info_dict['fulltitle'] = info_dict['title']\n        if len(info_dict['title']) > 200:\n            info_dict['title'] = info_dict['title'][:197] + '...'\n\n        if 'format' not in info_dict:\n            info_dict['format'] = info_dict['ext']\n\n        reason = self._match_entry(info_dict, incomplete=False)\n        if reason is not None:\n            self.to_screen('[download] ' + reason)\n            return\n\n        self._num_downloads += 1\n\n        info_dict['_filename'] = filename = self.prepare_filename(info_dict)\n\n        # Forced printings\n        if self.params.get('forcetitle', False):\n            self.to_stdout(info_dict['fulltitle'])\n        if self.params.get('forceid', False):\n            self.to_stdout(info_dict['id'])\n        if self.params.get('forceurl', False):\n            if info_dict.get('requested_formats') is not None:\n                for f in info_dict['requested_formats']:\n                    self.to_stdout(f['url'] + f.get('play_path', ''))\n            else:\n                # For RTMP URLs, also include the playpath\n                self.to_stdout(info_dict['url'] + info_dict.get('play_path', ''))\n        if self.params.get('forcethumbnail', False) and info_dict.get('thumbnail') is not None:\n            self.to_stdout(info_dict['thumbnail'])\n        if self.params.get('forcedescription', False) and info_dict.get('description') is not None:\n            self.to_stdout(info_dict['description'])\n        if self.params.get('forcefilename', False) and filename is not None:\n            self.to_stdout(filename)\n        if self.params.get('forceduration', False) and info_dict.get('duration') is not None:\n            self.to_stdout(formatSeconds(info_dict['duration']))\n        if self.params.get('forceformat', False):\n            self.to_stdout(info_dict['format'])\n        if self.params.get('forcejson', False):\n            self.to_stdout(json.dumps(info_dict))\n\n        # Do nothing else if in simulate mode\n        if self.params.get('simulate', False):\n            return\n\n        if filename is None:\n            return\n\n        try:\n            dn = os.path.dirname(sanitize_path(encodeFilename(filename)))\n            if dn and not os.path.exists(dn):\n                os.makedirs(dn)\n        except (OSError, IOError) as err:\n            self.report_error('unable to create directory ' + compat_str(err))\n            return\n\n        if self.params.get('writedescription', False):\n            descfn = replace_extension(filename, 'description', info_dict.get('ext'))\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(descfn)):\n                self.to_screen('[info] Video description is already present')\n            elif info_dict.get('description') is None:\n                self.report_warning('There\\'s no description to write.')\n            else:\n                try:\n                    self.to_screen('[info] Writing video description to: ' + descfn)\n                    with io.open(encodeFilename(descfn), 'w', encoding='utf-8') as descfile:\n                        descfile.write(info_dict['description'])\n                except (OSError, IOError):\n                    self.report_error('Cannot write description file ' + descfn)\n                    return\n\n        if self.params.get('writeannotations', False):\n            annofn = replace_extension(filename, 'annotations.xml', info_dict.get('ext'))\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(annofn)):\n                self.to_screen('[info] Video annotations are already present')\n            else:\n                try:\n                    self.to_screen('[info] Writing video annotations to: ' + annofn)\n                    with io.open(encodeFilename(annofn), 'w', encoding='utf-8') as annofile:\n                        annofile.write(info_dict['annotations'])\n                except (KeyError, TypeError):\n                    self.report_warning('There are no annotations to write.')\n                except (OSError, IOError):\n                    self.report_error('Cannot write annotations file: ' + annofn)\n                    return\n\n        subtitles_are_requested = any([self.params.get('writesubtitles', False),\n                                       self.params.get('writeautomaticsub')])\n\n        if subtitles_are_requested and info_dict.get('requested_subtitles'):\n            # subtitles download errors are already managed as troubles in relevant IE\n            # that way it will silently go on when used with unsupporting IE\n            subtitles = info_dict['requested_subtitles']\n            ie = self.get_info_extractor(info_dict['extractor_key'])\n            for sub_lang, sub_info in subtitles.items():\n                sub_format = sub_info['ext']\n                if sub_info.get('data') is not None:\n                    sub_data = sub_info['data']\n                else:\n                    try:\n                        sub_data = ie._download_webpage(\n                            sub_info['url'], info_dict['id'], note=False)\n                    except ExtractorError as err:\n                        self.report_warning('Unable to download subtitle for \"%s\": %s' %\n                                            (sub_lang, compat_str(err.cause)))\n                        continue\n                try:\n                    sub_filename = subtitles_filename(filename, sub_lang, sub_format)\n                    if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(sub_filename)):\n                        self.to_screen('[info] Video subtitle %s.%s is already_present' % (sub_lang, sub_format))\n                    else:\n                        self.to_screen('[info] Writing video subtitles to: ' + sub_filename)\n                        with io.open(encodeFilename(sub_filename), 'w', encoding='utf-8') as subfile:\n                            subfile.write(sub_data)\n                except (OSError, IOError):\n                    self.report_error('Cannot write subtitles file ' + sub_filename)\n                    return\n\n        if self.params.get('writeinfojson', False):\n            infofn = replace_extension(filename, 'info.json', info_dict.get('ext'))\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(infofn)):\n                self.to_screen('[info] Video description metadata is already present')\n            else:\n                self.to_screen('[info] Writing video description metadata as JSON to: ' + infofn)\n                try:\n                    write_json_file(self.filter_requested_info(info_dict), infofn)\n                except (OSError, IOError):\n                    self.report_error('Cannot write metadata to JSON file ' + infofn)\n                    return\n\n        self._write_thumbnails(info_dict, filename)\n\n        if not self.params.get('skip_download', False):\n            try:\n                def dl(name, info):\n                    fd = get_suitable_downloader(info, self.params)(self, self.params)\n                    for ph in self._progress_hooks:\n                        fd.add_progress_hook(ph)\n                    if self.params.get('verbose'):\n                        self.to_stdout('[debug] Invoking downloader on %r' % info.get('url'))\n                    return fd.download(name, info)\n\n                if info_dict.get('requested_formats') is not None:\n                    downloaded = []\n                    success = True\n                    merger = FFmpegMergerPP(self)\n                    if not merger.available:\n                        postprocessors = []\n                        self.report_warning('You have requested multiple '\n                                            'formats but ffmpeg or avconv are not installed.'\n                                            ' The formats won\\'t be merged.')\n                    else:\n                        postprocessors = [merger]\n\n                    def compatible_formats(formats):\n                        video, audio = formats\n                        # Check extension\n                        video_ext, audio_ext = audio.get('ext'), video.get('ext')\n                        if video_ext and audio_ext:\n                            COMPATIBLE_EXTS = (\n                                ('mp3', 'mp4', 'm4a', 'm4p', 'm4b', 'm4r', 'm4v'),\n                                ('webm')\n                            )\n                            for exts in COMPATIBLE_EXTS:\n                                if video_ext in exts and audio_ext in exts:\n                                    return True\n                        # TODO: Check acodec/vcodec\n                        return False\n\n                    filename_real_ext = os.path.splitext(filename)[1][1:]\n                    filename_wo_ext = (\n                        os.path.splitext(filename)[0]\n                        if filename_real_ext == info_dict['ext']\n                        else filename)\n                    requested_formats = info_dict['requested_formats']\n                    if self.params.get('merge_output_format') is None and not compatible_formats(requested_formats):\n                        info_dict['ext'] = 'mkv'\n                        self.report_warning(\n                            'Requested formats are incompatible for merge and will be merged into mkv.')\n                    # Ensure filename always has a correct extension for successful merge\n                    filename = '%s.%s' % (filename_wo_ext, info_dict['ext'])\n                    if os.path.exists(encodeFilename(filename)):\n                        self.to_screen(\n                            '[download] %s has already been downloaded and '\n                            'merged' % filename)\n                    else:\n                        for f in requested_formats:\n                            new_info = dict(info_dict)\n                            new_info.update(f)\n                            fname = self.prepare_filename(new_info)\n                            fname = prepend_extension(fname, 'f%s' % f['format_id'], new_info['ext'])\n                            downloaded.append(fname)\n                            partial_success = dl(fname, new_info)\n                            success = success and partial_success\n                        info_dict['__postprocessors'] = postprocessors\n                        info_dict['__files_to_merge'] = downloaded\n                else:\n                    # Just a single file\n                    success = dl(filename, info_dict)\n            except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n                self.report_error('unable to download video data: %s' % str(err))\n                return\n            except (OSError, IOError) as err:\n                raise UnavailableVideoError(err)\n            except (ContentTooShortError, ) as err:\n                self.report_error('content too short (expected %s bytes and served %s)' % (err.expected, err.downloaded))\n                return\n\n            if success:\n                # Fixup content\n                fixup_policy = self.params.get('fixup')\n                if fixup_policy is None:\n                    fixup_policy = 'detect_or_warn'\n\n                stretched_ratio = info_dict.get('stretched_ratio')\n                if stretched_ratio is not None and stretched_ratio != 1:\n                    if fixup_policy == 'warn':\n                        self.report_warning('%s: Non-uniform pixel ratio (%s)' % (\n                            info_dict['id'], stretched_ratio))\n                    elif fixup_policy == 'detect_or_warn':\n                        stretched_pp = FFmpegFixupStretchedPP(self)\n                        if stretched_pp.available:\n                            info_dict.setdefault('__postprocessors', [])\n                            info_dict['__postprocessors'].append(stretched_pp)\n                        else:\n                            self.report_warning(\n                                '%s: Non-uniform pixel ratio (%s). Install ffmpeg or avconv to fix this automatically.' % (\n                                    info_dict['id'], stretched_ratio))\n                    else:\n                        assert fixup_policy in ('ignore', 'never')\n\n                if info_dict.get('requested_formats') is None and info_dict.get('container') == 'm4a_dash':\n                    if fixup_policy == 'warn':\n                        self.report_warning('%s: writing DASH m4a. Only some players support this container.' % (\n                            info_dict['id']))\n                    elif fixup_policy == 'detect_or_warn':\n                        fixup_pp = FFmpegFixupM4aPP(self)\n                        if fixup_pp.available:\n                            info_dict.setdefault('__postprocessors', [])\n                            info_dict['__postprocessors'].append(fixup_pp)\n                        else:\n                            self.report_warning(\n                                '%s: writing DASH m4a. Only some players support this container. Install ffmpeg or avconv to fix this automatically.' % (\n                                    info_dict['id']))\n                    else:\n                        assert fixup_policy in ('ignore', 'never')\n\n                try:\n                    self.post_process(filename, info_dict)\n                except (PostProcessingError) as err:\n                    self.report_error('postprocessing: %s' % str(err))\n                    return\n                self.record_download_archive(info_dict)",
        "begin_line": 1338,
        "end_line": 1600,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.dl#1482",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.dl(name, info)",
        "snippet": "                def dl(name, info):\n                    fd = get_suitable_downloader(info, self.params)(self, self.params)\n                    for ph in self._progress_hooks:\n                        fd.add_progress_hook(ph)\n                    if self.params.get('verbose'):\n                        self.to_stdout('[debug] Invoking downloader on %r' % info.get('url'))\n                    return fd.download(name, info)",
        "begin_line": 1482,
        "end_line": 1488,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.0013404825737265416,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0013404825737265416,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.download#1602",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.download(self, url_list)",
        "snippet": "    def download(self, url_list):\n        \"\"\"Download a given list of URLs.\"\"\"\n        outtmpl = self.params.get('outtmpl', DEFAULT_OUTTMPL)\n        if (len(url_list) > 1 and\n                '%' not in outtmpl and\n                self.params.get('max_downloads') != 1):\n            raise SameFileError(outtmpl)\n\n        for url in url_list:\n            try:\n                # It also downloads the videos\n                res = self.extract_info(\n                    url, force_generic_extractor=self.params.get('force_generic_extractor', False))\n            except UnavailableVideoError:\n                self.report_error('unable to download video')\n            except MaxDownloadsReached:\n                self.to_screen('[info] Maximum number of downloaded files reached.')\n                raise\n            else:\n                if self.params.get('dump_single_json', False):\n                    self.to_stdout(json.dumps(res))\n\n        return self._download_retcode",
        "begin_line": 1602,
        "end_line": 1624,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006944444444444444,
            "pseudo_dstar_susp": 0.0022026431718061676,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0022026431718061676,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.download_with_info_file#1626",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.download_with_info_file(self, info_filename)",
        "snippet": "    def download_with_info_file(self, info_filename):\n        with contextlib.closing(fileinput.FileInput(\n                [info_filename], mode='r',\n                openhook=fileinput.hook_encoded('utf-8'))) as f:\n            # FileInput doesn't have a read method, we can't call json.load\n            info = self.filter_requested_info(json.loads('\\n'.join(f)))\n        try:\n            self.process_ie_result(info, download=True)\n        except DownloadError:\n            webpage_url = info.get('webpage_url')\n            if webpage_url is not None:\n                self.report_warning('The info failed to download, trying with \"%s\"' % webpage_url)\n                return self.download([webpage_url])\n            else:\n                raise\n        return self._download_retcode",
        "begin_line": 1626,
        "end_line": 1641,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.filter_requested_info#1644",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.filter_requested_info(info_dict)",
        "snippet": "    def filter_requested_info(info_dict):\n        return dict(\n            (k, v) for k, v in info_dict.items()\n            if k not in ['requested_formats', 'requested_subtitles'])",
        "begin_line": 1644,
        "end_line": 1647,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.0013404825737265416,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0013404825737265416,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.post_process#1649",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.post_process(self, filename, ie_info)",
        "snippet": "    def post_process(self, filename, ie_info):\n        \"\"\"Run all the postprocessors on the given file.\"\"\"\n        info = dict(ie_info)\n        info['filepath'] = filename\n        pps_chain = []\n        if ie_info.get('__postprocessors') is not None:\n            pps_chain.extend(ie_info['__postprocessors'])\n        pps_chain.extend(self._pps)\n        for pp in pps_chain:\n            files_to_delete = []\n            try:\n                files_to_delete, info = pp.run(info)\n            except PostProcessingError as e:\n                self.report_error(e.msg)\n            if files_to_delete and not self.params.get('keepvideo', False):\n                for old_filename in files_to_delete:\n                    self.to_screen('Deleting original file %s (pass -k to keep)' % old_filename)\n                    try:\n                        os.remove(encodeFilename(old_filename))\n                    except (IOError, OSError):\n                        self.report_warning('Unable to remove downloaded original file')",
        "begin_line": 1649,
        "end_line": 1669,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0014124293785310734,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.0014124293785310734,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._make_archive_id#1671",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._make_archive_id(self, info_dict)",
        "snippet": "    def _make_archive_id(self, info_dict):\n        # Future-proof against any change in case\n        # and backwards compatibility with prior versions\n        extractor = info_dict.get('extractor_key')\n        if extractor is None:\n            if 'id' in info_dict:\n                extractor = info_dict.get('ie_key')  # key in a playlist\n        if extractor is None:\n            return None  # Incomplete video information\n        return extractor.lower() + ' ' + info_dict['id']",
        "begin_line": 1671,
        "end_line": 1680,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.in_download_archive#1682",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.in_download_archive(self, info_dict)",
        "snippet": "    def in_download_archive(self, info_dict):\n        fn = self.params.get('download_archive')\n        if fn is None:\n            return False\n\n        vid_id = self._make_archive_id(info_dict)\n        if vid_id is None:\n            return False  # Incomplete video information\n\n        try:\n            with locked_file(fn, 'r', encoding='utf-8') as archive_file:\n                for line in archive_file:\n                    if line.strip() == vid_id:\n                        return True\n        except IOError as ioe:\n            if ioe.errno != errno.ENOENT:\n                raise\n        return False",
        "begin_line": 1682,
        "end_line": 1699,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024691358024691358,
            "pseudo_dstar_susp": 0.002061855670103093,
            "pseudo_tarantula_susp": 0.0016556291390728477,
            "pseudo_op2_susp": 0.002061855670103093,
            "pseudo_barinel_susp": 0.0016556291390728477
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.record_download_archive#1701",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.record_download_archive(self, info_dict)",
        "snippet": "    def record_download_archive(self, info_dict):\n        fn = self.params.get('download_archive')\n        if fn is None:\n            return\n        vid_id = self._make_archive_id(info_dict)\n        assert vid_id\n        with locked_file(fn, 'a', encoding='utf-8') as archive_file:\n            archive_file.write(vid_id + '\\n')",
        "begin_line": 1701,
        "end_line": 1708,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.format_resolution#1711",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.format_resolution(format, default='unknown')",
        "snippet": "    def format_resolution(format, default='unknown'):\n        if format.get('vcodec') == 'none':\n            return 'audio only'\n        if format.get('resolution') is not None:\n            return format['resolution']\n        if format.get('height') is not None:\n            if format.get('width') is not None:\n                res = '%sx%s' % (format['width'], format['height'])\n            else:\n                res = '%sp' % format['height']\n        elif format.get('width') is not None:\n            res = '?x%d' % format['width']\n        else:\n            res = default\n        return res",
        "begin_line": 1711,
        "end_line": 1725,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006944444444444444,
            "pseudo_dstar_susp": 0.0022026431718061676,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0022026431718061676,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._format_note#1727",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._format_note(self, fdict)",
        "snippet": "    def _format_note(self, fdict):\n        res = ''\n        if fdict.get('ext') in ['f4f', 'f4m']:\n            res += '(unsupported) '\n        if fdict.get('format_note') is not None:\n            res += fdict['format_note'] + ' '\n        if fdict.get('tbr') is not None:\n            res += '%4dk ' % fdict['tbr']\n        if fdict.get('container') is not None:\n            if res:\n                res += ', '\n            res += '%s container' % fdict['container']\n        if (fdict.get('vcodec') is not None and\n                fdict.get('vcodec') != 'none'):\n            if res:\n                res += ', '\n            res += fdict['vcodec']\n            if fdict.get('vbr') is not None:\n                res += '@'\n        elif fdict.get('vbr') is not None and fdict.get('abr') is not None:\n            res += 'video@'\n        if fdict.get('vbr') is not None:\n            res += '%4dk' % fdict['vbr']\n        if fdict.get('fps') is not None:\n            res += ', %sfps' % fdict['fps']\n        if fdict.get('acodec') is not None:\n            if res:\n                res += ', '\n            if fdict['acodec'] == 'none':\n                res += 'video only'\n            else:\n                res += '%-5s' % fdict['acodec']\n        elif fdict.get('abr') is not None:\n            if res:\n                res += ', '\n            res += 'audio'\n        if fdict.get('abr') is not None:\n            res += '@%3dk' % fdict['abr']\n        if fdict.get('asr') is not None:\n            res += ' (%5dHz)' % fdict['asr']\n        if fdict.get('filesize') is not None:\n            if res:\n                res += ', '\n            res += format_bytes(fdict['filesize'])\n        elif fdict.get('filesize_approx') is not None:\n            if res:\n                res += ', '\n            res += '~' + format_bytes(fdict['filesize_approx'])\n        return res",
        "begin_line": 1727,
        "end_line": 1775,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.list_thumbnails#1791",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.list_thumbnails(self, info_dict)",
        "snippet": "    def list_thumbnails(self, info_dict):\n        thumbnails = info_dict.get('thumbnails')\n        if not thumbnails:\n            tn_url = info_dict.get('thumbnail')\n            if tn_url:\n                thumbnails = [{'id': '0', 'url': tn_url}]\n            else:\n                self.to_screen(\n                    '[info] No thumbnails present for %s' % info_dict['id'])\n                return\n\n        self.to_screen(\n            '[info] Thumbnails for %s:' % info_dict['id'])\n        self.to_screen(render_table(\n            ['ID', 'width', 'height', 'URL'],\n            [[t['id'], t.get('width', 'unknown'), t.get('height', 'unknown'), t['url']] for t in thumbnails]))",
        "begin_line": 1791,
        "end_line": 1806,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.list_subtitles#1808",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.list_subtitles(self, video_id, subtitles, name='subtitles')",
        "snippet": "    def list_subtitles(self, video_id, subtitles, name='subtitles'):\n        if not subtitles:\n            self.to_screen('%s has no %s' % (video_id, name))\n            return\n        self.to_screen(\n            'Available %s for %s:' % (name, video_id))\n        self.to_screen(render_table(\n            ['Language', 'formats'],\n            [[lang, ', '.join(f['ext'] for f in reversed(formats))]\n                for lang, formats in subtitles.items()]))",
        "begin_line": 1808,
        "end_line": 1817,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.urlopen#1819",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.urlopen(self, req)",
        "snippet": "    def urlopen(self, req):\n        \"\"\" Start an HTTP download \"\"\"\n\n        # According to RFC 3986, URLs can not contain non-ASCII characters, however this is not\n        # always respected by websites, some tend to give out URLs with non percent-encoded\n        # non-ASCII characters (see telemb.py, ard.py [#3412])\n        # urllib chokes on URLs with non-ASCII characters (see http://bugs.python.org/issue3991)\n        # To work around aforementioned issue we will replace request's original URL with\n        # percent-encoded one\n        req_is_string = isinstance(req, compat_basestring)\n        url = req if req_is_string else req.get_full_url()\n        url_escaped = escape_url(url)\n\n        # Substitute URL if any change after escaping\n        if url != url_escaped:\n            if req_is_string:\n                req = url_escaped\n            else:\n                req_type = HEADRequest if req.get_method() == 'HEAD' else compat_urllib_request.Request\n                req = req_type(\n                    url_escaped, data=req.data, headers=req.headers,\n                    origin_req_host=req.origin_req_host, unverifiable=req.unverifiable)\n\n        return self._opener.open(req, timeout=self._socket_timeout)",
        "begin_line": 1819,
        "end_line": 1842,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005847953216374269,
            "pseudo_dstar_susp": 0.01282051282051282,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.01282051282051282,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.print_debug_header#1844",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.print_debug_header(self)",
        "snippet": "    def print_debug_header(self):\n        if not self.params.get('verbose'):\n            return\n\n        if type('') is not compat_str:\n            # Python 2.6 on SLES11 SP1 (https://github.com/rg3/youtube-dl/issues/3326)\n            self.report_warning(\n                'Your Python is broken! Update to a newer and supported version')\n\n        stdout_encoding = getattr(\n            sys.stdout, 'encoding', 'missing (%s)' % type(sys.stdout).__name__)\n        encoding_str = (\n            '[debug] Encodings: locale %s, fs %s, out %s, pref %s\\n' % (\n                locale.getpreferredencoding(),\n                sys.getfilesystemencoding(),\n                stdout_encoding,\n                self.get_encoding()))\n        write_string(encoding_str, encoding=None)\n\n        self._write_string('[debug] youtube-dl version ' + __version__ + '\\n')\n        try:\n            sp = subprocess.Popen(\n                ['git', 'rev-parse', '--short', 'HEAD'],\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n                cwd=os.path.dirname(os.path.abspath(__file__)))\n            out, err = sp.communicate()\n            out = out.decode().strip()\n            if re.match('[0-9a-f]+', out):\n                self._write_string('[debug] Git HEAD: ' + out + '\\n')\n        except Exception:\n            try:\n                sys.exc_clear()\n            except Exception:\n                pass\n        self._write_string('[debug] Python version %s - %s\\n' % (\n            platform.python_version(), platform_name()))\n\n        exe_versions = FFmpegPostProcessor.get_versions(self)\n        exe_versions['rtmpdump'] = rtmpdump_version()\n        exe_str = ', '.join(\n            '%s %s' % (exe, v)\n            for exe, v in sorted(exe_versions.items())\n            if v\n        )\n        if not exe_str:\n            exe_str = 'none'\n        self._write_string('[debug] exe versions: %s\\n' % exe_str)\n\n        proxy_map = {}\n        for handler in self._opener.handlers:\n            if hasattr(handler, 'proxies'):\n                proxy_map.update(handler.proxies)\n        self._write_string('[debug] Proxy map: ' + compat_str(proxy_map) + '\\n')\n\n        if self.params.get('call_home', False):\n            ipaddr = self.urlopen('https://yt-dl.org/ip').read().decode('utf-8')\n            self._write_string('[debug] Public IP address: %s\\n' % ipaddr)\n            latest_version = self.urlopen(\n                'https://yt-dl.org/latest/version').read().decode('utf-8')\n            if version_tuple(latest_version) > version_tuple(__version__):\n                self.report_warning(\n                    'You are using an outdated version (newest version: %s)! '\n                    'See https://yt-dl.org/update if you need help updating.' %\n                    latest_version)",
        "begin_line": 1844,
        "end_line": 1907,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024691358024691358,
            "pseudo_dstar_susp": 0.002061855670103093,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.002061855670103093,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._setup_opener#1909",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._setup_opener(self)",
        "snippet": "    def _setup_opener(self):\n        timeout_val = self.params.get('socket_timeout')\n        self._socket_timeout = 600 if timeout_val is None else float(timeout_val)\n\n        opts_cookiefile = self.params.get('cookiefile')\n        opts_proxy = self.params.get('proxy')\n\n        if opts_cookiefile is None:\n            self.cookiejar = compat_cookiejar.CookieJar()\n        else:\n            self.cookiejar = compat_cookiejar.MozillaCookieJar(\n                opts_cookiefile)\n            if os.access(opts_cookiefile, os.R_OK):\n                self.cookiejar.load()\n\n        cookie_processor = compat_urllib_request.HTTPCookieProcessor(\n            self.cookiejar)\n        if opts_proxy is not None:\n            if opts_proxy == '':\n                proxies = {}\n            else:\n                proxies = {'http': opts_proxy, 'https': opts_proxy}\n        else:\n            proxies = compat_urllib_request.getproxies()\n            # Set HTTPS proxy to HTTP one if given (https://github.com/rg3/youtube-dl/issues/805)\n            if 'http' in proxies and 'https' not in proxies:\n                proxies['https'] = proxies['http']\n        proxy_handler = PerRequestProxyHandler(proxies)\n\n        debuglevel = 1 if self.params.get('debug_printtraffic') else 0\n        https_handler = make_HTTPS_handler(self.params, debuglevel=debuglevel)\n        ydlh = YoutubeDLHandler(self.params, debuglevel=debuglevel)\n        opener = compat_urllib_request.build_opener(\n            proxy_handler, https_handler, cookie_processor, ydlh)\n\n        # Delete the default user-agent header, which would otherwise apply in\n        # cases where our custom HTTP handler doesn't come into play\n        # (See https://github.com/rg3/youtube-dl/issues/1309 for details)\n        opener.addheaders = []\n        self._opener = opener",
        "begin_line": 1909,
        "end_line": 1948,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008264462809917356,
            "pseudo_dstar_susp": 0.2,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.2,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.get_encoding#1960",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.get_encoding(self)",
        "snippet": "    def get_encoding(self):\n        encoding = self.params.get('encoding')\n        if encoding is None:\n            encoding = preferredencoding()\n        return encoding",
        "begin_line": 1960,
        "end_line": 1964,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._write_thumbnails#1966",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._write_thumbnails(self, info_dict, filename)",
        "snippet": "    def _write_thumbnails(self, info_dict, filename):\n        if self.params.get('writethumbnail', False):\n            thumbnails = info_dict.get('thumbnails')\n            if thumbnails:\n                thumbnails = [thumbnails[-1]]\n        elif self.params.get('write_all_thumbnails', False):\n            thumbnails = info_dict.get('thumbnails')\n        else:\n            return\n\n        if not thumbnails:\n            # No thumbnails present, so return immediately\n            return\n\n        for t in thumbnails:\n            thumb_ext = determine_ext(t['url'], 'jpg')\n            suffix = '_%s' % t['id'] if len(thumbnails) > 1 else ''\n            thumb_display_id = '%s ' % t['id'] if len(thumbnails) > 1 else ''\n            t['filename'] = thumb_filename = os.path.splitext(filename)[0] + suffix + '.' + thumb_ext\n\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(thumb_filename)):\n                self.to_screen('[%s] %s: Thumbnail %sis already present' %\n                               (info_dict['extractor'], info_dict['id'], thumb_display_id))\n            else:\n                self.to_screen('[%s] %s: Downloading thumbnail %s...' %\n                               (info_dict['extractor'], info_dict['id'], thumb_display_id))\n                try:\n                    uf = self.urlopen(t['url'])\n                    with open(thumb_filename, 'wb') as thumbf:\n                        shutil.copyfileobj(uf, thumbf)\n                    self.to_screen('[%s] %s: Writing thumbnail %sto: %s' %\n                                   (info_dict['extractor'], info_dict['id'], thumb_display_id, thumb_filename))\n                except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n                    self.report_warning('Unable to download thumbnail \"%s\": %s' %\n                                        (t['url'], compat_str(err)))",
        "begin_line": 1966,
        "end_line": 2000,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001364256480218281,
            "pseudo_dstar_susp": 0.001288659793814433,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.001288659793814433,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.__init__#234",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        \"\"\"Constructor. Receives an optional downloader.\"\"\"\n        self._ready = False\n        self.set_downloader(downloader)",
        "begin_line": 234,
        "end_line": 237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003952569169960474,
            "pseudo_dstar_susp": 1.0,
            "pseudo_tarantula_susp": 0.0009442870632672333,
            "pseudo_op2_susp": 1.0,
            "pseudo_barinel_susp": 0.0009442870632672333
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.suitable#240",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        \"\"\"Receives a URL and returns True if suitable for this IE.\"\"\"\n\n        # This does not use has/getattr intentionally - we want to know whether\n        # we have cached the regexp for *this* class, whereas getattr would also\n        # match the superclass\n        if '_VALID_URL_RE' not in cls.__dict__:\n            cls._VALID_URL_RE = re.compile(cls._VALID_URL)\n        return cls._VALID_URL_RE.match(url) is not None",
        "begin_line": 240,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.010638297872340425,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.010638297872340425,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._match_id#251",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._match_id(cls, url)",
        "snippet": "    def _match_id(cls, url):\n        if '_VALID_URL_RE' not in cls.__dict__:\n            cls._VALID_URL_RE = re.compile(cls._VALID_URL)\n        m = cls._VALID_URL_RE.match(url)\n        assert m\n        return m.group('id')",
        "begin_line": 251,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009689922480620155,
            "pseudo_dstar_susp": 0.004608294930875576,
            "pseudo_tarantula_susp": 0.0008445945945945946,
            "pseudo_op2_susp": 0.004608294930875576,
            "pseudo_barinel_susp": 0.0008445945945945946
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.working#259",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.working(cls)",
        "snippet": "    def working(cls):\n        \"\"\"Getter method for _WORKING.\"\"\"\n        return cls._WORKING",
        "begin_line": 259,
        "end_line": 261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002421307506053269,
            "pseudo_dstar_susp": 0.02,
            "pseudo_tarantula_susp": 0.0008517887563884157,
            "pseudo_op2_susp": 0.02,
            "pseudo_barinel_susp": 0.0008517887563884157
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.initialize#263",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.initialize(self)",
        "snippet": "    def initialize(self):\n        \"\"\"Initializes an instance (authentication, etc).\"\"\"\n        if not self._ready:\n            self._real_initialize()\n            self._ready = True",
        "begin_line": 263,
        "end_line": 267,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008928571428571428,
            "pseudo_dstar_susp": 0.01694915254237288,
            "pseudo_tarantula_susp": 0.0025575447570332483,
            "pseudo_op2_susp": 0.01694915254237288,
            "pseudo_barinel_susp": 0.0025575447570332483
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract#269",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract(self, url)",
        "snippet": "    def extract(self, url):\n        \"\"\"Extracts URL information and returns it in list of dicts.\"\"\"\n        try:\n            self.initialize()\n            return self._real_extract(url)\n        except ExtractorError:\n            raise\n        except compat_http_client.IncompleteRead as e:\n            raise ExtractorError('A network error has occured.', cause=e, expected=True)\n        except (KeyError, StopIteration) as e:\n            raise ExtractorError('An extractor error has occured.', cause=e)",
        "begin_line": 269,
        "end_line": 279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.3333333333333333,
            "pseudo_dstar_susp": 0.017241379310344827,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.017241379310344827,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.set_downloader#281",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.set_downloader(self, downloader)",
        "snippet": "    def set_downloader(self, downloader):\n        \"\"\"Sets the downloader for this IE.\"\"\"\n        self._downloader = downloader",
        "begin_line": 281,
        "end_line": 283,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008064516129032258,
            "pseudo_dstar_susp": 0.022222222222222223,
            "pseudo_tarantula_susp": 0.002136752136752137,
            "pseudo_op2_susp": 0.022222222222222223,
            "pseudo_barinel_susp": 0.002136752136752137
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._real_initialize#285",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        \"\"\"Real initialization process. Redefine in subclasses.\"\"\"\n        pass",
        "begin_line": 285,
        "end_line": 287,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.004651162790697674,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.004651162790697674,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.ie_key#294",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.ie_key(cls)",
        "snippet": "    def ie_key(cls):\n        \"\"\"A string for getting the InfoExtractor with get_info_extractor\"\"\"\n        return cls.__name__[:-2]",
        "begin_line": 294,
        "end_line": 296,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0625,
            "pseudo_dstar_susp": 0.006622516556291391,
            "pseudo_tarantula_susp": 0.002577319587628866,
            "pseudo_op2_susp": 0.006535947712418301,
            "pseudo_barinel_susp": 0.002577319587628866
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.IE_NAME#299",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.IE_NAME(self)",
        "snippet": "    def IE_NAME(self):\n        return type(self).__name__[:-2]",
        "begin_line": 299,
        "end_line": 300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0125,
            "pseudo_dstar_susp": 0.0035714285714285713,
            "pseudo_tarantula_susp": 0.0024509803921568627,
            "pseudo_op2_susp": 0.0035714285714285713,
            "pseudo_barinel_susp": 0.0024509803921568627
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._request_webpage#302",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True)",
        "snippet": "    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True):\n        \"\"\" Returns the response handle \"\"\"\n        if note is None:\n            self.report_download_webpage(video_id)\n        elif note is not False:\n            if video_id is None:\n                self.to_screen('%s' % (note,))\n            else:\n                self.to_screen('%s: %s' % (video_id, note))\n        try:\n            return self._downloader.urlopen(url_or_request)\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            if errnote is False:\n                return False\n            if errnote is None:\n                errnote = 'Unable to download webpage'\n            errmsg = '%s: %s' % (errnote, compat_str(err))\n            if fatal:\n                raise ExtractorError(errmsg, sys.exc_info()[2], cause=err)\n            else:\n                self._downloader.report_warning(errmsg)\n                return False",
        "begin_line": 302,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.3333333333333333,
            "pseudo_dstar_susp": 0.016666666666666666,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.016666666666666666,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_webpage_handle#325",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None)",
        "snippet": "    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None):\n        \"\"\" Returns a tuple (page content as string, URL handle) \"\"\"\n        # Strip hashes from the URL (#1038)\n        if isinstance(url_or_request, (compat_str, str)):\n            url_or_request = url_or_request.partition('#')[0]\n\n        urlh = self._request_webpage(url_or_request, video_id, note, errnote, fatal)\n        if urlh is False:\n            assert not fatal\n            return False\n        content = self._webpage_read_content(urlh, url_or_request, video_id, note, errnote, fatal, encoding=encoding)\n        return (content, urlh)",
        "begin_line": 325,
        "end_line": 336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.014084507042253521,
            "pseudo_dstar_susp": 0.017857142857142856,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.017857142857142856,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._guess_encoding_from_content#339",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._guess_encoding_from_content(content_type, webpage_bytes)",
        "snippet": "    def _guess_encoding_from_content(content_type, webpage_bytes):\n        m = re.match(r'[a-zA-Z0-9_.-]+/[a-zA-Z0-9_.-]+\\s*;\\s*charset=(.+)', content_type)\n        if m:\n            encoding = m.group(1)\n        else:\n            m = re.search(br'<meta[^>]+charset=[\\'\"]?([^\\'\")]+)[ /\\'\">]',\n                          webpage_bytes[:1024])\n            if m:\n                encoding = m.group(1).decode('ascii')\n            elif webpage_bytes.startswith(b'\\xff\\xfe'):\n                encoding = 'utf-16'\n            else:\n                encoding = 'utf-8'\n\n        return encoding",
        "begin_line": 339,
        "end_line": 353,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.011494252873563218,
            "pseudo_dstar_susp": 0.003115264797507788,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.003115264797507788,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._webpage_read_content#355",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True, prefix=None, encoding=None)",
        "snippet": "    def _webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True, prefix=None, encoding=None):\n        content_type = urlh.headers.get('Content-Type', '')\n        webpage_bytes = urlh.read()\n        if prefix is not None:\n            webpage_bytes = prefix + webpage_bytes\n        if not encoding:\n            encoding = self._guess_encoding_from_content(content_type, webpage_bytes)\n        if self._downloader.params.get('dump_intermediate_pages', False):\n            try:\n                url = url_or_request.get_full_url()\n            except AttributeError:\n                url = url_or_request\n            self.to_screen('Dumping request to ' + url)\n            dump = base64.b64encode(webpage_bytes).decode('ascii')\n            self._downloader.to_screen(dump)\n        if self._downloader.params.get('write_pages', False):\n            try:\n                url = url_or_request.get_full_url()\n            except AttributeError:\n                url = url_or_request\n            basen = '%s_%s' % (video_id, url)\n            if len(basen) > 240:\n                h = '___' + hashlib.md5(basen.encode('utf-8')).hexdigest()\n                basen = basen[:240 - len(h)] + h\n            raw_filename = basen + '.dump'\n            filename = sanitize_filename(raw_filename, restricted=True)\n            self.to_screen('Saving request to ' + filename)\n            # Working around MAX_PATH limitation on Windows (see\n            # http://msdn.microsoft.com/en-us/library/windows/desktop/aa365247(v=vs.85).aspx)\n            if os.name == 'nt':\n                absfilepath = os.path.abspath(filename)\n                if len(absfilepath) > 259:\n                    filename = '\\\\\\\\?\\\\' + absfilepath\n            with open(filename, 'wb') as outf:\n                outf.write(webpage_bytes)\n\n        try:\n            content = webpage_bytes.decode(encoding, 'replace')\n        except LookupError:\n            content = webpage_bytes.decode('utf-8', 'replace')\n\n        if ('<title>Access to this site is blocked</title>' in content and\n                'Websense' in content[:512]):\n            msg = 'Access to this webpage has been blocked by Websense filtering software in your network.'\n            blocked_iframe = self._html_search_regex(\n                r'<iframe src=\"([^\"]+)\"', content,\n                'Websense information URL', default=None)\n            if blocked_iframe:\n                msg += ' Visit %s for more details' % blocked_iframe\n            raise ExtractorError(msg, expected=True)\n        if '<title>The URL you requested has been blocked</title>' in content[:512]:\n            msg = (\n                'Access to this webpage has been blocked by Indian censorship. '\n                'Use a VPN or proxy server (with --proxy) to route around it.')\n            block_msg = self._html_search_regex(\n                r'</h1><p>(.*?)</p>',\n                content, 'block message', default=None)\n            if block_msg:\n                msg += ' (Message: \"%s\")' % block_msg.replace('\\n', ' ')\n            raise ExtractorError(msg, expected=True)\n\n        return content",
        "begin_line": 355,
        "end_line": 416,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.014084507042253521,
            "pseudo_dstar_susp": 0.0032679738562091504,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0032679738562091504,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_webpage#418",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None)",
        "snippet": "    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None):\n        \"\"\" Returns the data of the page as a string \"\"\"\n        success = False\n        try_count = 0\n        while success is False:\n            try:\n                res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal, encoding=encoding)\n                success = True\n            except compat_http_client.IncompleteRead as e:\n                try_count += 1\n                if try_count >= tries:\n                    raise e\n                self._sleep(timeout, video_id)\n        if res is False:\n            return res\n        else:\n            content, _ = res\n            return content",
        "begin_line": 418,
        "end_line": 435,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.2,
            "pseudo_dstar_susp": 0.018867924528301886,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.018867924528301886,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_xml#437",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_xml(self, url_or_request, video_id, note='Downloading XML', errnote='Unable to download XML', transform_source=None, fatal=True, encoding=None)",
        "snippet": "    def _download_xml(self, url_or_request, video_id,\n                      note='Downloading XML', errnote='Unable to download XML',\n                      transform_source=None, fatal=True, encoding=None):\n        \"\"\"Return the xml as an xml.etree.ElementTree.Element\"\"\"\n        xml_string = self._download_webpage(\n            url_or_request, video_id, note, errnote, fatal=fatal, encoding=encoding)\n        if xml_string is False:\n            return xml_string\n        if transform_source:\n            xml_string = transform_source(xml_string)\n        return xml.etree.ElementTree.fromstring(xml_string.encode('utf-8'))",
        "begin_line": 437,
        "end_line": 447,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.002512562814070352,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.002512562814070352,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_json#449",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_json(self, url_or_request, video_id, note='Downloading JSON metadata', errnote='Unable to download JSON metadata', transform_source=None, fatal=True, encoding=None)",
        "snippet": "    def _download_json(self, url_or_request, video_id,\n                       note='Downloading JSON metadata',\n                       errnote='Unable to download JSON metadata',\n                       transform_source=None,\n                       fatal=True, encoding=None):\n        json_string = self._download_webpage(\n            url_or_request, video_id, note, errnote, fatal=fatal,\n            encoding=encoding)\n        if (not fatal) and json_string is False:\n            return None\n        return self._parse_json(\n            json_string, video_id, transform_source=transform_source, fatal=fatal)",
        "begin_line": 449,
        "end_line": 460,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.0011627906976744186,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.0011627906976744186,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_json#462",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_json(self, json_string, video_id, transform_source=None, fatal=True)",
        "snippet": "    def _parse_json(self, json_string, video_id, transform_source=None, fatal=True):\n        if transform_source:\n            json_string = transform_source(json_string)\n        try:\n            return json.loads(json_string)\n        except ValueError as ve:\n            errmsg = '%s: Failed to parse JSON ' % video_id\n            if fatal:\n                raise ExtractorError(errmsg, cause=ve)\n            else:\n                self.report_warning(errmsg + str(ve))",
        "begin_line": 462,
        "end_line": 472,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.to_screen#479",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.to_screen(self, msg)",
        "snippet": "    def to_screen(self, msg):\n        \"\"\"Print msg to screen, prefixing it with '[ie_name]'\"\"\"\n        self._downloader.to_screen('[%s] %s' % (self.IE_NAME, msg))",
        "begin_line": 479,
        "end_line": 481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008928571428571428,
            "pseudo_dstar_susp": 0.01639344262295082,
            "pseudo_tarantula_susp": 0.0025575447570332483,
            "pseudo_op2_susp": 0.01639344262295082,
            "pseudo_barinel_susp": 0.0025575447570332483
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_extraction#483",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_extraction(self, id_or_name)",
        "snippet": "    def report_extraction(self, id_or_name):\n        \"\"\"Report information extraction.\"\"\"\n        self.to_screen('%s: Extracting information' % id_or_name)",
        "begin_line": 483,
        "end_line": 485,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.url_result#501",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.url_result(url, ie=None, video_id=None, video_title=None)",
        "snippet": "    def url_result(url, ie=None, video_id=None, video_title=None):\n        \"\"\"Returns a url that points to a page that should be processed\"\"\"\n        # TODO: ie should be the class used for getting the info\n        video_info = {'_type': 'url',\n                      'url': url,\n                      'ie_key': ie}\n        if video_id is not None:\n            video_info['id'] = video_id\n        if video_title is not None:\n            video_info['title'] = video_title\n        return video_info",
        "begin_line": 501,
        "end_line": 511,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008,
            "pseudo_dstar_susp": 0.0007898894154818325,
            "pseudo_tarantula_susp": 0.0010090817356205853,
            "pseudo_op2_susp": 0.0007898894154818325,
            "pseudo_barinel_susp": 0.0010090817356205853
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.playlist_result#514",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.playlist_result(entries, playlist_id=None, playlist_title=None, playlist_description=None)",
        "snippet": "    def playlist_result(entries, playlist_id=None, playlist_title=None, playlist_description=None):\n        \"\"\"Returns a playlist\"\"\"\n        video_info = {'_type': 'playlist',\n                      'entries': entries}\n        if playlist_id:\n            video_info['id'] = playlist_id\n        if playlist_title:\n            video_info['title'] = playlist_title\n        if playlist_description:\n            video_info['description'] = playlist_description\n        return video_info",
        "begin_line": 514,
        "end_line": 524,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._search_regex#526",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0, group=None)",
        "snippet": "    def _search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0, group=None):\n        \"\"\"\n        Perform a regex search on the given string, using a single or a list of\n        patterns returning the first matching group.\n        In case of failure return a default value or raise a WARNING or a\n        RegexNotFoundError, depending on fatal, specifying the field name.\n        \"\"\"\n        if isinstance(pattern, (str, compat_str, compiled_regex_type)):\n            mobj = re.search(pattern, string, flags)\n        else:\n            for p in pattern:\n                mobj = re.search(p, string, flags)\n                if mobj:\n                    break\n\n        if not self._downloader.params.get('no_color') and os.name != 'nt' and sys.stderr.isatty():\n            _name = '\\033[0;34m%s\\033[0m' % name\n        else:\n            _name = name\n\n        if mobj:\n            if group is None:\n                # return the first matching group\n                return next(g for g in mobj.groups() if g is not None)\n            else:\n                return mobj.group(group)\n        elif default is not _NO_DEFAULT:\n            return default\n        elif fatal:\n            raise RegexNotFoundError('Unable to extract %s' % _name)\n        else:\n            self._downloader.report_warning('unable to extract %s' % _name + bug_reports_message())\n            return None",
        "begin_line": 526,
        "end_line": 558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.009615384615384616,
            "pseudo_dstar_susp": 0.002881844380403458,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.002881844380403458,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._html_search_regex#560",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._html_search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0, group=None)",
        "snippet": "    def _html_search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0, group=None):\n        \"\"\"\n        Like _search_regex, but strips HTML tags and unescapes entities.\n        \"\"\"\n        res = self._search_regex(pattern, string, name, default, fatal, flags, group)\n        if res:\n            return clean_html(res).strip()\n        else:\n            return res",
        "begin_line": 560,
        "end_line": 568,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009852216748768472,
            "pseudo_dstar_susp": 0.0008539709649871904,
            "pseudo_tarantula_susp": 0.001567398119122257,
            "pseudo_op2_susp": 0.0008539709649871904,
            "pseudo_barinel_susp": 0.0015552099533437014
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_login_info#570",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_login_info(self)",
        "snippet": "    def _get_login_info(self):\n        \"\"\"\n        Get the login info as (username, password)\n        It will look in the netrc file using the _NETRC_MACHINE value\n        If there's no info available, return (None, None)\n        \"\"\"\n        if self._downloader is None:\n            return (None, None)\n\n        username = None\n        password = None\n        downloader_params = self._downloader.params\n\n        # Attempt to use provided username and password or .netrc data\n        if downloader_params.get('username', None) is not None:\n            username = downloader_params['username']\n            password = downloader_params['password']\n        elif downloader_params.get('usenetrc', False):\n            try:\n                info = netrc.netrc().authenticators(self._NETRC_MACHINE)\n                if info is not None:\n                    username = info[0]\n                    password = info[2]\n                else:\n                    raise netrc.NetrcParseError('No authenticators for %s' % self._NETRC_MACHINE)\n            except (IOError, netrc.NetrcParseError) as err:\n                self._downloader.report_warning('parsing .netrc: %s' % compat_str(err))\n\n        return (username, password)",
        "begin_line": 570,
        "end_line": 598,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02702702702702703,
            "pseudo_dstar_susp": 0.0038461538461538464,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0038461538461538464,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_regexes#618",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_regexes(prop)",
        "snippet": "    def _og_regexes(prop):\n        content_re = r'content=(?:\"([^>]+?)\"|\\'([^>]+?)\\')'\n        property_re = r'(?:name|property)=[\\'\"]og:%s[\\'\"]' % re.escape(prop)\n        template = r'<meta[^>]+?%s[^>]+?%s'\n        return [\n            template % (property_re, content_re),\n            template % (content_re, property_re),\n        ]",
        "begin_line": 618,
        "end_line": 625,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0014124293785310734,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.0014124293785310734,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_property#627",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_property(self, prop, html, name=None, **kargs)",
        "snippet": "    def _og_search_property(self, prop, html, name=None, **kargs):\n        if name is None:\n            name = 'OpenGraph %s' % prop\n        escaped = self._search_regex(self._og_regexes(prop), html, name, flags=re.DOTALL, **kargs)\n        if escaped is None:\n            return None\n        return unescapeHTML(escaped)",
        "begin_line": 627,
        "end_line": 633,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0014124293785310734,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.0014124293785310734,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_thumbnail#635",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_thumbnail(self, html, **kargs)",
        "snippet": "    def _og_search_thumbnail(self, html, **kargs):\n        return self._og_search_property('image', html, 'thumbnail url', fatal=False, **kargs)",
        "begin_line": 635,
        "end_line": 636,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_description#638",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_description(self, html, **kargs)",
        "snippet": "    def _og_search_description(self, html, **kargs):\n        return self._og_search_property('description', html, fatal=False, **kargs)",
        "begin_line": 638,
        "end_line": 639,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.0008904719501335708,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.0008904719501335708,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_title#641",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_title(self, html, **kargs)",
        "snippet": "    def _og_search_title(self, html, **kargs):\n        return self._og_search_property('title', html, **kargs)",
        "begin_line": 641,
        "end_line": 642,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._html_search_meta#653",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._html_search_meta(self, name, html, display_name=None, fatal=False, **kwargs)",
        "snippet": "    def _html_search_meta(self, name, html, display_name=None, fatal=False, **kwargs):\n        if display_name is None:\n            display_name = name\n        return self._html_search_regex(\n            r'''(?isx)<meta\n                    (?=[^>]+(?:itemprop|name|property)=([\"\\']?)%s\\1)\n                    [^>]+?content=([\"\\'])(?P<content>.*?)\\2''' % re.escape(name),\n            html, display_name, fatal=fatal, group='content', **kwargs)",
        "begin_line": 653,
        "end_line": 660,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.0008904719501335708,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.0008904719501335708,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._rta_search#665",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._rta_search(self, html)",
        "snippet": "    def _rta_search(self, html):\n        # See http://www.rtalabel.org/index.php?content=howtofaq#single\n        if re.search(r'(?ix)<meta\\s+name=\"rating\"\\s+'\n                     r'     content=\"RTA-5042-1996-1400-1577-RTA\"',\n                     html):\n            return 18\n        return 0",
        "begin_line": 665,
        "end_line": 671,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._sort_formats#708",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._sort_formats(self, formats, field_preference=None)",
        "snippet": "    def _sort_formats(self, formats, field_preference=None):\n        if not formats:\n            raise ExtractorError('No video formats found')\n\n        def _formats_key(f):\n            # TODO remove the following workaround\n            from ..utils import determine_ext\n            if not f.get('ext') and 'url' in f:\n                f['ext'] = determine_ext(f['url'])\n\n            if isinstance(field_preference, (list, tuple)):\n                return tuple(f.get(field) if f.get(field) is not None else -1 for field in field_preference)\n\n            preference = f.get('preference')\n            if preference is None:\n                proto = f.get('protocol')\n                if proto is None:\n                    proto = compat_urllib_parse_urlparse(f.get('url', '')).scheme\n\n                preference = 0 if proto in ['http', 'https'] else -0.1\n                if f.get('ext') in ['f4f', 'f4m']:  # Not yet supported\n                    preference -= 0.5\n\n            if f.get('vcodec') == 'none':  # audio only\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['aac', 'mp3', 'm4a', 'webm', 'ogg', 'opus']\n                else:\n                    ORDER = ['webm', 'opus', 'ogg', 'mp3', 'aac', 'm4a']\n                ext_preference = 0\n                try:\n                    audio_ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    audio_ext_preference = -1\n            else:\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['flv', 'mp4', 'webm']\n                else:\n                    ORDER = ['webm', 'flv', 'mp4']\n                try:\n                    ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    ext_preference = -1\n                audio_ext_preference = 0\n\n            return (\n                preference,\n                f.get('language_preference') if f.get('language_preference') is not None else -1,\n                f.get('quality') if f.get('quality') is not None else -1,\n                f.get('tbr') if f.get('tbr') is not None else -1,\n                f.get('filesize') if f.get('filesize') is not None else -1,\n                f.get('vbr') if f.get('vbr') is not None else -1,\n                f.get('height') if f.get('height') is not None else -1,\n                f.get('width') if f.get('width') is not None else -1,\n                ext_preference,\n                f.get('abr') if f.get('abr') is not None else -1,\n                audio_ext_preference,\n                f.get('fps') if f.get('fps') is not None else -1,\n                f.get('filesize_approx') if f.get('filesize_approx') is not None else -1,\n                f.get('source_preference') if f.get('source_preference') is not None else -1,\n                f.get('format_id') if f.get('format_id') is not None else '',\n            )\n        formats.sort(key=_formats_key)",
        "begin_line": 708,
        "end_line": 769,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._formats_key#712",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._formats_key(f)",
        "snippet": "        def _formats_key(f):\n            # TODO remove the following workaround\n            from ..utils import determine_ext\n            if not f.get('ext') and 'url' in f:\n                f['ext'] = determine_ext(f['url'])\n\n            if isinstance(field_preference, (list, tuple)):\n                return tuple(f.get(field) if f.get(field) is not None else -1 for field in field_preference)\n\n            preference = f.get('preference')\n            if preference is None:\n                proto = f.get('protocol')\n                if proto is None:\n                    proto = compat_urllib_parse_urlparse(f.get('url', '')).scheme\n\n                preference = 0 if proto in ['http', 'https'] else -0.1\n                if f.get('ext') in ['f4f', 'f4m']:  # Not yet supported\n                    preference -= 0.5\n\n            if f.get('vcodec') == 'none':  # audio only\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['aac', 'mp3', 'm4a', 'webm', 'ogg', 'opus']\n                else:\n                    ORDER = ['webm', 'opus', 'ogg', 'mp3', 'aac', 'm4a']\n                ext_preference = 0\n                try:\n                    audio_ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    audio_ext_preference = -1\n            else:\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['flv', 'mp4', 'webm']\n                else:\n                    ORDER = ['webm', 'flv', 'mp4']\n                try:\n                    ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    ext_preference = -1\n                audio_ext_preference = 0\n\n            return (\n                preference,\n                f.get('language_preference') if f.get('language_preference') is not None else -1,\n                f.get('quality') if f.get('quality') is not None else -1,\n                f.get('tbr') if f.get('tbr') is not None else -1,\n                f.get('filesize') if f.get('filesize') is not None else -1,\n                f.get('vbr') if f.get('vbr') is not None else -1,\n                f.get('height') if f.get('height') is not None else -1,\n                f.get('width') if f.get('width') is not None else -1,\n                ext_preference,\n                f.get('abr') if f.get('abr') is not None else -1,\n                audio_ext_preference,\n                f.get('fps') if f.get('fps') is not None else -1,\n                f.get('filesize_approx') if f.get('filesize_approx') is not None else -1,\n                f.get('source_preference') if f.get('source_preference') is not None else -1,\n                f.get('format_id') if f.get('format_id') is not None else '',\n            )",
        "begin_line": 712,
        "end_line": 768,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._is_valid_url#779",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._is_valid_url(self, url, video_id, item='video')",
        "snippet": "    def _is_valid_url(self, url, video_id, item='video'):\n        url = self._proto_relative_url(url, scheme='http:')\n        # For now assume non HTTP(S) URLs always valid\n        if not (url.startswith('http://') or url.startswith('https://')):\n            return True\n        try:\n            self._request_webpage(url, video_id, 'Checking %s URL' % item)\n            return True\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError):\n                self.to_screen(\n                    '%s: %s URL is invalid, skipping' % (video_id, item))\n                return False\n            raise",
        "begin_line": 779,
        "end_line": 792,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.http_scheme#794",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.http_scheme(self)",
        "snippet": "    def http_scheme(self):\n        \"\"\" Either \"http:\" or \"https:\", depending on the user's preferences \"\"\"\n        return (\n            'http:'\n            if self._downloader.params.get('prefer_insecure', False)\n            else 'https:')",
        "begin_line": 794,
        "end_line": 799,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_f4m_formats#818",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_f4m_formats(self, manifest_url, video_id, preference=None, f4m_id=None)",
        "snippet": "    def _extract_f4m_formats(self, manifest_url, video_id, preference=None, f4m_id=None):\n        manifest = self._download_xml(\n            manifest_url, video_id, 'Downloading f4m manifest',\n            'Unable to download f4m manifest')\n\n        formats = []\n        manifest_version = '1.0'\n        media_nodes = manifest.findall('{http://ns.adobe.com/f4m/1.0}media')\n        if not media_nodes:\n            manifest_version = '2.0'\n            media_nodes = manifest.findall('{http://ns.adobe.com/f4m/2.0}media')\n        for i, media_el in enumerate(media_nodes):\n            if manifest_version == '2.0':\n                manifest_url = ('/'.join(manifest_url.split('/')[:-1]) + '/' +\n                                (media_el.attrib.get('href') or media_el.attrib.get('url')))\n            tbr = int_or_none(media_el.attrib.get('bitrate'))\n            formats.append({\n                'format_id': '-'.join(filter(None, [f4m_id, compat_str(i if tbr is None else tbr)])),\n                'url': manifest_url,\n                'ext': 'flv',\n                'tbr': tbr,\n                'width': int_or_none(media_el.attrib.get('width')),\n                'height': int_or_none(media_el.attrib.get('height')),\n                'preference': preference,\n            })\n        self._sort_formats(formats)\n\n        return formats",
        "begin_line": 818,
        "end_line": 845,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_m3u8_formats#847",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_m3u8_formats(self, m3u8_url, video_id, ext=None, entry_protocol='m3u8', preference=None, m3u8_id=None, note=None, errnote=None)",
        "snippet": "    def _extract_m3u8_formats(self, m3u8_url, video_id, ext=None,\n                              entry_protocol='m3u8', preference=None,\n                              m3u8_id=None, note=None, errnote=None):\n\n        formats = [{\n            'format_id': '-'.join(filter(None, [m3u8_id, 'meta'])),\n            'url': m3u8_url,\n            'ext': ext,\n            'protocol': 'm3u8',\n            'preference': preference - 1 if preference else -1,\n            'resolution': 'multiple',\n            'format_note': 'Quality selection URL',\n        }]\n\n        format_url = lambda u: (\n            u\n            if re.match(r'^https?://', u)\n            else compat_urlparse.urljoin(m3u8_url, u))\n\n        m3u8_doc = self._download_webpage(\n            m3u8_url, video_id,\n            note=note or 'Downloading m3u8 information',\n            errnote=errnote or 'Failed to download m3u8 information')\n        last_info = None\n        last_media = None\n        kv_rex = re.compile(\n            r'(?P<key>[a-zA-Z_-]+)=(?P<val>\"[^\"]+\"|[^\",]+)(?:,|$)')\n        for line in m3u8_doc.splitlines():\n            if line.startswith('#EXT-X-STREAM-INF:'):\n                last_info = {}\n                for m in kv_rex.finditer(line):\n                    v = m.group('val')\n                    if v.startswith('\"'):\n                        v = v[1:-1]\n                    last_info[m.group('key')] = v\n            elif line.startswith('#EXT-X-MEDIA:'):\n                last_media = {}\n                for m in kv_rex.finditer(line):\n                    v = m.group('val')\n                    if v.startswith('\"'):\n                        v = v[1:-1]\n                    last_media[m.group('key')] = v\n            elif line.startswith('#') or not line.strip():\n                continue\n            else:\n                if last_info is None:\n                    formats.append({'url': format_url(line)})\n                    continue\n                tbr = int_or_none(last_info.get('BANDWIDTH'), scale=1000)\n                format_id = []\n                if m3u8_id:\n                    format_id.append(m3u8_id)\n                last_media_name = last_media.get('NAME') if last_media and last_media.get('TYPE') != 'SUBTITLES' else None\n                format_id.append(last_media_name if last_media_name else '%d' % (tbr if tbr else len(formats)))\n                f = {\n                    'format_id': '-'.join(format_id),\n                    'url': format_url(line.strip()),\n                    'tbr': tbr,\n                    'ext': ext,\n                    'protocol': entry_protocol,\n                    'preference': preference,\n                }\n                codecs = last_info.get('CODECS')\n                if codecs:\n                    # TODO: looks like video codec is not always necessarily goes first\n                    va_codecs = codecs.split(',')\n                    if va_codecs[0]:\n                        f['vcodec'] = va_codecs[0].partition('.')[0]\n                    if len(va_codecs) > 1 and va_codecs[1]:\n                        f['acodec'] = va_codecs[1].partition('.')[0]\n                resolution = last_info.get('RESOLUTION')\n                if resolution:\n                    width_str, height_str = resolution.split('x')\n                    f['width'] = int(width_str)\n                    f['height'] = int(height_str)\n                if last_media is not None:\n                    f['m3u8_media'] = last_media\n                    last_media = None\n                formats.append(f)\n                last_info = {}\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 847,
        "end_line": 928,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_smil_formats#931",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_smil_formats(self, smil_url, video_id, fatal=True)",
        "snippet": "    def _extract_smil_formats(self, smil_url, video_id, fatal=True):\n        smil = self._download_xml(\n            smil_url, video_id, 'Downloading SMIL file',\n            'Unable to download SMIL file', fatal=fatal)\n        if smil is False:\n            assert not fatal\n            return []\n\n        base = smil.find('./head/meta').get('base')\n\n        formats = []\n        rtmp_count = 0\n        if smil.findall('./body/seq/video'):\n            video = smil.findall('./body/seq/video')[0]\n            fmts, rtmp_count = self._parse_smil_video(video, video_id, base, rtmp_count)\n            formats.extend(fmts)\n        else:\n            for video in smil.findall('./body/switch/video'):\n                fmts, rtmp_count = self._parse_smil_video(video, video_id, base, rtmp_count)\n                formats.extend(fmts)\n\n        self._sort_formats(formats)\n\n        return formats",
        "begin_line": 931,
        "end_line": 954,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_smil_video#956",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_smil_video(self, video, video_id, base, rtmp_count)",
        "snippet": "    def _parse_smil_video(self, video, video_id, base, rtmp_count):\n        src = video.get('src')\n        if not src:\n            return ([], rtmp_count)\n        bitrate = int_or_none(video.get('system-bitrate') or video.get('systemBitrate'), 1000)\n        width = int_or_none(video.get('width'))\n        height = int_or_none(video.get('height'))\n        proto = video.get('proto')\n        if not proto:\n            if base:\n                if base.startswith('rtmp'):\n                    proto = 'rtmp'\n                elif base.startswith('http'):\n                    proto = 'http'\n        ext = video.get('ext')\n        if proto == 'm3u8':\n            return (self._extract_m3u8_formats(src, video_id, ext), rtmp_count)\n        elif proto == 'rtmp':\n            rtmp_count += 1\n            streamer = video.get('streamer') or base\n            return ([{\n                'url': streamer,\n                'play_path': src,\n                'ext': 'flv',\n                'format_id': 'rtmp-%d' % (rtmp_count if bitrate is None else bitrate),\n                'tbr': bitrate,\n                'width': width,\n                'height': height,\n            }], rtmp_count)\n        elif proto.startswith('http'):\n            return ([{\n                'url': base + src,\n                'ext': ext or 'flv',\n                'tbr': bitrate,\n                'width': width,\n                'height': height,\n            }], rtmp_count)",
        "begin_line": 956,
        "end_line": 992,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._live_title#994",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._live_title(self, name)",
        "snippet": "    def _live_title(self, name):\n        \"\"\" Generate the title for a live video \"\"\"\n        now = datetime.datetime.now()\n        now_str = now.strftime(\"%Y-%m-%d %H:%M\")\n        return name + ' ' + now_str",
        "begin_line": 994,
        "end_line": 998,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._int#1000",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._int(self, v, name, fatal=False, **kwargs)",
        "snippet": "    def _int(self, v, name, fatal=False, **kwargs):\n        res = int_or_none(v, **kwargs)\n        if 'get_attr' in kwargs:\n            print(getattr(v, kwargs['get_attr']))\n        if res is None:\n            msg = 'Failed to extract %s: Could not parse value %r' % (name, v)\n            if fatal:\n                raise ExtractorError(msg)\n            else:\n                self._downloader.report_warning(msg)\n        return res",
        "begin_line": 1000,
        "end_line": 1010,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._float#1012",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._float(self, v, name, fatal=False, **kwargs)",
        "snippet": "    def _float(self, v, name, fatal=False, **kwargs):\n        res = float_or_none(v, **kwargs)\n        if res is None:\n            msg = 'Failed to extract %s: Could not parse value %r' % (name, v)\n            if fatal:\n                raise ExtractorError(msg)\n            else:\n                self._downloader.report_warning(msg)\n        return res",
        "begin_line": 1012,
        "end_line": 1020,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._set_cookie#1022",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._set_cookie(self, domain, name, value, expire_time=None)",
        "snippet": "    def _set_cookie(self, domain, name, value, expire_time=None):\n        cookie = compat_cookiejar.Cookie(\n            0, name, value, None, None, domain, None,\n            None, '/', True, False, expire_time, '', None, None, None)\n        self._downloader.cookiejar.set_cookie(cookie)",
        "begin_line": 1022,
        "end_line": 1026,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004081632653061225,
            "pseudo_dstar_susp": 0.0029850746268656717,
            "pseudo_tarantula_susp": 0.0016556291390728477,
            "pseudo_op2_susp": 0.0029850746268656717,
            "pseudo_barinel_susp": 0.0016556291390728477
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.get_testcases#1028",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.get_testcases(self, include_onlymatching=False)",
        "snippet": "    def get_testcases(self, include_onlymatching=False):\n        t = getattr(self, '_TEST', None)\n        if t:\n            assert not hasattr(self, '_TESTS'), \\\n                '%s has _TEST and _TESTS' % type(self).__name__\n            tests = [t]\n        else:\n            tests = getattr(self, '_TESTS', [])\n        for t in tests:\n            if not include_onlymatching and t.get('only_matching', False):\n                continue\n            t['name'] = type(self).__name__[:-len('IE')]\n            yield t",
        "begin_line": 1028,
        "end_line": 1040,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.is_suitable#1042",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.is_suitable(self, age_limit)",
        "snippet": "    def is_suitable(self, age_limit):\n        \"\"\" Test whether the extractor is generally suitable for the given\n        age limit (i.e. pornographic sites are not, all others usually are) \"\"\"\n\n        any_restricted = False\n        for tc in self.get_testcases(include_onlymatching=False):\n            if 'playlist' in tc:\n                tc = tc['playlist'][0]\n            is_restricted = age_restricted(\n                tc.get('info_dict', {}).get('age_limit'), age_limit)\n            if not is_restricted:\n                return True\n            any_restricted = any_restricted or is_restricted\n        return not any_restricted",
        "begin_line": 1042,
        "end_line": 1055,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract_subtitles#1057",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract_subtitles(self, *args, **kwargs)",
        "snippet": "    def extract_subtitles(self, *args, **kwargs):\n        if (self._downloader.params.get('writesubtitles', False) or\n                self._downloader.params.get('listsubtitles')):\n            return self._get_subtitles(*args, **kwargs)\n        return {}",
        "begin_line": 1057,
        "end_line": 1061,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_subtitles#1063",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_subtitles(self, *args, **kwargs)",
        "snippet": "    def _get_subtitles(self, *args, **kwargs):\n        raise NotImplementedError(\"This method must be implemented by subclasses\")",
        "begin_line": 1063,
        "end_line": 1064,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract_automatic_captions#1066",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract_automatic_captions(self, *args, **kwargs)",
        "snippet": "    def extract_automatic_captions(self, *args, **kwargs):\n        if (self._downloader.params.get('writeautomaticsub', False) or\n                self._downloader.params.get('listsubtitles')):\n            return self._get_automatic_captions(*args, **kwargs)\n        return {}",
        "begin_line": 1066,
        "end_line": 1070,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_automatic_captions#1072",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_automatic_captions(self, *args, **kwargs)",
        "snippet": "    def _get_automatic_captions(self, *args, **kwargs):\n        raise NotImplementedError(\"This method must be implemented by subclasses\")",
        "begin_line": 1072,
        "end_line": 1073,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._make_valid_url#1084",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._make_valid_url(cls)",
        "snippet": "    def _make_valid_url(cls):\n        return r'%s(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' % cls._SEARCH_KEY",
        "begin_line": 1084,
        "end_line": 1085,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000774593338497289,
            "pseudo_dstar_susp": 0.002277904328018223,
            "pseudo_tarantula_susp": 0.000774593338497289,
            "pseudo_op2_susp": 0.002277904328018223,
            "pseudo_barinel_susp": 0.000774593338497289
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor.suitable#1088",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return re.match(cls._make_valid_url(), url) is not None",
        "begin_line": 1088,
        "end_line": 1089,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000774593338497289,
            "pseudo_dstar_susp": 0.002277904328018223,
            "pseudo_tarantula_susp": 0.000774593338497289,
            "pseudo_op2_susp": 0.002277904328018223,
            "pseudo_barinel_susp": 0.000774593338497289
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._real_extract#1091",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._real_extract(self, query)",
        "snippet": "    def _real_extract(self, query):\n        mobj = re.match(self._make_valid_url(), query)\n        if mobj is None:\n            raise ExtractorError('Invalid search query \"%s\"' % query)\n\n        prefix = mobj.group('prefix')\n        query = mobj.group('query')\n        if prefix == '':\n            return self._get_n_results(query, 1)\n        elif prefix == 'all':\n            return self._get_n_results(query, self._MAX_RESULTS)\n        else:\n            n = int(prefix)\n            if n <= 0:\n                raise ExtractorError('invalid download number %s for query \"%s\"' % (n, query))\n            elif n > self._MAX_RESULTS:\n                self._downloader.report_warning('%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))\n                n = self._MAX_RESULTS\n            return self._get_n_results(query, n)",
        "begin_line": 1091,
        "end_line": 1109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._get_n_results#1111",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n        raise NotImplementedError(\"This method must be implemented by subclasses\")",
        "begin_line": 1111,
        "end_line": 1113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._real_extract#183",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = url_basename(url)\n        webpage = self._download_webpage(url, title)\n        try:\n            # the url can be http://media.mtvnservices.com/fb/{mgid}.swf\n            # or http://media.mtvnservices.com/{mgid}\n            og_url = self._og_search_video_url(webpage)\n            mgid = url_basename(og_url)\n            if mgid.endswith('.swf'):\n                mgid = mgid[:-4]\n        except RegexNotFoundError:\n            mgid = None\n\n        if mgid is None or ':' not in mgid:\n            mgid = self._search_regex(\n                [r'data-mgid=\"(.*?)\"', r'swfobject.embedSWF\\(\".*?(mgid:.*?)\"'],\n                webpage, 'mgid')\n\n        videos_info = self._get_videos_info(mgid)\n        return videos_info",
        "begin_line": 183,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025207965717166626,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVIE._real_extract#260",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVIE",
        "signature": "youtube_dl.extractor.mtv.MTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        uri = mobj.groupdict().get('mgid')\n        if uri is None:\n            webpage = self._download_webpage(url, video_id)\n\n            # Some videos come from Vevo.com\n            m_vevo = re.search(\n                r'(?s)isVevoVideo = true;.*?vevoVideoId = \"(.*?)\";', webpage)\n            if m_vevo:\n                vevo_id = m_vevo.group(1)\n                self.to_screen('Vevo video detected: %s' % vevo_id)\n                return self.url_result('vevo:%s' % vevo_id, ie='Vevo')\n\n            uri = self._html_search_regex(r'/uri/(.*?)\\?', webpage, 'uri')\n        return self._get_videos_info(uri)",
        "begin_line": 260,
        "end_line": 276,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._real_extract#251",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        id = mobj.group('id')\n        user = mobj.group('user')\n        url_type = mobj.group('type')\n        if url_type == 'folder':\n            return self._extract_folder(url, id)\n        else:\n            return self._extract_video(user, id)",
        "begin_line": 251,
        "end_line": 259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00039635354736424893,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamShortenerIE._real_extract#269",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamShortenerIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamShortenerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        id = mobj.group('id')\n        webpage = self._download_webpage(url, id)\n\n        return {\n            '_type': 'url',\n            'url': self._og_search_url(webpage),\n        }",
        "begin_line": 269,
        "end_line": 277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyCourseIE.suitable#162",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyCourseIE",
        "signature": "youtube_dl.extractor.udemy.UdemyCourseIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if UdemyIE.suitable(url) else super(UdemyCourseIE, cls).suitable(url)",
        "begin_line": 162,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011173184357541898,
            "pseudo_dstar_susp": 0.0018726591760299626,
            "pseudo_tarantula_susp": 0.0011876484560570072,
            "pseudo_op2_susp": 0.0018726591760299626,
            "pseudo_barinel_susp": 0.0011876484560570072
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyCourseIE._real_extract#165",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyCourseIE",
        "signature": "youtube_dl.extractor.udemy.UdemyCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_path = mobj.group('coursepath')\n\n        response = self._download_json(\n            'https://www.udemy.com/api-1.1/courses/%s' % course_path,\n            course_path, 'Downloading course JSON')\n\n        course_id = int(response['id'])\n        course_title = response['title']\n\n        webpage = self._download_webpage(\n            'https://www.udemy.com/course/subscribe/?courseId=%s' % course_id,\n            course_id, 'Enrolling in the course')\n\n        if self._SUCCESSFULLY_ENROLLED in webpage:\n            self.to_screen('%s: Successfully enrolled in' % course_id)\n        elif self._ALREADY_ENROLLED in webpage:\n            self.to_screen('%s: Already enrolled in' % course_id)\n\n        response = self._download_json(\n            'https://www.udemy.com/api-1.1/courses/%s/curriculum' % course_id,\n            course_id, 'Downloading course curriculum')\n\n        entries = [\n            self.url_result(\n                'https://www.udemy.com/%s/#/lecture/%s' % (course_path, asset['id']), 'Udemy')\n            for asset in response if asset.get('assetType') or asset.get('asset_type') == 'Video'\n        ]\n\n        return self.playlist_result(entries, course_id, course_title)",
        "begin_line": 165,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025106703489831785,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVVideoIE._real_extract#92",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVVideoIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        player_params = self._parse_json(self._search_regex(\n            r'var\\s+bridge\\s*=\\s*([^;]+);', webpage, 'player parameters'),\n            video_id)\n\n        formats = [{\n            'url': source['src'],\n            'width': source.get('width'),\n            'height': source.get('height'),\n            'tbr': source.get('bitrate'),\n        } for source in player_params['sources']]\n\n        # For both metadata and downloaded files the duration varies among\n        # formats. I just pick the max one\n        duration = max(filter(None, [\n            float_or_none(source.get('duration'), scale=1000)\n            for source in player_params['sources']]))\n\n        subtitles = {}\n        for translation in player_params.get('translations', []):\n            lang_id = translation.get('language_w3c') or ISO639Utils.long2short(translation['language_medium'])\n            if lang_id not in subtitles:\n                subtitles[lang_id] = []\n            subtitles[lang_id].append({\n                'url': translation['vttPath'],\n                'ext': 'vtt',\n            })\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': player_params['title'],\n            'description': self._og_search_description(webpage),\n            'duration': duration,\n            'subtitles': subtitles,\n        }",
        "begin_line": 92,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014534883720930232,
            "pseudo_dstar_susp": 0.0025188916876574307,
            "pseudo_tarantula_susp": 0.0012165450121654502,
            "pseudo_op2_susp": 0.0025188916876574307,
            "pseudo_barinel_susp": 0.0012165450121654502
        }
    },
    {
        "name": "youtube_dl.options.parseOpts#22",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options.parseOpts(overrideArguments=None)",
        "snippet": "def parseOpts(overrideArguments=None):\n    def _readOptions(filename_bytes, default=[]):\n        try:\n            optionf = open(filename_bytes)\n        except IOError:\n            return default  # silently skip if file is not present\n        try:\n            res = []\n            for l in optionf:\n                res += shlex.split(l, comments=True)\n        finally:\n            optionf.close()\n        return res\n\n    def _readUserConf():\n        xdg_config_home = compat_getenv('XDG_CONFIG_HOME')\n        if xdg_config_home:\n            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')\n        else:\n            userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl.conf')\n        userConf = _readOptions(userConfFile, None)\n\n        if userConf is None:\n            appdata_dir = compat_getenv('appdata')\n            if appdata_dir:\n                userConf = _readOptions(\n                    os.path.join(appdata_dir, 'youtube-dl', 'config'),\n                    default=None)\n                if userConf is None:\n                    userConf = _readOptions(\n                        os.path.join(appdata_dir, 'youtube-dl', 'config.txt'),\n                        default=None)\n\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(compat_expanduser('~'), 'youtube-dl.conf'),\n                default=None)\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(compat_expanduser('~'), 'youtube-dl.conf.txt'),\n                default=None)\n\n        if userConf is None:\n            userConf = []\n\n        return userConf\n\n    def _format_option_string(option):\n        ''' ('-o', '--option') -> -o, --format METAVAR'''\n\n        opts = []\n\n        if option._short_opts:\n            opts.append(option._short_opts[0])\n        if option._long_opts:\n            opts.append(option._long_opts[0])\n        if len(opts) > 1:\n            opts.insert(1, ', ')\n\n        if option.takes_value():\n            opts.append(' %s' % option.metavar)\n\n        return \"\".join(opts)\n\n    def _comma_separated_values_options_callback(option, opt_str, value, parser):\n        setattr(parser.values, option.dest, value.split(','))\n\n    def _hide_login_info(opts):\n        opts = list(opts)\n        for private_opt in ['-p', '--password', '-u', '--username', '--video-password']:\n            try:\n                i = opts.index(private_opt)\n                opts[i + 1] = 'PRIVATE'\n            except ValueError:\n                pass\n        return opts\n\n    # No need to wrap help messages if we're on a wide console\n    columns = compat_get_terminal_size().columns\n    max_width = columns if columns else 80\n    max_help_position = 80\n\n    fmt = optparse.IndentedHelpFormatter(width=max_width, max_help_position=max_help_position)\n    fmt.format_option_strings = _format_option_string\n\n    kw = {\n        'version': __version__,\n        'formatter': fmt,\n        'usage': '%prog [OPTIONS] URL [URL...]',\n        'conflict_handler': 'resolve',\n    }\n\n    parser = optparse.OptionParser(**compat_kwargs(kw))\n\n    general = optparse.OptionGroup(parser, 'General Options')\n    general.add_option(\n        '-h', '--help',\n        action='help',\n        help='Print this help text and exit')\n    general.add_option(\n        '-v', '--version',\n        action='version',\n        help='Print program version and exit')\n    general.add_option(\n        '-U', '--update',\n        action='store_true', dest='update_self',\n        help='Update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')\n    general.add_option(\n        '-i', '--ignore-errors',\n        action='store_true', dest='ignoreerrors', default=False,\n        help='Continue on download errors, for example to skip unavailable videos in a playlist')\n    general.add_option(\n        '--abort-on-error',\n        action='store_false', dest='ignoreerrors',\n        help='Abort downloading of further videos (in the playlist or the command line) if an error occurs')\n    general.add_option(\n        '--dump-user-agent',\n        action='store_true', dest='dump_user_agent', default=False,\n        help='Display the current browser identification')\n    general.add_option(\n        '--list-extractors',\n        action='store_true', dest='list_extractors', default=False,\n        help='List all supported extractors')\n    general.add_option(\n        '--extractor-descriptions',\n        action='store_true', dest='list_extractor_descriptions', default=False,\n        help='Output descriptions of all supported extractors')\n    general.add_option(\n        '--force-generic-extractor',\n        action='store_true', dest='force_generic_extractor', default=False,\n        help='Force extraction to use the generic extractor')\n    general.add_option(\n        '--default-search',\n        dest='default_search', metavar='PREFIX',\n        help='Use this prefix for unqualified URLs. For example \"gvsearch2:\" downloads two videos from google videos for youtube-dl \"large apple\". Use the value \"auto\" to let youtube-dl guess (\"auto_warning\" to emit a warning when guessing). \"error\" just throws an error. The default value \"fixup_error\" repairs broken URLs, but emits an error if this is not possible instead of searching.')\n    general.add_option(\n        '--ignore-config',\n        action='store_true',\n        help='Do not read configuration files. '\n        'When given in the global configuration file /etc/youtube-dl.conf: '\n        'Do not read the user configuration in ~/.config/youtube-dl/config '\n        '(%APPDATA%/youtube-dl/config.txt on Windows)')\n    general.add_option(\n        '--flat-playlist',\n        action='store_const', dest='extract_flat', const='in_playlist',\n        default=False,\n        help='Do not extract the videos of a playlist, only list them.')\n    general.add_option(\n        '--no-color', '--no-colors',\n        action='store_true', dest='no_color',\n        default=False,\n        help='Do not emit color codes in output')\n\n    network = optparse.OptionGroup(parser, 'Network Options')\n    network.add_option(\n        '--proxy', dest='proxy',\n        default=None, metavar='URL',\n        help='Use the specified HTTP/HTTPS proxy. Pass in an empty string (--proxy \"\") for direct connection')\n    network.add_option(\n        '--socket-timeout',\n        dest='socket_timeout', type=float, default=None, metavar='SECONDS',\n        help='Time to wait before giving up, in seconds')\n    network.add_option(\n        '--source-address',\n        metavar='IP', dest='source_address', default=None,\n        help='Client-side IP address to bind to (experimental)',\n    )\n    network.add_option(\n        '-4', '--force-ipv4',\n        action='store_const', const='0.0.0.0', dest='source_address',\n        help='Make all connections via IPv4 (experimental)',\n    )\n    network.add_option(\n        '-6', '--force-ipv6',\n        action='store_const', const='::', dest='source_address',\n        help='Make all connections via IPv6 (experimental)',\n    )\n    network.add_option(\n        '--cn-verification-proxy',\n        dest='cn_verification_proxy', default=None, metavar='URL',\n        help='Use this proxy to verify the IP address for some Chinese sites. '\n        'The default proxy specified by --proxy (or none, if the options is not present) is used for the actual downloading. (experimental)'\n    )\n\n    selection = optparse.OptionGroup(parser, 'Video Selection')\n    selection.add_option(\n        '--playlist-start',\n        dest='playliststart', metavar='NUMBER', default=1, type=int,\n        help='Playlist video to start at (default is %default)')\n    selection.add_option(\n        '--playlist-end',\n        dest='playlistend', metavar='NUMBER', default=None, type=int,\n        help='Playlist video to end at (default is last)')\n    selection.add_option(\n        '--playlist-items',\n        dest='playlist_items', metavar='ITEM_SPEC', default=None,\n        help='Playlist video items to download. Specify indices of the videos in the playlist seperated by commas like: \"--playlist-items 1,2,5,8\" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: \"--playlist-items 1-3,7,10-13\", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')\n    selection.add_option(\n        '--match-title',\n        dest='matchtitle', metavar='REGEX',\n        help='Download only matching titles (regex or caseless sub-string)')\n    selection.add_option(\n        '--reject-title',\n        dest='rejecttitle', metavar='REGEX',\n        help='Skip download for matching titles (regex or caseless sub-string)')\n    selection.add_option(\n        '--max-downloads',\n        dest='max_downloads', metavar='NUMBER', type=int, default=None,\n        help='Abort after downloading NUMBER files')\n    selection.add_option(\n        '--min-filesize',\n        metavar='SIZE', dest='min_filesize', default=None,\n        help='Do not download any videos smaller than SIZE (e.g. 50k or 44.6m)')\n    selection.add_option(\n        '--max-filesize',\n        metavar='SIZE', dest='max_filesize', default=None,\n        help='Do not download any videos larger than SIZE (e.g. 50k or 44.6m)')\n    selection.add_option(\n        '--date',\n        metavar='DATE', dest='date', default=None,\n        help='Download only videos uploaded in this date')\n    selection.add_option(\n        '--datebefore',\n        metavar='DATE', dest='datebefore', default=None,\n        help='Download only videos uploaded on or before this date (i.e. inclusive)')\n    selection.add_option(\n        '--dateafter',\n        metavar='DATE', dest='dateafter', default=None,\n        help='Download only videos uploaded on or after this date (i.e. inclusive)')\n    selection.add_option(\n        '--min-views',\n        metavar='COUNT', dest='min_views', default=None, type=int,\n        help='Do not download any videos with less than COUNT views')\n    selection.add_option(\n        '--max-views',\n        metavar='COUNT', dest='max_views', default=None, type=int,\n        help='Do not download any videos with more than COUNT views')\n    selection.add_option(\n        '--match-filter',\n        metavar='FILTER', dest='match_filter', default=None,\n        help=(\n            'Generic video filter (experimental). '\n            'Specify any key (see help for -o for a list of available keys) to'\n            ' match if the key is present, '\n            '!key to check if the key is not present,'\n            'key > NUMBER (like \"comment_count > 12\", also works with '\n            '>=, <, <=, !=, =) to compare against a number, and '\n            '& to require multiple matches. '\n            'Values which are not known are excluded unless you'\n            ' put a question mark (?) after the operator.'\n            'For example, to only match videos that have been liked more than '\n            '100 times and disliked less than 50 times (or the dislike '\n            'functionality is not available at the given service), but who '\n            'also have a description, use  --match-filter '\n            '\"like_count > 100 & dislike_count <? 50 & description\" .'\n        ))\n    selection.add_option(\n        '--no-playlist',\n        action='store_true', dest='noplaylist', default=False,\n        help='Download only the video, if the URL refers to a video and a playlist.')\n    selection.add_option(\n        '--yes-playlist',\n        action='store_false', dest='noplaylist', default=False,\n        help='Download the playlist, if the URL refers to a video and a playlist.')\n    selection.add_option(\n        '--age-limit',\n        metavar='YEARS', dest='age_limit', default=None, type=int,\n        help='Download only videos suitable for the given age')\n    selection.add_option(\n        '--download-archive', metavar='FILE',\n        dest='download_archive',\n        help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')\n    selection.add_option(\n        '--include-ads',\n        dest='include_ads', action='store_true',\n        help='Download advertisements as well (experimental)')\n\n    authentication = optparse.OptionGroup(parser, 'Authentication Options')\n    authentication.add_option(\n        '-u', '--username',\n        dest='username', metavar='USERNAME',\n        help='Login with this account ID')\n    authentication.add_option(\n        '-p', '--password',\n        dest='password', metavar='PASSWORD',\n        help='Account password. If this option is left out, youtube-dl will ask interactively.')\n    authentication.add_option(\n        '-2', '--twofactor',\n        dest='twofactor', metavar='TWOFACTOR',\n        help='Two-factor auth code')\n    authentication.add_option(\n        '-n', '--netrc',\n        action='store_true', dest='usenetrc', default=False,\n        help='Use .netrc authentication data')\n    authentication.add_option(\n        '--video-password',\n        dest='videopassword', metavar='PASSWORD',\n        help='Video password (vimeo, smotri)')\n\n    video_format = optparse.OptionGroup(parser, 'Video Format Options')\n    video_format.add_option(\n        '-f', '--format',\n        action='store', dest='format', metavar='FORMAT', default=None,\n        help='Video format code, see the \"FORMAT SELECTION\" for all the info')\n    video_format.add_option(\n        '--all-formats',\n        action='store_const', dest='format', const='all',\n        help='Download all available video formats')\n    video_format.add_option(\n        '--prefer-free-formats',\n        action='store_true', dest='prefer_free_formats', default=False,\n        help='Prefer free video formats unless a specific one is requested')\n    video_format.add_option(\n        '-F', '--list-formats',\n        action='store_true', dest='listformats',\n        help='List all available formats')\n    video_format.add_option(\n        '--youtube-include-dash-manifest',\n        action='store_true', dest='youtube_include_dash_manifest', default=True,\n        help=optparse.SUPPRESS_HELP)\n    video_format.add_option(\n        '--youtube-skip-dash-manifest',\n        action='store_false', dest='youtube_include_dash_manifest',\n        help='Do not download the DASH manifest on YouTube videos')\n    video_format.add_option(\n        '--merge-output-format',\n        action='store', dest='merge_output_format', metavar='FORMAT', default=None,\n        help=(\n            'If a merge is required (e.g. bestvideo+bestaudio), '\n            'output to given container format. One of mkv, mp4, ogg, webm, flv. '\n            'Ignored if no merge is required'))\n\n    subtitles = optparse.OptionGroup(parser, 'Subtitle Options')\n    subtitles.add_option(\n        '--write-sub', '--write-srt',\n        action='store_true', dest='writesubtitles', default=False,\n        help='Write subtitle file')\n    subtitles.add_option(\n        '--write-auto-sub', '--write-automatic-sub',\n        action='store_true', dest='writeautomaticsub', default=False,\n        help='Write automatic subtitle file (YouTube only)')\n    subtitles.add_option(\n        '--all-subs',\n        action='store_true', dest='allsubtitles', default=False,\n        help='Download all the available subtitles of the video')\n    subtitles.add_option(\n        '--list-subs',\n        action='store_true', dest='listsubtitles', default=False,\n        help='List all available subtitles for the video')\n    subtitles.add_option(\n        '--sub-format',\n        action='store', dest='subtitlesformat', metavar='FORMAT', default='best',\n        help='Subtitle format, accepts formats preference, for example: \"srt\" or \"ass/srt/best\"')\n    subtitles.add_option(\n        '--sub-lang', '--sub-langs', '--srt-lang',\n        action='callback', dest='subtitleslangs', metavar='LANGS', type='str',\n        default=[], callback=_comma_separated_values_options_callback,\n        help='Languages of the subtitles to download (optional) separated by commas, use IETF language tags like \\'en,pt\\'')\n\n    downloader = optparse.OptionGroup(parser, 'Download Options')\n    downloader.add_option(\n        '-r', '--rate-limit',\n        dest='ratelimit', metavar='LIMIT',\n        help='Maximum download rate in bytes per second (e.g. 50K or 4.2M)')\n    downloader.add_option(\n        '-R', '--retries',\n        dest='retries', metavar='RETRIES', default=10,\n        help='Number of retries (default is %default), or \"infinite\".')\n    downloader.add_option(\n        '--buffer-size',\n        dest='buffersize', metavar='SIZE', default='1024',\n        help='Size of download buffer (e.g. 1024 or 16K) (default is %default)')\n    downloader.add_option(\n        '--no-resize-buffer',\n        action='store_true', dest='noresizebuffer', default=False,\n        help='Do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.')\n    downloader.add_option(\n        '--test',\n        action='store_true', dest='test', default=False,\n        help=optparse.SUPPRESS_HELP)\n    downloader.add_option(\n        '--playlist-reverse',\n        action='store_true',\n        help='Download playlist videos in reverse order')\n    downloader.add_option(\n        '--xattr-set-filesize',\n        dest='xattr_set_filesize', action='store_true',\n        help='Set file xattribute ytdl.filesize with expected filesize (experimental)')\n    downloader.add_option(\n        '--hls-prefer-native',\n        dest='hls_prefer_native', action='store_true',\n        help='Use the native HLS downloader instead of ffmpeg (experimental)')\n    downloader.add_option(\n        '--external-downloader',\n        dest='external_downloader', metavar='COMMAND',\n        help='Use the specified external downloader. '\n             'Currently supports %s' % ','.join(list_external_downloaders()))\n    downloader.add_option(\n        '--external-downloader-args',\n        dest='external_downloader_args', metavar='ARGS',\n        help='Give these arguments to the external downloader')\n\n    workarounds = optparse.OptionGroup(parser, 'Workarounds')\n    workarounds.add_option(\n        '--encoding',\n        dest='encoding', metavar='ENCODING',\n        help='Force the specified encoding (experimental)')\n    workarounds.add_option(\n        '--no-check-certificate',\n        action='store_true', dest='no_check_certificate', default=False,\n        help='Suppress HTTPS certificate validation')\n    workarounds.add_option(\n        '--prefer-insecure',\n        '--prefer-unsecure', action='store_true', dest='prefer_insecure',\n        help='Use an unencrypted connection to retrieve information about the video. (Currently supported only for YouTube)')\n    workarounds.add_option(\n        '--user-agent',\n        metavar='UA', dest='user_agent',\n        help='Specify a custom user agent')\n    workarounds.add_option(\n        '--referer',\n        metavar='URL', dest='referer', default=None,\n        help='Specify a custom referer, use if the video access is restricted to one domain',\n    )\n    workarounds.add_option(\n        '--add-header',\n        metavar='FIELD:VALUE', dest='headers', action='append',\n        help='Specify a custom HTTP header and its value, separated by a colon \\':\\'. You can use this option multiple times',\n    )\n    workarounds.add_option(\n        '--bidi-workaround',\n        dest='bidi_workaround', action='store_true',\n        help='Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')\n    workarounds.add_option(\n        '--sleep-interval', metavar='SECONDS',\n        dest='sleep_interval', type=float,\n        help='Number of seconds to sleep before each download.')\n\n    verbosity = optparse.OptionGroup(parser, 'Verbosity / Simulation Options')\n    verbosity.add_option(\n        '-q', '--quiet',\n        action='store_true', dest='quiet', default=False,\n        help='Activate quiet mode')\n    verbosity.add_option(\n        '--no-warnings',\n        dest='no_warnings', action='store_true', default=False,\n        help='Ignore warnings')\n    verbosity.add_option(\n        '-s', '--simulate',\n        action='store_true', dest='simulate', default=False,\n        help='Do not download the video and do not write anything to disk')\n    verbosity.add_option(\n        '--skip-download',\n        action='store_true', dest='skip_download', default=False,\n        help='Do not download the video')\n    verbosity.add_option(\n        '-g', '--get-url',\n        action='store_true', dest='geturl', default=False,\n        help='Simulate, quiet but print URL')\n    verbosity.add_option(\n        '-e', '--get-title',\n        action='store_true', dest='gettitle', default=False,\n        help='Simulate, quiet but print title')\n    verbosity.add_option(\n        '--get-id',\n        action='store_true', dest='getid', default=False,\n        help='Simulate, quiet but print id')\n    verbosity.add_option(\n        '--get-thumbnail',\n        action='store_true', dest='getthumbnail', default=False,\n        help='Simulate, quiet but print thumbnail URL')\n    verbosity.add_option(\n        '--get-description',\n        action='store_true', dest='getdescription', default=False,\n        help='Simulate, quiet but print video description')\n    verbosity.add_option(\n        '--get-duration',\n        action='store_true', dest='getduration', default=False,\n        help='Simulate, quiet but print video length')\n    verbosity.add_option(\n        '--get-filename',\n        action='store_true', dest='getfilename', default=False,\n        help='Simulate, quiet but print output filename')\n    verbosity.add_option(\n        '--get-format',\n        action='store_true', dest='getformat', default=False,\n        help='Simulate, quiet but print output format')\n    verbosity.add_option(\n        '-j', '--dump-json',\n        action='store_true', dest='dumpjson', default=False,\n        help='Simulate, quiet but print JSON information. See --output for a description of available keys.')\n    verbosity.add_option(\n        '-J', '--dump-single-json',\n        action='store_true', dest='dump_single_json', default=False,\n        help='Simulate, quiet but print JSON information for each command-line argument. If the URL refers to a playlist, dump the whole playlist information in a single line.')\n    verbosity.add_option(\n        '--print-json',\n        action='store_true', dest='print_json', default=False,\n        help='Be quiet and print the video information as JSON (video is still being downloaded).',\n    )\n    verbosity.add_option(\n        '--newline',\n        action='store_true', dest='progress_with_newline', default=False,\n        help='Output progress bar as new lines')\n    verbosity.add_option(\n        '--no-progress',\n        action='store_true', dest='noprogress', default=False,\n        help='Do not print progress bar')\n    verbosity.add_option(\n        '--console-title',\n        action='store_true', dest='consoletitle', default=False,\n        help='Display progress in console titlebar')\n    verbosity.add_option(\n        '-v', '--verbose',\n        action='store_true', dest='verbose', default=False,\n        help='Print various debugging information')\n    verbosity.add_option(\n        '--dump-pages', '--dump-intermediate-pages',\n        action='store_true', dest='dump_intermediate_pages', default=False,\n        help='Print downloaded pages encoded using base64 to debug problems (very verbose)')\n    verbosity.add_option(\n        '--write-pages',\n        action='store_true', dest='write_pages', default=False,\n        help='Write downloaded intermediary pages to files in the current directory to debug problems')\n    verbosity.add_option(\n        '--youtube-print-sig-code',\n        action='store_true', dest='youtube_print_sig_code', default=False,\n        help=optparse.SUPPRESS_HELP)\n    verbosity.add_option(\n        '--print-traffic', '--dump-headers',\n        dest='debug_printtraffic', action='store_true', default=False,\n        help='Display sent and read HTTP traffic')\n    verbosity.add_option(\n        '-C', '--call-home',\n        dest='call_home', action='store_true', default=False,\n        help='Contact the youtube-dl server for debugging')\n    verbosity.add_option(\n        '--no-call-home',\n        dest='call_home', action='store_false', default=False,\n        help='Do NOT contact the youtube-dl server for debugging')\n\n    filesystem = optparse.OptionGroup(parser, 'Filesystem Options')\n    filesystem.add_option(\n        '-a', '--batch-file',\n        dest='batchfile', metavar='FILE',\n        help='File containing URLs to download (\\'-\\' for stdin)')\n    filesystem.add_option(\n        '--id', default=False,\n        action='store_true', dest='useid', help='Use only video ID in file name')\n    filesystem.add_option(\n        '-o', '--output',\n        dest='outtmpl', metavar='TEMPLATE',\n        help=('Output filename template. Use %(title)s to get the title, '\n              '%(uploader)s for the uploader name, %(uploader_id)s for the uploader nickname if different, '\n              '%(autonumber)s to get an automatically incremented number, '\n              '%(ext)s for the filename extension, '\n              '%(format)s for the format description (like \"22 - 1280x720\" or \"HD\"), '\n              '%(format_id)s for the unique id of the format (like YouTube\\'s itags: \"137\"), '\n              '%(upload_date)s for the upload date (YYYYMMDD), '\n              '%(extractor)s for the provider (youtube, metacafe, etc), '\n              '%(id)s for the video id, '\n              '%(playlist_title)s, %(playlist_id)s, or %(playlist)s (=title if present, ID otherwise) for the playlist the video is in, '\n              '%(playlist_index)s for the position in the playlist. '\n              '%(height)s and %(width)s for the width and height of the video format. '\n              '%(resolution)s for a textual description of the resolution of the video format. '\n              '%% for a literal percent. '\n              'Use - to output to stdout. Can also be used to download to a different directory, '\n              'for example with -o \\'/my/downloads/%(uploader)s/%(title)s-%(id)s.%(ext)s\\' .'))\n    filesystem.add_option(\n        '--autonumber-size',\n        dest='autonumber_size', metavar='NUMBER',\n        help='Specify the number of digits in %(autonumber)s when it is present in output filename template or --auto-number option is given')\n    filesystem.add_option(\n        '--restrict-filenames',\n        action='store_true', dest='restrictfilenames', default=False,\n        help='Restrict filenames to only ASCII characters, and avoid \"&\" and spaces in filenames')\n    filesystem.add_option(\n        '-A', '--auto-number',\n        action='store_true', dest='autonumber', default=False,\n        help='[deprecated; use  -o \"%(autonumber)s-%(title)s.%(ext)s\" ] Number downloaded files starting from 00000')\n    filesystem.add_option(\n        '-t', '--title',\n        action='store_true', dest='usetitle', default=False,\n        help='[deprecated] Use title in file name (default)')\n    filesystem.add_option(\n        '-l', '--literal', default=False,\n        action='store_true', dest='usetitle',\n        help='[deprecated] Alias of --title')\n    filesystem.add_option(\n        '-w', '--no-overwrites',\n        action='store_true', dest='nooverwrites', default=False,\n        help='Do not overwrite files')\n    filesystem.add_option(\n        '-c', '--continue',\n        action='store_true', dest='continue_dl', default=True,\n        help='Force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.')\n    filesystem.add_option(\n        '--no-continue',\n        action='store_false', dest='continue_dl',\n        help='Do not resume partially downloaded files (restart from beginning)')\n    filesystem.add_option(\n        '--no-part',\n        action='store_true', dest='nopart', default=False,\n        help='Do not use .part files - write directly into output file')\n    filesystem.add_option(\n        '--no-mtime',\n        action='store_false', dest='updatetime', default=True,\n        help='Do not use the Last-modified header to set the file modification time')\n    filesystem.add_option(\n        '--write-description',\n        action='store_true', dest='writedescription', default=False,\n        help='Write video description to a .description file')\n    filesystem.add_option(\n        '--write-info-json',\n        action='store_true', dest='writeinfojson', default=False,\n        help='Write video metadata to a .info.json file')\n    filesystem.add_option(\n        '--write-annotations',\n        action='store_true', dest='writeannotations', default=False,\n        help='Write video annotations to a .annotations.xml file')\n    filesystem.add_option(\n        '--load-info',\n        dest='load_info_filename', metavar='FILE',\n        help='JSON file containing the video information (created with the \"--write-info-json\" option)')\n    filesystem.add_option(\n        '--cookies',\n        dest='cookiefile', metavar='FILE',\n        help='File to read cookies from and dump cookie jar in')\n    filesystem.add_option(\n        '--cache-dir', dest='cachedir', default=None, metavar='DIR',\n        help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl . At the moment, only YouTube player files (for videos with obfuscated signatures) are cached, but that may change.')\n    filesystem.add_option(\n        '--no-cache-dir', action='store_const', const=False, dest='cachedir',\n        help='Disable filesystem caching')\n    filesystem.add_option(\n        '--rm-cache-dir',\n        action='store_true', dest='rm_cachedir',\n        help='Delete all filesystem cache files')\n\n    thumbnail = optparse.OptionGroup(parser, 'Thumbnail images')\n    thumbnail.add_option(\n        '--write-thumbnail',\n        action='store_true', dest='writethumbnail', default=False,\n        help='Write thumbnail image to disk')\n    thumbnail.add_option(\n        '--write-all-thumbnails',\n        action='store_true', dest='write_all_thumbnails', default=False,\n        help='Write all thumbnail image formats to disk')\n    thumbnail.add_option(\n        '--list-thumbnails',\n        action='store_true', dest='list_thumbnails', default=False,\n        help='Simulate and list all available thumbnail formats')\n\n    postproc = optparse.OptionGroup(parser, 'Post-processing Options')\n    postproc.add_option(\n        '-x', '--extract-audio',\n        action='store_true', dest='extractaudio', default=False,\n        help='Convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')\n    postproc.add_option(\n        '--audio-format', metavar='FORMAT', dest='audioformat', default='best',\n        help='Specify audio format: \"best\", \"aac\", \"vorbis\", \"mp3\", \"m4a\", \"opus\", or \"wav\"; \"%default\" by default')\n    postproc.add_option(\n        '--audio-quality', metavar='QUALITY',\n        dest='audioquality', default='5',\n        help='Specify ffmpeg/avconv audio quality, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default %default)')\n    postproc.add_option(\n        '--recode-video',\n        metavar='FORMAT', dest='recodevideo', default=None,\n        help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv)')\n    postproc.add_option(\n        '-k', '--keep-video',\n        action='store_true', dest='keepvideo', default=False,\n        help='Keep the video file on disk after the post-processing; the video is erased by default')\n    postproc.add_option(\n        '--no-post-overwrites',\n        action='store_true', dest='nopostoverwrites', default=False,\n        help='Do not overwrite post-processed files; the post-processed files are overwritten by default')\n    postproc.add_option(\n        '--embed-subs',\n        action='store_true', dest='embedsubtitles', default=False,\n        help='Embed subtitles in the video (only for mkv and mp4 videos)')\n    postproc.add_option(\n        '--embed-thumbnail',\n        action='store_true', dest='embedthumbnail', default=False,\n        help='Embed thumbnail in the audio as cover art')\n    postproc.add_option(\n        '--add-metadata',\n        action='store_true', dest='addmetadata', default=False,\n        help='Write metadata to the video file')\n    postproc.add_option(\n        '--metadata-from-title',\n        metavar='FORMAT', dest='metafromtitle',\n        help='Parse additional metadata like song title / artist from the video title. '\n             'The format syntax is the same as --output, '\n             'the parsed parameters replace existing values. '\n             'Additional templates: %(album)s, %(artist)s. '\n             'Example: --metadata-from-title \"%(artist)s - %(title)s\" matches a title like '\n             '\"Coldplay - Paradise\"')\n    postproc.add_option(\n        '--xattrs',\n        action='store_true', dest='xattrs', default=False,\n        help='Write metadata to the video file\\'s xattrs (using dublin core and xdg standards)')\n    postproc.add_option(\n        '--fixup',\n        metavar='POLICY', dest='fixup', default='detect_or_warn',\n        help='Automatically correct known faults of the file. '\n             'One of never (do nothing), warn (only emit a warning), '\n             'detect_or_warn (the default; fix file if we can, warn otherwise)')\n    postproc.add_option(\n        '--prefer-avconv',\n        action='store_false', dest='prefer_ffmpeg',\n        help='Prefer avconv over ffmpeg for running the postprocessors (default)')\n    postproc.add_option(\n        '--prefer-ffmpeg',\n        action='store_true', dest='prefer_ffmpeg',\n        help='Prefer ffmpeg over avconv for running the postprocessors')\n    postproc.add_option(\n        '--ffmpeg-location', '--avconv-location', metavar='PATH',\n        dest='ffmpeg_location',\n        help='Location of the ffmpeg/avconv binary; either the path to the binary or its containing directory.')\n    postproc.add_option(\n        '--exec',\n        metavar='CMD', dest='exec_cmd',\n        help='Execute a command on the file after downloading, similar to find\\'s -exec syntax. Example: --exec \\'adb push {} /sdcard/Music/ && rm {}\\'')\n    postproc.add_option(\n        '--convert-subtitles', '--convert-subs',\n        metavar='FORMAT', dest='convertsubtitles', default=None,\n        help='Convert the subtitles to other format (currently supported: srt|ass|vtt)')\n\n    parser.add_option_group(general)\n    parser.add_option_group(network)\n    parser.add_option_group(selection)\n    parser.add_option_group(downloader)\n    parser.add_option_group(filesystem)\n    parser.add_option_group(thumbnail)\n    parser.add_option_group(verbosity)\n    parser.add_option_group(workarounds)\n    parser.add_option_group(video_format)\n    parser.add_option_group(subtitles)\n    parser.add_option_group(authentication)\n    parser.add_option_group(postproc)\n\n    if overrideArguments is not None:\n        opts, args = parser.parse_args(overrideArguments)\n        if opts.verbose:\n            write_string('[debug] Override config: ' + repr(overrideArguments) + '\\n')\n    else:\n        def compat_conf(conf):\n            if sys.version_info < (3,):\n                return [a.decode(preferredencoding(), 'replace') for a in conf]\n            return conf\n\n        command_line_conf = compat_conf(sys.argv[1:])\n\n        if '--ignore-config' in command_line_conf:\n            system_conf = []\n            user_conf = []\n        else:\n            system_conf = compat_conf(_readOptions('/etc/youtube-dl.conf'))\n            if '--ignore-config' in system_conf:\n                user_conf = []\n            else:\n                user_conf = compat_conf(_readUserConf())\n        argv = system_conf + user_conf + command_line_conf\n\n        opts, args = parser.parse_args(argv)\n        if opts.verbose:\n            write_string('[debug] System config: ' + repr(_hide_login_info(system_conf)) + '\\n')\n            write_string('[debug] User config: ' + repr(_hide_login_info(user_conf)) + '\\n')\n            write_string('[debug] Command-line args: ' + repr(_hide_login_info(command_line_conf)) + '\\n')\n\n    return parser, opts, args",
        "begin_line": 22,
        "end_line": 797,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00039635354736424893,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.__init__#14",
        "src_path": "youtube_dl/postprocessor/metadatafromtitle.py",
        "class_name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP",
        "signature": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.__init__(self, downloader, titleformat)",
        "snippet": "    def __init__(self, downloader, titleformat):\n        super(MetadataFromTitlePP, self).__init__(downloader)\n        self._titleformat = titleformat\n        self._titleregex = self.format_to_regex(titleformat)",
        "begin_line": 14,
        "end_line": 17,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.format_to_regex#19",
        "src_path": "youtube_dl/postprocessor/metadatafromtitle.py",
        "class_name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP",
        "signature": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.format_to_regex(self, fmt)",
        "snippet": "    def format_to_regex(self, fmt):\n        \"\"\"\n        Converts a string like\n           '%(title)s - %(artist)s'\n        to a regex like\n           '(?P<title>.+)\\ \\-\\ (?P<artist>.+)'\n        \"\"\"\n        lastpos = 0\n        regex = \"\"\n        # replace %(..)s with regex group and escape other string parts\n        for match in re.finditer(r'%\\((\\w+)\\)s', fmt):\n            regex += re.escape(fmt[lastpos:match.start()])\n            regex += r'(?P<' + match.group(1) + '>.+)'\n            lastpos = match.end()\n        if lastpos < len(fmt):\n            regex += re.escape(fmt[lastpos:len(fmt)])\n        return regex",
        "begin_line": 19,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformIE._real_extract#89",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        mobj = re.match(self._VALID_URL, url)\n        provider_id = mobj.group('provider_id')\n        video_id = mobj.group('id')\n\n        if not provider_id:\n            provider_id = 'dJ5BDC'\n\n        path = provider_id\n        if mobj.group('media'):\n            path += '/media'\n        path += '/' + video_id\n\n        if smuggled_data.get('force_smil_url', False):\n            smil_url = url\n        elif mobj.group('config'):\n            config_url = url + '&form=json'\n            config_url = config_url.replace('swf/', 'config/')\n            config_url = config_url.replace('onsite/', 'onsite/config/')\n            config = self._download_json(config_url, video_id, 'Downloading config')\n            smil_url = config['releaseUrl'] + '&format=SMIL&formats=MPEG4&manifest=f4m'\n        else:\n            smil_url = 'http://link.theplatform.com/s/%s/meta.smil?format=smil&mbr=true' % path\n\n        sig = smuggled_data.get('sig')\n        if sig:\n            smil_url = self._sign_url(smil_url, sig['key'], sig['secret'])\n\n        meta = self._download_xml(smil_url, video_id)\n        try:\n            error_msg = next(\n                n.attrib['abstract']\n                for n in meta.findall(_x('.//smil:ref'))\n                if n.attrib.get('title') == 'Geographic Restriction' or n.attrib.get('title') == 'Expired')\n        except StopIteration:\n            pass\n        else:\n            raise ExtractorError(error_msg, expected=True)\n\n        info_url = 'http://link.theplatform.com/s/%s?format=preview' % path\n        info_json = self._download_webpage(info_url, video_id)\n        info = json.loads(info_json)\n\n        subtitles = {}\n        captions = info.get('captions')\n        if isinstance(captions, list):\n            for caption in captions:\n                lang, src, mime = caption.get('lang', 'en'), caption.get('src'), caption.get('type')\n                subtitles[lang] = [{\n                    'ext': 'srt' if mime == 'text/srt' else 'ttml',\n                    'url': src,\n                }]\n\n        head = meta.find(_x('smil:head'))\n        body = meta.find(_x('smil:body'))\n\n        f4m_node = body.find(_x('smil:seq//smil:video'))\n        if f4m_node is None:\n            f4m_node = body.find(_x('smil:seq/smil:video'))\n        if f4m_node is not None and '.f4m' in f4m_node.attrib['src']:\n            f4m_url = f4m_node.attrib['src']\n            if 'manifest.f4m?' not in f4m_url:\n                f4m_url += '?'\n            # the parameters are from syfy.com, other sites may use others,\n            # they also work for nbc.com\n            f4m_url += '&g=UXWGVKRWHFSP&hdcore=3.0.3'\n            formats = self._extract_f4m_formats(f4m_url, video_id)\n        else:\n            formats = []\n            switch = body.find(_x('smil:switch'))\n            if switch is None:\n                switch = body.find(_x('smil:par//smil:switch'))\n            if switch is None:\n                switch = body.find(_x('smil:par/smil:switch'))\n            if switch is None:\n                switch = body.find(_x('smil:par'))\n            if switch is not None:\n                base_url = head.find(_x('smil:meta')).attrib['base']\n                for f in switch.findall(_x('smil:video')):\n                    attr = f.attrib\n                    width = int_or_none(attr.get('width'))\n                    height = int_or_none(attr.get('height'))\n                    vbr = int_or_none(attr.get('system-bitrate'), 1000)\n                    format_id = '%dx%d_%dk' % (width, height, vbr)\n                    formats.append({\n                        'format_id': format_id,\n                        'url': base_url,\n                        'play_path': 'mp4:' + attr['src'],\n                        'ext': 'flv',\n                        'width': width,\n                        'height': height,\n                        'vbr': vbr,\n                    })\n            else:\n                switch = body.find(_x('smil:seq//smil:switch'))\n                if switch is None:\n                    switch = body.find(_x('smil:seq/smil:switch'))\n                for f in switch.findall(_x('smil:video')):\n                    attr = f.attrib\n                    vbr = int_or_none(attr.get('system-bitrate'), 1000)\n                    ext = determine_ext(attr['src'])\n                    if ext == 'once':\n                        ext = 'mp4'\n                    formats.append({\n                        'format_id': compat_str(vbr),\n                        'url': attr['src'],\n                        'vbr': vbr,\n                        'ext': ext,\n                    })\n            self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'subtitles': subtitles,\n            'formats': formats,\n            'description': info['description'],\n            'thumbnail': info['defaultThumbnailUrl'],\n            'duration': int_or_none(info.get('duration'), 1000),\n        }",
        "begin_line": 89,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_entry_item#222",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_entry_item(self, html, content_path)",
        "snippet": "    def _extract_entry_item(self, html, content_path):\n        contents = self._extract_content(html, content_path)\n        if contents is None:\n            return contents\n\n        authors = self._extract_authors(html)\n\n        for content in contents:\n            content['authors'] = authors\n\n        return contents",
        "begin_line": 222,
        "end_line": 232,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025568908207619537,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.xstream.XstreamIE._real_extract#45",
        "src_path": "youtube_dl/extractor/xstream.py",
        "class_name": "youtube_dl.extractor.xstream.XstreamIE",
        "signature": "youtube_dl.extractor.xstream.XstreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        partner_id = mobj.group('partner_id')\n        video_id = mobj.group('id')\n\n        data = self._download_xml(\n            'http://frontend.xstream.dk/%s/feed/video/?platform=web&id=%s'\n            % (partner_id, video_id),\n            video_id)\n\n        NS_MAP = {\n            'atom': 'http://www.w3.org/2005/Atom',\n            'xt': 'http://xstream.dk/',\n            'media': 'http://search.yahoo.com/mrss/',\n        }\n\n        entry = data.find(xpath_with_ns('./atom:entry', NS_MAP))\n\n        title = xpath_text(\n            entry, xpath_with_ns('./atom:title', NS_MAP), 'title')\n        description = xpath_text(\n            entry, xpath_with_ns('./atom:summary', NS_MAP), 'description')\n        timestamp = parse_iso8601(xpath_text(\n            entry, xpath_with_ns('./atom:published', NS_MAP), 'upload date'))\n\n        formats = []\n        media_group = entry.find(xpath_with_ns('./media:group', NS_MAP))\n        for media_content in media_group.findall(xpath_with_ns('./media:content', NS_MAP)):\n            media_url = media_content.get('url')\n            if not media_url:\n                continue\n            tbr = int_or_none(media_content.get('bitrate'))\n            mobj = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', media_url)\n            if mobj:\n                formats.append({\n                    'url': mobj.group('url'),\n                    'play_path': 'mp4:%s' % mobj.group('playpath'),\n                    'app': mobj.group('app'),\n                    'ext': 'flv',\n                    'tbr': tbr,\n                    'format_id': 'rtmp-%d' % tbr,\n                })\n            else:\n                formats.append({\n                    'url': media_url,\n                    'tbr': tbr,\n                })\n        self._sort_formats(formats)\n\n        link = find_xpath_attr(\n            entry, xpath_with_ns('./atom:link', NS_MAP), 'rel', 'original')\n        if link is not None:\n            formats.append({\n                'url': link.get('href'),\n                'format_id': link.get('rel'),\n            })\n\n        thumbnails = [{\n            'url': splash.get('url'),\n            'width': int_or_none(splash.get('width')),\n            'height': int_or_none(splash.get('height')),\n        } for splash in media_group.findall(xpath_with_ns('./xt:splash', NS_MAP))]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 45,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002486325211337643,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.safari.SafariIE._real_extract#109",
        "src_path": "youtube_dl/extractor/safari.py",
        "class_name": "youtube_dl.extractor.safari.SafariIE",
        "signature": "youtube_dl.extractor.safari.SafariIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_id = mobj.group('course_id')\n        part = mobj.group('part')\n\n        webpage = self._download_webpage(\n            '%s/%s/chapter-content/%s.html' % (self._API_BASE, course_id, part),\n            part)\n\n        bc_url = BrightcoveIE._extract_brightcove_url(webpage)\n        if not bc_url:\n            raise ExtractorError('Could not extract Brightcove URL from %s' % url, expected=True)\n\n        return self.url_result(smuggle_url(bc_url, {'Referer': url}), 'Brightcove')",
        "begin_line": 109,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.000246669955599408,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.__init__#30",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        self._downloader = downloader",
        "begin_line": 30,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.set_downloader#33",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.set_downloader(self, downloader)",
        "snippet": "    def set_downloader(self, downloader):\n        \"\"\"Sets the downloader for this PP.\"\"\"\n        self._downloader = downloader",
        "begin_line": 33,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.tvc.TVCIE._extract_url#28",
        "src_path": "youtube_dl/extractor/tvc.py",
        "class_name": "youtube_dl.extractor.tvc.TVCIE",
        "signature": "youtube_dl.extractor.tvc.TVCIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:http:)?//(?:www\\.)?tvc\\.ru/video/iframe/id/[^\"]+)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 28,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._real_extract#149",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        if not video_id:\n            video_id = '%s_%s' % (mobj.group('oid'), mobj.group('id'))\n\n        info_url = 'http://vk.com/al_video.php?act=show&al=1&module=video&video=%s' % video_id\n        info_page = self._download_webpage(info_url, video_id)\n\n        ERRORS = {\n            r'>\u0412\u0438\u0434\u0435\u043e\u0437\u0430\u043f\u0438\u0441\u044c .*? \u0431\u044b\u043b\u0430 \u0438\u0437\u044a\u044f\u0442\u0430 \u0438\u0437 \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u043e\u0433\u043e \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u0432 \u0441\u0432\u044f\u0437\u0438 \u0441 \u043e\u0431\u0440\u0430\u0449\u0435\u043d\u0438\u0435\u043c \u043f\u0440\u0430\u0432\u043e\u043e\u0431\u043b\u0430\u0434\u0430\u0442\u0435\u043b\u044f.<':\n            'Video %s has been removed from public access due to rightholder complaint.',\n\n            r'<!>Please log in or <':\n            'Video %s is only available for registered users, '\n            'use --username and --password options to provide account credentials.',\n\n            r'<!>Unknown error':\n            'Video %s does not exist.',\n\n            r'<!>\u0412\u0438\u0434\u0435\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u043e \u043d\u0435\u0434\u043e\u0441\u0442\u0443\u043f\u043d\u043e':\n            'Video %s is temporarily unavailable.',\n        }\n\n        for error_re, error_msg in ERRORS.items():\n            if re.search(error_re, info_page):\n                raise ExtractorError(error_msg % video_id, expected=True)\n\n        m_yt = re.search(r'src=\"(http://www.youtube.com/.*?)\"', info_page)\n        if m_yt is not None:\n            self.to_screen('Youtube video detected')\n            return self.url_result(m_yt.group(1), 'Youtube')\n\n        m_rutube = re.search(\n            r'\\ssrc=\"((?:https?:)?//rutube\\.ru\\\\?/video\\\\?/embed(?:.*?))\\\\?\"', info_page)\n        if m_rutube is not None:\n            self.to_screen('rutube video detected')\n            rutube_url = self._proto_relative_url(\n                m_rutube.group(1).replace('\\\\', ''))\n            return self.url_result(rutube_url)\n\n        m_opts = re.search(r'(?s)var\\s+opts\\s*=\\s*({.+?});', info_page)\n        if m_opts:\n            m_opts_url = re.search(r\"url\\s*:\\s*'((?!/\\b)[^']+)\", m_opts.group(1))\n            if m_opts_url:\n                opts_url = m_opts_url.group(1)\n                if opts_url.startswith('//'):\n                    opts_url = 'http:' + opts_url\n                return self.url_result(opts_url)\n\n        data_json = self._search_regex(r'var\\s+vars\\s*=\\s*({.+?});', info_page, 'vars')\n        data = json.loads(data_json)\n\n        # Extract upload date\n        upload_date = None\n        mobj = re.search(r'id=\"mv_date(?:_views)?_wrap\"[^>]*>([a-zA-Z]+ [0-9]+), ([0-9]+) at', info_page)\n        if mobj is not None:\n            mobj.group(1) + ' ' + mobj.group(2)\n            upload_date = unified_strdate(mobj.group(1) + ' ' + mobj.group(2))\n\n        view_count = str_to_int(self._search_regex(\n            r'\"mv_views_count_number\"[^>]*>([\\d,.]+) views<',\n            info_page, 'view count', fatal=False))\n\n        formats = [{\n            'format_id': k,\n            'url': v,\n            'width': int(k[len('url'):]),\n        } for k, v in data.items()\n            if k.startswith('url')]\n        self._sort_formats(formats)\n\n        return {\n            'id': compat_str(data['vid']),\n            'formats': formats,\n            'title': unescapeHTML(data['md_title']),\n            'thumbnail': data.get('jpg'),\n            'uploader': data.get('md_author'),\n            'duration': data.get('duration'),\n            'upload_date': upload_date,\n            'view_count': view_count,\n        }",
        "begin_line": 149,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025031289111389235,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKUserVideosIE._real_extract#247",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKUserVideosIE",
        "signature": "youtube_dl.extractor.vk.VKUserVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n        page = self._download_webpage(url, page_id)\n        video_ids = orderedSet(\n            m.group(1) for m in re.finditer(r'href=\"/video([0-9_]+)\"', page))\n        url_entries = [\n            self.url_result(\n                'http://vk.com/video' + video_id, 'VK', video_id=video_id)\n            for video_id in video_ids]\n        return self.playlist_result(url_entries, page_id)",
        "begin_line": 247,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025412960609911054,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.aes_ctr_decrypt#11",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_ctr_decrypt(data, key, counter)",
        "snippet": "def aes_ctr_decrypt(data, key, counter):\n    \"\"\"\n    Decrypt with aes in counter mode\n\n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {instance} counter  Instance whose next_value function (@returns {int[]}  16-Byte block)\n                               returns the next counter block\n    @returns {int[]}           decrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n\n    decrypted_data = []\n    for i in range(block_count):\n        counter_block = counter.next_value()\n        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]\n        block += [0] * (BLOCK_SIZE_BYTES - len(block))\n\n        cipher_counter_block = aes_encrypt(counter_block, expanded_key)\n        decrypted_data += xor(block, cipher_counter_block)\n    decrypted_data = decrypted_data[:len(data)]\n\n    return decrypted_data",
        "begin_line": 11,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.aes_cbc_decrypt#37",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_cbc_decrypt(data, key, iv)",
        "snippet": "def aes_cbc_decrypt(data, key, iv):\n    \"\"\"\n    Decrypt with aes in CBC mode\n\n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {int[]} iv          16-Byte IV\n    @returns {int[]}           decrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n\n    decrypted_data = []\n    previous_cipher_block = iv\n    for i in range(block_count):\n        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]\n        block += [0] * (BLOCK_SIZE_BYTES - len(block))\n\n        decrypted_block = aes_decrypt(block, expanded_key)\n        decrypted_data += xor(decrypted_block, previous_cipher_block)\n        previous_cipher_block = block\n    decrypted_data = decrypted_data[:len(data)]\n\n    return decrypted_data",
        "begin_line": 37,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.key_expansion#63",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.key_expansion(data)",
        "snippet": "def key_expansion(data):\n    \"\"\"\n    Generate key schedule\n\n    @param {int[]} data  16/24/32-Byte cipher key\n    @returns {int[]}     176/208/240-Byte expanded key\n    \"\"\"\n    data = data[:]  # copy\n    rcon_iteration = 1\n    key_size_bytes = len(data)\n    expanded_key_size_bytes = (key_size_bytes // 4 + 7) * BLOCK_SIZE_BYTES\n\n    while len(data) < expanded_key_size_bytes:\n        temp = data[-4:]\n        temp = key_schedule_core(temp, rcon_iteration)\n        rcon_iteration += 1\n        data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        for _ in range(3):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        if key_size_bytes == 32:\n            temp = data[-4:]\n            temp = sub_bytes(temp)\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        for _ in range(3 if key_size_bytes == 32 else 2 if key_size_bytes == 24 else 0):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n    data = data[:expanded_key_size_bytes]\n\n    return data",
        "begin_line": 63,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.aes_encrypt#98",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_encrypt(data, expanded_key)",
        "snippet": "def aes_encrypt(data, expanded_key):\n    \"\"\"\n    Encrypt one block with aes\n\n    @param {int[]} data          16-Byte state\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte cipher\n    \"\"\"\n    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n    for i in range(1, rounds + 1):\n        data = sub_bytes(data)\n        data = shift_rows(data)\n        if i != rounds:\n            data = mix_columns(data)\n        data = xor(data, expanded_key[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES])\n\n    return data",
        "begin_line": 98,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.aes_decrypt#119",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_decrypt(data, expanded_key)",
        "snippet": "def aes_decrypt(data, expanded_key):\n    \"\"\"\n    Decrypt one block with aes\n\n    @param {int[]} data          16-Byte cipher\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte state\n    \"\"\"\n    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n\n    for i in range(rounds, 0, -1):\n        data = xor(data, expanded_key[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES])\n        if i != rounds:\n            data = mix_columns_inv(data)\n        data = shift_rows_inv(data)\n        data = sub_bytes_inv(data)\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n\n    return data",
        "begin_line": 119,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.aes_decrypt_text#140",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_decrypt_text(data, password, key_size_bytes)",
        "snippet": "def aes_decrypt_text(data, password, key_size_bytes):\n    \"\"\"\n    Decrypt text\n    - The first 8 Bytes of decoded 'data' are the 8 high Bytes of the counter\n    - The cipher key is retrieved by encrypting the first 16 Byte of 'password'\n      with the first 'key_size_bytes' Bytes from 'password' (if necessary filled with 0's)\n    - Mode of operation is 'counter'\n\n    @param {str} data                    Base64 encoded string\n    @param {str,unicode} password        Password (will be encoded with utf-8)\n    @param {int} key_size_bytes          Possible values: 16 for 128-Bit, 24 for 192-Bit or 32 for 256-Bit\n    @returns {str}                       Decrypted data\n    \"\"\"\n    NONCE_LENGTH_BYTES = 8\n\n    data = bytes_to_intlist(base64.b64decode(data.encode('utf-8')))\n    password = bytes_to_intlist(password.encode('utf-8'))\n\n    key = password[:key_size_bytes] + [0] * (key_size_bytes - len(password))\n    key = aes_encrypt(key[:BLOCK_SIZE_BYTES], key_expansion(key)) * (key_size_bytes // BLOCK_SIZE_BYTES)\n\n    nonce = data[:NONCE_LENGTH_BYTES]\n    cipher = data[NONCE_LENGTH_BYTES:]\n\n    class Counter:\n        __value = nonce + [0] * (BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)\n\n        def next_value(self):\n            temp = self.__value\n            self.__value = inc(self.__value)\n            return temp\n\n    decrypted_data = aes_ctr_decrypt(cipher, key, Counter())\n    plaintext = intlist_to_bytes(decrypted_data)\n\n    return plaintext",
        "begin_line": 140,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.Counter.aes_decrypt_text#140",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes.Counter",
        "signature": "youtube_dl.aes.Counter.aes_decrypt_text(data, password, key_size_bytes)",
        "snippet": "def aes_decrypt_text(data, password, key_size_bytes):\n    \"\"\"\n    Decrypt text\n    - The first 8 Bytes of decoded 'data' are the 8 high Bytes of the counter\n    - The cipher key is retrieved by encrypting the first 16 Byte of 'password'\n      with the first 'key_size_bytes' Bytes from 'password' (if necessary filled with 0's)\n    - Mode of operation is 'counter'\n\n    @param {str} data                    Base64 encoded string\n    @param {str,unicode} password        Password (will be encoded with utf-8)\n    @param {int} key_size_bytes          Possible values: 16 for 128-Bit, 24 for 192-Bit or 32 for 256-Bit\n    @returns {str}                       Decrypted data\n    \"\"\"\n    NONCE_LENGTH_BYTES = 8\n\n    data = bytes_to_intlist(base64.b64decode(data.encode('utf-8')))\n    password = bytes_to_intlist(password.encode('utf-8'))\n\n    key = password[:key_size_bytes] + [0] * (key_size_bytes - len(password))\n    key = aes_encrypt(key[:BLOCK_SIZE_BYTES], key_expansion(key)) * (key_size_bytes // BLOCK_SIZE_BYTES)\n\n    nonce = data[:NONCE_LENGTH_BYTES]\n    cipher = data[NONCE_LENGTH_BYTES:]\n\n    class Counter:\n        __value = nonce + [0] * (BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)\n\n        def next_value(self):\n            temp = self.__value\n            self.__value = inc(self.__value)\n            return temp\n\n    decrypted_data = aes_ctr_decrypt(cipher, key, Counter())\n    plaintext = intlist_to_bytes(decrypted_data)\n\n    return plaintext",
        "begin_line": 140,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.Counter.next_value#167",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes.Counter",
        "signature": "youtube_dl.aes.Counter.next_value(self)",
        "snippet": "        def next_value(self):\n            temp = self.__value\n            self.__value = inc(self.__value)\n            return temp",
        "begin_line": 167,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.sub_bytes#252",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.sub_bytes(data)",
        "snippet": "def sub_bytes(data):\n    return [SBOX[x] for x in data]",
        "begin_line": 252,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.sub_bytes_inv#256",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.sub_bytes_inv(data)",
        "snippet": "def sub_bytes_inv(data):\n    return [SBOX_INV[x] for x in data]",
        "begin_line": 256,
        "end_line": 257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.rotate#260",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.rotate(data)",
        "snippet": "def rotate(data):\n    return data[1:] + [data[0]]",
        "begin_line": 260,
        "end_line": 261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.key_schedule_core#264",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.key_schedule_core(data, rcon_iteration)",
        "snippet": "def key_schedule_core(data, rcon_iteration):\n    data = rotate(data)\n    data = sub_bytes(data)\n    data[0] = data[0] ^ RCON[rcon_iteration]\n\n    return data",
        "begin_line": 264,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.xor#272",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.xor(data1, data2)",
        "snippet": "def xor(data1, data2):\n    return [x ^ y for x, y in zip(data1, data2)]",
        "begin_line": 272,
        "end_line": 273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.rijndael_mul#276",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.rijndael_mul(a, b)",
        "snippet": "def rijndael_mul(a, b):\n    if(a == 0 or b == 0):\n        return 0\n    return RIJNDAEL_EXP_TABLE[(RIJNDAEL_LOG_TABLE[a] + RIJNDAEL_LOG_TABLE[b]) % 0xFF]",
        "begin_line": 276,
        "end_line": 279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.mix_column#282",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_column(data, matrix)",
        "snippet": "def mix_column(data, matrix):\n    data_mixed = []\n    for row in range(4):\n        mixed = 0\n        for column in range(4):\n            # xor is (+) and (-)\n            mixed ^= rijndael_mul(data[column], matrix[row][column])\n        data_mixed.append(mixed)\n    return data_mixed",
        "begin_line": 282,
        "end_line": 290,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.mix_columns#293",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_columns(data, matrix=MIX_COLUMN_MATRIX)",
        "snippet": "def mix_columns(data, matrix=MIX_COLUMN_MATRIX):\n    data_mixed = []\n    for i in range(4):\n        column = data[i * 4: (i + 1) * 4]\n        data_mixed += mix_column(column, matrix)\n    return data_mixed",
        "begin_line": 293,
        "end_line": 298,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.mix_columns_inv#301",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_columns_inv(data)",
        "snippet": "def mix_columns_inv(data):\n    return mix_columns(data, MIX_COLUMN_MATRIX_INV)",
        "begin_line": 301,
        "end_line": 302,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.shift_rows#305",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.shift_rows(data)",
        "snippet": "def shift_rows(data):\n    data_shifted = []\n    for column in range(4):\n        for row in range(4):\n            data_shifted.append(data[((column + row) & 0b11) * 4 + row])\n    return data_shifted",
        "begin_line": 305,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.shift_rows_inv#313",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.shift_rows_inv(data)",
        "snippet": "def shift_rows_inv(data):\n    data_shifted = []\n    for column in range(4):\n        for row in range(4):\n            data_shifted.append(data[((column - row) & 0b11) * 4 + row])\n    return data_shifted",
        "begin_line": 313,
        "end_line": 318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.aes.inc#321",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.inc(data)",
        "snippet": "def inc(data):\n    data = data[:]  # copy\n    for i in range(len(data) - 1, -1, -1):\n        if data[i] == 255:\n            data[i] = 0\n        else:\n            data[i] = data[i] + 1\n            break\n    return data",
        "begin_line": 321,
        "end_line": 329,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.letv.LetvTvIE._real_extract#167",
        "src_path": "youtube_dl/extractor/letv.py",
        "class_name": "youtube_dl.extractor.letv.LetvTvIE",
        "signature": "youtube_dl.extractor.letv.LetvTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        page = self._download_webpage(url, playlist_id)\n\n        media_urls = list(set(re.findall(\n            r'http://www.letv.com/ptv/vplay/\\d+.html', page)))\n        entries = [self.url_result(media_url, ie='Letv')\n                   for media_url in media_urls]\n\n        title = self._html_search_meta('keywords', page,\n                                       fatal=False).split('\uff0c')[0]\n        description = self._html_search_meta('description', page, fatal=False)\n\n        return self.playlist_result(entries, playlist_id, playlist_title=title,\n                                    playlist_description=description)",
        "begin_line": 167,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00026191723415400735,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE._real_extract#161",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader_id = mobj.group('subdomain')\n        album_id = mobj.group('album_id')\n        playlist_id = album_id or uploader_id\n        webpage = self._download_webpage(url, playlist_id)\n        tracks_paths = re.findall(r'<a href=\"(.*?)\" itemprop=\"url\">', webpage)\n        if not tracks_paths:\n            raise ExtractorError('The page doesn\\'t contain any tracks')\n        entries = [\n            self.url_result(compat_urlparse.urljoin(url, t_path), ie=BandcampIE.ie_key())\n            for t_path in tracks_paths]\n        title = self._search_regex(\n            r'album_title\\s*:\\s*\"(.*?)\"', webpage, 'title', fatal=False)\n        return {\n            '_type': 'playlist',\n            'uploader_id': uploader_id,\n            'id': playlist_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 161,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002608242044861763,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.steam.SteamIE._real_extract#62",
        "src_path": "youtube_dl/extractor/steam.py",
        "class_name": "youtube_dl.extractor.steam.SteamIE",
        "signature": "youtube_dl.extractor.steam.SteamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        fileID = m.group('fileID')\n        if fileID:\n            videourl = url\n            playlist_id = fileID\n        else:\n            gameID = m.group('gameID')\n            playlist_id = gameID\n            videourl = self._VIDEO_PAGE_TEMPLATE % playlist_id\n        webpage = self._download_webpage(videourl, playlist_id)\n\n        if re.search('<h2>Please enter your birth date to continue:</h2>', webpage) is not None:\n            videourl = self._AGECHECK_TEMPLATE % playlist_id\n            self.report_age_confirmation()\n            webpage = self._download_webpage(videourl, playlist_id)\n\n        if fileID:\n            playlist_title = self._html_search_regex(\n                r'<div class=\"workshopItemTitle\">(.+)</div>', webpage, 'title')\n            mweb = re.finditer(r'''(?x)\n                'movie_(?P<videoID>[0-9]+)':\\s*\\{\\s*\n                YOUTUBE_VIDEO_ID:\\s*\"(?P<youtube_id>[^\"]+)\",\n                ''', webpage)\n            videos = [{\n                '_type': 'url',\n                'url': vid.group('youtube_id'),\n                'ie_key': 'Youtube',\n            } for vid in mweb]\n        else:\n            playlist_title = self._html_search_regex(\n                r'<h2 class=\"pageheader\">(.*?)</h2>', webpage, 'game title')\n\n            mweb = re.finditer(r'''(?x)\n                'movie_(?P<videoID>[0-9]+)':\\s*\\{\\s*\n                FILENAME:\\s*\"(?P<videoURL>[\\w:/\\.\\?=]+)\"\n                (,\\s*MOVIE_NAME:\\s*\\\"(?P<videoName>[\\w:/\\.\\?=\\+-]+)\\\")?\\s*\\},\n                ''', webpage)\n            titles = re.finditer(\n                r'<span class=\"title\">(?P<videoName>.+?)</span>', webpage)\n            thumbs = re.finditer(\n                r'<img class=\"movie_thumb\" src=\"(?P<thumbnail>.+?)\">', webpage)\n            videos = []\n\n            for vid, vtitle, thumb in zip(mweb, titles, thumbs):\n                video_id = vid.group('videoID')\n                title = vtitle.group('videoName')\n                video_url = vid.group('videoURL')\n                video_thumb = thumb.group('thumbnail')\n                if not video_url:\n                    raise ExtractorError('Cannot find video url for %s' % video_id)\n                videos.append({\n                    'id': video_id,\n                    'url': video_url,\n                    'ext': 'flv',\n                    'title': unescapeHTML(title),\n                    'thumbnail': video_thumb\n                })\n        if not videos:\n            raise ExtractorError('Could not find any videos')\n\n        return self.playlist_result(videos, playlist_id, playlist_title)",
        "begin_line": 62,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007818608287724785,
            "pseudo_dstar_susp": 0.000774593338497289,
            "pseudo_tarantula_susp": 0.0009560229445506692,
            "pseudo_op2_susp": 0.000774593338497289,
            "pseudo_barinel_susp": 0.0009560229445506692
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.__init__#33",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        PostProcessor.__init__(self, downloader)\n        self._determine_executables()",
        "begin_line": 33,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.get_versions#50",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.get_versions(downloader=None)",
        "snippet": "    def get_versions(downloader=None):\n        return FFmpegPostProcessor(downloader)._versions",
        "begin_line": 50,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._determine_executables#53",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._determine_executables(self)",
        "snippet": "    def _determine_executables(self):\n        programs = ['avprobe', 'avconv', 'ffmpeg', 'ffprobe']\n        prefer_ffmpeg = self._downloader.params.get('prefer_ffmpeg', False)\n\n        self.basename = None\n        self.probe_basename = None\n\n        self._paths = None\n        self._versions = None\n        if self._downloader:\n            location = self._downloader.params.get('ffmpeg_location')\n            if location is not None:\n                if not os.path.exists(location):\n                    self._downloader.report_warning(\n                        'ffmpeg-location %s does not exist! '\n                        'Continuing without avconv/ffmpeg.' % (location))\n                    self._versions = {}\n                    return\n                elif not os.path.isdir(location):\n                    basename = os.path.splitext(os.path.basename(location))[0]\n                    if basename not in programs:\n                        self._downloader.report_warning(\n                            'Cannot identify executable %s, its basename should be one of %s. '\n                            'Continuing without avconv/ffmpeg.' %\n                            (location, ', '.join(programs)))\n                        self._versions = {}\n                        return None\n                    location = os.path.dirname(os.path.abspath(location))\n                    if basename in ('ffmpeg', 'ffprobe'):\n                        prefer_ffmpeg = True\n\n                self._paths = dict(\n                    (p, os.path.join(location, p)) for p in programs)\n                self._versions = dict(\n                    (p, get_exe_version(self._paths[p], args=['-version']))\n                    for p in programs)\n        if self._versions is None:\n            self._versions = dict(\n                (p, get_exe_version(p, args=['-version'])) for p in programs)\n            self._paths = dict((p, p) for p in programs)\n\n        if prefer_ffmpeg:\n            prefs = ('ffmpeg', 'avconv')\n        else:\n            prefs = ('avconv', 'ffmpeg')\n        for p in prefs:\n            if self._versions[p]:\n                self.basename = p\n                break\n\n        if prefer_ffmpeg:\n            prefs = ('ffprobe', 'avprobe')\n        else:\n            prefs = ('avprobe', 'ffprobe')\n        for p in prefs:\n            if self._versions[p]:\n                self.probe_basename = p\n                break",
        "begin_line": 53,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.__init__#163",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.__init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False)",
        "snippet": "    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False):\n        FFmpegPostProcessor.__init__(self, downloader)\n        if preferredcodec is None:\n            preferredcodec = 'best'\n        self._preferredcodec = preferredcodec\n        self._preferredquality = preferredquality\n        self._nopostoverwrites = nopostoverwrites",
        "begin_line": 163,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002498750624687656,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.get_audio_codec#171",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.get_audio_codec(self, path)",
        "snippet": "    def get_audio_codec(self, path):\n\n        if not self.probe_available:\n            raise PostProcessingError('ffprobe or avprobe not found. Please install one.')\n        try:\n            cmd = [\n                encodeFilename(self.probe_executable, True),\n                encodeArgument('-show_streams'),\n                encodeFilename(self._ffmpeg_filename_argument(path), True)]\n            if self._downloader.params.get('verbose', False):\n                self._downloader.to_screen('[debug] %s command line: %s' % (self.basename, shell_quote(cmd)))\n            handle = subprocess.Popen(cmd, stderr=compat_subprocess_get_DEVNULL(), stdout=subprocess.PIPE, stdin=subprocess.PIPE)\n            output = handle.communicate()[0]\n            if handle.wait() != 0:\n                return None\n        except (IOError, OSError):\n            return None\n        audio_codec = None\n        for line in output.decode('ascii', 'ignore').split('\\n'):\n            if line.startswith('codec_name='):\n                audio_codec = line.split('=')[1].strip()\n            elif line.strip() == 'codec_type=audio' and audio_codec is not None:\n                return audio_codec\n        return None",
        "begin_line": 171,
        "end_line": 194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025150905432595576,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP.run#295",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP.run(self, information)",
        "snippet": "    def run(self, information):\n        path = information['filepath']\n        prefix, sep, ext = path.rpartition('.')\n        outpath = prefix + sep + self._preferedformat\n        if information['ext'] == self._preferedformat:\n            self._downloader.to_screen('[ffmpeg] Not converting video file %s - already is in target format %s' % (path, self._preferedformat))\n            return [], information\n        self._downloader.to_screen('[' + 'ffmpeg' + '] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) + outpath)\n        self.run_ffmpeg(path, outpath, [])\n        information['filepath'] = outpath\n        information['format'] = self._preferedformat\n        information['ext'] = self._preferedformat\n        return [path], information",
        "begin_line": 295,
        "end_line": 307,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.run#311",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.run(self, information)",
        "snippet": "    def run(self, information):\n        if information['ext'] not in ['mp4', 'mkv']:\n            self._downloader.to_screen('[ffmpeg] Subtitles can only be embedded in mp4 or mkv files')\n            return [], information\n        subtitles = information.get('requested_subtitles')\n        if not subtitles:\n            self._downloader.to_screen('[ffmpeg] There aren\\'t any subtitles to embed')\n            return [], information\n\n        sub_langs = list(subtitles.keys())\n        filename = information['filepath']\n        sub_filenames = [subtitles_filename(filename, lang, sub_info['ext']) for lang, sub_info in subtitles.items()]\n        input_files = [filename] + sub_filenames\n\n        opts = [\n            '-map', '0',\n            '-c', 'copy',\n            # Don't copy the existing subtitles, we may be running the\n            # postprocessor a second time\n            '-map', '-0:s',\n        ]\n        if information['ext'] == 'mp4':\n            opts += ['-c:s', 'mov_text']\n        for (i, lang) in enumerate(sub_langs):\n            opts.extend(['-map', '%d:0' % (i + 1)])\n            lang_code = ISO639Utils.short2long(lang)\n            if lang_code is not None:\n                opts.extend(['-metadata:s:s:%d' % i, 'language=%s' % lang_code])\n\n        temp_filename = prepend_extension(filename, 'temp')\n        self._downloader.to_screen('[ffmpeg] Embedding subtitles in \\'%s\\'' % filename)\n        self.run_ffmpeg_multiple_files(input_files, temp_filename, opts)\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return sub_filenames, information",
        "begin_line": 311,
        "end_line": 346,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP.run#350",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP.run(self, info)",
        "snippet": "    def run(self, info):\n        metadata = {}\n        if info.get('title') is not None:\n            metadata['title'] = info['title']\n        if info.get('upload_date') is not None:\n            metadata['date'] = info['upload_date']\n        if info.get('artist') is not None:\n            metadata['artist'] = info['artist']\n        elif info.get('uploader') is not None:\n            metadata['artist'] = info['uploader']\n        elif info.get('uploader_id') is not None:\n            metadata['artist'] = info['uploader_id']\n        if info.get('description') is not None:\n            metadata['description'] = info['description']\n            metadata['comment'] = info['description']\n        if info.get('webpage_url') is not None:\n            metadata['purl'] = info['webpage_url']\n        if info.get('album') is not None:\n            metadata['album'] = info['album']\n\n        if not metadata:\n            self._downloader.to_screen('[ffmpeg] There isn\\'t any metadata to add')\n            return [], info\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        if info['ext'] == 'm4a':\n            options = ['-vn', '-acodec', 'copy']\n        else:\n            options = ['-c', 'copy']\n\n        for (name, value) in metadata.items():\n            options.extend(['-metadata', '%s=%s' % (name, value)])\n\n        self._downloader.to_screen('[ffmpeg] Adding metadata to \\'%s\\'' % filename)\n        self.run_ffmpeg(filename, temp_filename, options)\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n        return [], info",
        "begin_line": 350,
        "end_line": 389,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupStretchedPP.run#421",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupStretchedPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupStretchedPP.run(self, info)",
        "snippet": "    def run(self, info):\n        stretched_ratio = info.get('stretched_ratio')\n        if stretched_ratio is None or stretched_ratio == 1:\n            return [], info\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        options = ['-c', 'copy', '-aspect', '%f' % stretched_ratio]\n        self._downloader.to_screen('[ffmpeg] Fixing aspect ratio in \"%s\"' % filename)\n        self.run_ffmpeg(filename, temp_filename, options)\n\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return [], info",
        "begin_line": 421,
        "end_line": 436,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNBlogsIE._real_extract#138",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNBlogsIE",
        "signature": "youtube_dl.extractor.cnn.CNNBlogsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, url_basename(url))\n        cnn_url = self._html_search_regex(r'data-url=\"(.+?)\"', webpage, 'cnn url')\n        return {\n            '_type': 'url',\n            'url': cnn_url,\n            'ie_key': CNNIE.ie_key(),\n        }",
        "begin_line": 138,
        "end_line": 145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002572678157962439,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.preferredencoding#70",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.preferredencoding()",
        "snippet": "def preferredencoding():\n    \"\"\"Get preferred encoding.\n\n    Returns the best encoding scheme for the system, based on\n    locale.getpreferredencoding() and some further tweaks.\n    \"\"\"\n    try:\n        pref = locale.getpreferredencoding()\n        'TEST'.encode(pref)\n    except Exception:\n        pref = 'UTF-8'\n\n    return pref",
        "begin_line": 70,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.write_json_file#85",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_json_file(obj, fn)",
        "snippet": "def write_json_file(obj, fn):\n    \"\"\" Encode obj as JSON and write it to fn, atomically if possible \"\"\"\n\n    fn = encodeFilename(fn)\n    if sys.version_info < (3, 0) and sys.platform != 'win32':\n        encoding = get_filesystem_encoding()\n        # os.path.basename returns a bytes object, but NamedTemporaryFile\n        # will fail if the filename contains non ascii characters unless we\n        # use a unicode object\n        path_basename = lambda f: os.path.basename(fn).decode(encoding)\n        # the same for os.path.dirname\n        path_dirname = lambda f: os.path.dirname(fn).decode(encoding)\n    else:\n        path_basename = os.path.basename\n        path_dirname = os.path.dirname\n\n    args = {\n        'suffix': '.tmp',\n        'prefix': path_basename(fn) + '.',\n        'dir': path_dirname(fn),\n        'delete': False,\n    }\n\n    # In Python 2.x, json.dump expects a bytestream.\n    # In Python 3.x, it writes to a character stream\n    if sys.version_info < (3, 0):\n        args['mode'] = 'wb'\n    else:\n        args.update({\n            'mode': 'w',\n            'encoding': 'utf-8',\n        })\n\n    tf = tempfile.NamedTemporaryFile(**compat_kwargs(args))\n\n    try:\n        with tf:\n            json.dump(obj, tf)\n        if sys.platform == 'win32':\n            # Need to remove existing file on Windows, else os.rename raises\n            # WindowsError or FileExistsError.\n            try:\n                os.unlink(fn)\n            except OSError:\n                pass\n        os.rename(tf.name, fn)\n    except Exception:\n        try:\n            os.remove(tf.name)\n        except OSError:\n            pass\n        raise",
        "begin_line": 85,
        "end_line": 136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005747126436781609,
            "pseudo_dstar_susp": 0.003484320557491289,
            "pseudo_tarantula_susp": 0.001358695652173913,
            "pseudo_op2_susp": 0.003484320557491289,
            "pseudo_barinel_susp": 0.001358695652173913
        }
    },
    {
        "name": "youtube_dl.utils.find_xpath_attr#140",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.find_xpath_attr(node, xpath, key, val)",
        "snippet": "    def find_xpath_attr(node, xpath, key, val):\n        \"\"\" Find the xpath xpath[@key=val] \"\"\"\n        assert re.match(r'^[a-zA-Z-]+$', key)\n        assert re.match(r'^[a-zA-Z0-9@\\s:._-]*$', val)\n        expr = xpath + \"[@%s='%s']\" % (key, val)\n        return node.find(expr)",
        "begin_line": 140,
        "end_line": 145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.xpath_with_ns#162",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_with_ns(path, ns_map)",
        "snippet": "def xpath_with_ns(path, ns_map):\n    components = [c.split(':') for c in path.split('/')]\n    replaced = []\n    for c in components:\n        if len(c) == 1:\n            replaced.append(c[0])\n        else:\n            ns, tag = c\n            replaced.append('{%s}%s' % (ns_map[ns], tag))\n    return '/'.join(replaced)",
        "begin_line": 162,
        "end_line": 171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.xpath_text#174",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_text(node, xpath, name=None, fatal=False)",
        "snippet": "def xpath_text(node, xpath, name=None, fatal=False):\n    if sys.version_info < (2, 7):  # Crazy 2.6\n        xpath = xpath.encode('ascii')\n\n    n = node.find(xpath)\n    if n is None or n.text is None:\n        if fatal:\n            name = xpath if name is None else name\n            raise ExtractorError('Could not find XML element %s' % name)\n        else:\n            return None\n    return n.text",
        "begin_line": 174,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.clean_html#216",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.clean_html(html)",
        "snippet": "def clean_html(html):\n    \"\"\"Clean an HTML snippet into a readable string\"\"\"\n\n    if html is None:  # Convenience for sanitizing descriptions etc.\n        return html\n\n    # Newline vs <br />\n    html = html.replace('\\n', ' ')\n    html = re.sub(r'\\s*<\\s*br\\s*/?\\s*>\\s*', '\\n', html)\n    html = re.sub(r'<\\s*/\\s*p\\s*>\\s*<\\s*p[^>]*>', '\\n', html)\n    # Strip html tags\n    html = re.sub('<.*?>', '', html)\n    # Replace html entities\n    html = unescapeHTML(html)\n    return html.strip()",
        "begin_line": 216,
        "end_line": 230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.002680965147453083,
            "pseudo_tarantula_susp": 0.001567398119122257,
            "pseudo_op2_susp": 0.002680965147453083,
            "pseudo_barinel_susp": 0.0015552099533437014
        }
    },
    {
        "name": "youtube_dl.utils.sanitize_open#233",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_open(filename, open_mode)",
        "snippet": "def sanitize_open(filename, open_mode):\n    \"\"\"Try to open the given filename, and slightly tweak it if this fails.\n\n    Attempts to open the given filename. If this fails, it tries to change\n    the filename slightly, step by step, until it's either able to open it\n    or it fails and raises a final exception, like the standard open()\n    function.\n\n    It returns the tuple (stream, definitive_file_name).\n    \"\"\"\n    try:\n        if filename == '-':\n            if sys.platform == 'win32':\n                import msvcrt\n                msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)\n            return (sys.stdout.buffer if hasattr(sys.stdout, 'buffer') else sys.stdout, filename)\n        stream = open(encodeFilename(filename), open_mode)\n        return (stream, filename)\n    except (IOError, OSError) as err:\n        if err.errno in (errno.EACCES,):\n            raise\n\n        # In case of error, try to remove win32 forbidden chars\n        alt_filename = sanitize_path(filename)\n        if alt_filename == filename:\n            raise\n        else:\n            # An exception here should be caught in the caller\n            stream = open(encodeFilename(alt_filename), open_mode)\n            return (stream, alt_filename)",
        "begin_line": 233,
        "end_line": 262,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002398081534772182,
            "pseudo_dstar_susp": 0.002386634844868735,
            "pseudo_tarantula_susp": 0.0014144271570014145,
            "pseudo_op2_susp": 0.002386634844868735,
            "pseudo_barinel_susp": 0.0014144271570014145
        }
    },
    {
        "name": "youtube_dl.utils.timeconvert#265",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.timeconvert(timestr)",
        "snippet": "def timeconvert(timestr):\n    \"\"\"Convert RFC 2822 defined time string into system timestamp\"\"\"\n    timestamp = None\n    timetuple = email.utils.parsedate_tz(timestr)\n    if timetuple is not None:\n        timestamp = email.utils.mktime_tz(timetuple)\n    return timestamp",
        "begin_line": 265,
        "end_line": 271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.sanitize_filename#274",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_filename(s, restricted=False, is_id=False)",
        "snippet": "def sanitize_filename(s, restricted=False, is_id=False):\n    \"\"\"Sanitizes a string so it could be used as part of a filename.\n    If restricted is set, use a stricter subset of allowed characters.\n    Set is_id if this is not an arbitrary string, but an ID that should be kept if possible\n    \"\"\"\n    def replace_insane(char):\n        if char == '?' or ord(char) < 32 or ord(char) == 127:\n            return ''\n        elif char == '\"':\n            return '' if restricted else '\\''\n        elif char == ':':\n            return '_-' if restricted else ' -'\n        elif char in '\\\\/|*<>':\n            return '_'\n        if restricted and (char in '!&\\'()[]{}$;`^,#' or char.isspace()):\n            return '_'\n        if restricted and ord(char) > 127:\n            return '_'\n        return char\n\n    # Handle timestamps\n    s = re.sub(r'[0-9]+(?::[0-9]+)+', lambda m: m.group(0).replace(':', '_'), s)\n    result = ''.join(map(replace_insane, s))\n    if not is_id:\n        while '__' in result:\n            result = result.replace('__', '_')\n        result = result.strip('_')\n        # Common case of \"Foreign band name - English song title\"\n        if restricted and result.startswith('-_'):\n            result = result[2:]\n        if result.startswith('-'):\n            result = '_' + result[len('-'):]\n        result = result.lstrip('.')\n        if not result:\n            result = '_'\n    return result",
        "begin_line": 274,
        "end_line": 309,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009487666034155598,
            "pseudo_dstar_susp": 0.004524886877828055,
            "pseudo_tarantula_susp": 0.0013869625520110957,
            "pseudo_op2_susp": 0.004524886877828055,
            "pseudo_barinel_susp": 0.0013869625520110957
        }
    },
    {
        "name": "youtube_dl.utils.replace_insane#279",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.replace_insane(char)",
        "snippet": "    def replace_insane(char):\n        if char == '?' or ord(char) < 32 or ord(char) == 127:\n            return ''\n        elif char == '\"':\n            return '' if restricted else '\\''\n        elif char == ':':\n            return '_-' if restricted else ' -'\n        elif char in '\\\\/|*<>':\n            return '_'\n        if restricted and (char in '!&\\'()[]{}$;`^,#' or char.isspace()):\n            return '_'\n        if restricted and ord(char) > 127:\n            return '_'\n        return char",
        "begin_line": 279,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009852216748768472,
            "pseudo_dstar_susp": 0.004132231404958678,
            "pseudo_tarantula_susp": 0.001567398119122257,
            "pseudo_op2_susp": 0.004132231404958678,
            "pseudo_barinel_susp": 0.0015552099533437014
        }
    },
    {
        "name": "youtube_dl.utils.sanitize_path#312",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_path(s)",
        "snippet": "def sanitize_path(s):\n    \"\"\"Sanitizes and normalizes path on Windows\"\"\"\n    if sys.platform != 'win32':\n        return s\n    drive_or_unc, _ = os.path.splitdrive(s)\n    if sys.version_info < (2, 7) and not drive_or_unc:\n        drive_or_unc, _ = os.path.splitunc(s)\n    norm_path = os.path.normpath(remove_start(s, drive_or_unc)).split(os.path.sep)\n    if drive_or_unc:\n        norm_path.pop(0)\n    sanitized_path = [\n        path_part if path_part in ['.', '..'] else re.sub('(?:[/<>:\"\\\\|\\\\\\\\?\\\\*]|\\.$)', '#', path_part)\n        for path_part in norm_path]\n    if drive_or_unc:\n        sanitized_path.insert(0, drive_or_unc + os.path.sep)\n    return os.path.join(*sanitized_path)",
        "begin_line": 312,
        "end_line": 327,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.004524886877828055,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.004524886877828055,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.utils._htmlentity_transform#339",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._htmlentity_transform(entity)",
        "snippet": "def _htmlentity_transform(entity):\n    \"\"\"Transforms an HTML entity to a character.\"\"\"\n    # Known non-numeric HTML entity\n    if entity in compat_html_entities.name2codepoint:\n        return compat_chr(compat_html_entities.name2codepoint[entity])\n\n    mobj = re.match(r'#(x[0-9a-fA-F]+|[0-9]+)', entity)\n    if mobj is not None:\n        numstr = mobj.group(1)\n        if numstr.startswith('x'):\n            base = 16\n            numstr = '0%s' % numstr\n        else:\n            base = 10\n        return compat_chr(int(numstr, base))\n\n    # Unknown entity in name, return its literal representation\n    return ('&%s;' % entity)",
        "begin_line": 339,
        "end_line": 356,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.0008904719501335708,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.0008904719501335708,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.utils.unescapeHTML#359",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unescapeHTML(s)",
        "snippet": "def unescapeHTML(s):\n    if s is None:\n        return None\n    assert type(s) == compat_str\n\n    return re.sub(\n        r'&([^;]+);', lambda m: _htmlentity_transform(m.group(1)), s)",
        "begin_line": 359,
        "end_line": 365,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004166666666666667,
            "pseudo_dstar_susp": 0.002398081534772182,
            "pseudo_tarantula_susp": 0.001692047377326565,
            "pseudo_op2_susp": 0.002398081534772182,
            "pseudo_barinel_susp": 0.001692047377326565
        }
    },
    {
        "name": "youtube_dl.utils.encodeFilename#380",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encodeFilename(s, for_subprocess=False)",
        "snippet": "def encodeFilename(s, for_subprocess=False):\n    \"\"\"\n    @param s The name of the file\n    \"\"\"\n\n    assert type(s) == compat_str\n\n    # Python 3 has a Unicode API\n    if sys.version_info >= (3, 0):\n        return s\n\n    # Pass '' directly to use Unicode APIs on Windows 2000 and up\n    # (Detecting Windows NT 4 is tricky because 'major >= 4' would\n    # match Windows 9x series as well. Besides, NT 4 is obsolete.)\n    if not for_subprocess and sys.platform == 'win32' and sys.getwindowsversion()[0] >= 5:\n        return s\n\n    return s.encode(get_subprocess_encoding(), 'ignore')",
        "begin_line": 380,
        "end_line": 397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014749262536873156,
            "pseudo_dstar_susp": 0.002,
            "pseudo_tarantula_susp": 0.001567398119122257,
            "pseudo_op2_susp": 0.002,
            "pseudo_barinel_susp": 0.0015552099533437014
        }
    },
    {
        "name": "youtube_dl.utils.decodeFilename#400",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decodeFilename(b, for_subprocess=False)",
        "snippet": "def decodeFilename(b, for_subprocess=False):\n\n    if sys.version_info >= (3, 0):\n        return b\n\n    if not isinstance(b, bytes):\n        return b\n\n    return b.decode(get_subprocess_encoding(), 'ignore')",
        "begin_line": 400,
        "end_line": 408,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.encodeArgument#411",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encodeArgument(s)",
        "snippet": "def encodeArgument(s):\n    if not isinstance(s, compat_str):\n        # Legacy code that uses byte strings\n        # Uncomment the following line after fixing all post processors\n        # assert False, 'Internal error: %r should be of type %r, is %r' % (s, compat_str, type(s))\n        s = s.decode('ascii')\n    return encodeFilename(s, True)",
        "begin_line": 411,
        "end_line": 417,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.decodeOption#424",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decodeOption(optval)",
        "snippet": "def decodeOption(optval):\n    if optval is None:\n        return optval\n    if isinstance(optval, bytes):\n        optval = optval.decode(preferredencoding())\n\n    assert isinstance(optval, compat_str)\n    return optval",
        "begin_line": 424,
        "end_line": 431,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.formatSeconds#434",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.formatSeconds(secs)",
        "snippet": "def formatSeconds(secs):\n    if secs > 3600:\n        return '%d:%02d:%02d' % (secs // 3600, (secs % 3600) // 60, secs % 60)\n    elif secs > 60:\n        return '%d:%02d' % (secs // 60, secs % 60)\n    else:\n        return '%d' % secs",
        "begin_line": 434,
        "end_line": 440,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.make_HTTPS_handler#443",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.make_HTTPS_handler(params, **kwargs)",
        "snippet": "def make_HTTPS_handler(params, **kwargs):\n    opts_no_check_certificate = params.get('nocheckcertificate', False)\n    if hasattr(ssl, 'create_default_context'):  # Python >= 3.4 or 2.7.9\n        context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n        if opts_no_check_certificate:\n            context.check_hostname = False\n            context.verify_mode = ssl.CERT_NONE\n        try:\n            return YoutubeDLHTTPSHandler(params, context=context, **kwargs)\n        except TypeError:\n            # Python 2.7.8\n            # (create_default_context present but HTTPSHandler has no context=)\n            pass\n\n    if sys.version_info < (3, 2):\n        return YoutubeDLHTTPSHandler(params, **kwargs)\n    else:  # Python < 3.4\n        context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n        context.verify_mode = (ssl.CERT_NONE\n                               if opts_no_check_certificate\n                               else ssl.CERT_REQUIRED)\n        context.set_default_verify_paths()\n        return YoutubeDLHTTPSHandler(params, context=context, **kwargs)",
        "begin_line": 443,
        "end_line": 465,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008264462809917356,
            "pseudo_dstar_susp": 0.04,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.04,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.utils.bug_reports_message#468",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.bug_reports_message()",
        "snippet": "def bug_reports_message():\n    if ytdl_is_updateable():\n        update_cmd = 'type  youtube-dl -U  to update'\n    else:\n        update_cmd = 'see  https://yt-dl.org/update  on how to update'\n    msg = '; please report this issue on https://yt-dl.org/bug .'\n    msg += ' Make sure you are using the latest version; %s.' % update_cmd\n    msg += ' Be sure to call youtube-dl with the --verbose flag and include its complete output.'\n    return msg",
        "begin_line": 468,
        "end_line": 476,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.024390243902439025,
            "pseudo_dstar_susp": 0.003745318352059925,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.003745318352059925,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.ExtractorError.__init__#482",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ExtractorError",
        "signature": "youtube_dl.utils.ExtractorError.__init__(self, msg, tb=None, expected=False, cause=None, video_id=None)",
        "snippet": "    def __init__(self, msg, tb=None, expected=False, cause=None, video_id=None):\n        \"\"\" tb, if given, is the original traceback (so that it can be printed out).\n        If expected is set, this is a normal error message and most likely not a bug in youtube-dl.\n        \"\"\"\n\n        if sys.exc_info()[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError):\n            expected = True\n        if video_id is not None:\n            msg = video_id + ': ' + msg\n        if cause:\n            msg += ' (caused by %r)' % cause\n        if not expected:\n            msg += bug_reports_message()\n        super(ExtractorError, self).__init__(msg)\n\n        self.traceback = tb\n        self.exc_info = sys.exc_info()  # preserve original exception\n        self.cause = cause\n        self.video_id = video_id",
        "begin_line": 482,
        "end_line": 500,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.09090909090909091,
            "pseudo_dstar_susp": 0.009174311926605505,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.009174311926605505,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.ExtractorError.format_traceback#502",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ExtractorError",
        "signature": "youtube_dl.utils.ExtractorError.format_traceback(self)",
        "snippet": "    def format_traceback(self):\n        if self.traceback is None:\n            return None\n        return ''.join(traceback.format_tb(self.traceback))",
        "begin_line": 502,
        "end_line": 505,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00425531914893617,
            "pseudo_dstar_susp": 0.008547008547008548,
            "pseudo_tarantula_susp": 0.0017391304347826088,
            "pseudo_op2_susp": 0.008547008547008548,
            "pseudo_barinel_susp": 0.0017391304347826088
        }
    },
    {
        "name": "youtube_dl.utils.DownloadError.__init__#528",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DownloadError",
        "signature": "youtube_dl.utils.DownloadError.__init__(self, msg, exc_info=None)",
        "snippet": "    def __init__(self, msg, exc_info=None):\n        \"\"\" exc_info, if given, is the original exception that caused the trouble (as returned by sys.exc_info()). \"\"\"\n        super(DownloadError, self).__init__(msg)\n        self.exc_info = exc_info",
        "begin_line": 528,
        "end_line": 531,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024691358024691358,
            "pseudo_dstar_susp": 0.00390625,
            "pseudo_tarantula_susp": 0.0016556291390728477,
            "pseudo_op2_susp": 0.00390625,
            "pseudo_barinel_susp": 0.0016556291390728477
        }
    },
    {
        "name": "youtube_dl.utils.ContentTooShortError.__init__#579",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ContentTooShortError",
        "signature": "youtube_dl.utils.ContentTooShortError.__init__(self, downloaded, expected)",
        "snippet": "    def __init__(self, downloaded, expected):\n        self.downloaded = downloaded\n        self.expected = expected",
        "begin_line": 579,
        "end_line": 581,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils._create_http_connection#584",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._create_http_connection(ydl_handler, http_class, is_https, *args, **kwargs)",
        "snippet": "def _create_http_connection(ydl_handler, http_class, is_https, *args, **kwargs):\n    hc = http_class(*args, **kwargs)\n    source_address = ydl_handler._params.get('source_address')\n    if source_address is not None:\n        sa = (source_address, 0)\n        if hasattr(hc, 'source_address'):  # Python 2.7+\n            hc.source_address = sa\n        else:  # Python 2.6\n            def _hc_connect(self, *args, **kwargs):\n                sock = compat_socket_create_connection(\n                    (self.host, self.port), self.timeout, sa)\n                if is_https:\n                    self.sock = ssl.wrap_socket(\n                        sock, self.key_file, self.cert_file,\n                        ssl_version=ssl.PROTOCOL_TLSv1)\n                else:\n                    self.sock = sock\n            hc.connect = functools.partial(_hc_connect, hc)\n\n    return hc",
        "begin_line": 584,
        "end_line": 603,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005847953216374269,
            "pseudo_dstar_susp": 0.01282051282051282,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.01282051282051282,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.__init__#624",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.__init__(self, params, *args, **kwargs)",
        "snippet": "    def __init__(self, params, *args, **kwargs):\n        compat_urllib_request.HTTPHandler.__init__(self, *args, **kwargs)\n        self._params = params",
        "begin_line": 624,
        "end_line": 626,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008264462809917356,
            "pseudo_dstar_susp": 0.04,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.04,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_open#628",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_open(self, req)",
        "snippet": "    def http_open(self, req):\n        return self.do_open(functools.partial(\n            _create_http_connection, self, compat_http_client.HTTPConnection, False),\n            req)",
        "begin_line": 628,
        "end_line": 631,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031746031746031746,
            "pseudo_dstar_susp": 0.0064516129032258064,
            "pseudo_tarantula_susp": 0.0017301038062283738,
            "pseudo_op2_susp": 0.006802721088435374,
            "pseudo_barinel_susp": 0.0017301038062283738
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.addinfourl_wrapper#641",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.addinfourl_wrapper(stream, headers, url, code)",
        "snippet": "    def addinfourl_wrapper(stream, headers, url, code):\n        if hasattr(compat_urllib_request.addinfourl, 'getcode'):\n            return compat_urllib_request.addinfourl(stream, headers, url, code)\n        ret = compat_urllib_request.addinfourl(stream, headers, url)\n        ret.code = code\n        return ret",
        "begin_line": 641,
        "end_line": 646,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.017241379310344827,
            "pseudo_dstar_susp": 0.003424657534246575,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.003424657534246575,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_request#648",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_request(self, req)",
        "snippet": "    def http_request(self, req):\n        for h, v in std_headers.items():\n            # Capitalize is needed because of Python bug 2275: http://bugs.python.org/issue2275\n            # The dict keys are capitalized because of this bug by urllib\n            if h.capitalize() not in req.headers:\n                req.add_header(h, v)\n        if 'Youtubedl-no-compression' in req.headers:\n            if 'Accept-encoding' in req.headers:\n                del req.headers['Accept-encoding']\n            del req.headers['Youtubedl-no-compression']\n\n        if sys.version_info < (2, 7) and '#' in req.get_full_url():\n            # Python 2.6 is brain-dead when it comes to fragments\n            req._Request__original = req._Request__original.partition('#')[0]\n            req._Request__r_type = req._Request__r_type.partition('#')[0]\n\n        return req",
        "begin_line": 648,
        "end_line": 664,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008928571428571428,
            "pseudo_dstar_susp": 0.01282051282051282,
            "pseudo_tarantula_susp": 0.0025575447570332483,
            "pseudo_op2_susp": 0.01282051282051282,
            "pseudo_barinel_susp": 0.0025575447570332483
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_response#666",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_response(self, req, resp)",
        "snippet": "    def http_response(self, req, resp):\n        old_resp = resp\n        # gzip\n        if resp.headers.get('Content-encoding', '') == 'gzip':\n            content = resp.read()\n            gz = gzip.GzipFile(fileobj=io.BytesIO(content), mode='rb')\n            try:\n                uncompressed = io.BytesIO(gz.read())\n            except IOError as original_ioerror:\n                # There may be junk add the end of the file\n                # See http://stackoverflow.com/q/4928560/35070 for details\n                for i in range(1, 1024):\n                    try:\n                        gz = gzip.GzipFile(fileobj=io.BytesIO(content[:-i]), mode='rb')\n                        uncompressed = io.BytesIO(gz.read())\n                    except IOError:\n                        continue\n                    break\n                else:\n                    raise original_ioerror\n            resp = self.addinfourl_wrapper(uncompressed, old_resp.headers, old_resp.url, old_resp.code)\n            resp.msg = old_resp.msg\n        # deflate\n        if resp.headers.get('Content-encoding', '') == 'deflate':\n            gz = io.BytesIO(self.deflate(resp.read()))\n            resp = self.addinfourl_wrapper(gz, old_resp.headers, old_resp.url, old_resp.code)\n            resp.msg = old_resp.msg\n        return resp",
        "begin_line": 666,
        "end_line": 693,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.03125,
            "pseudo_dstar_susp": 0.004975124378109453,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.004901960784313725,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHTTPSHandler.__init__#700",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHTTPSHandler",
        "signature": "youtube_dl.utils.YoutubeDLHTTPSHandler.__init__(self, params, https_conn_class=None, *args, **kwargs)",
        "snippet": "    def __init__(self, params, https_conn_class=None, *args, **kwargs):\n        compat_urllib_request.HTTPSHandler.__init__(self, *args, **kwargs)\n        self._https_conn_class = https_conn_class or compat_http_client.HTTPSConnection\n        self._params = params",
        "begin_line": 700,
        "end_line": 703,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008264462809917356,
            "pseudo_dstar_susp": 0.04,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.04,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHTTPSHandler.https_open#705",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHTTPSHandler",
        "signature": "youtube_dl.utils.YoutubeDLHTTPSHandler.https_open(self, req)",
        "snippet": "    def https_open(self, req):\n        kwargs = {}\n        if hasattr(self, '_context'):  # python > 2.6\n            kwargs['context'] = self._context\n        if hasattr(self, '_check_hostname'):  # python 3.x\n            kwargs['check_hostname'] = self._check_hostname\n        return self.do_open(functools.partial(\n            _create_http_connection, self, self._https_conn_class, True),\n            req, **kwargs)",
        "begin_line": 705,
        "end_line": 713,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008928571428571428,
            "pseudo_dstar_susp": 0.00625,
            "pseudo_tarantula_susp": 0.0025575447570332483,
            "pseudo_op2_susp": 0.006172839506172839,
            "pseudo_barinel_susp": 0.0025575447570332483
        }
    },
    {
        "name": "youtube_dl.utils.parse_iso8601#716",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_iso8601(date_str, delimiter='T', timezone=None)",
        "snippet": "def parse_iso8601(date_str, delimiter='T', timezone=None):\n    \"\"\" Return a UNIX timestamp from the given date \"\"\"\n\n    if date_str is None:\n        return None\n\n    if timezone is None:\n        m = re.search(\n            r'(\\.[0-9]+)?(?:Z$| ?(?P<sign>\\+|-)(?P<hours>[0-9]{2}):?(?P<minutes>[0-9]{2})$)',\n            date_str)\n        if not m:\n            timezone = datetime.timedelta()\n        else:\n            date_str = date_str[:-len(m.group(0))]\n            if not m.group('sign'):\n                timezone = datetime.timedelta()\n            else:\n                sign = 1 if m.group('sign') == '+' else -1\n                timezone = datetime.timedelta(\n                    hours=sign * int(m.group('hours')),\n                    minutes=sign * int(m.group('minutes')))\n    date_format = '%Y-%m-%d{0}%H:%M:%S'.format(delimiter)\n    dt = datetime.datetime.strptime(date_str, date_format) - timezone\n    return calendar.timegm(dt.timetuple())",
        "begin_line": 716,
        "end_line": 739,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.unified_strdate#742",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unified_strdate(date_str, day_first=True)",
        "snippet": "def unified_strdate(date_str, day_first=True):\n    \"\"\"Return a string with the date in the format YYYYMMDD\"\"\"\n\n    if date_str is None:\n        return None\n    upload_date = None\n    # Replace commas\n    date_str = date_str.replace(',', ' ')\n    # %z (UTC offset) is only supported in python>=3.2\n    if not re.match(r'^[0-9]{1,2}-[0-9]{1,2}-[0-9]{4}$', date_str):\n        date_str = re.sub(r' ?(\\+|-)[0-9]{2}:?[0-9]{2}$', '', date_str)\n    # Remove AM/PM + timezone\n    date_str = re.sub(r'(?i)\\s*(?:AM|PM)(?:\\s+[A-Z]+)?', '', date_str)\n\n    format_expressions = [\n        '%d %B %Y',\n        '%d %b %Y',\n        '%B %d %Y',\n        '%b %d %Y',\n        '%b %dst %Y %I:%M%p',\n        '%b %dnd %Y %I:%M%p',\n        '%b %dth %Y %I:%M%p',\n        '%Y %m %d',\n        '%Y-%m-%d',\n        '%Y/%m/%d',\n        '%Y/%m/%d %H:%M:%S',\n        '%Y-%m-%d %H:%M:%S',\n        '%Y-%m-%d %H:%M:%S.%f',\n        '%d.%m.%Y %H:%M',\n        '%d.%m.%Y %H.%M',\n        '%Y-%m-%dT%H:%M:%SZ',\n        '%Y-%m-%dT%H:%M:%S.%fZ',\n        '%Y-%m-%dT%H:%M:%S.%f0Z',\n        '%Y-%m-%dT%H:%M:%S',\n        '%Y-%m-%dT%H:%M:%S.%f',\n        '%Y-%m-%dT%H:%M',\n    ]\n    if day_first:\n        format_expressions.extend([\n            '%d-%m-%Y',\n            '%d.%m.%Y',\n            '%d/%m/%Y',\n            '%d/%m/%y',\n            '%d/%m/%Y %H:%M:%S',\n        ])\n    else:\n        format_expressions.extend([\n            '%m-%d-%Y',\n            '%m.%d.%Y',\n            '%m/%d/%Y',\n            '%m/%d/%y',\n            '%m/%d/%Y %H:%M:%S',\n        ])\n    for expression in format_expressions:\n        try:\n            upload_date = datetime.datetime.strptime(date_str, expression).strftime('%Y%m%d')\n        except ValueError:\n            pass\n    if upload_date is None:\n        timetuple = email.utils.parsedate_tz(date_str)\n        if timetuple:\n            upload_date = datetime.datetime(*timetuple[:6]).strftime('%Y%m%d')\n    return upload_date",
        "begin_line": 742,
        "end_line": 804,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.determine_ext#807",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.determine_ext(url, default_ext='unknown_video')",
        "snippet": "def determine_ext(url, default_ext='unknown_video'):\n    if url is None:\n        return default_ext\n    guess = url.partition('?')[0].rpartition('.')[2]\n    if re.match(r'^[A-Za-z0-9]+$', guess):\n        return guess\n    else:\n        return default_ext",
        "begin_line": 807,
        "end_line": 814,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.subtitles_filename#817",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.subtitles_filename(filename, sub_lang, sub_format)",
        "snippet": "def subtitles_filename(filename, sub_lang, sub_format):\n    return filename.rsplit('.', 1)[0] + '.' + sub_lang + '.' + sub_format",
        "begin_line": 817,
        "end_line": 818,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.date_from_str#821",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.date_from_str(date_str)",
        "snippet": "def date_from_str(date_str):\n    \"\"\"\n    Return a datetime object from a string in the format YYYYMMDD or\n    (now|today)[+-][0-9](day|week|month|year)(s)?\"\"\"\n    today = datetime.date.today()\n    if date_str in ('now', 'today'):\n        return today\n    if date_str == 'yesterday':\n        return today - datetime.timedelta(days=1)\n    match = re.match('(now|today)(?P<sign>[+-])(?P<time>\\d+)(?P<unit>day|week|month|year)(s)?', date_str)\n    if match is not None:\n        sign = match.group('sign')\n        time = int(match.group('time'))\n        if sign == '-':\n            time = -time\n        unit = match.group('unit')\n        # A bad aproximation?\n        if unit == 'month':\n            unit = 'day'\n            time *= 30\n        elif unit == 'year':\n            unit = 'day'\n            time *= 365\n        unit += 's'\n        delta = datetime.timedelta(**{unit: time})\n        return today + delta\n    return datetime.datetime.strptime(date_str, \"%Y%m%d\").date()",
        "begin_line": 821,
        "end_line": 847,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__init__#863",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__init__(self, start=None, end=None)",
        "snippet": "    def __init__(self, start=None, end=None):\n        \"\"\"start and end must be strings in the format accepted by date\"\"\"\n        if start is not None:\n            self.start = date_from_str(start)\n        else:\n            self.start = datetime.datetime.min.date()\n        if end is not None:\n            self.end = date_from_str(end)\n        else:\n            self.end = datetime.datetime.max.date()\n        if self.start > self.end:\n            raise ValueError('Date range: \"%s\" , the start date must be before the end date' % self)",
        "begin_line": 863,
        "end_line": 874,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__contains__#881",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__contains__(self, date)",
        "snippet": "    def __contains__(self, date):\n        \"\"\"Check if the date is in the range\"\"\"\n        if not isinstance(date, datetime.date):\n            date = date_from_str(date)\n        return self.start <= date <= self.end",
        "begin_line": 881,
        "end_line": 885,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__str__#887",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__str__(self)",
        "snippet": "    def __str__(self):\n        return '%s - %s' % (self.start.isoformat(), self.end.isoformat())",
        "begin_line": 887,
        "end_line": 888,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.platform_name#891",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.platform_name()",
        "snippet": "def platform_name():\n    \"\"\" Returns the platform name as a compat_str \"\"\"\n    res = platform.platform()\n    if isinstance(res, bytes):\n        res = res.decode(preferredencoding())\n\n    assert isinstance(res, compat_str)\n    return res",
        "begin_line": 891,
        "end_line": 898,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils._windows_write_string#901",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._windows_write_string(s, out)",
        "snippet": "def _windows_write_string(s, out):\n    \"\"\" Returns True if the string was written using special methods,\n    False if it has yet to be written out.\"\"\"\n    # Adapted from http://stackoverflow.com/a/3259271/35070\n\n    import ctypes\n    import ctypes.wintypes\n\n    WIN_OUTPUT_IDS = {\n        1: -11,\n        2: -12,\n    }\n\n    try:\n        fileno = out.fileno()\n    except AttributeError:\n        # If the output stream doesn't have a fileno, it's virtual\n        return False\n    except io.UnsupportedOperation:\n        # Some strange Windows pseudo files?\n        return False\n    if fileno not in WIN_OUTPUT_IDS:\n        return False\n\n    GetStdHandle = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.HANDLE, ctypes.wintypes.DWORD)(\n        (b\"GetStdHandle\", ctypes.windll.kernel32))\n    h = GetStdHandle(WIN_OUTPUT_IDS[fileno])\n\n    WriteConsoleW = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.BOOL, ctypes.wintypes.HANDLE, ctypes.wintypes.LPWSTR,\n        ctypes.wintypes.DWORD, ctypes.POINTER(ctypes.wintypes.DWORD),\n        ctypes.wintypes.LPVOID)((b\"WriteConsoleW\", ctypes.windll.kernel32))\n    written = ctypes.wintypes.DWORD(0)\n\n    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)((b\"GetFileType\", ctypes.windll.kernel32))\n    FILE_TYPE_CHAR = 0x0002\n    FILE_TYPE_REMOTE = 0x8000\n    GetConsoleMode = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.BOOL, ctypes.wintypes.HANDLE,\n        ctypes.POINTER(ctypes.wintypes.DWORD))(\n        (b\"GetConsoleMode\", ctypes.windll.kernel32))\n    INVALID_HANDLE_VALUE = ctypes.wintypes.DWORD(-1).value\n\n    def not_a_console(handle):\n        if handle == INVALID_HANDLE_VALUE or handle is None:\n            return True\n        return ((GetFileType(handle) & ~FILE_TYPE_REMOTE) != FILE_TYPE_CHAR or\n                GetConsoleMode(handle, ctypes.byref(ctypes.wintypes.DWORD())) == 0)\n\n    if not_a_console(h):\n        return False\n\n    def next_nonbmp_pos(s):\n        try:\n            return next(i for i, c in enumerate(s) if ord(c) > 0xffff)\n        except StopIteration:\n            return len(s)\n\n    while s:\n        count = min(next_nonbmp_pos(s), 1024)\n\n        ret = WriteConsoleW(\n            h, s, count if count else 2, ctypes.byref(written), None)\n        if ret == 0:\n            raise OSError('Failed to write string')\n        if not count:  # We just wrote a non-BMP character\n            assert written.value == 2\n            s = s[1:]\n        else:\n            assert written.value > 0\n            s = s[written.value:]\n    return True",
        "begin_line": 901,
        "end_line": 973,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.write_string#976",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_string(s, out=None, encoding=None)",
        "snippet": "def write_string(s, out=None, encoding=None):\n    if out is None:\n        out = sys.stderr\n    assert type(s) == compat_str\n\n    if sys.platform == 'win32' and encoding is None and hasattr(out, 'fileno'):\n        if _windows_write_string(s, out):\n            return\n\n    if ('b' in getattr(out, 'mode', '') or\n            sys.version_info[0] < 3):  # Python 2 lies about mode of sys.stderr\n        byt = s.encode(encoding or preferredencoding(), 'ignore')\n        out.write(byt)\n    elif hasattr(out, 'buffer'):\n        enc = encoding or getattr(out, 'encoding', None) or preferredencoding()\n        byt = s.encode(enc, 'ignore')\n        out.buffer.write(byt)\n    else:\n        out.write(s)\n    out.flush()",
        "begin_line": 976,
        "end_line": 995,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031746031746031746,
            "pseudo_dstar_susp": 0.005405405405405406,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.005405405405405406,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.bytes_to_intlist#998",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.bytes_to_intlist(bs)",
        "snippet": "def bytes_to_intlist(bs):\n    if not bs:\n        return []\n    if isinstance(bs[0], int):  # Python 3\n        return list(bs)\n    else:\n        return [ord(c) for c in bs]",
        "begin_line": 998,
        "end_line": 1004,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00039635354736424893,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.intlist_to_bytes#1007",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.intlist_to_bytes(xs)",
        "snippet": "def intlist_to_bytes(xs):\n    if not xs:\n        return b''\n    return struct_pack('%dB' % len(xs), *xs)",
        "begin_line": 1007,
        "end_line": 1010,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils._lock_file#1071",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._lock_file(f, exclusive)",
        "snippet": "    def _lock_file(f, exclusive):\n        fcntl.flock(f, fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH)",
        "begin_line": 1071,
        "end_line": 1072,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils._unlock_file#1074",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._unlock_file(f)",
        "snippet": "    def _unlock_file(f):\n        fcntl.flock(f, fcntl.LOCK_UN)",
        "begin_line": 1074,
        "end_line": 1075,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__init__#1079",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__init__(self, filename, mode, encoding=None)",
        "snippet": "    def __init__(self, filename, mode, encoding=None):\n        assert mode in ['r', 'a', 'w']\n        self.f = io.open(filename, mode, encoding=encoding)\n        self.mode = mode",
        "begin_line": 1079,
        "end_line": 1082,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__enter__#1084",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__enter__(self)",
        "snippet": "    def __enter__(self):\n        exclusive = self.mode != 'r'\n        try:\n            _lock_file(self.f, exclusive)\n        except IOError:\n            self.f.close()\n            raise\n        return self",
        "begin_line": 1084,
        "end_line": 1091,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__exit__#1093",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__exit__(self, etype, value, traceback)",
        "snippet": "    def __exit__(self, etype, value, traceback):\n        try:\n            _unlock_file(self.f)\n        finally:\n            self.f.close()",
        "begin_line": 1093,
        "end_line": 1097,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__iter__#1099",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return iter(self.f)",
        "begin_line": 1099,
        "end_line": 1100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.write#1102",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.write(self, *args)",
        "snippet": "    def write(self, *args):\n        return self.f.write(*args)",
        "begin_line": 1102,
        "end_line": 1103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.read#1105",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.read(self, *args)",
        "snippet": "    def read(self, *args):\n        return self.f.read(*args)",
        "begin_line": 1105,
        "end_line": 1106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.get_filesystem_encoding#1109",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_filesystem_encoding()",
        "snippet": "def get_filesystem_encoding():\n    encoding = sys.getfilesystemencoding()\n    return encoding if encoding is not None else 'utf-8'",
        "begin_line": 1109,
        "end_line": 1111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.shell_quote#1114",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.shell_quote(args)",
        "snippet": "def shell_quote(args):\n    quoted_args = []\n    encoding = get_filesystem_encoding()\n    for a in args:\n        if isinstance(a, bytes):\n            # We may get a filename encoded with 'encodeFilename'\n            a = a.decode(encoding)\n        quoted_args.append(pipes.quote(a))\n    return ' '.join(quoted_args)",
        "begin_line": 1114,
        "end_line": 1122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.smuggle_url#1125",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.smuggle_url(url, data)",
        "snippet": "def smuggle_url(url, data):\n    \"\"\" Pass additional data in a URL for internal use. \"\"\"\n\n    sdata = compat_urllib_parse.urlencode(\n        {'__youtubedl_smuggle': json.dumps(data)})\n    return url + '#' + sdata",
        "begin_line": 1125,
        "end_line": 1130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.unsmuggle_url#1133",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unsmuggle_url(smug_url, default=None)",
        "snippet": "def unsmuggle_url(smug_url, default=None):\n    if '#__youtubedl_smuggle' not in smug_url:\n        return smug_url, default\n    url, _, sdata = smug_url.rpartition('#')\n    jsond = compat_parse_qs(sdata)['__youtubedl_smuggle'][0]\n    data = json.loads(jsond)\n    return url, data",
        "begin_line": 1133,
        "end_line": 1139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004310344827586207,
            "pseudo_dstar_susp": 0.002105263157894737,
            "pseudo_tarantula_susp": 0.002136752136752137,
            "pseudo_op2_susp": 0.002105263157894737,
            "pseudo_barinel_susp": 0.002136752136752137
        }
    },
    {
        "name": "youtube_dl.utils.format_bytes#1142",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.format_bytes(bytes)",
        "snippet": "def format_bytes(bytes):\n    if bytes is None:\n        return 'N/A'\n    if type(bytes) is str:\n        bytes = float(bytes)\n    if bytes == 0.0:\n        exponent = 0\n    else:\n        exponent = int(math.log(bytes, 1024.0))\n    suffix = ['B', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB', 'EiB', 'ZiB', 'YiB'][exponent]\n    converted = float(bytes) / float(1024 ** exponent)\n    return '%.2f%s' % (converted, suffix)",
        "begin_line": 1142,
        "end_line": 1153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.parse_filesize#1156",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_filesize(s)",
        "snippet": "def parse_filesize(s):\n    if s is None:\n        return None\n\n    # The lower-case forms are of course incorrect and inofficial,\n    # but we support those too\n    _UNIT_TABLE = {\n        'B': 1,\n        'b': 1,\n        'KiB': 1024,\n        'KB': 1000,\n        'kB': 1024,\n        'Kb': 1000,\n        'MiB': 1024 ** 2,\n        'MB': 1000 ** 2,\n        'mB': 1024 ** 2,\n        'Mb': 1000 ** 2,\n        'GiB': 1024 ** 3,\n        'GB': 1000 ** 3,\n        'gB': 1024 ** 3,\n        'Gb': 1000 ** 3,\n        'TiB': 1024 ** 4,\n        'TB': 1000 ** 4,\n        'tB': 1024 ** 4,\n        'Tb': 1000 ** 4,\n        'PiB': 1024 ** 5,\n        'PB': 1000 ** 5,\n        'pB': 1024 ** 5,\n        'Pb': 1000 ** 5,\n        'EiB': 1024 ** 6,\n        'EB': 1000 ** 6,\n        'eB': 1024 ** 6,\n        'Eb': 1000 ** 6,\n        'ZiB': 1024 ** 7,\n        'ZB': 1000 ** 7,\n        'zB': 1024 ** 7,\n        'Zb': 1000 ** 7,\n        'YiB': 1024 ** 8,\n        'YB': 1000 ** 8,\n        'yB': 1024 ** 8,\n        'Yb': 1000 ** 8,\n    }\n\n    units_re = '|'.join(re.escape(u) for u in _UNIT_TABLE)\n    m = re.match(\n        r'(?P<num>[0-9]+(?:[,.][0-9]*)?)\\s*(?P<unit>%s)' % units_re, s)\n    if not m:\n        return None\n\n    num_str = m.group('num').replace(',', '.')\n    mult = _UNIT_TABLE[m.group('unit')]\n    return int(float(num_str) * mult)",
        "begin_line": 1156,
        "end_line": 1207,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.month_by_name#1210",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.month_by_name(name)",
        "snippet": "def month_by_name(name):\n    \"\"\" Return the number of a month by (locale-independently) English name \"\"\"\n\n    try:\n        return ENGLISH_MONTH_NAMES.index(name) + 1\n    except ValueError:\n        return None",
        "begin_line": 1210,
        "end_line": 1216,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.month_by_abbreviation#1219",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.month_by_abbreviation(abbrev)",
        "snippet": "def month_by_abbreviation(abbrev):\n    \"\"\" Return the number of a month by (locale-independently) English\n        abbreviations \"\"\"\n\n    try:\n        return [s[:3] for s in ENGLISH_MONTH_NAMES].index(abbrev) + 1\n    except ValueError:\n        return None",
        "begin_line": 1219,
        "end_line": 1226,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.fix_xml_ampersands#1229",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fix_xml_ampersands(xml_str)",
        "snippet": "def fix_xml_ampersands(xml_str):\n    \"\"\"Replace all the '&' by '&amp;' in XML\"\"\"\n    return re.sub(\n        r'&(?!amp;|lt;|gt;|apos;|quot;|#x[0-9a-fA-F]{,4};|#[0-9]{,4};)',\n        '&amp;',\n        xml_str)",
        "begin_line": 1229,
        "end_line": 1234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.setproctitle#1237",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.setproctitle(title)",
        "snippet": "def setproctitle(title):\n    assert isinstance(title, compat_str)\n    try:\n        libc = ctypes.cdll.LoadLibrary(\"libc.so.6\")\n    except OSError:\n        return\n    title_bytes = title.encode('utf-8')\n    buf = ctypes.create_string_buffer(len(title_bytes))\n    buf.value = title_bytes\n    try:\n        libc.prctl(15, buf, 0, 0, 0)\n    except AttributeError:\n        return  # Strange libc, just skip this",
        "begin_line": 1237,
        "end_line": 1249,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00039635354736424893,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.remove_start#1252",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.remove_start(s, start)",
        "snippet": "def remove_start(s, start):\n    if s.startswith(start):\n        return s[len(start):]\n    return s",
        "begin_line": 1252,
        "end_line": 1255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.remove_end#1258",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.remove_end(s, end)",
        "snippet": "def remove_end(s, end):\n    if s.endswith(end):\n        return s[:-len(end)]\n    return s",
        "begin_line": 1258,
        "end_line": 1261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.url_basename#1264",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.url_basename(url)",
        "snippet": "def url_basename(url):\n    path = compat_urlparse.urlparse(url).path\n    return path.strip('/').split('/')[-1]",
        "begin_line": 1264,
        "end_line": 1266,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.00234192037470726,
            "pseudo_tarantula_susp": 0.0013869625520110957,
            "pseudo_op2_susp": 0.00234192037470726,
            "pseudo_barinel_susp": 0.0013869625520110957
        }
    },
    {
        "name": "youtube_dl.utils.HEADRequest.get_method#1270",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.HEADRequest",
        "signature": "youtube_dl.utils.HEADRequest.get_method(self)",
        "snippet": "    def get_method(self):\n        return \"HEAD\"",
        "begin_line": 1270,
        "end_line": 1271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002658160552897395,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.int_or_none#1274",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.int_or_none(v, scale=1, default=None, get_attr=None, invscale=1)",
        "snippet": "def int_or_none(v, scale=1, default=None, get_attr=None, invscale=1):\n    if get_attr:\n        if v is not None:\n            v = getattr(v, get_attr, None)\n    if v == '':\n        v = None\n    return default if v is None else (int(v) * invscale // scale)",
        "begin_line": 1274,
        "end_line": 1280,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.str_or_none#1283",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.str_or_none(v, default=None)",
        "snippet": "def str_or_none(v, default=None):\n    return default if v is None else compat_str(v)",
        "begin_line": 1283,
        "end_line": 1284,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.str_to_int#1287",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.str_to_int(int_str)",
        "snippet": "def str_to_int(int_str):\n    \"\"\" A more relaxed version of int_or_none \"\"\"\n    if int_str is None:\n        return None\n    int_str = re.sub(r'[,\\.\\+]', '', int_str)\n    return int(int_str)",
        "begin_line": 1287,
        "end_line": 1292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.float_or_none#1295",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.float_or_none(v, scale=1, invscale=1, default=None)",
        "snippet": "def float_or_none(v, scale=1, invscale=1, default=None):\n    return default if v is None else (float(v) * invscale / scale)",
        "begin_line": 1295,
        "end_line": 1296,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0014124293785310734,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.0014124293785310734,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.utils.parse_duration#1299",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_duration(s)",
        "snippet": "def parse_duration(s):\n    if not isinstance(s, compat_basestring):\n        return None\n\n    s = s.strip()\n\n    m = re.match(\n        r'''(?ix)(?:P?T)?\n        (?:\n            (?P<only_mins>[0-9.]+)\\s*(?:mins?|minutes?)\\s*|\n            (?P<only_hours>[0-9.]+)\\s*(?:hours?)|\n\n            \\s*(?P<hours_reversed>[0-9]+)\\s*(?:[:h]|hours?)\\s*(?P<mins_reversed>[0-9]+)\\s*(?:[:m]|mins?|minutes?)\\s*|\n            (?:\n                (?:\n                    (?:(?P<days>[0-9]+)\\s*(?:[:d]|days?)\\s*)?\n                    (?P<hours>[0-9]+)\\s*(?:[:h]|hours?)\\s*\n                )?\n                (?P<mins>[0-9]+)\\s*(?:[:m]|mins?|minutes?)\\s*\n            )?\n            (?P<secs>[0-9]+)(?P<ms>\\.[0-9]+)?\\s*(?:s|secs?|seconds?)?\n        )$''', s)\n    if not m:\n        return None\n    res = 0\n    if m.group('only_mins'):\n        return float_or_none(m.group('only_mins'), invscale=60)\n    if m.group('only_hours'):\n        return float_or_none(m.group('only_hours'), invscale=60 * 60)\n    if m.group('secs'):\n        res += int(m.group('secs'))\n    if m.group('mins_reversed'):\n        res += int(m.group('mins_reversed')) * 60\n    if m.group('mins'):\n        res += int(m.group('mins')) * 60\n    if m.group('hours'):\n        res += int(m.group('hours')) * 60 * 60\n    if m.group('hours_reversed'):\n        res += int(m.group('hours_reversed')) * 60 * 60\n    if m.group('days'):\n        res += int(m.group('days')) * 24 * 60 * 60\n    if m.group('ms'):\n        res += float(m.group('ms'))\n    return res",
        "begin_line": 1299,
        "end_line": 1342,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.prepend_extension#1345",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.prepend_extension(filename, ext, expected_real_ext=None)",
        "snippet": "def prepend_extension(filename, ext, expected_real_ext=None):\n    name, real_ext = os.path.splitext(filename)\n    return (\n        '{0}.{1}{2}'.format(name, ext, real_ext)\n        if not expected_real_ext or real_ext[1:] == expected_real_ext\n        else '{0}.{1}'.format(filename, ext))",
        "begin_line": 1345,
        "end_line": 1350,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.replace_extension#1353",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.replace_extension(filename, ext, expected_real_ext=None)",
        "snippet": "def replace_extension(filename, ext, expected_real_ext=None):\n    name, real_ext = os.path.splitext(filename)\n    return '{0}.{1}'.format(\n        name if not expected_real_ext or real_ext[1:] == expected_real_ext else filename,\n        ext)",
        "begin_line": 1353,
        "end_line": 1357,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001364256480218281,
            "pseudo_dstar_susp": 0.001288659793814433,
            "pseudo_tarantula_susp": 0.001567398119122257,
            "pseudo_op2_susp": 0.001288659793814433,
            "pseudo_barinel_susp": 0.0015552099533437014
        }
    },
    {
        "name": "youtube_dl.utils.check_executable#1360",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.check_executable(exe, args=[])",
        "snippet": "def check_executable(exe, args=[]):\n    \"\"\" Checks if the given binary is installed somewhere in PATH, and returns its name.\n    args can be a list of arguments for a short output (like -version) \"\"\"\n    try:\n        subprocess.Popen([exe] + args, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n    except OSError:\n        return False\n    return exe",
        "begin_line": 1360,
        "end_line": 1367,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.get_exe_version#1370",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_exe_version(exe, args=['--version'], version_re=None, unrecognized='present')",
        "snippet": "def get_exe_version(exe, args=['--version'],\n                    version_re=None, unrecognized='present'):\n    \"\"\" Returns the version of the specified executable,\n    or False if the executable is not present \"\"\"\n    try:\n        out, _ = subprocess.Popen(\n            [encodeArgument(exe)] + args,\n            stdout=subprocess.PIPE, stderr=subprocess.STDOUT).communicate()\n    except OSError:\n        return False\n    if isinstance(out, bytes):  # Python 2.x\n        out = out.decode('ascii', 'ignore')\n    return detect_exe_version(out, version_re, unrecognized)",
        "begin_line": 1370,
        "end_line": 1382,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.detect_exe_version#1385",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.detect_exe_version(output, version_re=None, unrecognized='present')",
        "snippet": "def detect_exe_version(output, version_re=None, unrecognized='present'):\n    assert isinstance(output, compat_str)\n    if version_re is None:\n        version_re = r'version\\s+([-0-9._a-zA-Z]+)'\n    m = re.search(version_re, output)\n    if m:\n        return m.group(1)\n    else:\n        return unrecognized",
        "begin_line": 1385,
        "end_line": 1393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.PagedList.__len__#1397",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PagedList",
        "signature": "youtube_dl.utils.PagedList.__len__(self)",
        "snippet": "    def __len__(self):\n        # This is only useful for tests\n        return len(self.getslice())",
        "begin_line": 1397,
        "end_line": 1399,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.OnDemandPagedList.__init__#1403",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.OnDemandPagedList",
        "signature": "youtube_dl.utils.OnDemandPagedList.__init__(self, pagefunc, pagesize)",
        "snippet": "    def __init__(self, pagefunc, pagesize):\n        self._pagefunc = pagefunc\n        self._pagesize = pagesize",
        "begin_line": 1403,
        "end_line": 1405,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.OnDemandPagedList.getslice#1407",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.OnDemandPagedList",
        "signature": "youtube_dl.utils.OnDemandPagedList.getslice(self, start=0, end=None)",
        "snippet": "    def getslice(self, start=0, end=None):\n        res = []\n        for pagenum in itertools.count(start // self._pagesize):\n            firstid = pagenum * self._pagesize\n            nextfirstid = pagenum * self._pagesize + self._pagesize\n            if start >= nextfirstid:\n                continue\n\n            page_results = list(self._pagefunc(pagenum))\n\n            startv = (\n                start % self._pagesize\n                if firstid <= start < nextfirstid\n                else 0)\n\n            endv = (\n                ((end - 1) % self._pagesize) + 1\n                if (end is not None and firstid <= end <= nextfirstid)\n                else None)\n\n            if startv != 0 or endv is not None:\n                page_results = page_results[startv:endv]\n            res.extend(page_results)\n\n            # A little optimization - if current page is not \"full\", ie. does\n            # not contain page_size videos then we can assume that this page\n            # is the last one - there are no more ids on further pages -\n            # i.e. no need to query again.\n            if len(page_results) + startv < self._pagesize:\n                break\n\n            # If we got the whole page, but the next page is not interesting,\n            # break out early as well\n            if end == nextfirstid:\n                break\n        return res",
        "begin_line": 1407,
        "end_line": 1442,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.InAdvancePagedList.__init__#1446",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.InAdvancePagedList",
        "signature": "youtube_dl.utils.InAdvancePagedList.__init__(self, pagefunc, pagecount, pagesize)",
        "snippet": "    def __init__(self, pagefunc, pagecount, pagesize):\n        self._pagefunc = pagefunc\n        self._pagecount = pagecount\n        self._pagesize = pagesize",
        "begin_line": 1446,
        "end_line": 1449,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.InAdvancePagedList.getslice#1451",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.InAdvancePagedList",
        "signature": "youtube_dl.utils.InAdvancePagedList.getslice(self, start=0, end=None)",
        "snippet": "    def getslice(self, start=0, end=None):\n        res = []\n        start_page = start // self._pagesize\n        end_page = (\n            self._pagecount if end is None else (end // self._pagesize + 1))\n        skip_elems = start - start_page * self._pagesize\n        only_more = None if end is None else end - start\n        for pagenum in range(start_page, end_page):\n            page = list(self._pagefunc(pagenum))\n            if skip_elems:\n                page = page[skip_elems:]\n                skip_elems = None\n            if only_more is not None:\n                if len(page) < only_more:\n                    only_more -= len(page)\n                else:\n                    page = page[:only_more]\n                    res.extend(page)\n                    break\n            res.extend(page)\n        return res",
        "begin_line": 1451,
        "end_line": 1471,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.uppercase_escape#1474",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.uppercase_escape(s)",
        "snippet": "def uppercase_escape(s):\n    unicode_escape = codecs.getdecoder('unicode_escape')\n    return re.sub(\n        r'\\\\U[0-9a-fA-F]{8}',\n        lambda m: unicode_escape(m.group(0))[0],\n        s)",
        "begin_line": 1474,
        "end_line": 1479,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.lowercase_escape#1482",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.lowercase_escape(s)",
        "snippet": "def lowercase_escape(s):\n    unicode_escape = codecs.getdecoder('unicode_escape')\n    return re.sub(\n        r'\\\\u[0-9a-fA-F]{4}',\n        lambda m: unicode_escape(m.group(0))[0],\n        s)",
        "begin_line": 1482,
        "end_line": 1487,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.escape_rfc3986#1490",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.escape_rfc3986(s)",
        "snippet": "def escape_rfc3986(s):\n    \"\"\"Escape non-ASCII characters as suggested by RFC 3986\"\"\"\n    if sys.version_info < (3, 0) and isinstance(s, compat_str):\n        s = s.encode('utf-8')\n    return compat_urllib_parse.quote(s, b\"%/;:@&=+$,!~*'()?#[]\")",
        "begin_line": 1490,
        "end_line": 1494,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005847953216374269,
            "pseudo_dstar_susp": 0.01098901098901099,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.01098901098901099,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.utils.escape_url#1497",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.escape_url(url)",
        "snippet": "def escape_url(url):\n    \"\"\"Escape URL as suggested by RFC 3986\"\"\"\n    url_parsed = compat_urllib_parse_urlparse(url)\n    return url_parsed._replace(\n        path=escape_rfc3986(url_parsed.path),\n        params=escape_rfc3986(url_parsed.params),\n        query=escape_rfc3986(url_parsed.query),\n        fragment=escape_rfc3986(url_parsed.fragment)\n    ).geturl()",
        "begin_line": 1497,
        "end_line": 1505,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005847953216374269,
            "pseudo_dstar_susp": 0.015384615384615385,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.015384615384615385,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.utils.read_batch_urls#1525",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.read_batch_urls(batch_fd)",
        "snippet": "def read_batch_urls(batch_fd):\n    def fixup(url):\n        if not isinstance(url, compat_str):\n            url = url.decode('utf-8', 'replace')\n        BOM_UTF8 = '\\xef\\xbb\\xbf'\n        if url.startswith(BOM_UTF8):\n            url = url[len(BOM_UTF8):]\n        url = url.strip()\n        if url.startswith(('#', ';', ']')):\n            return False\n        return url\n\n    with contextlib.closing(batch_fd) as fd:\n        return [url for url in map(fixup, fd) if url]",
        "begin_line": 1525,
        "end_line": 1538,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.fixup#1526",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fixup(url)",
        "snippet": "    def fixup(url):\n        if not isinstance(url, compat_str):\n            url = url.decode('utf-8', 'replace')\n        BOM_UTF8 = '\\xef\\xbb\\xbf'\n        if url.startswith(BOM_UTF8):\n            url = url[len(BOM_UTF8):]\n        url = url.strip()\n        if url.startswith(('#', ';', ']')):\n            return False\n        return url",
        "begin_line": 1526,
        "end_line": 1535,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.urlencode_postdata#1541",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.urlencode_postdata(*args, **kargs)",
        "snippet": "def urlencode_postdata(*args, **kargs):\n    return compat_urllib_parse.urlencode(*args, **kargs).encode('ascii')",
        "begin_line": 1541,
        "end_line": 1542,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.parse_xml#1551",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_xml(s)",
        "snippet": "def parse_xml(s):\n    class TreeBuilder(xml.etree.ElementTree.TreeBuilder):\n        def doctype(self, name, pubid, system):\n            pass  # Ignore doctypes\n\n    parser = xml.etree.ElementTree.XMLParser(target=TreeBuilder())\n    kwargs = {'parser': parser} if sys.version_info >= (2, 7) else {}\n    tree = xml.etree.ElementTree.XML(s.encode('utf-8'), **kwargs)\n    # Fix up XML parser in Python 2.x\n    if sys.version_info < (3, 0):\n        for n in etree_iter(tree):\n            if n.text is not None:\n                if not isinstance(n.text, compat_str):\n                    n.text = n.text.decode('utf-8')\n    return tree",
        "begin_line": 1551,
        "end_line": 1565,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.TreeBuilder.parse_xml#1551",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.TreeBuilder",
        "signature": "youtube_dl.utils.TreeBuilder.parse_xml(s)",
        "snippet": "def parse_xml(s):\n    class TreeBuilder(xml.etree.ElementTree.TreeBuilder):\n        def doctype(self, name, pubid, system):\n            pass  # Ignore doctypes\n\n    parser = xml.etree.ElementTree.XMLParser(target=TreeBuilder())\n    kwargs = {'parser': parser} if sys.version_info >= (2, 7) else {}\n    tree = xml.etree.ElementTree.XML(s.encode('utf-8'), **kwargs)\n    # Fix up XML parser in Python 2.x\n    if sys.version_info < (3, 0):\n        for n in etree_iter(tree):\n            if n.text is not None:\n                if not isinstance(n.text, compat_str):\n                    n.text = n.text.decode('utf-8')\n    return tree",
        "begin_line": 1551,
        "end_line": 1565,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.TreeBuilder.doctype#1553",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.TreeBuilder",
        "signature": "youtube_dl.utils.TreeBuilder.doctype(self, name, pubid, system)",
        "snippet": "        def doctype(self, name, pubid, system):\n            pass  # Ignore doctypes",
        "begin_line": 1553,
        "end_line": 1554,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.parse_age_limit#1577",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_age_limit(s)",
        "snippet": "def parse_age_limit(s):\n    if s is None:\n        return None\n    m = re.match(r'^(?P<age>\\d{1,2})\\+?$', s)\n    return int(m.group('age')) if m else US_RATINGS.get(s, None)",
        "begin_line": 1577,
        "end_line": 1581,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.strip_jsonp#1584",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.strip_jsonp(code)",
        "snippet": "def strip_jsonp(code):\n    return re.sub(\n        r'(?s)^[a-zA-Z0-9_]+\\s*\\(\\s*(.*)\\);?\\s*?(?://[^\\n]*)*$', r'\\1', code)",
        "begin_line": 1584,
        "end_line": 1586,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.js_to_json#1589",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.js_to_json(code)",
        "snippet": "def js_to_json(code):\n    def fix_kv(m):\n        v = m.group(0)\n        if v in ('true', 'false', 'null'):\n            return v\n        if v.startswith('\"'):\n            return v\n        if v.startswith(\"'\"):\n            v = v[1:-1]\n            v = re.sub(r\"\\\\\\\\|\\\\'|\\\"\", lambda m: {\n                '\\\\\\\\': '\\\\\\\\',\n                \"\\\\'\": \"'\",\n                '\"': '\\\\\"',\n            }[m.group(0)], v)\n        return '\"%s\"' % v\n\n    res = re.sub(r'''(?x)\n        \"(?:[^\"\\\\]*(?:\\\\\\\\|\\\\['\"nu]))*[^\"\\\\]*\"|\n        '(?:[^'\\\\]*(?:\\\\\\\\|\\\\['\"nu]))*[^'\\\\]*'|\n        [a-zA-Z_][.a-zA-Z_0-9]*\n        ''', fix_kv, code)\n    res = re.sub(r',(\\s*[\\]}])', lambda m: m.group(1), res)\n    return res",
        "begin_line": 1589,
        "end_line": 1611,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.fix_kv#1590",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fix_kv(m)",
        "snippet": "    def fix_kv(m):\n        v = m.group(0)\n        if v in ('true', 'false', 'null'):\n            return v\n        if v.startswith('\"'):\n            return v\n        if v.startswith(\"'\"):\n            v = v[1:-1]\n            v = re.sub(r\"\\\\\\\\|\\\\'|\\\"\", lambda m: {\n                '\\\\\\\\': '\\\\\\\\',\n                \"\\\\'\": \"'\",\n                '\"': '\\\\\"',\n            }[m.group(0)], v)\n        return '\"%s\"' % v",
        "begin_line": 1590,
        "end_line": 1603,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.qualities#1614",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.qualities(quality_ids)",
        "snippet": "def qualities(quality_ids):\n    \"\"\" Get a numeric quality value out of a list of possible values \"\"\"\n    def q(qid):\n        try:\n            return quality_ids.index(qid)\n        except ValueError:\n            return -1\n    return q",
        "begin_line": 1614,
        "end_line": 1621,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.limit_length#1627",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.limit_length(s, length)",
        "snippet": "def limit_length(s, length):\n    \"\"\" Add ellipses to overly long strings \"\"\"\n    if s is None:\n        return None\n    ELLIPSES = '...'\n    if len(s) > length:\n        return s[:length - len(ELLIPSES)] + ELLIPSES\n    return s",
        "begin_line": 1627,
        "end_line": 1634,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.version_tuple#1637",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.version_tuple(v)",
        "snippet": "def version_tuple(v):\n    return tuple(int(e) for e in re.split(r'[-.]', v))",
        "begin_line": 1637,
        "end_line": 1638,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.is_outdated_version#1641",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.is_outdated_version(version, limit, assume_new=True)",
        "snippet": "def is_outdated_version(version, limit, assume_new=True):\n    if not version:\n        return not assume_new\n    try:\n        return version_tuple(version) < version_tuple(limit)\n    except ValueError:\n        return not assume_new",
        "begin_line": 1641,
        "end_line": 1647,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.ytdl_is_updateable#1650",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.ytdl_is_updateable()",
        "snippet": "def ytdl_is_updateable():\n    \"\"\" Returns if youtube-dl can be updated with -U \"\"\"\n    from zipimport import zipimporter\n\n    return isinstance(globals().get('__loader__'), zipimporter) or hasattr(sys, 'frozen')",
        "begin_line": 1650,
        "end_line": 1654,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.003676470588235294,
            "pseudo_tarantula_susp": 0.0027472527472527475,
            "pseudo_op2_susp": 0.003676470588235294,
            "pseudo_barinel_susp": 0.0027472527472527475
        }
    },
    {
        "name": "youtube_dl.utils.args_to_str#1657",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.args_to_str(args)",
        "snippet": "def args_to_str(args):\n    # Get a short string representation for a subprocess command\n    return ' '.join(shlex_quote(a) for a in args)",
        "begin_line": 1657,
        "end_line": 1659,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.mimetype2ext#1662",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.mimetype2ext(mt)",
        "snippet": "def mimetype2ext(mt):\n    _, _, res = mt.rpartition('/')\n\n    return {\n        'x-ms-wmv': 'wmv',\n        'x-mp4-fragmented': 'mp4',\n        'ttml+xml': 'ttml',\n    }.get(res, res)",
        "begin_line": 1662,
        "end_line": 1669,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.urlhandle_detect_ext#1672",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.urlhandle_detect_ext(url_handle)",
        "snippet": "def urlhandle_detect_ext(url_handle):\n    try:\n        url_handle.headers\n        getheader = lambda h: url_handle.headers[h]\n    except AttributeError:  # Python < 3\n        getheader = url_handle.info().getheader\n\n    cd = getheader('Content-Disposition')\n    if cd:\n        m = re.match(r'attachment;\\s*filename=\"(?P<filename>[^\"]+)\"', cd)\n        if m:\n            e = determine_ext(m.group('filename'), default_ext=None)\n            if e:\n                return e\n\n    return mimetype2ext(getheader('Content-Type'))",
        "begin_line": 1672,
        "end_line": 1687,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.age_restricted#1690",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.age_restricted(content_limit, age_limit)",
        "snippet": "def age_restricted(content_limit, age_limit):\n    \"\"\" Returns True iff the content should be blocked \"\"\"\n\n    if age_limit is None:  # No limit set\n        return False\n    if content_limit is None:\n        return False  # Content available for everyone\n    return age_limit < content_limit",
        "begin_line": 1690,
        "end_line": 1697,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014749262536873156,
            "pseudo_dstar_susp": 0.002,
            "pseudo_tarantula_susp": 0.001466275659824047,
            "pseudo_op2_susp": 0.002,
            "pseudo_barinel_susp": 0.001466275659824047
        }
    },
    {
        "name": "youtube_dl.utils.is_html#1700",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.is_html(first_bytes)",
        "snippet": "def is_html(first_bytes):\n    \"\"\" Detect whether a file contains HTML by examining its first bytes. \"\"\"\n\n    BOMS = [\n        (b'\\xef\\xbb\\xbf', 'utf-8'),\n        (b'\\x00\\x00\\xfe\\xff', 'utf-32-be'),\n        (b'\\xff\\xfe\\x00\\x00', 'utf-32-le'),\n        (b'\\xff\\xfe', 'utf-16-le'),\n        (b'\\xfe\\xff', 'utf-16-be'),\n    ]\n    for bom, enc in BOMS:\n        if first_bytes.startswith(bom):\n            s = first_bytes[len(bom):].decode(enc, 'replace')\n            break\n    else:\n        s = first_bytes.decode('utf-8', 'replace')\n\n    return re.match(r'^\\s*<', s)",
        "begin_line": 1700,
        "end_line": 1717,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.determine_protocol#1720",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.determine_protocol(info_dict)",
        "snippet": "def determine_protocol(info_dict):\n    protocol = info_dict.get('protocol')\n    if protocol is not None:\n        return protocol\n\n    url = info_dict['url']\n    if url.startswith('rtmp'):\n        return 'rtmp'\n    elif url.startswith('mms'):\n        return 'mms'\n    elif url.startswith('rtsp'):\n        return 'rtsp'\n\n    ext = determine_ext(url)\n    if ext == 'm3u8':\n        return 'm3u8'\n    elif ext == 'f4m':\n        return 'f4m'\n\n    return compat_urllib_parse_urlparse(url).scheme",
        "begin_line": 1720,
        "end_line": 1739,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001364256480218281,
            "pseudo_dstar_susp": 0.001288659793814433,
            "pseudo_tarantula_susp": 0.001567398119122257,
            "pseudo_op2_susp": 0.001288659793814433,
            "pseudo_barinel_susp": 0.0015552099533437014
        }
    },
    {
        "name": "youtube_dl.utils.render_table#1742",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.render_table(header_row, data)",
        "snippet": "def render_table(header_row, data):\n    \"\"\" Render a list of rows, each as a list of values \"\"\"\n    table = [header_row] + data\n    max_lens = [max(len(compat_str(v)) for v in col) for col in zip(*table)]\n    format_str = ' '.join('%-' + compat_str(ml + 1) + 's' for ml in max_lens[:-1]) + '%s'\n    return '\\n'.join(format_str % tuple(row) for row in table)",
        "begin_line": 1742,
        "end_line": 1747,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils._match_one#1750",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._match_one(filter_part, dct)",
        "snippet": "def _match_one(filter_part, dct):\n    COMPARISON_OPERATORS = {\n        '<': operator.lt,\n        '<=': operator.le,\n        '>': operator.gt,\n        '>=': operator.ge,\n        '=': operator.eq,\n        '!=': operator.ne,\n    }\n    operator_rex = re.compile(r'''(?x)\\s*\n        (?P<key>[a-z_]+)\n        \\s*(?P<op>%s)(?P<none_inclusive>\\s*\\?)?\\s*\n        (?:\n            (?P<intval>[0-9.]+(?:[kKmMgGtTpPeEzZyY]i?[Bb]?)?)|\n            (?P<strval>(?![0-9.])[a-z0-9A-Z]*)\n        )\n        \\s*$\n        ''' % '|'.join(map(re.escape, COMPARISON_OPERATORS.keys())))\n    m = operator_rex.search(filter_part)\n    if m:\n        op = COMPARISON_OPERATORS[m.group('op')]\n        if m.group('strval') is not None:\n            if m.group('op') not in ('=', '!='):\n                raise ValueError(\n                    'Operator %s does not support string values!' % m.group('op'))\n            comparison_value = m.group('strval')\n        else:\n            try:\n                comparison_value = int(m.group('intval'))\n            except ValueError:\n                comparison_value = parse_filesize(m.group('intval'))\n                if comparison_value is None:\n                    comparison_value = parse_filesize(m.group('intval') + 'B')\n                if comparison_value is None:\n                    raise ValueError(\n                        'Invalid integer value %r in filter part %r' % (\n                            m.group('intval'), filter_part))\n        actual_value = dct.get(m.group('key'))\n        if actual_value is None:\n            return m.group('none_inclusive')\n        return op(actual_value, comparison_value)\n\n    UNARY_OPERATORS = {\n        '': lambda v: v is not None,\n        '!': lambda v: v is None,\n    }\n    operator_rex = re.compile(r'''(?x)\\s*\n        (?P<op>%s)\\s*(?P<key>[a-z_]+)\n        \\s*$\n        ''' % '|'.join(map(re.escape, UNARY_OPERATORS.keys())))\n    m = operator_rex.search(filter_part)\n    if m:\n        op = UNARY_OPERATORS[m.group('op')]\n        actual_value = dct.get(m.group('key'))\n        return op(actual_value)\n\n    raise ValueError('Invalid filter part %r' % filter_part)",
        "begin_line": 1750,
        "end_line": 1806,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.match_str#1809",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.match_str(filter_str, dct)",
        "snippet": "def match_str(filter_str, dct):\n    \"\"\" Filter a dictionary with a simple string syntax. Returns True (=passes filter) or false \"\"\"\n\n    return all(\n        _match_one(filter_part, dct) for filter_part in filter_str.split('&'))",
        "begin_line": 1809,
        "end_line": 1813,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.match_filter_func#1816",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.match_filter_func(filter_str)",
        "snippet": "def match_filter_func(filter_str):\n    def _match_func(info_dict):\n        if match_str(filter_str, info_dict):\n            return None\n        else:\n            video_title = info_dict.get('title', info_dict.get('id', 'video'))\n            return '%s does not pass filter %s, skipping ..' % (video_title, filter_str)\n    return _match_func",
        "begin_line": 1816,
        "end_line": 1823,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils._match_func#1817",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._match_func(info_dict)",
        "snippet": "    def _match_func(info_dict):\n        if match_str(filter_str, info_dict):\n            return None\n        else:\n            video_title = info_dict.get('title', info_dict.get('id', 'video'))\n            return '%s does not pass filter %s, skipping ..' % (video_title, filter_str)",
        "begin_line": 1817,
        "end_line": 1822,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.parse_dfxp_time_expr#1826",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_dfxp_time_expr(time_expr)",
        "snippet": "def parse_dfxp_time_expr(time_expr):\n    if not time_expr:\n        return 0.0\n\n    mobj = re.match(r'^(?P<time_offset>\\d+(?:\\.\\d+)?)s?$', time_expr)\n    if mobj:\n        return float(mobj.group('time_offset'))\n\n    mobj = re.match(r'^(\\d+):(\\d\\d):(\\d\\d(?:\\.\\d+)?)$', time_expr)\n    if mobj:\n        return 3600 * int(mobj.group(1)) + 60 * int(mobj.group(2)) + float(mobj.group(3))",
        "begin_line": 1826,
        "end_line": 1836,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.srt_subtitles_timecode#1839",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.srt_subtitles_timecode(seconds)",
        "snippet": "def srt_subtitles_timecode(seconds):\n    return '%02d:%02d:%02d,%03d' % (seconds / 3600, (seconds % 3600) / 60, seconds % 60, (seconds % 1) * 1000)",
        "begin_line": 1839,
        "end_line": 1840,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.dfxp2srt#1843",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.dfxp2srt(dfxp_data)",
        "snippet": "def dfxp2srt(dfxp_data):\n    _x = functools.partial(xpath_with_ns, ns_map={\n        'ttml': 'http://www.w3.org/ns/ttml',\n        'ttaf1': 'http://www.w3.org/2006/10/ttaf1',\n    })\n\n    def parse_node(node):\n        str_or_empty = functools.partial(str_or_none, default='')\n\n        out = str_or_empty(node.text)\n\n        for child in node:\n            if child.tag in (_x('ttml:br'), _x('ttaf1:br'), 'br'):\n                out += '\\n' + str_or_empty(child.tail)\n            elif child.tag in (_x('ttml:span'), _x('ttaf1:span'), 'span'):\n                out += str_or_empty(parse_node(child))\n            else:\n                out += str_or_empty(xml.etree.ElementTree.tostring(child))\n\n        return out\n\n    dfxp = xml.etree.ElementTree.fromstring(dfxp_data.encode('utf-8'))\n    out = []\n    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall(_x('.//ttaf1:p')) or dfxp.findall('.//p')\n\n    if not paras:\n        raise ValueError('Invalid dfxp/TTML subtitle')\n\n    for para, index in zip(paras, itertools.count(1)):\n        begin_time = parse_dfxp_time_expr(para.attrib['begin'])\n        end_time = parse_dfxp_time_expr(para.attrib.get('end'))\n        if not end_time:\n            end_time = begin_time + parse_dfxp_time_expr(para.attrib['dur'])\n        out.append('%d\\n%s --> %s\\n%s\\n\\n' % (\n            index,\n            srt_subtitles_timecode(begin_time),\n            srt_subtitles_timecode(end_time),\n            parse_node(para)))\n\n    return ''.join(out)",
        "begin_line": 1843,
        "end_line": 1882,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.parse_node#1849",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_node(node)",
        "snippet": "    def parse_node(node):\n        str_or_empty = functools.partial(str_or_none, default='')\n\n        out = str_or_empty(node.text)\n\n        for child in node:\n            if child.tag in (_x('ttml:br'), _x('ttaf1:br'), 'br'):\n                out += '\\n' + str_or_empty(child.tail)\n            elif child.tag in (_x('ttml:span'), _x('ttaf1:span'), 'span'):\n                out += str_or_empty(parse_node(child))\n            else:\n                out += str_or_empty(xml.etree.ElementTree.tostring(child))\n\n        return out",
        "begin_line": 1849,
        "end_line": 1862,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.utils.ISO639Utils.long2short#2080",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ISO639Utils",
        "signature": "youtube_dl.utils.ISO639Utils.long2short(cls, code)",
        "snippet": "    def long2short(cls, code):\n        \"\"\"Convert language code from ISO 639-2/T to ISO 639-1\"\"\"\n        for short_name, long_name in cls._lang_map.items():\n            if long_name == code:\n                return short_name",
        "begin_line": 2080,
        "end_line": 2084,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.utils.PerRequestProxyHandler.__init__#2348",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PerRequestProxyHandler",
        "signature": "youtube_dl.utils.PerRequestProxyHandler.__init__(self, proxies=None)",
        "snippet": "    def __init__(self, proxies=None):\n        # Set default handlers\n        for type in ('http', 'https'):\n            setattr(self, '%s_open' % type,\n                    lambda r, proxy='__noproxy__', type=type, meth=self.proxy_open:\n                        meth(r, proxy, type))\n        return compat_urllib_request.ProxyHandler.__init__(self, proxies)",
        "begin_line": 2348,
        "end_line": 2354,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00625,
            "pseudo_dstar_susp": 0.04,
            "pseudo_tarantula_susp": 0.0017482517482517483,
            "pseudo_op2_susp": 0.04,
            "pseudo_barinel_susp": 0.0017482517482517483
        }
    },
    {
        "name": "youtube_dl.utils.PerRequestProxyHandler.proxy_open#2356",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PerRequestProxyHandler",
        "signature": "youtube_dl.utils.PerRequestProxyHandler.proxy_open(self, req, proxy, type)",
        "snippet": "    def proxy_open(self, req, proxy, type):\n        req_proxy = req.headers.get('Ytdl-request-proxy')\n        if req_proxy is not None:\n            proxy = req_proxy\n            del req.headers['Ytdl-request-proxy']\n\n        if proxy == '__noproxy__':\n            return None  # No Proxy\n        return compat_urllib_request.ProxyHandler.proxy_open(\n            self, req, proxy, type)",
        "begin_line": 2356,
        "end_line": 2365,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005847953216374269,
            "pseudo_dstar_susp": 0.015384615384615385,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.015384615384615385,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaBaseIE._login#27",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaBaseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'username': username.encode('utf-8'),\n            'password': password.encode('utf-8'),\n            'remember': 'false',\n            'stayPut': 'false'\n        }\n        request = compat_urllib_request.Request(\n            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))\n        login_page = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        # Not (yet) logged in\n        m = re.search(r'loginResultJson = \\'(?P<json>[^\\']+)\\';', login_page)\n        if m is not None:\n            response = m.group('json')\n            response_json = json.loads(response)\n            state = response_json['state']\n\n            if state == 'notlogged':\n                raise ExtractorError(\n                    'Unable to login, incorrect username and/or password',\n                    expected=True)\n\n            # This is when we get popup:\n            # > You're already logged in to lynda.com on two devices.\n            # > If you log in here, we'll log you out of another device.\n            # So, we need to confirm this.\n            if state == 'conflicted':\n                confirm_form = {\n                    'username': '',\n                    'password': '',\n                    'resolve': 'true',\n                    'remember': 'false',\n                    'stayPut': 'false',\n                }\n                request = compat_urllib_request.Request(\n                    self._LOGIN_URL, compat_urllib_parse.urlencode(confirm_form).encode('utf-8'))\n                login_page = self._download_webpage(\n                    request, None,\n                    'Confirming log in and log out from another device')\n\n        if re.search(self._SUCCESSFUL_LOGIN_REGEX, login_page) is None:\n            raise ExtractorError('Unable to log in')",
        "begin_line": 27,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudUserIE._real_extract#315",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudUserIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader = mobj.group('user')\n        resource = mobj.group('rsrc')\n        if resource is None:\n            resource = 'tracks'\n        elif resource == 'likes':\n            resource = 'favorites'\n\n        url = 'http://soundcloud.com/%s/' % uploader\n        resolv_url = self._resolv_url(url)\n        user = self._download_json(\n            resolv_url, uploader, 'Downloading user info')\n        base_url = 'http://api.soundcloud.com/users/%s/%s.json?' % (uploader, resource)\n\n        entries = []\n        for i in itertools.count():\n            data = compat_urllib_parse.urlencode({\n                'offset': i * 50,\n                'limit': 50,\n                'client_id': self._CLIENT_ID,\n            })\n            new_entries = self._download_json(\n                base_url + data, uploader, 'Downloading track page %s' % (i + 1))\n            if len(new_entries) == 0:\n                self.to_screen('%s: End page received' % uploader)\n                break\n            entries.extend(self.url_result(e['permalink_url'], 'Soundcloud') for e in new_entries)\n\n        return {\n            '_type': 'playlist',\n            'id': compat_str(user['id']),\n            'title': user['username'],\n            'entries': entries,\n        }",
        "begin_line": 315,
        "end_line": 349,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00039635354736424893,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE._real_extract#365",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        base_url = '%s//api.soundcloud.com/playlists/%s.json?' % (self.http_scheme(), playlist_id)\n\n        data_dict = {\n            'client_id': self._CLIENT_ID,\n        }\n        token = mobj.group('token')\n\n        if token:\n            data_dict['secret_token'] = token\n\n        data = compat_urllib_parse.urlencode(data_dict)\n        data = self._download_json(\n            base_url + data, playlist_id, 'Downloading playlist')\n\n        entries = [\n            self._extract_info_dict(t, quiet=True, secret_token=token)\n            for t in data['tracks']]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': data.get('title'),\n            'description': data.get('description'),\n            'entries': entries,\n        }",
        "begin_line": 365,
        "end_line": 392,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.senateisvp.SenateISVPIE._search_iframe_url#82",
        "src_path": "youtube_dl/extractor/senateisvp.py",
        "class_name": "youtube_dl.extractor.senateisvp.SenateISVPIE",
        "signature": "youtube_dl.extractor.senateisvp.SenateISVPIE._search_iframe_url(webpage)",
        "snippet": "    def _search_iframe_url(webpage):\n        mobj = re.search(\n            r\"<iframe[^>]+src=['\\\"](?P<url>http://www\\.senate\\.gov/isvp/?\\?[^'\\\"]+)['\\\"]\",\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 82,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.abc7news.Abc7NewsIE._real_extract#36",
        "src_path": "youtube_dl/extractor/abc7news.py",
        "class_name": "youtube_dl.extractor.abc7news.Abc7NewsIE",
        "signature": "youtube_dl.extractor.abc7news.Abc7NewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        m3u8 = self._html_search_meta(\n            'contentURL', webpage, 'm3u8 url', fatal=True)\n\n        formats = self._extract_m3u8_formats(m3u8, display_id, 'mp4')\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage).strip()\n        description = self._og_search_description(webpage).strip()\n        thumbnail = self._og_search_thumbnail(webpage)\n        timestamp = parse_iso8601(self._search_regex(\n            r'<div class=\"meta\">\\s*<time class=\"timeago\" datetime=\"([^\"]+)\">',\n            webpage, 'upload date', fatal=False))\n        uploader = self._search_regex(\n            r'rel=\"author\">([^<]+)</a>',\n            webpage, 'uploader', default=None)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'formats': formats,\n        }",
        "begin_line": 36,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001092896174863388,
            "pseudo_dstar_susp": 0.0028089887640449437,
            "pseudo_tarantula_susp": 0.0009871668311944718,
            "pseudo_op2_susp": 0.0028089887640449437,
            "pseudo_barinel_susp": 0.0009871668311944718
        }
    },
    {
        "name": "youtube_dl.extractor.rai.RaiIE._extract_relinker_url#78",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiIE",
        "signature": "youtube_dl.extractor.rai.RaiIE._extract_relinker_url(self, webpage)",
        "snippet": "    def _extract_relinker_url(self, webpage):\n        return self._proto_relative_url(self._search_regex(\n            [r'name=\"videourl\" content=\"([^\"]+)\"', r'var\\s+videoURL(?:_MP4)?\\s*=\\s*\"([^\"]+)\"'],\n            webpage, 'relinker url', default=None))",
        "begin_line": 78,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.000244081034903588,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.rai.RaiIE._real_extract#83",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiIE",
        "signature": "youtube_dl.extractor.rai.RaiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        host = mobj.group('host')\n\n        webpage = self._download_webpage(url, video_id)\n\n        relinker_url = self._extract_relinker_url(webpage)\n\n        if not relinker_url:\n            iframe_path = self._search_regex(\n                r'<iframe[^>]+src=\"/?(dl/[^\"]+\\?iframe\\b[^\"]*)\"',\n                webpage, 'iframe')\n            webpage = self._download_webpage(\n                '%s/%s' % (host, iframe_path), video_id)\n            relinker_url = self._extract_relinker_url(webpage)\n\n        relinker = self._download_json(\n            '%s&output=47' % relinker_url, video_id)\n\n        media_url = relinker['video'][0]\n        ct = relinker.get('ct')\n        if ct == 'f4m':\n            formats = self._extract_f4m_formats(\n                media_url + '&hdcore=3.7.0&plugin=aasp-3.7.0.39.44', video_id)\n        else:\n            formats = [{\n                'url': media_url,\n                'format_id': ct,\n            }]\n\n        json_link = self._html_search_meta(\n            'jsonlink', webpage, 'JSON link', default=None)\n        if json_link:\n            media = self._download_json(\n                host + json_link, video_id, 'Downloading video JSON')\n            title = media.get('name')\n            description = media.get('desc')\n            thumbnail = media.get('image_300') or media.get('image_medium') or media.get('image')\n            duration = parse_duration(media.get('length'))\n            uploader = media.get('author')\n            upload_date = unified_strdate(media.get('date'))\n        else:\n            title = (self._search_regex(\n                r'var\\s+videoTitolo\\s*=\\s*\"(.+?)\";',\n                webpage, 'title', default=None) or self._og_search_title(webpage)).replace('\\\\\"', '\"')\n            description = self._og_search_description(webpage)\n            thumbnail = self._og_search_thumbnail(webpage)\n            duration = None\n            uploader = self._html_search_meta('Editore', webpage, 'uploader')\n            upload_date = unified_strdate(self._html_search_meta(\n                'item-date', webpage, 'upload date', default=None))\n\n        subtitles = self.extract_subtitles(video_id, webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 83,
        "end_line": 148,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.downloader.__init__.get_suitable_downloader#26",
        "src_path": "youtube_dl/downloader/__init__.py",
        "class_name": "youtube_dl.downloader.__init__",
        "signature": "youtube_dl.downloader.__init__.get_suitable_downloader(info_dict, params={})",
        "snippet": "def get_suitable_downloader(info_dict, params={}):\n    \"\"\"Get the downloader class that can handle the info dict.\"\"\"\n    protocol = determine_protocol(info_dict)\n    info_dict['protocol'] = protocol\n\n    external_downloader = params.get('external_downloader')\n    if external_downloader is not None:\n        ed = get_external_downloader(external_downloader)\n        if ed.supports(info_dict):\n            return ed\n\n    if protocol == 'm3u8' and params.get('hls_prefer_native'):\n        return NativeHlsFD\n\n    return PROTOCOL_MAP.get(protocol, HttpFD)",
        "begin_line": 26,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.addanime.AddAnimeIE._real_extract#34",
        "src_path": "youtube_dl/extractor/addanime.py",
        "class_name": "youtube_dl.extractor.addanime.AddAnimeIE",
        "signature": "youtube_dl.extractor.addanime.AddAnimeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        try:\n            webpage = self._download_webpage(url, video_id)\n        except ExtractorError as ee:\n            if not isinstance(ee.cause, compat_HTTPError) or \\\n               ee.cause.code != 503:\n                raise\n\n            redir_webpage = ee.cause.read().decode('utf-8')\n            action = self._search_regex(\n                r'<form id=\"challenge-form\" action=\"([^\"]+)\"',\n                redir_webpage, 'Redirect form')\n            vc = self._search_regex(\n                r'<input type=\"hidden\" name=\"jschl_vc\" value=\"([^\"]+)\"/>',\n                redir_webpage, 'redirect vc value')\n            av = re.search(\n                r'a\\.value = ([0-9]+)[+]([0-9]+)[*]([0-9]+);',\n                redir_webpage)\n            if av is None:\n                raise ExtractorError('Cannot find redirect math task')\n            av_res = int(av.group(1)) + int(av.group(2)) * int(av.group(3))\n\n            parsed_url = compat_urllib_parse_urlparse(url)\n            av_val = av_res + len(parsed_url.netloc)\n            confirm_url = (\n                parsed_url.scheme + '://' + parsed_url.netloc +\n                action + '?' +\n                compat_urllib_parse.urlencode({\n                    'jschl_vc': vc, 'jschl_answer': compat_str(av_val)}))\n            self._download_webpage(\n                confirm_url, video_id,\n                note='Confirming after redirect')\n            webpage = self._download_webpage(url, video_id)\n\n        FORMATS = ('normal', 'hq')\n        quality = qualities(FORMATS)\n        formats = []\n        for format_id in FORMATS:\n            rex = r\"var %s_video_file = '(.*?)';\" % re.escape(format_id)\n            video_url = self._search_regex(rex, webpage, 'video file URLx',\n                                           fatal=False)\n            if not video_url:\n                continue\n            formats.append({\n                'format_id': format_id,\n                'url': video_url,\n                'quality': quality(format_id),\n            })\n        self._sort_formats(formats)\n        video_title = self._og_search_title(webpage)\n        video_description = self._og_search_description(webpage)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'formats': formats,\n            'title': video_title,\n            'description': video_description\n        }",
        "begin_line": 34,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007733952049497294,
            "pseudo_dstar_susp": 0.0007722007722007722,
            "pseudo_tarantula_susp": 0.0007898894154818325,
            "pseudo_op2_susp": 0.0007722007722007722,
            "pseudo_barinel_susp": 0.0007898894154818325
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._prepare_call#33",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._prepare_call(self, path, timestamp=None, post_data=None)",
        "snippet": "    def _prepare_call(self, path, timestamp=None, post_data=None):\n        path += '?' if '?' not in path else '&'\n        if not timestamp:\n            timestamp = int(time.time())\n        query = self._API_QUERY_TEMPLATE % (path, self._APP, timestamp)\n        if self._token:\n            query += '&token=%s' % self._token\n        sig = hmac.new(\n            self._APP_SECRET.encode('ascii'),\n            query.encode('ascii'),\n            hashlib.sha1\n        ).hexdigest()\n        url = self._API_URL_TEMPLATE % (query, sig)\n        return compat_urllib_request.Request(\n            url, json.dumps(post_data).encode('utf-8')) if post_data else url",
        "begin_line": 33,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._call_api#49",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._call_api(self, path, video_id, note, timestamp=None, post_data=None)",
        "snippet": "    def _call_api(self, path, video_id, note, timestamp=None, post_data=None):\n        resp = self._download_json(\n            self._prepare_call(path, timestamp, post_data), video_id, note)\n\n        error = resp.get('error')\n        if error:\n            if error == 'invalid timestamp':\n                resp = self._download_json(\n                    self._prepare_call(path, int(resp['current_timestamp']), post_data),\n                    video_id, '%s (retry)' % note)\n                error = resp.get('error')\n            if error:\n                self._raise_error(resp['error'])\n\n        return resp",
        "begin_line": 49,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._real_initialize#70",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 70,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiIE._real_extract#178",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiIE",
        "signature": "youtube_dl.extractor.viki.VikiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._call_api(\n            'videos/%s.json' % video_id, video_id, 'Downloading video JSON')\n\n        title = None\n        titles = video.get('titles')\n        if titles:\n            title = titles.get('en') or titles[titles.keys()[0]]\n        if not title:\n            title = 'Episode %d' % video.get('number') if video.get('type') == 'episode' else video.get('id') or video_id\n            container_titles = video.get('container', {}).get('titles')\n            if container_titles:\n                container_title = container_titles.get('en') or container_titles[container_titles.keys()[0]]\n                title = '%s - %s' % (container_title, title)\n\n        descriptions = video.get('descriptions')\n        description = descriptions.get('en') or descriptions[titles.keys()[0]] if descriptions else None\n\n        duration = int_or_none(video.get('duration'))\n        timestamp = parse_iso8601(video.get('created_at'))\n        uploader = video.get('author')\n        like_count = int_or_none(video.get('likes', {}).get('count'))\n        age_limit = parse_age_limit(video.get('rating'))\n\n        thumbnails = []\n        for thumbnail_id, thumbnail in video.get('images', {}).items():\n            thumbnails.append({\n                'id': thumbnail_id,\n                'url': thumbnail.get('url'),\n            })\n\n        subtitles = {}\n        for subtitle_lang, _ in video.get('subtitle_completions', {}).items():\n            subtitles[subtitle_lang] = [{\n                'ext': subtitles_format,\n                'url': self._prepare_call(\n                    'videos/%s/subtitles/%s.%s' % (video_id, subtitle_lang, subtitles_format)),\n            } for subtitles_format in ('srt', 'vtt')]\n\n        result = {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'like_count': like_count,\n            'age_limit': age_limit,\n            'thumbnails': thumbnails,\n            'subtitles': subtitles,\n        }\n\n        streams = self._call_api(\n            'videos/%s/streams.json' % video_id, video_id,\n            'Downloading video streams JSON')\n\n        if 'external' in streams:\n            result.update({\n                '_type': 'url_transparent',\n                'url': streams['external']['url'],\n            })\n            return result\n\n        formats = []\n        for format_id, stream_dict in streams.items():\n            height = self._search_regex(\n                r'^(\\d+)[pP]$', format_id, 'height', default=None)\n            for protocol, format_dict in stream_dict.items():\n                if format_id == 'm3u8':\n                    formats = self._extract_m3u8_formats(\n                        format_dict['url'], video_id, 'mp4', m3u8_id='m3u8-%s' % protocol)\n                else:\n                    formats.append({\n                        'url': format_dict['url'],\n                        'format_id': '%s-%s' % (format_id, protocol),\n                        'height': height,\n                    })\n        self._sort_formats(formats)\n\n        result['formats'] = formats\n        return result",
        "begin_line": 178,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_brightcove_urls#194",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_brightcove_urls(cls, webpage)",
        "snippet": "    def _extract_brightcove_urls(cls, webpage):\n        \"\"\"Return a list of all Brightcove URLs from the webpage \"\"\"\n\n        url_m = re.search(\n            r'<meta\\s+property=[\\'\"]og:video[\\'\"]\\s+content=[\\'\"](https?://(?:secure|c)\\.brightcove.com/[^\\'\"]+)[\\'\"]',\n            webpage)\n        if url_m:\n            url = unescapeHTML(url_m.group(1))\n            # Some sites don't add it, we can't download with this url, for example:\n            # http://www.ktvu.com/videos/news/raw-video-caltrain-releases-video-of-man-almost/vCTZdY/\n            if 'playerKey' in url or 'videoId' in url:\n                return [url]\n\n        matches = re.findall(\n            r'''(?sx)<object\n            (?:\n                [^>]+?class=[\\'\"][^>]*?BrightcoveExperience.*?[\\'\"] |\n                [^>]*?>\\s*<param\\s+name=\"movie\"\\s+value=\"https?://[^/]*brightcove\\.com/\n            ).+?>\\s*</object>''',\n            webpage)\n        if matches:\n            return list(filter(None, [cls._build_brighcove_url(m) for m in matches]))\n\n        return list(filter(None, [\n            cls._build_brighcove_url_from_js(custom_bc)\n            for custom_bc in re.findall(r'(customBC\\.createVideo\\(.+?\\);)', webpage)]))",
        "begin_line": 194,
        "end_line": 219,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._real_extract#221",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        # Change the 'videoId' and others field to '@videoPlayer'\n        url = re.sub(r'(?<=[?&])(videoI(d|D)|bctid)', '%40videoPlayer', url)\n        # Change bckey (used by bcove.me urls) to playerKey\n        url = re.sub(r'(?<=[?&])bckey', 'playerKey', url)\n        mobj = re.match(self._VALID_URL, url)\n        query_str = mobj.group('query')\n        query = compat_urlparse.parse_qs(query_str)\n\n        videoPlayer = query.get('@videoPlayer')\n        if videoPlayer:\n            # We set the original url as the default 'Referer' header\n            referer = smuggled_data.get('Referer', url)\n            return self._get_video_info(\n                videoPlayer[0], query_str, query, referer=referer)\n        elif 'playerKey' in query:\n            player_key = query['playerKey']\n            return self._get_playlist_info(player_key[0])\n        else:\n            raise ExtractorError(\n                'Cannot find playerKey= variable. Did you forget quotes in a shell invocation?',\n                expected=True)",
        "begin_line": 221,
        "end_line": 244,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002554931016862545,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.cspan.CSpanIE._real_extract#59",
        "src_path": "youtube_dl/extractor/cspan.py",
        "class_name": "youtube_dl.extractor.cspan.CSpanIE",
        "signature": "youtube_dl.extractor.cspan.CSpanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_id = mobj.group('id')\n        webpage = self._download_webpage(url, page_id)\n        video_id = self._search_regex(r'progid=\\'?([0-9]+)\\'?>', webpage, 'video id')\n\n        description = self._html_search_regex(\n            [\n                # The full description\n                r'<div class=\\'expandable\\'>(.*?)<a href=\\'#\\'',\n                # If the description is small enough the other div is not\n                # present, otherwise this is a stripped version\n                r'<p class=\\'initial\\'>(.*?)</p>'\n            ],\n            webpage, 'description', flags=re.DOTALL, default=None)\n\n        info_url = 'http://c-spanvideo.org/videoLibrary/assets/player/ajax-player.php?os=android&html5=program&id=' + video_id\n        data = self._download_json(info_url, video_id)\n\n        doc = self._download_xml(\n            'http://www.c-span.org/common/services/flashXml.php?programid=' + video_id,\n            video_id)\n\n        title = find_xpath_attr(doc, './/string', 'name', 'title').text\n        thumbnail = find_xpath_attr(doc, './/string', 'name', 'poster').text\n\n        senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)\n        if senate_isvp_url:\n            surl = smuggle_url(senate_isvp_url, {'force_title': title})\n            return self.url_result(surl, 'SenateISVP', video_id, title)\n\n        files = data['video']['files']\n        try:\n            capfile = data['video']['capfile']['#text']\n        except KeyError:\n            capfile = None\n\n        entries = [{\n            'id': '%s_%d' % (video_id, partnum + 1),\n            'title': (\n                title if len(files) == 1 else\n                '%s part %d' % (title, partnum + 1)),\n            'url': unescapeHTML(f['path']['#text']),\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': int_or_none(f.get('length', {}).get('#text')),\n            'subtitles': {\n                'en': [{\n                    'url': capfile,\n                    'ext': determine_ext(capfile, 'dfxp')\n                }],\n            } if capfile else None,\n        } for partnum, f in enumerate(files)]\n\n        if len(entries) == 1:\n            entry = dict(entries[0])\n            entry['id'] = video_id\n            return entry\n        else:\n            return {\n                '_type': 'playlist',\n                'entries': entries,\n                'title': title,\n                'id': video_id,\n            }",
        "begin_line": 59,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.000242306760358614,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._real_extract#115",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url, re.VERBOSE)\n        if m.group('type').startswith('embed'):\n            desktop_url = m.group('proto') + 'www' + m.group('urlmain')\n            return self.url_result(desktop_url, 'TED')\n        name = m.group('name')\n        if m.group('type_talk'):\n            return self._talk_info(url, name)\n        elif m.group('type_watch'):\n            return self._watch_info(url, name)\n        else:\n            return self._playlist_videos_info(url, name)",
        "begin_line": 115,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006944444444444444,
            "pseudo_dstar_susp": 0.0022026431718061676,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0022026431718061676,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._talk_info#145",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._talk_info(self, url, video_name)",
        "snippet": "    def _talk_info(self, url, video_name):\n        webpage = self._download_webpage(url, video_name)\n        self.report_extraction(video_name)\n\n        talk_info = self._extract_info(webpage)['talks'][0]\n\n        external = talk_info.get('external')\n        if external:\n            service = external['service']\n            self.to_screen('Found video from %s' % service)\n            ext_url = None\n            if service.lower() == 'youtube':\n                ext_url = external.get('code')\n            return {\n                '_type': 'url',\n                'url': ext_url or external['uri'],\n            }\n\n        formats = [{\n            'url': format_url,\n            'format_id': format_id,\n            'format': format_id,\n        } for (format_id, format_url) in talk_info['nativeDownloads'].items() if format_url is not None]\n        if formats:\n            for f in formats:\n                finfo = self._NATIVE_FORMATS.get(f['format_id'])\n                if finfo:\n                    f.update(finfo)\n\n        for format_id, resources in talk_info['resources'].items():\n            if format_id == 'h264':\n                for resource in resources:\n                    bitrate = int_or_none(resource.get('bitrate'))\n                    formats.append({\n                        'url': resource['file'],\n                        'format_id': '%s-%sk' % (format_id, bitrate),\n                        'tbr': bitrate,\n                    })\n            elif format_id == 'rtmp':\n                streamer = talk_info.get('streamer')\n                if not streamer:\n                    continue\n                for resource in resources:\n                    formats.append({\n                        'format_id': '%s-%s' % (format_id, resource.get('name')),\n                        'url': streamer,\n                        'play_path': resource['file'],\n                        'ext': 'flv',\n                        'width': int_or_none(resource.get('width')),\n                        'height': int_or_none(resource.get('height')),\n                        'tbr': int_or_none(resource.get('bitrate')),\n                    })\n            elif format_id == 'hls':\n                hls_formats = self._extract_m3u8_formats(\n                    resources.get('stream'), video_name, 'mp4', m3u8_id=format_id)\n                for f in hls_formats:\n                    if f.get('format_id') == 'hls-meta':\n                        continue\n                    if not f.get('height'):\n                        f['vcodec'] = 'none'\n                    else:\n                        f['acodec'] = 'none'\n                formats.extend(hls_formats)\n\n        audio_download = talk_info.get('audioDownload')\n        if audio_download:\n            formats.append({\n                'url': audio_download,\n                'format_id': 'audio',\n                'vcodec': 'none',\n                'preference': -0.5,\n            })\n\n        self._sort_formats(formats)\n\n        video_id = compat_str(talk_info['id'])\n\n        thumbnail = talk_info['thumb']\n        if not thumbnail.startswith('http'):\n            thumbnail = 'http://' + thumbnail\n        return {\n            'id': video_id,\n            'title': talk_info['title'].strip(),\n            'uploader': talk_info['speaker'],\n            'thumbnail': thumbnail,\n            'description': self._og_search_description(webpage),\n            'subtitles': self._get_subtitles(video_id, talk_info),\n            'formats': formats,\n            'duration': talk_info.get('duration'),\n        }",
        "begin_line": 145,
        "end_line": 234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._prefer_source#89",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._prefer_source(self, formats)",
        "snippet": "    def _prefer_source(self, formats):\n        try:\n            source = next(f for f in formats if f['format_id'] == 'Source')\n            source['preference'] = 10\n        except StopIteration:\n            pass  # No Source stream present\n        self._sort_formats(formats)",
        "begin_line": 89,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.000245398773006135,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._download_info#99",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._download_info(self, item, item_id)",
        "snippet": "    def _download_info(self, item, item_id):\n        return self._extract_info(self._download_json(\n            '%s/kraken/videos/%s%s' % (self._API_BASE, item, item_id), item_id,\n            'Downloading %s info JSON' % self._ITEM_TYPE))",
        "begin_line": 99,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00024509803921568627,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_media#104",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_media(self, item_id)",
        "snippet": "    def _extract_media(self, item_id):\n        info = self._download_info(self._ITEM_SHORTCUT, item_id)\n        response = self._download_json(\n            '%s/api/videos/%s%s' % (self._API_BASE, self._ITEM_SHORTCUT, item_id), item_id,\n            'Downloading %s playlist JSON' % self._ITEM_TYPE)\n        entries = []\n        chunks = response['chunks']\n        qualities = list(chunks.keys())\n        for num, fragment in enumerate(zip(*chunks.values()), start=1):\n            formats = []\n            for fmt_num, fragment_fmt in enumerate(fragment):\n                format_id = qualities[fmt_num]\n                fmt = {\n                    'url': fragment_fmt['url'],\n                    'format_id': format_id,\n                    'quality': 1 if format_id == 'live' else 0,\n                }\n                m = re.search(r'^(?P<height>\\d+)[Pp]', format_id)\n                if m:\n                    fmt['height'] = int(m.group('height'))\n                formats.append(fmt)\n            self._sort_formats(formats)\n            entry = dict(info)\n            entry['id'] = '%s_%d' % (entry['id'], num)\n            entry['title'] = '%s part %d' % (entry['title'], num)\n            entry['formats'] = formats\n            entries.append(entry)\n        return self.playlist_result(entries, info['id'], info['title'])",
        "begin_line": 104,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00024594195769798326,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_info#133",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_info(self, info)",
        "snippet": "    def _extract_info(self, info):\n        return {\n            'id': info['_id'],\n            'title': info['title'],\n            'description': info['description'],\n            'duration': info['length'],\n            'thumbnail': info['preview'],\n            'uploader': info['channel']['display_name'],\n            'uploader_id': info['channel']['name'],\n            'timestamp': parse_iso8601(info['recorded_at']),\n            'view_count': info['views'],\n        }",
        "begin_line": 133,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002469135802469136,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._real_extract#146",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_media(self._match_id(url))",
        "begin_line": 146,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00024807740014884643,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchVodIE._real_extract#211",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchVodIE",
        "signature": "youtube_dl.extractor.twitch.TwitchVodIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        item_id = self._match_id(url)\n        info = self._download_info(self._ITEM_SHORTCUT, item_id)\n        access_token = self._download_json(\n            '%s/api/vods/%s/access_token' % (self._API_BASE, item_id), item_id,\n            'Downloading %s access token' % self._ITEM_TYPE)\n        formats = self._extract_m3u8_formats(\n            '%s/vod/%s?nauth=%s&nauthsig=%s&allow_source=true'\n            % (self._USHER_BASE, item_id, access_token['token'], access_token['sig']),\n            item_id, 'mp4')\n        self._prefer_source(formats)\n        info['formats'] = formats\n        return info",
        "begin_line": 211,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025075225677031093,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist#230",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist(self, channel_id)",
        "snippet": "    def _extract_playlist(self, channel_id):\n        info = self._download_json(\n            '%s/kraken/channels/%s' % (self._API_BASE, channel_id),\n            channel_id, 'Downloading channel info JSON')\n        channel_name = info.get('display_name') or info.get('name')\n        entries = []\n        offset = 0\n        limit = self._PAGE_LIMIT\n        for counter in itertools.count(1):\n            response = self._download_json(\n                self._PLAYLIST_URL % (channel_id, offset, limit),\n                channel_id, 'Downloading %s videos JSON page %d' % (self._PLAYLIST_TYPE, counter))\n            page_entries = self._extract_playlist_page(response)\n            if not page_entries:\n                break\n            entries.extend(page_entries)\n            offset += limit\n        return self.playlist_result(\n            [self.url_result(entry) for entry in set(entries)],\n            channel_id, channel_name)",
        "begin_line": 230,
        "end_line": 249,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025150905432595576,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist_page#251",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist_page(self, response)",
        "snippet": "    def _extract_playlist_page(self, response):\n        videos = response.get('videos')\n        return [video['url'] for video in videos] if videos else []",
        "begin_line": 251,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025207965717166626,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._real_extract#255",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_playlist(self._match_id(url))",
        "begin_line": 255,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002550369803621525,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBookmarksIE._extract_playlist_page#305",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBookmarksIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBookmarksIE._extract_playlist_page(self, response)",
        "snippet": "    def _extract_playlist_page(self, response):\n        entries = []\n        for bookmark in response.get('bookmarks', []):\n            video = bookmark.get('video')\n            if not video:\n                continue\n            entries.append(video['url'])\n        return entries",
        "begin_line": 305,
        "end_line": 312,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchStreamIE._real_extract#340",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchStreamIE",
        "signature": "youtube_dl.extractor.twitch.TwitchStreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        stream = self._download_json(\n            '%s/kraken/streams/%s' % (self._API_BASE, channel_id), channel_id,\n            'Downloading stream JSON').get('stream')\n\n        # Fallback on profile extraction if stream is offline\n        if not stream:\n            return self.url_result(\n                'http://www.twitch.tv/%s/profile' % channel_id,\n                'TwitchProfile', channel_id)\n\n        access_token = self._download_json(\n            '%s/api/channels/%s/access_token' % (self._API_BASE, channel_id), channel_id,\n            'Downloading channel access token')\n\n        query = {\n            'allow_source': 'true',\n            'p': random.randint(1000000, 10000000),\n            'player': 'twitchweb',\n            'segment_preference': '4',\n            'sig': access_token['sig'].encode('utf-8'),\n            'token': access_token['token'].encode('utf-8'),\n        }\n        formats = self._extract_m3u8_formats(\n            '%s/api/channel/hls/%s.m3u8?%s'\n            % (self._USHER_BASE, channel_id, compat_urllib_parse.urlencode(query)),\n            channel_id, 'mp4')\n        self._prefer_source(formats)\n\n        view_count = stream.get('viewers')\n        timestamp = parse_iso8601(stream.get('created_at'))\n\n        channel = stream['channel']\n        title = self._live_title(channel.get('display_name') or channel.get('name'))\n        description = channel.get('status')\n\n        thumbnails = []\n        for thumbnail_key, thumbnail_url in stream['preview'].items():\n            m = re.search(r'(?P<width>\\d+)x(?P<height>\\d+)\\.jpg$', thumbnail_key)\n            if not m:\n                continue\n            thumbnails.append({\n                'url': thumbnail_url,\n                'width': int(m.group('width')),\n                'height': int(m.group('height')),\n            })\n\n        return {\n            'id': compat_str(stream['_id']),\n            'display_id': channel_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'uploader': channel.get('display_name'),\n            'uploader_id': channel.get('name'),\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'formats': formats,\n            'is_live': True,\n        }",
        "begin_line": 340,
        "end_line": 401,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.__init__#30",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.__init__(self, code, objects=None)",
        "snippet": "    def __init__(self, code, objects=None):\n        if objects is None:\n            objects = {}\n        self.code = code\n        self._functions = {}\n        self._objects = objects",
        "begin_line": 30,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002588661661920787,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.interpret_statement#37",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.interpret_statement(self, stmt, local_vars, allow_recursion=100)",
        "snippet": "    def interpret_statement(self, stmt, local_vars, allow_recursion=100):\n        if allow_recursion < 0:\n            raise ExtractorError('Recursion limit reached')\n\n        should_abort = False\n        stmt = stmt.lstrip()\n        stmt_m = re.match(r'var\\s', stmt)\n        if stmt_m:\n            expr = stmt[len(stmt_m.group(0)):]\n        else:\n            return_m = re.match(r'return(?:\\s+|$)', stmt)\n            if return_m:\n                expr = stmt[len(return_m.group(0)):]\n                should_abort = True\n            else:\n                # Try interpreting it as an expression\n                expr = stmt\n\n        v = self.interpret_expression(expr, local_vars, allow_recursion)\n        return v, should_abort",
        "begin_line": 37,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002658160552897395,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.interpret_expression#58",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.interpret_expression(self, expr, local_vars, allow_recursion)",
        "snippet": "    def interpret_expression(self, expr, local_vars, allow_recursion):\n        expr = expr.strip()\n\n        if expr == '':  # Empty expression\n            return None\n\n        if expr.startswith('('):\n            parens_count = 0\n            for m in re.finditer(r'[()]', expr):\n                if m.group(0) == '(':\n                    parens_count += 1\n                else:\n                    parens_count -= 1\n                    if parens_count == 0:\n                        sub_expr = expr[1:m.start()]\n                        sub_result = self.interpret_expression(\n                            sub_expr, local_vars, allow_recursion)\n                        remaining_expr = expr[m.end():].strip()\n                        if not remaining_expr:\n                            return sub_result\n                        else:\n                            expr = json.dumps(sub_result) + remaining_expr\n                        break\n            else:\n                raise ExtractorError('Premature end of parens in %r' % expr)\n\n        for op, opfunc in _ASSIGN_OPERATORS:\n            m = re.match(r'''(?x)\n                (?P<out>%s)(?:\\[(?P<index>[^\\]]+?)\\])?\n                \\s*%s\n                (?P<expr>.*)$''' % (_NAME_RE, re.escape(op)), expr)\n            if not m:\n                continue\n            right_val = self.interpret_expression(\n                m.group('expr'), local_vars, allow_recursion - 1)\n\n            if m.groupdict().get('index'):\n                lvar = local_vars[m.group('out')]\n                idx = self.interpret_expression(\n                    m.group('index'), local_vars, allow_recursion)\n                assert isinstance(idx, int)\n                cur = lvar[idx]\n                val = opfunc(cur, right_val)\n                lvar[idx] = val\n                return val\n            else:\n                cur = local_vars.get(m.group('out'))\n                val = opfunc(cur, right_val)\n                local_vars[m.group('out')] = val\n                return val\n\n        if expr.isdigit():\n            return int(expr)\n\n        var_m = re.match(\n            r'(?!if|return|true|false)(?P<name>%s)$' % _NAME_RE,\n            expr)\n        if var_m:\n            return local_vars[var_m.group('name')]\n\n        try:\n            return json.loads(expr)\n        except ValueError:\n            pass\n\n        m = re.match(\n            r'(?P<var>%s)\\.(?P<member>[^(]+)(?:\\(+(?P<args>[^()]*)\\))?$' % _NAME_RE,\n            expr)\n        if m:\n            variable = m.group('var')\n            member = m.group('member')\n            arg_str = m.group('args')\n\n            if variable in local_vars:\n                obj = local_vars[variable]\n            else:\n                if variable not in self._objects:\n                    self._objects[variable] = self.extract_object(variable)\n                obj = self._objects[variable]\n\n            if arg_str is None:\n                # Member access\n                if member == 'length':\n                    return len(obj)\n                return obj[member]\n\n            assert expr.endswith(')')\n            # Function call\n            if arg_str == '':\n                argvals = tuple()\n            else:\n                argvals = tuple([\n                    self.interpret_expression(v, local_vars, allow_recursion)\n                    for v in arg_str.split(',')])\n\n            if member == 'split':\n                assert argvals == ('',)\n                return list(obj)\n            if member == 'join':\n                assert len(argvals) == 1\n                return argvals[0].join(obj)\n            if member == 'reverse':\n                assert len(argvals) == 0\n                obj.reverse()\n                return obj\n            if member == 'slice':\n                assert len(argvals) == 1\n                return obj[argvals[0]:]\n            if member == 'splice':\n                assert isinstance(obj, list)\n                index, howMany = argvals\n                res = []\n                for i in range(index, min(index + howMany, len(obj))):\n                    res.append(obj.pop(index))\n                return res\n\n            return obj[member](argvals)\n\n        m = re.match(\n            r'(?P<in>%s)\\[(?P<idx>.+)\\]$' % _NAME_RE, expr)\n        if m:\n            val = local_vars[m.group('in')]\n            idx = self.interpret_expression(\n                m.group('idx'), local_vars, allow_recursion - 1)\n            return val[idx]\n\n        for op, opfunc in _OPERATORS:\n            m = re.match(r'(?P<x>.+?)%s(?P<y>.+)' % re.escape(op), expr)\n            if not m:\n                continue\n            x, abort = self.interpret_statement(\n                m.group('x'), local_vars, allow_recursion - 1)\n            if abort:\n                raise ExtractorError(\n                    'Premature left-side return of %s in %r' % (op, expr))\n            y, abort = self.interpret_statement(\n                m.group('y'), local_vars, allow_recursion - 1)\n            if abort:\n                raise ExtractorError(\n                    'Premature right-side return of %s in %r' % (op, expr))\n            return opfunc(x, y)\n\n        m = re.match(\n            r'^(?P<func>%s)\\((?P<args>[a-zA-Z0-9_$,]+)\\)$' % _NAME_RE, expr)\n        if m:\n            fname = m.group('func')\n            argvals = tuple([\n                int(v) if v.isdigit() else local_vars[v]\n                for v in m.group('args').split(',')])\n            if fname not in self._functions:\n                self._functions[fname] = self.extract_function(fname)\n            return self._functions[fname](argvals)\n\n        raise ExtractorError('Unsupported JS expression %r' % expr)",
        "begin_line": 58,
        "end_line": 211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.extract_function#232",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.extract_function(self, funcname)",
        "snippet": "    def extract_function(self, funcname):\n        func_m = re.search(\n            r'''(?x)\n                (?:function\\s+%s|[{;]%s\\s*=\\s*function)\\s*\n                \\((?P<args>[^)]*)\\)\\s*\n                \\{(?P<code>[^}]+)\\}''' % (\n                re.escape(funcname), re.escape(funcname)),\n            self.code)\n        if func_m is None:\n            raise ExtractorError('Could not find JS function %r' % funcname)\n        argnames = func_m.group('args').split(',')\n\n        return self.build_function(argnames, func_m.group('code'))",
        "begin_line": 232,
        "end_line": 244,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002588661661920787,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.call_function#246",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.call_function(self, funcname, *args)",
        "snippet": "    def call_function(self, funcname, *args):\n        f = self.extract_function(funcname)\n        return f(args)",
        "begin_line": 246,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002588661661920787,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.build_function#250",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.build_function(self, argnames, code)",
        "snippet": "    def build_function(self, argnames, code):\n        def resf(args):\n            local_vars = dict(zip(argnames, args))\n            for stmt in code.split(';'):\n                res, abort = self.interpret_statement(stmt, local_vars)\n                if abort:\n                    break\n            return res\n        return resf",
        "begin_line": 250,
        "end_line": 258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002588661661920787,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.resf#251",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.resf(args)",
        "snippet": "        def resf(args):\n            local_vars = dict(zip(argnames, args))\n            for stmt in code.split(';'):\n                res, abort = self.interpret_statement(stmt, local_vars)\n                if abort:\n                    break\n            return res",
        "begin_line": 251,
        "end_line": 257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002588661661920787,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.rutv.RUTVIE._extract_url#105",
        "src_path": "youtube_dl/extractor/rutv.py",
        "class_name": "youtube_dl.extractor.rutv.RUTVIE",
        "signature": "youtube_dl.extractor.rutv.RUTVIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://player\\.(?:rutv\\.ru|vgtrk\\.com)/(?:iframe/(?:swf|video|live)/id|index/iframe/cast_id)/.+?)\\1', webpage)\n        if mobj:\n            return mobj.group('url')\n\n        mobj = re.search(\n            r'<meta[^>]+?property=([\"\\'])og:video\\1[^>]+?content=([\"\\'])(?P<url>https?://player\\.(?:rutv\\.ru|vgtrk\\.com)/flash2v/container\\.swf\\?id=.+?\\2)',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 105,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKTVIE._real_extract#211",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKTVIE",
        "signature": "youtube_dl.extractor.nrk.NRKTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        part_id = mobj.group('part_id')\n        baseurl = mobj.group('baseurl')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta(\n            'title', webpage, 'title')\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n\n        thumbnail = self._html_search_regex(\n            r'data-posterimage=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n        upload_date = unified_strdate(self._html_search_meta(\n            'rightsfrom', webpage, 'upload date', fatal=False))\n        duration = float_or_none(self._html_search_regex(\n            r'data-duration=\"([^\"]+)\"',\n            webpage, 'duration', fatal=False))\n\n        # playlist\n        parts = re.findall(\n            r'<a href=\"#del=(\\d+)\"[^>]+data-argument=\"([^\"]+)\">([^<]+)</a>', webpage)\n        if parts:\n            entries = []\n            for current_part_id, stream_url, part_title in parts:\n                if part_id and current_part_id != part_id:\n                    continue\n                video_part_id = '%s-part%s' % (video_id, current_part_id)\n                formats = self._extract_f4m(stream_url, video_part_id)\n                entries.append({\n                    'id': video_part_id,\n                    'title': part_title,\n                    'description': description,\n                    'thumbnail': thumbnail,\n                    'upload_date': upload_date,\n                    'formats': formats,\n                })\n            if part_id:\n                if entries:\n                    return entries[0]\n            else:\n                playlist = self.playlist_result(entries, video_id, title, description)\n                playlist.update({\n                    'thumbnail': thumbnail,\n                    'upload_date': upload_date,\n                    'duration': duration,\n                })\n                return playlist\n\n        formats = []\n\n        f4m_url = re.search(r'data-media=\"([^\"]+)\"', webpage)\n        if f4m_url:\n            formats.extend(self._extract_f4m(f4m_url.group(1), video_id))\n\n        m3u8_url = re.search(r'data-hls-media=\"([^\"]+)\"', webpage)\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(m3u8_url.group(1), video_id, 'mp4'))\n        self._sort_formats(formats)\n\n        subtitles_url = self._html_search_regex(\n            r'data-subtitlesurl[ ]*=[ ]*\"([^\"]+)\"',\n            webpage, 'subtitle URL', default=None)\n        subtitles = None\n        if subtitles_url:\n            subtitles = self.extract_subtitles(subtitles_url, video_id, baseurl)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 211,
        "end_line": 290,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.hitbox.HitboxLiveIE._real_extract#151",
        "src_path": "youtube_dl/extractor/hitbox.py",
        "class_name": "youtube_dl.extractor.hitbox.HitboxLiveIE",
        "signature": "youtube_dl.extractor.hitbox.HitboxLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        player_config = self._download_json(\n            'https://www.hitbox.tv/api/player/config/live/%s' % video_id,\n            video_id)\n\n        formats = []\n        cdns = player_config.get('cdns')\n        servers = []\n        for cdn in cdns:\n            base_url = cdn.get('netConnectionUrl')\n            host = re.search('.+\\.([^\\.]+\\.[^\\./]+)/.+', base_url).group(1)\n            if base_url not in servers:\n                servers.append(base_url)\n                for stream in cdn.get('bitrates'):\n                    label = stream.get('label')\n                    if label == 'Auto':\n                        continue\n                    stream_url = stream.get('url')\n                    if not stream_url:\n                        continue\n                    bitrate = int_or_none(stream.get('bitrate'))\n                    if stream.get('provider') == 'hls' or determine_ext(stream_url) == 'm3u8':\n                        if not stream_url.startswith('http'):\n                            continue\n                        formats.append({\n                            'url': stream_url,\n                            'ext': 'mp4',\n                            'tbr': bitrate,\n                            'format_note': label,\n                            'rtmp_live': True,\n                        })\n                    else:\n                        formats.append({\n                            'url': '%s/%s' % (base_url, stream_url),\n                            'ext': 'mp4',\n                            'tbr': bitrate,\n                            'rtmp_live': True,\n                            'format_note': host,\n                            'page_url': url,\n                            'player_url': 'http://www.hitbox.tv/static/player/flowplayer/flowplayer.commercial-3.2.16.swf',\n                        })\n        self._sort_formats(formats)\n\n        metadata = self._extract_metadata(\n            'https://www.hitbox.tv/api/media/live',\n            video_id)\n        metadata['formats'] = formats\n        metadata['is_live'] = True\n        metadata['title'] = self._live_title(metadata.get('title'))\n\n        return metadata",
        "begin_line": 151,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002544529262086514,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE._real_extract#21",
        "src_path": "youtube_dl/extractor/academicearth.py",
        "class_name": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE",
        "signature": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n        title = self._html_search_regex(\n            r'<h1 class=\"playlist-name\"[^>]*?>(.*?)</h1>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<p class=\"excerpt\"[^>]*?>(.*?)</p>',\n            webpage, 'description', fatal=False)\n        urls = re.findall(\n            r'<li class=\"lecture-preview\">\\s*?<a target=\"_blank\" href=\"([^\"]+)\">',\n            webpage)\n        entries = [self.url_result(u) for u in urls]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': title,\n            'description': description,\n            'entries': entries,\n        }",
        "begin_line": 21,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000779423226812159,
            "pseudo_dstar_susp": 0.002785515320334262,
            "pseudo_tarantula_susp": 0.0007751937984496124,
            "pseudo_op2_susp": 0.002785515320334262,
            "pseudo_barinel_susp": 0.0007751937984496124
        }
    },
    {
        "name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._real_extract#54",
        "src_path": "youtube_dl/extractor/ceskatelevize.py",
        "class_name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE",
        "signature": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url = url.replace('/porady/', '/ivysilani/').replace('/video/', '')\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        NOT_AVAILABLE_STRING = 'This content is not available at your territory due to limited copyright.'\n        if '%s</p>' % NOT_AVAILABLE_STRING in webpage:\n            raise ExtractorError(NOT_AVAILABLE_STRING, expected=True)\n\n        typ = self._html_search_regex(r'getPlaylistUrl\\(\\[\\{\"type\":\"(.+?)\",\"id\":\".+?\"\\}\\],', webpage, 'type')\n        episode_id = self._html_search_regex(r'getPlaylistUrl\\(\\[\\{\"type\":\".+?\",\"id\":\"(.+?)\"\\}\\],', webpage, 'episode_id')\n\n        data = {\n            'playlist[0][type]': typ,\n            'playlist[0][id]': episode_id,\n            'requestUrl': compat_urllib_parse_urlparse(url).path,\n            'requestSource': 'iVysilani',\n        }\n\n        req = compat_urllib_request.Request(\n            'http://www.ceskatelevize.cz/ivysilani/ajax/get-client-playlist',\n            data=compat_urllib_parse.urlencode(data))\n\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n        req.add_header('x-addr', '127.0.0.1')\n        req.add_header('X-Requested-With', 'XMLHttpRequest')\n        req.add_header('Referer', url)\n\n        playlistpage = self._download_json(req, video_id)\n\n        playlist_url = playlistpage['url']\n        if playlist_url == 'error_region':\n            raise ExtractorError(NOT_AVAILABLE_STRING, expected=True)\n\n        req = compat_urllib_request.Request(compat_urllib_parse.unquote(playlist_url))\n        req.add_header('Referer', url)\n\n        playlist = self._download_json(req, video_id)\n\n        item = playlist['playlist'][0]\n        formats = []\n        for format_id, stream_url in item['streamUrls'].items():\n            formats.extend(self._extract_m3u8_formats(stream_url, video_id, 'mp4'))\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        duration = float_or_none(item.get('duration'))\n        thumbnail = item.get('previewImageUrl')\n\n        subtitles = {}\n        subs = item.get('subtitles')\n        if subs:\n            subtitles = self.extract_subtitles(episode_id, subs)\n\n        return {\n            'id': episode_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 54,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.sportbox.SportBoxEmbedIE._extract_urls#87",
        "src_path": "youtube_dl/extractor/sportbox.py",
        "class_name": "youtube_dl.extractor.sportbox.SportBoxEmbedIE",
        "signature": "youtube_dl.extractor.sportbox.SportBoxEmbedIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe[^>]+src=\"(https?://news\\.sportbox\\.ru/vdl/player[^\"]+)\"',\n            webpage)",
        "begin_line": 87,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVIE._extract_url#106",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(r'<meta\\s[^>]*https?://api\\.blip\\.tv/\\w+/redirect/\\w+/(\\d+)', webpage)\n        if mobj:\n            return 'http://blip.tv/a/a-' + mobj.group(1)\n        mobj = re.search(r'<(?:iframe|embed|object)\\s[^>]*(https?://(?:\\w+\\.)?blip\\.tv/(?:play/|api\\.swf#)[a-zA-Z0-9_]+)', webpage)\n        if mobj:\n            return mobj.group(1)",
        "begin_line": 106,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVIE._real_extract#114",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        lookup_id = mobj.group('lookup_id')\n\n        # See https://github.com/rg3/youtube-dl/issues/857 and\n        # https://github.com/rg3/youtube-dl/issues/4197\n        if lookup_id:\n            urlh = self._request_webpage(\n                'http://blip.tv/play/%s' % lookup_id, lookup_id, 'Resolving lookup id')\n            url = compat_urlparse.urlparse(urlh.geturl())\n            qs = compat_urlparse.parse_qs(url.query)\n            mobj = re.match(self._VALID_URL, qs['file'][0])\n\n        video_id = mobj.group('id')\n\n        rss = self._download_xml('http://blip.tv/rss/flash/%s' % video_id, video_id, 'Downloading video RSS')\n\n        def blip(s):\n            return '{http://blip.tv/dtd/blip/1.0}%s' % s\n\n        def media(s):\n            return '{http://search.yahoo.com/mrss/}%s' % s\n\n        def itunes(s):\n            return '{http://www.itunes.com/dtds/podcast-1.0.dtd}%s' % s\n\n        item = rss.find('channel/item')\n\n        video_id = item.find(blip('item_id')).text\n        title = item.find('./title').text\n        description = clean_html(compat_str(item.find(blip('puredescription')).text))\n        timestamp = parse_iso8601(item.find(blip('datestamp')).text)\n        uploader = item.find(blip('user')).text\n        uploader_id = item.find(blip('userid')).text\n        duration = int(item.find(blip('runtime')).text)\n        media_thumbnail = item.find(media('thumbnail'))\n        thumbnail = media_thumbnail.get('url') if media_thumbnail is not None else item.find(itunes('image')).text\n        categories = [category.text for category in item.findall('category')]\n\n        formats = []\n        subtitles_urls = {}\n\n        media_group = item.find(media('group'))\n        for media_content in media_group.findall(media('content')):\n            url = media_content.get('url')\n            role = media_content.get(blip('role'))\n            msg = self._download_webpage(\n                url + '?showplayer=20140425131715&referrer=http://blip.tv&mask=7&skin=flashvars&view=url',\n                video_id, 'Resolving URL for %s' % role)\n            real_url = compat_urlparse.parse_qs(msg.strip())['message'][0]\n\n            media_type = media_content.get('type')\n            if media_type == 'text/srt' or url.endswith('.srt'):\n                LANGS = {\n                    'english': 'en',\n                }\n                lang = role.rpartition('-')[-1].strip().lower()\n                langcode = LANGS.get(lang, lang)\n                subtitles_urls[langcode] = url\n            elif media_type.startswith('video/'):\n                formats.append({\n                    'url': real_url,\n                    'format_id': role,\n                    'format_note': media_type,\n                    'vcodec': media_content.get(blip('vcodec')) or 'none',\n                    'acodec': media_content.get(blip('acodec')),\n                    'filesize': media_content.get('filesize'),\n                    'width': int_or_none(media_content.get('width')),\n                    'height': int_or_none(media_content.get('height')),\n                })\n        self._check_formats(formats, video_id)\n        self._sort_formats(formats)\n\n        subtitles = self.extract_subtitles(video_id, subtitles_urls)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 114,
        "end_line": 201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVUserIE._real_extract#231",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVUserIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        username = mobj.group(1)\n\n        page_base = 'http://m.blip.tv/pr/show_get_full_episode_list?users_id=%s&lite=0&esi=1'\n\n        page = self._download_webpage(url, username, 'Downloading user page')\n        mobj = re.search(r'data-users-id=\"([^\"]+)\"', page)\n        page_base = page_base % mobj.group(1)\n        title = self._og_search_title(page)\n\n        # Download video ids using BlipTV Ajax calls. Result size per\n        # query is limited (currently to 12 videos) so we need to query\n        # page by page until there are no video ids - it means we got\n        # all of them.\n\n        video_ids = []\n        pagenum = 1\n\n        while True:\n            url = page_base + \"&page=\" + str(pagenum)\n            page = self._download_webpage(\n                url, username, 'Downloading video ids from page %d' % pagenum)\n\n            # Extract video identifiers\n            ids_in_page = []\n\n            for mobj in re.finditer(r'href=\"/([^\"]+)\"', page):\n                if mobj.group(1) not in ids_in_page:\n                    ids_in_page.append(unescapeHTML(mobj.group(1)))\n\n            video_ids.extend(ids_in_page)\n\n            # A little optimization - if current page is not\n            # \"full\", ie. does not contain PAGE_SIZE video ids then\n            # we can assume that this page is the last one - there\n            # are no more ids on further pages - no need to query\n            # again.\n\n            if len(ids_in_page) < self._PAGE_SIZE:\n                break\n\n            pagenum += 1\n\n        urls = ['http://blip.tv/%s' % video_id for video_id in video_ids]\n        url_entries = [self.url_result(vurl, 'BlipTV') for vurl in urls]\n        return self.playlist_result(\n            url_entries, playlist_title=title, playlist_id=username)",
        "begin_line": 231,
        "end_line": 278,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025246149962130775,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.walla.WallaIE._real_extract#36",
        "src_path": "youtube_dl/extractor/walla.py",
        "class_name": "youtube_dl.extractor.walla.WallaIE",
        "signature": "youtube_dl.extractor.walla.WallaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        video = self._download_xml(\n            'http://video2.walla.co.il/?w=null/null/%s/@@/video/flv_pl' % video_id,\n            display_id)\n\n        item = video.find('./items/item')\n\n        title = xpath_text(item, './title', 'title')\n        description = xpath_text(item, './synopsis', 'description')\n        thumbnail = xpath_text(item, './preview_pic', 'thumbnail')\n        duration = int_or_none(xpath_text(item, './duration', 'duration'))\n\n        subtitles = {}\n        for subtitle in item.findall('./subtitles/subtitle'):\n            lang = xpath_text(subtitle, './title')\n            subtitles[self._SUBTITLE_LANGS.get(lang, lang)] = [{\n                'ext': 'srt',\n                'url': xpath_text(subtitle, './src'),\n            }]\n\n        formats = []\n        for quality in item.findall('./qualities/quality'):\n            format_id = xpath_text(quality, './title')\n            fmt = {\n                'url': 'rtmp://wafla.walla.co.il/vod',\n                'play_path': xpath_text(quality, './src'),\n                'player_url': 'http://isc.walla.co.il/w9/swf/video_swf/vod/WallaMediaPlayerAvod.swf',\n                'page_url': url,\n                'ext': 'flv',\n                'format_id': xpath_text(quality, './title'),\n            }\n            m = re.search(r'^(?P<height>\\d+)[Pp]', format_id)\n            if m:\n                fmt['height'] = int(m.group('height'))\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 36,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006944444444444444,
            "pseudo_dstar_susp": 0.0022026431718061676,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0022026431718061676,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.abc.ABCIE._real_extract#24",
        "src_path": "youtube_dl/extractor/abc.py",
        "class_name": "youtube_dl.extractor.abc.ABCIE",
        "signature": "youtube_dl.extractor.abc.ABCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        urls_info_json = self._search_regex(\n            r'inlineVideoData\\.push\\((.*?)\\);', webpage, 'video urls',\n            flags=re.DOTALL)\n        urls_info = json.loads(urls_info_json.replace('\\'', '\"'))\n        formats = [{\n            'url': url_info['url'],\n            'width': int(url_info['width']),\n            'height': int(url_info['height']),\n            'tbr': int(url_info['bitrate']),\n            'filesize': int(url_info['filesize']),\n        } for url_info in urls_info]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 24,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010141987829614604,
            "pseudo_dstar_susp": 0.0058823529411764705,
            "pseudo_tarantula_susp": 0.0009775171065493646,
            "pseudo_op2_susp": 0.0058823529411764705,
            "pseudo_barinel_susp": 0.0009775171065493646
        }
    },
    {
        "name": "youtube_dl.extractor.eighttracks.EightTracksIE._real_extract#104",
        "src_path": "youtube_dl/extractor/eighttracks.py",
        "class_name": "youtube_dl.extractor.eighttracks.EightTracksIE",
        "signature": "youtube_dl.extractor.eighttracks.EightTracksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        data = self._parse_json(\n            self._search_regex(\n                r\"(?s)PAGE\\.mix\\s*=\\s*({.+?});\\n\", webpage, 'trax information'),\n            playlist_id)\n\n        session = str(random.randint(0, 1000000000))\n        mix_id = data['id']\n        track_count = data['tracks_count']\n        duration = data['duration']\n        avg_song_duration = float(duration) / track_count\n        # duration is sometimes negative, use predefined avg duration\n        if avg_song_duration <= 0:\n            avg_song_duration = 300\n        first_url = 'http://8tracks.com/sets/%s/play?player=sm&mix_id=%s&format=jsonh' % (session, mix_id)\n        next_url = first_url\n        entries = []\n\n        for i in range(track_count):\n            api_json = None\n            download_tries = 0\n\n            while api_json is None:\n                try:\n                    api_json = self._download_webpage(\n                        next_url, playlist_id,\n                        note='Downloading song information %d/%d' % (i + 1, track_count),\n                        errnote='Failed to download song information')\n                except ExtractorError:\n                    if download_tries > 3:\n                        raise\n                    else:\n                        download_tries += 1\n                        self._sleep(avg_song_duration, playlist_id)\n\n            api_data = json.loads(api_json)\n            track_data = api_data['set']['track']\n            info = {\n                'id': compat_str(track_data['id']),\n                'url': track_data['track_file_stream_url'],\n                'title': track_data['performer'] + ' - ' + track_data['name'],\n                'raw_title': track_data['name'],\n                'uploader_id': data['user']['login'],\n                'ext': 'm4a',\n            }\n            entries.append(info)\n\n            next_url = 'http://8tracks.com/sets/%s/next?player=sm&mix_id=%s&format=jsonh&track_id=%s' % (\n                session, mix_id, track_data['id'])\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': compat_str(mix_id),\n            'display_id': playlist_id,\n            'title': data.get('name'),\n            'description': data.get('description'),\n        }",
        "begin_line": 104,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002550369803621525,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterEmbedIE._extract_urls#153",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterEmbedIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterEmbedIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [url for _, url in re.findall(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?xhamster\\.com/xembed\\.php\\?video=\\d+)\\1',\n            webpage)]",
        "begin_line": 153,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00039635354736424893,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE._extract_url#90",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE",
        "signature": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        iframe_m = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://vplayer\\.nbcsports\\.com/[^\"]+)\"', webpage)\n        if iframe_m:\n            return iframe_m.group('url')",
        "begin_line": 90,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.report_following_redirect#876",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.report_following_redirect(self, new_url)",
        "snippet": "    def report_following_redirect(self, new_url):\n        \"\"\"Report information extraction.\"\"\"\n        self._downloader.to_screen('[redirect] Following redirect to %s' % new_url)",
        "begin_line": 876,
        "end_line": 878,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._extract_rss#880",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._extract_rss(self, url, video_id, doc)",
        "snippet": "    def _extract_rss(self, url, video_id, doc):\n        playlist_title = doc.find('./channel/title').text\n        playlist_desc_el = doc.find('./channel/description')\n        playlist_desc = None if playlist_desc_el is None else playlist_desc_el.text\n\n        entries = []\n        for it in doc.findall('./channel/item'):\n            next_url = xpath_text(it, 'link', fatal=False)\n            if not next_url:\n                enclosure_nodes = it.findall('./enclosure')\n                for e in enclosure_nodes:\n                    next_url = e.attrib.get('url')\n                    if next_url:\n                        break\n\n            if not next_url:\n                continue\n\n            entries.append({\n                '_type': 'url',\n                'url': next_url,\n                'title': it.find('title').text,\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': url,\n            'title': playlist_title,\n            'description': playlist_desc,\n            'entries': entries,\n        }",
        "begin_line": 880,
        "end_line": 910,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._extract_camtasia#912",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._extract_camtasia(self, url, video_id, webpage)",
        "snippet": "    def _extract_camtasia(self, url, video_id, webpage):\n        \"\"\" Returns None if no camtasia video can be found. \"\"\"\n\n        camtasia_cfg = self._search_regex(\n            r'fo\\.addVariable\\(\\s*\"csConfigFile\",\\s*\"([^\"]+)\"\\s*\\);',\n            webpage, 'camtasia configuration file', default=None)\n        if camtasia_cfg is None:\n            return None\n\n        title = self._html_search_meta('DC.title', webpage, fatal=True)\n\n        camtasia_url = compat_urlparse.urljoin(url, camtasia_cfg)\n        camtasia_cfg = self._download_xml(\n            camtasia_url, video_id,\n            note='Downloading camtasia configuration',\n            errnote='Failed to download camtasia configuration')\n        fileset_node = camtasia_cfg.find('./playlist/array/fileset')\n\n        entries = []\n        for n in fileset_node.getchildren():\n            url_n = n.find('./uri')\n            if url_n is None:\n                continue\n\n            entries.append({\n                'id': os.path.splitext(url_n.text.rpartition('/')[2])[0],\n                'title': '%s - %s' % (title, n.tag),\n                'url': compat_urlparse.urljoin(url, url_n.text),\n                'duration': float_or_none(n.find('./duration').text),\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'title': title,\n        }",
        "begin_line": 912,
        "end_line": 947,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._real_extract#949",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        if url.startswith('//'):\n            return {\n                '_type': 'url',\n                'url': self.http_scheme() + url,\n            }\n\n        parsed_url = compat_urlparse.urlparse(url)\n        if not parsed_url.scheme:\n            default_search = self._downloader.params.get('default_search')\n            if default_search is None:\n                default_search = 'fixup_error'\n\n            if default_search in ('auto', 'auto_warning', 'fixup_error'):\n                if '/' in url:\n                    self._downloader.report_warning('The url doesn\\'t specify the protocol, trying with http')\n                    return self.url_result('http://' + url)\n                elif default_search != 'fixup_error':\n                    if default_search == 'auto_warning':\n                        if re.match(r'^(?:url|URL)$', url):\n                            raise ExtractorError(\n                                'Invalid URL:  %r . Call youtube-dl like this:  youtube-dl -v \"https://www.youtube.com/watch?v=BaW_jenozKc\"  ' % url,\n                                expected=True)\n                        else:\n                            self._downloader.report_warning(\n                                'Falling back to youtube search for  %s . Set --default-search \"auto\" to suppress this warning.' % url)\n                    return self.url_result('ytsearch:' + url)\n\n            if default_search in ('error', 'fixup_error'):\n                raise ExtractorError(\n                    '%r is not a valid URL. '\n                    'Set --default-search \"ytsearch\" (or run  youtube-dl \"ytsearch:%s\" ) to search YouTube'\n                    % (url, url), expected=True)\n            else:\n                if ':' not in default_search:\n                    default_search += ':'\n                return self.url_result(default_search + url)\n\n        url, smuggled_data = unsmuggle_url(url)\n        force_videoid = None\n        is_intentional = smuggled_data and smuggled_data.get('to_generic')\n        if smuggled_data and 'force_videoid' in smuggled_data:\n            force_videoid = smuggled_data['force_videoid']\n            video_id = force_videoid\n        else:\n            video_id = compat_urllib_parse_unquote(os.path.splitext(url.rstrip('/').split('/')[-1])[0])\n\n        self.to_screen('%s: Requesting header' % video_id)\n\n        head_req = HEADRequest(url)\n        head_response = self._request_webpage(\n            head_req, video_id,\n            note=False, errnote='Could not send HEAD request to %s' % url,\n            fatal=False)\n\n        if head_response is not False:\n            # Check for redirect\n            new_url = head_response.geturl()\n            if url != new_url:\n                self.report_following_redirect(new_url)\n                if force_videoid:\n                    new_url = smuggle_url(\n                        new_url, {'force_videoid': force_videoid})\n                return self.url_result(new_url)\n\n        full_response = None\n        if head_response is False:\n            request = compat_urllib_request.Request(url)\n            request.add_header('Accept-Encoding', '*')\n            full_response = self._request_webpage(request, video_id)\n            head_response = full_response\n\n        # Check for direct link to a video\n        content_type = head_response.headers.get('Content-Type', '')\n        m = re.match(r'^(?P<type>audio|video|application(?=/ogg$))/(?P<format_id>.+)$', content_type)\n        if m:\n            upload_date = unified_strdate(\n                head_response.headers.get('Last-Modified'))\n            return {\n                'id': video_id,\n                'title': compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0]),\n                'direct': True,\n                'formats': [{\n                    'format_id': m.group('format_id'),\n                    'url': url,\n                    'vcodec': 'none' if m.group('type') == 'audio' else None\n                }],\n                'upload_date': upload_date,\n            }\n\n        if not self._downloader.params.get('test', False) and not is_intentional:\n            force = self._downloader.params.get('force_generic_extractor', False)\n            self._downloader.report_warning(\n                '%s on generic information extractor.' % ('Forcing' if force else 'Falling back'))\n\n        if not full_response:\n            request = compat_urllib_request.Request(url)\n            # Some webservers may serve compressed content of rather big size (e.g. gzipped flac)\n            # making it impossible to download only chunk of the file (yet we need only 512kB to\n            # test whether it's HTML or not). According to youtube-dl default Accept-Encoding\n            # that will always result in downloading the whole file that is not desirable.\n            # Therefore for extraction pass we have to override Accept-Encoding to any in order\n            # to accept raw bytes and being able to download only a chunk.\n            # It may probably better to solve this by checking Content-Type for application/octet-stream\n            # after HEAD request finishes, but not sure if we can rely on this.\n            request.add_header('Accept-Encoding', '*')\n            full_response = self._request_webpage(request, video_id)\n\n        # Maybe it's a direct link to a video?\n        # Be careful not to download the whole thing!\n        first_bytes = full_response.read(512)\n        if not is_html(first_bytes):\n            self._downloader.report_warning(\n                'URL could be a direct video link, returning it as such.')\n            upload_date = unified_strdate(\n                head_response.headers.get('Last-Modified'))\n            return {\n                'id': video_id,\n                'title': compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0]),\n                'direct': True,\n                'url': url,\n                'upload_date': upload_date,\n            }\n\n        webpage = self._webpage_read_content(\n            full_response, url, video_id, prefix=first_bytes)\n\n        self.report_extraction(video_id)\n\n        # Is it an RSS feed?\n        try:\n            doc = parse_xml(webpage)\n            if doc.tag == 'rss':\n                return self._extract_rss(url, video_id, doc)\n        except compat_xml_parse_error:\n            pass\n\n        # Is it a Camtasia project?\n        camtasia_res = self._extract_camtasia(url, video_id, webpage)\n        if camtasia_res is not None:\n            return camtasia_res\n\n        # Sometimes embedded video player is hidden behind percent encoding\n        # (e.g. https://github.com/rg3/youtube-dl/issues/2448)\n        # Unescaping the whole page allows to handle those cases in a generic way\n        webpage = compat_urllib_parse.unquote(webpage)\n\n        # it's tempting to parse this further, but you would\n        # have to take into account all the variations like\n        #   Video Title - Site Name\n        #   Site Name | Video Title\n        #   Video Title - Tagline | Site Name\n        # and so on and so forth; it's just not practical\n        video_title = self._html_search_regex(\n            r'(?s)<title>(.*?)</title>', webpage, 'video title',\n            default='video')\n\n        # Try to detect age limit automatically\n        age_limit = self._rta_search(webpage)\n        # And then there are the jokers who advertise that they use RTA,\n        # but actually don't.\n        AGE_LIMIT_MARKERS = [\n            r'Proudly Labeled <a href=\"http://www.rtalabel.org/\" title=\"Restricted to Adults\">RTA</a>',\n        ]\n        if any(re.search(marker, webpage) for marker in AGE_LIMIT_MARKERS):\n            age_limit = 18\n\n        # video uploader is domain name\n        video_uploader = self._search_regex(\n            r'^(?:https?://)?([^/]*)/.*', url, 'video uploader')\n\n        # Helper method\n        def _playlist_from_matches(matches, getter=None, ie=None):\n            urlrs = orderedSet(\n                self.url_result(self._proto_relative_url(getter(m) if getter else m), ie)\n                for m in matches)\n            return self.playlist_result(\n                urlrs, playlist_id=video_id, playlist_title=video_title)\n\n        # Look for BrightCove:\n        bc_urls = BrightcoveIE._extract_brightcove_urls(webpage)\n        if bc_urls:\n            self.to_screen('Brightcove video detected.')\n            entries = [{\n                '_type': 'url',\n                'url': smuggle_url(bc_url, {'Referer': url}),\n                'ie_key': 'Brightcove'\n            } for bc_url in bc_urls]\n\n            return {\n                '_type': 'playlist',\n                'title': video_title,\n                'id': video_id,\n                'entries': entries,\n            }\n\n        # Look for embedded rtl.nl player\n        matches = re.findall(\n            r'<iframe[^>]+?src=\"((?:https?:)?//(?:www\\.)?rtl\\.nl/system/videoplayer/[^\"]+(?:video_)?embed[^\"]+)\"',\n            webpage)\n        if matches:\n            return _playlist_from_matches(matches, ie='RtlNl')\n\n        vimeo_url = VimeoIE._extract_vimeo_url(url, webpage)\n        if vimeo_url is not None:\n            return self.url_result(vimeo_url)\n\n        # Look for embedded YouTube player\n        matches = re.findall(r'''(?x)\n            (?:\n                <iframe[^>]+?src=|\n                data-video-url=|\n                <embed[^>]+?src=|\n                embedSWF\\(?:\\s*|\n                new\\s+SWFObject\\(\n            )\n            ([\"\\'])\n                (?P<url>(?:https?:)?//(?:www\\.)?youtube(?:-nocookie)?\\.com/\n                (?:embed|v|p)/.+?)\n            \\1''', webpage)\n        if matches:\n            return _playlist_from_matches(\n                matches, lambda m: unescapeHTML(m[1]))\n\n        # Look for lazyYT YouTube embed\n        matches = re.findall(\n            r'class=\"lazyYT\" data-youtube-id=\"([^\"]+)\"', webpage)\n        if matches:\n            return _playlist_from_matches(matches, lambda m: unescapeHTML(m))\n\n        # Look for embedded Dailymotion player\n        matches = re.findall(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?dailymotion\\.com/embed/video/.+?)\\1', webpage)\n        if matches:\n            return _playlist_from_matches(\n                matches, lambda m: unescapeHTML(m[1]))\n\n        # Look for embedded Dailymotion playlist player (#3822)\n        m = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?dailymotion\\.[a-z]{2,3}/widget/jukebox\\?.+?)\\1', webpage)\n        if m:\n            playlists = re.findall(\n                r'list\\[\\]=/playlist/([^/]+)/', unescapeHTML(m.group('url')))\n            if playlists:\n                return _playlist_from_matches(\n                    playlists, lambda p: '//dailymotion.com/playlist/%s' % p)\n\n        # Look for embedded Wistia player\n        match = re.search(\n            r'<(?:meta[^>]+?content|iframe[^>]+?src)=([\"\\'])(?P<url>(?:https?:)?//(?:fast\\.)?wistia\\.net/embed/iframe/.+?)\\1', webpage)\n        if match:\n            embed_url = self._proto_relative_url(\n                unescapeHTML(match.group('url')))\n            return {\n                '_type': 'url_transparent',\n                'url': embed_url,\n                'ie_key': 'Wistia',\n                'uploader': video_uploader,\n                'title': video_title,\n                'id': video_id,\n            }\n\n        match = re.search(r'(?:id=[\"\\']wistia_|data-wistia-?id=[\"\\']|Wistia\\.embed\\([\"\\'])(?P<id>[^\"\\']+)', webpage)\n        if match:\n            return {\n                '_type': 'url_transparent',\n                'url': 'http://fast.wistia.net/embed/iframe/{0:}'.format(match.group('id')),\n                'ie_key': 'Wistia',\n                'uploader': video_uploader,\n                'title': video_title,\n                'id': match.group('id')\n            }\n\n        # Look for embedded blip.tv player\n        bliptv_url = BlipTVIE._extract_url(webpage)\n        if bliptv_url:\n            return self.url_result(bliptv_url, 'BlipTV')\n\n        # Look for SVT player\n        svt_url = SVTIE._extract_url(webpage)\n        if svt_url:\n            return self.url_result(svt_url, 'SVT')\n\n        # Look for embedded condenast player\n        matches = re.findall(\n            r'<iframe\\s+(?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?src=\"(https?://player\\.cnevids\\.com/embed/[^\"]+\")',\n            webpage)\n        if matches:\n            return {\n                '_type': 'playlist',\n                'entries': [{\n                    '_type': 'url',\n                    'ie_key': 'CondeNast',\n                    'url': ma,\n                } for ma in matches],\n                'title': video_title,\n                'id': video_id,\n            }\n\n        # Look for Bandcamp pages with custom domain\n        mobj = re.search(r'<meta property=\"og:url\"[^>]*?content=\"(.*?bandcamp\\.com.*?)\"', webpage)\n        if mobj is not None:\n            burl = unescapeHTML(mobj.group(1))\n            # Don't set the extractor because it can be a track url or an album\n            return self.url_result(burl)\n\n        # Look for embedded Vevo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:cache\\.)?vevo\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for embedded Viddler player\n        mobj = re.search(\n            r'<(?:iframe[^>]+?src|param[^>]+?value)=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?viddler\\.com/(?:embed|player)/.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for NYTimes player\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//graphics8\\.nytimes\\.com/bcvideo/[^/]+/iframe/embed\\.html.+?)\\1>',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for Libsyn player\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//html5-player\\.libsyn\\.com/embed/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for Ooyala videos\n        mobj = (re.search(r'player\\.ooyala\\.com/[^\"?]+\\?[^\"]*?(?:embedCode|ec)=(?P<ec>[^\"&]+)', webpage) or\n                re.search(r'OO\\.Player\\.create\\([\\'\"].*?[\\'\"],\\s*[\\'\"](?P<ec>.{32})[\\'\"]', webpage) or\n                re.search(r'SBN\\.VideoLinkset\\.ooyala\\([\\'\"](?P<ec>.{32})[\\'\"]\\)', webpage) or\n                re.search(r'data-ooyala-video-id\\s*=\\s*[\\'\"](?P<ec>.{32})[\\'\"]', webpage))\n        if mobj is not None:\n            return OoyalaIE._build_url_result(mobj.group('ec'))\n\n        # Look for multiple Ooyala embeds on SBN network websites\n        mobj = re.search(r'SBN\\.VideoLinkset\\.entryGroup\\((\\[.*?\\])', webpage)\n        if mobj is not None:\n            embeds = self._parse_json(mobj.group(1), video_id, fatal=False)\n            if embeds:\n                return _playlist_from_matches(\n                    embeds, getter=lambda v: OoyalaIE._url_for_embed_code(v['provider_video_id']), ie='Ooyala')\n\n        # Look for Aparat videos\n        mobj = re.search(r'<iframe .*?src=\"(http://www\\.aparat\\.com/video/[^\"]+)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group(1), 'Aparat')\n\n        # Look for MPORA videos\n        mobj = re.search(r'<iframe .*?src=\"(http://mpora\\.(?:com|de)/videos/[^\"]+)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group(1), 'Mpora')\n\n        # Look for embedded NovaMov-based player\n        mobj = re.search(\n            r'''(?x)<(?:pagespeed_)?iframe[^>]+?src=([\"\\'])\n                    (?P<url>http://(?:(?:embed|www)\\.)?\n                        (?:novamov\\.com|\n                           nowvideo\\.(?:ch|sx|eu|at|ag|co)|\n                           videoweed\\.(?:es|com)|\n                           movshare\\.(?:net|sx|ag)|\n                           divxstage\\.(?:eu|net|ch|co|at|ag))\n                        /embed\\.php.+?)\\1''', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for embedded Facebook player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https://www\\.facebook\\.com/video/embed.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Facebook')\n\n        # Look for embedded VK player\n        mobj = re.search(r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://vk\\.com/video_ext\\.php.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'VK')\n\n        # Look for embedded ivi player\n        mobj = re.search(r'<embed[^>]+?src=([\"\\'])(?P<url>https?://(?:www\\.)?ivi\\.ru/video/player.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Ivi')\n\n        # Look for embedded Huffington Post player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://embed\\.live\\.huffingtonpost\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'HuffPost')\n\n        # Look for embed.ly\n        mobj = re.search(r'class=[\"\\']embedly-card[\"\\'][^>]href=[\"\\'](?P<url>[^\"\\']+)', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n        mobj = re.search(r'class=[\"\\']embedly-embed[\"\\'][^>]src=[\"\\'][^\"\\']*url=(?P<url>[^&]+)', webpage)\n        if mobj is not None:\n            return self.url_result(compat_urllib_parse.unquote(mobj.group('url')))\n\n        # Look for funnyordie embed\n        matches = re.findall(r'<iframe[^>]+?src=\"(https?://(?:www\\.)?funnyordie\\.com/embed/[^\"]+)\"', webpage)\n        if matches:\n            return _playlist_from_matches(\n                matches, getter=unescapeHTML, ie='FunnyOrDie')\n\n        # Look for BBC iPlayer embed\n        matches = re.findall(r'setPlaylist\\(\"(https?://www\\.bbc\\.co\\.uk/iplayer/[^/]+/[\\da-z]{8})\"\\)', webpage)\n        if matches:\n            return _playlist_from_matches(matches, ie='BBCCoUk')\n\n        # Look for embedded RUTV player\n        rutv_url = RUTVIE._extract_url(webpage)\n        if rutv_url:\n            return self.url_result(rutv_url, 'RUTV')\n\n        # Look for embedded TVC player\n        tvc_url = TVCIE._extract_url(webpage)\n        if tvc_url:\n            return self.url_result(tvc_url, 'TVC')\n\n        # Look for embedded SportBox player\n        sportbox_urls = SportBoxEmbedIE._extract_urls(webpage)\n        if sportbox_urls:\n            return _playlist_from_matches(sportbox_urls, ie='SportBoxEmbed')\n\n        # Look for embedded PornHub player\n        pornhub_url = PornHubIE._extract_url(webpage)\n        if pornhub_url:\n            return self.url_result(pornhub_url, 'PornHub')\n\n        # Look for embedded XHamster player\n        xhamster_urls = XHamsterEmbedIE._extract_urls(webpage)\n        if xhamster_urls:\n            return _playlist_from_matches(xhamster_urls, ie='XHamsterEmbed')\n\n        # Look for embedded Tvigle player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//cloud\\.tvigle\\.ru/video/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Tvigle')\n\n        # Look for embedded TED player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://embed(?:-ssl)?\\.ted\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'TED')\n\n        # Look for embedded Ustream videos\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>http://www\\.ustream\\.tv/embed/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Ustream')\n\n        # Look for embedded arte.tv player\n        mobj = re.search(\n            r'<script [^>]*?src=\"(?P<url>http://www\\.arte\\.tv/playerv2/embed[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'ArteTVEmbed')\n\n        # Look for embedded smotri.com player\n        smotri_url = SmotriIE._extract_url(webpage)\n        if smotri_url:\n            return self.url_result(smotri_url, 'Smotri')\n\n        # Look for embeded soundcloud player\n        mobj = re.search(\n            r'<iframe\\s+(?:[a-zA-Z0-9_-]+=\"[^\"]+\"\\s+)*src=\"(?P<url>https?://(?:w\\.)?soundcloud\\.com/player[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            url = unescapeHTML(mobj.group('url'))\n            return self.url_result(url)\n\n        # Look for embedded vulture.com player\n        mobj = re.search(\n            r'<iframe src=\"(?P<url>https?://video\\.vulture\\.com/[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            url = unescapeHTML(mobj.group('url'))\n            return self.url_result(url, ie='Vulture')\n\n        # Look for embedded mtvservices player\n        mobj = re.search(\n            r'<iframe src=\"(?P<url>https?://media\\.mtvnservices\\.com/embed/[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            url = unescapeHTML(mobj.group('url'))\n            return self.url_result(url, ie='MTVServicesEmbedded')\n\n        # Look for embedded yahoo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://(?:screen|movies)\\.yahoo\\.com/.+?\\.html\\?format=embed)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Yahoo')\n\n        # Look for embedded sbs.com.au player\n        mobj = re.search(\n            r'''(?x)\n            (?:\n                <meta\\s+property=\"og:video\"\\s+content=|\n                <iframe[^>]+?src=\n            )\n            ([\"\\'])(?P<url>https?://(?:www\\.)?sbs\\.com\\.au/ondemand/video/.+?)\\1''',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'SBS')\n\n        # Look for embedded Cinchcast player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://player\\.cinchcast\\.com/.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Cinchcast')\n\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://m(?:lb)?\\.mlb\\.com/shared/video/embed/embed\\.html\\?.+?)\\1',\n            webpage)\n        if not mobj:\n            mobj = re.search(\n                r'data-video-link=[\"\\'](?P<url>http://m.mlb.com/video/[^\"\\']+)',\n                webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'MLB')\n\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>%s)\\1' % CondeNastIE.EMBED_URL,\n            webpage)\n        if mobj is not None:\n            return self.url_result(self._proto_relative_url(mobj.group('url'), scheme='http:'), 'CondeNast')\n\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://new\\.livestream\\.com/[^\"]+/player[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Livestream')\n\n        # Look for Zapiks embed\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://(?:www\\.)?zapiks\\.fr/index\\.php\\?.+?)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Zapiks')\n\n        # Look for Kaltura embeds\n        mobj = re.search(\n            r\"(?s)kWidget\\.(?:thumb)?[Ee]mbed\\(\\{.*?'wid'\\s*:\\s*'_?(?P<partner_id>[^']+)',.*?'entry_id'\\s*:\\s*'(?P<id>[^']+)',\", webpage)\n        if mobj is not None:\n            return self.url_result('kaltura:%(partner_id)s:%(id)s' % mobj.groupdict(), 'Kaltura')\n\n        # Look for Eagle.Platform embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://.+?\\.media\\.eagleplatform\\.com/index/player\\?.+?)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'EaglePlatform')\n\n        # Look for ClipYou (uses Eagle.Platform) embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=\"https?://(?P<host>media\\.clipyou\\.ru)/index/player\\?.*\\brecord_id=(?P<id>\\d+).*\"', webpage)\n        if mobj is not None:\n            return self.url_result('eagleplatform:%(host)s:%(id)s' % mobj.groupdict(), 'EaglePlatform')\n\n        # Look for Pladform embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://out\\.pladform\\.ru/player\\?.+?)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Pladform')\n\n        # Look for Playwire embeds\n        mobj = re.search(\n            r'<script[^>]+data-config=([\"\\'])(?P<url>(?:https?:)?//config\\.playwire\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for 5min embeds\n        mobj = re.search(\n            r'<meta[^>]+property=\"og:video\"[^>]+content=\"https?://embed\\.5min\\.com/(?P<id>[0-9]+)/?', webpage)\n        if mobj is not None:\n            return self.url_result('5min:%s' % mobj.group('id'), 'FiveMin')\n\n        # Look for Crooks and Liars embeds\n        mobj = re.search(\n            r'<(?:iframe[^>]+src|param[^>]+value)=([\"\\'])(?P<url>(?:https?:)?//embed\\.crooksandliars\\.com/(?:embed|v)/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for NBC Sports VPlayer embeds\n        nbc_sports_url = NBCSportsVPlayerIE._extract_url(webpage)\n        if nbc_sports_url:\n            return self.url_result(nbc_sports_url, 'NBCSportsVPlayer')\n\n        # Look for UDN embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>%s)\"' % UDNEmbedIE._VALID_URL, webpage)\n        if mobj is not None:\n            return self.url_result(\n                compat_urlparse.urljoin(url, mobj.group('url')), 'UDNEmbed')\n\n        # Look for Senate ISVP iframe\n        senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)\n        if senate_isvp_url:\n            return self.url_result(senate_isvp_url, 'SenateISVP')\n\n        # Look for Dailymotion Cloud videos\n        dmcloud_url = DailymotionCloudIE._extract_dmcloud_url(webpage)\n        if dmcloud_url:\n            return self.url_result(dmcloud_url, 'DailymotionCloud')\n\n        # Look for OnionStudios embeds\n        onionstudios_url = OnionStudiosIE._extract_url(webpage)\n        if onionstudios_url:\n            return self.url_result(onionstudios_url)\n\n        # Look for SnagFilms embeds\n        snagfilms_url = SnagFilmsEmbedIE._extract_url(webpage)\n        if snagfilms_url:\n            return self.url_result(snagfilms_url)\n\n        # Look for AdobeTVVideo embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=[\\'\"]((?:https?:)?//video\\.tv\\.adobe\\.com/v/\\d+[^\"]+)[\\'\"]',\n            webpage)\n        if mobj is not None:\n            return self.url_result(\n                self._proto_relative_url(unescapeHTML(mobj.group(1))),\n                'AdobeTVVideo')\n\n        def check_video(vurl):\n            if YoutubeIE.suitable(vurl):\n                return True\n            vpath = compat_urlparse.urlparse(vurl).path\n            vext = determine_ext(vpath)\n            return '.' in vpath and vext not in ('swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml')\n\n        def filter_video(urls):\n            return list(filter(check_video, urls))\n\n        # Start with something easy: JW Player in SWFObject\n        found = filter_video(re.findall(r'flashvars: [\\'\"](?:.*&)?file=(http[^\\'\"&]*)', webpage))\n        if not found:\n            # Look for gorilla-vid style embedding\n            found = filter_video(re.findall(r'''(?sx)\n                (?:\n                    jw_plugins|\n                    JWPlayerOptions|\n                    jwplayer\\s*\\(\\s*[\"'][^'\"]+[\"']\\s*\\)\\s*\\.setup\n                )\n                .*?\n                ['\"]?file['\"]?\\s*:\\s*[\"\\'](.*?)[\"\\']''', webpage))\n        if not found:\n            # Broaden the search a little bit\n            found = filter_video(re.findall(r'[^A-Za-z0-9]?(?:file|source)=(http[^\\'\"&]*)', webpage))\n        if not found:\n            # Broaden the findall a little bit: JWPlayer JS loader\n            found = filter_video(re.findall(\n                r'[^A-Za-z0-9]?file[\"\\']?:\\s*[\"\\'](http(?![^\\'\"]+\\.[0-9]+[\\'\"])[^\\'\"]+)[\"\\']', webpage))\n        if not found:\n            # Flow player\n            found = filter_video(re.findall(r'''(?xs)\n                flowplayer\\(\"[^\"]+\",\\s*\n                    \\{[^}]+?\\}\\s*,\n                    \\s*\\{[^}]+? [\"']?clip[\"']?\\s*:\\s*\\{\\s*\n                        [\"']?url[\"']?\\s*:\\s*[\"']([^\"']+)[\"']\n            ''', webpage))\n        if not found:\n            # Cinerama player\n            found = re.findall(\n                r\"cinerama\\.embedPlayer\\(\\s*\\'[^']+\\',\\s*'([^']+)'\", webpage)\n        if not found:\n            # Try to find twitter cards info\n            found = filter_video(re.findall(\n                r'<meta (?:property|name)=\"twitter:player:stream\" (?:content|value)=\"(.+?)\"', webpage))\n        if not found:\n            # We look for Open Graph info:\n            # We have to match any number spaces between elements, some sites try to align them (eg.: statigr.am)\n            m_video_type = re.findall(r'<meta.*?property=\"og:video:type\".*?content=\"video/(.*?)\"', webpage)\n            # We only look in og:video if the MIME type is a video, don't try if it's a Flash player:\n            if m_video_type is not None:\n                found = filter_video(re.findall(r'<meta.*?property=\"og:video\".*?content=\"(.*?)\"', webpage))\n        if not found:\n            # HTML5 video\n            found = re.findall(r'(?s)<video[^<]*(?:>.*?<source[^>]*)?\\s+src=[\"\\'](.*?)[\"\\']', webpage)\n        if not found:\n            REDIRECT_REGEX = r'[0-9]{,2};\\s*(?:URL|url)=\\'?([^\\'\"]+)'\n            found = re.search(\n                r'(?i)<meta\\s+(?=(?:[a-z-]+=\"[^\"]+\"\\s+)*http-equiv=\"refresh\")'\n                r'(?:[a-z-]+=\"[^\"]+\"\\s+)*?content=\"%s' % REDIRECT_REGEX,\n                webpage)\n            if not found:\n                # Look also in Refresh HTTP header\n                refresh_header = head_response.headers.get('Refresh')\n                if refresh_header:\n                    found = re.search(REDIRECT_REGEX, refresh_header)\n            if found:\n                new_url = compat_urlparse.urljoin(url, found.group(1))\n                self.report_following_redirect(new_url)\n                return {\n                    '_type': 'url',\n                    'url': new_url,\n                }\n        if not found:\n            raise UnsupportedError(url)\n\n        entries = []\n        for video_url in found:\n            video_url = compat_urlparse.urljoin(url, video_url)\n            video_id = compat_urllib_parse.unquote(os.path.basename(video_url))\n\n            # Sometimes, jwplayer extraction will result in a YouTube URL\n            if YoutubeIE.suitable(video_url):\n                entries.append(self.url_result(video_url, 'Youtube'))\n                continue\n\n            # here's a fun little line of code for you:\n            video_id = os.path.splitext(video_id)[0]\n\n            if determine_ext(video_url) == 'smil':\n                entries.append({\n                    'id': video_id,\n                    'formats': self._extract_smil_formats(video_url, video_id),\n                    'uploader': video_uploader,\n                    'title': video_title,\n                    'age_limit': age_limit,\n                })\n            else:\n                entries.append({\n                    'id': video_id,\n                    'url': video_url,\n                    'uploader': video_uploader,\n                    'title': video_title,\n                    'age_limit': age_limit,\n                })\n\n        if len(entries) == 1:\n            return entries[0]\n        else:\n            for num, e in enumerate(entries, start=1):\n                # 'url' results don't have a title\n                if e.get('title') is not None:\n                    e['title'] = '%s (%d)' % (e['title'], num)\n            return {\n                '_type': 'playlist',\n                'entries': entries,\n            }",
        "begin_line": 949,
        "end_line": 1693,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._playlist_from_matches#1121",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._playlist_from_matches(matches, getter=None, ie=None)",
        "snippet": "        def _playlist_from_matches(matches, getter=None, ie=None):\n            urlrs = orderedSet(\n                self.url_result(self._proto_relative_url(getter(m) if getter else m), ie)\n                for m in matches)\n            return self.playlist_result(\n                urlrs, playlist_id=video_id, playlist_title=video_title)",
        "begin_line": 1121,
        "end_line": 1126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.check_video#1577",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.check_video(vurl)",
        "snippet": "        def check_video(vurl):\n            if YoutubeIE.suitable(vurl):\n                return True\n            vpath = compat_urlparse.urlparse(vurl).path\n            vext = determine_ext(vpath)\n            return '.' in vpath and vext not in ('swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml')",
        "begin_line": 1577,
        "end_line": 1582,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.filter_video#1584",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.filter_video(urls)",
        "snippet": "        def filter_video(urls):\n            return list(filter(check_video, urls))",
        "begin_line": 1584,
        "end_line": 1585,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.downloader.http.HttpFD.real_download#21",
        "src_path": "youtube_dl/downloader/http.py",
        "class_name": "youtube_dl.downloader.http.HttpFD",
        "signature": "youtube_dl.downloader.http.HttpFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        tmpfilename = self.temp_name(filename)\n        stream = None\n\n        # Do not include the Accept-Encoding header\n        headers = {'Youtubedl-no-compression': 'True'}\n        add_headers = info_dict.get('http_headers')\n        if add_headers:\n            headers.update(add_headers)\n        basic_request = compat_urllib_request.Request(url, None, headers)\n        request = compat_urllib_request.Request(url, None, headers)\n\n        is_test = self.params.get('test', False)\n\n        if is_test:\n            request.add_header('Range', 'bytes=0-%s' % str(self._TEST_FILE_SIZE - 1))\n\n        # Establish possible resume length\n        if os.path.isfile(encodeFilename(tmpfilename)):\n            resume_len = os.path.getsize(encodeFilename(tmpfilename))\n        else:\n            resume_len = 0\n\n        open_mode = 'wb'\n        if resume_len != 0:\n            if self.params.get('continuedl', True):\n                self.report_resuming_byte(resume_len)\n                request.add_header('Range', 'bytes=%d-' % resume_len)\n                open_mode = 'ab'\n            else:\n                resume_len = 0\n\n        count = 0\n        retries = self.params.get('retries', 0)\n        while count <= retries:\n            # Establish connection\n            try:\n                data = self.ydl.urlopen(request)\n                break\n            except (compat_urllib_error.HTTPError, ) as err:\n                if (err.code < 500 or err.code >= 600) and err.code != 416:\n                    # Unexpected HTTP error\n                    raise\n                elif err.code == 416:\n                    # Unable to resume (requested range not satisfiable)\n                    try:\n                        # Open the connection again without the range header\n                        data = self.ydl.urlopen(basic_request)\n                        content_length = data.info()['Content-Length']\n                    except (compat_urllib_error.HTTPError, ) as err:\n                        if err.code < 500 or err.code >= 600:\n                            raise\n                    else:\n                        # Examine the reported length\n                        if (content_length is not None and\n                                (resume_len - 100 < int(content_length) < resume_len + 100)):\n                            # The file had already been fully downloaded.\n                            # Explanation to the above condition: in issue #175 it was revealed that\n                            # YouTube sometimes adds or removes a few bytes from the end of the file,\n                            # changing the file size slightly and causing problems for some users. So\n                            # I decided to implement a suggested change and consider the file\n                            # completely downloaded if the file size differs less than 100 bytes from\n                            # the one in the hard drive.\n                            self.report_file_already_downloaded(filename)\n                            self.try_rename(tmpfilename, filename)\n                            self._hook_progress({\n                                'filename': filename,\n                                'status': 'finished',\n                                'downloaded_bytes': resume_len,\n                                'total_bytes': resume_len,\n                            })\n                            return True\n                        else:\n                            # The length does not match, we start the download over\n                            self.report_unable_to_resume()\n                            resume_len = 0\n                            open_mode = 'wb'\n                            break\n            except socket.error as e:\n                if e.errno != errno.ECONNRESET:\n                    # Connection reset is no problem, just retry\n                    raise\n\n            # Retry\n            count += 1\n            if count <= retries:\n                self.report_retry(count, retries)\n\n        if count > retries:\n            self.report_error('giving up after %s retries' % retries)\n            return False\n\n        data_len = data.info().get('Content-length', None)\n\n        # Range HTTP header may be ignored/unsupported by a webserver\n        # (e.g. extractor/scivee.py, extractor/bambuser.py).\n        # However, for a test we still would like to download just a piece of a file.\n        # To achieve this we limit data_len to _TEST_FILE_SIZE and manually control\n        # block size when downloading a file.\n        if is_test and (data_len is None or int(data_len) > self._TEST_FILE_SIZE):\n            data_len = self._TEST_FILE_SIZE\n\n        if data_len is not None:\n            data_len = int(data_len) + resume_len\n            min_data_len = self.params.get(\"min_filesize\", None)\n            max_data_len = self.params.get(\"max_filesize\", None)\n            if min_data_len is not None and data_len < min_data_len:\n                self.to_screen('\\r[download] File is smaller than min-filesize (%s bytes < %s bytes). Aborting.' % (data_len, min_data_len))\n                return False\n            if max_data_len is not None and data_len > max_data_len:\n                self.to_screen('\\r[download] File is larger than max-filesize (%s bytes > %s bytes). Aborting.' % (data_len, max_data_len))\n                return False\n\n        byte_counter = 0 + resume_len\n        block_size = self.params.get('buffersize', 1024)\n        start = time.time()\n\n        # measure time over whole while-loop, so slow_down() and best_block_size() work together properly\n        now = None  # needed for slow_down() in the first loop run\n        before = start  # start measuring\n        while True:\n\n            # Download and write\n            data_block = data.read(block_size if not is_test else min(block_size, data_len - byte_counter))\n            byte_counter += len(data_block)\n\n            # exit loop when download is finished\n            if len(data_block) == 0:\n                break\n\n            # Open destination file just in time\n            if stream is None:\n                try:\n                    (stream, tmpfilename) = sanitize_open(tmpfilename, open_mode)\n                    assert stream is not None\n                    filename = self.undo_temp_name(tmpfilename)\n                    self.report_destination(filename)\n                except (OSError, IOError) as err:\n                    self.report_error('unable to open for writing: %s' % str(err))\n                    return False\n\n                if self.params.get('xattr_set_filesize', False) and data_len is not None:\n                    try:\n                        import xattr\n                        xattr.setxattr(tmpfilename, 'user.ytdl.filesize', str(data_len))\n                    except(OSError, IOError, ImportError) as err:\n                        self.report_error('unable to set filesize xattr: %s' % str(err))\n\n            try:\n                stream.write(data_block)\n            except (IOError, OSError) as err:\n                self.to_stderr('\\n')\n                self.report_error('unable to write data: %s' % str(err))\n                return False\n\n            # Apply rate limit\n            self.slow_down(start, now, byte_counter - resume_len)\n\n            # end measuring of one loop run\n            now = time.time()\n            after = now\n\n            # Adjust block size\n            if not self.params.get('noresizebuffer', False):\n                block_size = self.best_block_size(after - before, len(data_block))\n\n            before = after\n\n            # Progress message\n            speed = self.calc_speed(start, now, byte_counter - resume_len)\n            if data_len is None:\n                eta = None\n            else:\n                eta = self.calc_eta(start, time.time(), data_len - resume_len, byte_counter - resume_len)\n\n            self._hook_progress({\n                'status': 'downloading',\n                'downloaded_bytes': byte_counter,\n                'total_bytes': data_len,\n                'tmpfilename': tmpfilename,\n                'filename': filename,\n                'eta': eta,\n                'speed': speed,\n                'elapsed': now - start,\n            })\n\n            if is_test and byte_counter == data_len:\n                break\n\n        if stream is None:\n            self.to_stderr('\\n')\n            self.report_error('Did not get any data blocks')\n            return False\n        if tmpfilename != '-':\n            stream.close()\n\n        if data_len is not None and byte_counter != data_len:\n            raise ContentTooShortError(byte_counter, int(data_len))\n        self.try_rename(tmpfilename, filename)\n\n        # Update file modification time\n        if self.params.get('updatetime', True):\n            info_dict['filetime'] = self.try_utime(filename, data.info().get('last-modified', None))\n\n        self._hook_progress({\n            'downloaded_bytes': byte_counter,\n            'total_bytes': byte_counter,\n            'filename': filename,\n            'status': 'finished',\n            'elapsed': time.time() - start,\n        })\n\n        return True",
        "begin_line": 21,
        "end_line": 234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035460992907801418,
            "pseudo_dstar_susp": 0.0014124293785310734,
            "pseudo_tarantula_susp": 0.0022988505747126436,
            "pseudo_op2_susp": 0.0014124293785310734,
            "pseudo_barinel_susp": 0.0022988505747126436
        }
    },
    {
        "name": "youtube_dl.extractor.wrzuta.WrzutaIE._real_extract#42",
        "src_path": "youtube_dl/extractor/wrzuta.py",
        "class_name": "youtube_dl.extractor.wrzuta.WrzutaIE",
        "signature": "youtube_dl.extractor.wrzuta.WrzutaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        typ = mobj.group('typ')\n        uploader = mobj.group('uploader')\n\n        webpage = self._download_webpage(url, video_id)\n\n        quality = qualities(['SD', 'MQ', 'HQ', 'HD'])\n\n        audio_table = {'flv': 'mp3', 'webm': 'ogg', '???': 'mp3'}\n\n        embedpage = self._download_json('http://www.wrzuta.pl/npp/embed/%s/%s' % (uploader, video_id), video_id)\n\n        formats = []\n        for media in embedpage['url']:\n            fmt = media['type'].split('@')[0]\n            if typ == 'audio':\n                ext = audio_table.get(fmt, fmt)\n            else:\n                ext = fmt\n\n            formats.append({\n                'format_id': '%s_%s' % (ext, media['quality'].lower()),\n                'url': media['url'],\n                'ext': ext,\n                'quality': quality(media['quality']),\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'duration': int_or_none(embedpage['duration']),\n            'uploader_id': uploader,\n            'description': self._og_search_description(webpage),\n            'age_limit': embedpage.get('minimalAge', 0),\n        }",
        "begin_line": 42,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00024154589371980676,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE._real_extract#124",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract id and simplified title from URL\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n\n        video_id = mobj.group(1)\n\n        # the video may come from an external site\n        m_external = re.match('^(\\w{2})-(.*)$', video_id)\n        if m_external is not None:\n            prefix, ext_id = m_external.groups()\n            # Check if video comes from YouTube\n            if prefix == 'yt':\n                return self.url_result('http://www.youtube.com/watch?v=%s' % ext_id, 'Youtube')\n            # CBS videos use theplatform.com\n            if prefix == 'cb':\n                return self.url_result('theplatform:%s' % ext_id, 'ThePlatform')\n\n        # Retrieve video webpage to extract further information\n        req = compat_urllib_request.Request('http://www.metacafe.com/watch/%s/' % video_id)\n\n        # AnyClip videos require the flashversion cookie so that we get the link\n        # to the mp4 file\n        mobj_an = re.match(r'^an-(.*?)$', video_id)\n        if mobj_an:\n            req.headers['Cookie'] = 'flashVersion=0;'\n        webpage = self._download_webpage(req, video_id)\n\n        # Extract URL, uploader and title from webpage\n        self.report_extraction(video_id)\n        video_url = None\n        mobj = re.search(r'(?m)&mediaURL=([^&]+)', webpage)\n        if mobj is not None:\n            mediaURL = compat_urllib_parse.unquote(mobj.group(1))\n            video_ext = mediaURL[-3:]\n\n            # Extract gdaKey if available\n            mobj = re.search(r'(?m)&gdaKey=(.*?)&', webpage)\n            if mobj is None:\n                video_url = mediaURL\n            else:\n                gdaKey = mobj.group(1)\n                video_url = '%s?__gda__=%s' % (mediaURL, gdaKey)\n        if video_url is None:\n            mobj = re.search(r'<video src=\"([^\"]+)\"', webpage)\n            if mobj:\n                video_url = mobj.group(1)\n                video_ext = 'mp4'\n        if video_url is None:\n            flashvars = self._search_regex(\n                r' name=\"flashvars\" value=\"(.*?)\"', webpage, 'flashvars',\n                default=None)\n            if flashvars:\n                vardict = compat_parse_qs(flashvars)\n                if 'mediaData' not in vardict:\n                    raise ExtractorError('Unable to extract media URL')\n                mobj = re.search(\n                    r'\"mediaURL\":\"(?P<mediaURL>http.*?)\",(.*?)\"key\":\"(?P<key>.*?)\"', vardict['mediaData'][0])\n                if mobj is None:\n                    raise ExtractorError('Unable to extract media URL')\n                mediaURL = mobj.group('mediaURL').replace('\\\\/', '/')\n                video_url = '%s?__gda__=%s' % (mediaURL, mobj.group('key'))\n                video_ext = determine_ext(video_url)\n        if video_url is None:\n            player_url = self._search_regex(\n                r\"swfobject\\.embedSWF\\('([^']+)'\",\n                webpage, 'config URL', default=None)\n            if player_url:\n                config_url = self._search_regex(\n                    r'config=(.+)$', player_url, 'config URL')\n                config_doc = self._download_xml(\n                    config_url, video_id,\n                    note='Downloading video config')\n                smil_url = config_doc.find('.//properties').attrib['smil_file']\n                smil_doc = self._download_xml(\n                    smil_url, video_id,\n                    note='Downloading SMIL document')\n                base_url = smil_doc.find('./head/meta').attrib['base']\n                video_url = []\n                for vn in smil_doc.findall('.//video'):\n                    br = int(vn.attrib['system-bitrate'])\n                    play_path = vn.attrib['src']\n                    video_url.append({\n                        'format_id': 'smil-%d' % br,\n                        'url': base_url,\n                        'play_path': play_path,\n                        'page_url': url,\n                        'player_url': player_url,\n                        'ext': play_path.partition(':')[0],\n                    })\n\n        if video_url is None:\n            raise ExtractorError('Unsupported video type')\n\n        video_title = self._html_search_regex(\n            r'(?im)<title>(.*) - Video</title>', webpage, 'title')\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        video_uploader = self._html_search_regex(\n            r'submitter=(.*?);|googletag\\.pubads\\(\\)\\.setTargeting\\(\"(?:channel|submiter)\",\"([^\"]+)\"\\);',\n            webpage, 'uploader nickname', fatal=False)\n        duration = int_or_none(\n            self._html_search_meta('video:duration', webpage))\n\n        age_limit = (\n            18\n            if re.search(r'\"contentRating\":\"restricted\"', webpage)\n            else 0)\n\n        if isinstance(video_url, list):\n            formats = video_url\n        else:\n            formats = [{\n                'url': video_url,\n                'ext': video_ext,\n            }]\n\n        self._sort_formats(formats)\n        return {\n            'id': video_id,\n            'description': description,\n            'uploader': video_uploader,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'age_limit': age_limit,\n            'formats': formats,\n            'duration': duration,\n        }",
        "begin_line": 124,
        "end_line": 252,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002461841457410143,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.__init__.gen_extractors#769",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.gen_extractors()",
        "snippet": "def gen_extractors():\n    \"\"\" Return a list of an instance of every supported extractor.\n    The order does matter; the first extractor matched is the one handling the URL.\n    \"\"\"\n    return [klass() for klass in _ALL_CLASSES]",
        "begin_line": 769,
        "end_line": 773,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031746031746031746,
            "pseudo_dstar_susp": 0.0020833333333333333,
            "pseudo_tarantula_susp": 0.0017301038062283738,
            "pseudo_op2_susp": 0.0020833333333333333,
            "pseudo_barinel_susp": 0.0017301038062283738
        }
    },
    {
        "name": "youtube_dl.extractor.__init__.get_info_extractor#787",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.get_info_extractor(ie_name)",
        "snippet": "def get_info_extractor(ie_name):\n    \"\"\"Returns the info extractor class with the given ie_name\"\"\"\n    return globals()[ie_name + 'IE']",
        "begin_line": 787,
        "end_line": 789,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001201923076923077,
            "pseudo_dstar_susp": 0.005025125628140704,
            "pseudo_tarantula_susp": 0.001893939393939394,
            "pseudo_op2_susp": 0.005025125628140704,
            "pseudo_barinel_susp": 0.001893939393939394
        }
    },
    {
        "name": "youtube_dl.extractor.cloudy.CloudyIE._real_extract#99",
        "src_path": "youtube_dl/extractor/cloudy.py",
        "class_name": "youtube_dl.extractor.cloudy.CloudyIE",
        "signature": "youtube_dl.extractor.cloudy.CloudyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_host = mobj.group('host')\n        video_id = mobj.group('id')\n\n        url = self._EMBED_URL % (video_host, video_id)\n        webpage = self._download_webpage(url, video_id)\n\n        file_key = self._search_regex(\n            [r'key\\s*:\\s*\"([^\"]+)\"', r'filekey\\s*=\\s*\"([^\"]+)\"'],\n            webpage, 'file_key')\n\n        return self._extract_video(video_host, video_id, file_key)",
        "begin_line": 99,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002482005460412013,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.canalplus.CanalplusIE._real_extract#69",
        "src_path": "youtube_dl/extractor/canalplus.py",
        "class_name": "youtube_dl.extractor.canalplus.CanalplusIE",
        "signature": "youtube_dl.extractor.canalplus.CanalplusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.groupdict().get('id')\n\n        site_id = self._SITE_ID_MAP[mobj.group('site') or 'canal']\n\n        # Beware, some subclasses do not define an id group\n        display_id = url_basename(mobj.group('path'))\n\n        if video_id is None:\n            webpage = self._download_webpage(url, display_id)\n            video_id = self._search_regex(\n                r'<canal:player[^>]+?videoId=\"(\\d+)\"', webpage, 'video id')\n\n        info_url = self._VIDEO_INFO_TEMPLATE % (site_id, video_id)\n        doc = self._download_xml(info_url, video_id, 'Downloading video XML')\n\n        video_info = [video for video in doc if video.find('ID').text == video_id][0]\n        media = video_info.find('MEDIA')\n        infos = video_info.find('INFOS')\n\n        preference = qualities(['MOBILE', 'BAS_DEBIT', 'HAUT_DEBIT', 'HD', 'HLS', 'HDS'])\n\n        fmt_url = next(iter(media.find('VIDEOS'))).text\n        if '/geo' in fmt_url.lower():\n            response = self._request_webpage(\n                HEADRequest(fmt_url), video_id,\n                'Checking if the video is georestricted')\n            if '/blocage' in response.geturl():\n                raise ExtractorError(\n                    'The video is not available in your country',\n                    expected=True)\n\n        formats = []\n        for fmt in media.find('VIDEOS'):\n            format_url = fmt.text\n            if not format_url:\n                continue\n            format_id = fmt.tag\n            if format_id == 'HLS':\n                hls_formats = self._extract_m3u8_formats(format_url, video_id, 'flv')\n                for fmt in hls_formats:\n                    fmt['preference'] = preference(format_id)\n                formats.extend(hls_formats)\n            elif format_id == 'HDS':\n                hds_formats = self._extract_f4m_formats(format_url + '?hdcore=2.11.3', video_id)\n                for fmt in hds_formats:\n                    fmt['preference'] = preference(format_id)\n                formats.extend(hds_formats)\n            else:\n                formats.append({\n                    'url': format_url,\n                    'format_id': format_id,\n                    'preference': preference(format_id),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': '%s - %s' % (infos.find('TITRAGE/TITRE').text,\n                                  infos.find('TITRAGE/SOUS_TITRE').text),\n            'upload_date': unified_strdate(infos.find('PUBLICATION/DATE').text),\n            'thumbnail': media.find('IMAGES/GRAND').text,\n            'description': infos.find('DESCRIPTION').text,\n            'view_count': int(infos.find('NB_VUES').text),\n            'like_count': int(infos.find('NB_LIKES').text),\n            'comment_count': int(infos.find('NB_COMMENTS').text),\n            'formats': formats,\n        }",
        "begin_line": 69,
        "end_line": 138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002469135802469136,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.cache.Cache.__init__#16",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.__init__(self, ydl)",
        "snippet": "    def __init__(self, ydl):\n        self._ydl = ydl",
        "begin_line": 16,
        "end_line": 17,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027548209366391185,
            "pseudo_dstar_susp": 0.021739130434782608,
            "pseudo_tarantula_susp": 0.0009033423667570009,
            "pseudo_op2_susp": 0.021739130434782608,
            "pseudo_barinel_susp": 0.0009033423667570009
        }
    },
    {
        "name": "youtube_dl.cache.Cache._get_root_dir#19",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache._get_root_dir(self)",
        "snippet": "    def _get_root_dir(self):\n        res = self._ydl.params.get('cachedir')\n        if res is None:\n            cache_root = compat_getenv('XDG_CACHE_HOME', '~/.cache')\n            res = os.path.join(cache_root, 'youtube-dl')\n        return compat_expanduser(res)",
        "begin_line": 19,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.cache.Cache._get_cache_fn#26",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache._get_cache_fn(self, section, key, dtype)",
        "snippet": "    def _get_cache_fn(self, section, key, dtype):\n        assert re.match(r'^[a-zA-Z0-9_.-]+$', section), \\\n            'invalid section %r' % section\n        assert re.match(r'^[a-zA-Z0-9_.-]+$', key), 'invalid key %r' % key\n        return os.path.join(\n            self._get_root_dir(), section, '%s.%s' % (key, dtype))",
        "begin_line": 26,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.cache.Cache.enabled#34",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.enabled(self)",
        "snippet": "    def enabled(self):\n        return self._ydl.params.get('cachedir') is not False",
        "begin_line": 34,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.cache.Cache.store#37",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.store(self, section, key, data, dtype='json')",
        "snippet": "    def store(self, section, key, data, dtype='json'):\n        assert dtype in ('json',)\n\n        if not self.enabled:\n            return\n\n        fn = self._get_cache_fn(section, key, dtype)\n        try:\n            try:\n                os.makedirs(os.path.dirname(fn))\n            except OSError as ose:\n                if ose.errno != errno.EEXIST:\n                    raise\n            write_json_file(data, fn)\n        except Exception:\n            tb = traceback.format_exc()\n            self._ydl.report_warning(\n                'Writing cache to %r failed: %s' % (fn, tb))",
        "begin_line": 37,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.cache.Cache.load#56",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.load(self, section, key, dtype='json', default=None)",
        "snippet": "    def load(self, section, key, dtype='json', default=None):\n        assert dtype in ('json',)\n\n        if not self.enabled:\n            return default\n\n        cache_fn = self._get_cache_fn(section, key, dtype)\n        try:\n            try:\n                with io.open(cache_fn, 'r', encoding='utf-8') as cachef:\n                    return json.load(cachef)\n            except ValueError:\n                try:\n                    file_size = os.path.getsize(cache_fn)\n                except (OSError, IOError) as oe:\n                    file_size = str(oe)\n                self._ydl.report_warning(\n                    'Cache retrieval from %s failed (%s)' % (cache_fn, file_size))\n        except IOError:\n            pass  # No cache available\n\n        return default",
        "begin_line": 56,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.cache.Cache.remove#79",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.remove(self)",
        "snippet": "    def remove(self):\n        if not self.enabled:\n            self._ydl.to_screen('Cache is disabled (Did you combine --no-cache-dir and --rm-cache-dir?)')\n            return\n\n        cachedir = self._get_root_dir()\n        if not any((term in cachedir) for term in ('cache', 'tmp')):\n            raise Exception('Not removing directory %s - this does not look like a cache dir' % cachedir)\n\n        self._ydl.to_screen(\n            'Removing cache dir %s .' % cachedir, skip_eol=True)\n        if os.path.exists(cachedir):\n            self._ydl.to_screen('.', skip_eol=True)\n            shutil.rmtree(cachedir)\n        self._ydl.to_screen('.')",
        "begin_line": 79,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.atttechchannel.ATTTechChannelIE._real_extract#26",
        "src_path": "youtube_dl/extractor/atttechchannel.py",
        "class_name": "youtube_dl.extractor.atttechchannel.ATTTechChannelIE",
        "signature": "youtube_dl.extractor.atttechchannel.ATTTechChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._search_regex(\n            r\"url\\s*:\\s*'(rtmp://[^']+)'\",\n            webpage, 'video URL')\n\n        video_id = self._search_regex(\n            r'mediaid\\s*=\\s*(\\d+)',\n            webpage, 'video id', fatal=False)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        upload_date = unified_strdate(self._search_regex(\n            r'[Rr]elease\\s+date:\\s*(\\d{1,2}/\\d{1,2}/\\d{4})',\n            webpage, 'upload date', fatal=False), False)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'ext': 'flv',\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 26,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0012690355329949238,
            "pseudo_dstar_susp": 0.0028169014084507044,
            "pseudo_tarantula_susp": 0.0010050251256281408,
            "pseudo_op2_susp": 0.0028169014084507044,
            "pseudo_barinel_susp": 0.0010050251256281408
        }
    },
    {
        "name": "youtube_dl.extractor.ard.ARDIE._real_extract#153",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDIE",
        "signature": "youtube_dl.extractor.ard.ARDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n\n        player_url = mobj.group('mainurl') + '~playerXml.xml'\n        doc = self._download_xml(player_url, display_id)\n        video_node = doc.find('./video')\n        upload_date = unified_strdate(xpath_text(\n            video_node, './broadcastDate'))\n        thumbnail = xpath_text(video_node, './/teaserImage//variant/url')\n\n        formats = []\n        for a in video_node.findall('.//asset'):\n            f = {\n                'format_id': a.attrib['type'],\n                'width': int_or_none(a.find('./frameWidth').text),\n                'height': int_or_none(a.find('./frameHeight').text),\n                'vbr': int_or_none(a.find('./bitrateVideo').text),\n                'abr': int_or_none(a.find('./bitrateAudio').text),\n                'vcodec': a.find('./codecVideo').text,\n                'tbr': int_or_none(a.find('./totalBitrate').text),\n            }\n            if a.find('./serverPrefix').text:\n                f['url'] = a.find('./serverPrefix').text\n                f['playpath'] = a.find('./fileName').text\n            else:\n                f['url'] = a.find('./fileName').text\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': mobj.group('id'),\n            'formats': formats,\n            'display_id': display_id,\n            'title': video_node.find('./title').text,\n            'duration': parse_duration(video_node.find('./duration').text),\n            'upload_date': upload_date,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 153,
        "end_line": 191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0055248618784530384,
            "pseudo_dstar_susp": 0.002840909090909091,
            "pseudo_tarantula_susp": 0.00145985401459854,
            "pseudo_op2_susp": 0.002840909090909091,
            "pseudo_barinel_susp": 0.00145985401459854
        }
    },
    {
        "name": "youtube_dl.downloader.rtmp.rtmpdump_version#18",
        "src_path": "youtube_dl/downloader/rtmp.py",
        "class_name": "youtube_dl.downloader.rtmp",
        "signature": "youtube_dl.downloader.rtmp.rtmpdump_version()",
        "snippet": "def rtmpdump_version():\n    return get_exe_version(\n        'rtmpdump', ['--help'], r'(?i)RTMPDump\\s*v?([0-9a-zA-Z._-]+)')",
        "begin_line": 18,
        "end_line": 20,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.__init__.main#404",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__.main(argv=None)",
        "snippet": "def main(argv=None):\n    try:\n        _real_main(argv)\n    except DownloadError:\n        sys.exit(1)\n    except SameFileError:\n        sys.exit('ERROR: fixed output name but more than one file to download')\n    except KeyboardInterrupt:\n        sys.exit('\\nERROR: Interrupted by user')",
        "begin_line": 404,
        "end_line": 412,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00039635354736424893,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.compat._testfunc#308",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat._testfunc(x)",
        "snippet": "    def _testfunc(x):\n        pass",
        "begin_line": 308,
        "end_line": 309,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.appletrailers.AppleTrailersIE._real_extract#73",
        "src_path": "youtube_dl/extractor/appletrailers.py",
        "class_name": "youtube_dl.extractor.appletrailers.AppleTrailersIE",
        "signature": "youtube_dl.extractor.appletrailers.AppleTrailersIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        movie = mobj.group('movie')\n        uploader_id = mobj.group('company')\n\n        playlist_url = compat_urlparse.urljoin(url, 'includes/playlists/itunes.inc')\n\n        def fix_html(s):\n            s = re.sub(r'(?s)<script[^<]*?>.*?</script>', '', s)\n            s = re.sub(r'<img ([^<]*?)>', r'<img \\1/>', s)\n            # The ' in the onClick attributes are not escaped, it couldn't be parsed\n            # like: http://trailers.apple.com/trailers/wb/gravity/\n\n            def _clean_json(m):\n                return 'iTunes.playURL(%s);' % m.group(1).replace('\\'', '&#39;')\n            s = re.sub(self._JSON_RE, _clean_json, s)\n            s = '<html>%s</html>' % s\n            return s\n        doc = self._download_xml(playlist_url, movie, transform_source=fix_html)\n\n        playlist = []\n        for li in doc.findall('./div/ul/li'):\n            on_click = li.find('.//a').attrib['onClick']\n            trailer_info_json = self._search_regex(self._JSON_RE,\n                                                   on_click, 'trailer info')\n            trailer_info = json.loads(trailer_info_json)\n            title = trailer_info['title']\n            video_id = movie + '-' + re.sub(r'[^a-zA-Z0-9]', '', title).lower()\n            thumbnail = li.find('.//img').attrib['src']\n            upload_date = trailer_info['posted'].replace('-', '')\n\n            runtime = trailer_info['runtime']\n            m = re.search(r'(?P<minutes>[0-9]+):(?P<seconds>[0-9]{1,2})', runtime)\n            duration = None\n            if m:\n                duration = 60 * int(m.group('minutes')) + int(m.group('seconds'))\n\n            first_url = trailer_info['url']\n            trailer_id = first_url.split('/')[-1].rpartition('_')[0].lower()\n            settings_json_url = compat_urlparse.urljoin(url, 'includes/settings/%s.json' % trailer_id)\n            settings = self._download_json(settings_json_url, trailer_id, 'Downloading settings json')\n\n            formats = []\n            for format in settings['metadata']['sizes']:\n                # The src is a file pointing to the real video file\n                format_url = re.sub(r'_(\\d*p.mov)', r'_h\\1', format['src'])\n                formats.append({\n                    'url': format_url,\n                    'format': format['type'],\n                    'width': int_or_none(format['width']),\n                    'height': int_or_none(format['height']),\n                })\n\n            self._sort_formats(formats)\n\n            playlist.append({\n                '_type': 'video',\n                'id': video_id,\n                'formats': formats,\n                'title': title,\n                'duration': duration,\n                'thumbnail': thumbnail,\n                'upload_date': upload_date,\n                'uploader_id': uploader_id,\n                'http_headers': {\n                    'User-Agent': 'QuickTime compatible (youtube-dl)',\n                },\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': movie,\n            'entries': playlist,\n        }",
        "begin_line": 73,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.000250501002004008,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.svt.SVTIE._extract_url#68",
        "src_path": "youtube_dl/extractor/svt.py",
        "class_name": "youtube_dl.extractor.svt.SVTIE",
        "signature": "youtube_dl.extractor.svt.SVTIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'(?:<iframe src|href)=\"(?P<url>%s[^\"]*)\"' % SVTIE._VALID_URL, webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 68,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.ku6.Ku6IE._real_extract#18",
        "src_path": "youtube_dl/extractor/ku6.py",
        "class_name": "youtube_dl.extractor.ku6.Ku6IE",
        "signature": "youtube_dl.extractor.ku6.Ku6IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h1 title=.*>(.*?)</h1>', webpage, 'title')\n        dataUrl = 'http://v.ku6.com/fetchVideo4Player/%s.html' % video_id\n        jsonData = self._download_json(dataUrl, video_id)\n        downloadUrl = jsonData['data']['f']\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': downloadUrl\n        }",
        "begin_line": 18,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._set_language#47",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._set_language(self)",
        "snippet": "    def _set_language(self):\n        self._set_cookie(\n            '.youtube.com', 'PREF', 'f1=50000000&hl=en',\n            # YouTube sets the expire time to about two months\n            expire_time=time.time() + 2 * 30 * 24 * 3600)",
        "begin_line": 47,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.014084507042253521,
            "pseudo_dstar_susp": 0.0032679738562091504,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0032679738562091504,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._login#58",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._login(self)",
        "snippet": "    def _login(self):\n        \"\"\"\n        Attempt to log in to YouTube.\n        True is returned if successful or skipped.\n        False is returned if login failed.\n\n        If _LOGIN_REQUIRED is set and no authentication was provided, an error is raised.\n        \"\"\"\n        (username, password) = self._get_login_info()\n        # No authentication to be performed\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return True\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None,\n            note='Downloading login page',\n            errnote='unable to fetch login page', fatal=False)\n        if login_page is False:\n            return\n\n        galx = self._search_regex(r'(?s)<input.+?name=\"GALX\".+?value=\"(.+?)\"',\n                                  login_page, 'Login GALX parameter')\n\n        # Log in\n        login_form_strs = {\n            'continue': 'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',\n            'Email': username,\n            'GALX': galx,\n            'Passwd': password,\n\n            'PersistentCookie': 'yes',\n            '_utf8': '\u9731',\n            'bgresponse': 'js_disabled',\n            'checkConnection': '',\n            'checkedDomains': 'youtube',\n            'dnConn': '',\n            'pstMsg': '0',\n            'rmShown': '1',\n            'secTok': '',\n            'signIn': 'Sign in',\n            'timeStmp': '',\n            'service': 'youtube',\n            'uilel': '3',\n            'hl': 'en_US',\n        }\n\n        # Convert to UTF-8 *before* urlencode because Python 2.x's urlencode\n        # chokes on unicode\n        login_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k, v in login_form_strs.items())\n        login_data = compat_urllib_parse.urlencode(login_form).encode('ascii')\n\n        req = compat_urllib_request.Request(self._LOGIN_URL, login_data)\n        login_results = self._download_webpage(\n            req, None,\n            note='Logging in', errnote='unable to log in', fatal=False)\n        if login_results is False:\n            return False\n\n        if re.search(r'id=\"errormsg_0_Passwd\"', login_results) is not None:\n            raise ExtractorError('Please use your account password and a two-factor code instead of an application-specific password.', expected=True)\n\n        # Two-Factor\n        # TODO add SMS and phone call support - these require making a request and then prompting the user\n\n        if re.search(r'(?i)<form[^>]* id=\"gaia_secondfactorform\"', login_results) is not None:\n            tfa_code = self._get_tfa_info()\n\n            if tfa_code is None:\n                self._downloader.report_warning('Two-factor authentication required. Provide it with --twofactor <code>')\n                self._downloader.report_warning('(Note that only TOTP (Google Authenticator App) codes work at this time.)')\n                return False\n\n            # Unlike the first login form, secTok and timeStmp are both required for the TFA form\n\n            match = re.search(r'id=\"secTok\"\\n\\s+value=\\'(.+)\\'/>', login_results, re.M | re.U)\n            if match is None:\n                self._downloader.report_warning('Failed to get secTok - did the page structure change?')\n            secTok = match.group(1)\n            match = re.search(r'id=\"timeStmp\"\\n\\s+value=\\'(.+)\\'/>', login_results, re.M | re.U)\n            if match is None:\n                self._downloader.report_warning('Failed to get timeStmp - did the page structure change?')\n            timeStmp = match.group(1)\n\n            tfa_form_strs = {\n                'continue': 'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',\n                'smsToken': '',\n                'smsUserPin': tfa_code,\n                'smsVerifyPin': 'Verify',\n\n                'PersistentCookie': 'yes',\n                'checkConnection': '',\n                'checkedDomains': 'youtube',\n                'pstMsg': '1',\n                'secTok': secTok,\n                'timeStmp': timeStmp,\n                'service': 'youtube',\n                'hl': 'en_US',\n            }\n            tfa_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k, v in tfa_form_strs.items())\n            tfa_data = compat_urllib_parse.urlencode(tfa_form).encode('ascii')\n\n            tfa_req = compat_urllib_request.Request(self._TWOFACTOR_URL, tfa_data)\n            tfa_results = self._download_webpage(\n                tfa_req, None,\n                note='Submitting TFA code', errnote='unable to submit tfa', fatal=False)\n\n            if tfa_results is False:\n                return False\n\n            if re.search(r'(?i)<form[^>]* id=\"gaia_secondfactorform\"', tfa_results) is not None:\n                self._downloader.report_warning('Two-factor code expired. Please try again, or use a one-use backup code instead.')\n                return False\n            if re.search(r'(?i)<form[^>]* id=\"gaia_loginform\"', tfa_results) is not None:\n                self._downloader.report_warning('unable to log in - did the page structure change?')\n                return False\n            if re.search(r'smsauth-interstitial-reviewsettings', tfa_results) is not None:\n                self._downloader.report_warning('Your Google account has a security notice. Please log in on your web browser, resolve the notice, and try again.')\n                return False\n\n        if re.search(r'(?i)<form[^>]* id=\"gaia_loginform\"', login_results) is not None:\n            self._downloader.report_warning('unable to log in: bad username or password')\n            return False\n        return True",
        "begin_line": 58,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02040816326530612,
            "pseudo_dstar_susp": 0.0035971223021582736,
            "pseudo_tarantula_susp": 0.00273224043715847,
            "pseudo_op2_susp": 0.0035971223021582736,
            "pseudo_barinel_susp": 0.00273224043715847
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._real_initialize#184",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        if self._downloader is None:\n            return\n        self._set_language()\n        if not self._login():\n            return",
        "begin_line": 184,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0196078431372549,
            "pseudo_dstar_susp": 0.0035460992907801418,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0035460992907801418,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.__init__#524",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        super(YoutubeIE, self).__init__(*args, **kwargs)\n        self._player_cache = {}",
        "begin_line": 524,
        "end_line": 526,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006329113924050633,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.002070393374741201,
            "pseudo_op2_susp": 0.006329113924050633,
            "pseudo_barinel_susp": 0.002070393374741201
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.extract_id#759",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.extract_id(cls, url)",
        "snippet": "    def extract_id(cls, url):\n        mobj = re.match(cls._VALID_URL, url, re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        video_id = mobj.group(2)\n        return video_id",
        "begin_line": 759,
        "end_line": 764,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004016064257028112,
            "pseudo_dstar_susp": 0.0029498525073746312,
            "pseudo_tarantula_susp": 0.0012547051442910915,
            "pseudo_op2_susp": 0.0029498525073746312,
            "pseudo_barinel_susp": 0.0012547051442910915
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._real_extract#835",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        proto = (\n            'http' if self._downloader.params.get('prefer_insecure', False)\n            else 'https')\n\n        # Extract original video URL from URL with redirection, like age verification, using next_url parameter\n        mobj = re.search(self._NEXT_URL_RE, url)\n        if mobj:\n            url = proto + '://www.youtube.com/' + compat_urllib_parse.unquote(mobj.group(1)).lstrip('/')\n        video_id = self.extract_id(url)\n\n        # Get video webpage\n        url = proto + '://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1&bpctr=9999999999' % video_id\n        video_webpage = self._download_webpage(url, video_id)\n\n        # Attempt to extract SWF player URL\n        mobj = re.search(r'swfConfig.*?\"(https?:\\\\/\\\\/.*?watch.*?-.*?\\.swf)\"', video_webpage)\n        if mobj is not None:\n            player_url = re.sub(r'\\\\(.)', r'\\1', mobj.group(1))\n        else:\n            player_url = None\n\n        # Get video info\n        embed_webpage = None\n        if re.search(r'player-age-gate-content\">', video_webpage) is not None:\n            age_gate = True\n            # We simulate the access to the video from www.youtube.com/v/{video_id}\n            # this can be viewed without login into Youtube\n            url = proto + '://www.youtube.com/embed/%s' % video_id\n            embed_webpage = self._download_webpage(url, video_id, 'Downloading embed webpage')\n            data = compat_urllib_parse.urlencode({\n                'video_id': video_id,\n                'eurl': 'https://youtube.googleapis.com/v/' + video_id,\n                'sts': self._search_regex(\n                    r'\"sts\"\\s*:\\s*(\\d+)', embed_webpage, 'sts', default=''),\n            })\n            video_info_url = proto + '://www.youtube.com/get_video_info?' + data\n            video_info_webpage = self._download_webpage(\n                video_info_url, video_id,\n                note='Refetching age-gated info webpage',\n                errnote='unable to download video info webpage')\n            video_info = compat_parse_qs(video_info_webpage)\n        else:\n            age_gate = False\n            try:\n                # Try looking directly into the video webpage\n                mobj = re.search(r';ytplayer\\.config\\s*=\\s*({.*?});', video_webpage)\n                if not mobj:\n                    raise ValueError('Could not find ytplayer.config')  # caught below\n                json_code = uppercase_escape(mobj.group(1))\n                ytplayer_config = json.loads(json_code)\n                args = ytplayer_config['args']\n                # Convert to the same format returned by compat_parse_qs\n                video_info = dict((k, [v]) for k, v in args.items())\n                if not args.get('url_encoded_fmt_stream_map'):\n                    raise ValueError('No stream_map present')  # caught below\n            except ValueError:\n                # We fallback to the get_video_info pages (used by the embed page)\n                self.report_video_info_webpage_download(video_id)\n                for el_type in ['&el=embedded', '&el=detailpage', '&el=vevo', '']:\n                    video_info_url = (\n                        '%s://www.youtube.com/get_video_info?&video_id=%s%s&ps=default&eurl=&gl=US&hl=en'\n                        % (proto, video_id, el_type))\n                    video_info_webpage = self._download_webpage(\n                        video_info_url,\n                        video_id, note=False,\n                        errnote='unable to download video info webpage')\n                    video_info = compat_parse_qs(video_info_webpage)\n                    if 'token' in video_info:\n                        break\n        if 'token' not in video_info:\n            if 'reason' in video_info:\n                if 'The uploader has not made this video available in your country.' in video_info['reason']:\n                    regions_allowed = self._html_search_meta('regionsAllowed', video_webpage, default=None)\n                    if regions_allowed is not None:\n                        raise ExtractorError('YouTube said: This video is available in %s only' % (\n                            ', '.join(map(ISO3166Utils.short2full, regions_allowed.split(',')))),\n                            expected=True)\n                raise ExtractorError(\n                    'YouTube said: %s' % video_info['reason'][0],\n                    expected=True, video_id=video_id)\n            else:\n                raise ExtractorError(\n                    '\"token\" parameter not in video info for unknown reason',\n                    video_id=video_id)\n\n        if 'view_count' in video_info:\n            view_count = int(video_info['view_count'][0])\n        else:\n            view_count = None\n\n        # Check for \"rental\" videos\n        if 'ypc_video_rental_bar_text' in video_info and 'author' not in video_info:\n            raise ExtractorError('\"rental\" videos not supported')\n\n        # Start extracting information\n        self.report_information_extraction(video_id)\n\n        # uploader\n        if 'author' not in video_info:\n            raise ExtractorError('Unable to extract uploader name')\n        video_uploader = compat_urllib_parse.unquote_plus(video_info['author'][0])\n\n        # uploader_id\n        video_uploader_id = None\n        mobj = re.search(r'<link itemprop=\"url\" href=\"http://www.youtube.com/(?:user|channel)/([^\"]+)\">', video_webpage)\n        if mobj is not None:\n            video_uploader_id = mobj.group(1)\n        else:\n            self._downloader.report_warning('unable to extract uploader nickname')\n\n        # title\n        if 'title' in video_info:\n            video_title = video_info['title'][0]\n        else:\n            self._downloader.report_warning('Unable to extract video title')\n            video_title = '_'\n\n        # thumbnail image\n        # We try first to get a high quality image:\n        m_thumb = re.search(r'<span itemprop=\"thumbnail\".*?href=\"(.*?)\">',\n                            video_webpage, re.DOTALL)\n        if m_thumb is not None:\n            video_thumbnail = m_thumb.group(1)\n        elif 'thumbnail_url' not in video_info:\n            self._downloader.report_warning('unable to extract video thumbnail')\n            video_thumbnail = None\n        else:   # don't panic if we can't find it\n            video_thumbnail = compat_urllib_parse.unquote_plus(video_info['thumbnail_url'][0])\n\n        # upload date\n        upload_date = None\n        mobj = re.search(r'(?s)id=\"eow-date.*?>(.*?)</span>', video_webpage)\n        if mobj is None:\n            mobj = re.search(\n                r'(?s)id=\"watch-uploader-info\".*?>.*?(?:Published|Uploaded|Streamed live) on (.*?)</strong>',\n                video_webpage)\n        if mobj is not None:\n            upload_date = ' '.join(re.sub(r'[/,-]', r' ', mobj.group(1)).split())\n            upload_date = unified_strdate(upload_date)\n\n        m_cat_container = self._search_regex(\n            r'(?s)<h4[^>]*>\\s*Category\\s*</h4>\\s*<ul[^>]*>(.*?)</ul>',\n            video_webpage, 'categories', default=None)\n        if m_cat_container:\n            category = self._html_search_regex(\n                r'(?s)<a[^<]+>(.*?)</a>', m_cat_container, 'category',\n                default=None)\n            video_categories = None if category is None else [category]\n        else:\n            video_categories = None\n\n        # description\n        video_description = get_element_by_id(\"eow-description\", video_webpage)\n        if video_description:\n            video_description = re.sub(r'''(?x)\n                <a\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?\n                    title=\"([^\"]+)\"\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?\n                    class=\"yt-uix-redirect-link\"\\s*>\n                [^<]+\n                </a>\n            ''', r'\\1', video_description)\n            video_description = clean_html(video_description)\n        else:\n            fd_mobj = re.search(r'<meta name=\"description\" content=\"([^\"]+)\"', video_webpage)\n            if fd_mobj:\n                video_description = unescapeHTML(fd_mobj.group(1))\n            else:\n                video_description = ''\n\n        def _extract_count(count_name):\n            count = self._search_regex(\n                r'id=\"watch-%s\"[^>]*>.*?([\\d,]+)\\s*</span>' % re.escape(count_name),\n                video_webpage, count_name, default=None)\n            if count is not None:\n                return int(count.replace(',', ''))\n            return None\n        like_count = _extract_count('like')\n        dislike_count = _extract_count('dislike')\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, video_webpage)\n        automatic_captions = self.extract_automatic_captions(video_id, video_webpage)\n\n        if 'length_seconds' not in video_info:\n            self._downloader.report_warning('unable to extract video duration')\n            video_duration = None\n        else:\n            video_duration = int(compat_urllib_parse.unquote_plus(video_info['length_seconds'][0]))\n\n        # annotations\n        video_annotations = None\n        if self._downloader.params.get('writeannotations', False):\n            video_annotations = self._extract_annotations(video_id)\n\n        def _map_to_format_list(urlmap):\n            formats = []\n            for itag, video_real_url in urlmap.items():\n                dct = {\n                    'format_id': itag,\n                    'url': video_real_url,\n                    'player_url': player_url,\n                }\n                if itag in self._formats:\n                    dct.update(self._formats[itag])\n                formats.append(dct)\n            return formats\n\n        if 'conn' in video_info and video_info['conn'][0].startswith('rtmp'):\n            self.report_rtmp_download()\n            formats = [{\n                'format_id': '_rtmp',\n                'protocol': 'rtmp',\n                'url': video_info['conn'][0],\n                'player_url': player_url,\n            }]\n        elif len(video_info.get('url_encoded_fmt_stream_map', [''])[0]) >= 1 or len(video_info.get('adaptive_fmts', [''])[0]) >= 1:\n            encoded_url_map = video_info.get('url_encoded_fmt_stream_map', [''])[0] + ',' + video_info.get('adaptive_fmts', [''])[0]\n            if 'rtmpe%3Dyes' in encoded_url_map:\n                raise ExtractorError('rtmpe downloads are not supported, see https://github.com/rg3/youtube-dl/issues/343 for more information.', expected=True)\n            url_map = {}\n            for url_data_str in encoded_url_map.split(','):\n                url_data = compat_parse_qs(url_data_str)\n                if 'itag' not in url_data or 'url' not in url_data:\n                    continue\n                format_id = url_data['itag'][0]\n                url = url_data['url'][0]\n\n                if 'sig' in url_data:\n                    url += '&signature=' + url_data['sig'][0]\n                elif 's' in url_data:\n                    encrypted_sig = url_data['s'][0]\n                    ASSETS_RE = r'\"assets\":.+?\"js\":\\s*(\"[^\"]+\")'\n\n                    jsplayer_url_json = self._search_regex(\n                        ASSETS_RE,\n                        embed_webpage if age_gate else video_webpage,\n                        'JS player URL (1)', default=None)\n                    if not jsplayer_url_json and not age_gate:\n                        # We need the embed website after all\n                        if embed_webpage is None:\n                            embed_url = proto + '://www.youtube.com/embed/%s' % video_id\n                            embed_webpage = self._download_webpage(\n                                embed_url, video_id, 'Downloading embed webpage')\n                        jsplayer_url_json = self._search_regex(\n                            ASSETS_RE, embed_webpage, 'JS player URL')\n\n                    player_url = json.loads(jsplayer_url_json)\n                    if player_url is None:\n                        player_url_json = self._search_regex(\n                            r'ytplayer\\.config.*?\"url\"\\s*:\\s*(\"[^\"]+\")',\n                            video_webpage, 'age gate player URL')\n                        player_url = json.loads(player_url_json)\n\n                    if self._downloader.params.get('verbose'):\n                        if player_url is None:\n                            player_version = 'unknown'\n                            player_desc = 'unknown'\n                        else:\n                            if player_url.endswith('swf'):\n                                player_version = self._search_regex(\n                                    r'-(.+?)(?:/watch_as3)?\\.swf$', player_url,\n                                    'flash player', fatal=False)\n                                player_desc = 'flash player %s' % player_version\n                            else:\n                                player_version = self._search_regex(\n                                    r'html5player-([^/]+?)(?:/html5player)?\\.js',\n                                    player_url,\n                                    'html5 player', fatal=False)\n                                player_desc = 'html5 player %s' % player_version\n\n                        parts_sizes = self._signature_cache_id(encrypted_sig)\n                        self.to_screen('{%s} signature length %s, %s' %\n                                       (format_id, parts_sizes, player_desc))\n\n                    signature = self._decrypt_signature(\n                        encrypted_sig, video_id, player_url, age_gate)\n                    url += '&signature=' + signature\n                if 'ratebypass' not in url:\n                    url += '&ratebypass=yes'\n                url_map[format_id] = url\n            formats = _map_to_format_list(url_map)\n        elif video_info.get('hlsvp'):\n            manifest_url = video_info['hlsvp'][0]\n            url_map = self._extract_from_m3u8(manifest_url, video_id)\n            formats = _map_to_format_list(url_map)\n        else:\n            raise ExtractorError('no conn, hlsvp or url_encoded_fmt_stream_map information found in video info')\n\n        # Look for the DASH manifest\n        if self._downloader.params.get('youtube_include_dash_manifest', True):\n            dash_mpd = video_info.get('dashmpd')\n            if dash_mpd:\n                dash_manifest_url = dash_mpd[0]\n                try:\n                    dash_formats = self._parse_dash_manifest(\n                        video_id, dash_manifest_url, player_url, age_gate)\n                except (ExtractorError, KeyError) as e:\n                    self.report_warning(\n                        'Skipping DASH manifest: %r' % e, video_id)\n                else:\n                    # Remove the formats we found through non-DASH, they\n                    # contain less info and it can be wrong, because we use\n                    # fixed values (for example the resolution). See\n                    # https://github.com/rg3/youtube-dl/issues/5774 for an\n                    # example.\n                    dash_keys = set(df['format_id'] for df in dash_formats)\n                    formats = [f for f in formats if f['format_id'] not in dash_keys]\n                    formats.extend(dash_formats)\n\n        # Check for malformed aspect ratio\n        stretched_m = re.search(\n            r'<meta\\s+property=\"og:video:tag\".*?content=\"yt:stretch=(?P<w>[0-9]+):(?P<h>[0-9]+)\">',\n            video_webpage)\n        if stretched_m:\n            ratio = float(stretched_m.group('w')) / float(stretched_m.group('h'))\n            for f in formats:\n                if f.get('vcodec') != 'none':\n                    f['stretched_ratio'] = ratio\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'uploader_id': video_uploader_id,\n            'upload_date': upload_date,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'categories': video_categories,\n            'subtitles': video_subtitles,\n            'automatic_captions': automatic_captions,\n            'duration': video_duration,\n            'age_limit': 18 if age_gate else 0,\n            'annotations': video_annotations,\n            'webpage_url': proto + '://www.youtube.com/watch?v=%s' % video_id,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'average_rating': float_or_none(video_info.get('avg_rating', [None])[0]),\n            'formats': formats,\n        }",
        "begin_line": 835,
        "end_line": 1179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.014084507042253521,
            "pseudo_dstar_susp": 0.0032679738562091504,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0032679738562091504,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_initialize#1276",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 1276,
        "end_line": 1277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008605851979345956,
            "pseudo_dstar_susp": 0.001184834123222749,
            "pseudo_tarantula_susp": 0.0012254901960784314,
            "pseudo_op2_susp": 0.001184834123222749,
            "pseudo_barinel_susp": 0.0012285012285012285
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_mix#1279",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_mix(self, playlist_id)",
        "snippet": "    def _extract_mix(self, playlist_id):\n        # The mixes are generated from a single video\n        # the id of the playlist is just 'RD' + video_id\n        url = 'https://youtube.com/watch?v=%s&list=%s' % (playlist_id[-11:], playlist_id)\n        webpage = self._download_webpage(\n            url, playlist_id, 'Downloading Youtube mix')\n        search_title = lambda class_name: get_element_by_attribute('class', class_name, webpage)\n        title_span = (\n            search_title('playlist-title') or\n            search_title('title long-title') or\n            search_title('title'))\n        title = clean_html(title_span)\n        ids = orderedSet(re.findall(\n            r'''(?xs)data-video-username=\".*?\".*?\n                       href=\"/watch\\?v=([0-9A-Za-z_-]{11})&amp;[^\"]*?list=%s''' % re.escape(playlist_id),\n            webpage))\n        url_results = self._ids_to_results(ids)\n\n        return self.playlist_result(url_results, playlist_id, title)",
        "begin_line": 1279,
        "end_line": 1297,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_playlist#1299",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_playlist(self, playlist_id)",
        "snippet": "    def _extract_playlist(self, playlist_id):\n        url = self._TEMPLATE_URL % playlist_id\n        page = self._download_webpage(url, playlist_id)\n\n        for match in re.findall(r'<div class=\"yt-alert-message\">([^<]+)</div>', page):\n            match = match.strip()\n            # Check if the playlist exists or is private\n            if re.match(r'[^<]*(The|This) playlist (does not exist|is private)[^<]*', match):\n                raise ExtractorError(\n                    'The playlist doesn\\'t exist or is private, use --username or '\n                    '--netrc to access it.',\n                    expected=True)\n            elif re.match(r'[^<]*Invalid parameters[^<]*', match):\n                raise ExtractorError(\n                    'Invalid parameters. Maybe URL is incorrect.',\n                    expected=True)\n            elif re.match(r'[^<]*Choose your language[^<]*', match):\n                continue\n            else:\n                self.report_warning('Youtube gives an alert message: ' + match)\n\n        # Extract the video ids from the playlist pages\n        def _entries():\n            more_widget_html = content_html = page\n            for page_num in itertools.count(1):\n                matches = re.finditer(self._VIDEO_RE, content_html)\n                # We remove the duplicates and the link with index 0\n                # (it's not the first video of the playlist)\n                new_ids = orderedSet(m.group('id') for m in matches if m.group('index') != '0')\n                for vid_id in new_ids:\n                    yield self.url_result(vid_id, 'Youtube', video_id=vid_id)\n\n                mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n                if not mobj:\n                    break\n\n                more = self._download_json(\n                    'https://youtube.com/%s' % mobj.group('more'), playlist_id,\n                    'Downloading page #%s' % page_num,\n                    transform_source=uppercase_escape)\n                content_html = more['content_html']\n                if not content_html.strip():\n                    # Some webpages show a \"Load more\" button but they don't\n                    # have more videos\n                    break\n                more_widget_html = more['load_more_widget_html']\n\n        playlist_title = self._html_search_regex(\n            r'(?s)<h1 class=\"pl-header-title[^\"]*\">\\s*(.*?)\\s*</h1>',\n            page, 'title')\n\n        return self.playlist_result(_entries(), playlist_id, playlist_title)",
        "begin_line": 1299,
        "end_line": 1350,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_extract#1352",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract playlist id\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        playlist_id = mobj.group(1) or mobj.group(2)\n\n        # Check if it's a video-specific URL\n        query_dict = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        if 'v' in query_dict:\n            video_id = query_dict['v'][0]\n            if self._downloader.params.get('noplaylist'):\n                self.to_screen('Downloading just video %s because of --no-playlist' % video_id)\n                return self.url_result(video_id, 'Youtube', video_id=video_id)\n            else:\n                self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))\n\n        if playlist_id.startswith('RD') or playlist_id.startswith('UL'):\n            # Mixes require a custom extraction process\n            return self._extract_mix(playlist_id)\n\n        return self._extract_playlist(playlist_id)",
        "begin_line": 1352,
        "end_line": 1373,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeChannelIE._real_extract#1406",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeChannelIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        url = self._TEMPLATE_URL % channel_id\n\n        # Channel by page listing is restricted to 35 pages of 30 items, i.e. 1050 videos total (see #5778)\n        # Workaround by extracting as a playlist if managed to obtain channel playlist URL\n        # otherwise fallback on channel by page extraction\n        channel_page = self._download_webpage(\n            url + '?view=57', channel_id,\n            'Downloading channel page', fatal=False)\n        channel_playlist_id = self._html_search_meta(\n            'channelId', channel_page, 'channel id', default=None)\n        if not channel_playlist_id:\n            channel_playlist_id = self._search_regex(\n                r'data-channel-external-id=\"([^\"]+)\"',\n                channel_page, 'channel id', default=None)\n        if channel_playlist_id and channel_playlist_id.startswith('UC'):\n            playlist_id = 'UU' + channel_playlist_id[2:]\n            return self.url_result(\n                compat_urlparse.urljoin(url, '/playlist?list=%s' % playlist_id), 'YoutubePlaylist')\n\n        channel_page = self._download_webpage(url, channel_id, 'Downloading page #1')\n        autogenerated = re.search(r'''(?x)\n                class=\"[^\"]*?(?:\n                    channel-header-autogenerated-label|\n                    yt-channel-title-autogenerated\n                )[^\"]*\"''', channel_page) is not None\n\n        if autogenerated:\n            # The videos are contained in a single page\n            # the ajax pages can't be used, they are empty\n            entries = [\n                self.url_result(\n                    video_id, 'Youtube', video_id=video_id,\n                    video_title=video_title)\n                for video_id, video_title in self.extract_videos_from_page(channel_page)]\n            return self.playlist_result(entries, channel_id)\n\n        def _entries():\n            more_widget_html = content_html = channel_page\n            for pagenum in itertools.count(1):\n\n                for video_id, video_title in self.extract_videos_from_page(content_html):\n                    yield self.url_result(\n                        video_id, 'Youtube', video_id=video_id,\n                        video_title=video_title)\n\n                mobj = re.search(\n                    r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"',\n                    more_widget_html)\n                if not mobj:\n                    break\n\n                more = self._download_json(\n                    'https://youtube.com/%s' % mobj.group('more'), channel_id,\n                    'Downloading page #%s' % (pagenum + 1),\n                    transform_source=uppercase_escape)\n                content_html = more['content_html']\n                more_widget_html = more['load_more_widget_html']\n\n        return self.playlist_result(_entries(), channel_id)",
        "begin_line": 1406,
        "end_line": 1467,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeUserIE.suitable#1488",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeUserIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeUserIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        # Don't return True if the url can be extracted with other youtube\n        # extractor, the regex would is too permissive and it would match.\n        other_ies = iter(klass for (name, klass) in globals().items() if name.endswith('IE') and klass is not cls)\n        if any(ie.suitable(url) for ie in other_ies):\n            return False\n        else:\n            return super(YoutubeUserIE, cls).suitable(url)",
        "begin_line": 1488,
        "end_line": 1495,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSearchURLIE._real_extract#1562",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSearchURLIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSearchURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        query = compat_urllib_parse.unquote_plus(mobj.group('query'))\n\n        webpage = self._download_webpage(url, query)\n        result_code = self._search_regex(\n            r'(?s)<ol[^>]+class=\"item-section\"(.*?)</ol>', webpage, 'result HTML')\n\n        part_codes = re.findall(\n            r'(?s)<h3 class=\"yt-lockup-title\">(.*?)</h3>', result_code)\n        entries = []\n        for part_code in part_codes:\n            part_title = self._html_search_regex(\n                [r'(?s)title=\"([^\"]+)\"', r'>([^<]+)</a>'], part_code, 'item title', fatal=False)\n            part_url_snippet = self._html_search_regex(\n                r'(?s)href=\"([^\"]+)\"', part_code, 'item URL')\n            part_url = compat_urlparse.urljoin(\n                'https://www.youtube.com/', part_url_snippet)\n            entries.append({\n                '_type': 'url',\n                'url': part_url,\n                'title': part_title,\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'title': query,\n        }",
        "begin_line": 1562,
        "end_line": 1590,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeShowIE._real_extract#1606",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeShowIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        webpage = self._download_webpage(\n            url, playlist_id, 'Downloading show webpage')\n        # There's one playlist for each season of the show\n        m_seasons = list(re.finditer(r'href=\"(/playlist\\?list=.*?)\"', webpage))\n        self.to_screen('%s: Found %s seasons' % (playlist_id, len(m_seasons)))\n        entries = [\n            self.url_result(\n                'https://www.youtube.com' + season.group(1), 'YoutubePlaylist')\n            for season in m_seasons\n        ]\n        title = self._og_search_title(webpage, fatal=False)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 1606,
        "end_line": 1626,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor.IE_NAME#1637",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor.IE_NAME(self)",
        "snippet": "    def IE_NAME(self):\n        return 'youtube:%s' % self._FEED_NAME",
        "begin_line": 1637,
        "end_line": 1638,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00039635354736424893,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_initialize#1640",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 1640,
        "end_line": 1641,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_extract#1643",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page = self._download_webpage(\n            'https://www.youtube.com/feed/%s' % self._FEED_NAME, self._PLAYLIST_TITLE)\n\n        # The extraction process is the same as for playlists, but the regex\n        # for the video ids doesn't contain an index\n        ids = []\n        more_widget_html = content_html = page\n        for page_num in itertools.count(1):\n            matches = re.findall(r'href=\"\\s*/watch\\?v=([0-9A-Za-z_-]{11})', content_html)\n\n            # 'recommended' feed has infinite 'load more' and each new portion spins\n            # the same videos in (sometimes) slightly different order, so we'll check\n            # for unicity and break when portion has no new videos\n            new_ids = filter(lambda video_id: video_id not in ids, orderedSet(matches))\n            if not new_ids:\n                break\n\n            ids.extend(new_ids)\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), self._PLAYLIST_TITLE,\n                'Downloading page #%s' % page_num,\n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            more_widget_html = more['load_more_widget_html']\n\n        return self.playlist_result(\n            self._ids_to_results(ids), playlist_title=self._PLAYLIST_TITLE)",
        "begin_line": 1643,
        "end_line": 1675,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeWatchLaterIE._real_extract#1685",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeWatchLaterIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeWatchLaterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_playlist('WL')",
        "begin_line": 1685,
        "end_line": 1686,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFavouritesIE._real_extract#1695",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFavouritesIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeFavouritesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage('https://www.youtube.com/my_favorites', 'Youtube Favourites videos')\n        playlist_id = self._search_regex(r'list=(.+?)[\"&]', webpage, 'favourites playlist id')\n        return self.url_result(playlist_id, 'YoutubePlaylist')",
        "begin_line": 1695,
        "end_line": 1698,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE._real_extract#1757",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        raise ExtractorError(\n            'Did you forget to quote the URL? Remember that & is a meta '\n            'character in most shells, so you want to put the URL in quotes, '\n            'like  youtube-dl '\n            '\"http://www.youtube.com/watch?feature=foo&v=BaW_jenozKc\" '\n            ' or simply  youtube-dl BaW_jenozKc  .',\n            expected=True)",
        "begin_line": 1757,
        "end_line": 1764,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeTruncatedIDIE._real_extract#1777",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeTruncatedIDIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeTruncatedIDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        raise ExtractorError(\n            'Incomplete YouTube ID %s. URL %s looks truncated.' % (video_id, url),\n            expected=True)",
        "begin_line": 1777,
        "end_line": 1781,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._build_request#25",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._build_request(url)",
        "snippet": "    def _build_request(url):\n        \"\"\"Build a request with the family filter disabled\"\"\"\n        request = compat_urllib_request.Request(url)\n        request.add_header('Cookie', 'family_filter=off; ff=off')\n        return request",
        "begin_line": 25,
        "end_line": 29,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006944444444444444,
            "pseudo_dstar_susp": 0.0022026431718061676,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0022026431718061676,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._real_extract#87",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        url = 'https://www.dailymotion.com/video/%s' % video_id\n\n        # Retrieve video webpage to extract further information\n        request = self._build_request(url)\n        webpage = self._download_webpage(request, video_id)\n\n        # Extract URL, uploader and title from webpage\n        self.report_extraction(video_id)\n\n        # It may just embed a vevo video:\n        m_vevo = re.search(\n            r'<link rel=\"video_src\" href=\"[^\"]*?vevo.com[^\"]*?video=(?P<id>[\\w]*)',\n            webpage)\n        if m_vevo is not None:\n            vevo_id = m_vevo.group('id')\n            self.to_screen('Vevo video detected: %s' % vevo_id)\n            return self.url_result('vevo:%s' % vevo_id, ie='Vevo')\n\n        age_limit = self._rta_search(webpage)\n\n        video_upload_date = None\n        mobj = re.search(r'<meta property=\"video:release_date\" content=\"([0-9]{4})-([0-9]{2})-([0-9]{2}).+?\"/>', webpage)\n        if mobj is not None:\n            video_upload_date = mobj.group(1) + mobj.group(2) + mobj.group(3)\n\n        embed_url = 'https://www.dailymotion.com/embed/video/%s' % video_id\n        embed_request = self._build_request(embed_url)\n        embed_page = self._download_webpage(\n            embed_request, video_id, 'Downloading embed page')\n        info = self._search_regex(r'var info = ({.*?}),$', embed_page,\n                                  'video info', flags=re.MULTILINE)\n        info = json.loads(info)\n        if info.get('error') is not None:\n            msg = 'Couldn\\'t get video, Dailymotion says: %s' % info['error']['title']\n            raise ExtractorError(msg, expected=True)\n\n        formats = []\n        for (key, format_id) in self._FORMATS:\n            video_url = info.get(key)\n            if video_url is not None:\n                m_size = re.search(r'H264-(\\d+)x(\\d+)', video_url)\n                if m_size is not None:\n                    width, height = map(int_or_none, (m_size.group(1), m_size.group(2)))\n                else:\n                    width, height = None, None\n                formats.append({\n                    'url': video_url,\n                    'ext': 'mp4',\n                    'format_id': format_id,\n                    'width': width,\n                    'height': height,\n                })\n        if not formats:\n            raise ExtractorError('Unable to extract video URL')\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, webpage)\n\n        view_count = str_to_int(self._search_regex(\n            r'video_views_count[^>]+>\\s+([\\d\\.,]+)',\n            webpage, 'view count', fatal=False))\n\n        title = self._og_search_title(webpage, default=None)\n        if title is None:\n            title = self._html_search_regex(\n                r'(?s)<span\\s+id=\"video_title\"[^>]*>(.*?)</span>', webpage,\n                'title')\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'uploader': info['owner.screenname'],\n            'upload_date': video_upload_date,\n            'title': title,\n            'subtitles': video_subtitles,\n            'thumbnail': info['thumbnail_url'],\n            'age_limit': age_limit,\n            'view_count': view_count,\n        }",
        "begin_line": 87,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008547008547008548,
            "pseudo_dstar_susp": 0.0024752475247524753,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0024752475247524753,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._real_extract#213",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        webpage = self._download_webpage(url, playlist_id)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': self._og_search_title(webpage),\n            'entries': self._extract_entries(playlist_id),\n        }",
        "begin_line": 213,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025297242600556537,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionUserIE._real_extract#239",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionUserIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        webpage = self._download_webpage(\n            'https://www.dailymotion.com/user/%s' % user, user)\n        full_user = unescapeHTML(self._html_search_regex(\n            r'<a class=\"nav-image\" title=\"([^\"]+)\" href=\"/%s\">' % re.escape(user),\n            webpage, 'user'))\n\n        return {\n            '_type': 'playlist',\n            'id': user,\n            'title': full_user,\n            'entries': self._extract_entries(user),\n        }",
        "begin_line": 239,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00026014568158168577,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionCloudIE._extract_dmcloud_url#267",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionCloudIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionCloudIE._extract_dmcloud_url(self, webpage)",
        "snippet": "    def _extract_dmcloud_url(self, webpage):\n        mobj = re.search(r'<iframe[^>]+src=[\\'\"](http://api\\.dmcloud\\.net/embed/[^/]+/[^\\'\"]+)[\\'\"]', webpage)\n        if mobj:\n            return mobj.group(1)\n\n        mobj = re.search(r'<input[^>]+id=[\\'\"]dmcloudUrlEmissionSelect[\\'\"][^>]+value=[\\'\"](http://api\\.dmcloud\\.net/embed/[^/]+/[^\\'\"]+)[\\'\"]', webpage)\n        if mobj:\n            return mobj.group(1)",
        "begin_line": 267,
        "end_line": 274,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._login#33",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor",
        "signature": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return\n        self.report_login()\n        login_url = 'https://vimeo.com/log_in'\n        webpage = self._download_webpage(login_url, None, False)\n        token = self._search_regex(r'xsrft\":\"(.*?)\"', webpage, 'login token')\n        data = urlencode_postdata({\n            'email': username,\n            'password': password,\n            'action': 'login',\n            'service': 'vimeo',\n            'token': token,\n        })\n        login_request = compat_urllib_request.Request(login_url, data)\n        login_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        login_request.add_header('Cookie', 'xsrft=%s' % token)\n        self._download_webpage(login_request, None, False, 'Wrong login info')",
        "begin_line": 33,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.010101010101010102,
            "pseudo_dstar_susp": 0.002777777777777778,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.002777777777777778,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._extract_vimeo_url#178",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._extract_vimeo_url(url, webpage)",
        "snippet": "    def _extract_vimeo_url(url, webpage):\n        # Look for embedded (iframe) Vimeo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//player\\.vimeo\\.com/video/.+?)\\1', webpage)\n        if mobj:\n            player_url = unescapeHTML(mobj.group('url'))\n            surl = smuggle_url(player_url, {'Referer': url})\n            return surl\n        # Look for embedded (swf embed) Vimeo player\n        mobj = re.search(\n            r'<embed[^>]+?src=\"((?:https?:)?//(?:www\\.)?vimeo\\.com/moogaloop\\.swf.+?)\"', webpage)\n        if mobj:\n            return mobj.group(1)",
        "begin_line": 178,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._real_initialize#224",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 224,
        "end_line": 225,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006944444444444444,
            "pseudo_dstar_susp": 0.0022026431718061676,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0022026431718061676,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._real_extract#227",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, data = unsmuggle_url(url)\n        headers = std_headers\n        if data is not None:\n            headers = headers.copy()\n            headers.update(data)\n        if 'Referer' not in headers:\n            headers['Referer'] = url\n\n        # Extract ID from URL\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        orig_url = url\n        if mobj.group('pro') or mobj.group('player'):\n            url = 'https://player.vimeo.com/video/' + video_id\n        else:\n            url = 'https://vimeo.com/' + video_id\n\n        # Retrieve video webpage to extract further information\n        request = compat_urllib_request.Request(url, None, headers)\n        try:\n            webpage = self._download_webpage(request, video_id)\n        except ExtractorError as ee:\n            if isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 403:\n                errmsg = ee.cause.read()\n                if b'Because of its privacy settings, this video cannot be played here' in errmsg:\n                    raise ExtractorError(\n                        'Cannot download embed-only video without embedding '\n                        'URL. Please call youtube-dl with the URL of the page '\n                        'that embeds this video.',\n                        expected=True)\n            raise\n\n        # Now we begin extracting as much information as we can from what we\n        # retrieved. First we extract the information common to all extractors,\n        # and latter we extract those that are Vimeo specific.\n        self.report_extraction(video_id)\n\n        vimeo_config = self._search_regex(\n            r'vimeo\\.config\\s*=\\s*({.+?});', webpage,\n            'vimeo config', default=None)\n        if vimeo_config:\n            seed_status = self._parse_json(vimeo_config, video_id).get('seed_status', {})\n            if seed_status.get('state') == 'failed':\n                raise ExtractorError(\n                    '%s returned error: %s' % (self.IE_NAME, seed_status['title']),\n                    expected=True)\n\n        # Extract the config JSON\n        try:\n            try:\n                config_url = self._html_search_regex(\n                    r' data-config-url=\"(.+?)\"', webpage, 'config URL')\n                config_json = self._download_webpage(config_url, video_id)\n                config = json.loads(config_json)\n            except RegexNotFoundError:\n                # For pro videos or player.vimeo.com urls\n                # We try to find out to which variable is assigned the config dic\n                m_variable_name = re.search('(\\w)\\.video\\.id', webpage)\n                if m_variable_name is not None:\n                    config_re = r'%s=({[^}].+?});' % re.escape(m_variable_name.group(1))\n                else:\n                    config_re = [r' = {config:({.+?}),assets:', r'(?:[abc])=({.+?});']\n                config = self._search_regex(config_re, webpage, 'info section',\n                                            flags=re.DOTALL)\n                config = json.loads(config)\n        except Exception as e:\n            if re.search('The creator of this video has not given you permission to embed it on this domain.', webpage):\n                raise ExtractorError('The author has restricted the access to this video, try with the \"--referer\" option')\n\n            if re.search(r'<form[^>]+?id=\"pw_form\"', webpage) is not None:\n                if data and '_video_password_verified' in data:\n                    raise ExtractorError('video password verification failed!')\n                self._verify_video_password(url, video_id, webpage)\n                return self._real_extract(\n                    smuggle_url(url, {'_video_password_verified': 'verified'}))\n            else:\n                raise ExtractorError('Unable to extract info section',\n                                     cause=e)\n        else:\n            if config.get('view') == 4:\n                config = self._verify_player_video_password(url, video_id)\n\n        # Extract title\n        video_title = config[\"video\"][\"title\"]\n\n        # Extract uploader and uploader_id\n        video_uploader = config[\"video\"][\"owner\"][\"name\"]\n        video_uploader_id = config[\"video\"][\"owner\"][\"url\"].split('/')[-1] if config[\"video\"][\"owner\"][\"url\"] else None\n\n        # Extract video thumbnail\n        video_thumbnail = config[\"video\"].get(\"thumbnail\")\n        if video_thumbnail is None:\n            video_thumbs = config[\"video\"].get(\"thumbs\")\n            if video_thumbs and isinstance(video_thumbs, dict):\n                _, video_thumbnail = sorted((int(width if width.isdigit() else 0), t_url) for (width, t_url) in video_thumbs.items())[-1]\n\n        # Extract video description\n\n        video_description = self._html_search_regex(\n            r'(?s)<div\\s+class=\"[^\"]*description[^\"]*\"[^>]*>(.*?)</div>',\n            webpage, 'description', default=None)\n        if not video_description:\n            video_description = self._html_search_meta(\n                'description', webpage, default=None)\n        if not video_description and mobj.group('pro'):\n            orig_webpage = self._download_webpage(\n                orig_url, video_id,\n                note='Downloading webpage for description',\n                fatal=False)\n            if orig_webpage:\n                video_description = self._html_search_meta(\n                    'description', orig_webpage, default=None)\n        if not video_description and not mobj.group('player'):\n            self._downloader.report_warning('Cannot find video description')\n\n        # Extract video duration\n        video_duration = int_or_none(config[\"video\"].get(\"duration\"))\n\n        # Extract upload date\n        video_upload_date = None\n        mobj = re.search(r'<time[^>]+datetime=\"([^\"]+)\"', webpage)\n        if mobj is not None:\n            video_upload_date = unified_strdate(mobj.group(1))\n\n        try:\n            view_count = int(self._search_regex(r'UserPlays:(\\d+)', webpage, 'view count'))\n            like_count = int(self._search_regex(r'UserLikes:(\\d+)', webpage, 'like count'))\n            comment_count = int(self._search_regex(r'UserComments:(\\d+)', webpage, 'comment count'))\n        except RegexNotFoundError:\n            # This info is only available in vimeo.com/{id} urls\n            view_count = None\n            like_count = None\n            comment_count = None\n\n        # Vimeo specific: extract request signature and timestamp\n        sig = config['request']['signature']\n        timestamp = config['request']['timestamp']\n\n        # Vimeo specific: extract video codec and quality information\n        # First consider quality, then codecs, then take everything\n        codecs = [('vp6', 'flv'), ('vp8', 'flv'), ('h264', 'mp4')]\n        files = {'hd': [], 'sd': [], 'other': []}\n        config_files = config[\"video\"].get(\"files\") or config[\"request\"].get(\"files\")\n        for codec_name, codec_extension in codecs:\n            for quality in config_files.get(codec_name, []):\n                format_id = '-'.join((codec_name, quality)).lower()\n                key = quality if quality in files else 'other'\n                video_url = None\n                if isinstance(config_files[codec_name], dict):\n                    file_info = config_files[codec_name][quality]\n                    video_url = file_info.get('url')\n                else:\n                    file_info = {}\n                if video_url is None:\n                    video_url = \"http://player.vimeo.com/play_redirect?clip_id=%s&sig=%s&time=%s&quality=%s&codecs=%s&type=moogaloop_local&embed_location=\" \\\n                        % (video_id, sig, timestamp, quality, codec_name.upper())\n\n                files[key].append({\n                    'ext': codec_extension,\n                    'url': video_url,\n                    'format_id': format_id,\n                    'width': file_info.get('width'),\n                    'height': file_info.get('height'),\n                })\n        formats = []\n        for key in ('other', 'sd', 'hd'):\n            formats += files[key]\n        if len(formats) == 0:\n            raise ExtractorError('No known codec found')\n\n        subtitles = {}\n        text_tracks = config['request'].get('text_tracks')\n        if text_tracks:\n            for tt in text_tracks:\n                subtitles[tt['lang']] = [{\n                    'ext': 'vtt',\n                    'url': 'https://vimeo.com' + tt['url'],\n                }]\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'uploader_id': video_uploader_id,\n            'upload_date': video_upload_date,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'duration': video_duration,\n            'formats': formats,\n            'webpage_url': url,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'subtitles': subtitles,\n        }",
        "begin_line": 227,
        "end_line": 422,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006944444444444444,
            "pseudo_dstar_susp": 0.0022026431718061676,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0022026431718061676,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._page_url#439",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        return '%s/videos/page:%d/' % (base_url, pagenum)",
        "begin_line": 439,
        "end_line": 440,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_videos#475",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_videos(self, list_id, base_url)",
        "snippet": "    def _extract_videos(self, list_id, base_url):\n        video_ids = []\n        for pagenum in itertools.count(1):\n            page_url = self._page_url(base_url, pagenum)\n            webpage = self._download_webpage(\n                page_url, list_id,\n                'Downloading page %s' % pagenum)\n\n            if pagenum == 1:\n                webpage = self._login_list_password(page_url, list_id, webpage)\n\n            video_ids.extend(re.findall(r'id=\"clip_(\\d+?)\"', webpage))\n            if re.search(self._MORE_PAGES_INDICATOR, webpage, re.DOTALL) is None:\n                break\n\n        entries = [self.url_result('https://vimeo.com/%s' % video_id, 'Vimeo')\n                   for video_id in video_ids]\n        return {'_type': 'playlist',\n                'id': list_id,\n                'title': self._extract_list_title(webpage),\n                'entries': entries,\n                }",
        "begin_line": 475,
        "end_line": 496,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002572678157962439,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoUserIE._real_extract#517",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoUserIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        return self._extract_videos(name, 'https://vimeo.com/%s' % name)",
        "begin_line": 517,
        "end_line": 520,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoGroupsIE._real_extract#570",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoGroupsIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoGroupsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        return self._extract_videos(name, 'https://vimeo.com/groups/%s' % name)",
        "begin_line": 570,
        "end_line": 573,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00042426813746287653,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_extract#603",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoReviewIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        player_url = 'https://player.vimeo.com/player/' + video_id\n        return self.url_result(player_url, 'Vimeo', video_id)",
        "begin_line": 603,
        "end_line": 607,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0002658160552897395,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoLikesIE._real_extract#650",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoLikesIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoLikesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        user_id = self._match_id(url)\n        webpage = self._download_webpage(url, user_id)\n        page_count = self._int(\n            self._search_regex(\n                r'''(?x)<li><a\\s+href=\"[^\"]+\"\\s+data-page=\"([0-9]+)\">\n                    .*?</a></li>\\s*<li\\s+class=\"pagination_next\">\n                ''', webpage, 'page count'),\n            'page count', fatal=True)\n        PAGE_SIZE = 12\n        title = self._html_search_regex(\n            r'(?s)<h1>(.+?)</h1>', webpage, 'title', fatal=False)\n        description = self._html_search_meta('description', webpage)\n\n        def _get_page(idx):\n            page_url = 'https://vimeo.com/user%s/likes/page:%d/sort:date' % (\n                user_id, idx + 1)\n            webpage = self._download_webpage(\n                page_url, user_id,\n                note='Downloading page %d/%d' % (idx + 1, page_count))\n            video_list = self._search_regex(\n                r'(?s)<ol class=\"js-browse_list[^\"]+\"[^>]*>(.*?)</ol>',\n                webpage, 'video content')\n            paths = re.findall(\n                r'<li[^>]*>\\s*<a\\s+href=\"([^\"]+)\"', video_list)\n            for path in paths:\n                yield {\n                    '_type': 'url',\n                    'url': compat_urlparse.urljoin(page_url, path),\n                }\n\n        pl = InAdvancePagedList(_get_page, page_count, PAGE_SIZE)\n\n        return {\n            '_type': 'playlist',\n            'id': 'user%s_likes' % user_id,\n            'title': title,\n            'description': description,\n            'entries': pl,\n        }",
        "begin_line": 650,
        "end_line": 689,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPOIE._real_extract#89",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOIE",
        "signature": "youtube_dl.extractor.npo.NPOIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self._get_info(video_id)",
        "begin_line": 89,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004878048780487805,
            "pseudo_dstar_susp": 0.0015151515151515152,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.0015151515151515152,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPOIE._get_info#93",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOIE",
        "signature": "youtube_dl.extractor.npo.NPOIE._get_info(self, video_id)",
        "snippet": "    def _get_info(self, video_id):\n        metadata = self._download_json(\n            'http://e.omroep.nl/metadata/aflevering/%s' % video_id,\n            video_id,\n            # We have to remove the javascript callback\n            transform_source=strip_jsonp,\n        )\n\n        token = self._get_token(video_id)\n\n        formats = []\n\n        pubopties = metadata.get('pubopties')\n        if pubopties:\n            quality = qualities(['adaptive', 'wmv_sb', 'h264_sb', 'wmv_bb', 'h264_bb', 'wvc1_std', 'h264_std'])\n            for format_id in pubopties:\n                format_info = self._download_json(\n                    'http://ida.omroep.nl/odi/?prid=%s&puboptions=%s&adaptive=yes&token=%s'\n                    % (video_id, format_id, token),\n                    video_id, 'Downloading %s JSON' % format_id)\n                if format_info.get('error_code', 0) or format_info.get('errorcode', 0):\n                    continue\n                streams = format_info.get('streams')\n                if streams:\n                    video_info = self._download_json(\n                        streams[0] + '&type=json',\n                        video_id, 'Downloading %s stream JSON' % format_id)\n                else:\n                    video_info = format_info\n                video_url = video_info.get('url')\n                if not video_url:\n                    continue\n                if format_id == 'adaptive':\n                    formats.extend(self._extract_m3u8_formats(video_url, video_id))\n                else:\n                    formats.append({\n                        'url': video_url,\n                        'format_id': format_id,\n                        'quality': quality(format_id),\n                    })\n\n        streams = metadata.get('streams')\n        if streams:\n            for i, stream in enumerate(streams):\n                stream_url = stream.get('url')\n                if not stream_url:\n                    continue\n                if '.asf' not in stream_url:\n                    formats.append({\n                        'url': stream_url,\n                        'quality': stream.get('kwaliteit'),\n                    })\n                    continue\n                asx = self._download_xml(\n                    stream_url, video_id,\n                    'Downloading stream %d ASX playlist' % i,\n                    transform_source=fix_xml_ampersands)\n                ref = asx.find('./ENTRY/Ref')\n                if ref is None:\n                    continue\n                video_url = ref.get('href')\n                if not video_url:\n                    continue\n                formats.append({\n                    'url': video_url,\n                    'ext': stream.get('formaat', 'asf'),\n                    'quality': stream.get('kwaliteit'),\n                })\n\n        self._sort_formats(formats)\n\n        subtitles = {}\n        if metadata.get('tt888') == 'ja':\n            subtitles['nl'] = [{\n                'ext': 'vtt',\n                'url': 'http://e.omroep.nl/tt888/%s' % video_id,\n            }]\n\n        return {\n            'id': video_id,\n            'title': metadata['titel'],\n            'description': metadata['info'],\n            'thumbnail': metadata.get('images', [{'url': None}])[-1]['url'],\n            'upload_date': unified_strdate(metadata.get('gidsdatum')),\n            'duration': parse_duration(metadata.get('tijdsduur')),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 93,
        "end_line": 180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001851851851851852,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.005649717514124294,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.005649717514124294
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPORadioFragmentIE._real_extract#324",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPORadioFragmentIE",
        "signature": "youtube_dl.extractor.npo.NPORadioFragmentIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        audio_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, audio_id)\n\n        title = self._html_search_regex(\n            r'href=\"/radio/[^/]+/fragment/%s\" title=\"([^\"]+)\"' % audio_id,\n            webpage, 'title')\n\n        audio_url = self._search_regex(\n            r\"data-streams='([^']+)'\", webpage, 'audio url')\n\n        return {\n            'id': audio_id,\n            'url': audio_url,\n            'title': title,\n        }",
        "begin_line": 324,
        "end_line": 340,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.npo.TegenlichtVproIE._real_extract#361",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.TegenlichtVproIE",
        "signature": "youtube_dl.extractor.npo.TegenlichtVproIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        name = url_basename(url)\n        webpage = self._download_webpage(url, name)\n        urn = self._html_search_meta('mediaurn', webpage)\n        info_page = self._download_json(\n            'http://rs.vpro.nl/v2/api/media/%s.json' % urn, name)\n        return self._get_info(info_page['mid'])",
        "begin_line": 361,
        "end_line": 367,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.snagfilms.SnagFilmsEmbedIE._extract_url#32",
        "src_path": "youtube_dl/extractor/snagfilms.py",
        "class_name": "youtube_dl.extractor.snagfilms.SnagFilmsEmbedIE",
        "signature": "youtube_dl.extractor.snagfilms.SnagFilmsEmbedIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:embed\\.)?snagfilms\\.com/embed/player.+?)\\1',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 32,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._extract_url#145",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<embed[^>]src=([\"\\'])(?P<url>http://pics\\.smotri\\.com/(?:player|scrubber_custom8)\\.swf\\?file=v.+?\\1)',\n            webpage)\n        if mobj is not None:\n            return mobj.group('url')\n\n        mobj = re.search(\n            r'''(?x)<div\\s+class=\"video_file\">http://smotri\\.com/video/download/file/[^<]+</div>\\s*\n                    <div\\s+class=\"video_image\">[^<]+</div>\\s*\n                    <div\\s+class=\"video_id\">(?P<id>[^<]+)</div>''', webpage)\n        if mobj is not None:\n            return 'http://smotri.com/video/view/?id=%s' % mobj.group('id')",
        "begin_line": 145,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._real_extract#164",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_form = {\n            'ticket': video_id,\n            'video_url': '1',\n            'frame_url': '1',\n            'devid': 'LoadupFlashPlayer',\n            'getvideoinfo': '1',\n        }\n\n        video_password = self._downloader.params.get('videopassword', None)\n        if video_password:\n            video_form['pass'] = hashlib.md5(video_password.encode('utf-8')).hexdigest()\n\n        request = compat_urllib_request.Request(\n            'http://smotri.com/video/view/url/bot/', compat_urllib_parse.urlencode(video_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n\n        video = self._download_json(request, video_id, 'Downloading video JSON')\n\n        video_url = video.get('_vidURL') or video.get('_vidURL_mp4')\n\n        if not video_url:\n            if video.get('_moderate_no'):\n                raise ExtractorError(\n                    'Video %s has not been approved by moderator' % video_id, expected=True)\n\n            if video.get('error'):\n                raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n            if video.get('_pass_protected') == 1:\n                msg = ('Invalid video password' if video_password\n                       else 'This video is protected by a password, use the --video-password option')\n                raise ExtractorError(msg, expected=True)\n\n        title = video['title']\n        thumbnail = video['_imgURL']\n        upload_date = unified_strdate(video['added'])\n        uploader = video['userNick']\n        uploader_id = video['userLogin']\n        duration = int_or_none(video['duration'])\n\n        # Video JSON does not provide enough meta data\n        # We will extract some from the video web page instead\n        webpage_url = 'http://smotri.com/video/view/?id=%s' % video_id\n        webpage = self._download_webpage(webpage_url, video_id, 'Downloading video page')\n\n        # Warning if video is unavailable\n        warning = self._html_search_regex(\n            r'<div class=\"videoUnModer\">(.*?)</div>', webpage,\n            'warning message', default=None)\n        if warning is not None:\n            self._downloader.report_warning(\n                'Video %s may not be available; smotri said: %s ' %\n                (video_id, warning))\n\n        # Adult content\n        if re.search('EroConfirmText\">', webpage) is not None:\n            self.report_age_confirmation()\n            confirm_string = self._html_search_regex(\n                r'<a href=\"/video/view/\\?id=%s&confirm=([^\"]+)\" title=\"[^\"]+\">' % video_id,\n                webpage, 'confirm string')\n            confirm_url = webpage_url + '&confirm=%s' % confirm_string\n            webpage = self._download_webpage(confirm_url, video_id, 'Downloading video page (age confirmed)')\n            adult_content = True\n        else:\n            adult_content = False\n\n        view_count = self._html_search_regex(\n            '\u041e\u0431\u0449\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u043e\u0432.*?<span class=\"Number\">(\\\\d+)</span>',\n            webpage, 'view count', fatal=False, flags=re.MULTILINE | re.DOTALL)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'view_count': int_or_none(view_count),\n            'age_limit': 18 if adult_content else 0,\n        }",
        "begin_line": 164,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.00025075225677031093,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriCommunityIE._real_extract#264",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriCommunityIE",
        "signature": "youtube_dl.extractor.smotri.SmotriCommunityIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        community_id = mobj.group('communityid')\n\n        url = 'http://smotri.com/export/rss/video/by/community/-/%s/video.xml' % community_id\n        rss = self._download_xml(url, community_id, 'Downloading community RSS')\n\n        entries = [self.url_result(video_url.text, 'Smotri')\n                   for video_url in rss.findall('./channel/item/link')]\n\n        description_text = rss.find('./channel/description').text\n        community_title = self._html_search_regex(\n            '^\u0412\u0438\u0434\u0435\u043e \u0441\u043e\u043e\u0431\u0449\u0435\u0441\u0442\u0432\u0430 \"([^\"]+)\"$', description_text, 'community title')\n\n        return self.playlist_result(entries, community_id, community_title)",
        "begin_line": 264,
        "end_line": 278,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0003170577045022194,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriUserIE._real_extract#294",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriUserIE",
        "signature": "youtube_dl.extractor.smotri.SmotriUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('userid')\n\n        url = 'http://smotri.com/export/rss/user/video/-/%s/video.xml' % user_id\n        rss = self._download_xml(url, user_id, 'Downloading user RSS')\n\n        entries = [self.url_result(video_url.text, 'Smotri')\n                   for video_url in rss.findall('./channel/item/link')]\n\n        description_text = rss.find('./channel/description').text\n        user_nickname = self._html_search_regex(\n            '^\u0412\u0438\u0434\u0435\u043e \u0440\u0435\u0436\u0438\u0441\u0441\u0435\u0440\u0430 (.*)$', description_text,\n            'user nickname')\n\n        return self.playlist_result(entries, user_id, user_nickname)",
        "begin_line": 294,
        "end_line": 309,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036483035388544326,
            "pseudo_dstar_susp": 0.00036483035388544326,
            "pseudo_tarantula_susp": 0.00036483035388544326,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.00036483035388544326
        }
    }
]