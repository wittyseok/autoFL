[
    {
        "name": "spacy.tests.conftest.pytest_runtest_setup#12",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pytest_runtest_setup(item)",
        "snippet": "def pytest_runtest_setup(item):\n    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)\n\n    for opt in [\"slow\"]:\n        if opt in item.keywords and not getopt(opt):\n            pytest.skip(\"need --%s option to run\" % opt)",
        "begin_line": 12,
        "end_line": 24,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.getopt#13",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.getopt(opt)",
        "snippet": "    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)",
        "begin_line": 13,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tokenizer#31",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tokenizer()",
        "snippet": "def tokenizer():\n    return get_lang_class(\"xx\").Defaults.create_tokenizer()",
        "begin_line": 31,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ar_tokenizer#36",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ar_tokenizer()",
        "snippet": "def ar_tokenizer():\n    return get_lang_class(\"ar\").Defaults.create_tokenizer()",
        "begin_line": 36,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.bn_tokenizer#41",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.bn_tokenizer()",
        "snippet": "def bn_tokenizer():\n    return get_lang_class(\"bn\").Defaults.create_tokenizer()",
        "begin_line": 41,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ca_tokenizer#46",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ca_tokenizer()",
        "snippet": "def ca_tokenizer():\n    return get_lang_class(\"ca\").Defaults.create_tokenizer()",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.da_tokenizer#51",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.da_tokenizer()",
        "snippet": "def da_tokenizer():\n    return get_lang_class(\"da\").Defaults.create_tokenizer()",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.de_tokenizer#56",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.de_tokenizer()",
        "snippet": "def de_tokenizer():\n    return get_lang_class(\"de\").Defaults.create_tokenizer()",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.el_tokenizer#61",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.el_tokenizer()",
        "snippet": "def el_tokenizer():\n    return get_lang_class(\"el\").Defaults.create_tokenizer()",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_tokenizer#66",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_tokenizer()",
        "snippet": "def en_tokenizer():\n    return get_lang_class(\"en\").Defaults.create_tokenizer()",
        "begin_line": 66,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_vocab#71",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_vocab()",
        "snippet": "def en_vocab():\n    return get_lang_class(\"en\").Defaults.create_vocab()",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.es_tokenizer#82",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.es_tokenizer()",
        "snippet": "def es_tokenizer():\n    return get_lang_class(\"es\").Defaults.create_tokenizer()",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fi_tokenizer#87",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fi_tokenizer()",
        "snippet": "def fi_tokenizer():\n    return get_lang_class(\"fi\").Defaults.create_tokenizer()",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fr_tokenizer#92",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fr_tokenizer()",
        "snippet": "def fr_tokenizer():\n    return get_lang_class(\"fr\").Defaults.create_tokenizer()",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ga_tokenizer#97",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ga_tokenizer()",
        "snippet": "def ga_tokenizer():\n    return get_lang_class(\"ga\").Defaults.create_tokenizer()",
        "begin_line": 97,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.he_tokenizer#102",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.he_tokenizer()",
        "snippet": "def he_tokenizer():\n    return get_lang_class(\"he\").Defaults.create_tokenizer()",
        "begin_line": 102,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.hu_tokenizer#112",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.hu_tokenizer()",
        "snippet": "def hu_tokenizer():\n    return get_lang_class(\"hu\").Defaults.create_tokenizer()",
        "begin_line": 112,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.id_tokenizer#117",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.id_tokenizer()",
        "snippet": "def id_tokenizer():\n    return get_lang_class(\"id\").Defaults.create_tokenizer()",
        "begin_line": 117,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.it_tokenizer#122",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.it_tokenizer()",
        "snippet": "def it_tokenizer():\n    return get_lang_class(\"it\").Defaults.create_tokenizer()",
        "begin_line": 122,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.lb_tokenizer#139",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.lb_tokenizer()",
        "snippet": "def lb_tokenizer():\n    return get_lang_class(\"lb\").Defaults.create_tokenizer()",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.lt_tokenizer#144",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.lt_tokenizer()",
        "snippet": "def lt_tokenizer():\n    return get_lang_class(\"lt\").Defaults.create_tokenizer()",
        "begin_line": 144,
        "end_line": 145,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nb_tokenizer#149",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nb_tokenizer()",
        "snippet": "def nb_tokenizer():\n    return get_lang_class(\"nb\").Defaults.create_tokenizer()",
        "begin_line": 149,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nl_tokenizer#154",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nl_tokenizer()",
        "snippet": "def nl_tokenizer():\n    return get_lang_class(\"nl\").Defaults.create_tokenizer()",
        "begin_line": 154,
        "end_line": 155,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.pl_tokenizer#159",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pl_tokenizer()",
        "snippet": "def pl_tokenizer():\n    return get_lang_class(\"pl\").Defaults.create_tokenizer()",
        "begin_line": 159,
        "end_line": 160,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ro_tokenizer#169",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ro_tokenizer()",
        "snippet": "def ro_tokenizer():\n    return get_lang_class(\"ro\").Defaults.create_tokenizer()",
        "begin_line": 169,
        "end_line": 170,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sr_tokenizer#186",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sr_tokenizer()",
        "snippet": "def sr_tokenizer():\n    return get_lang_class(\"sr\").Defaults.create_tokenizer()",
        "begin_line": 186,
        "end_line": 187,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sv_tokenizer#191",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sv_tokenizer()",
        "snippet": "def sv_tokenizer():\n    return get_lang_class(\"sv\").Defaults.create_tokenizer()",
        "begin_line": 191,
        "end_line": 192,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tt_tokenizer#207",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tt_tokenizer()",
        "snippet": "def tt_tokenizer():\n    return get_lang_class(\"tt\").Defaults.create_tokenizer()",
        "begin_line": 207,
        "end_line": 208,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ur_tokenizer#219",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ur_tokenizer()",
        "snippet": "def ur_tokenizer():\n    return get_lang_class(\"ur\").Defaults.create_tokenizer()",
        "begin_line": 219,
        "end_line": 220,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.make_tempdir#23",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.make_tempdir()",
        "snippet": "def make_tempdir():\n    d = Path(tempfile.mkdtemp())\n    yield d\n    shutil.rmtree(path2str(d))",
        "begin_line": 23,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_doc#29",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None)",
        "snippet": "def get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None):\n    \"\"\"Create Doc object from given vocab, words and annotations.\"\"\"\n    pos = pos or [\"\"] * len(words)\n    tags = tags or [\"\"] * len(words)\n    heads = heads or [0] * len(words)\n    deps = deps or [\"\"] * len(words)\n    for value in deps + tags + pos:\n        vocab.strings.add(value)\n\n    doc = Doc(vocab, words=words)\n    attrs = doc.to_array([POS, HEAD, DEP])\n    for i, (p, head, dep) in enumerate(zip(pos, heads, deps)):\n        attrs[i, 0] = doc.vocab.strings[p]\n        attrs[i, 1] = head\n        attrs[i, 2] = doc.vocab.strings[dep]\n    doc.from_array([POS, HEAD, DEP], attrs)\n    if ents:\n        doc.ents = [\n            Span(doc, start, end, label=doc.vocab.strings[label])\n            for start, end, label in ents\n        ]\n    if tags:\n        for token in doc:\n            token.tag_ = tags[token.i]\n    return doc",
        "begin_line": 29,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.add_vecs_to_vocab#68",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.add_vecs_to_vocab(vocab, vectors)",
        "snippet": "def add_vecs_to_vocab(vocab, vectors):\n    \"\"\"Add list of vector tuples to given vocab. All vectors need to have the\n    same length. Format: [(\"text\", [1, 2, 3])]\"\"\"\n    length = len(vectors[0][1])\n    vocab.reset_vectors(width=length)\n    for word, vec in vectors:\n        vocab.set_vector(word, vector=vec)\n    return vocab",
        "begin_line": 68,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_cosine#78",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_cosine(vec1, vec2)",
        "snippet": "def get_cosine(vec1, vec2):\n    \"\"\"Get cosine for two given vectors\"\"\"\n    return numpy.dot(vec1, vec2) / (numpy.linalg.norm(vec1) * numpy.linalg.norm(vec2))",
        "begin_line": 78,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.assert_docs_equal#83",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.assert_docs_equal(doc1, doc2)",
        "snippet": "def assert_docs_equal(doc1, doc2):\n    \"\"\"Compare two Doc objects and assert that they're equal. Tests for tokens,\n    tags, dependencies and entities.\"\"\"\n    assert [t.orth for t in doc1] == [t.orth for t in doc2]\n\n    assert [t.pos for t in doc1] == [t.pos for t in doc2]\n    assert [t.tag for t in doc1] == [t.tag for t in doc2]\n\n    assert [t.head.i for t in doc1] == [t.head.i for t in doc2]\n    assert [t.dep for t in doc1] == [t.dep for t in doc2]\n    if doc1.is_parsed and doc2.is_parsed:\n        assert [s for s in doc1.sents] == [s for s in doc2.sents]\n\n    assert [t.ent_type for t in doc1] == [t.ent_type for t in doc2]\n    assert [t.ent_iob for t in doc1] == [t.ent_iob for t in doc2]\n    assert [ent for ent in doc1.ents] == [ent for ent in doc2.ents]",
        "begin_line": 83,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.nlp#17",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.nlp()",
        "snippet": "def nlp():\n    nlp = Language(Vocab())\n    textcat = nlp.create_pipe(\"textcat\")\n    for label in (\"POSITIVE\", \"NEGATIVE\"):\n        textcat.add_label(label)\n    nlp.add_pipe(textcat)\n    nlp.begin_training()\n    return nlp",
        "begin_line": 17,
        "end_line": 24,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.test_language_update#27",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.test_language_update(nlp)",
        "snippet": "def test_language_update(nlp):\n    text = \"hello world\"\n    annots = {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0}}\n    wrongkeyannots = {\"LABEL\": True}\n    doc = Doc(nlp.vocab, words=text.split(\" \"))\n    gold = GoldParse(doc, **annots)\n    # Update with doc and gold objects\n    nlp.update([doc], [gold])\n    # Update with text and dict\n    nlp.update([text], [annots])\n    # Update with doc object and dict\n    nlp.update([doc], [annots])\n    # Update with text and gold object\n    nlp.update([text], [gold])\n    # Update badly\n    with pytest.raises(IndexError):\n        nlp.update([doc], [])\n    with pytest.raises(IndexError):\n        nlp.update([], [gold])\n    with pytest.raises(ValueError):\n        nlp.update([text], [wrongkeyannots])",
        "begin_line": 27,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.test_language_evaluate#50",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.test_language_evaluate(nlp)",
        "snippet": "def test_language_evaluate(nlp):\n    text = \"hello world\"\n    annots = {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0}}\n    doc = Doc(nlp.vocab, words=text.split(\" \"))\n    gold = GoldParse(doc, **annots)\n    # Evaluate with doc and gold objects\n    nlp.evaluate([(doc, gold)])\n    # Evaluate with text and dict\n    nlp.evaluate([(text, annots)])\n    # Evaluate with doc object and dict\n    nlp.evaluate([(doc, annots)])\n    # Evaluate with text and gold object\n    nlp.evaluate([(text, gold)])\n    # Evaluate badly\n    with pytest.raises(Exception):\n        nlp.evaluate([text, gold])",
        "begin_line": 50,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.test_evaluate_no_pipe#68",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.test_evaluate_no_pipe(nlp)",
        "snippet": "def test_evaluate_no_pipe(nlp):\n    \"\"\"Test that docs are processed correctly within Language.pipe if the\n    component doesn't expose a .pipe method.\"\"\"\n\n    def pipe(doc):\n        return doc\n\n    text = \"hello world\"\n    annots = {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0}}\n    nlp = Language(Vocab())\n    nlp.add_pipe(pipe)\n    nlp.evaluate([(text, annots)])",
        "begin_line": 68,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.pipe#72",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.pipe(doc)",
        "snippet": "    def pipe(doc):\n        return doc",
        "begin_line": 72,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.vector_modification_pipe#82",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.vector_modification_pipe(doc)",
        "snippet": "def vector_modification_pipe(doc):\n    doc.vector += 1\n    return doc",
        "begin_line": 82,
        "end_line": 84,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.userdata_pipe#87",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.userdata_pipe(doc)",
        "snippet": "def userdata_pipe(doc):\n    doc.user_data[\"foo\"] = \"bar\"\n    return doc",
        "begin_line": 87,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.ner_pipe#92",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.ner_pipe(doc)",
        "snippet": "def ner_pipe(doc):\n    span = Span(doc, 0, 1, label=\"FIRST\")\n    doc.ents += (span,)\n    return doc",
        "begin_line": 92,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.sample_vectors#99",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.sample_vectors()",
        "snippet": "def sample_vectors():\n    return [\n        (\"spacy\", [-0.1, -0.2, -0.3]),\n        (\"world\", [-0.2, -0.3, -0.4]),\n        (\"pipe\", [0.7, 0.8, 0.9]),\n    ]",
        "begin_line": 99,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.nlp2#108",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.nlp2(nlp, sample_vectors)",
        "snippet": "def nlp2(nlp, sample_vectors):\n    add_vecs_to_vocab(nlp.vocab, sample_vectors)\n    nlp.add_pipe(vector_modification_pipe)\n    nlp.add_pipe(ner_pipe)\n    nlp.add_pipe(userdata_pipe)\n    return nlp",
        "begin_line": 108,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.texts#117",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.texts()",
        "snippet": "def texts():\n    data = [\n        \"Hello world.\",\n        \"This is spacy.\",\n        \"You can use multiprocessing with pipe method.\",\n        \"Please try!\",\n    ]\n    return data",
        "begin_line": 117,
        "end_line": 124,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.test_language_pipe#128",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.test_language_pipe(nlp2, n_process, texts)",
        "snippet": "def test_language_pipe(nlp2, n_process, texts):\n    texts = texts * 10\n    expecteds = [nlp2(text) for text in texts]\n    docs = nlp2.pipe(texts, n_process=n_process, batch_size=2)\n\n    for doc, expected_doc in zip(docs, expecteds):\n        assert_docs_equal(doc, expected_doc)",
        "begin_line": 128,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.test_language.test_language_pipe_stream#141",
        "src_path": "spacy/tests/test_language.py",
        "class_name": "spacy.tests.test_language",
        "signature": "spacy.tests.test_language.test_language_pipe_stream(nlp2, n_process, texts)",
        "snippet": "def test_language_pipe_stream(nlp2, n_process, texts):\n    # check if nlp.pipe can handle infinite length iterator properly.\n    stream_texts = itertools.cycle(texts)\n    texts0, texts1 = itertools.tee(stream_texts)\n    expecteds = (nlp2(text) for text in texts0)\n    docs = nlp2.pipe(texts1, n_process=n_process, batch_size=2)\n\n    n_fetch = 20\n    for doc, expected_doc in itertools.islice(zip(docs, expecteds), n_fetch):\n        assert_docs_equal(doc, expected_doc)",
        "begin_line": 141,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    }
]