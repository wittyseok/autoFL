coverage run -m pytest pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved
============================= test session starts ==============================
platform linux -- Python 3.8.3, pytest-5.4.3, py-1.8.1, pluggy-0.13.1
rootdir: /home/user/BugsInPy/temp/projects/pandas, inifile: setup.cfg
plugins: hypothesis-5.16.0
collected 69 items

pandas/tests/groupby/test_categorical.py .......FF...................... [ 44%]
.....sss.FF.FF..........FF............                                   [100%]

=================================== FAILURES ===================================
________ test_series_groupby_on_2_categoricals_unobserved[count-False] _________

reduction_func = 'count', observed = False

    def test_series_groupby_on_2_categoricals_unobserved(
        reduction_func: str, observed: bool
    ):
        # GH 17605
    
        if reduction_func == "ngroup":
            pytest.skip("ngroup is not truly a reduction")
    
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABCD")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABCD")),
                "value": [0.1] * 4,
            }
        )
        args = {"nth": [0]}.get(reduction_func, [])
    
        expected_length = 4 if observed else 16
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=observed)["value"]
        agg = getattr(series_groupby, reduction_func)
        result = agg(*args)
    
>       assert len(result) == expected_length
E       assert 4 == 16
E        +  where 4 = len(cat_1  cat_2\nA      A        1\n       B        1\nB      A        1\n       B        1\nName: value, dtype: int64)

pandas/tests/groupby/test_categorical.py:1280: AssertionError
_________ test_series_groupby_on_2_categoricals_unobserved[count-None] _________

reduction_func = 'count', observed = None

    def test_series_groupby_on_2_categoricals_unobserved(
        reduction_func: str, observed: bool
    ):
        # GH 17605
    
        if reduction_func == "ngroup":
            pytest.skip("ngroup is not truly a reduction")
    
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABCD")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABCD")),
                "value": [0.1] * 4,
            }
        )
        args = {"nth": [0]}.get(reduction_func, [])
    
        expected_length = 4 if observed else 16
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=observed)["value"]
        agg = getattr(series_groupby, reduction_func)
        result = agg(*args)
    
>       assert len(result) == expected_length
E       assert 4 == 16
E        +  where 4 = len(cat_1  cat_2\nA      A        1\n       B        1\nB      A        1\n       B        1\nName: value, dtype: int64)

pandas/tests/groupby/test_categorical.py:1280: AssertionError
_________ test_series_groupby_on_2_categoricals_unobserved[nth-False] __________

reduction_func = 'nth', observed = False

    def test_series_groupby_on_2_categoricals_unobserved(
        reduction_func: str, observed: bool
    ):
        # GH 17605
    
        if reduction_func == "ngroup":
            pytest.skip("ngroup is not truly a reduction")
    
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABCD")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABCD")),
                "value": [0.1] * 4,
            }
        )
        args = {"nth": [0]}.get(reduction_func, [])
    
        expected_length = 4 if observed else 16
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=observed)["value"]
        agg = getattr(series_groupby, reduction_func)
        result = agg(*args)
    
>       assert len(result) == expected_length
E       assert 4 == 16
E        +  where 4 = len(cat_1  cat_2\nA      A        0.1\n       B        0.1\nB      A        0.1\n       B        0.1\nName: value, dtype: float64)

pandas/tests/groupby/test_categorical.py:1280: AssertionError
__________ test_series_groupby_on_2_categoricals_unobserved[nth-None] __________

reduction_func = 'nth', observed = None

    def test_series_groupby_on_2_categoricals_unobserved(
        reduction_func: str, observed: bool
    ):
        # GH 17605
    
        if reduction_func == "ngroup":
            pytest.skip("ngroup is not truly a reduction")
    
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABCD")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABCD")),
                "value": [0.1] * 4,
            }
        )
        args = {"nth": [0]}.get(reduction_func, [])
    
        expected_length = 4 if observed else 16
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=observed)["value"]
        agg = getattr(series_groupby, reduction_func)
        result = agg(*args)
    
>       assert len(result) == expected_length
E       assert 4 == 16
E        +  where 4 = len(cat_1  cat_2\nA      A        0.1\n       B        0.1\nB      A        0.1\n       B        0.1\nName: value, dtype: float64)

pandas/tests/groupby/test_categorical.py:1280: AssertionError
_______ test_series_groupby_on_2_categoricals_unobserved[nunique-False] ________

reduction_func = 'nunique', observed = False

    def test_series_groupby_on_2_categoricals_unobserved(
        reduction_func: str, observed: bool
    ):
        # GH 17605
    
        if reduction_func == "ngroup":
            pytest.skip("ngroup is not truly a reduction")
    
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABCD")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABCD")),
                "value": [0.1] * 4,
            }
        )
        args = {"nth": [0]}.get(reduction_func, [])
    
        expected_length = 4 if observed else 16
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=observed)["value"]
        agg = getattr(series_groupby, reduction_func)
        result = agg(*args)
    
>       assert len(result) == expected_length
E       assert 4 == 16
E        +  where 4 = len(cat_1  cat_2\nA      A        1\n       B        1\nB      A        1\n       B        1\nName: value, dtype: int64)

pandas/tests/groupby/test_categorical.py:1280: AssertionError
________ test_series_groupby_on_2_categoricals_unobserved[nunique-None] ________

reduction_func = 'nunique', observed = None

    def test_series_groupby_on_2_categoricals_unobserved(
        reduction_func: str, observed: bool
    ):
        # GH 17605
    
        if reduction_func == "ngroup":
            pytest.skip("ngroup is not truly a reduction")
    
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABCD")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABCD")),
                "value": [0.1] * 4,
            }
        )
        args = {"nth": [0]}.get(reduction_func, [])
    
        expected_length = 4 if observed else 16
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=observed)["value"]
        agg = getattr(series_groupby, reduction_func)
        result = agg(*args)
    
>       assert len(result) == expected_length
E       assert 4 == 16
E        +  where 4 = len(cat_1  cat_2\nA      A        1\n       B        1\nB      A        1\n       B        1\nName: value, dtype: int64)

pandas/tests/groupby/test_categorical.py:1280: AssertionError
_________ test_series_groupby_on_2_categoricals_unobserved[size-False] _________

reduction_func = 'size', observed = False

    def test_series_groupby_on_2_categoricals_unobserved(
        reduction_func: str, observed: bool
    ):
        # GH 17605
    
        if reduction_func == "ngroup":
            pytest.skip("ngroup is not truly a reduction")
    
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABCD")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABCD")),
                "value": [0.1] * 4,
            }
        )
        args = {"nth": [0]}.get(reduction_func, [])
    
        expected_length = 4 if observed else 16
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=observed)["value"]
        agg = getattr(series_groupby, reduction_func)
        result = agg(*args)
    
>       assert len(result) == expected_length
E       assert 4 == 16
E        +  where 4 = len(cat_1  cat_2\nA      A        1\n       B        1\nB      A        1\n       B        1\nName: value, dtype: int64)

pandas/tests/groupby/test_categorical.py:1280: AssertionError
_________ test_series_groupby_on_2_categoricals_unobserved[size-None] __________

reduction_func = 'size', observed = None

    def test_series_groupby_on_2_categoricals_unobserved(
        reduction_func: str, observed: bool
    ):
        # GH 17605
    
        if reduction_func == "ngroup":
            pytest.skip("ngroup is not truly a reduction")
    
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABCD")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABCD")),
                "value": [0.1] * 4,
            }
        )
        args = {"nth": [0]}.get(reduction_func, [])
    
        expected_length = 4 if observed else 16
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=observed)["value"]
        agg = getattr(series_groupby, reduction_func)
        result = agg(*args)
    
>       assert len(result) == expected_length
E       assert 4 == 16
E        +  where 4 = len(cat_1  cat_2\nA      A        1\n       B        1\nB      A        1\n       B        1\nName: value, dtype: int64)

pandas/tests/groupby/test_categorical.py:1280: AssertionError
=========================== short test summary info ============================
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved[count-False]
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved[count-None]
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved[nth-False]
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved[nth-None]
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved[nunique-False]
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved[nunique-None]
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved[size-False]
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved[size-None]
=================== 8 failed, 58 passed, 3 skipped in 1.46s ====================

coverage run -m pytest pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans
============================= test session starts ==============================
platform linux -- Python 3.8.3, pytest-5.4.3, py-1.8.1, pluggy-0.13.1
rootdir: /home/user/BugsInPy/temp/projects/pandas, inifile: setup.cfg
plugins: hypothesis-5.16.0
collected 22 items

pandas/tests/groupby/test_categorical.py ..F.........FF...F....          [100%]

=================================== FAILURES ===================================
___ test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans[count-0] ___

self = MultiIndex([('A', 'A'),
            ('A', 'B'),
            ('B', 'A'),
            ('B', 'B')],
           names=['cat_1', 'cat_2'])
key = ('A', 'C'), level = 0, drop_level = True

    def get_loc_level(self, key, level=0, drop_level: bool = True):
        """
        Get both the location for the requested label(s) and the
        resulting sliced index.
    
        Parameters
        ----------
        key : label or sequence of labels
        level : int/level name or list thereof, optional
        drop_level : bool, default True
            if ``False``, the resulting index will not drop any level.
    
        Returns
        -------
        loc : A 2-tuple where the elements are:
              Element 0: int, slice object or boolean array
              Element 1: The resulting sliced multiindex/index. If the key
              contains all levels, this will be ``None``.
    
        See Also
        --------
        MultiIndex.get_loc  : Get location for a label or a tuple of labels.
        MultiIndex.get_locs : Get location for a label/slice/list/mask or a
                              sequence of such.
    
        Examples
        --------
        >>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')],
        ...                                names=['A', 'B'])
    
        >>> mi.get_loc_level('b')
        (slice(1, 3, None), Index(['e', 'f'], dtype='object', name='B'))
    
        >>> mi.get_loc_level('e', level='B')
        (array([False,  True, False], dtype=bool),
        Index(['b'], dtype='object', name='A'))
    
        >>> mi.get_loc_level(['b', 'e'])
        (1, None)
        """
    
        # different name to distinguish from maybe_droplevels
        def maybe_mi_droplevels(indexer, levels, drop_level: bool):
            if not drop_level:
                return self[indexer]
            # kludgearound
            orig_index = new_index = self[indexer]
            levels = [self._get_level_number(i) for i in levels]
            for i in sorted(levels, reverse=True):
                try:
                    new_index = new_index.droplevel(i)
                except ValueError:
    
                    # no dropping here
                    return orig_index
            return new_index
    
        if isinstance(level, (tuple, list)):
            if len(key) != len(level):
                raise AssertionError(
                    "Key for location must have same length as number of levels"
                )
            result = None
            for lev, k in zip(level, key):
                loc, new_index = self.get_loc_level(k, level=lev)
                if isinstance(loc, slice):
                    mask = np.zeros(len(self), dtype=bool)
                    mask[loc] = True
                    loc = mask
    
                result = loc if result is None else result & loc
    
            return result, maybe_mi_droplevels(result, level, drop_level)
    
        level = self._get_level_number(level)
    
        # kludge for #1796
        if isinstance(key, list):
            key = tuple(key)
    
        if isinstance(key, tuple) and level == 0:
    
            try:
                if key in self.levels[0]:
                    indexer = self._get_level_indexer(key, level=level)
                    new_index = maybe_mi_droplevels(indexer, [0], drop_level)
                    return indexer, new_index
            except TypeError:
                pass
    
            if not any(isinstance(k, slice) for k in key):
    
                # partial selection
                # optionally get indexer to avoid re-calculation
                def partial_selection(key, indexer=None):
                    if indexer is None:
                        indexer = self.get_loc(key)
                    ilevels = [
                        i for i in range(len(key)) if key[i] != slice(None, None)
                    ]
                    return indexer, maybe_mi_droplevels(indexer, ilevels, drop_level)
    
                if len(key) == self.nlevels and self.is_unique:
                    # Complete key in unique index -> standard get_loc
                    try:
>                       return (self._engine.get_loc(key), None)

pandas/core/indexes/multi.py:2840: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   return self._base.get_loc(self, lab_int)

pandas/_libs/index.pyx:702: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   cpdef get_loc(self, object val):

pandas/_libs/index.pyx:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   return self.mapping.get_item(val)

pandas/_libs/index.pyx:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   cpdef get_item(self, uint64_t val):

pandas/_libs/hashtable_class_helper.pxi:693: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   raise KeyError(val)
E   KeyError: 7

pandas/_libs/hashtable_class_helper.pxi:700: KeyError

The above exception was the direct cause of the following exception:

func = 'count', zero_or_nan = 0

    @pytest.mark.parametrize(
        "func, zero_or_nan",
        [
            ("all", np.NaN),
            ("any", np.NaN),
            ("count", 0),
            ("first", np.NaN),
            ("idxmax", np.NaN),
            ("idxmin", np.NaN),
            ("last", np.NaN),
            ("mad", np.NaN),
            ("max", np.NaN),
            ("mean", np.NaN),
            ("median", np.NaN),
            ("min", np.NaN),
            ("nth", np.NaN),
            ("nunique", 0),
            ("prod", np.NaN),
            ("quantile", np.NaN),
            ("sem", np.NaN),
            ("size", 0),
            ("skew", np.NaN),
            ("std", np.NaN),
            ("sum", np.NaN),
            ("var", np.NaN),
        ],
    )
    def test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans(func, zero_or_nan):
        # GH 17605
        # Tests whether the unobserved categories in the result contain 0 or NaN
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABC")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABC")),
                "value": [0.1] * 4,
            }
        )
        unobserved = [tuple("AC"), tuple("BC"), tuple("CA"), tuple("CB"), tuple("CC")]
        args = {"nth": [0]}.get(func, [])
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=False)["value"]
        agg = getattr(series_groupby, func)
        result = agg(*args)
    
        for idx in unobserved:
>           val = result.loc[idx]

pandas/tests/groupby/test_categorical.py:1328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
pandas/core/indexing.py:1387: in __getitem__
    return self._getitem_tuple(key)
pandas/core/indexing.py:798: in _getitem_tuple
    return self._getitem_lowerdim(tup)
pandas/core/indexing.py:902: in _getitem_lowerdim
    result = self._handle_lowerdim_multi_index_axis0(tup)
pandas/core/indexing.py:882: in _handle_lowerdim_multi_index_axis0
    raise ek
pandas/core/indexing.py:874: in _handle_lowerdim_multi_index_axis0
    return self._get_label(tup, axis=axis)
pandas/core/indexing.py:156: in _get_label
    return self.obj._xs(label, axis=axis)
pandas/core/generic.py:3596: in xs
    loc, new_index = self.index.get_loc_level(key, drop_level=drop_level)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiIndex([('A', 'A'),
            ('A', 'B'),
            ('B', 'A'),
            ('B', 'B')],
           names=['cat_1', 'cat_2'])
key = ('A', 'C'), level = 0, drop_level = True

    def get_loc_level(self, key, level=0, drop_level: bool = True):
        """
        Get both the location for the requested label(s) and the
        resulting sliced index.
    
        Parameters
        ----------
        key : label or sequence of labels
        level : int/level name or list thereof, optional
        drop_level : bool, default True
            if ``False``, the resulting index will not drop any level.
    
        Returns
        -------
        loc : A 2-tuple where the elements are:
              Element 0: int, slice object or boolean array
              Element 1: The resulting sliced multiindex/index. If the key
              contains all levels, this will be ``None``.
    
        See Also
        --------
        MultiIndex.get_loc  : Get location for a label or a tuple of labels.
        MultiIndex.get_locs : Get location for a label/slice/list/mask or a
                              sequence of such.
    
        Examples
        --------
        >>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')],
        ...                                names=['A', 'B'])
    
        >>> mi.get_loc_level('b')
        (slice(1, 3, None), Index(['e', 'f'], dtype='object', name='B'))
    
        >>> mi.get_loc_level('e', level='B')
        (array([False,  True, False], dtype=bool),
        Index(['b'], dtype='object', name='A'))
    
        >>> mi.get_loc_level(['b', 'e'])
        (1, None)
        """
    
        # different name to distinguish from maybe_droplevels
        def maybe_mi_droplevels(indexer, levels, drop_level: bool):
            if not drop_level:
                return self[indexer]
            # kludgearound
            orig_index = new_index = self[indexer]
            levels = [self._get_level_number(i) for i in levels]
            for i in sorted(levels, reverse=True):
                try:
                    new_index = new_index.droplevel(i)
                except ValueError:
    
                    # no dropping here
                    return orig_index
            return new_index
    
        if isinstance(level, (tuple, list)):
            if len(key) != len(level):
                raise AssertionError(
                    "Key for location must have same length as number of levels"
                )
            result = None
            for lev, k in zip(level, key):
                loc, new_index = self.get_loc_level(k, level=lev)
                if isinstance(loc, slice):
                    mask = np.zeros(len(self), dtype=bool)
                    mask[loc] = True
                    loc = mask
    
                result = loc if result is None else result & loc
    
            return result, maybe_mi_droplevels(result, level, drop_level)
    
        level = self._get_level_number(level)
    
        # kludge for #1796
        if isinstance(key, list):
            key = tuple(key)
    
        if isinstance(key, tuple) and level == 0:
    
            try:
                if key in self.levels[0]:
                    indexer = self._get_level_indexer(key, level=level)
                    new_index = maybe_mi_droplevels(indexer, [0], drop_level)
                    return indexer, new_index
            except TypeError:
                pass
    
            if not any(isinstance(k, slice) for k in key):
    
                # partial selection
                # optionally get indexer to avoid re-calculation
                def partial_selection(key, indexer=None):
                    if indexer is None:
                        indexer = self.get_loc(key)
                    ilevels = [
                        i for i in range(len(key)) if key[i] != slice(None, None)
                    ]
                    return indexer, maybe_mi_droplevels(indexer, ilevels, drop_level)
    
                if len(key) == self.nlevels and self.is_unique:
                    # Complete key in unique index -> standard get_loc
                    try:
                        return (self._engine.get_loc(key), None)
                    except KeyError as e:
>                       raise KeyError(key) from e
E                       KeyError: ('A', 'C')

pandas/core/indexes/multi.py:2842: KeyError
___ test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans[nth-nan] ___

self = MultiIndex([('A', 'A'),
            ('A', 'B'),
            ('B', 'A'),
            ('B', 'B')],
           names=['cat_1', 'cat_2'])
key = ('A', 'C'), level = 0, drop_level = True

    def get_loc_level(self, key, level=0, drop_level: bool = True):
        """
        Get both the location for the requested label(s) and the
        resulting sliced index.
    
        Parameters
        ----------
        key : label or sequence of labels
        level : int/level name or list thereof, optional
        drop_level : bool, default True
            if ``False``, the resulting index will not drop any level.
    
        Returns
        -------
        loc : A 2-tuple where the elements are:
              Element 0: int, slice object or boolean array
              Element 1: The resulting sliced multiindex/index. If the key
              contains all levels, this will be ``None``.
    
        See Also
        --------
        MultiIndex.get_loc  : Get location for a label or a tuple of labels.
        MultiIndex.get_locs : Get location for a label/slice/list/mask or a
                              sequence of such.
    
        Examples
        --------
        >>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')],
        ...                                names=['A', 'B'])
    
        >>> mi.get_loc_level('b')
        (slice(1, 3, None), Index(['e', 'f'], dtype='object', name='B'))
    
        >>> mi.get_loc_level('e', level='B')
        (array([False,  True, False], dtype=bool),
        Index(['b'], dtype='object', name='A'))
    
        >>> mi.get_loc_level(['b', 'e'])
        (1, None)
        """
    
        # different name to distinguish from maybe_droplevels
        def maybe_mi_droplevels(indexer, levels, drop_level: bool):
            if not drop_level:
                return self[indexer]
            # kludgearound
            orig_index = new_index = self[indexer]
            levels = [self._get_level_number(i) for i in levels]
            for i in sorted(levels, reverse=True):
                try:
                    new_index = new_index.droplevel(i)
                except ValueError:
    
                    # no dropping here
                    return orig_index
            return new_index
    
        if isinstance(level, (tuple, list)):
            if len(key) != len(level):
                raise AssertionError(
                    "Key for location must have same length as number of levels"
                )
            result = None
            for lev, k in zip(level, key):
                loc, new_index = self.get_loc_level(k, level=lev)
                if isinstance(loc, slice):
                    mask = np.zeros(len(self), dtype=bool)
                    mask[loc] = True
                    loc = mask
    
                result = loc if result is None else result & loc
    
            return result, maybe_mi_droplevels(result, level, drop_level)
    
        level = self._get_level_number(level)
    
        # kludge for #1796
        if isinstance(key, list):
            key = tuple(key)
    
        if isinstance(key, tuple) and level == 0:
    
            try:
                if key in self.levels[0]:
                    indexer = self._get_level_indexer(key, level=level)
                    new_index = maybe_mi_droplevels(indexer, [0], drop_level)
                    return indexer, new_index
            except TypeError:
                pass
    
            if not any(isinstance(k, slice) for k in key):
    
                # partial selection
                # optionally get indexer to avoid re-calculation
                def partial_selection(key, indexer=None):
                    if indexer is None:
                        indexer = self.get_loc(key)
                    ilevels = [
                        i for i in range(len(key)) if key[i] != slice(None, None)
                    ]
                    return indexer, maybe_mi_droplevels(indexer, ilevels, drop_level)
    
                if len(key) == self.nlevels and self.is_unique:
                    # Complete key in unique index -> standard get_loc
                    try:
>                       return (self._engine.get_loc(key), None)

pandas/core/indexes/multi.py:2840: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   return self._base.get_loc(self, lab_int)

pandas/_libs/index.pyx:702: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   cpdef get_loc(self, object val):

pandas/_libs/index.pyx:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   return self.mapping.get_item(val)

pandas/_libs/index.pyx:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   cpdef get_item(self, uint64_t val):

pandas/_libs/hashtable_class_helper.pxi:693: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   raise KeyError(val)
E   KeyError: 7

pandas/_libs/hashtable_class_helper.pxi:700: KeyError

The above exception was the direct cause of the following exception:

func = 'nth', zero_or_nan = nan

    @pytest.mark.parametrize(
        "func, zero_or_nan",
        [
            ("all", np.NaN),
            ("any", np.NaN),
            ("count", 0),
            ("first", np.NaN),
            ("idxmax", np.NaN),
            ("idxmin", np.NaN),
            ("last", np.NaN),
            ("mad", np.NaN),
            ("max", np.NaN),
            ("mean", np.NaN),
            ("median", np.NaN),
            ("min", np.NaN),
            ("nth", np.NaN),
            ("nunique", 0),
            ("prod", np.NaN),
            ("quantile", np.NaN),
            ("sem", np.NaN),
            ("size", 0),
            ("skew", np.NaN),
            ("std", np.NaN),
            ("sum", np.NaN),
            ("var", np.NaN),
        ],
    )
    def test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans(func, zero_or_nan):
        # GH 17605
        # Tests whether the unobserved categories in the result contain 0 or NaN
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABC")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABC")),
                "value": [0.1] * 4,
            }
        )
        unobserved = [tuple("AC"), tuple("BC"), tuple("CA"), tuple("CB"), tuple("CC")]
        args = {"nth": [0]}.get(func, [])
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=False)["value"]
        agg = getattr(series_groupby, func)
        result = agg(*args)
    
        for idx in unobserved:
>           val = result.loc[idx]

pandas/tests/groupby/test_categorical.py:1328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
pandas/core/indexing.py:1387: in __getitem__
    return self._getitem_tuple(key)
pandas/core/indexing.py:798: in _getitem_tuple
    return self._getitem_lowerdim(tup)
pandas/core/indexing.py:902: in _getitem_lowerdim
    result = self._handle_lowerdim_multi_index_axis0(tup)
pandas/core/indexing.py:882: in _handle_lowerdim_multi_index_axis0
    raise ek
pandas/core/indexing.py:874: in _handle_lowerdim_multi_index_axis0
    return self._get_label(tup, axis=axis)
pandas/core/indexing.py:156: in _get_label
    return self.obj._xs(label, axis=axis)
pandas/core/generic.py:3596: in xs
    loc, new_index = self.index.get_loc_level(key, drop_level=drop_level)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiIndex([('A', 'A'),
            ('A', 'B'),
            ('B', 'A'),
            ('B', 'B')],
           names=['cat_1', 'cat_2'])
key = ('A', 'C'), level = 0, drop_level = True

    def get_loc_level(self, key, level=0, drop_level: bool = True):
        """
        Get both the location for the requested label(s) and the
        resulting sliced index.
    
        Parameters
        ----------
        key : label or sequence of labels
        level : int/level name or list thereof, optional
        drop_level : bool, default True
            if ``False``, the resulting index will not drop any level.
    
        Returns
        -------
        loc : A 2-tuple where the elements are:
              Element 0: int, slice object or boolean array
              Element 1: The resulting sliced multiindex/index. If the key
              contains all levels, this will be ``None``.
    
        See Also
        --------
        MultiIndex.get_loc  : Get location for a label or a tuple of labels.
        MultiIndex.get_locs : Get location for a label/slice/list/mask or a
                              sequence of such.
    
        Examples
        --------
        >>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')],
        ...                                names=['A', 'B'])
    
        >>> mi.get_loc_level('b')
        (slice(1, 3, None), Index(['e', 'f'], dtype='object', name='B'))
    
        >>> mi.get_loc_level('e', level='B')
        (array([False,  True, False], dtype=bool),
        Index(['b'], dtype='object', name='A'))
    
        >>> mi.get_loc_level(['b', 'e'])
        (1, None)
        """
    
        # different name to distinguish from maybe_droplevels
        def maybe_mi_droplevels(indexer, levels, drop_level: bool):
            if not drop_level:
                return self[indexer]
            # kludgearound
            orig_index = new_index = self[indexer]
            levels = [self._get_level_number(i) for i in levels]
            for i in sorted(levels, reverse=True):
                try:
                    new_index = new_index.droplevel(i)
                except ValueError:
    
                    # no dropping here
                    return orig_index
            return new_index
    
        if isinstance(level, (tuple, list)):
            if len(key) != len(level):
                raise AssertionError(
                    "Key for location must have same length as number of levels"
                )
            result = None
            for lev, k in zip(level, key):
                loc, new_index = self.get_loc_level(k, level=lev)
                if isinstance(loc, slice):
                    mask = np.zeros(len(self), dtype=bool)
                    mask[loc] = True
                    loc = mask
    
                result = loc if result is None else result & loc
    
            return result, maybe_mi_droplevels(result, level, drop_level)
    
        level = self._get_level_number(level)
    
        # kludge for #1796
        if isinstance(key, list):
            key = tuple(key)
    
        if isinstance(key, tuple) and level == 0:
    
            try:
                if key in self.levels[0]:
                    indexer = self._get_level_indexer(key, level=level)
                    new_index = maybe_mi_droplevels(indexer, [0], drop_level)
                    return indexer, new_index
            except TypeError:
                pass
    
            if not any(isinstance(k, slice) for k in key):
    
                # partial selection
                # optionally get indexer to avoid re-calculation
                def partial_selection(key, indexer=None):
                    if indexer is None:
                        indexer = self.get_loc(key)
                    ilevels = [
                        i for i in range(len(key)) if key[i] != slice(None, None)
                    ]
                    return indexer, maybe_mi_droplevels(indexer, ilevels, drop_level)
    
                if len(key) == self.nlevels and self.is_unique:
                    # Complete key in unique index -> standard get_loc
                    try:
                        return (self._engine.get_loc(key), None)
                    except KeyError as e:
>                       raise KeyError(key) from e
E                       KeyError: ('A', 'C')

pandas/core/indexes/multi.py:2842: KeyError
__ test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans[nunique-0] __

self = MultiIndex([('A', 'A'),
            ('A', 'B'),
            ('B', 'A'),
            ('B', 'B')],
           names=['cat_1', 'cat_2'])
key = ('A', 'C'), level = 0, drop_level = True

    def get_loc_level(self, key, level=0, drop_level: bool = True):
        """
        Get both the location for the requested label(s) and the
        resulting sliced index.
    
        Parameters
        ----------
        key : label or sequence of labels
        level : int/level name or list thereof, optional
        drop_level : bool, default True
            if ``False``, the resulting index will not drop any level.
    
        Returns
        -------
        loc : A 2-tuple where the elements are:
              Element 0: int, slice object or boolean array
              Element 1: The resulting sliced multiindex/index. If the key
              contains all levels, this will be ``None``.
    
        See Also
        --------
        MultiIndex.get_loc  : Get location for a label or a tuple of labels.
        MultiIndex.get_locs : Get location for a label/slice/list/mask or a
                              sequence of such.
    
        Examples
        --------
        >>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')],
        ...                                names=['A', 'B'])
    
        >>> mi.get_loc_level('b')
        (slice(1, 3, None), Index(['e', 'f'], dtype='object', name='B'))
    
        >>> mi.get_loc_level('e', level='B')
        (array([False,  True, False], dtype=bool),
        Index(['b'], dtype='object', name='A'))
    
        >>> mi.get_loc_level(['b', 'e'])
        (1, None)
        """
    
        # different name to distinguish from maybe_droplevels
        def maybe_mi_droplevels(indexer, levels, drop_level: bool):
            if not drop_level:
                return self[indexer]
            # kludgearound
            orig_index = new_index = self[indexer]
            levels = [self._get_level_number(i) for i in levels]
            for i in sorted(levels, reverse=True):
                try:
                    new_index = new_index.droplevel(i)
                except ValueError:
    
                    # no dropping here
                    return orig_index
            return new_index
    
        if isinstance(level, (tuple, list)):
            if len(key) != len(level):
                raise AssertionError(
                    "Key for location must have same length as number of levels"
                )
            result = None
            for lev, k in zip(level, key):
                loc, new_index = self.get_loc_level(k, level=lev)
                if isinstance(loc, slice):
                    mask = np.zeros(len(self), dtype=bool)
                    mask[loc] = True
                    loc = mask
    
                result = loc if result is None else result & loc
    
            return result, maybe_mi_droplevels(result, level, drop_level)
    
        level = self._get_level_number(level)
    
        # kludge for #1796
        if isinstance(key, list):
            key = tuple(key)
    
        if isinstance(key, tuple) and level == 0:
    
            try:
                if key in self.levels[0]:
                    indexer = self._get_level_indexer(key, level=level)
                    new_index = maybe_mi_droplevels(indexer, [0], drop_level)
                    return indexer, new_index
            except TypeError:
                pass
    
            if not any(isinstance(k, slice) for k in key):
    
                # partial selection
                # optionally get indexer to avoid re-calculation
                def partial_selection(key, indexer=None):
                    if indexer is None:
                        indexer = self.get_loc(key)
                    ilevels = [
                        i for i in range(len(key)) if key[i] != slice(None, None)
                    ]
                    return indexer, maybe_mi_droplevels(indexer, ilevels, drop_level)
    
                if len(key) == self.nlevels and self.is_unique:
                    # Complete key in unique index -> standard get_loc
                    try:
>                       return (self._engine.get_loc(key), None)

pandas/core/indexes/multi.py:2840: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   return self._base.get_loc(self, lab_int)

pandas/_libs/index.pyx:702: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   cpdef get_loc(self, object val):

pandas/_libs/index.pyx:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   return self.mapping.get_item(val)

pandas/_libs/index.pyx:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   cpdef get_item(self, uint64_t val):

pandas/_libs/hashtable_class_helper.pxi:693: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   raise KeyError(val)
E   KeyError: 7

pandas/_libs/hashtable_class_helper.pxi:700: KeyError

The above exception was the direct cause of the following exception:

func = 'nunique', zero_or_nan = 0

    @pytest.mark.parametrize(
        "func, zero_or_nan",
        [
            ("all", np.NaN),
            ("any", np.NaN),
            ("count", 0),
            ("first", np.NaN),
            ("idxmax", np.NaN),
            ("idxmin", np.NaN),
            ("last", np.NaN),
            ("mad", np.NaN),
            ("max", np.NaN),
            ("mean", np.NaN),
            ("median", np.NaN),
            ("min", np.NaN),
            ("nth", np.NaN),
            ("nunique", 0),
            ("prod", np.NaN),
            ("quantile", np.NaN),
            ("sem", np.NaN),
            ("size", 0),
            ("skew", np.NaN),
            ("std", np.NaN),
            ("sum", np.NaN),
            ("var", np.NaN),
        ],
    )
    def test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans(func, zero_or_nan):
        # GH 17605
        # Tests whether the unobserved categories in the result contain 0 or NaN
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABC")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABC")),
                "value": [0.1] * 4,
            }
        )
        unobserved = [tuple("AC"), tuple("BC"), tuple("CA"), tuple("CB"), tuple("CC")]
        args = {"nth": [0]}.get(func, [])
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=False)["value"]
        agg = getattr(series_groupby, func)
        result = agg(*args)
    
        for idx in unobserved:
>           val = result.loc[idx]

pandas/tests/groupby/test_categorical.py:1328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
pandas/core/indexing.py:1387: in __getitem__
    return self._getitem_tuple(key)
pandas/core/indexing.py:798: in _getitem_tuple
    return self._getitem_lowerdim(tup)
pandas/core/indexing.py:902: in _getitem_lowerdim
    result = self._handle_lowerdim_multi_index_axis0(tup)
pandas/core/indexing.py:882: in _handle_lowerdim_multi_index_axis0
    raise ek
pandas/core/indexing.py:874: in _handle_lowerdim_multi_index_axis0
    return self._get_label(tup, axis=axis)
pandas/core/indexing.py:156: in _get_label
    return self.obj._xs(label, axis=axis)
pandas/core/generic.py:3596: in xs
    loc, new_index = self.index.get_loc_level(key, drop_level=drop_level)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiIndex([('A', 'A'),
            ('A', 'B'),
            ('B', 'A'),
            ('B', 'B')],
           names=['cat_1', 'cat_2'])
key = ('A', 'C'), level = 0, drop_level = True

    def get_loc_level(self, key, level=0, drop_level: bool = True):
        """
        Get both the location for the requested label(s) and the
        resulting sliced index.
    
        Parameters
        ----------
        key : label or sequence of labels
        level : int/level name or list thereof, optional
        drop_level : bool, default True
            if ``False``, the resulting index will not drop any level.
    
        Returns
        -------
        loc : A 2-tuple where the elements are:
              Element 0: int, slice object or boolean array
              Element 1: The resulting sliced multiindex/index. If the key
              contains all levels, this will be ``None``.
    
        See Also
        --------
        MultiIndex.get_loc  : Get location for a label or a tuple of labels.
        MultiIndex.get_locs : Get location for a label/slice/list/mask or a
                              sequence of such.
    
        Examples
        --------
        >>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')],
        ...                                names=['A', 'B'])
    
        >>> mi.get_loc_level('b')
        (slice(1, 3, None), Index(['e', 'f'], dtype='object', name='B'))
    
        >>> mi.get_loc_level('e', level='B')
        (array([False,  True, False], dtype=bool),
        Index(['b'], dtype='object', name='A'))
    
        >>> mi.get_loc_level(['b', 'e'])
        (1, None)
        """
    
        # different name to distinguish from maybe_droplevels
        def maybe_mi_droplevels(indexer, levels, drop_level: bool):
            if not drop_level:
                return self[indexer]
            # kludgearound
            orig_index = new_index = self[indexer]
            levels = [self._get_level_number(i) for i in levels]
            for i in sorted(levels, reverse=True):
                try:
                    new_index = new_index.droplevel(i)
                except ValueError:
    
                    # no dropping here
                    return orig_index
            return new_index
    
        if isinstance(level, (tuple, list)):
            if len(key) != len(level):
                raise AssertionError(
                    "Key for location must have same length as number of levels"
                )
            result = None
            for lev, k in zip(level, key):
                loc, new_index = self.get_loc_level(k, level=lev)
                if isinstance(loc, slice):
                    mask = np.zeros(len(self), dtype=bool)
                    mask[loc] = True
                    loc = mask
    
                result = loc if result is None else result & loc
    
            return result, maybe_mi_droplevels(result, level, drop_level)
    
        level = self._get_level_number(level)
    
        # kludge for #1796
        if isinstance(key, list):
            key = tuple(key)
    
        if isinstance(key, tuple) and level == 0:
    
            try:
                if key in self.levels[0]:
                    indexer = self._get_level_indexer(key, level=level)
                    new_index = maybe_mi_droplevels(indexer, [0], drop_level)
                    return indexer, new_index
            except TypeError:
                pass
    
            if not any(isinstance(k, slice) for k in key):
    
                # partial selection
                # optionally get indexer to avoid re-calculation
                def partial_selection(key, indexer=None):
                    if indexer is None:
                        indexer = self.get_loc(key)
                    ilevels = [
                        i for i in range(len(key)) if key[i] != slice(None, None)
                    ]
                    return indexer, maybe_mi_droplevels(indexer, ilevels, drop_level)
    
                if len(key) == self.nlevels and self.is_unique:
                    # Complete key in unique index -> standard get_loc
                    try:
                        return (self._engine.get_loc(key), None)
                    except KeyError as e:
>                       raise KeyError(key) from e
E                       KeyError: ('A', 'C')

pandas/core/indexes/multi.py:2842: KeyError
___ test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans[size-0] ____

self = MultiIndex([('A', 'A'),
            ('A', 'B'),
            ('B', 'A'),
            ('B', 'B')],
           names=['cat_1', 'cat_2'])
key = ('A', 'C'), level = 0, drop_level = True

    def get_loc_level(self, key, level=0, drop_level: bool = True):
        """
        Get both the location for the requested label(s) and the
        resulting sliced index.
    
        Parameters
        ----------
        key : label or sequence of labels
        level : int/level name or list thereof, optional
        drop_level : bool, default True
            if ``False``, the resulting index will not drop any level.
    
        Returns
        -------
        loc : A 2-tuple where the elements are:
              Element 0: int, slice object or boolean array
              Element 1: The resulting sliced multiindex/index. If the key
              contains all levels, this will be ``None``.
    
        See Also
        --------
        MultiIndex.get_loc  : Get location for a label or a tuple of labels.
        MultiIndex.get_locs : Get location for a label/slice/list/mask or a
                              sequence of such.
    
        Examples
        --------
        >>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')],
        ...                                names=['A', 'B'])
    
        >>> mi.get_loc_level('b')
        (slice(1, 3, None), Index(['e', 'f'], dtype='object', name='B'))
    
        >>> mi.get_loc_level('e', level='B')
        (array([False,  True, False], dtype=bool),
        Index(['b'], dtype='object', name='A'))
    
        >>> mi.get_loc_level(['b', 'e'])
        (1, None)
        """
    
        # different name to distinguish from maybe_droplevels
        def maybe_mi_droplevels(indexer, levels, drop_level: bool):
            if not drop_level:
                return self[indexer]
            # kludgearound
            orig_index = new_index = self[indexer]
            levels = [self._get_level_number(i) for i in levels]
            for i in sorted(levels, reverse=True):
                try:
                    new_index = new_index.droplevel(i)
                except ValueError:
    
                    # no dropping here
                    return orig_index
            return new_index
    
        if isinstance(level, (tuple, list)):
            if len(key) != len(level):
                raise AssertionError(
                    "Key for location must have same length as number of levels"
                )
            result = None
            for lev, k in zip(level, key):
                loc, new_index = self.get_loc_level(k, level=lev)
                if isinstance(loc, slice):
                    mask = np.zeros(len(self), dtype=bool)
                    mask[loc] = True
                    loc = mask
    
                result = loc if result is None else result & loc
    
            return result, maybe_mi_droplevels(result, level, drop_level)
    
        level = self._get_level_number(level)
    
        # kludge for #1796
        if isinstance(key, list):
            key = tuple(key)
    
        if isinstance(key, tuple) and level == 0:
    
            try:
                if key in self.levels[0]:
                    indexer = self._get_level_indexer(key, level=level)
                    new_index = maybe_mi_droplevels(indexer, [0], drop_level)
                    return indexer, new_index
            except TypeError:
                pass
    
            if not any(isinstance(k, slice) for k in key):
    
                # partial selection
                # optionally get indexer to avoid re-calculation
                def partial_selection(key, indexer=None):
                    if indexer is None:
                        indexer = self.get_loc(key)
                    ilevels = [
                        i for i in range(len(key)) if key[i] != slice(None, None)
                    ]
                    return indexer, maybe_mi_droplevels(indexer, ilevels, drop_level)
    
                if len(key) == self.nlevels and self.is_unique:
                    # Complete key in unique index -> standard get_loc
                    try:
>                       return (self._engine.get_loc(key), None)

pandas/core/indexes/multi.py:2840: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   return self._base.get_loc(self, lab_int)

pandas/_libs/index.pyx:702: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   cpdef get_loc(self, object val):

pandas/_libs/index.pyx:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   return self.mapping.get_item(val)

pandas/_libs/index.pyx:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   cpdef get_item(self, uint64_t val):

pandas/_libs/hashtable_class_helper.pxi:693: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   raise KeyError(val)
E   KeyError: 7

pandas/_libs/hashtable_class_helper.pxi:700: KeyError

The above exception was the direct cause of the following exception:

func = 'size', zero_or_nan = 0

    @pytest.mark.parametrize(
        "func, zero_or_nan",
        [
            ("all", np.NaN),
            ("any", np.NaN),
            ("count", 0),
            ("first", np.NaN),
            ("idxmax", np.NaN),
            ("idxmin", np.NaN),
            ("last", np.NaN),
            ("mad", np.NaN),
            ("max", np.NaN),
            ("mean", np.NaN),
            ("median", np.NaN),
            ("min", np.NaN),
            ("nth", np.NaN),
            ("nunique", 0),
            ("prod", np.NaN),
            ("quantile", np.NaN),
            ("sem", np.NaN),
            ("size", 0),
            ("skew", np.NaN),
            ("std", np.NaN),
            ("sum", np.NaN),
            ("var", np.NaN),
        ],
    )
    def test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans(func, zero_or_nan):
        # GH 17605
        # Tests whether the unobserved categories in the result contain 0 or NaN
        df = pd.DataFrame(
            {
                "cat_1": pd.Categorical(list("AABB"), categories=list("ABC")),
                "cat_2": pd.Categorical(list("AB") * 2, categories=list("ABC")),
                "value": [0.1] * 4,
            }
        )
        unobserved = [tuple("AC"), tuple("BC"), tuple("CA"), tuple("CB"), tuple("CC")]
        args = {"nth": [0]}.get(func, [])
    
        series_groupby = df.groupby(["cat_1", "cat_2"], observed=False)["value"]
        agg = getattr(series_groupby, func)
        result = agg(*args)
    
        for idx in unobserved:
>           val = result.loc[idx]

pandas/tests/groupby/test_categorical.py:1328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
pandas/core/indexing.py:1387: in __getitem__
    return self._getitem_tuple(key)
pandas/core/indexing.py:798: in _getitem_tuple
    return self._getitem_lowerdim(tup)
pandas/core/indexing.py:902: in _getitem_lowerdim
    result = self._handle_lowerdim_multi_index_axis0(tup)
pandas/core/indexing.py:882: in _handle_lowerdim_multi_index_axis0
    raise ek
pandas/core/indexing.py:874: in _handle_lowerdim_multi_index_axis0
    return self._get_label(tup, axis=axis)
pandas/core/indexing.py:156: in _get_label
    return self.obj._xs(label, axis=axis)
pandas/core/generic.py:3596: in xs
    loc, new_index = self.index.get_loc_level(key, drop_level=drop_level)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiIndex([('A', 'A'),
            ('A', 'B'),
            ('B', 'A'),
            ('B', 'B')],
           names=['cat_1', 'cat_2'])
key = ('A', 'C'), level = 0, drop_level = True

    def get_loc_level(self, key, level=0, drop_level: bool = True):
        """
        Get both the location for the requested label(s) and the
        resulting sliced index.
    
        Parameters
        ----------
        key : label or sequence of labels
        level : int/level name or list thereof, optional
        drop_level : bool, default True
            if ``False``, the resulting index will not drop any level.
    
        Returns
        -------
        loc : A 2-tuple where the elements are:
              Element 0: int, slice object or boolean array
              Element 1: The resulting sliced multiindex/index. If the key
              contains all levels, this will be ``None``.
    
        See Also
        --------
        MultiIndex.get_loc  : Get location for a label or a tuple of labels.
        MultiIndex.get_locs : Get location for a label/slice/list/mask or a
                              sequence of such.
    
        Examples
        --------
        >>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')],
        ...                                names=['A', 'B'])
    
        >>> mi.get_loc_level('b')
        (slice(1, 3, None), Index(['e', 'f'], dtype='object', name='B'))
    
        >>> mi.get_loc_level('e', level='B')
        (array([False,  True, False], dtype=bool),
        Index(['b'], dtype='object', name='A'))
    
        >>> mi.get_loc_level(['b', 'e'])
        (1, None)
        """
    
        # different name to distinguish from maybe_droplevels
        def maybe_mi_droplevels(indexer, levels, drop_level: bool):
            if not drop_level:
                return self[indexer]
            # kludgearound
            orig_index = new_index = self[indexer]
            levels = [self._get_level_number(i) for i in levels]
            for i in sorted(levels, reverse=True):
                try:
                    new_index = new_index.droplevel(i)
                except ValueError:
    
                    # no dropping here
                    return orig_index
            return new_index
    
        if isinstance(level, (tuple, list)):
            if len(key) != len(level):
                raise AssertionError(
                    "Key for location must have same length as number of levels"
                )
            result = None
            for lev, k in zip(level, key):
                loc, new_index = self.get_loc_level(k, level=lev)
                if isinstance(loc, slice):
                    mask = np.zeros(len(self), dtype=bool)
                    mask[loc] = True
                    loc = mask
    
                result = loc if result is None else result & loc
    
            return result, maybe_mi_droplevels(result, level, drop_level)
    
        level = self._get_level_number(level)
    
        # kludge for #1796
        if isinstance(key, list):
            key = tuple(key)
    
        if isinstance(key, tuple) and level == 0:
    
            try:
                if key in self.levels[0]:
                    indexer = self._get_level_indexer(key, level=level)
                    new_index = maybe_mi_droplevels(indexer, [0], drop_level)
                    return indexer, new_index
            except TypeError:
                pass
    
            if not any(isinstance(k, slice) for k in key):
    
                # partial selection
                # optionally get indexer to avoid re-calculation
                def partial_selection(key, indexer=None):
                    if indexer is None:
                        indexer = self.get_loc(key)
                    ilevels = [
                        i for i in range(len(key)) if key[i] != slice(None, None)
                    ]
                    return indexer, maybe_mi_droplevels(indexer, ilevels, drop_level)
    
                if len(key) == self.nlevels and self.is_unique:
                    # Complete key in unique index -> standard get_loc
                    try:
                        return (self._engine.get_loc(key), None)
                    except KeyError as e:
>                       raise KeyError(key) from e
E                       KeyError: ('A', 'C')

pandas/core/indexes/multi.py:2842: KeyError
=========================== short test summary info ============================
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans[count-0]
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans[nth-nan]
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans[nunique-0]
FAILED pandas/tests/groupby/test_categorical.py::test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans[size-0]
========================= 4 failed, 18 passed in 3.04s =========================
