[
    {
        "name": "pandas.tests.io.excel.conftest.frame#11",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.frame(float_frame)",
        "snippet": "def frame(float_frame):\n    \"\"\"\n    Returns the first ten items in fixture \"float_frame\".\n    \"\"\"\n    return float_frame[:10]",
        "begin_line": 11,
        "end_line": 15,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.tsframe#19",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.tsframe()",
        "snippet": "def tsframe():\n    return tm.makeTimeDataFrame()[:5]",
        "begin_line": 19,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.merge_cells#24",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.merge_cells(request)",
        "snippet": "def merge_cells(request):\n    return request.param",
        "begin_line": 24,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.df_ref#29",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.df_ref(datapath)",
        "snippet": "def df_ref(datapath):\n    \"\"\"\n    Obtain the reference data from read_csv with the Python engine.\n    \"\"\"\n    filepath = datapath(\"io\", \"data\", \"csv\", \"test1.csv\")\n    df_ref = read_csv(filepath, index_col=0, parse_dates=True, engine=\"python\")\n    return df_ref",
        "begin_line": 29,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.read_ext#39",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.read_ext(request)",
        "snippet": "def read_ext(request):\n    \"\"\"\n    Valid extensions for reading Excel files.\n    \"\"\"\n    return request.param",
        "begin_line": 39,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.check_for_file_leaks#47",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.check_for_file_leaks()",
        "snippet": "def check_for_file_leaks():\n    \"\"\"\n    Fixture to run around every test to ensure that we are not leaking files.\n\n    See also\n    --------\n    _test_decorators.check_file_leaks\n    \"\"\"\n    # GH#30162\n    psutil = td.safe_import(\"psutil\")\n    if not psutil:\n        yield\n\n    else:\n        proc = psutil.Process()\n        flist = proc.open_files()\n        yield\n        flist2 = proc.open_files()\n        assert flist == flist2",
        "begin_line": 47,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.pytables.conftest.setup_path#7",
        "src_path": "pandas/tests/io/pytables/conftest.py",
        "class_name": "pandas.tests.io.pytables.conftest",
        "signature": "pandas.tests.io.pytables.conftest.setup_path()",
        "snippet": "def setup_path():\n    \"\"\"Fixture for setup path\"\"\"\n    return f\"tmp.__{tm.rands(10)}__.h5\"",
        "begin_line": 7,
        "end_line": 9,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.pytables.conftest.setup_mode#13",
        "src_path": "pandas/tests/io/pytables/conftest.py",
        "class_name": "pandas.tests.io.pytables.conftest",
        "signature": "pandas.tests.io.pytables.conftest.setup_mode()",
        "snippet": "def setup_mode():\n    \"\"\" Reset testing mode fixture\"\"\"\n    tm.reset_testing_mode()\n    yield\n    tm.set_testing_mode()",
        "begin_line": 13,
        "end_line": 17,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.sas.test_xport.numeric_as_float#17",
        "src_path": "pandas/tests/io/sas/test_xport.py",
        "class_name": "pandas.tests.io.sas.test_xport",
        "signature": "pandas.tests.io.sas.test_xport.numeric_as_float(data)",
        "snippet": "def numeric_as_float(data):\n    for v in data.columns:\n        if data[v].dtype is np.dtype(\"int64\"):\n            data[v] = data[v].astype(np.float64)",
        "begin_line": 17,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.sas.test_xport.TestXport.setup_method#25",
        "src_path": "pandas/tests/io/sas/test_xport.py",
        "class_name": "pandas.tests.io.sas.test_xport.TestXport",
        "signature": "pandas.tests.io.sas.test_xport.TestXport.setup_method(self, datapath)",
        "snippet": "    def setup_method(self, datapath):\n        self.dirpath = datapath(\"io\", \"sas\", \"data\")\n        self.file01 = os.path.join(self.dirpath, \"DEMO_G.xpt\")\n        self.file02 = os.path.join(self.dirpath, \"SSHSV1_A.xpt\")\n        self.file02b = open(os.path.join(self.dirpath, \"SSHSV1_A.xpt\"), \"rb\")\n        self.file03 = os.path.join(self.dirpath, \"DRXFCD_G.xpt\")\n        self.file04 = os.path.join(self.dirpath, \"paxraw_d_short.xpt\")",
        "begin_line": 25,
        "end_line": 31,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.sas.test_xport.TestXport.test1_basic#33",
        "src_path": "pandas/tests/io/sas/test_xport.py",
        "class_name": "pandas.tests.io.sas.test_xport.TestXport",
        "signature": "pandas.tests.io.sas.test_xport.TestXport.test1_basic(self)",
        "snippet": "    def test1_basic(self):\n        # Tests with DEMO_G.xpt (all numeric file)\n\n        # Compare to this\n        data_csv = pd.read_csv(self.file01.replace(\".xpt\", \".csv\"))\n        numeric_as_float(data_csv)\n\n        # Read full file\n        data = read_sas(self.file01, format=\"xport\")\n        tm.assert_frame_equal(data, data_csv)\n        num_rows = data.shape[0]\n\n        # Test reading beyond end of file\n        reader = read_sas(self.file01, format=\"xport\", iterator=True)\n        data = reader.read(num_rows + 100)\n        assert data.shape[0] == num_rows\n        reader.close()\n\n        # Test incremental read with `read` method.\n        reader = read_sas(self.file01, format=\"xport\", iterator=True)\n        data = reader.read(10)\n        reader.close()\n        tm.assert_frame_equal(data, data_csv.iloc[0:10, :])\n\n        # Test incremental read with `get_chunk` method.\n        reader = read_sas(self.file01, format=\"xport\", chunksize=10)\n        data = reader.get_chunk()\n        reader.close()\n        tm.assert_frame_equal(data, data_csv.iloc[0:10, :])\n\n        # Test read in loop\n        m = 0\n        reader = read_sas(self.file01, format=\"xport\", chunksize=100)\n        for x in reader:\n            m += x.shape[0]\n        reader.close()\n        assert m == num_rows\n\n        # Read full file with `read_sas` method\n        data = read_sas(self.file01)\n        tm.assert_frame_equal(data, data_csv)",
        "begin_line": 33,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.sas.test_xport.TestXport.test1_index#75",
        "src_path": "pandas/tests/io/sas/test_xport.py",
        "class_name": "pandas.tests.io.sas.test_xport.TestXport",
        "signature": "pandas.tests.io.sas.test_xport.TestXport.test1_index(self)",
        "snippet": "    def test1_index(self):\n        # Tests with DEMO_G.xpt using index (all numeric file)\n\n        # Compare to this\n        data_csv = pd.read_csv(self.file01.replace(\".xpt\", \".csv\"))\n        data_csv = data_csv.set_index(\"SEQN\")\n        numeric_as_float(data_csv)\n\n        # Read full file\n        data = read_sas(self.file01, index=\"SEQN\", format=\"xport\")\n        tm.assert_frame_equal(data, data_csv, check_index_type=False)\n\n        # Test incremental read with `read` method.\n        reader = read_sas(self.file01, index=\"SEQN\", format=\"xport\", iterator=True)\n        data = reader.read(10)\n        reader.close()\n        tm.assert_frame_equal(data, data_csv.iloc[0:10, :], check_index_type=False)\n\n        # Test incremental read with `get_chunk` method.\n        reader = read_sas(self.file01, index=\"SEQN\", format=\"xport\", chunksize=10)\n        data = reader.get_chunk()\n        reader.close()\n        tm.assert_frame_equal(data, data_csv.iloc[0:10, :], check_index_type=False)",
        "begin_line": 75,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.sas.test_xport.TestXport.test1_incremental#99",
        "src_path": "pandas/tests/io/sas/test_xport.py",
        "class_name": "pandas.tests.io.sas.test_xport.TestXport",
        "signature": "pandas.tests.io.sas.test_xport.TestXport.test1_incremental(self)",
        "snippet": "    def test1_incremental(self):\n        # Test with DEMO_G.xpt, reading full file incrementally\n\n        data_csv = pd.read_csv(self.file01.replace(\".xpt\", \".csv\"))\n        data_csv = data_csv.set_index(\"SEQN\")\n        numeric_as_float(data_csv)\n\n        reader = read_sas(self.file01, index=\"SEQN\", chunksize=1000)\n\n        all_data = list(reader)\n        data = pd.concat(all_data, axis=0)\n\n        tm.assert_frame_equal(data, data_csv, check_index_type=False)",
        "begin_line": 99,
        "end_line": 111,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.sas.test_xport.TestXport.test2#113",
        "src_path": "pandas/tests/io/sas/test_xport.py",
        "class_name": "pandas.tests.io.sas.test_xport.TestXport",
        "signature": "pandas.tests.io.sas.test_xport.TestXport.test2(self)",
        "snippet": "    def test2(self):\n        # Test with SSHSV1_A.xpt\n\n        # Compare to this\n        data_csv = pd.read_csv(self.file02.replace(\".xpt\", \".csv\"))\n        numeric_as_float(data_csv)\n\n        data = read_sas(self.file02)\n        tm.assert_frame_equal(data, data_csv)",
        "begin_line": 113,
        "end_line": 121,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.sas.test_xport.TestXport.test2_binary#123",
        "src_path": "pandas/tests/io/sas/test_xport.py",
        "class_name": "pandas.tests.io.sas.test_xport.TestXport",
        "signature": "pandas.tests.io.sas.test_xport.TestXport.test2_binary(self)",
        "snippet": "    def test2_binary(self):\n        # Test with SSHSV1_A.xpt, read as a binary file\n\n        # Compare to this\n        data_csv = pd.read_csv(self.file02.replace(\".xpt\", \".csv\"))\n        numeric_as_float(data_csv)\n\n        data = read_sas(self.file02b, format=\"xport\")\n        tm.assert_frame_equal(data, data_csv)",
        "begin_line": 123,
        "end_line": 131,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.sas.test_xport.TestXport.test_multiple_types#133",
        "src_path": "pandas/tests/io/sas/test_xport.py",
        "class_name": "pandas.tests.io.sas.test_xport.TestXport",
        "signature": "pandas.tests.io.sas.test_xport.TestXport.test_multiple_types(self)",
        "snippet": "    def test_multiple_types(self):\n        # Test with DRXFCD_G.xpt (contains text and numeric variables)\n\n        # Compare to this\n        data_csv = pd.read_csv(self.file03.replace(\".xpt\", \".csv\"))\n\n        data = read_sas(self.file03, encoding=\"utf-8\")\n        tm.assert_frame_equal(data, data_csv)",
        "begin_line": 133,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.sas.test_xport.TestXport.test_truncated_float_support#142",
        "src_path": "pandas/tests/io/sas/test_xport.py",
        "class_name": "pandas.tests.io.sas.test_xport.TestXport",
        "signature": "pandas.tests.io.sas.test_xport.TestXport.test_truncated_float_support(self)",
        "snippet": "    def test_truncated_float_support(self):\n        # Test with paxraw_d_short.xpt, a shortened version of:\n        # http://wwwn.cdc.gov/Nchs/Nhanes/2005-2006/PAXRAW_D.ZIP\n        # This file has truncated floats (5 bytes in this case).\n\n        # GH 11713\n\n        data_csv = pd.read_csv(self.file04.replace(\".xpt\", \".csv\"))\n\n        data = read_sas(self.file04, format=\"xport\")\n        tm.assert_frame_equal(data.astype(\"int64\"), data_csv)",
        "begin_line": 142,
        "end_line": 152,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.pytables.common.safe_remove#16",
        "src_path": "pandas/tests/io/pytables/common.py",
        "class_name": "pandas.tests.io.pytables.common",
        "signature": "pandas.tests.io.pytables.common.safe_remove(path)",
        "snippet": "def safe_remove(path):\n    if path is not None:\n        try:\n            os.remove(path)\n        except OSError:\n            pass",
        "begin_line": 16,
        "end_line": 21,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.pytables.common.safe_close#24",
        "src_path": "pandas/tests/io/pytables/common.py",
        "class_name": "pandas.tests.io.pytables.common",
        "signature": "pandas.tests.io.pytables.common.safe_close(store)",
        "snippet": "def safe_close(store):\n    try:\n        if store is not None:\n            store.close()\n    except IOError:\n        pass",
        "begin_line": 24,
        "end_line": 29,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.pytables.common.create_tempfile#32",
        "src_path": "pandas/tests/io/pytables/common.py",
        "class_name": "pandas.tests.io.pytables.common",
        "signature": "pandas.tests.io.pytables.common.create_tempfile(path)",
        "snippet": "def create_tempfile(path):\n    \"\"\" create an unopened named temporary file \"\"\"\n    return os.path.join(tempfile.gettempdir(), path)",
        "begin_line": 32,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.pytables.common.ensure_clean_store#39",
        "src_path": "pandas/tests/io/pytables/common.py",
        "class_name": "pandas.tests.io.pytables.common",
        "signature": "pandas.tests.io.pytables.common.ensure_clean_store(path, mode='a', complevel=None, complib=None, fletcher32=False)",
        "snippet": "def ensure_clean_store(path, mode=\"a\", complevel=None, complib=None, fletcher32=False):\n\n    try:\n\n        # put in the temporary path if we don't have one already\n        if not len(os.path.dirname(path)):\n            path = create_tempfile(path)\n\n        store = HDFStore(\n            path, mode=mode, complevel=complevel, complib=complib, fletcher32=False\n        )\n        yield store\n    finally:\n        safe_close(store)\n        if mode == \"w\" or mode == \"a\":\n            safe_remove(path)",
        "begin_line": 39,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.pytables.common.ensure_clean_path#58",
        "src_path": "pandas/tests/io/pytables/common.py",
        "class_name": "pandas.tests.io.pytables.common",
        "signature": "pandas.tests.io.pytables.common.ensure_clean_path(path)",
        "snippet": "def ensure_clean_path(path):\n    \"\"\"\n    return essentially a named temporary file that is not opened\n    and deleted on exiting; if path is a list, then create and\n    return list of filenames\n    \"\"\"\n    try:\n        if isinstance(path, list):\n            filenames = [create_tempfile(p) for p in path]\n            yield filenames\n        else:\n            filenames = [create_tempfile(path)]\n            yield filenames[0]\n    finally:\n        for f in filenames:\n            safe_remove(f)",
        "begin_line": 58,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.pytables.common._maybe_remove#76",
        "src_path": "pandas/tests/io/pytables/common.py",
        "class_name": "pandas.tests.io.pytables.common",
        "signature": "pandas.tests.io.pytables.common._maybe_remove(store, key)",
        "snippet": "def _maybe_remove(store, key):\n    \"\"\"\n    For tests using tables, try removing the table to be sure there is\n    no content from previous tests using the same table name.\n    \"\"\"\n    try:\n        store.remove(key)\n    except (ValueError, KeyError):\n        pass",
        "begin_line": 76,
        "end_line": 84,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.conftest.tips_file#11",
        "src_path": "pandas/tests/io/conftest.py",
        "class_name": "pandas.tests.io.conftest",
        "signature": "pandas.tests.io.conftest.tips_file(datapath)",
        "snippet": "def tips_file(datapath):\n    \"\"\"Path to the tips dataset\"\"\"\n    return datapath(\"io\", \"parser\", \"data\", \"tips.csv\")",
        "begin_line": 11,
        "end_line": 13,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.conftest.jsonl_file#17",
        "src_path": "pandas/tests/io/conftest.py",
        "class_name": "pandas.tests.io.conftest",
        "signature": "pandas.tests.io.conftest.jsonl_file(datapath)",
        "snippet": "def jsonl_file(datapath):\n    \"\"\"Path a JSONL dataset\"\"\"\n    return datapath(\"io\", \"parser\", \"data\", \"items.jsonl\")",
        "begin_line": 17,
        "end_line": 19,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.conftest.salaries_table#23",
        "src_path": "pandas/tests/io/conftest.py",
        "class_name": "pandas.tests.io.conftest",
        "signature": "pandas.tests.io.conftest.salaries_table(datapath)",
        "snippet": "def salaries_table(datapath):\n    \"\"\"DataFrame with the salaries dataset\"\"\"\n    return read_csv(datapath(\"io\", \"parser\", \"data\", \"salaries.csv\"), sep=\"\\t\")",
        "begin_line": 23,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.conftest.s3_resource#29",
        "src_path": "pandas/tests/io/conftest.py",
        "class_name": "pandas.tests.io.conftest",
        "signature": "pandas.tests.io.conftest.s3_resource(tips_file, jsonl_file)",
        "snippet": "def s3_resource(tips_file, jsonl_file):\n    \"\"\"\n    Fixture for mocking S3 interaction.\n\n    The primary bucket name is \"pandas-test\". The following datasets\n    are loaded.\n\n    - tips.csv\n    - tips.csv.gz\n    - tips.csv.bz2\n    - items.jsonl\n\n    A private bucket \"cant_get_it\" is also created. The boto3 s3 resource\n    is yielded by the fixture.\n    \"\"\"\n    s3fs = pytest.importorskip(\"s3fs\")\n    boto3 = pytest.importorskip(\"boto3\")\n\n    with tm.ensure_safe_environment_variables():\n        # temporary workaround as moto fails for botocore >= 1.11 otherwise,\n        # see https://github.com/spulec/moto/issues/1924 & 1952\n        os.environ.setdefault(\"AWS_ACCESS_KEY_ID\", \"foobar_key\")\n        os.environ.setdefault(\"AWS_SECRET_ACCESS_KEY\", \"foobar_secret\")\n\n        moto = pytest.importorskip(\"moto\")\n\n        test_s3_files = [\n            (\"tips#1.csv\", tips_file),\n            (\"tips.csv\", tips_file),\n            (\"tips.csv.gz\", tips_file + \".gz\"),\n            (\"tips.csv.bz2\", tips_file + \".bz2\"),\n            (\"items.jsonl\", jsonl_file),\n        ]\n\n        def add_tips_files(bucket_name):\n            for s3_key, file_name in test_s3_files:\n                with open(file_name, \"rb\") as f:\n                    conn.Bucket(bucket_name).put_object(Key=s3_key, Body=f)\n\n        try:\n            s3 = moto.mock_s3()\n            s3.start()\n\n            # see gh-16135\n            bucket = \"pandas-test\"\n            conn = boto3.resource(\"s3\", region_name=\"us-east-1\")\n\n            conn.create_bucket(Bucket=bucket)\n            add_tips_files(bucket)\n\n            conn.create_bucket(Bucket=\"cant_get_it\", ACL=\"private\")\n            add_tips_files(\"cant_get_it\")\n            s3fs.S3FileSystem.clear_instance_cache()\n            yield conn\n        finally:\n            s3.stop()",
        "begin_line": 29,
        "end_line": 84,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.conftest.add_tips_files#63",
        "src_path": "pandas/tests/io/conftest.py",
        "class_name": "pandas.tests.io.conftest",
        "signature": "pandas.tests.io.conftest.add_tips_files(bucket_name)",
        "snippet": "        def add_tips_files(bucket_name):\n            for s3_key, file_name in test_s3_files:\n                with open(file_name, \"rb\") as f:\n                    conn.Bucket(bucket_name).put_object(Key=s3_key, Body=f)",
        "begin_line": 63,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.update_kwargs#14",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.update_kwargs(self, kwargs)",
        "snippet": "    def update_kwargs(self, kwargs):\n        kwargs = kwargs.copy()\n        kwargs.update(dict(engine=self.engine, low_memory=self.low_memory))\n\n        return kwargs",
        "begin_line": 14,
        "end_line": 18,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.read_csv#20",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.read_csv(self, *args, **kwargs)",
        "snippet": "    def read_csv(self, *args, **kwargs):\n        kwargs = self.update_kwargs(kwargs)\n        return read_csv(*args, **kwargs)",
        "begin_line": 20,
        "end_line": 22,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.csv_dir_path#48",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.csv_dir_path(datapath)",
        "snippet": "def csv_dir_path(datapath):\n    \"\"\"\n    The directory path to the data files needed for parser tests.\n    \"\"\"\n    return datapath(\"io\", \"parser\", \"data\")",
        "begin_line": 48,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.csv1#56",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.csv1(csv_dir_path)",
        "snippet": "def csv1(csv_dir_path):\n    \"\"\"\n    The path to the data file \"test1.csv\" needed for parser tests.\n    \"\"\"\n    return os.path.join(csv_dir_path, \"test1.csv\")",
        "begin_line": 56,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.all_parsers#77",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.all_parsers(request)",
        "snippet": "def all_parsers(request):\n    \"\"\"\n    Fixture all of the CSV parsers.\n    \"\"\"\n    return request.param",
        "begin_line": 77,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.c_parser_only#85",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.c_parser_only(request)",
        "snippet": "def c_parser_only(request):\n    \"\"\"\n    Fixture all of the CSV parsers using the C engine.\n    \"\"\"\n    return request.param",
        "begin_line": 85,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.python_parser_only#93",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.python_parser_only(request)",
        "snippet": "def python_parser_only(request):\n    \"\"\"\n    Fixture all of the CSV parsers using the Python engine.\n    \"\"\"\n    return request.param",
        "begin_line": 93,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.utf_value#111",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.utf_value(request)",
        "snippet": "def utf_value(request):\n    \"\"\"\n    Fixture for all possible integer values for a UTF encoding.\n    \"\"\"\n    return request.param",
        "begin_line": 111,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.encoding_fmt#119",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.encoding_fmt(request)",
        "snippet": "def encoding_fmt(request):\n    \"\"\"\n    Fixture for all possible string formats of a UTF encoding.\n    \"\"\"\n    return request.param",
        "begin_line": 119,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.conftest.orient#5",
        "src_path": "pandas/tests/io/json/conftest.py",
        "class_name": "pandas.tests.io.json.conftest",
        "signature": "pandas.tests.io.json.conftest.orient(request)",
        "snippet": "def orient(request):\n    \"\"\"\n    Fixture for orients excluding the table format.\n    \"\"\"\n    return request.param",
        "begin_line": 5,
        "end_line": 9,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_series#94",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_series()",
        "snippet": "def _create_sp_series():\n    nan = np.nan\n\n    # nan-based\n    arr = np.arange(15, dtype=np.float64)\n    arr[7:12] = nan\n    arr[-1:] = nan\n\n    bseries = Series(SparseArray(arr, kind=\"block\"))\n    bseries.name = \"bseries\"\n    return bseries",
        "begin_line": 94,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_tsseries#107",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_tsseries()",
        "snippet": "def _create_sp_tsseries():\n    nan = np.nan\n\n    # nan-based\n    arr = np.arange(15, dtype=np.float64)\n    arr[7:12] = nan\n    arr[-1:] = nan\n\n    date_index = bdate_range(\"1/1/2011\", periods=len(arr))\n    bseries = Series(SparseArray(arr, kind=\"block\"), index=date_index)\n    bseries.name = \"btsseries\"\n    return bseries",
        "begin_line": 107,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_frame#121",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_frame()",
        "snippet": "def _create_sp_frame():\n    nan = np.nan\n\n    data = {\n        \"A\": [nan, nan, nan, 0, 1, 2, 3, 4, 5, 6],\n        \"B\": [0, 1, 2, nan, nan, nan, 3, 4, 5, 6],\n        \"C\": np.arange(10).astype(np.int64),\n        \"D\": [0, 1, 2, 3, 4, 5, nan, nan, nan, nan],\n    }\n\n    dates = bdate_range(\"1/1/2011\", periods=10)\n    return DataFrame(data, index=dates).apply(SparseArray)",
        "begin_line": 121,
        "end_line": 132,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.create_data#135",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.create_data()",
        "snippet": "def create_data():\n    \"\"\" create the pickle data \"\"\"\n    data = {\n        \"A\": [0.0, 1.0, 2.0, 3.0, np.nan],\n        \"B\": [0, 1, 0, 1, 0],\n        \"C\": [\"foo1\", \"foo2\", \"foo3\", \"foo4\", \"foo5\"],\n        \"D\": date_range(\"1/1/2009\", periods=5),\n        \"E\": [0.0, 1, Timestamp(\"20100101\"), \"foo\", 2.0],\n    }\n\n    scalars = dict(timestamp=Timestamp(\"20130101\"), period=Period(\"2012\", \"M\"))\n\n    index = dict(\n        int=Index(np.arange(10)),\n        date=date_range(\"20130101\", periods=10),\n        period=period_range(\"2013-01-01\", freq=\"M\", periods=10),\n        float=Index(np.arange(10, dtype=np.float64)),\n        uint=Index(np.arange(10, dtype=np.uint64)),\n        timedelta=timedelta_range(\"00:00:00\", freq=\"30T\", periods=10),\n    )\n\n    index[\"range\"] = RangeIndex(10)\n\n    if _loose_version >= LooseVersion(\"0.21\"):\n        from pandas import interval_range\n\n        index[\"interval\"] = interval_range(0, periods=10)\n\n    mi = dict(\n        reg2=MultiIndex.from_tuples(\n            tuple(\n                zip(\n                    *[\n                        [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n                        [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n                    ]\n                )\n            ),\n            names=[\"first\", \"second\"],\n        )\n    )\n\n    series = dict(\n        float=Series(data[\"A\"]),\n        int=Series(data[\"B\"]),\n        mixed=Series(data[\"E\"]),\n        ts=Series(\n            np.arange(10).astype(np.int64), index=date_range(\"20130101\", periods=10)\n        ),\n        mi=Series(\n            np.arange(5).astype(np.float64),\n            index=MultiIndex.from_tuples(\n                tuple(zip(*[[1, 1, 2, 2, 2], [3, 4, 3, 4, 5]])), names=[\"one\", \"two\"]\n            ),\n        ),\n        dup=Series(np.arange(5).astype(np.float64), index=[\"A\", \"B\", \"C\", \"D\", \"A\"]),\n        cat=Series(Categorical([\"foo\", \"bar\", \"baz\"])),\n        dt=Series(date_range(\"20130101\", periods=5)),\n        dt_tz=Series(date_range(\"20130101\", periods=5, tz=\"US/Eastern\")),\n        period=Series([Period(\"2000Q1\")] * 5),\n    )\n\n    mixed_dup_df = DataFrame(data)\n    mixed_dup_df.columns = list(\"ABCDA\")\n    frame = dict(\n        float=DataFrame({\"A\": series[\"float\"], \"B\": series[\"float\"] + 1}),\n        int=DataFrame({\"A\": series[\"int\"], \"B\": series[\"int\"] + 1}),\n        mixed=DataFrame({k: data[k] for k in [\"A\", \"B\", \"C\", \"D\"]}),\n        mi=DataFrame(\n            {\"A\": np.arange(5).astype(np.float64), \"B\": np.arange(5).astype(np.int64)},\n            index=MultiIndex.from_tuples(\n                tuple(\n                    zip(\n                        *[\n                            [\"bar\", \"bar\", \"baz\", \"baz\", \"baz\"],\n                            [\"one\", \"two\", \"one\", \"two\", \"three\"],\n                        ]\n                    )\n                ),\n                names=[\"first\", \"second\"],\n            ),\n        ),\n        dup=DataFrame(\n            np.arange(15).reshape(5, 3).astype(np.float64), columns=[\"A\", \"B\", \"A\"]\n        ),\n        cat_onecol=DataFrame({\"A\": Categorical([\"foo\", \"bar\"])}),\n        cat_and_float=DataFrame(\n            {\n                \"A\": Categorical([\"foo\", \"bar\", \"baz\"]),\n                \"B\": np.arange(3).astype(np.int64),\n            }\n        ),\n        mixed_dup=mixed_dup_df,\n        dt_mixed_tzs=DataFrame(\n            {\n                \"A\": Timestamp(\"20130102\", tz=\"US/Eastern\"),\n                \"B\": Timestamp(\"20130603\", tz=\"CET\"),\n            },\n            index=range(5),\n        ),\n        dt_mixed2_tzs=DataFrame(\n            {\n                \"A\": Timestamp(\"20130102\", tz=\"US/Eastern\"),\n                \"B\": Timestamp(\"20130603\", tz=\"CET\"),\n                \"C\": Timestamp(\"20130603\", tz=\"UTC\"),\n            },\n            index=range(5),\n        ),\n    )\n\n    cat = dict(\n        int8=Categorical(list(\"abcdefg\")),\n        int16=Categorical(np.arange(1000)),\n        int32=Categorical(np.arange(10000)),\n    )\n\n    timestamp = dict(\n        normal=Timestamp(\"2011-01-01\"),\n        nat=NaT,\n        tz=Timestamp(\"2011-01-01\", tz=\"US/Eastern\"),\n    )\n\n    timestamp[\"freq\"] = Timestamp(\"2011-01-01\", freq=\"D\")\n    timestamp[\"both\"] = Timestamp(\"2011-01-01\", tz=\"Asia/Tokyo\", freq=\"M\")\n\n    off = {\n        \"DateOffset\": DateOffset(years=1),\n        \"DateOffset_h_ns\": DateOffset(hour=6, nanoseconds=5824),\n        \"BusinessDay\": BusinessDay(offset=timedelta(seconds=9)),\n        \"BusinessHour\": BusinessHour(normalize=True, n=6, end=\"15:14\"),\n        \"CustomBusinessDay\": CustomBusinessDay(weekmask=\"Mon Fri\"),\n        \"SemiMonthBegin\": SemiMonthBegin(day_of_month=9),\n        \"SemiMonthEnd\": SemiMonthEnd(day_of_month=24),\n        \"MonthBegin\": MonthBegin(1),\n        \"MonthEnd\": MonthEnd(1),\n        \"QuarterBegin\": QuarterBegin(1),\n        \"QuarterEnd\": QuarterEnd(1),\n        \"Day\": Day(1),\n        \"YearBegin\": YearBegin(1),\n        \"YearEnd\": YearEnd(1),\n        \"Week\": Week(1),\n        \"Week_Tues\": Week(2, normalize=False, weekday=1),\n        \"WeekOfMonth\": WeekOfMonth(week=3, weekday=4),\n        \"LastWeekOfMonth\": LastWeekOfMonth(n=1, weekday=3),\n        \"FY5253\": FY5253(n=2, weekday=6, startingMonth=7, variation=\"last\"),\n        \"Easter\": Easter(),\n        \"Hour\": Hour(1),\n        \"Minute\": Minute(1),\n    }\n\n    return dict(\n        series=series,\n        frame=frame,\n        index=index,\n        scalars=scalars,\n        mi=mi,\n        sp_series=dict(float=_create_sp_series(), ts=_create_sp_tsseries()),\n        sp_frame=dict(float=_create_sp_frame()),\n        cat=cat,\n        timestamp=timestamp,\n        offsets=off,\n    )",
        "begin_line": 135,
        "end_line": 296,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.create_pickle_data#299",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.create_pickle_data()",
        "snippet": "def create_pickle_data():\n    data = create_data()\n\n    return data",
        "begin_line": 299,
        "end_line": 302,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.platform_name#305",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.platform_name()",
        "snippet": "def platform_name():\n    return \"_\".join(\n        [\n            str(pandas.__version__),\n            str(pl.machine()),\n            str(pl.system().lower()),\n            str(pl.python_version()),\n        ]\n    )",
        "begin_line": 305,
        "end_line": 313,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.write_legacy_pickles#316",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.write_legacy_pickles(output_dir)",
        "snippet": "def write_legacy_pickles(output_dir):\n\n    version = pandas.__version__\n\n    print(\n        \"This script generates a storage file for the current arch, system, \"\n        \"and python version\"\n    )\n    print(f\"  pandas version: {version}\")\n    print(f\"  output dir    : {output_dir}\")\n    print(\"  storage format: pickle\")\n\n    pth = f\"{platform_name()}.pickle\"\n\n    fh = open(os.path.join(output_dir, pth), \"wb\")\n    pickle.dump(create_pickle_data(), fh, pickle.HIGHEST_PROTOCOL)\n    fh.close()\n\n    print(f\"created pickle file: {pth}\")",
        "begin_line": 316,
        "end_line": 334,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.write_legacy_file#337",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.write_legacy_file()",
        "snippet": "def write_legacy_file():\n    # force our cwd to be the first searched\n    sys.path.insert(0, \".\")\n\n    if not (3 <= len(sys.argv) <= 4):\n        exit(\n            \"Specify output directory and storage type: generate_legacy_\"\n            \"storage_files.py <output_dir> <storage_type> \"\n        )\n\n    output_dir = str(sys.argv[1])\n    storage_type = str(sys.argv[2])\n\n    if storage_type == \"pickle\":\n        write_legacy_pickles(output_dir=output_dir)\n    else:\n        exit(\"storage_type must be one of {'pickle'}\")",
        "begin_line": 337,
        "end_line": 353,
        "comment": "",
        "is_bug": false
    }
]