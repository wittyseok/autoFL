[
    {
        "name": "spacy.tests.conftest.pytest_runtest_setup#12",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pytest_runtest_setup(item)",
        "snippet": "def pytest_runtest_setup(item):\n    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)\n\n    for opt in [\"slow\"]:\n        if opt in item.keywords and not getopt(opt):\n            pytest.skip(\"need --%s option to run\" % opt)",
        "begin_line": 12,
        "end_line": 24,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.getopt#13",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.getopt(opt)",
        "snippet": "    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)",
        "begin_line": 13,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tokenizer#31",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tokenizer()",
        "snippet": "def tokenizer():\n    return get_lang_class(\"xx\").Defaults.create_tokenizer()",
        "begin_line": 31,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ar_tokenizer#36",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ar_tokenizer()",
        "snippet": "def ar_tokenizer():\n    return get_lang_class(\"ar\").Defaults.create_tokenizer()",
        "begin_line": 36,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.bn_tokenizer#41",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.bn_tokenizer()",
        "snippet": "def bn_tokenizer():\n    return get_lang_class(\"bn\").Defaults.create_tokenizer()",
        "begin_line": 41,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ca_tokenizer#46",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ca_tokenizer()",
        "snippet": "def ca_tokenizer():\n    return get_lang_class(\"ca\").Defaults.create_tokenizer()",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.da_tokenizer#51",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.da_tokenizer()",
        "snippet": "def da_tokenizer():\n    return get_lang_class(\"da\").Defaults.create_tokenizer()",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.de_tokenizer#56",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.de_tokenizer()",
        "snippet": "def de_tokenizer():\n    return get_lang_class(\"de\").Defaults.create_tokenizer()",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.el_tokenizer#61",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.el_tokenizer()",
        "snippet": "def el_tokenizer():\n    return get_lang_class(\"el\").Defaults.create_tokenizer()",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_tokenizer#66",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_tokenizer()",
        "snippet": "def en_tokenizer():\n    return get_lang_class(\"en\").Defaults.create_tokenizer()",
        "begin_line": 66,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_vocab#71",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_vocab()",
        "snippet": "def en_vocab():\n    return get_lang_class(\"en\").Defaults.create_vocab()",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.es_tokenizer#82",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.es_tokenizer()",
        "snippet": "def es_tokenizer():\n    return get_lang_class(\"es\").Defaults.create_tokenizer()",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.eu_tokenizer#87",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.eu_tokenizer()",
        "snippet": "def eu_tokenizer():\n    return get_lang_class(\"eu\").Defaults.create_tokenizer()",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fi_tokenizer#92",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fi_tokenizer()",
        "snippet": "def fi_tokenizer():\n    return get_lang_class(\"fi\").Defaults.create_tokenizer()",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fr_tokenizer#97",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fr_tokenizer()",
        "snippet": "def fr_tokenizer():\n    return get_lang_class(\"fr\").Defaults.create_tokenizer()",
        "begin_line": 97,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ga_tokenizer#102",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ga_tokenizer()",
        "snippet": "def ga_tokenizer():\n    return get_lang_class(\"ga\").Defaults.create_tokenizer()",
        "begin_line": 102,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.he_tokenizer#107",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.he_tokenizer()",
        "snippet": "def he_tokenizer():\n    return get_lang_class(\"he\").Defaults.create_tokenizer()",
        "begin_line": 107,
        "end_line": 108,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.hu_tokenizer#117",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.hu_tokenizer()",
        "snippet": "def hu_tokenizer():\n    return get_lang_class(\"hu\").Defaults.create_tokenizer()",
        "begin_line": 117,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.id_tokenizer#122",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.id_tokenizer()",
        "snippet": "def id_tokenizer():\n    return get_lang_class(\"id\").Defaults.create_tokenizer()",
        "begin_line": 122,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.it_tokenizer#127",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.it_tokenizer()",
        "snippet": "def it_tokenizer():\n    return get_lang_class(\"it\").Defaults.create_tokenizer()",
        "begin_line": 127,
        "end_line": 128,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.lb_tokenizer#144",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.lb_tokenizer()",
        "snippet": "def lb_tokenizer():\n    return get_lang_class(\"lb\").Defaults.create_tokenizer()",
        "begin_line": 144,
        "end_line": 145,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.lt_tokenizer#149",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.lt_tokenizer()",
        "snippet": "def lt_tokenizer():\n    return get_lang_class(\"lt\").Defaults.create_tokenizer()",
        "begin_line": 149,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nb_tokenizer#154",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nb_tokenizer()",
        "snippet": "def nb_tokenizer():\n    return get_lang_class(\"nb\").Defaults.create_tokenizer()",
        "begin_line": 154,
        "end_line": 155,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nl_tokenizer#159",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nl_tokenizer()",
        "snippet": "def nl_tokenizer():\n    return get_lang_class(\"nl\").Defaults.create_tokenizer()",
        "begin_line": 159,
        "end_line": 160,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.pl_tokenizer#164",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pl_tokenizer()",
        "snippet": "def pl_tokenizer():\n    return get_lang_class(\"pl\").Defaults.create_tokenizer()",
        "begin_line": 164,
        "end_line": 165,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ro_tokenizer#174",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ro_tokenizer()",
        "snippet": "def ro_tokenizer():\n    return get_lang_class(\"ro\").Defaults.create_tokenizer()",
        "begin_line": 174,
        "end_line": 175,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sr_tokenizer#191",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sr_tokenizer()",
        "snippet": "def sr_tokenizer():\n    return get_lang_class(\"sr\").Defaults.create_tokenizer()",
        "begin_line": 191,
        "end_line": 192,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sv_tokenizer#196",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sv_tokenizer()",
        "snippet": "def sv_tokenizer():\n    return get_lang_class(\"sv\").Defaults.create_tokenizer()",
        "begin_line": 196,
        "end_line": 197,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tt_tokenizer#212",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tt_tokenizer()",
        "snippet": "def tt_tokenizer():\n    return get_lang_class(\"tt\").Defaults.create_tokenizer()",
        "begin_line": 212,
        "end_line": 213,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ur_tokenizer#224",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ur_tokenizer()",
        "snippet": "def ur_tokenizer():\n    return get_lang_class(\"ur\").Defaults.create_tokenizer()",
        "begin_line": 224,
        "end_line": 225,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.yo_tokenizer#229",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.yo_tokenizer()",
        "snippet": "def yo_tokenizer():\n    return get_lang_class(\"yo\").Defaults.create_tokenizer()",
        "begin_line": 229,
        "end_line": 230,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.hy_tokenizer#239",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.hy_tokenizer()",
        "snippet": "def hy_tokenizer():\n    return get_lang_class(\"hy\").Defaults.create_tokenizer()",
        "begin_line": 239,
        "end_line": 240,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.regression.test_issue5314.test_issue5314#13",
        "src_path": "spacy/tests/regression/test_issue5314.py",
        "class_name": "spacy.tests.regression.test_issue5314",
        "signature": "spacy.tests.regression.test_issue5314.test_issue5314(text)",
        "snippet": "def test_issue5314(text):\n    title = \"Ark\u00e6ologi\"\n    clean_text, _ = _process_wp_text(title, text, {})\n\n    expected_text = \"Ark\u00e6ologi er studiet af tidligere tiders menneskelige aktivitet, prim\u00e6rt gennem studiet af menneskets materielle levn.\"\n    assert clean_text.strip() == expected_text",
        "begin_line": 13,
        "end_line": 18,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.make_tempdir#25",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.make_tempdir()",
        "snippet": "def make_tempdir():\n    d = Path(tempfile.mkdtemp())\n    yield d\n    shutil.rmtree(path2str(d))",
        "begin_line": 25,
        "end_line": 28,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_doc#31",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None, lemmas=None)",
        "snippet": "def get_doc(\n    vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None, lemmas=None\n):\n    \"\"\"Create Doc object from given vocab, words and annotations.\"\"\"\n    if deps and not heads:\n        heads = [0] * len(deps)\n    headings = []\n    values = []\n    annotations = [pos, heads, deps, lemmas, tags]\n    possible_headings = [POS, HEAD, DEP, LEMMA, TAG]\n    for a, annot in enumerate(annotations):\n        if annot is not None:\n            if len(annot) != len(words):\n                raise ValueError(Errors.E189)\n            headings.append(possible_headings[a])\n            if annot is not heads:\n                values.extend(annot)\n    for value in values:\n        vocab.strings.add(value)\n\n    doc = Doc(vocab, words=words)\n\n    # if there are any other annotations, set them\n    if headings:\n        attrs = doc.to_array(headings)\n\n        j = 0\n        for annot in annotations:\n            if annot:\n                if annot is heads:\n                    for i in range(len(words)):\n                        if attrs.ndim == 1:\n                            attrs[i] = heads[i]\n                        else:\n                            attrs[i, j] = heads[i]\n                else:\n                    for i in range(len(words)):\n                        if attrs.ndim == 1:\n                            attrs[i] = doc.vocab.strings[annot[i]]\n                        else:\n                            attrs[i, j] = doc.vocab.strings[annot[i]]\n                j += 1\n        doc.from_array(headings, attrs)\n\n    # finally, set the entities\n    if ents:\n        doc.ents = [\n            Span(doc, start, end, label=doc.vocab.strings[label])\n            for start, end, label in ents\n        ]\n    return doc",
        "begin_line": 31,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.add_vecs_to_vocab#96",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.add_vecs_to_vocab(vocab, vectors)",
        "snippet": "def add_vecs_to_vocab(vocab, vectors):\n    \"\"\"Add list of vector tuples to given vocab. All vectors need to have the\n    same length. Format: [(\"text\", [1, 2, 3])]\"\"\"\n    length = len(vectors[0][1])\n    vocab.reset_vectors(width=length)\n    for word, vec in vectors:\n        vocab.set_vector(word, vector=vec)\n    return vocab",
        "begin_line": 96,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_cosine#106",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_cosine(vec1, vec2)",
        "snippet": "def get_cosine(vec1, vec2):\n    \"\"\"Get cosine for two given vectors\"\"\"\n    return numpy.dot(vec1, vec2) / (numpy.linalg.norm(vec1) * numpy.linalg.norm(vec2))",
        "begin_line": 106,
        "end_line": 108,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.assert_docs_equal#111",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.assert_docs_equal(doc1, doc2)",
        "snippet": "def assert_docs_equal(doc1, doc2):\n    \"\"\"Compare two Doc objects and assert that they're equal. Tests for tokens,\n    tags, dependencies and entities.\"\"\"\n    assert [t.orth for t in doc1] == [t.orth for t in doc2]\n\n    assert [t.pos for t in doc1] == [t.pos for t in doc2]\n    assert [t.tag for t in doc1] == [t.tag for t in doc2]\n\n    assert [t.head.i for t in doc1] == [t.head.i for t in doc2]\n    assert [t.dep for t in doc1] == [t.dep for t in doc2]\n    assert [t.is_sent_start for t in doc1] == [t.is_sent_start for t in doc2]\n\n    assert [t.ent_type for t in doc1] == [t.ent_type for t in doc2]\n    assert [t.ent_iob for t in doc1] == [t.ent_iob for t in doc2]\n    for ent1, ent2 in zip(doc1.ents, doc2.ents):\n        assert ent1.start == ent2.start\n        assert ent1.end == ent2.end\n        assert ent1.label == ent2.label\n        assert ent1.kb_id == ent2.kb_id",
        "begin_line": 111,
        "end_line": 129,
        "comment": "",
        "is_bug": false
    }
]