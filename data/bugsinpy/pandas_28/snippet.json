[
    {
        "name": "pandas.core.dtypes.dtypes.Registry.find#98",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.Registry",
        "signature": "pandas.core.dtypes.dtypes.Registry.find(self, dtype: Union[Type[ExtensionDtype], str])",
        "snippet": "    def find(\n        self, dtype: Union[Type[ExtensionDtype], str]\n    ) -> Optional[Type[ExtensionDtype]]:\n        \"\"\"\n        Parameters\n        ----------\n        dtype : Type[ExtensionDtype] or str\n\n        Returns\n        -------\n        return the first matching dtype, otherwise return None\n        \"\"\"\n        if not isinstance(dtype, str):\n            dtype_type = dtype\n            if not isinstance(dtype, type):\n                dtype_type = type(dtype)\n            if issubclass(dtype_type, ExtensionDtype):\n                return dtype\n\n            return None\n\n        for dtype_type in self.dtypes:\n            try:\n                return dtype_type.construct_from_string(dtype)\n            except TypeError:\n                pass\n\n        return None",
        "begin_line": 98,
        "end_line": 125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.CategoricalDtype.construct_from_string#369",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.CategoricalDtype",
        "signature": "pandas.core.dtypes.dtypes.CategoricalDtype.construct_from_string(cls, string: str_type)",
        "snippet": "    def construct_from_string(cls, string: str_type) -> \"CategoricalDtype\":\n        \"\"\"\n        Construct a CategoricalDtype from a string.\n\n        Parameters\n        ----------\n        string : str\n            Must be the string \"category\" in order to be successfully constructed.\n\n        Returns\n        -------\n        CategoricalDtype\n            Instance of the dtype.\n\n        Raises\n        ------\n        TypeError\n            If a CategoricalDtype cannot be constructed from the input.\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\n                f\"'construct_from_string' expects a string, got {type(string)}\"\n            )\n        if string != cls.name:\n            raise TypeError(f\"Cannot construct a 'CategoricalDtype' from '{string}'\")\n\n        # need ordered=None to ensure that operations specifying dtype=\"category\" don't\n        # override the ordered value for existing categoricals\n        return cls(ordered=None)",
        "begin_line": 369,
        "end_line": 397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.DatetimeTZDtype.construct_from_string#751",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.DatetimeTZDtype",
        "signature": "pandas.core.dtypes.dtypes.DatetimeTZDtype.construct_from_string(cls, string: str_type)",
        "snippet": "    def construct_from_string(cls, string: str_type) -> \"DatetimeTZDtype\":\n        \"\"\"\n        Construct a DatetimeTZDtype from a string.\n\n        Parameters\n        ----------\n        string : str\n            The string alias for this DatetimeTZDtype.\n            Should be formatted like ``datetime64[ns, <tz>]``,\n            where ``<tz>`` is the timezone name.\n\n        Examples\n        --------\n        >>> DatetimeTZDtype.construct_from_string('datetime64[ns, UTC]')\n        datetime64[ns, UTC]\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\n                f\"'construct_from_string' expects a string, got {type(string)}\"\n            )\n\n        msg = f\"Cannot construct a 'DatetimeTZDtype' from '{string}'\"\n        match = cls._match.match(string)\n        if match:\n            d = match.groupdict()\n            try:\n                return cls(unit=d[\"unit\"], tz=d[\"tz\"])\n            except (KeyError, TypeError, ValueError) as err:\n                # KeyError if maybe_get_tz tries and fails to get a\n                #  pytz timezone (actually pytz.UnknownTimeZoneError).\n                # TypeError if we pass a nonsense tz;\n                # ValueError if we pass a unit other than \"ns\"\n                raise TypeError(msg) from err\n        raise TypeError(msg)",
        "begin_line": 751,
        "end_line": 784,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.PeriodDtype.construct_from_string#904",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.PeriodDtype",
        "signature": "pandas.core.dtypes.dtypes.PeriodDtype.construct_from_string(cls, string: str_type)",
        "snippet": "    def construct_from_string(cls, string: str_type) -> \"PeriodDtype\":\n        \"\"\"\n        Strict construction from a string, raise a TypeError if not\n        possible\n        \"\"\"\n        if (\n            isinstance(string, str)\n            and (string.startswith(\"period[\") or string.startswith(\"Period[\"))\n            or isinstance(string, ABCDateOffset)\n        ):\n            # do not parse string like U as period[U]\n            # avoid tuple to be regarded as freq\n            try:\n                return cls(freq=string)\n            except ValueError:\n                pass\n        if isinstance(string, str):\n            msg = f\"Cannot construct a 'PeriodDtype' from '{string}'\"\n        else:\n            msg = f\"'construct_from_string' expects a string, got {type(string)}\"\n        raise TypeError(msg)",
        "begin_line": 904,
        "end_line": 924,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.PeriodDtype.is_dtype#954",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.PeriodDtype",
        "signature": "pandas.core.dtypes.dtypes.PeriodDtype.is_dtype(cls, dtype: object)",
        "snippet": "    def is_dtype(cls, dtype: object) -> bool:\n        \"\"\"\n        Return a boolean if we if the passed type is an actual dtype that we\n        can match (via string or type)\n        \"\"\"\n        if isinstance(dtype, str):\n            # PeriodDtype can be instantiated from freq string like \"U\",\n            # but doesn't regard freq str like \"U\" as dtype.\n            if dtype.startswith(\"period[\") or dtype.startswith(\"Period[\"):\n                try:\n                    if cls._parse_dtype_strict(dtype) is not None:\n                        return True\n                    else:\n                        return False\n                except ValueError:\n                    return False\n            else:\n                return False\n        return super().is_dtype(dtype)",
        "begin_line": 954,
        "end_line": 972,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.IntervalDtype.construct_from_string#1112",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.IntervalDtype",
        "signature": "pandas.core.dtypes.dtypes.IntervalDtype.construct_from_string(cls, string)",
        "snippet": "    def construct_from_string(cls, string):\n        \"\"\"\n        attempt to construct this type from a string, raise a TypeError\n        if its not possible\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\n                f\"'construct_from_string' expects a string, got {type(string)}\"\n            )\n\n        if string.lower() == \"interval\" or cls._match.search(string) is not None:\n            return cls(string)\n\n        msg = (\n            f\"Cannot construct a 'IntervalDtype' from '{string}'.\\n\\n\"\n            \"Incorrectly formatted string passed to constructor. \"\n            \"Valid formats include Interval or Interval[dtype] \"\n            \"where dtype is numeric, datetime, or timedelta\"\n        )\n        raise TypeError(msg)",
        "begin_line": 1112,
        "end_line": 1131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.IntervalDtype.is_dtype#1166",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.IntervalDtype",
        "signature": "pandas.core.dtypes.dtypes.IntervalDtype.is_dtype(cls, dtype: object)",
        "snippet": "    def is_dtype(cls, dtype: object) -> bool:\n        \"\"\"\n        Return a boolean if we if the passed type is an actual dtype that we\n        can match (via string or type)\n        \"\"\"\n        if isinstance(dtype, str):\n            if dtype.lower().startswith(\"interval\"):\n                try:\n                    if cls.construct_from_string(dtype) is not None:\n                        return True\n                    else:\n                        return False\n                except (ValueError, TypeError):\n                    return False\n            else:\n                return False\n        return super().is_dtype(dtype)",
        "begin_line": 1166,
        "end_line": 1182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex.__new__#50",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex.__new__(cls, data=None, dtype=None, copy=False, name=None)",
        "snippet": "    def __new__(cls, data=None, dtype=None, copy=False, name=None):\n        cls._validate_dtype(dtype)\n        name = maybe_extract_name(name, data, cls)\n\n        # Coerce to ndarray if not already ndarray or Index\n        if not isinstance(data, (np.ndarray, Index)):\n            if is_scalar(data):\n                raise cls._scalar_data_error(data)\n\n            # other iterable of some kind\n            if not isinstance(data, (ABCSeries, list, tuple)):\n                data = list(data)\n\n            data = np.asarray(data, dtype=dtype)\n\n        if issubclass(data.dtype.type, str):\n            cls._string_data_error(data)\n\n        if copy or not is_dtype_equal(data.dtype, cls._default_dtype):\n            subarr = np.array(data, dtype=cls._default_dtype, copy=copy)\n            cls._assert_safe_casting(data, subarr)\n        else:\n            subarr = data\n\n        if subarr.ndim > 1:\n            # GH#13601, GH#20285, GH#27125\n            raise ValueError(\"Index data must be 1-dimensional\")\n\n        subarr = np.asarray(subarr)\n        return cls._simple_new(subarr, name=name)",
        "begin_line": 50,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex._validate_dtype#82",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex._validate_dtype(cls, dtype: Dtype)",
        "snippet": "    def _validate_dtype(cls, dtype: Dtype) -> None:\n        if dtype is None:\n            return\n        validation_metadata = {\n            \"int64index\": (is_signed_integer_dtype, \"signed integer\"),\n            \"uint64index\": (is_unsigned_integer_dtype, \"unsigned integer\"),\n            \"float64index\": (is_float_dtype, \"float\"),\n            \"rangeindex\": (is_signed_integer_dtype, \"signed integer\"),\n        }\n\n        validation_func, expected = validation_metadata[cls._typ]\n        if not validation_func(dtype):\n            raise ValueError(\n                f\"Incorrect `dtype` passed: expected {expected}, received {dtype}\"\n            )",
        "begin_line": 82,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex._shallow_copy#106",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex._shallow_copy(self, values=None, name: Label=lib.no_default)",
        "snippet": "    def _shallow_copy(self, values=None, name: Label = lib.no_default):\n        if values is not None and not self._can_hold_na and values.dtype.kind == \"f\":\n            name = self.name if name is lib.no_default else name\n            # Ensure we are not returning an Int64Index with float data:\n            return Float64Index._simple_new(values, name=name)\n        return super()._shallow_copy(values=values, name=name)",
        "begin_line": 106,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex.is_all_dates#155",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex.is_all_dates(self)",
        "snippet": "    def is_all_dates(self) -> bool:\n        \"\"\"\n        Checks that all the labels are datetime objects.\n        \"\"\"\n        return False",
        "begin_line": 155,
        "end_line": 159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.numeric.IntegerIndex.__contains__#229",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.IntegerIndex",
        "signature": "pandas.core.indexes.numeric.IntegerIndex.__contains__(self, key)",
        "snippet": "    def __contains__(self, key) -> bool:\n        \"\"\"\n        Check if key is a float and has a decimal. If it has, return False.\n        \"\"\"\n        hash(key)\n        try:\n            if is_float(key) and int(key) != key:\n                return False\n            return key in self._engine\n        except (OverflowError, TypeError, ValueError):\n            return False",
        "begin_line": 229,
        "end_line": 239,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.numeric.IntegerIndex.inferred_type#242",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.IntegerIndex",
        "signature": "pandas.core.indexes.numeric.IntegerIndex.inferred_type(self)",
        "snippet": "    def inferred_type(self) -> str:\n        \"\"\"\n        Always 'integer' for ``Int64Index`` and ``UInt64Index``\n        \"\"\"\n        return \"integer\"",
        "begin_line": 242,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.algorithms._get_take_nd_function#1431",
        "src_path": "pandas/core/algorithms.py",
        "class_name": "pandas.core.algorithms",
        "signature": "pandas.core.algorithms._get_take_nd_function(ndim: int, arr_dtype, out_dtype, axis: int=0, mask_info=None)",
        "snippet": "def _get_take_nd_function(\n    ndim: int, arr_dtype, out_dtype, axis: int = 0, mask_info=None\n):\n    if ndim <= 2:\n        tup = (arr_dtype.name, out_dtype.name)\n        if ndim == 1:\n            func = _take_1d_dict.get(tup, None)\n        elif ndim == 2:\n            if axis == 0:\n                func = _take_2d_axis0_dict.get(tup, None)\n            else:\n                func = _take_2d_axis1_dict.get(tup, None)\n        if func is not None:\n            return func\n\n        tup = (out_dtype.name, out_dtype.name)\n        if ndim == 1:\n            func = _take_1d_dict.get(tup, None)\n        elif ndim == 2:\n            if axis == 0:\n                func = _take_2d_axis0_dict.get(tup, None)\n            else:\n                func = _take_2d_axis1_dict.get(tup, None)\n        if func is not None:\n            func = _convert_wrapper(func, out_dtype)\n            return func\n\n    def func2(arr, indexer, out, fill_value=np.nan):\n        indexer = ensure_int64(indexer)\n        _take_nd_object(\n            arr, indexer, out, axis=axis, fill_value=fill_value, mask_info=mask_info\n        )\n\n    return func2",
        "begin_line": 1431,
        "end_line": 1464,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.algorithms.take_nd#1560",
        "src_path": "pandas/core/algorithms.py",
        "class_name": "pandas.core.algorithms",
        "signature": "pandas.core.algorithms.take_nd(arr, indexer, axis: int=0, out=None, fill_value=np.nan, allow_fill: bool=True)",
        "snippet": "def take_nd(\n    arr, indexer, axis: int = 0, out=None, fill_value=np.nan, allow_fill: bool = True\n):\n    \"\"\"\n    Specialized Cython take which sets NaN values in one pass\n\n    This dispatches to ``take`` defined on ExtensionArrays. It does not\n    currently dispatch to ``SparseArray.take`` for sparse ``arr``.\n\n    Parameters\n    ----------\n    arr : array-like\n        Input array.\n    indexer : ndarray\n        1-D array of indices to take, subarrays corresponding to -1 value\n        indices are filed with fill_value\n    axis : int, default 0\n        Axis to take from\n    out : ndarray or None, default None\n        Optional output array, must be appropriate type to hold input and\n        fill_value together, if indexer has any -1 value entries; call\n        maybe_promote to determine this type for any fill_value\n    fill_value : any, default np.nan\n        Fill value to replace -1 values with\n    allow_fill : boolean, default True\n        If False, indexer is assumed to contain no -1 values so no filling\n        will be done.  This short-circuits computation of a mask.  Result is\n        undefined if allow_fill == False and -1 is present in indexer.\n\n    Returns\n    -------\n    subarray : array-like\n        May be the same type as the input, or cast to an ndarray.\n    \"\"\"\n    mask_info = None\n\n    if is_extension_array_dtype(arr):\n        return arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\n    arr = extract_array(arr)\n    arr = np.asarray(arr)\n\n    if indexer is None:\n        indexer = np.arange(arr.shape[axis], dtype=np.int64)\n        dtype, fill_value = arr.dtype, arr.dtype.type()\n    else:\n        indexer = ensure_int64(indexer, copy=False)\n        if not allow_fill:\n            dtype, fill_value = arr.dtype, arr.dtype.type()\n            mask_info = None, False\n        else:\n            # check for promotion based on types only (do this first because\n            # it's faster than computing a mask)\n            dtype, fill_value = maybe_promote(arr.dtype, fill_value)\n            if dtype != arr.dtype and (out is None or out.dtype != dtype):\n                # check if promotion is actually required based on indexer\n                mask = indexer == -1\n                needs_masking = mask.any()\n                mask_info = mask, needs_masking\n                if needs_masking:\n                    if out is not None and out.dtype != dtype:\n                        raise TypeError(\"Incompatible type for fill_value\")\n                else:\n                    # if not, then depromote, set fill_value to dummy\n                    # (it won't be used but we don't want the cython code\n                    # to crash when trying to cast it to dtype)\n                    dtype, fill_value = arr.dtype, arr.dtype.type()\n\n    flip_order = False\n    if arr.ndim == 2:\n        if arr.flags.f_contiguous:\n            flip_order = True\n\n    if flip_order:\n        arr = arr.T\n        axis = arr.ndim - axis - 1\n        if out is not None:\n            out = out.T\n\n    # at this point, it's guaranteed that dtype can hold both the arr values\n    # and the fill_value\n    if out is None:\n        out_shape_ = list(arr.shape)\n        out_shape_[axis] = len(indexer)\n        out_shape = tuple(out_shape_)\n        if arr.flags.f_contiguous and axis == arr.ndim - 1:\n            # minor tweak that can make an order-of-magnitude difference\n            # for dataframes initialized directly from 2-d ndarrays\n            # (s.t. df.values is c-contiguous and df._mgr.blocks[0] is its\n            # f-contiguous transpose)\n            out = np.empty(out_shape, dtype=dtype, order=\"F\")\n        else:\n            out = np.empty(out_shape, dtype=dtype)\n\n    func = _get_take_nd_function(\n        arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n    )\n    func(arr, indexer, out, fill_value)\n\n    if flip_order:\n        out = out.T\n    return out",
        "begin_line": 1560,
        "end_line": 1661,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.strings.cat_core#58",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.cat_core(list_of_columns: List, sep: str)",
        "snippet": "def cat_core(list_of_columns: List, sep: str):\n    \"\"\"\n    Auxiliary function for :meth:`str.cat`\n\n    Parameters\n    ----------\n    list_of_columns : list of numpy arrays\n        List of arrays to be concatenated with sep;\n        these arrays may not contain NaNs!\n    sep : string\n        The separator string for concatenating the columns.\n\n    Returns\n    -------\n    nd.array\n        The concatenation of list_of_columns with sep.\n    \"\"\"\n    if sep == \"\":\n        # no need to interleave sep if it is empty\n        arr_of_cols = np.asarray(list_of_columns, dtype=object)\n        return np.sum(arr_of_cols, axis=0)\n    list_with_sep = [sep] * (2 * len(list_of_columns) - 1)\n    list_with_sep[::2] = list_of_columns\n    arr_with_sep = np.asarray(list_with_sep, dtype=object)\n    return np.sum(arr_with_sep, axis=0)",
        "begin_line": 58,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.strings.cat_safe#85",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.cat_safe(list_of_columns: List, sep: str)",
        "snippet": "def cat_safe(list_of_columns: List, sep: str):\n    \"\"\"\n    Auxiliary function for :meth:`str.cat`.\n\n    Same signature as cat_core, but handles TypeErrors in concatenation, which\n    happen if the arrays in list_of columns have the wrong dtypes or content.\n\n    Parameters\n    ----------\n    list_of_columns : list of numpy arrays\n        List of arrays to be concatenated with sep;\n        these arrays may not contain NaNs!\n    sep : string\n        The separator string for concatenating the columns.\n\n    Returns\n    -------\n    nd.array\n        The concatenation of list_of_columns with sep.\n    \"\"\"\n    try:\n        result = cat_core(list_of_columns, sep)\n    except TypeError:\n        # if there are any non-string values (wrong dtype or hidden behind\n        # object dtype), np.sum will fail; catch and return with better message\n        for column in list_of_columns:\n            dtype = lib.infer_dtype(column, skipna=True)\n            if dtype not in [\"string\", \"empty\"]:\n                raise TypeError(\n                    \"Concatenation requires list-likes containing only \"\n                    \"strings (or missing values). Offending values found in \"\n                    f\"column {dtype}\"\n                ) from None\n    return result",
        "begin_line": 85,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.strings._forbid_nonstring_types#1986",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._forbid_nonstring_types(func)",
        "snippet": "    def _forbid_nonstring_types(func):\n        func_name = func.__name__ if name is None else name\n\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            if self._inferred_dtype not in allowed_types:\n                msg = (\n                    f\"Cannot use .str.{func_name} with values of \"\n                    f\"inferred dtype '{self._inferred_dtype}'.\"\n                )\n                raise TypeError(msg)\n            return func(self, *args, **kwargs)\n\n        wrapper.__name__ = func_name\n        return wrapper",
        "begin_line": 1986,
        "end_line": 2000,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.strings.wrapper#1990",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.wrapper(self, *args, **kwargs)",
        "snippet": "        def wrapper(self, *args, **kwargs):\n            if self._inferred_dtype not in allowed_types:\n                msg = (\n                    f\"Cannot use .str.{func_name} with values of \"\n                    f\"inferred dtype '{self._inferred_dtype}'.\"\n                )\n                raise TypeError(msg)\n            return func(self, *args, **kwargs)",
        "begin_line": 1990,
        "end_line": 1997,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.__init__#2093",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.__init__(self, data)",
        "snippet": "    def __init__(self, data):\n        self._inferred_dtype = self._validate(data)\n        self._is_categorical = is_categorical_dtype(data)\n        self._is_string = data.dtype.name == \"string\"\n\n        # ._values.categories works for both Series/Index\n        self._parent = data._values.categories if self._is_categorical else data\n        # save orig to blow up categoricals to the right type\n        self._orig = data\n        self._freeze()",
        "begin_line": 2093,
        "end_line": 2102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.strings.StringMethods._validate#2105",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods._validate(data)",
        "snippet": "    def _validate(data):\n        \"\"\"\n        Auxiliary function for StringMethods, infers and checks dtype of data.\n\n        This is a \"first line of defence\" at the creation of the StringMethods-\n        object (see _make_accessor), and just checks that the dtype is in the\n        *union* of the allowed types over all string methods below; this\n        restriction is then refined on a per-method basis using the decorator\n        @forbid_nonstring_types (more info in the corresponding docstring).\n\n        This really should exclude all series/index with any non-string values,\n        but that isn't practical for performance reasons until we have a str\n        dtype (GH 9343 / 13877)\n\n        Parameters\n        ----------\n        data : The content of the Series\n\n        Returns\n        -------\n        dtype : inferred dtype of data\n        \"\"\"\n        from pandas import StringDtype\n\n        if isinstance(data, ABCMultiIndex):\n            raise AttributeError(\n                \"Can only use .str accessor with Index, not MultiIndex\"\n            )\n\n        # see _libs/lib.pyx for list of inferred types\n        allowed_types = [\"string\", \"empty\", \"bytes\", \"mixed\", \"mixed-integer\"]\n\n        values = getattr(data, \"values\", data)  # Series / Index\n        values = getattr(values, \"categories\", values)  # categorical / normal\n\n        # explicitly allow StringDtype\n        if isinstance(values.dtype, StringDtype):\n            return \"string\"\n\n        try:\n            inferred_dtype = lib.infer_dtype(values, skipna=True)\n        except ValueError:\n            # GH#27571 mostly occurs with ExtensionArray\n            inferred_dtype = None\n\n        if inferred_dtype not in allowed_types:\n            raise AttributeError(\"Can only use .str accessor with string values!\")\n        return inferred_dtype",
        "begin_line": 2105,
        "end_line": 2152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.strings.StringMethods._get_series_list#2273",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods._get_series_list(self, others)",
        "snippet": "    def _get_series_list(self, others):\n        \"\"\"\n        Auxiliary function for :meth:`str.cat`. Turn potentially mixed input\n        into a list of Series (elements without an index must match the length\n        of the calling Series/Index).\n\n        Parameters\n        ----------\n        others : Series, DataFrame, np.ndarray, list-like or list-like of\n            Objects that are either Series, Index or np.ndarray (1-dim).\n\n        Returns\n        -------\n        list of Series\n            Others transformed into list of Series.\n        \"\"\"\n        from pandas import Series, DataFrame\n\n        # self._orig is either Series or Index\n        idx = self._orig if isinstance(self._orig, ABCIndexClass) else self._orig.index\n\n        # Generally speaking, all objects without an index inherit the index\n        # `idx` of the calling Series/Index - i.e. must have matching length.\n        # Objects with an index (i.e. Series/Index/DataFrame) keep their own.\n        if isinstance(others, ABCSeries):\n            return [others]\n        elif isinstance(others, ABCIndexClass):\n            return [Series(others._values, index=others)]\n        elif isinstance(others, ABCDataFrame):\n            return [others[x] for x in others]\n        elif isinstance(others, np.ndarray) and others.ndim == 2:\n            others = DataFrame(others, index=idx)\n            return [others[x] for x in others]\n        elif is_list_like(others, allow_sets=False):\n            others = list(others)  # ensure iterators do not get read twice etc\n\n            # in case of list-like `others`, all elements must be\n            # either Series/Index/np.ndarray (1-dim)...\n            if all(\n                isinstance(x, (ABCSeries, ABCIndexClass))\n                or (isinstance(x, np.ndarray) and x.ndim == 1)\n                for x in others\n            ):\n                los = []\n                while others:  # iterate through list and append each element\n                    los = los + self._get_series_list(others.pop(0))\n                return los\n            # ... or just strings\n            elif all(not is_list_like(x) for x in others):\n                return [Series(others, index=idx)]\n        raise TypeError(\n            \"others must be Series, Index, DataFrame, np.ndarrary \"\n            \"or list-like (either containing only strings or \"\n            \"containing only objects of type Series/Index/\"\n            \"np.ndarray[1-dim])\"\n        )",
        "begin_line": 2273,
        "end_line": 2328,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.cat#2331",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.cat(self, others=None, sep=None, na_rep=None, join='left')",
        "snippet": "    def cat(self, others=None, sep=None, na_rep=None, join=\"left\"):\n        \"\"\"\n        Concatenate strings in the Series/Index with given separator.\n\n        If `others` is specified, this function concatenates the Series/Index\n        and elements of `others` element-wise.\n        If `others` is not passed, then all values in the Series/Index are\n        concatenated into a single string with a given `sep`.\n\n        Parameters\n        ----------\n        others : Series, Index, DataFrame, np.ndarray or list-like\n            Series, Index, DataFrame, np.ndarray (one- or two-dimensional) and\n            other list-likes of strings must have the same length as the\n            calling Series/Index, with the exception of indexed objects (i.e.\n            Series/Index/DataFrame) if `join` is not None.\n\n            If others is a list-like that contains a combination of Series,\n            Index or np.ndarray (1-dim), then all elements will be unpacked and\n            must satisfy the above criteria individually.\n\n            If others is None, the method returns the concatenation of all\n            strings in the calling Series/Index.\n        sep : str, default ''\n            The separator between the different elements/columns. By default\n            the empty string `''` is used.\n        na_rep : str or None, default None\n            Representation that is inserted for all missing values:\n\n            - If `na_rep` is None, and `others` is None, missing values in the\n              Series/Index are omitted from the result.\n            - If `na_rep` is None, and `others` is not None, a row containing a\n              missing value in any of the columns (before concatenation) will\n              have a missing value in the result.\n        join : {'left', 'right', 'outer', 'inner'}, default 'left'\n            Determines the join-style between the calling Series/Index and any\n            Series/Index/DataFrame in `others` (objects without an index need\n            to match the length of the calling Series/Index). To disable\n            alignment, use `.values` on any Series/Index/DataFrame in `others`.\n\n            .. versionadded:: 0.23.0\n            .. versionchanged:: 1.0.0\n                Changed default of `join` from None to `'left'`.\n\n        Returns\n        -------\n        str, Series or Index\n            If `others` is None, `str` is returned, otherwise a `Series/Index`\n            (same type as caller) of objects is returned.\n\n        See Also\n        --------\n        split : Split each string in the Series/Index.\n        join : Join lists contained as elements in the Series/Index.\n\n        Examples\n        --------\n        When not passing `others`, all values are concatenated into a single\n        string:\n\n        >>> s = pd.Series(['a', 'b', np.nan, 'd'])\n        >>> s.str.cat(sep=' ')\n        'a b d'\n\n        By default, NA values in the Series are ignored. Using `na_rep`, they\n        can be given a representation:\n\n        >>> s.str.cat(sep=' ', na_rep='?')\n        'a b ? d'\n\n        If `others` is specified, corresponding values are concatenated with\n        the separator. Result will be a Series of strings.\n\n        >>> s.str.cat(['A', 'B', 'C', 'D'], sep=',')\n        0    a,A\n        1    b,B\n        2    NaN\n        3    d,D\n        dtype: object\n\n        Missing values will remain missing in the result, but can again be\n        represented using `na_rep`\n\n        >>> s.str.cat(['A', 'B', 'C', 'D'], sep=',', na_rep='-')\n        0    a,A\n        1    b,B\n        2    -,C\n        3    d,D\n        dtype: object\n\n        If `sep` is not specified, the values are concatenated without\n        separation.\n\n        >>> s.str.cat(['A', 'B', 'C', 'D'], na_rep='-')\n        0    aA\n        1    bB\n        2    -C\n        3    dD\n        dtype: object\n\n        Series with different indexes can be aligned before concatenation. The\n        `join`-keyword works as in other methods.\n\n        >>> t = pd.Series(['d', 'a', 'e', 'c'], index=[3, 0, 4, 2])\n        >>> s.str.cat(t, join='left', na_rep='-')\n        0    aa\n        1    b-\n        2    -c\n        3    dd\n        dtype: object\n        >>>\n        >>> s.str.cat(t, join='outer', na_rep='-')\n        0    aa\n        1    b-\n        2    -c\n        3    dd\n        4    -e\n        dtype: object\n        >>>\n        >>> s.str.cat(t, join='inner', na_rep='-')\n        0    aa\n        2    -c\n        3    dd\n        dtype: object\n        >>>\n        >>> s.str.cat(t, join='right', na_rep='-')\n        3    dd\n        0    aa\n        4    -e\n        2    -c\n        dtype: object\n\n        For more examples, see :ref:`here <text.concatenate>`.\n        \"\"\"\n        from pandas import Index, Series, concat\n\n        if isinstance(others, str):\n            raise ValueError(\"Did you mean to supply a `sep` keyword?\")\n        if sep is None:\n            sep = \"\"\n\n        if isinstance(self._orig, ABCIndexClass):\n            data = Series(self._orig, index=self._orig)\n        else:  # Series\n            data = self._orig\n\n        # concatenate Series/Index with itself if no \"others\"\n        if others is None:\n            data = ensure_object(data)\n            na_mask = isna(data)\n            if na_rep is None and na_mask.any():\n                data = data[~na_mask]\n            elif na_rep is not None and na_mask.any():\n                data = np.where(na_mask, na_rep, data)\n            return sep.join(data)\n\n        try:\n            # turn anything in \"others\" into lists of Series\n            others = self._get_series_list(others)\n        except ValueError as err:  # do not catch TypeError raised by _get_series_list\n            raise ValueError(\n                \"If `others` contains arrays or lists (or other \"\n                \"list-likes without an index), these must all be \"\n                \"of the same length as the calling Series/Index.\"\n            ) from err\n\n        # align if required\n        if any(not data.index.equals(x.index) for x in others):\n            # Need to add keys for uniqueness in case of duplicate columns\n            others = concat(\n                others,\n                axis=1,\n                join=(join if join == \"inner\" else \"outer\"),\n                keys=range(len(others)),\n                sort=False,\n                copy=False,\n            )\n            data, others = data.align(others, join=join)\n            others = [others[x] for x in others]  # again list of Series\n\n        all_cols = [ensure_object(x) for x in [data] + others]\n        na_masks = np.array([isna(x) for x in all_cols])\n        union_mask = np.logical_or.reduce(na_masks, axis=0)\n\n        if na_rep is None and union_mask.any():\n            # no na_rep means NaNs for all rows where any column has a NaN\n            # only necessary if there are actually any NaNs\n            result = np.empty(len(data), dtype=object)\n            np.putmask(result, union_mask, np.nan)\n\n            not_masked = ~union_mask\n            result[not_masked] = cat_safe([x[not_masked] for x in all_cols], sep)\n        elif na_rep is not None and union_mask.any():\n            # fill NaNs with na_rep in case there are actually any NaNs\n            all_cols = [\n                np.where(nm, na_rep, col) for nm, col in zip(na_masks, all_cols)\n            ]\n            result = cat_safe(all_cols, sep)\n        else:\n            # no NaNs - can just concatenate\n            result = cat_safe(all_cols, sep)\n\n        if isinstance(self._orig, ABCIndexClass):\n            # add dtype for case that result is all-NA\n            result = Index(result, dtype=object, name=self._orig.name)\n        else:  # Series\n            if is_categorical_dtype(self._orig.dtype):\n                # We need to infer the new categories.\n                dtype = None\n            else:\n                dtype = self._orig.dtype\n            result = Series(result, dtype=dtype, index=data.index, name=self._orig.name)\n        return result",
        "begin_line": 2331,
        "end_line": 2543,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.reshape.concat.concat#67",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat",
        "signature": "pandas.core.reshape.concat.concat(objs: Union[Iterable[FrameOrSeriesUnion], Mapping[Label, FrameOrSeriesUnion]], axis=0, join='outer', ignore_index: bool=False, keys=None, levels=None, names=None, verify_integrity: bool=False, sort: bool=False, copy: bool=True)",
        "snippet": "def concat(\n    objs: Union[Iterable[FrameOrSeriesUnion], Mapping[Label, FrameOrSeriesUnion]],\n    axis=0,\n    join=\"outer\",\n    ignore_index: bool = False,\n    keys=None,\n    levels=None,\n    names=None,\n    verify_integrity: bool = False,\n    sort: bool = False,\n    copy: bool = True,\n) -> FrameOrSeriesUnion:\n    \"\"\"\n    Concatenate pandas objects along a particular axis with optional set logic\n    along the other axes.\n\n    Can also add a layer of hierarchical indexing on the concatenation axis,\n    which may be useful if the labels are the same (or overlapping) on\n    the passed axis number.\n\n    Parameters\n    ----------\n    objs : a sequence or mapping of Series or DataFrame objects\n        If a mapping is passed, the sorted keys will be used as the `keys`\n        argument, unless it is passed, in which case the values will be\n        selected (see below). Any None objects will be dropped silently unless\n        they are all None in which case a ValueError will be raised.\n    axis : {0/'index', 1/'columns'}, default 0\n        The axis to concatenate along.\n    join : {'inner', 'outer'}, default 'outer'\n        How to handle indexes on other axis (or axes).\n    ignore_index : bool, default False\n        If True, do not use the index values along the concatenation axis. The\n        resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n        concatenating objects where the concatenation axis does not have\n        meaningful indexing information. Note the index values on the other\n        axes are still respected in the join.\n    keys : sequence, default None\n        If multiple levels passed, should contain tuples. Construct\n        hierarchical index using the passed keys as the outermost level.\n    levels : list of sequences, default None\n        Specific levels (unique values) to use for constructing a\n        MultiIndex. Otherwise they will be inferred from the keys.\n    names : list, default None\n        Names for the levels in the resulting hierarchical index.\n    verify_integrity : bool, default False\n        Check whether the new concatenated axis contains duplicates. This can\n        be very expensive relative to the actual data concatenation.\n    sort : bool, default False\n        Sort non-concatenation axis if it is not already aligned when `join`\n        is 'outer'.\n        This has no effect when ``join='inner'``, which already preserves\n        the order of the non-concatenation axis.\n\n        .. versionadded:: 0.23.0\n        .. versionchanged:: 1.0.0\n\n           Changed to not sort by default.\n\n    copy : bool, default True\n        If False, do not copy data unnecessarily.\n\n    Returns\n    -------\n    object, type of objs\n        When concatenating all ``Series`` along the index (axis=0), a\n        ``Series`` is returned. When ``objs`` contains at least one\n        ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n        the columns (axis=1), a ``DataFrame`` is returned.\n\n    See Also\n    --------\n    Series.append : Concatenate Series.\n    DataFrame.append : Concatenate DataFrames.\n    DataFrame.join : Join DataFrames using indexes.\n    DataFrame.merge : Merge DataFrames by indexes or columns.\n\n    Notes\n    -----\n    The keys, levels, and names arguments are all optional.\n\n    A walkthrough of how this method fits in with other tools for combining\n    pandas objects can be found `here\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n\n    Examples\n    --------\n    Combine two ``Series``.\n\n    >>> s1 = pd.Series(['a', 'b'])\n    >>> s2 = pd.Series(['c', 'd'])\n    >>> pd.concat([s1, s2])\n    0    a\n    1    b\n    0    c\n    1    d\n    dtype: object\n\n    Clear the existing index and reset it in the result\n    by setting the ``ignore_index`` option to ``True``.\n\n    >>> pd.concat([s1, s2], ignore_index=True)\n    0    a\n    1    b\n    2    c\n    3    d\n    dtype: object\n\n    Add a hierarchical index at the outermost level of\n    the data with the ``keys`` option.\n\n    >>> pd.concat([s1, s2], keys=['s1', 's2'])\n    s1  0    a\n        1    b\n    s2  0    c\n        1    d\n    dtype: object\n\n    Label the index keys you create with the ``names`` option.\n\n    >>> pd.concat([s1, s2], keys=['s1', 's2'],\n    ...           names=['Series name', 'Row ID'])\n    Series name  Row ID\n    s1           0         a\n                 1         b\n    s2           0         c\n                 1         d\n    dtype: object\n\n    Combine two ``DataFrame`` objects with identical columns.\n\n    >>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n    ...                    columns=['letter', 'number'])\n    >>> df1\n      letter  number\n    0      a       1\n    1      b       2\n    >>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n    ...                    columns=['letter', 'number'])\n    >>> df2\n      letter  number\n    0      c       3\n    1      d       4\n    >>> pd.concat([df1, df2])\n      letter  number\n    0      a       1\n    1      b       2\n    0      c       3\n    1      d       4\n\n    Combine ``DataFrame`` objects with overlapping columns\n    and return everything. Columns outside the intersection will\n    be filled with ``NaN`` values.\n\n    >>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n    ...                    columns=['letter', 'number', 'animal'])\n    >>> df3\n      letter  number animal\n    0      c       3    cat\n    1      d       4    dog\n    >>> pd.concat([df1, df3], sort=False)\n      letter  number animal\n    0      a       1    NaN\n    1      b       2    NaN\n    0      c       3    cat\n    1      d       4    dog\n\n    Combine ``DataFrame`` objects with overlapping columns\n    and return only those that are shared by passing ``inner`` to\n    the ``join`` keyword argument.\n\n    >>> pd.concat([df1, df3], join=\"inner\")\n      letter  number\n    0      a       1\n    1      b       2\n    0      c       3\n    1      d       4\n\n    Combine ``DataFrame`` objects horizontally along the x axis by\n    passing in ``axis=1``.\n\n    >>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n    ...                    columns=['animal', 'name'])\n    >>> pd.concat([df1, df4], axis=1)\n      letter  number  animal    name\n    0      a       1    bird   polly\n    1      b       2  monkey  george\n\n    Prevent the result from including duplicate index values with the\n    ``verify_integrity`` option.\n\n    >>> df5 = pd.DataFrame([1], index=['a'])\n    >>> df5\n       0\n    a  1\n    >>> df6 = pd.DataFrame([2], index=['a'])\n    >>> df6\n       0\n    a  2\n    >>> pd.concat([df5, df6], verify_integrity=True)\n    Traceback (most recent call last):\n        ...\n    ValueError: Indexes have overlapping values: ['a']\n    \"\"\"\n    op = _Concatenator(\n        objs,\n        axis=axis,\n        ignore_index=ignore_index,\n        join=join,\n        keys=keys,\n        levels=levels,\n        names=names,\n        verify_integrity=verify_integrity,\n        copy=copy,\n        sort=sort,\n    )\n\n    return op.get_result()",
        "begin_line": 67,
        "end_line": 284,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator.__init__#292",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator.__init__(self, objs, axis=0, join: str='outer', keys=None, levels=None, names=None, ignore_index: bool=False, verify_integrity: bool=False, copy: bool=True, sort=False)",
        "snippet": "    def __init__(\n        self,\n        objs,\n        axis=0,\n        join: str = \"outer\",\n        keys=None,\n        levels=None,\n        names=None,\n        ignore_index: bool = False,\n        verify_integrity: bool = False,\n        copy: bool = True,\n        sort=False,\n    ):\n        if isinstance(objs, (NDFrame, str)):\n            raise TypeError(\n                \"first argument must be an iterable of pandas \"\n                f'objects, you passed an object of type \"{type(objs).__name__}\"'\n            )\n\n        if join == \"outer\":\n            self.intersect = False\n        elif join == \"inner\":\n            self.intersect = True\n        else:  # pragma: no cover\n            raise ValueError(\n                \"Only can inner (intersect) or outer (union) join the other axis\"\n            )\n\n        if isinstance(objs, abc.Mapping):\n            if keys is None:\n                keys = list(objs.keys())\n            objs = [objs[k] for k in keys]\n        else:\n            objs = list(objs)\n\n        if len(objs) == 0:\n            raise ValueError(\"No objects to concatenate\")\n\n        if keys is None:\n            objs = list(com.not_none(*objs))\n        else:\n            # #1649\n            clean_keys = []\n            clean_objs = []\n            for k, v in zip(keys, objs):\n                if v is None:\n                    continue\n                clean_keys.append(k)\n                clean_objs.append(v)\n            objs = clean_objs\n            name = getattr(keys, \"name\", None)\n            keys = Index(clean_keys, name=name)\n\n        if len(objs) == 0:\n            raise ValueError(\"All objects passed were None\")\n\n        # consolidate data & figure out what our result ndim is going to be\n        ndims = set()\n        for obj in objs:\n            if not isinstance(obj, (Series, DataFrame)):\n                msg = (\n                    f\"cannot concatenate object of type '{type(obj)}'; \"\n                    \"only Series and DataFrame objs are valid\"\n                )\n                raise TypeError(msg)\n\n            # consolidate\n            obj._consolidate(inplace=True)\n            ndims.add(obj.ndim)\n\n        # get the sample\n        # want the highest ndim that we have, and must be non-empty\n        # unless all objs are empty\n        sample = None\n        if len(ndims) > 1:\n            max_ndim = max(ndims)\n            for obj in objs:\n                if obj.ndim == max_ndim and np.sum(obj.shape):\n                    sample = obj\n                    break\n\n        else:\n            # filter out the empties if we have not multi-index possibilities\n            # note to keep empty Series as it affect to result columns / name\n            non_empties = [\n                obj for obj in objs if sum(obj.shape) > 0 or isinstance(obj, Series)\n            ]\n\n            if len(non_empties) and (\n                keys is None and names is None and levels is None and not self.intersect\n            ):\n                objs = non_empties\n                sample = objs[0]\n\n        if sample is None:\n            sample = objs[0]\n        self.objs = objs\n\n        # Standardize axis parameter to int\n        if isinstance(sample, Series):\n            axis = DataFrame._get_axis_number(axis)\n        else:\n            axis = sample._get_axis_number(axis)\n\n        # Need to flip BlockManager axis in the DataFrame special case\n        self._is_frame = isinstance(sample, ABCDataFrame)\n        if self._is_frame:\n            axis = DataFrame._get_block_manager_axis(axis)\n\n        self._is_series = isinstance(sample, ABCSeries)\n        if not 0 <= axis <= sample.ndim:\n            raise AssertionError(\n                f\"axis must be between 0 and {sample.ndim}, input was {axis}\"\n            )\n\n        # if we have mixed ndims, then convert to highest ndim\n        # creating column numbers as needed\n        if len(ndims) > 1:\n            current_column = 0\n            max_ndim = sample.ndim\n            self.objs, objs = [], self.objs\n            for obj in objs:\n\n                ndim = obj.ndim\n                if ndim == max_ndim:\n                    pass\n\n                elif ndim != max_ndim - 1:\n                    raise ValueError(\n                        \"cannot concatenate unaligned mixed \"\n                        \"dimensional NDFrame objects\"\n                    )\n\n                else:\n                    name = getattr(obj, \"name\", None)\n                    if ignore_index or name is None:\n                        name = current_column\n                        current_column += 1\n\n                    # doing a row-wise concatenation so need everything\n                    # to line up\n                    if self._is_frame and axis == 1:\n                        name = 0\n                    obj = sample._constructor({name: obj})\n\n                self.objs.append(obj)\n\n        # note: this is the BlockManager axis (since DataFrame is transposed)\n        self.bm_axis = axis\n        self.axis = 1 - self.bm_axis if self._is_frame else 0\n        self.keys = keys\n        self.names = names or getattr(keys, \"names\", None)\n        self.levels = levels\n        self.sort = sort\n\n        self.ignore_index = ignore_index\n        self.verify_integrity = verify_integrity\n        self.copy = copy\n\n        self.new_axes = self._get_new_axes()",
        "begin_line": 292,
        "end_line": 451,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator.get_result#453",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator.get_result(self)",
        "snippet": "    def get_result(self):\n\n        # series only\n        if self._is_series:\n\n            # stack blocks\n            if self.bm_axis == 0:\n                name = com.consensus_name_attr(self.objs)\n                cons = self.objs[0]._constructor\n\n                arrs = [ser._values for ser in self.objs]\n\n                res = concat_compat(arrs, axis=0)\n                result = cons(res, index=self.new_axes[0], name=name, dtype=res.dtype)\n                return result.__finalize__(self, method=\"concat\")\n\n            # combine as columns in a frame\n            else:\n                data = dict(zip(range(len(self.objs)), self.objs))\n                cons = DataFrame\n\n                index, columns = self.new_axes\n                df = cons(data, index=index)\n                df.columns = columns\n                return df.__finalize__(self, method=\"concat\")\n\n        # combine block managers\n        else:\n            mgrs_indexers = []\n            for obj in self.objs:\n                indexers = {}\n                for ax, new_labels in enumerate(self.new_axes):\n                    # ::-1 to convert BlockManager ax to DataFrame ax\n                    if ax == self.bm_axis:\n                        # Suppress reindexing on concat axis\n                        continue\n\n                    # 1-ax to convert BlockManager axis to DataFrame axis\n                    obj_labels = obj.axes[1 - ax]\n                    if not new_labels.equals(obj_labels):\n                        indexers[ax] = obj_labels.reindex(new_labels)[1]\n\n                mgrs_indexers.append((obj._mgr, indexers))\n\n            new_data = concatenate_block_managers(\n                mgrs_indexers, self.new_axes, concat_axis=self.bm_axis, copy=self.copy\n            )\n            if not self.copy:\n                new_data._consolidate_inplace()\n\n            cons = self.objs[0]._constructor\n            return cons(new_data).__finalize__(self, method=\"concat\")",
        "begin_line": 453,
        "end_line": 504,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator._get_result_dim#506",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator._get_result_dim(self)",
        "snippet": "    def _get_result_dim(self) -> int:\n        if self._is_series and self.bm_axis == 1:\n            return 2\n        else:\n            return self.objs[0].ndim",
        "begin_line": 506,
        "end_line": 510,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator._get_new_axes#512",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator._get_new_axes(self)",
        "snippet": "    def _get_new_axes(self) -> List[Index]:\n        ndim = self._get_result_dim()\n        return [\n            self._get_concat_axis() if i == self.bm_axis else self._get_comb_axis(i)\n            for i in range(ndim)\n        ]",
        "begin_line": 512,
        "end_line": 517,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator._get_comb_axis#519",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator._get_comb_axis(self, i: int)",
        "snippet": "    def _get_comb_axis(self, i: int) -> Index:\n        data_axis = self.objs[0]._get_block_manager_axis(i)\n        return get_objs_combined_axis(\n            self.objs,\n            axis=data_axis,\n            intersect=self.intersect,\n            sort=self.sort,\n            copy=self.copy,\n        )",
        "begin_line": 519,
        "end_line": 527,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator._get_concat_axis#529",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator._get_concat_axis(self)",
        "snippet": "    def _get_concat_axis(self) -> Index:\n        \"\"\"\n        Return index to be used along concatenation axis.\n        \"\"\"\n        if self._is_series:\n            if self.bm_axis == 0:\n                indexes = [x.index for x in self.objs]\n            elif self.ignore_index:\n                idx = ibase.default_index(len(self.objs))\n                return idx\n            elif self.keys is None:\n                names: List[Label] = [None] * len(self.objs)\n                num = 0\n                has_names = False\n                for i, x in enumerate(self.objs):\n                    if not isinstance(x, Series):\n                        raise TypeError(\n                            f\"Cannot concatenate type 'Series' with \"\n                            f\"object of type '{type(x).__name__}'\"\n                        )\n                    if x.name is not None:\n                        names[i] = x.name\n                        has_names = True\n                    else:\n                        names[i] = num\n                        num += 1\n                if has_names:\n                    return Index(names)\n                else:\n                    return ibase.default_index(len(self.objs))\n            else:\n                return ensure_index(self.keys).set_names(self.names)\n        else:\n            indexes = [x.axes[self.axis] for x in self.objs]\n\n        if self.ignore_index:\n            idx = ibase.default_index(sum(len(i) for i in indexes))\n            return idx\n\n        if self.keys is None:\n            concat_axis = _concat_indexes(indexes)\n        else:\n            concat_axis = _make_concat_multiindex(\n                indexes, self.keys, self.levels, self.names\n            )\n\n        self._maybe_check_integrity(concat_axis)\n\n        return concat_axis",
        "begin_line": 529,
        "end_line": 577,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.__init__#122",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.__init__(self, blocks: Sequence[Block], axes: Sequence[Index], do_integrity_check: bool=True)",
        "snippet": "    def __init__(\n        self,\n        blocks: Sequence[Block],\n        axes: Sequence[Index],\n        do_integrity_check: bool = True,\n    ):\n        self.axes = [ensure_index(ax) for ax in axes]\n        self.blocks: Tuple[Block, ...] = tuple(blocks)\n\n        for block in blocks:\n            if self.ndim != block.ndim:\n                raise AssertionError(\n                    f\"Number of Block dimensions ({block.ndim}) must equal \"\n                    f\"number of axes ({self.ndim})\"\n                )\n\n        if do_integrity_check:\n            self._verify_integrity()\n\n        # Populate known_consolidate, blknos, and blklocs lazily\n        self._known_consolidated = False\n        self._blknos = None\n        self._blklocs = None",
        "begin_line": 122,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.from_blocks#147",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.from_blocks(cls, blocks: List[Block], axes: List[Index])",
        "snippet": "    def from_blocks(cls, blocks: List[Block], axes: List[Index]):\n        \"\"\"\n        Constructor for BlockManager and SingleBlockManager with same signature.\n        \"\"\"\n        return cls(blocks, axes, do_integrity_check=False)",
        "begin_line": 147,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.blknos#154",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.blknos(self)",
        "snippet": "    def blknos(self):\n        \"\"\"\n        Suppose we want to find the array corresponding to our i'th column.\n\n        blknos[i] identifies the block from self.blocks that contains this column.\n\n        blklocs[i] identifies the column of interest within\n        self.blocks[self.blknos[i]]\n        \"\"\"\n        if self._blknos is None:\n            # Note: these can be altered by other BlockManager methods.\n            self._rebuild_blknos_and_blklocs()\n\n        return self._blknos",
        "begin_line": 154,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.blklocs#170",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.blklocs(self)",
        "snippet": "    def blklocs(self):\n        \"\"\"\n        See blknos.__doc__\n        \"\"\"\n        if self._blklocs is None:\n            # Note: these can be altered by other BlockManager methods.\n            self._rebuild_blknos_and_blklocs()\n\n        return self._blklocs",
        "begin_line": 170,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.shape#203",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.shape(self)",
        "snippet": "    def shape(self) -> Tuple[int, ...]:\n        return tuple(len(ax) for ax in self.axes)",
        "begin_line": 203,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.ndim#207",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.ndim(self)",
        "snippet": "    def ndim(self) -> int:\n        return len(self.axes)",
        "begin_line": 207,
        "end_line": 208,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.set_axis#210",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.set_axis(self, axis: int, new_labels: Index)",
        "snippet": "    def set_axis(self, axis: int, new_labels: Index) -> None:\n        # Caller is responsible for ensuring we have an Index object.\n        old_len = len(self.axes[axis])\n        new_len = len(new_labels)\n\n        if new_len != old_len:\n            raise ValueError(\n                f\"Length mismatch: Expected axis has {old_len} elements, new \"\n                f\"values have {new_len} elements\"\n            )\n\n        self.axes[axis] = new_labels",
        "begin_line": 210,
        "end_line": 221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._rebuild_blknos_and_blklocs#236",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._rebuild_blknos_and_blklocs(self)",
        "snippet": "    def _rebuild_blknos_and_blklocs(self) -> None:\n        \"\"\"\n        Update mgr._blknos / mgr._blklocs.\n        \"\"\"\n        new_blknos = np.empty(self.shape[0], dtype=np.int64)\n        new_blklocs = np.empty(self.shape[0], dtype=np.int64)\n        new_blknos.fill(-1)\n        new_blklocs.fill(-1)\n\n        for blkno, blk in enumerate(self.blocks):\n            rl = blk.mgr_locs\n            new_blknos[rl.indexer] = blkno\n            new_blklocs[rl.indexer] = np.arange(len(rl))\n\n        if (new_blknos == -1).any():\n            # TODO: can we avoid this?  it isn't cheap\n            raise AssertionError(\"Gaps in blk ref_locs\")\n\n        self._blknos = new_blknos\n        self._blklocs = new_blklocs",
        "begin_line": 236,
        "end_line": 255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.items#258",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.items(self)",
        "snippet": "    def items(self) -> Index:\n        return self.axes[0]",
        "begin_line": 258,
        "end_line": 259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.__len__#316",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.__len__(self)",
        "snippet": "    def __len__(self) -> int:\n        return len(self.items)",
        "begin_line": 316,
        "end_line": 317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._verify_integrity#331",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._verify_integrity(self)",
        "snippet": "    def _verify_integrity(self) -> None:\n        mgr_shape = self.shape\n        tot_items = sum(len(x.mgr_locs) for x in self.blocks)\n        for block in self.blocks:\n            if block._verify_integrity and block.shape[1:] != mgr_shape[1:]:\n                raise construction_error(tot_items, block.shape[1:], self.axes)\n        if len(self.items) != tot_items:\n            raise AssertionError(\n                \"Number of manager items must equal union of \"\n                f\"block items\\n# manager items: {len(self.items)}, # \"\n                f\"tot_items: {tot_items}\"\n            )",
        "begin_line": 331,
        "end_line": 342,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.apply#370",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.apply(self: T, f, align_keys=None, **kwargs)",
        "snippet": "    def apply(self: T, f, align_keys=None, **kwargs) -> T:\n        \"\"\"\n        Iterate over the blocks, collect and create a new BlockManager.\n\n        Parameters\n        ----------\n        f : str or callable\n            Name of the Block method to apply.\n\n        Returns\n        -------\n        BlockManager\n        \"\"\"\n        assert \"filter\" not in kwargs\n\n        align_keys = align_keys or []\n        result_blocks: List[Block] = []\n        # fillna: Series/DataFrame is responsible for making sure value is aligned\n\n        self._consolidate_inplace()\n\n        align_copy = False\n        if f == \"where\":\n            align_copy = True\n\n        aligned_args = {\n            k: kwargs[k]\n            for k in align_keys\n            if isinstance(kwargs[k], (ABCSeries, ABCDataFrame))\n        }\n\n        for b in self.blocks:\n\n            if aligned_args:\n                b_items = self.items[b.mgr_locs.indexer]\n\n                for k, obj in aligned_args.items():\n                    axis = obj._info_axis_number\n                    kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy)._values\n\n            if callable(f):\n                applied = b.apply(f, **kwargs)\n            else:\n                applied = getattr(b, f)(**kwargs)\n            result_blocks = _extend_blocks(applied, result_blocks)\n\n        if len(result_blocks) == 0:\n            return self.make_empty(self.axes)\n\n        return type(self).from_blocks(result_blocks, self.axes)",
        "begin_line": 370,
        "end_line": 419,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.is_consolidated#670",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.is_consolidated(self)",
        "snippet": "    def is_consolidated(self) -> bool:\n        \"\"\"\n        Return True if more than one block with the same dtype\n        \"\"\"\n        if not self._known_consolidated:\n            self._consolidate_check()\n        return self._is_consolidated",
        "begin_line": 670,
        "end_line": 676,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._consolidate_check#678",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._consolidate_check(self)",
        "snippet": "    def _consolidate_check(self) -> None:\n        dtypes = [blk.dtype for blk in self.blocks if blk._can_consolidate]\n        self._is_consolidated = len(dtypes) == len(set(dtypes))\n        self._known_consolidated = True",
        "begin_line": 678,
        "end_line": 681,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.copy#775",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.copy(self: T, deep=True)",
        "snippet": "    def copy(self: T, deep=True) -> T:\n        \"\"\"\n        Make deep or shallow copy of BlockManager\n\n        Parameters\n        ----------\n        deep : bool or string, default True\n            If False, return shallow copy (do not copy data)\n            If 'all', copy data and a deep copy of the index\n\n        Returns\n        -------\n        BlockManager\n        \"\"\"\n        # this preserves the notion of view copying of axes\n        if deep:\n            # hit in e.g. tests.io.json.test_pandas\n\n            def copy_func(ax):\n                return ax.copy(deep=True) if deep == \"all\" else ax.view()\n\n            new_axes = [copy_func(ax) for ax in self.axes]\n        else:\n            new_axes = list(self.axes)\n\n        res = self.apply(\"copy\", deep=deep)\n        res.axes = new_axes\n        return res",
        "begin_line": 775,
        "end_line": 802,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.copy_func#793",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.copy_func(ax)",
        "snippet": "            def copy_func(ax):\n                return ax.copy(deep=True) if deep == \"all\" else ax.view()",
        "begin_line": 793,
        "end_line": 794,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.consolidate#921",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.consolidate(self)",
        "snippet": "    def consolidate(self) -> \"BlockManager\":\n        \"\"\"\n        Join together blocks having same dtype\n\n        Returns\n        -------\n        y : BlockManager\n        \"\"\"\n        if self.is_consolidated():\n            return self\n\n        bm = type(self)(self.blocks, self.axes)\n        bm._is_consolidated = False\n        bm._consolidate_inplace()\n        return bm",
        "begin_line": 921,
        "end_line": 935,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._consolidate_inplace#937",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._consolidate_inplace(self)",
        "snippet": "    def _consolidate_inplace(self) -> None:\n        if not self.is_consolidated():\n            self.blocks = tuple(_consolidate(self.blocks))\n            self._is_consolidated = True\n            self._known_consolidated = True\n            self._rebuild_blknos_and_blklocs()",
        "begin_line": 937,
        "end_line": 942,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.get#944",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.get(self, item)",
        "snippet": "    def get(self, item):\n        \"\"\"\n        Return values for selected item (ndarray or BlockManager).\n        \"\"\"\n        if self.items.is_unique:\n\n            if not isna(item):\n                loc = self.items.get_loc(item)\n            else:\n                indexer = np.arange(len(self.items))[isna(self.items)]\n\n                # allow a single nan location indexer\n                if not is_scalar(indexer):\n                    if len(indexer) == 1:\n                        loc = indexer.item()\n                    else:\n                        raise ValueError(\"cannot label index with a null key\")\n\n            return self.iget(loc)\n        else:\n\n            if isna(item):\n                raise TypeError(\"cannot label index with a null key\")\n\n            indexer = self.items.get_indexer_for([item])\n            return self.reindex_indexer(\n                new_axis=self.items[indexer], indexer=indexer, axis=0, allow_dups=True\n            )",
        "begin_line": 944,
        "end_line": 971,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.iget#973",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.iget(self, i: int)",
        "snippet": "    def iget(self, i: int) -> \"SingleBlockManager\":\n        \"\"\"\n        Return the data as a SingleBlockManager.\n        \"\"\"\n        block = self.blocks[self.blknos[i]]\n        values = block.iget(self.blklocs[i])\n\n        # shortcut for select a single-dim from a 2-dim BM\n        return SingleBlockManager(\n            block.make_block_same_class(\n                values, placement=slice(0, len(values)), ndim=1\n            ),\n            self.axes[1],\n        )",
        "begin_line": 973,
        "end_line": 986,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.reindex_indexer#1243",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.reindex_indexer(self: T, new_axis, indexer, axis: int, fill_value=None, allow_dups: bool=False, copy: bool=True)",
        "snippet": "    def reindex_indexer(\n        self: T,\n        new_axis,\n        indexer,\n        axis: int,\n        fill_value=None,\n        allow_dups: bool = False,\n        copy: bool = True,\n    ) -> T:\n        \"\"\"\n        Parameters\n        ----------\n        new_axis : Index\n        indexer : ndarray of int64 or None\n        axis : int\n        fill_value : object, default None\n        allow_dups : bool, default False\n        copy : bool, default True\n\n\n        pandas-indexer with -1's only.\n        \"\"\"\n        if indexer is None:\n            if new_axis is self.axes[axis] and not copy:\n                return self\n\n            result = self.copy(deep=copy)\n            result.axes = list(self.axes)\n            result.axes[axis] = new_axis\n            return result\n\n        self._consolidate_inplace()\n\n        # some axes don't allow reindexing with dups\n        if not allow_dups:\n            self.axes[axis]._can_reindex(indexer)\n\n        if axis >= self.ndim:\n            raise IndexError(\"Requested axis not found in manager\")\n\n        if axis == 0:\n            new_blocks = self._slice_take_blocks_ax0(indexer, fill_value=fill_value)\n        else:\n            new_blocks = [\n                blk.take_nd(\n                    indexer,\n                    axis=axis,\n                    fill_value=(\n                        fill_value if fill_value is not None else blk.fill_value\n                    ),\n                )\n                for blk in self.blocks\n            ]\n\n        new_axes = list(self.axes)\n        new_axes[axis] = new_axis\n\n        return type(self).from_blocks(new_blocks, new_axes)",
        "begin_line": 1243,
        "end_line": 1300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.__init__#1485",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.__init__(self, block: Block, axis: Index, do_integrity_check: bool=False, fastpath=lib.no_default)",
        "snippet": "    def __init__(\n        self,\n        block: Block,\n        axis: Index,\n        do_integrity_check: bool = False,\n        fastpath=lib.no_default,\n    ):\n        assert isinstance(block, Block), type(block)\n        assert isinstance(axis, Index), type(axis)\n\n        if fastpath is not lib.no_default:\n            warnings.warn(\n                \"The `fastpath` keyword is deprecated and will be removed \"\n                \"in a future version.\",\n                FutureWarning,\n                stacklevel=2,\n            )\n\n        self.axes = [axis]\n        self.blocks = tuple([block])",
        "begin_line": 1485,
        "end_line": 1504,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.from_blocks#1507",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.from_blocks(cls, blocks: List[Block], axes: List[Index])",
        "snippet": "    def from_blocks(\n        cls, blocks: List[Block], axes: List[Index]\n    ) -> \"SingleBlockManager\":\n        \"\"\"\n        Constructor for BlockManager and SingleBlockManager with same signature.\n        \"\"\"\n        assert len(blocks) == 1\n        assert len(axes) == 1\n        return cls(blocks[0], axes[0], do_integrity_check=False)",
        "begin_line": 1507,
        "end_line": 1515,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.from_array#1518",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.from_array(cls, array: ArrayLike, index: Index)",
        "snippet": "    def from_array(cls, array: ArrayLike, index: Index) -> \"SingleBlockManager\":\n        \"\"\"\n        Constructor for if we have an array that is not yet a Block.\n        \"\"\"\n        block = make_block(array, placement=slice(0, len(index)), ndim=1)\n        return cls(block, index)",
        "begin_line": 1518,
        "end_line": 1523,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager._block#1529",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager._block(self)",
        "snippet": "    def _block(self) -> Block:\n        return self.blocks[0]",
        "begin_line": 1529,
        "end_line": 1530,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.dtype#1556",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.dtype(self)",
        "snippet": "    def dtype(self) -> DtypeObj:\n        return self._block.dtype",
        "begin_line": 1556,
        "end_line": 1557,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.external_values#1565",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.external_values(self)",
        "snippet": "    def external_values(self):\n        \"\"\"The array that Series.values returns\"\"\"\n        return self._block.external_values()",
        "begin_line": 1565,
        "end_line": 1567,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.internal_values#1569",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.internal_values(self)",
        "snippet": "    def internal_values(self):\n        \"\"\"The array that Series._values returns\"\"\"\n        return self._block.internal_values()",
        "begin_line": 1569,
        "end_line": 1571,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.is_consolidated#1577",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.is_consolidated(self)",
        "snippet": "    def is_consolidated(self) -> bool:\n        return True",
        "begin_line": 1577,
        "end_line": 1578,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager._consolidate_inplace#1583",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager._consolidate_inplace(self)",
        "snippet": "    def _consolidate_inplace(self):\n        pass",
        "begin_line": 1583,
        "end_line": 1584,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.create_block_manager_from_arrays#1631",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers.create_block_manager_from_arrays(arrays, names: Index, axes: List[Index])",
        "snippet": "def create_block_manager_from_arrays(\n    arrays, names: Index, axes: List[Index]\n) -> BlockManager:\n    assert isinstance(names, Index)\n    assert isinstance(axes, list)\n    assert all(isinstance(x, Index) for x in axes)\n\n    try:\n        blocks = form_blocks(arrays, names, axes)\n        mgr = BlockManager(blocks, axes)\n        mgr._consolidate_inplace()\n        return mgr\n    except ValueError as e:\n        raise construction_error(len(arrays), arrays[0].shape, axes, e)",
        "begin_line": 1631,
        "end_line": 1644,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers.form_blocks#1671",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers.form_blocks(arrays, names: Index, axes)",
        "snippet": "def form_blocks(arrays, names: Index, axes) -> List[Block]:\n    # put \"leftover\" items in float bucket, where else?\n    # generalize?\n    items_dict: DefaultDict[str, List] = defaultdict(list)\n    extra_locs = []\n\n    names_idx = names\n    if names_idx.equals(axes[0]):\n        names_indexer = np.arange(len(names_idx))\n    else:\n        assert names_idx.intersection(axes[0]).is_unique\n        names_indexer = names_idx.get_indexer_for(axes[0])\n\n    for i, name_idx in enumerate(names_indexer):\n        if name_idx == -1:\n            extra_locs.append(i)\n            continue\n\n        k = names[name_idx]\n        v = arrays[name_idx]\n\n        block_type = get_block_type(v)\n        items_dict[block_type.__name__].append((i, k, v))\n\n    blocks: List[Block] = []\n    if len(items_dict[\"FloatBlock\"]):\n        float_blocks = _multi_blockify(items_dict[\"FloatBlock\"])\n        blocks.extend(float_blocks)\n\n    if len(items_dict[\"ComplexBlock\"]):\n        complex_blocks = _multi_blockify(items_dict[\"ComplexBlock\"])\n        blocks.extend(complex_blocks)\n\n    if len(items_dict[\"TimeDeltaBlock\"]):\n        timedelta_blocks = _multi_blockify(items_dict[\"TimeDeltaBlock\"])\n        blocks.extend(timedelta_blocks)\n\n    if len(items_dict[\"IntBlock\"]):\n        int_blocks = _multi_blockify(items_dict[\"IntBlock\"])\n        blocks.extend(int_blocks)\n\n    if len(items_dict[\"DatetimeBlock\"]):\n        datetime_blocks = _simple_blockify(items_dict[\"DatetimeBlock\"], DT64NS_DTYPE)\n        blocks.extend(datetime_blocks)\n\n    if len(items_dict[\"DatetimeTZBlock\"]):\n        dttz_blocks = [\n            make_block(array, klass=DatetimeTZBlock, placement=i)\n            for i, _, array in items_dict[\"DatetimeTZBlock\"]\n        ]\n        blocks.extend(dttz_blocks)\n\n    if len(items_dict[\"BoolBlock\"]):\n        bool_blocks = _simple_blockify(items_dict[\"BoolBlock\"], np.bool_)\n        blocks.extend(bool_blocks)\n\n    if len(items_dict[\"ObjectBlock\"]) > 0:\n        object_blocks = _simple_blockify(items_dict[\"ObjectBlock\"], np.object_)\n        blocks.extend(object_blocks)\n\n    if len(items_dict[\"CategoricalBlock\"]) > 0:\n        cat_blocks = [\n            make_block(array, klass=CategoricalBlock, placement=i)\n            for i, _, array in items_dict[\"CategoricalBlock\"]\n        ]\n        blocks.extend(cat_blocks)\n\n    if len(items_dict[\"ExtensionBlock\"]):\n\n        external_blocks = [\n            make_block(array, klass=ExtensionBlock, placement=i)\n            for i, _, array in items_dict[\"ExtensionBlock\"]\n        ]\n\n        blocks.extend(external_blocks)\n\n    if len(items_dict[\"ObjectValuesExtensionBlock\"]):\n        external_blocks = [\n            make_block(array, klass=ObjectValuesExtensionBlock, placement=i)\n            for i, _, array in items_dict[\"ObjectValuesExtensionBlock\"]\n        ]\n\n        blocks.extend(external_blocks)\n\n    if len(extra_locs):\n        shape = (len(extra_locs),) + tuple(len(x) for x in axes[1:])\n\n        # empty items -> dtype object\n        block_values = np.empty(shape, dtype=object)\n        block_values.fill(np.nan)\n\n        na_block = make_block(block_values, placement=extra_locs)\n        blocks.append(na_block)\n\n    return blocks",
        "begin_line": 1671,
        "end_line": 1765,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers._simple_blockify#1768",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._simple_blockify(tuples, dtype)",
        "snippet": "def _simple_blockify(tuples, dtype):\n    \"\"\"\n    return a single array of a block that has a single dtype; if dtype is\n    not None, coerce to this dtype\n    \"\"\"\n    values, placement = _stack_arrays(tuples, dtype)\n\n    # TODO: CHECK DTYPE?\n    if dtype is not None and values.dtype != dtype:  # pragma: no cover\n        values = values.astype(dtype)\n\n    block = make_block(values, placement=placement)\n    return [block]",
        "begin_line": 1768,
        "end_line": 1780,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers._stack_arrays#1799",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._stack_arrays(tuples, dtype)",
        "snippet": "def _stack_arrays(tuples, dtype):\n\n    # fml\n    def _asarray_compat(x):\n        if isinstance(x, ABCSeries):\n            return x._values\n        else:\n            return np.asarray(x)\n\n    def _shape_compat(x):\n        if isinstance(x, ABCSeries):\n            return (len(x),)\n        else:\n            return x.shape\n\n    placement, names, arrays = zip(*tuples)\n\n    first = arrays[0]\n    shape = (len(arrays),) + _shape_compat(first)\n\n    stacked = np.empty(shape, dtype=dtype)\n    for i, arr in enumerate(arrays):\n        stacked[i] = _asarray_compat(arr)\n\n    return stacked, placement",
        "begin_line": 1799,
        "end_line": 1823,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers._asarray_compat#1802",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._asarray_compat(x)",
        "snippet": "    def _asarray_compat(x):\n        if isinstance(x, ABCSeries):\n            return x._values\n        else:\n            return np.asarray(x)",
        "begin_line": 1802,
        "end_line": 1806,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.managers._shape_compat#1808",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._shape_compat(x)",
        "snippet": "    def _shape_compat(x):\n        if isinstance(x, ABCSeries):\n            return (len(x),)\n        else:\n            return x.shape",
        "begin_line": 1808,
        "end_line": 1812,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasDtype.__init__#47",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasDtype",
        "signature": "pandas.core.arrays.numpy_.PandasDtype.__init__(self, dtype: object)",
        "snippet": "    def __init__(self, dtype: object):\n        self._dtype = np.dtype(dtype)",
        "begin_line": 47,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.__init__#157",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.__init__(self, values: Union[np.ndarray, 'PandasArray'], copy: bool=False)",
        "snippet": "    def __init__(self, values: Union[np.ndarray, \"PandasArray\"], copy: bool = False):\n        if isinstance(values, type(self)):\n            values = values._ndarray\n        if not isinstance(values, np.ndarray):\n            raise ValueError(\n                f\"'values' must be a NumPy array, not {type(values).__name__}\"\n            )\n\n        if values.ndim != 1:\n            raise ValueError(\"PandasArray must be 1-dimensional.\")\n\n        if copy:\n            values = values.copy()\n\n        self._ndarray = values\n        self._dtype = PandasDtype(values.dtype)",
        "begin_line": 157,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.__array__#202",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.__array__(self, dtype=None)",
        "snippet": "    def __array__(self, dtype=None) -> np.ndarray:\n        return np.asarray(self._ndarray, dtype=dtype)",
        "begin_line": 202,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.base.NoNewAttributesMixin._freeze#103",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.NoNewAttributesMixin",
        "signature": "pandas.core.base.NoNewAttributesMixin._freeze(self)",
        "snippet": "    def _freeze(self):\n        \"\"\"\n        Prevents setting additional attributes.\n        \"\"\"\n        object.__setattr__(self, \"__frozen\", True)",
        "begin_line": 103,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.base.NoNewAttributesMixin.__setattr__#110",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.NoNewAttributesMixin",
        "signature": "pandas.core.base.NoNewAttributesMixin.__setattr__(self, key: str, value)",
        "snippet": "    def __setattr__(self, key: str, value):\n        # _cache is used by a decorator\n        # We need to check both 1.) cls.__dict__ and 2.) getattr(self, key)\n        # because\n        # 1.) getattr is false for attributes that raise errors\n        # 2.) cls.__dict__ doesn't traverse into base classes\n        if getattr(self, \"__frozen\", False) and not (\n            key == \"_cache\"\n            or key in type(self).__dict__\n            or getattr(self, key, None) is not None\n        ):\n            raise AttributeError(f\"You cannot add any new attribute '{key}'\")\n        object.__setattr__(self, key, value)",
        "begin_line": 110,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.shape#622",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.shape(self)",
        "snippet": "    def shape(self):\n        \"\"\"\n        Return a tuple of the shape of the underlying data.\n        \"\"\"\n        return self._values.shape",
        "begin_line": 622,
        "end_line": 626,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.ndim#633",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.ndim(self)",
        "snippet": "    def ndim(self) -> int:\n        \"\"\"\n        Number of dimensions of the underlying data, by definition 1.\n        \"\"\"\n        return 1",
        "begin_line": 633,
        "end_line": 637,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.__iter__#1034",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.__iter__(self)",
        "snippet": "    def __iter__(self):\n        \"\"\"\n        Return an iterator of the values.\n\n        These are each a scalar type, which is a Python scalar\n        (for str, int, float) or a pandas scalar\n        (for Timestamp/Timedelta/Interval/Period)\n\n        Returns\n        -------\n        iterator\n        \"\"\"\n        # We are explicitly making element iterators.\n        if not isinstance(self._values, np.ndarray):\n            # Check type instead of dtype to catch DTA/TDA\n            return iter(self._values)\n        else:\n            return map(self._values.item, range(self._values.size))",
        "begin_line": 1034,
        "end_line": 1051,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.common.cast_scalar_indexer#143",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.cast_scalar_indexer(val)",
        "snippet": "def cast_scalar_indexer(val):\n    \"\"\"\n    To avoid numpy DeprecationWarnings, cast float to integer where valid.\n\n    Parameters\n    ----------\n    val : scalar\n\n    Returns\n    -------\n    outval : scalar\n    \"\"\"\n    # assumes lib.is_scalar(val)\n    if lib.is_float(val) and val.is_integer():\n        return int(val)\n    return val",
        "begin_line": 143,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.common.all_none#175",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.all_none(*args)",
        "snippet": "def all_none(*args) -> bool:\n    \"\"\"\n    Returns a boolean indicating if all arguments are None.\n    \"\"\"\n    return all(arg is None for arg in args)",
        "begin_line": 175,
        "end_line": 179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008396305625524769,
            "pseudo_dstar_susp": 0.015151515151515152,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.015151515151515152,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.common.asarray_tuplesafe#211",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.asarray_tuplesafe(values, dtype=None)",
        "snippet": "def asarray_tuplesafe(values, dtype=None):\n\n    if not (isinstance(values, (list, tuple)) or hasattr(values, \"__array__\")):\n        values = list(values)\n    elif isinstance(values, ABCIndexClass):\n        return values._values\n\n    if isinstance(values, list) and dtype in [np.object_, object]:\n        return construct_1d_object_array_from_listlike(values)\n\n    result = np.asarray(values, dtype=dtype)\n\n    if issubclass(result.dtype.type, str):\n        result = np.asarray(values, dtype=object)\n\n    if result.ndim == 2:\n        # Avoid building an array of arrays:\n        values = [tuple(x) for x in values]\n        result = construct_1d_object_array_from_listlike(values)\n\n    return result",
        "begin_line": 211,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.common.maybe_iterable_to_list#267",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.maybe_iterable_to_list(obj: Union[Iterable[T], T])",
        "snippet": "def maybe_iterable_to_list(obj: Union[Iterable[T], T]) -> Union[Collection[T], T]:\n    \"\"\"\n    If obj is Iterable but not list-like, consume into list.\n    \"\"\"\n    if isinstance(obj, abc.Iterable) and not isinstance(obj, abc.Sized):\n        return list(obj)\n    return obj",
        "begin_line": 267,
        "end_line": 273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.common.apply_if_callable#322",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.apply_if_callable(maybe_callable, obj, **kwargs)",
        "snippet": "def apply_if_callable(maybe_callable, obj, **kwargs):\n    \"\"\"\n    Evaluate possibly callable input using obj and kwargs if it is callable,\n    otherwise return as it is.\n\n    Parameters\n    ----------\n    maybe_callable : possibly a callable\n    obj : NDFrame\n    **kwargs\n    \"\"\"\n    if callable(maybe_callable):\n        return maybe_callable(obj, **kwargs)\n\n    return maybe_callable",
        "begin_line": 322,
        "end_line": 336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.accessor.CachedAccessor.__get__#183",
        "src_path": "pandas/core/accessor.py",
        "class_name": "pandas.core.accessor.CachedAccessor",
        "signature": "pandas.core.accessor.CachedAccessor.__get__(self, obj, cls)",
        "snippet": "    def __get__(self, obj, cls):\n        if obj is None:\n            # we're accessing the attribute of the class, i.e., Dataset.geo\n            return self._accessor\n        accessor_obj = self._accessor(obj)\n        # Replace the property with the accessor object. Inspired by:\n        # https://www.pydanny.com/cached-property.html\n        # We need to use object.__setattr__ because we overwrite __setattr__ on\n        # NDFrame\n        object.__setattr__(obj, self._name, accessor_obj)\n        return accessor_obj",
        "begin_line": 183,
        "end_line": 193,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_number#31",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_number(obj)",
        "snippet": "def is_number(obj) -> bool:\n    \"\"\"\n    Check if the object is a number.\n\n    Returns True when the object is a number, and False if is not.\n\n    Parameters\n    ----------\n    obj : any type\n        The object to check if is a number.\n\n    Returns\n    -------\n    is_number : bool\n        Whether `obj` is a number or not.\n\n    See Also\n    --------\n    api.types.is_integer: Checks a subgroup of numbers.\n\n    Examples\n    --------\n    >>> pd.api.types.is_number(1)\n    True\n    >>> pd.api.types.is_number(7.15)\n    True\n\n    Booleans are valid because they are int subclass.\n\n    >>> pd.api.types.is_number(False)\n    True\n\n    >>> pd.api.types.is_number(\"foo\")\n    False\n    >>> pd.api.types.is_number(\"5\")\n    False\n    \"\"\"\n    return isinstance(obj, (Number, np.number))",
        "begin_line": 31,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005617977528089888,
            "pseudo_dstar_susp": 0.0005617977528089888,
            "pseudo_tarantula_susp": 0.0005617977528089888,
            "pseudo_op2_susp": 0.0005605381165919282,
            "pseudo_barinel_susp": 0.0005617977528089888
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_dict_like#263",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_dict_like(obj)",
        "snippet": "def is_dict_like(obj) -> bool:\n    \"\"\"\n    Check if the object is dict-like.\n\n    Parameters\n    ----------\n    obj : The object to check\n\n    Returns\n    -------\n    is_dict_like : bool\n        Whether `obj` has dict-like properties.\n\n    Examples\n    --------\n    >>> is_dict_like({1: 2})\n    True\n    >>> is_dict_like([1, 2, 3])\n    False\n    >>> is_dict_like(dict)\n    False\n    >>> is_dict_like(dict())\n    True\n    \"\"\"\n    dict_like_attrs = (\"__getitem__\", \"keys\", \"__contains__\")\n    return (\n        all(hasattr(obj, attr) for attr in dict_like_attrs)\n        # [GH 25196] exclude classes\n        and not isinstance(obj, type)\n    )",
        "begin_line": 263,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008396305625524769,
            "pseudo_dstar_susp": 0.015151515151515152,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.015151515151515152,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_hashable#322",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_hashable(obj)",
        "snippet": "def is_hashable(obj) -> bool:\n    \"\"\"\n    Return True if hash(obj) will succeed, False otherwise.\n\n    Some types will pass a test against collections.abc.Hashable but fail when\n    they are actually hashed with hash().\n\n    Distinguish between these and other types by trying the call to hash() and\n    seeing if they raise TypeError.\n\n    Returns\n    -------\n    bool\n\n    Examples\n    --------\n    >>> import collections\n    >>> a = ([],)\n    >>> isinstance(a, collections.abc.Hashable)\n    True\n    >>> is_hashable(a)\n    False\n    \"\"\"\n    # Unfortunately, we can't use isinstance(obj, collections.abc.Hashable),\n    # which can be faster than calling hash. That is because numpy scalars\n    # fail this test.\n\n    # Reconsider this decision once this numpy bug is fixed:\n    # https://github.com/numpy/numpy/issues/5562\n\n    try:\n        hash(obj)\n    except TypeError:\n        return False\n    else:\n        return True",
        "begin_line": 322,
        "end_line": 357,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_sequence#360",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_sequence(obj)",
        "snippet": "def is_sequence(obj) -> bool:\n    \"\"\"\n    Check if the object is a sequence of objects.\n    String types are not included as sequences here.\n\n    Parameters\n    ----------\n    obj : The object to check\n\n    Returns\n    -------\n    is_sequence : bool\n        Whether `obj` is a sequence of objects.\n\n    Examples\n    --------\n    >>> l = [1, 2, 3]\n    >>>\n    >>> is_sequence(l)\n    True\n    >>> is_sequence(iter(l))\n    False\n    \"\"\"\n    try:\n        iter(obj)  # Can iterate over it.\n        len(obj)  # Has a length associated with it.\n        return not isinstance(obj, (str, bytes))\n    except (TypeError, AttributeError):\n        return False",
        "begin_line": 360,
        "end_line": 388,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.frozen.FrozenList.__getitem__#66",
        "src_path": "pandas/core/indexes/frozen.py",
        "class_name": "pandas.core.indexes.frozen.FrozenList",
        "signature": "pandas.core.indexes.frozen.FrozenList.__getitem__(self, n)",
        "snippet": "    def __getitem__(self, n):\n        if isinstance(n, slice):\n            return type(self)(super().__getitem__(n))\n        return super().__getitem__(n)",
        "begin_line": 66,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.frozen.FrozenList.__eq__#76",
        "src_path": "pandas/core/indexes/frozen.py",
        "class_name": "pandas.core.indexes.frozen.FrozenList",
        "signature": "pandas.core.indexes.frozen.FrozenList.__eq__(self, other: Any)",
        "snippet": "    def __eq__(self, other: Any) -> bool:\n        if isinstance(other, (tuple, FrozenList)):\n            other = list(other)\n        return super().__eq__(other)",
        "begin_line": 76,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005617977528089888,
            "pseudo_dstar_susp": 0.0005617977528089888,
            "pseudo_tarantula_susp": 0.0005617977528089888,
            "pseudo_op2_susp": 0.0005605381165919282,
            "pseudo_barinel_susp": 0.0005617977528089888
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.__new__#88",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.__new__(cls, start=None, stop=None, step=None, dtype=None, copy=False, name=None)",
        "snippet": "    def __new__(\n        cls, start=None, stop=None, step=None, dtype=None, copy=False, name=None,\n    ):\n\n        cls._validate_dtype(dtype)\n        name = maybe_extract_name(name, start, cls)\n\n        # RangeIndex\n        if isinstance(start, RangeIndex):\n            start = start._range\n            return cls._simple_new(start, name=name)\n\n        # validate the arguments\n        if com.all_none(start, stop, step):\n            raise TypeError(\"RangeIndex(...) must be called with integers\")\n\n        start = ensure_python_int(start) if start is not None else 0\n\n        if stop is None:\n            start, stop = 0, start\n        else:\n            stop = ensure_python_int(stop)\n\n        step = ensure_python_int(step) if step is not None else 1\n        if step == 0:\n            raise ValueError(\"Step must not be zero\")\n\n        rng = range(start, stop, step)\n        return cls._simple_new(rng, name=name)",
        "begin_line": 88,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._simple_new#137",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._simple_new(cls, values: range, name: Label=None)",
        "snippet": "    def _simple_new(cls, values: range, name: Label = None) -> \"RangeIndex\":\n        result = object.__new__(cls)\n\n        assert isinstance(values, range)\n\n        result._range = values\n        result.name = name\n        result._cache = {}\n        result._reset_identity()\n        return result",
        "begin_line": 137,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._data#156",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._data(self)",
        "snippet": "    def _data(self):\n        \"\"\"\n        An int array that for performance reasons is created only when needed.\n\n        The constructed array is saved in ``_cached_data``. This allows us to\n        check if the array has been created without accessing ``_data`` and\n        triggering the construction.\n        \"\"\"\n        if self._cached_data is None:\n            self._cached_data = np.arange(\n                self.start, self.stop, self.step, dtype=np.int64\n            )\n        return self._cached_data",
        "begin_line": 156,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._get_data_as_items#174",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._get_data_as_items(self)",
        "snippet": "    def _get_data_as_items(self):\n        \"\"\" return a list of tuples of start, stop, step \"\"\"\n        rng = self._range\n        return [(\"start\", rng.start), (\"stop\", rng.stop), (\"step\", rng.step)]",
        "begin_line": 174,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._format_attrs#187",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._format_attrs(self)",
        "snippet": "    def _format_attrs(self):\n        \"\"\"\n        Return a list of tuples of the (attr, formatted_value)\n        \"\"\"\n        attrs = self._get_data_as_items()\n        if self.name is not None:\n            attrs.append((\"name\", ibase.default_pprint(self.name)))\n        return attrs",
        "begin_line": 187,
        "end_line": 194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._format_data#196",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._format_data(self, name=None)",
        "snippet": "    def _format_data(self, name=None):\n        # we are formatting thru the attributes\n        return None",
        "begin_line": 196,
        "end_line": 198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.start#211",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.start(self)",
        "snippet": "    def start(self):\n        \"\"\"\n        The value of the `start` parameter (``0`` if this was not supplied).\n        \"\"\"\n        # GH 25710\n        return self._range.start",
        "begin_line": 211,
        "end_line": 216,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.stop#234",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.stop(self)",
        "snippet": "    def stop(self):\n        \"\"\"\n        The value of the `stop` parameter.\n        \"\"\"\n        return self._range.stop",
        "begin_line": 234,
        "end_line": 238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.step#257",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.step(self)",
        "snippet": "    def step(self):\n        \"\"\"\n        The value of the `step` parameter (``1`` if this was not supplied).\n        \"\"\"\n        # GH 25710\n        return self._range.step",
        "begin_line": 257,
        "end_line": 262,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.dtype#317",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.dtype(self)",
        "snippet": "    def dtype(self) -> np.dtype:\n        return np.dtype(np.int64)",
        "begin_line": 317,
        "end_line": 318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._shallow_copy#390",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._shallow_copy(self, values=None, name: Label=no_default)",
        "snippet": "    def _shallow_copy(self, values=None, name: Label = no_default):\n        name = self.name if name is no_default else name\n\n        if values is None:\n            result = self._simple_new(self._range, name=name)\n            result._cache = self._cache.copy()\n            return result\n        else:\n            return Int64Index._simple_new(values, name=name)",
        "begin_line": 390,
        "end_line": 398,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.equals#448",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.equals(self, other)",
        "snippet": "    def equals(self, other) -> bool:\n        \"\"\"\n        Determines if two Index objects contain the same elements.\n        \"\"\"\n        if isinstance(other, RangeIndex):\n            return self._range == other._range\n        return super().equals(other)",
        "begin_line": 448,
        "end_line": 454,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.join#623",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.join(self, other, how='left', level=None, return_indexers=False, sort=False)",
        "snippet": "    def join(self, other, how=\"left\", level=None, return_indexers=False, sort=False):\n        if how == \"outer\" and self is not other:\n            # note: could return RangeIndex in more circumstances\n            return self._int64index.join(other, how, level, return_indexers, sort)\n\n        return super().join(other, how, level, return_indexers, sort)",
        "begin_line": 623,
        "end_line": 628,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.__len__#679",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.__len__(self)",
        "snippet": "    def __len__(self) -> int:\n        \"\"\"\n        return the length of the RangeIndex\n        \"\"\"\n        return len(self._range)",
        "begin_line": 679,
        "end_line": 683,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.util._decorators.decorator#354",
        "src_path": "pandas/util/_decorators.py",
        "class_name": "pandas.util._decorators",
        "signature": "pandas.util._decorators.decorator(func: F)",
        "snippet": "    def decorator(func: F) -> F:\n        @wraps(func)\n        def wrapper(*args, **kwargs) -> Callable:\n            return func(*args, **kwargs)\n\n        # collecting docstring and docstring templates\n        docstring_components: List[Union[str, Callable]] = []\n        if func.__doc__:\n            docstring_components.append(dedent(func.__doc__))\n\n        for arg in args:\n            if hasattr(arg, \"_docstring_components\"):\n                docstring_components.extend(arg._docstring_components)  # type: ignore\n            elif isinstance(arg, str) or arg.__doc__:\n                docstring_components.append(arg)\n\n        # formatting templates and concatenating docstring\n        wrapper.__doc__ = \"\".join(\n            [\n                arg.format(**kwargs)\n                if isinstance(arg, str)\n                else dedent(arg.__doc__ or \"\")\n                for arg in docstring_components\n            ]\n        )\n\n        wrapper._docstring_components = docstring_components  # type: ignore\n\n        return cast(F, wrapper)",
        "begin_line": 354,
        "end_line": 382,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.util._decorators.wrapper#356",
        "src_path": "pandas/util/_decorators.py",
        "class_name": "pandas.util._decorators",
        "signature": "pandas.util._decorators.wrapper(*args, **kwargs)",
        "snippet": "        def wrapper(*args, **kwargs) -> Callable:\n            return func(*args, **kwargs)",
        "begin_line": 356,
        "end_line": 357,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.format.TextAdjustment.__init__#390",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.TextAdjustment",
        "signature": "pandas.io.formats.format.TextAdjustment.__init__(self)",
        "snippet": "    def __init__(self):\n        self.encoding = get_option(\"display.encoding\")",
        "begin_line": 390,
        "end_line": 391,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.format.TextAdjustment.len#393",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.TextAdjustment",
        "signature": "pandas.io.formats.format.TextAdjustment.len(self, text: str)",
        "snippet": "    def len(self, text: str) -> int:\n        return len(text)",
        "begin_line": 393,
        "end_line": 394,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.format._get_adjustment#442",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format._get_adjustment()",
        "snippet": "def _get_adjustment() -> TextAdjustment:\n    use_east_asian_width = get_option(\"display.unicode.east_asian_width\")\n    if use_east_asian_width:\n        return EastAsianTextAdjustment()\n    else:\n        return TextAdjustment()",
        "begin_line": 442,
        "end_line": 447,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.__init__#115",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.__init__(self, values, placement, ndim=None)",
        "snippet": "    def __init__(self, values, placement, ndim=None):\n        self.ndim = self._check_ndim(values, ndim)\n        self.mgr_locs = placement\n        self.values = values\n\n        if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):\n            raise ValueError(\n                f\"Wrong number of items passed {len(self.values)}, \"\n                f\"placement implies {len(self.mgr_locs)}\"\n            )",
        "begin_line": 115,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block._check_ndim#126",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block._check_ndim(self, values, ndim)",
        "snippet": "    def _check_ndim(self, values, ndim):\n        \"\"\"\n        ndim inference and validation.\n\n        Infers ndim from 'values' if not provided to __init__.\n        Validates that values.ndim and ndim are consistent if and only if\n        the class variable '_validate_ndim' is True.\n\n        Parameters\n        ----------\n        values : array-like\n        ndim : int or None\n\n        Returns\n        -------\n        ndim : int\n\n        Raises\n        ------\n        ValueError : the number of dimensions do not match\n        \"\"\"\n        if ndim is None:\n            ndim = values.ndim\n\n        if self._validate_ndim and values.ndim != ndim:\n            raise ValueError(\n                \"Wrong number of dimensions. \"\n                f\"values.ndim != ndim [{values.ndim} != {ndim}]\"\n            )\n        return ndim",
        "begin_line": 126,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.external_values#185",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.external_values(self)",
        "snippet": "    def external_values(self):\n        \"\"\"\n        The array that Series.values returns (public attribute).\n\n        This has some historical constraints, and is overridden in block\n        subclasses to return the correct array (e.g. period returns\n        object ndarray and datetimetz a datetime64[ns] ndarray instead of\n        proper extension array).\n        \"\"\"\n        return self.values",
        "begin_line": 185,
        "end_line": 194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.internal_values#196",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.internal_values(self)",
        "snippet": "    def internal_values(self):\n        \"\"\"\n        The array that Series._values returns (internal values).\n        \"\"\"\n        return self.values",
        "begin_line": 196,
        "end_line": 200,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.array_values#202",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.array_values(self)",
        "snippet": "    def array_values(self) -> ExtensionArray:\n        \"\"\"\n        The array that Series.array returns. Always an ExtensionArray.\n        \"\"\"\n        return PandasArray(self.values)",
        "begin_line": 202,
        "end_line": 206,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.fill_value#225",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.fill_value(self)",
        "snippet": "    def fill_value(self):\n        return np.nan",
        "begin_line": 225,
        "end_line": 226,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.mgr_locs#229",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.mgr_locs(self)",
        "snippet": "    def mgr_locs(self):\n        return self._mgr_locs",
        "begin_line": 229,
        "end_line": 230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.mgr_locs#233",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.mgr_locs(self, new_mgr_locs)",
        "snippet": "    def mgr_locs(self, new_mgr_locs):\n        if not isinstance(new_mgr_locs, libinternals.BlockPlacement):\n            new_mgr_locs = libinternals.BlockPlacement(new_mgr_locs)\n\n        self._mgr_locs = new_mgr_locs",
        "begin_line": 233,
        "end_line": 237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.make_block_same_class#251",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.make_block_same_class(self, values, placement=None, ndim=None)",
        "snippet": "    def make_block_same_class(self, values, placement=None, ndim=None):\n        \"\"\" Wrap given values in a block of same type as self. \"\"\"\n        if placement is None:\n            placement = self.mgr_locs\n        if ndim is None:\n            ndim = self.ndim\n        return make_block(values, placement=placement, ndim=ndim, klass=type(self))",
        "begin_line": 251,
        "end_line": 257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.shape#304",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.shape(self)",
        "snippet": "    def shape(self):\n        return self.values.shape",
        "begin_line": 304,
        "end_line": 305,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.dtype#308",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.dtype(self)",
        "snippet": "    def dtype(self):\n        return self.values.dtype",
        "begin_line": 308,
        "end_line": 309,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.iget#321",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.iget(self, i)",
        "snippet": "    def iget(self, i):\n        return self.values[i]",
        "begin_line": 321,
        "end_line": 322,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.copy#670",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.copy(self, deep: bool=True)",
        "snippet": "    def copy(self, deep: bool = True):\n        \"\"\" copy constructor \"\"\"\n        values = self.values\n        if deep:\n            values = values.copy()\n        return self.make_block_same_class(values, ndim=self.ndim)",
        "begin_line": 670,
        "end_line": 675,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.take_nd#1233",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.take_nd(self, indexer, axis: int, new_mgr_locs=None, fill_value=lib.no_default)",
        "snippet": "    def take_nd(self, indexer, axis: int, new_mgr_locs=None, fill_value=lib.no_default):\n        \"\"\"\n        Take values according to indexer and return them as a block.bb\n\n        \"\"\"\n        # algos.take_nd dispatches for DatetimeTZBlock, CategoricalBlock\n        # so need to preserve types\n        # sparse is treated like an ndarray, but needs .get_values() shaping\n\n        values = self.values\n\n        if fill_value is lib.no_default:\n            fill_value = self.fill_value\n            allow_fill = False\n        else:\n            allow_fill = True\n\n        new_values = algos.take_nd(\n            values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\n        )\n\n        # Called from three places in managers, all of which satisfy\n        #  this assertion\n        assert not (axis == 0 and new_mgr_locs is None)\n        if new_mgr_locs is None:\n            new_mgr_locs = self.mgr_locs\n\n        if not is_dtype_equal(new_values.dtype, self.dtype):\n            return self.make_block(new_values, new_mgr_locs)\n        else:\n            return self.make_block_same_class(new_values, new_mgr_locs)",
        "begin_line": 1233,
        "end_line": 1263,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.blocks.ObjectBlock.__init__#2380",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.ObjectBlock",
        "signature": "pandas.core.internals.blocks.ObjectBlock.__init__(self, values, placement=None, ndim=2)",
        "snippet": "    def __init__(self, values, placement=None, ndim=2):\n        if issubclass(values.dtype.type, str):\n            values = np.array(values, dtype=object)\n\n        super().__init__(values, ndim=ndim, placement=placement)",
        "begin_line": 2380,
        "end_line": 2384,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.blocks.get_block_type#2683",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks.get_block_type(values, dtype=None)",
        "snippet": "def get_block_type(values, dtype=None):\n    \"\"\"\n    Find the appropriate Block subclass to use for the given values and dtype.\n\n    Parameters\n    ----------\n    values : ndarray-like\n    dtype : numpy or pandas dtype\n\n    Returns\n    -------\n    cls : class, subclass of Block\n    \"\"\"\n    dtype = dtype or values.dtype\n    vtype = dtype.type\n\n    if is_sparse(dtype):\n        # Need this first(ish) so that Sparse[datetime] is sparse\n        cls = ExtensionBlock\n    elif is_categorical_dtype(values.dtype):\n        cls = CategoricalBlock\n    elif issubclass(vtype, np.datetime64):\n        assert not is_datetime64tz_dtype(values)\n        cls = DatetimeBlock\n    elif is_datetime64tz_dtype(values):\n        cls = DatetimeTZBlock\n    elif is_interval_dtype(dtype) or is_period_dtype(dtype):\n        cls = ObjectValuesExtensionBlock\n    elif is_extension_array_dtype(values):\n        cls = ExtensionBlock\n    elif issubclass(vtype, np.floating):\n        cls = FloatBlock\n    elif issubclass(vtype, np.timedelta64):\n        assert issubclass(vtype, np.integer)\n        cls = TimeDeltaBlock\n    elif issubclass(vtype, np.complexfloating):\n        cls = ComplexBlock\n    elif issubclass(vtype, np.integer):\n        cls = IntBlock\n    elif dtype == np.bool_:\n        cls = BoolBlock\n    else:\n        cls = ObjectBlock\n    return cls",
        "begin_line": 2683,
        "end_line": 2726,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.internals.blocks.make_block#2729",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks.make_block(values, placement, klass=None, ndim=None, dtype=None)",
        "snippet": "def make_block(values, placement, klass=None, ndim=None, dtype=None):\n    # Ensure that we don't allow PandasArray / PandasDtype in internals.\n    # For now, blocks should be backed by ndarrays when possible.\n    if isinstance(values, ABCPandasArray):\n        values = values.to_numpy()\n        if ndim and ndim > 1:\n            values = np.atleast_2d(values)\n\n    if isinstance(dtype, PandasDtype):\n        dtype = dtype.numpy_dtype\n\n    if klass is None:\n        dtype = dtype or values.dtype\n        klass = get_block_type(values, dtype)\n\n    elif klass is DatetimeTZBlock and not is_datetime64tz_dtype(values):\n        # TODO: This is no longer hit internally; does it need to be retained\n        #  for e.g. pyarrow?\n        values = DatetimeArray._simple_new(values, dtype=dtype)\n\n    return klass(values, ndim=ndim, placement=placement)",
        "begin_line": 2729,
        "end_line": 2749,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.blocks._extend_blocks#2755",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks._extend_blocks(result, blocks=None)",
        "snippet": "def _extend_blocks(result, blocks=None):\n    \"\"\" return a new extended blocks, given the result \"\"\"\n    if blocks is None:\n        blocks = []\n    if isinstance(result, list):\n        for r in result:\n            if isinstance(r, list):\n                blocks.extend(r)\n            else:\n                blocks.append(r)\n    else:\n        assert isinstance(result, Block), type(result)\n        blocks.append(result)\n    return blocks",
        "begin_line": 2755,
        "end_line": 2768,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.console.get_console_size#8",
        "src_path": "pandas/io/formats/console.py",
        "class_name": "pandas.io.formats.console",
        "signature": "pandas.io.formats.console.get_console_size()",
        "snippet": "def get_console_size():\n    \"\"\"\n    Return console size as tuple = (width, height).\n\n    Returns (None,None) in non-interactive session.\n    \"\"\"\n    from pandas import get_option\n\n    display_width = get_option(\"display.width\")\n    display_height = get_option(\"display.max_rows\")\n\n    # Consider\n    # interactive shell terminal, can detect term size\n    # interactive non-shell terminal (ipnb/ipqtconsole), cannot detect term\n    # size non-interactive script, should disregard term size\n\n    # in addition\n    # width,height have default values, but setting to 'None' signals\n    # should use Auto-Detection, But only in interactive shell-terminal.\n    # Simple. yeah.\n\n    if in_interactive_session():\n        if in_ipython_frontend():\n            # sane defaults for interactive non-shell terminal\n            # match default for width,height in config_init\n            from pandas._config.config import get_default_val\n\n            terminal_width = get_default_val(\"display.width\")\n            terminal_height = get_default_val(\"display.max_rows\")\n        else:\n            # pure terminal\n            terminal_width, terminal_height = get_terminal_size()\n    else:\n        terminal_width, terminal_height = None, None\n\n    # Note if the User sets width/Height to None (auto-detection)\n    # and we're in a script (non-inter), this will return (None,None)\n    # caller needs to deal.\n    return (display_width or terminal_width, display_height or terminal_height)",
        "begin_line": 8,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.console.in_interactive_session#53",
        "src_path": "pandas/io/formats/console.py",
        "class_name": "pandas.io.formats.console",
        "signature": "pandas.io.formats.console.in_interactive_session()",
        "snippet": "def in_interactive_session():\n    \"\"\"\n    Check if we're running in an interactive shell.\n\n    Returns\n    -------\n    bool\n        True if running under python/ipython interactive shell.\n    \"\"\"\n    from pandas import get_option\n\n    def check_main():\n        try:\n            import __main__ as main\n        except ModuleNotFoundError:\n            return get_option(\"mode.sim_interactive\")\n        return not hasattr(main, \"__file__\") or get_option(\"mode.sim_interactive\")\n\n    try:\n        return __IPYTHON__ or check_main()  # noqa\n    except NameError:\n        return check_main()",
        "begin_line": 53,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.console.check_main#64",
        "src_path": "pandas/io/formats/console.py",
        "class_name": "pandas.io.formats.console",
        "signature": "pandas.io.formats.console.check_main()",
        "snippet": "    def check_main():\n        try:\n            import __main__ as main\n        except ModuleNotFoundError:\n            return get_option(\"mode.sim_interactive\")\n        return not hasattr(main, \"__file__\") or get_option(\"mode.sim_interactive\")",
        "begin_line": 64,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.base.ExtensionDtype.construct_from_string#200",
        "src_path": "pandas/core/dtypes/base.py",
        "class_name": "pandas.core.dtypes.base.ExtensionDtype",
        "signature": "pandas.core.dtypes.base.ExtensionDtype.construct_from_string(cls, string: str)",
        "snippet": "    def construct_from_string(cls, string: str):\n        r\"\"\"\n        Construct this type from a string.\n\n        This is useful mainly for data types that accept parameters.\n        For example, a period dtype accepts a frequency parameter that\n        can be set as ``period[H]`` (where H means hourly frequency).\n\n        By default, in the abstract class, just the name of the type is\n        expected. But subclasses can overwrite this method to accept\n        parameters.\n\n        Parameters\n        ----------\n        string : str\n            The name of the type, for example ``category``.\n\n        Returns\n        -------\n        ExtensionDtype\n            Instance of the dtype.\n\n        Raises\n        ------\n        TypeError\n            If a class cannot be constructed from this 'string'.\n\n        Examples\n        --------\n        For extension dtypes with arguments the following may be an\n        adequate implementation.\n\n        >>> @classmethod\n        ... def construct_from_string(cls, string):\n        ...     pattern = re.compile(r\"^my_type\\[(?P<arg_name>.+)\\]$\")\n        ...     match = pattern.match(string)\n        ...     if match:\n        ...         return cls(**match.groupdict())\n        ...     else:\n        ...         raise TypeError(\n        ...             f\"Cannot construct a '{cls.__name__}' from '{string}'\"\n        ...         )\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\n                f\"'construct_from_string' expects a string, got {type(string)}\"\n            )\n        # error: Non-overlapping equality check (left operand type: \"str\", right\n        #  operand type: \"Callable[[ExtensionDtype], str]\")  [comparison-overlap]\n        assert isinstance(cls.name, str), (cls, type(cls.name))\n        if string != cls.name:\n            raise TypeError(f\"Cannot construct a '{cls.__name__}' from '{string}'\")\n        return cls()",
        "begin_line": 200,
        "end_line": 252,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.base.ExtensionDtype.is_dtype#255",
        "src_path": "pandas/core/dtypes/base.py",
        "class_name": "pandas.core.dtypes.base.ExtensionDtype",
        "signature": "pandas.core.dtypes.base.ExtensionDtype.is_dtype(cls, dtype: object)",
        "snippet": "    def is_dtype(cls, dtype: object) -> bool:\n        \"\"\"\n        Check if we match 'dtype'.\n\n        Parameters\n        ----------\n        dtype : object\n            The object to check.\n\n        Returns\n        -------\n        bool\n\n        Notes\n        -----\n        The default implementation is True if\n\n        1. ``cls.construct_from_string(dtype)`` is an instance\n           of ``cls``.\n        2. ``dtype`` is an object and is an instance of ``cls``\n        3. ``dtype`` has a ``dtype`` attribute, and any of the above\n           conditions is true for ``dtype.dtype``.\n        \"\"\"\n        dtype = getattr(dtype, \"dtype\", dtype)\n\n        if isinstance(dtype, (ABCSeries, ABCIndexClass, ABCDataFrame, np.dtype)):\n            # https://github.com/pandas-dev/pandas/issues/22960\n            # avoid passing data to `construct_from_string`. This could\n            # cause a FutureWarning from numpy about failing elementwise\n            # comparison from, e.g., comparing DataFrame == 'category'.\n            return False\n        elif dtype is None:\n            return False\n        elif isinstance(dtype, cls):\n            return True\n        if isinstance(dtype, str):\n            try:\n                return cls.construct_from_string(dtype) is not None\n            except TypeError:\n                return False\n        return False",
        "begin_line": 255,
        "end_line": 295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas._config.config._get_single_key#86",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_single_key(pat: str, silent: bool)",
        "snippet": "def _get_single_key(pat: str, silent: bool) -> str:\n    keys = _select_options(pat)\n    if len(keys) == 0:\n        if not silent:\n            _warn_if_deprecated(pat)\n        raise OptionError(f\"No such keys(s): {repr(pat)}\")\n    if len(keys) > 1:\n        raise OptionError(\"Pattern matched multiple keys\")\n    key = keys[0]\n\n    if not silent:\n        _warn_if_deprecated(key)\n\n    key = _translate_key(key)\n\n    return key",
        "begin_line": 86,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000855431993156544,
            "pseudo_dstar_susp": 0.022727272727272728,
            "pseudo_tarantula_susp": 0.000855431993156544,
            "pseudo_op2_susp": 0.022727272727272728,
            "pseudo_barinel_susp": 0.000855431993156544
        }
    },
    {
        "name": "pandas._config.config._get_option#104",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_option(pat: str, silent: bool=False)",
        "snippet": "def _get_option(pat: str, silent: bool = False):\n    key = _get_single_key(pat, silent)\n\n    # walk the nested dict\n    root, k = _get_root(key)\n    return root[k]",
        "begin_line": 104,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas._config.config._set_option#112",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._set_option(*args, **kwargs)",
        "snippet": "def _set_option(*args, **kwargs) -> None:\n    # must at least 1 arg deal with constraints later\n    nargs = len(args)\n    if not nargs or nargs % 2 != 0:\n        raise ValueError(\"Must provide an even number of non-keyword arguments\")\n\n    # default to false\n    silent = kwargs.pop(\"silent\", False)\n\n    if kwargs:\n        kwarg = list(kwargs.keys())[0]\n        raise TypeError(f'_set_option() got an unexpected keyword argument \"{kwarg}\"')\n\n    for k, v in zip(args[::2], args[1::2]):\n        key = _get_single_key(k, silent)\n\n        o = _get_registered_option(key)\n        if o and o.validator:\n            o.validator(v)\n\n        # walk the nested dict\n        root, k = _get_root(key)\n        root[k] = v\n\n        if o.cb:\n            if silent:\n                with warnings.catch_warnings(record=True):\n                    o.cb(key)\n            else:\n                o.cb(key)",
        "begin_line": 112,
        "end_line": 141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas._config.config.CallableDynamicDoc.__call__#232",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config.CallableDynamicDoc",
        "signature": "pandas._config.config.CallableDynamicDoc.__call__(self, *args, **kwds)",
        "snippet": "    def __call__(self, *args, **kwds):\n        return self.__func__(*args, **kwds)",
        "begin_line": 232,
        "end_line": 233,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000855431993156544,
            "pseudo_dstar_susp": 0.022727272727272728,
            "pseudo_tarantula_susp": 0.000855431993156544,
            "pseudo_op2_susp": 0.022727272727272728,
            "pseudo_barinel_susp": 0.000855431993156544
        }
    },
    {
        "name": "pandas._config.config._select_options#539",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._select_options(pat: str)",
        "snippet": "def _select_options(pat: str) -> List[str]:\n    \"\"\"\n    returns a list of keys matching `pat`\n\n    if pat==\"all\", returns all registered options\n    \"\"\"\n    # short-circuit for exact key\n    if pat in _registered_options:\n        return [pat]\n\n    # else look through all of them\n    keys = sorted(_registered_options.keys())\n    if pat == \"all\":  # reserved key\n        return keys\n\n    return [k for k in keys if re.search(pat, k, re.I)]",
        "begin_line": 539,
        "end_line": 554,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.022727272727272728,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.022727272727272728,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas._config.config._get_root#557",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_root(key: str)",
        "snippet": "def _get_root(key: str) -> Tuple[Dict[str, Any], str]:\n    path = key.split(\".\")\n    cursor = _global_config\n    for p in path[:-1]:\n        cursor = cursor[p]\n    return cursor, path[-1]",
        "begin_line": 557,
        "end_line": 562,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000855431993156544,
            "pseudo_dstar_susp": 0.022727272727272728,
            "pseudo_tarantula_susp": 0.000855431993156544,
            "pseudo_op2_susp": 0.022727272727272728,
            "pseudo_barinel_susp": 0.000855431993156544
        }
    },
    {
        "name": "pandas._config.config._get_deprecated_option#571",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_deprecated_option(key: str)",
        "snippet": "def _get_deprecated_option(key: str):\n    \"\"\"\n    Retrieves the metadata for a deprecated option, if `key` is deprecated.\n\n    Returns\n    -------\n    DeprecatedOption (namedtuple) if key is deprecated, None otherwise\n    \"\"\"\n    try:\n        d = _deprecated_options[key]\n    except KeyError:\n        return None\n    else:\n        return d",
        "begin_line": 571,
        "end_line": 584,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000855431993156544,
            "pseudo_dstar_susp": 0.022727272727272728,
            "pseudo_tarantula_susp": 0.000855431993156544,
            "pseudo_op2_susp": 0.022727272727272728,
            "pseudo_barinel_susp": 0.000855431993156544
        }
    },
    {
        "name": "pandas._config.config._get_registered_option#587",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_registered_option(key: str)",
        "snippet": "def _get_registered_option(key: str):\n    \"\"\"\n    Retrieves the option metadata if `key` is a registered option.\n\n    Returns\n    -------\n    RegisteredOption (namedtuple) if key is deprecated, None otherwise\n    \"\"\"\n    return _registered_options.get(key)",
        "begin_line": 587,
        "end_line": 595,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas._config.config._translate_key#598",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._translate_key(key: str)",
        "snippet": "def _translate_key(key: str) -> str:\n    \"\"\"\n    if key id deprecated and a replacement key defined, will return the\n    replacement key, otherwise returns `key` as - is\n    \"\"\"\n    d = _get_deprecated_option(key)\n    if d:\n        return d.rkey or key\n    else:\n        return key",
        "begin_line": 598,
        "end_line": 607,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000855431993156544,
            "pseudo_dstar_susp": 0.022727272727272728,
            "pseudo_tarantula_susp": 0.000855431993156544,
            "pseudo_op2_susp": 0.022727272727272728,
            "pseudo_barinel_susp": 0.000855431993156544
        }
    },
    {
        "name": "pandas._config.config._warn_if_deprecated#610",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._warn_if_deprecated(key: str)",
        "snippet": "def _warn_if_deprecated(key: str) -> bool:\n    \"\"\"\n    Checks if `key` is a deprecated option and if so, prints a warning.\n\n    Returns\n    -------\n    bool - True if `key` is deprecated, False otherwise.\n    \"\"\"\n    d = _get_deprecated_option(key)\n    if d:\n        if d.msg:\n            print(d.msg)\n            warnings.warn(d.msg, FutureWarning)\n        else:\n            msg = f\"'{key}' is deprecated\"\n            if d.removal_ver:\n                msg += f\" and will be removed in {d.removal_ver}\"\n            if d.rkey:\n                msg += f\", please use '{d.rkey}' instead.\"\n            else:\n                msg += \", please refrain from using it.\"\n\n            warnings.warn(msg, FutureWarning)\n        return True\n    return False",
        "begin_line": 610,
        "end_line": 634,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000855431993156544,
            "pseudo_dstar_susp": 0.022727272727272728,
            "pseudo_tarantula_susp": 0.000855431993156544,
            "pseudo_op2_susp": 0.022727272727272728,
            "pseudo_barinel_susp": 0.000855431993156544
        }
    },
    {
        "name": "pandas._config.config.inner#804",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config.inner(x)",
        "snippet": "    def inner(x) -> None:\n        if x not in legal_values:\n\n            if not any(c(x) for c in callables):\n                uvals = [str(lval) for lval in legal_values]\n                pp_values = \"|\".join(uvals)\n                msg = f\"Value must be one of {pp_values}\"\n                if len(callables):\n                    msg += \" or a callable\"\n                raise ValueError(msg)",
        "begin_line": 804,
        "end_line": 813,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_convert_platform#86",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_convert_platform(values)",
        "snippet": "def maybe_convert_platform(values):\n    \"\"\" try to do platform conversion, allow ndarray or list here \"\"\"\n    if isinstance(values, (list, tuple, range)):\n        values = construct_1d_object_array_from_listlike(values)\n    if getattr(values, \"dtype\", None) == np.object_:\n        if hasattr(values, \"_values\"):\n            values = values._values\n        values = lib.maybe_convert_objects(values)\n\n    return values",
        "begin_line": 86,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_promote#456",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_promote(dtype, fill_value=np.nan)",
        "snippet": "def maybe_promote(dtype, fill_value=np.nan):\n    \"\"\"\n    Find the minimal dtype that can hold both the given dtype and fill_value.\n\n    Parameters\n    ----------\n    dtype : np.dtype or ExtensionDtype\n    fill_value : scalar, default np.nan\n\n    Returns\n    -------\n    dtype\n        Upcasted from dtype argument if necessary.\n    fill_value\n        Upcasted from fill_value argument if necessary.\n    \"\"\"\n    if not is_scalar(fill_value) and not is_object_dtype(dtype):\n        # with object dtype there is nothing to promote, and the user can\n        #  pass pretty much any weird fill_value they like\n        raise ValueError(\"fill_value must be a scalar\")\n\n    # if we passed an array here, determine the fill value by dtype\n    if isinstance(fill_value, np.ndarray):\n        if issubclass(fill_value.dtype.type, (np.datetime64, np.timedelta64)):\n            fill_value = fill_value.dtype.type(\"NaT\", \"ns\")\n        else:\n\n            # we need to change to object type as our\n            # fill_value is of object type\n            if fill_value.dtype == np.object_:\n                dtype = np.dtype(np.object_)\n            fill_value = np.nan\n\n        if dtype == np.object_ or dtype.kind in [\"U\", \"S\"]:\n            # We treat string-like dtypes as object, and _always_ fill\n            #  with np.nan\n            fill_value = np.nan\n            dtype = np.dtype(np.object_)\n\n    # returns tuple of (dtype, fill_value)\n    if issubclass(dtype.type, np.datetime64):\n        if isinstance(fill_value, datetime) and fill_value.tzinfo is not None:\n            # Trying to insert tzaware into tznaive, have to cast to object\n            dtype = np.dtype(np.object_)\n        elif is_integer(fill_value) or (is_float(fill_value) and not isna(fill_value)):\n            dtype = np.dtype(np.object_)\n        else:\n            try:\n                fill_value = tslibs.Timestamp(fill_value).to_datetime64()\n            except (TypeError, ValueError):\n                dtype = np.dtype(np.object_)\n    elif issubclass(dtype.type, np.timedelta64):\n        if (\n            is_integer(fill_value)\n            or (is_float(fill_value) and not np.isnan(fill_value))\n            or isinstance(fill_value, str)\n        ):\n            # TODO: What about str that can be a timedelta?\n            dtype = np.dtype(np.object_)\n        else:\n            try:\n                fv = tslibs.Timedelta(fill_value)\n            except ValueError:\n                dtype = np.dtype(np.object_)\n            else:\n                if fv is NaT:\n                    # NaT has no `to_timedelta64` method\n                    fill_value = np.timedelta64(\"NaT\", \"ns\")\n                else:\n                    fill_value = fv.to_timedelta64()\n    elif is_datetime64tz_dtype(dtype):\n        if isna(fill_value):\n            fill_value = NaT\n        elif not isinstance(fill_value, datetime):\n            dtype = np.dtype(np.object_)\n        elif fill_value.tzinfo is None:\n            dtype = np.dtype(np.object_)\n        elif not tz_compare(fill_value.tzinfo, dtype.tz):\n            # TODO: sure we want to cast here?\n            dtype = np.dtype(np.object_)\n\n    elif is_extension_array_dtype(dtype) and isna(fill_value):\n        fill_value = dtype.na_value\n\n    elif is_float(fill_value):\n        if issubclass(dtype.type, np.bool_):\n            dtype = np.dtype(np.object_)\n\n        elif issubclass(dtype.type, np.integer):\n            dtype = np.dtype(np.float64)\n\n        elif dtype.kind == \"f\":\n            mst = np.min_scalar_type(fill_value)\n            if mst > dtype:\n                # e.g. mst is np.float64 and dtype is np.float32\n                dtype = mst\n\n        elif dtype.kind == \"c\":\n            mst = np.min_scalar_type(fill_value)\n            dtype = np.promote_types(dtype, mst)\n\n    elif is_bool(fill_value):\n        if not issubclass(dtype.type, np.bool_):\n            dtype = np.dtype(np.object_)\n\n    elif is_integer(fill_value):\n        if issubclass(dtype.type, np.bool_):\n            dtype = np.dtype(np.object_)\n\n        elif issubclass(dtype.type, np.integer):\n            if not np.can_cast(fill_value, dtype):\n                # upcast to prevent overflow\n                mst = np.min_scalar_type(fill_value)\n                dtype = np.promote_types(dtype, mst)\n                if dtype.kind == \"f\":\n                    # Case where we disagree with numpy\n                    dtype = np.dtype(np.object_)\n\n    elif is_complex(fill_value):\n        if issubclass(dtype.type, np.bool_):\n            dtype = np.dtype(np.object_)\n\n        elif issubclass(dtype.type, (np.integer, np.floating)):\n            mst = np.min_scalar_type(fill_value)\n            dtype = np.promote_types(dtype, mst)\n\n        elif dtype.kind == \"c\":\n            mst = np.min_scalar_type(fill_value)\n            if mst > dtype:\n                # e.g. mst is np.complex128 and dtype is np.complex64\n                dtype = mst\n\n    elif fill_value is None:\n        if is_float_dtype(dtype) or is_complex_dtype(dtype):\n            fill_value = np.nan\n        elif is_integer_dtype(dtype):\n            dtype = np.float64\n            fill_value = np.nan\n        elif is_datetime_or_timedelta_dtype(dtype):\n            fill_value = dtype.type(\"NaT\", \"ns\")\n        else:\n            dtype = np.dtype(np.object_)\n            fill_value = np.nan\n    else:\n        dtype = np.dtype(np.object_)\n\n    # in case we have a string that looked like a number\n    if is_extension_array_dtype(dtype):\n        pass\n    elif issubclass(np.dtype(dtype).type, (bytes, str)):\n        dtype = np.dtype(np.object_)\n\n    fill_value = _ensure_dtype_type(fill_value, dtype)\n    return dtype, fill_value",
        "begin_line": 456,
        "end_line": 609,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.cast._ensure_dtype_type#612",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast._ensure_dtype_type(value, dtype)",
        "snippet": "def _ensure_dtype_type(value, dtype):\n    \"\"\"\n    Ensure that the given value is an instance of the given dtype.\n\n    e.g. if out dtype is np.complex64, we should have an instance of that\n    as opposed to a python complex object.\n\n    Parameters\n    ----------\n    value : object\n    dtype : np.dtype or ExtensionDtype\n\n    Returns\n    -------\n    object\n    \"\"\"\n    # Start with exceptions in which we do _not_ cast to numpy types\n    if is_extension_array_dtype(dtype):\n        return value\n    elif dtype == np.object_:\n        return value\n    elif isna(value):\n        # e.g. keep np.nan rather than try to cast to np.float32(np.nan)\n        return value\n\n    return dtype.type(value)",
        "begin_line": 612,
        "end_line": 637,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_castable#1193",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_castable(arr)",
        "snippet": "def maybe_castable(arr) -> bool:\n    # return False to force a non-fastpath\n\n    # check datetime64[ns]/timedelta64[ns] are valid\n    # otherwise try to coerce\n    kind = arr.dtype.kind\n    if kind == \"M\":\n        return is_datetime64_ns_dtype(arr.dtype)\n    elif kind == \"m\":\n        return is_timedelta64_ns_dtype(arr.dtype)\n\n    return arr.dtype.name not in _POSSIBLY_CAST_DTYPES",
        "begin_line": 1193,
        "end_line": 1204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_infer_to_datetimelike#1207",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_infer_to_datetimelike(value, convert_dates: bool=False)",
        "snippet": "def maybe_infer_to_datetimelike(value, convert_dates: bool = False):\n    \"\"\"\n    we might have a array (or single object) that is datetime like,\n    and no dtype is passed don't change the value unless we find a\n    datetime/timedelta set\n\n    this is pretty strict in that a datetime/timedelta is REQUIRED\n    in addition to possible nulls/string likes\n\n    Parameters\n    ----------\n    value : np.array / Series / Index / list-like\n    convert_dates : bool, default False\n       if True try really hard to convert dates (such as datetime.date), other\n       leave inferred dtype 'date' alone\n\n    \"\"\"\n    # TODO: why not timedelta?\n    if isinstance(\n        value, (ABCDatetimeIndex, ABCPeriodIndex, ABCDatetimeArray, ABCPeriodArray)\n    ):\n        return value\n    elif isinstance(value, ABCSeries):\n        if isinstance(value._values, ABCDatetimeIndex):\n            return value._values\n\n    v = value\n\n    if not is_list_like(v):\n        v = [v]\n    v = np.array(v, copy=False)\n\n    # we only care about object dtypes\n    if not is_object_dtype(v):\n        return value\n\n    shape = v.shape\n    if not v.ndim == 1:\n        v = v.ravel()\n\n    if not len(v):\n        return value\n\n    def try_datetime(v):\n        # safe coerce to datetime64\n        try:\n            # GH19671\n            v = tslib.array_to_datetime(v, require_iso8601=True, errors=\"raise\")[0]\n        except ValueError:\n\n            # we might have a sequence of the same-datetimes with tz's\n            # if so coerce to a DatetimeIndex; if they are not the same,\n            # then these stay as object dtype, xref GH19671\n            from pandas._libs.tslibs import conversion\n            from pandas import DatetimeIndex\n\n            try:\n\n                values, tz = conversion.datetime_to_datetime64(v)\n                return DatetimeIndex(values).tz_localize(\"UTC\").tz_convert(tz=tz)\n            except (ValueError, TypeError):\n                pass\n\n        except Exception:\n            pass\n\n        return v.reshape(shape)\n\n    def try_timedelta(v):\n        # safe coerce to timedelta64\n\n        # will try first with a string & object conversion\n        from pandas import to_timedelta\n\n        try:\n            td_values = to_timedelta(v)\n        except ValueError:\n            return v.reshape(shape)\n        else:\n            return np.asarray(td_values).reshape(shape)\n\n    inferred_type = lib.infer_datetimelike_array(ensure_object(v))\n\n    if inferred_type == \"date\" and convert_dates:\n        value = try_datetime(v)\n    elif inferred_type == \"datetime\":\n        value = try_datetime(v)\n    elif inferred_type == \"timedelta\":\n        value = try_timedelta(v)\n    elif inferred_type == \"nat\":\n\n        # if all NaT, return as datetime\n        if isna(v).all():\n            value = try_datetime(v)\n        else:\n\n            # We have at least a NaT and a string\n            # try timedelta first to avoid spurious datetime conversions\n            # e.g. '00:00:01' is a timedelta but technically is also a datetime\n            value = try_timedelta(v)\n            if lib.infer_dtype(value, skipna=False) in [\"mixed\"]:\n                # cannot skip missing values, as NaT implies that the string\n                # is actually a datetime\n                value = try_datetime(v)\n\n    return value",
        "begin_line": 1207,
        "end_line": 1312,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.cast.try_datetime#1250",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.try_datetime(v)",
        "snippet": "    def try_datetime(v):\n        # safe coerce to datetime64\n        try:\n            # GH19671\n            v = tslib.array_to_datetime(v, require_iso8601=True, errors=\"raise\")[0]\n        except ValueError:\n\n            # we might have a sequence of the same-datetimes with tz's\n            # if so coerce to a DatetimeIndex; if they are not the same,\n            # then these stay as object dtype, xref GH19671\n            from pandas._libs.tslibs import conversion\n            from pandas import DatetimeIndex\n\n            try:\n\n                values, tz = conversion.datetime_to_datetime64(v)\n                return DatetimeIndex(values).tz_localize(\"UTC\").tz_convert(tz=tz)\n            except (ValueError, TypeError):\n                pass\n\n        except Exception:\n            pass\n\n        return v.reshape(shape)",
        "begin_line": 1250,
        "end_line": 1273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.cast.try_timedelta#1275",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.try_timedelta(v)",
        "snippet": "    def try_timedelta(v):\n        # safe coerce to timedelta64\n\n        # will try first with a string & object conversion\n        from pandas import to_timedelta\n\n        try:\n            td_values = to_timedelta(v)\n        except ValueError:\n            return v.reshape(shape)\n        else:\n            return np.asarray(td_values).reshape(shape)",
        "begin_line": 1275,
        "end_line": 1286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_cast_to_datetime#1315",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_cast_to_datetime(value, dtype, errors: str='raise')",
        "snippet": "def maybe_cast_to_datetime(value, dtype, errors: str = \"raise\"):\n    \"\"\"\n    try to cast the array/value to a datetimelike dtype, converting float\n    nan to iNaT\n    \"\"\"\n    from pandas.core.tools.timedeltas import to_timedelta\n    from pandas.core.tools.datetimes import to_datetime\n\n    if dtype is not None:\n        if isinstance(dtype, str):\n            dtype = np.dtype(dtype)\n\n        is_datetime64 = is_datetime64_dtype(dtype)\n        is_datetime64tz = is_datetime64tz_dtype(dtype)\n        is_timedelta64 = is_timedelta64_dtype(dtype)\n\n        if is_datetime64 or is_datetime64tz or is_timedelta64:\n\n            # Force the dtype if needed.\n            msg = (\n                f\"The '{dtype.name}' dtype has no unit. \"\n                f\"Please pass in '{dtype.name}[ns]' instead.\"\n            )\n\n            if is_datetime64 and not is_dtype_equal(dtype, DT64NS_DTYPE):\n\n                # pandas supports dtype whose granularity is less than [ns]\n                # e.g., [ps], [fs], [as]\n                if dtype <= np.dtype(\"M8[ns]\"):\n                    if dtype.name == \"datetime64\":\n                        raise ValueError(msg)\n                    dtype = DT64NS_DTYPE\n                else:\n                    raise TypeError(f\"cannot convert datetimelike to dtype [{dtype}]\")\n            elif is_datetime64tz:\n\n                # our NaT doesn't support tz's\n                # this will coerce to DatetimeIndex with\n                # a matching dtype below\n                if is_scalar(value) and isna(value):\n                    value = [value]\n\n            elif is_timedelta64 and not is_dtype_equal(dtype, TD64NS_DTYPE):\n\n                # pandas supports dtype whose granularity is less than [ns]\n                # e.g., [ps], [fs], [as]\n                if dtype <= np.dtype(\"m8[ns]\"):\n                    if dtype.name == \"timedelta64\":\n                        raise ValueError(msg)\n                    dtype = TD64NS_DTYPE\n                else:\n                    raise TypeError(f\"cannot convert timedeltalike to dtype [{dtype}]\")\n\n            if is_scalar(value):\n                if value == iNaT or isna(value):\n                    value = iNaT\n            else:\n                value = np.array(value, copy=False)\n\n                # have a scalar array-like (e.g. NaT)\n                if value.ndim == 0:\n                    value = iNaT\n\n                # we have an array of datetime or timedeltas & nulls\n                elif np.prod(value.shape) or not is_dtype_equal(value.dtype, dtype):\n                    try:\n                        if is_datetime64:\n                            value = to_datetime(value, errors=errors)\n                            # GH 25843: Remove tz information since the dtype\n                            # didn't specify one\n                            if value.tz is not None:\n                                value = value.tz_localize(None)\n                            value = value._values\n                        elif is_datetime64tz:\n                            # The string check can be removed once issue #13712\n                            # is solved. String data that is passed with a\n                            # datetime64tz is assumed to be naive which should\n                            # be localized to the timezone.\n                            is_dt_string = is_string_dtype(value)\n                            value = to_datetime(value, errors=errors).array\n                            if is_dt_string:\n                                # Strings here are naive, so directly localize\n                                value = value.tz_localize(dtype.tz)\n                            else:\n                                # Numeric values are UTC at this point,\n                                # so localize and convert\n                                value = value.tz_localize(\"UTC\").tz_convert(dtype.tz)\n                        elif is_timedelta64:\n                            value = to_timedelta(value, errors=errors)._values\n                    except OutOfBoundsDatetime:\n                        raise\n                    except (AttributeError, ValueError, TypeError):\n                        pass\n\n        # coerce datetimelike to object\n        elif is_datetime64_dtype(value) and not is_datetime64_dtype(dtype):\n            if is_object_dtype(dtype):\n                if value.dtype != DT64NS_DTYPE:\n                    value = value.astype(DT64NS_DTYPE)\n                ints = np.asarray(value).view(\"i8\")\n                return tslib.ints_to_pydatetime(ints)\n\n            # we have a non-castable dtype that was passed\n            raise TypeError(f\"Cannot cast datetime64 to {dtype}\")\n\n    else:\n\n        is_array = isinstance(value, np.ndarray)\n\n        # catch a datetime/timedelta that is not of ns variety\n        # and no coercion specified\n        if is_array and value.dtype.kind in [\"M\", \"m\"]:\n            dtype = value.dtype\n\n            if dtype.kind == \"M\" and dtype != DT64NS_DTYPE:\n                value = tslibs.conversion.ensure_datetime64ns(value)\n\n            elif dtype.kind == \"m\" and dtype != TD64NS_DTYPE:\n                value = to_timedelta(value)\n\n        # only do this if we have an array and the dtype of the array is not\n        # setup already we are not an integer/object, so don't bother with this\n        # conversion\n        elif not (\n            is_array\n            and not (\n                issubclass(value.dtype.type, np.integer) or value.dtype == np.object_\n            )\n        ):\n            value = maybe_infer_to_datetimelike(value)\n\n    return value",
        "begin_line": 1315,
        "end_line": 1446,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.cast.construct_1d_object_array_from_listlike#1563",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.construct_1d_object_array_from_listlike(values)",
        "snippet": "def construct_1d_object_array_from_listlike(values):\n    \"\"\"\n    Transform any list-like object in a 1-dimensional numpy array of object\n    dtype.\n\n    Parameters\n    ----------\n    values : any iterable which has a len()\n\n    Raises\n    ------\n    TypeError\n        * If `values` does not have a len()\n\n    Returns\n    -------\n    1-dimensional numpy array of dtype object\n    \"\"\"\n    # numpy will try to interpret nested lists as further dimensions, hence\n    # making a 1D array that contains list-likes is a bit tricky:\n    result = np.empty(len(values), dtype=\"object\")\n    result[:] = values\n    return result",
        "begin_line": 1563,
        "end_line": 1585,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.cast.construct_1d_ndarray_preserving_na#1588",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.construct_1d_ndarray_preserving_na(values, dtype=None, copy: bool=False)",
        "snippet": "def construct_1d_ndarray_preserving_na(values, dtype=None, copy: bool = False):\n    \"\"\"\n    Construct a new ndarray, coercing `values` to `dtype`, preserving NA.\n\n    Parameters\n    ----------\n    values : Sequence\n    dtype : numpy.dtype, optional\n    copy : bool, default False\n        Note that copies may still be made with ``copy=False`` if casting\n        is required.\n\n    Returns\n    -------\n    arr : ndarray[dtype]\n\n    Examples\n    --------\n    >>> np.array([1.0, 2.0, None], dtype='str')\n    array(['1.0', '2.0', 'None'], dtype='<U4')\n\n    >>> construct_1d_ndarray_preserving_na([1.0, 2.0, None], dtype=np.dtype('str'))\n    array(['1.0', '2.0', None], dtype=object)\n    \"\"\"\n    subarr = np.array(values, dtype=dtype, copy=copy)\n\n    if dtype is not None and dtype.kind in (\"U\", \"S\"):\n        # GH-21083\n        # We can't just return np.array(subarr, dtype='str') since\n        # NumPy will convert the non-string objects into strings\n        # Including NA values. Se we have to go\n        # string -> object -> update NA, which requires an\n        # additional pass over the data.\n        na_values = isna(values)\n        subarr2 = subarr.astype(object)\n        subarr2[na_values] = np.asarray(values, dtype=object)[na_values]\n        subarr = subarr2\n\n    return subarr",
        "begin_line": 1588,
        "end_line": 1626,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_cast_to_integer_array#1629",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_cast_to_integer_array(arr, dtype, copy: bool=False)",
        "snippet": "def maybe_cast_to_integer_array(arr, dtype, copy: bool = False):\n    \"\"\"\n    Takes any dtype and returns the casted version, raising for when data is\n    incompatible with integer/unsigned integer dtypes.\n\n    .. versionadded:: 0.24.0\n\n    Parameters\n    ----------\n    arr : array-like\n        The array to cast.\n    dtype : str, np.dtype\n        The integer dtype to cast the array to.\n    copy: bool, default False\n        Whether to make a copy of the array before returning.\n\n    Returns\n    -------\n    ndarray\n        Array of integer or unsigned integer dtype.\n\n    Raises\n    ------\n    OverflowError : the dtype is incompatible with the data\n    ValueError : loss of precision has occurred during casting\n\n    Examples\n    --------\n    If you try to coerce negative values to unsigned integers, it raises:\n\n    >>> pd.Series([-1], dtype=\"uint64\")\n    Traceback (most recent call last):\n        ...\n    OverflowError: Trying to coerce negative values to unsigned integers\n\n    Also, if you try to coerce float values to integers, it raises:\n\n    >>> pd.Series([1, 2, 3.5], dtype=\"int64\")\n    Traceback (most recent call last):\n        ...\n    ValueError: Trying to coerce float values to integers\n    \"\"\"\n    try:\n        if not hasattr(arr, \"astype\"):\n            casted = np.array(arr, dtype=dtype, copy=copy)\n        else:\n            casted = arr.astype(dtype, copy=copy)\n    except OverflowError as err:\n        raise OverflowError(\n            \"The elements provided in the data cannot all be \"\n            f\"casted to the dtype {dtype}\"\n        ) from err\n\n    if np.array_equal(arr, casted):\n        return casted\n\n    # We do this casting to allow for proper\n    # data and dtype checking.\n    #\n    # We didn't do this earlier because NumPy\n    # doesn't handle `uint64` correctly.\n    arr = np.asarray(arr)\n\n    if is_unsigned_integer_dtype(dtype) and (arr < 0).any():\n        raise OverflowError(\"Trying to coerce negative values to unsigned integers\")\n\n    if is_integer_dtype(dtype) and (is_float_dtype(arr) or is_object_dtype(arr)):\n        raise ValueError(\"Trying to coerce float values to integers\")",
        "begin_line": 1629,
        "end_line": 1696,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.construction.arrays_to_mgr#57",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction.arrays_to_mgr(arrays, arr_names, index, columns, dtype=None, verify_integrity: bool=True)",
        "snippet": "def arrays_to_mgr(\n    arrays, arr_names, index, columns, dtype=None, verify_integrity: bool = True\n):\n    \"\"\"\n    Segregate Series based on type and coerce into matrices.\n\n    Needs to handle a lot of exceptional cases.\n    \"\"\"\n    arr_names = ensure_index(arr_names)\n\n    if verify_integrity:\n        # figure out the index, if necessary\n        if index is None:\n            index = extract_index(arrays)\n        else:\n            index = ensure_index(index)\n\n        # don't force copy because getting jammed in an ndarray anyway\n        arrays = _homogenize(arrays, index, dtype)\n\n        columns = ensure_index(columns)\n    else:\n        columns = ensure_index(columns)\n        index = ensure_index(index)\n\n    # from BlockManager perspective\n    axes = [columns, index]\n\n    return create_block_manager_from_arrays(arrays, arr_names, axes)",
        "begin_line": 57,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.construction.init_dict#224",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction.init_dict(data, index, columns, dtype=None)",
        "snippet": "def init_dict(data, index, columns, dtype=None):\n    \"\"\"\n    Segregate Series based on type and coerce into matrices.\n    Needs to handle a lot of exceptional cases.\n    \"\"\"\n    if columns is not None:\n        from pandas.core.series import Series\n\n        arrays = Series(data, index=columns, dtype=object)\n        data_names = arrays.index\n\n        missing = arrays.isna()\n        if index is None:\n            # GH10856\n            # raise ValueError if only scalars in dict\n            index = extract_index(arrays[~missing])\n        else:\n            index = ensure_index(index)\n\n        # no obvious \"empty\" int column\n        if missing.any() and not is_integer_dtype(dtype):\n            if dtype is None or np.issubdtype(dtype, np.flexible):\n                # GH#1783\n                nan_dtype = object\n            else:\n                nan_dtype = dtype\n            val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype)\n            arrays.loc[missing] = [val] * missing.sum()\n\n    else:\n        keys = list(data.keys())\n        columns = data_names = Index(keys)\n        arrays = (com.maybe_iterable_to_list(data[k]) for k in keys)\n        # GH#24096 need copy to be deep for datetime64tz case\n        # TODO: See if we can avoid these copies\n        arrays = [\n            arr if not isinstance(arr, ABCIndexClass) else arr._data for arr in arrays\n        ]\n        arrays = [\n            arr if not is_datetime64tz_dtype(arr) else arr.copy() for arr in arrays\n        ]\n    return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)",
        "begin_line": 224,
        "end_line": 265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.internals.construction._homogenize#311",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction._homogenize(data, index, dtype=None)",
        "snippet": "def _homogenize(data, index, dtype=None):\n    oindex = None\n    homogenized = []\n\n    for val in data:\n        if isinstance(val, ABCSeries):\n            if dtype is not None:\n                val = val.astype(dtype)\n            if val.index is not index:\n                # Forces alignment. No need to copy data since we\n                # are putting it into an ndarray later\n                val = val.reindex(index, copy=False)\n        else:\n            if isinstance(val, dict):\n                if oindex is None:\n                    oindex = index.astype(\"O\")\n\n                if isinstance(index, (ABCDatetimeIndex, ABCTimedeltaIndex)):\n                    val = com.dict_compat(val)\n                else:\n                    val = dict(val)\n                val = lib.fast_multiget(val, oindex.values, default=np.nan)\n            val = sanitize_array(\n                val, index, dtype=dtype, copy=False, raise_cast_failure=False\n            )\n\n        homogenized.append(val)\n\n    return homogenized",
        "begin_line": 311,
        "end_line": 339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.common.ensure_python_int#174",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.ensure_python_int(value: Union[int, np.integer])",
        "snippet": "def ensure_python_int(value: Union[int, np.integer]) -> int:\n    \"\"\"\n    Ensure that a value is a python int.\n\n    Parameters\n    ----------\n    value: int or numpy.integer\n\n    Returns\n    -------\n    int\n\n    Raises\n    ------\n    TypeError: if the value isn't an int or can't be converted to one.\n    \"\"\"\n    if not is_scalar(value):\n        raise TypeError(\n            f\"Value needs to be a scalar value, was type {type(value).__name__}\"\n        )\n    try:\n        new_value = int(value)\n        assert new_value == value\n    except (TypeError, ValueError, AssertionError) as err:\n        raise TypeError(f\"Wrong type {type(value)} for value {value}\") from err\n    return new_value",
        "begin_line": 174,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.classes#202",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.classes(*klasses)",
        "snippet": "def classes(*klasses) -> Callable:\n    \"\"\" evaluate if the tipo is a subclass of the klasses \"\"\"\n    return lambda tipo: issubclass(tipo, klasses)",
        "begin_line": 202,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008396305625524769,
            "pseudo_dstar_susp": 0.015151515151515152,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.015151515151515152,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.classes_and_not_datetimelike#207",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.classes_and_not_datetimelike(*klasses)",
        "snippet": "def classes_and_not_datetimelike(*klasses) -> Callable:\n    \"\"\"\n    evaluate if the tipo is a subclass of the klasses\n    and not a datetimelike\n    \"\"\"\n    return lambda tipo: (\n        issubclass(tipo, klasses)\n        and not issubclass(tipo, (np.datetime64, np.timedelta64))\n    )",
        "begin_line": 207,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.015151515151515152,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.015151515151515152,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_object_dtype#218",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_object_dtype(arr_or_dtype)",
        "snippet": "def is_object_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the object dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the object dtype.\n\n    Examples\n    --------\n    >>> is_object_dtype(object)\n    True\n    >>> is_object_dtype(int)\n    False\n    >>> is_object_dtype(np.array([], dtype=object))\n    True\n    >>> is_object_dtype(np.array([], dtype=int))\n    False\n    >>> is_object_dtype([1, 2, 3])\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.object_))",
        "begin_line": 218,
        "end_line": 245,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_sparse#248",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_sparse(arr)",
        "snippet": "def is_sparse(arr) -> bool:\n    \"\"\"\n    Check whether an array-like is a 1-D pandas sparse array.\n\n    Check that the one-dimensional array-like is a pandas sparse array.\n    Returns True if it is a pandas sparse array, not another type of\n    sparse array.\n\n    Parameters\n    ----------\n    arr : array-like\n        Array-like to check.\n\n    Returns\n    -------\n    bool\n        Whether or not the array-like is a pandas sparse array.\n\n    Examples\n    --------\n    Returns `True` if the parameter is a 1-D pandas sparse array.\n\n    >>> is_sparse(pd.arrays.SparseArray([0, 0, 1, 0]))\n    True\n    >>> is_sparse(pd.Series(pd.arrays.SparseArray([0, 0, 1, 0])))\n    True\n\n    Returns `False` if the parameter is not sparse.\n\n    >>> is_sparse(np.array([0, 0, 1, 0]))\n    False\n    >>> is_sparse(pd.Series([0, 1, 0, 0]))\n    False\n\n    Returns `False` if the parameter is not a pandas sparse array.\n\n    >>> from scipy.sparse import bsr_matrix\n    >>> is_sparse(bsr_matrix([0, 1, 0, 0]))\n    False\n\n    Returns `False` if the parameter has more than one dimension.\n    \"\"\"\n    from pandas.core.arrays.sparse import SparseDtype\n\n    dtype = getattr(arr, \"dtype\", arr)\n    return isinstance(dtype, SparseDtype)",
        "begin_line": 248,
        "end_line": 293,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64_dtype#372",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the datetime64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the datetime64 dtype.\n\n    Examples\n    --------\n    >>> is_datetime64_dtype(object)\n    False\n    >>> is_datetime64_dtype(np.datetime64)\n    True\n    >>> is_datetime64_dtype(np.array([], dtype=int))\n    False\n    >>> is_datetime64_dtype(np.array([], dtype=np.datetime64))\n    True\n    >>> is_datetime64_dtype([1, 2, 3])\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.datetime64))",
        "begin_line": 372,
        "end_line": 399,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64tz_dtype#402",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64tz_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64tz_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of a DatetimeTZDtype dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of a DatetimeTZDtype dtype.\n\n    Examples\n    --------\n    >>> is_datetime64tz_dtype(object)\n    False\n    >>> is_datetime64tz_dtype([1, 2, 3])\n    False\n    >>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3]))  # tz-naive\n    False\n    >>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    True\n\n    >>> dtype = DatetimeTZDtype(\"ns\", tz=\"US/Eastern\")\n    >>> s = pd.Series([], dtype=dtype)\n    >>> is_datetime64tz_dtype(dtype)\n    True\n    >>> is_datetime64tz_dtype(s)\n    True\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    return DatetimeTZDtype.is_dtype(arr_or_dtype)",
        "begin_line": 402,
        "end_line": 436,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_timedelta64_dtype#439",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_timedelta64_dtype(arr_or_dtype)",
        "snippet": "def is_timedelta64_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the timedelta64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the timedelta64 dtype.\n\n    Examples\n    --------\n    >>> is_timedelta64_dtype(object)\n    False\n    >>> is_timedelta64_dtype(np.timedelta64)\n    True\n    >>> is_timedelta64_dtype([1, 2, 3])\n    False\n    >>> is_timedelta64_dtype(pd.Series([], dtype=\"timedelta64[ns]\"))\n    True\n    >>> is_timedelta64_dtype('0 days')\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.timedelta64))",
        "begin_line": 439,
        "end_line": 466,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_period_dtype#469",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_period_dtype(arr_or_dtype)",
        "snippet": "def is_period_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Period dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Period dtype.\n\n    Examples\n    --------\n    >>> is_period_dtype(object)\n    False\n    >>> is_period_dtype(PeriodDtype(freq=\"D\"))\n    True\n    >>> is_period_dtype([1, 2, 3])\n    False\n    >>> is_period_dtype(pd.Period(\"2017-01-01\"))\n    False\n    >>> is_period_dtype(pd.PeriodIndex([], freq=\"A\"))\n    True\n    \"\"\"\n    # TODO: Consider making Period an instance of PeriodDtype\n    if arr_or_dtype is None:\n        return False\n    return PeriodDtype.is_dtype(arr_or_dtype)",
        "begin_line": 469,
        "end_line": 499,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_interval_dtype#502",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_interval_dtype(arr_or_dtype)",
        "snippet": "def is_interval_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Interval dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Interval dtype.\n\n    Examples\n    --------\n    >>> is_interval_dtype(object)\n    False\n    >>> is_interval_dtype(IntervalDtype())\n    True\n    >>> is_interval_dtype([1, 2, 3])\n    False\n    >>>\n    >>> interval = pd.Interval(1, 2, closed=\"right\")\n    >>> is_interval_dtype(interval)\n    False\n    >>> is_interval_dtype(pd.IntervalIndex([interval]))\n    True\n    \"\"\"\n    # TODO: Consider making Interval an instance of IntervalDtype\n    if arr_or_dtype is None:\n        return False\n    return IntervalDtype.is_dtype(arr_or_dtype)",
        "begin_line": 502,
        "end_line": 534,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_categorical_dtype#537",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_categorical_dtype(arr_or_dtype)",
        "snippet": "def is_categorical_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Categorical dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Categorical dtype.\n\n    Examples\n    --------\n    >>> is_categorical_dtype(object)\n    False\n    >>> is_categorical_dtype(CategoricalDtype())\n    True\n    >>> is_categorical_dtype([1, 2, 3])\n    False\n    >>> is_categorical_dtype(pd.Categorical([1, 2, 3]))\n    True\n    >>> is_categorical_dtype(pd.CategoricalIndex([1, 2, 3]))\n    True\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    return CategoricalDtype.is_dtype(arr_or_dtype)",
        "begin_line": 537,
        "end_line": 566,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_string_dtype#569",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_string_dtype(arr_or_dtype)",
        "snippet": "def is_string_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of the string dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the string dtype.\n\n    Examples\n    --------\n    >>> is_string_dtype(str)\n    True\n    >>> is_string_dtype(object)\n    True\n    >>> is_string_dtype(int)\n    False\n    >>>\n    >>> is_string_dtype(np.array(['a', 'b']))\n    True\n    >>> is_string_dtype(pd.Series([1, 2]))\n    False\n    \"\"\"\n    # TODO: gh-15585: consider making the checks stricter.\n    def condition(dtype) -> bool:\n        return dtype.kind in (\"O\", \"S\", \"U\") and not is_excluded_dtype(dtype)\n\n    def is_excluded_dtype(dtype) -> bool:\n        \"\"\"\n        These have kind = \"O\" but aren't string dtypes so need to be explicitly excluded\n        \"\"\"\n        is_excluded_checks = (is_period_dtype, is_interval_dtype)\n        return any(is_excluded(dtype) for is_excluded in is_excluded_checks)\n\n    return _is_dtype(arr_or_dtype, condition)",
        "begin_line": 569,
        "end_line": 608,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.condition#598",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.condition(dtype)",
        "snippet": "    def condition(dtype) -> bool:\n        return dtype.kind in (\"O\", \"S\", \"U\") and not is_excluded_dtype(dtype)",
        "begin_line": 598,
        "end_line": 599,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008396305625524769,
            "pseudo_dstar_susp": 0.015151515151515152,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.015151515151515152,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_excluded_dtype#601",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_excluded_dtype(dtype)",
        "snippet": "    def is_excluded_dtype(dtype) -> bool:\n        \"\"\"\n        These have kind = \"O\" but aren't string dtypes so need to be explicitly excluded\n        \"\"\"\n        is_excluded_checks = (is_period_dtype, is_interval_dtype)\n        return any(is_excluded(dtype) for is_excluded in is_excluded_checks)",
        "begin_line": 601,
        "end_line": 606,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008396305625524769,
            "pseudo_dstar_susp": 0.015151515151515152,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.015151515151515152,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_dtype_equal#611",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_dtype_equal(source, target)",
        "snippet": "def is_dtype_equal(source, target) -> bool:\n    \"\"\"\n    Check if two dtypes are equal.\n\n    Parameters\n    ----------\n    source : The first dtype to compare\n    target : The second dtype to compare\n\n    Returns\n    -------\n    boolean\n        Whether or not the two dtypes are equal.\n\n    Examples\n    --------\n    >>> is_dtype_equal(int, float)\n    False\n    >>> is_dtype_equal(\"int\", int)\n    True\n    >>> is_dtype_equal(object, \"category\")\n    False\n    >>> is_dtype_equal(CategoricalDtype(), \"category\")\n    True\n    >>> is_dtype_equal(DatetimeTZDtype(tz=\"UTC\"), \"datetime64\")\n    False\n    \"\"\"\n    try:\n        source = _get_dtype(source)\n        target = _get_dtype(target)\n        return source == target\n    except (TypeError, AttributeError):\n\n        # invalid comparison\n        # object == category will hit this\n        return False",
        "begin_line": 611,
        "end_line": 646,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_integer_dtype#699",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_integer_dtype(arr_or_dtype)",
        "snippet": "def is_integer_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of an integer dtype.\n\n    Unlike in `in_any_int_dtype`, timedelta64 instances will return False.\n\n    .. versionchanged:: 0.24.0\n\n       The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\n       as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of an integer dtype and\n        not an instance of timedelta64.\n\n    Examples\n    --------\n    >>> is_integer_dtype(str)\n    False\n    >>> is_integer_dtype(int)\n    True\n    >>> is_integer_dtype(float)\n    False\n    >>> is_integer_dtype(np.uint64)\n    True\n    >>> is_integer_dtype('int8')\n    True\n    >>> is_integer_dtype('Int8')\n    True\n    >>> is_integer_dtype(pd.Int8Dtype)\n    True\n    >>> is_integer_dtype(np.datetime64)\n    False\n    >>> is_integer_dtype(np.timedelta64)\n    False\n    >>> is_integer_dtype(np.array(['a', 'b']))\n    False\n    >>> is_integer_dtype(pd.Series([1, 2]))\n    True\n    >>> is_integer_dtype(np.array([], dtype=np.timedelta64))\n    False\n    >>> is_integer_dtype(pd.Index([1, 2.]))  # float\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes_and_not_datetimelike(np.integer))",
        "begin_line": 699,
        "end_line": 750,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_signed_integer_dtype#753",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_signed_integer_dtype(arr_or_dtype)",
        "snippet": "def is_signed_integer_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a signed integer dtype.\n\n    Unlike in `in_any_int_dtype`, timedelta64 instances will return False.\n\n    .. versionchanged:: 0.24.0\n\n       The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\n       as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a signed integer dtype\n        and not an instance of timedelta64.\n\n    Examples\n    --------\n    >>> is_signed_integer_dtype(str)\n    False\n    >>> is_signed_integer_dtype(int)\n    True\n    >>> is_signed_integer_dtype(float)\n    False\n    >>> is_signed_integer_dtype(np.uint64)  # unsigned\n    False\n    >>> is_signed_integer_dtype('int8')\n    True\n    >>> is_signed_integer_dtype('Int8')\n    True\n    >>> is_signed_integer_dtype(pd.Int8Dtype)\n    True\n    >>> is_signed_integer_dtype(np.datetime64)\n    False\n    >>> is_signed_integer_dtype(np.timedelta64)\n    False\n    >>> is_signed_integer_dtype(np.array(['a', 'b']))\n    False\n    >>> is_signed_integer_dtype(pd.Series([1, 2]))\n    True\n    >>> is_signed_integer_dtype(np.array([], dtype=np.timedelta64))\n    False\n    >>> is_signed_integer_dtype(pd.Index([1, 2.]))  # float\n    False\n    >>> is_signed_integer_dtype(np.array([1, 2], dtype=np.uint32))  # unsigned\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes_and_not_datetimelike(np.signedinteger))",
        "begin_line": 753,
        "end_line": 806,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_unsigned_integer_dtype#809",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_unsigned_integer_dtype(arr_or_dtype)",
        "snippet": "def is_unsigned_integer_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of an unsigned integer dtype.\n\n    .. versionchanged:: 0.24.0\n\n       The nullable Integer dtypes (e.g. pandas.UInt64Dtype) are also\n       considered as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of an unsigned integer dtype.\n\n    Examples\n    --------\n    >>> is_unsigned_integer_dtype(str)\n    False\n    >>> is_unsigned_integer_dtype(int)  # signed\n    False\n    >>> is_unsigned_integer_dtype(float)\n    False\n    >>> is_unsigned_integer_dtype(np.uint64)\n    True\n    >>> is_unsigned_integer_dtype('uint8')\n    True\n    >>> is_unsigned_integer_dtype('UInt8')\n    True\n    >>> is_unsigned_integer_dtype(pd.UInt8Dtype)\n    True\n    >>> is_unsigned_integer_dtype(np.array(['a', 'b']))\n    False\n    >>> is_unsigned_integer_dtype(pd.Series([1, 2]))  # signed\n    False\n    >>> is_unsigned_integer_dtype(pd.Index([1, 2.]))  # float\n    False\n    >>> is_unsigned_integer_dtype(np.array([1, 2], dtype=np.uint32))\n    True\n    \"\"\"\n    return _is_dtype_type(\n        arr_or_dtype, classes_and_not_datetimelike(np.unsignedinteger)\n    )",
        "begin_line": 809,
        "end_line": 855,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64_any_dtype#908",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64_any_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64_any_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of the datetime64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    bool\n        Whether or not the array or dtype is of the datetime64 dtype.\n\n    Examples\n    --------\n    >>> is_datetime64_any_dtype(str)\n    False\n    >>> is_datetime64_any_dtype(int)\n    False\n    >>> is_datetime64_any_dtype(np.datetime64)  # can be tz-naive\n    True\n    >>> is_datetime64_any_dtype(DatetimeTZDtype(\"ns\", \"US/Eastern\"))\n    True\n    >>> is_datetime64_any_dtype(np.array(['a', 'b']))\n    False\n    >>> is_datetime64_any_dtype(np.array([1, 2]))\n    False\n    >>> is_datetime64_any_dtype(np.array([], dtype=\"datetime64[ns]\"))\n    True\n    >>> is_datetime64_any_dtype(pd.DatetimeIndex([1, 2, 3], dtype=\"datetime64[ns]\"))\n    True\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    return is_datetime64_dtype(arr_or_dtype) or is_datetime64tz_dtype(arr_or_dtype)",
        "begin_line": 908,
        "end_line": 943,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime_or_timedelta_dtype#1024",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime_or_timedelta_dtype(arr_or_dtype)",
        "snippet": "def is_datetime_or_timedelta_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of\n    a timedelta64 or datetime64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a timedelta64,\n        or datetime64 dtype.\n\n    Examples\n    --------\n    >>> is_datetime_or_timedelta_dtype(str)\n    False\n    >>> is_datetime_or_timedelta_dtype(int)\n    False\n    >>> is_datetime_or_timedelta_dtype(np.datetime64)\n    True\n    >>> is_datetime_or_timedelta_dtype(np.timedelta64)\n    True\n    >>> is_datetime_or_timedelta_dtype(np.array(['a', 'b']))\n    False\n    >>> is_datetime_or_timedelta_dtype(pd.Series([1, 2]))\n    False\n    >>> is_datetime_or_timedelta_dtype(np.array([], dtype=np.timedelta64))\n    True\n    >>> is_datetime_or_timedelta_dtype(np.array([], dtype=np.datetime64))\n    True\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.datetime64, np.timedelta64))",
        "begin_line": 1024,
        "end_line": 1059,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005617977528089888,
            "pseudo_dstar_susp": 0.0005617977528089888,
            "pseudo_tarantula_susp": 0.0005617977528089888,
            "pseudo_op2_susp": 0.0005605381165919282,
            "pseudo_barinel_susp": 0.0005617977528089888
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetimelike_v_numeric#1122",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetimelike_v_numeric(a, b)",
        "snippet": "def is_datetimelike_v_numeric(a, b):\n    \"\"\"\n    Check if we are comparing a datetime-like object to a numeric object.\n    By \"numeric,\" we mean an object that is either of an int or float dtype.\n\n    Parameters\n    ----------\n    a : array-like, scalar\n        The first object to check.\n    b : array-like, scalar\n        The second object to check.\n\n    Returns\n    -------\n    boolean\n        Whether we return a comparing a datetime-like to a numeric object.\n\n    Examples\n    --------\n    >>> from datetime import datetime\n    >>> dt = np.datetime64(datetime(2017, 1, 1))\n    >>>\n    >>> is_datetimelike_v_numeric(1, 1)\n    False\n    >>> is_datetimelike_v_numeric(dt, dt)\n    False\n    >>> is_datetimelike_v_numeric(1, dt)\n    True\n    >>> is_datetimelike_v_numeric(dt, 1)  # symmetric check\n    True\n    >>> is_datetimelike_v_numeric(np.array([dt]), 1)\n    True\n    >>> is_datetimelike_v_numeric(np.array([1]), dt)\n    True\n    >>> is_datetimelike_v_numeric(np.array([dt]), np.array([1]))\n    True\n    >>> is_datetimelike_v_numeric(np.array([1]), np.array([2]))\n    False\n    >>> is_datetimelike_v_numeric(np.array([dt]), np.array([dt]))\n    False\n    \"\"\"\n    if not hasattr(a, \"dtype\"):\n        a = np.asarray(a)\n    if not hasattr(b, \"dtype\"):\n        b = np.asarray(b)\n\n    def is_numeric(x):\n        \"\"\"\n        Check if an object has a numeric dtype (i.e. integer or float).\n        \"\"\"\n        return is_integer_dtype(x) or is_float_dtype(x)\n\n    return (needs_i8_conversion(a) and is_numeric(b)) or (\n        needs_i8_conversion(b) and is_numeric(a)\n    )",
        "begin_line": 1122,
        "end_line": 1176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005617977528089888,
            "pseudo_dstar_susp": 0.0005617977528089888,
            "pseudo_tarantula_susp": 0.0005617977528089888,
            "pseudo_op2_susp": 0.0005605381165919282,
            "pseudo_barinel_susp": 0.0005617977528089888
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_numeric#1168",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_numeric(x)",
        "snippet": "    def is_numeric(x):\n        \"\"\"\n        Check if an object has a numeric dtype (i.e. integer or float).\n        \"\"\"\n        return is_integer_dtype(x) or is_float_dtype(x)",
        "begin_line": 1168,
        "end_line": 1172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005617977528089888,
            "pseudo_dstar_susp": 0.0005617977528089888,
            "pseudo_tarantula_susp": 0.0005617977528089888,
            "pseudo_op2_susp": 0.0005605381165919282,
            "pseudo_barinel_susp": 0.0005617977528089888
        }
    },
    {
        "name": "pandas.core.dtypes.common.needs_i8_conversion#1179",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.needs_i8_conversion(arr_or_dtype)",
        "snippet": "def needs_i8_conversion(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the array or dtype should be converted to int64.\n\n    An array-like or dtype \"needs\" such a conversion if the array-like\n    or dtype is of a datetime-like dtype\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype should be converted to int64.\n\n    Examples\n    --------\n    >>> needs_i8_conversion(str)\n    False\n    >>> needs_i8_conversion(np.int64)\n    False\n    >>> needs_i8_conversion(np.datetime64)\n    True\n    >>> needs_i8_conversion(np.array(['a', 'b']))\n    False\n    >>> needs_i8_conversion(pd.Series([1, 2]))\n    False\n    >>> needs_i8_conversion(pd.Series([], dtype=\"timedelta64[ns]\"))\n    True\n    >>> needs_i8_conversion(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    True\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    return (\n        is_datetime_or_timedelta_dtype(arr_or_dtype)\n        or is_datetime64tz_dtype(arr_or_dtype)\n        or is_period_dtype(arr_or_dtype)\n    )",
        "begin_line": 1179,
        "end_line": 1219,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005617977528089888,
            "pseudo_dstar_susp": 0.0005617977528089888,
            "pseudo_tarantula_susp": 0.0005617977528089888,
            "pseudo_op2_susp": 0.0005605381165919282,
            "pseudo_barinel_susp": 0.0005617977528089888
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_string_like_dtype#1264",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_string_like_dtype(arr_or_dtype)",
        "snippet": "def is_string_like_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a string-like dtype.\n\n    Unlike `is_string_dtype`, the object dtype is excluded because it\n    is a mixed dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the string dtype.\n\n    Examples\n    --------\n    >>> is_string_like_dtype(str)\n    True\n    >>> is_string_like_dtype(object)\n    False\n    >>> is_string_like_dtype(np.array(['a', 'b']))\n    True\n    >>> is_string_like_dtype(pd.Series([1, 2]))\n    False\n    \"\"\"\n    return _is_dtype(arr_or_dtype, lambda dtype: dtype.kind in (\"S\", \"U\"))",
        "begin_line": 1264,
        "end_line": 1292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008396305625524769,
            "pseudo_dstar_susp": 0.015151515151515152,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.015151515151515152,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_float_dtype#1295",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_float_dtype(arr_or_dtype)",
        "snippet": "def is_float_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a float dtype.\n\n    This function is internal and should not be exposed in the public API.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a float dtype.\n\n    Examples\n    --------\n    >>> is_float_dtype(str)\n    False\n    >>> is_float_dtype(int)\n    False\n    >>> is_float_dtype(float)\n    True\n    >>> is_float_dtype(np.array(['a', 'b']))\n    False\n    >>> is_float_dtype(pd.Series([1, 2]))\n    False\n    >>> is_float_dtype(pd.Index([1, 2.]))\n    True\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.floating))",
        "begin_line": 1295,
        "end_line": 1326,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_bool_dtype#1329",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_bool_dtype(arr_or_dtype)",
        "snippet": "def is_bool_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a boolean dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a boolean dtype.\n\n    Notes\n    -----\n    An ExtensionArray is considered boolean when the ``_is_boolean``\n    attribute is set to True.\n\n    Examples\n    --------\n    >>> is_bool_dtype(str)\n    False\n    >>> is_bool_dtype(int)\n    False\n    >>> is_bool_dtype(bool)\n    True\n    >>> is_bool_dtype(np.bool)\n    True\n    >>> is_bool_dtype(np.array(['a', 'b']))\n    False\n    >>> is_bool_dtype(pd.Series([1, 2]))\n    False\n    >>> is_bool_dtype(np.array([True, False]))\n    True\n    >>> is_bool_dtype(pd.Categorical([True, False]))\n    True\n    >>> is_bool_dtype(pd.arrays.SparseArray([True, False]))\n    True\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    try:\n        dtype = _get_dtype(arr_or_dtype)\n    except TypeError:\n        return False\n\n    if isinstance(arr_or_dtype, CategoricalDtype):\n        arr_or_dtype = arr_or_dtype.categories\n        # now we use the special definition for Index\n\n    if isinstance(arr_or_dtype, ABCIndexClass):\n\n        # TODO(jreback)\n        # we don't have a boolean Index class\n        # so its object, we need to infer to\n        # guess this\n        return arr_or_dtype.is_object and arr_or_dtype.inferred_type == \"boolean\"\n    elif is_extension_array_dtype(arr_or_dtype):\n        dtype = getattr(arr_or_dtype, \"dtype\", arr_or_dtype)\n        return dtype._is_boolean\n\n    return issubclass(dtype.type, np.bool_)",
        "begin_line": 1329,
        "end_line": 1391,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_extension_array_dtype#1459",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_extension_array_dtype(arr_or_dtype)",
        "snippet": "def is_extension_array_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check if an object is a pandas extension array type.\n\n    See the :ref:`Use Guide <extending.extension-types>` for more.\n\n    Parameters\n    ----------\n    arr_or_dtype : object\n        For array-like input, the ``.dtype`` attribute will\n        be extracted.\n\n    Returns\n    -------\n    bool\n        Whether the `arr_or_dtype` is an extension array type.\n\n    Notes\n    -----\n    This checks whether an object implements the pandas extension\n    array interface. In pandas, this includes:\n\n    * Categorical\n    * Sparse\n    * Interval\n    * Period\n    * DatetimeArray\n    * TimedeltaArray\n\n    Third-party libraries may implement arrays or types satisfying\n    this interface as well.\n\n    Examples\n    --------\n    >>> from pandas.api.types import is_extension_array_dtype\n    >>> arr = pd.Categorical(['a', 'b'])\n    >>> is_extension_array_dtype(arr)\n    True\n    >>> is_extension_array_dtype(arr.dtype)\n    True\n\n    >>> arr = np.array(['a', 'b'])\n    >>> is_extension_array_dtype(arr.dtype)\n    False\n    \"\"\"\n    dtype = getattr(arr_or_dtype, \"dtype\", arr_or_dtype)\n    return isinstance(dtype, ExtensionDtype) or registry.find(dtype) is not None",
        "begin_line": 1459,
        "end_line": 1505,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_complex_dtype#1508",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_complex_dtype(arr_or_dtype)",
        "snippet": "def is_complex_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a complex dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a complex dtype.\n\n    Examples\n    --------\n    >>> is_complex_dtype(str)\n    False\n    >>> is_complex_dtype(int)\n    False\n    >>> is_complex_dtype(np.complex)\n    True\n    >>> is_complex_dtype(np.array(['a', 'b']))\n    False\n    >>> is_complex_dtype(pd.Series([1, 2]))\n    False\n    >>> is_complex_dtype(np.array([1 + 1j, 5]))\n    True\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.complexfloating))",
        "begin_line": 1508,
        "end_line": 1537,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005617977528089888,
            "pseudo_dstar_susp": 0.0005617977528089888,
            "pseudo_tarantula_susp": 0.0005617977528089888,
            "pseudo_op2_susp": 0.0005605381165919282,
            "pseudo_barinel_susp": 0.0005617977528089888
        }
    },
    {
        "name": "pandas.core.dtypes.common._is_dtype#1540",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._is_dtype(arr_or_dtype, condition)",
        "snippet": "def _is_dtype(arr_or_dtype, condition) -> bool:\n    \"\"\"\n    Return a boolean if the condition is satisfied for the arr_or_dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like, str, np.dtype, or ExtensionArrayType\n        The array-like or dtype object whose dtype we want to extract.\n    condition : callable[Union[np.dtype, ExtensionDtype]]\n\n    Returns\n    -------\n    bool\n\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    try:\n        dtype = _get_dtype(arr_or_dtype)\n    except (TypeError, ValueError, UnicodeEncodeError):\n        return False\n    return condition(dtype)",
        "begin_line": 1540,
        "end_line": 1561,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common._get_dtype#1564",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._get_dtype(arr_or_dtype)",
        "snippet": "def _get_dtype(arr_or_dtype) -> DtypeObj:\n    \"\"\"\n    Get the dtype instance associated with an array\n    or dtype object.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype object whose dtype we want to extract.\n\n    Returns\n    -------\n    obj_dtype : The extract dtype instance from the\n                passed in array or dtype object.\n\n    Raises\n    ------\n    TypeError : The passed in object is None.\n    \"\"\"\n    if arr_or_dtype is None:\n        raise TypeError(\"Cannot deduce dtype from null object\")\n\n    # fastpath\n    elif isinstance(arr_or_dtype, np.dtype):\n        return arr_or_dtype\n    elif isinstance(arr_or_dtype, type):\n        return np.dtype(arr_or_dtype)\n\n    # if we have an array-like\n    elif hasattr(arr_or_dtype, \"dtype\"):\n        arr_or_dtype = arr_or_dtype.dtype\n\n    return pandas_dtype(arr_or_dtype)",
        "begin_line": 1564,
        "end_line": 1596,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.common._is_dtype_type#1599",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._is_dtype_type(arr_or_dtype, condition)",
        "snippet": "def _is_dtype_type(arr_or_dtype, condition) -> bool:\n    \"\"\"\n    Return a boolean if the condition is satisfied for the arr_or_dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype object whose dtype we want to extract.\n    condition : callable[Union[np.dtype, ExtensionDtypeType]]\n\n    Returns\n    -------\n    bool : if the condition is satisfied for the arr_or_dtype\n    \"\"\"\n    if arr_or_dtype is None:\n        return condition(type(None))\n\n    # fastpath\n    if isinstance(arr_or_dtype, np.dtype):\n        return condition(arr_or_dtype.type)\n    elif isinstance(arr_or_dtype, type):\n        if issubclass(arr_or_dtype, ExtensionDtype):\n            arr_or_dtype = arr_or_dtype.type\n        return condition(np.dtype(arr_or_dtype).type)\n\n    # if we have an array-like\n    if hasattr(arr_or_dtype, \"dtype\"):\n        arr_or_dtype = arr_or_dtype.dtype\n\n    # we are not possibly a dtype\n    elif is_list_like(arr_or_dtype):\n        return condition(type(None))\n\n    try:\n        tipo = pandas_dtype(arr_or_dtype).type\n    except (TypeError, ValueError, UnicodeEncodeError):\n        if is_scalar(arr_or_dtype):\n            return condition(type(None))\n\n        return False\n\n    return condition(tipo)",
        "begin_line": 1599,
        "end_line": 1640,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.common.pandas_dtype#1732",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.pandas_dtype(dtype)",
        "snippet": "def pandas_dtype(dtype) -> DtypeObj:\n    \"\"\"\n    Convert input into a pandas only dtype object or a numpy dtype object.\n\n    Parameters\n    ----------\n    dtype : object to be converted\n\n    Returns\n    -------\n    np.dtype or a pandas dtype\n\n    Raises\n    ------\n    TypeError if not a dtype\n    \"\"\"\n    # short-circuit\n    if isinstance(dtype, np.ndarray):\n        return dtype.dtype\n    elif isinstance(dtype, (np.dtype, ExtensionDtype)):\n        return dtype\n\n    # registered extension types\n    result = registry.find(dtype)\n    if result is not None:\n        return result\n\n    # try a numpy dtype\n    # raise a consistent TypeError if failed\n    try:\n        npdtype = np.dtype(dtype)\n    except SyntaxError as err:\n        # np.dtype uses `eval` which can raise SyntaxError\n        raise TypeError(f\"data type '{dtype}' not understood\") from err\n\n    # Any invalid dtype (such as pd.Timestamp) should raise an error.\n    # np.dtype(invalid_type).kind = 0 for such objects. However, this will\n    # also catch some valid dtypes such as object, np.object_ and 'object'\n    # which we safeguard against by catching them earlier and returning\n    # np.dtype(valid_dtype) before this condition is evaluated.\n    if is_hashable(dtype) and dtype in [object, np.object_, \"object\", \"O\"]:\n        # check hashability to avoid errors/DeprecationWarning when we get\n        # here and `dtype` is an array\n        return npdtype\n    elif npdtype.kind == \"O\":\n        raise TypeError(f\"dtype '{dtype}' not understood\")\n\n    return npdtype",
        "begin_line": 1732,
        "end_line": 1779,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.missing.isna#44",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing.isna(obj)",
        "snippet": "def isna(obj):\n    \"\"\"\n    Detect missing values for an array-like object.\n\n    This function takes a scalar or array-like object and indicates\n    whether values are missing (``NaN`` in numeric arrays, ``None`` or ``NaN``\n    in object arrays, ``NaT`` in datetimelike).\n\n    Parameters\n    ----------\n    obj : scalar or array-like\n        Object to check for null or missing values.\n\n    Returns\n    -------\n    bool or array-like of bool\n        For scalar input, returns a scalar boolean.\n        For array input, returns an array of boolean indicating whether each\n        corresponding element is missing.\n\n    See Also\n    --------\n    notna : Boolean inverse of pandas.isna.\n    Series.isna : Detect missing values in a Series.\n    DataFrame.isna : Detect missing values in a DataFrame.\n    Index.isna : Detect missing values in an Index.\n\n    Examples\n    --------\n    Scalar arguments (including strings) result in a scalar boolean.\n\n    >>> pd.isna('dog')\n    False\n\n    >>> pd.isna(pd.NA)\n    True\n\n    >>> pd.isna(np.nan)\n    True\n\n    ndarrays result in an ndarray of booleans.\n\n    >>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n    >>> array\n    array([[ 1., nan,  3.],\n           [ 4.,  5., nan]])\n    >>> pd.isna(array)\n    array([[False,  True, False],\n           [False, False,  True]])\n\n    For indexes, an ndarray of booleans is returned.\n\n    >>> index = pd.DatetimeIndex([\"2017-07-05\", \"2017-07-06\", None,\n    ...                           \"2017-07-08\"])\n    >>> index\n    DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],\n                  dtype='datetime64[ns]', freq=None)\n    >>> pd.isna(index)\n    array([False, False,  True, False])\n\n    For Series and DataFrame, the same type is returned, containing booleans.\n\n    >>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])\n    >>> df\n         0     1    2\n    0  ant   bee  cat\n    1  dog  None  fly\n    >>> pd.isna(df)\n           0      1      2\n    0  False  False  False\n    1  False   True  False\n\n    >>> pd.isna(df[1])\n    0    False\n    1     True\n    Name: 1, dtype: bool\n    \"\"\"\n    return _isna(obj)",
        "begin_line": 44,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.missing._isna_new#127",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing._isna_new(obj)",
        "snippet": "def _isna_new(obj):\n\n    if is_scalar(obj):\n        return libmissing.checknull(obj)\n    # hack (for now) because MI registers as ndarray\n    elif isinstance(obj, ABCMultiIndex):\n        raise NotImplementedError(\"isna is not defined for MultiIndex\")\n    elif isinstance(obj, type):\n        return False\n    elif isinstance(obj, (ABCSeries, np.ndarray, ABCIndexClass, ABCExtensionArray)):\n        return _isna_ndarraylike(obj)\n    elif isinstance(obj, ABCDataFrame):\n        return obj.isna()\n    elif isinstance(obj, list):\n        return _isna_ndarraylike(np.asarray(obj, dtype=object))\n    elif hasattr(obj, \"__array__\"):\n        return _isna_ndarraylike(np.asarray(obj))\n    else:\n        return False",
        "begin_line": 127,
        "end_line": 145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.missing._isna_ndarraylike#210",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing._isna_ndarraylike(obj)",
        "snippet": "def _isna_ndarraylike(obj):\n    is_extension = is_extension_array_dtype(obj.dtype)\n    values = getattr(obj, \"_values\", obj)\n    dtype = values.dtype\n\n    if is_extension:\n        result = values.isna()\n    elif is_string_dtype(dtype):\n        result = _isna_string_dtype(values, dtype, old=False)\n\n    elif needs_i8_conversion(dtype):\n        # this is the NaT pattern\n        result = values.view(\"i8\") == iNaT\n    else:\n        result = np.isnan(values)\n\n    # box\n    if isinstance(obj, ABCSeries):\n        result = obj._constructor(result, index=obj.index, name=obj.name, copy=False)\n\n    return result",
        "begin_line": 210,
        "end_line": 230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.missing._isna_string_dtype#253",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing._isna_string_dtype(values: np.ndarray, dtype: np.dtype, old: bool)",
        "snippet": "def _isna_string_dtype(values: np.ndarray, dtype: np.dtype, old: bool) -> np.ndarray:\n    # Working around NumPy ticket 1542\n    shape = values.shape\n\n    if is_string_like_dtype(dtype):\n        result = np.zeros(values.shape, dtype=bool)\n    else:\n        result = np.empty(shape, dtype=bool)\n        if old:\n            vec = libmissing.isnaobj_old(values.ravel())\n        else:\n            vec = libmissing.isnaobj(values.ravel())\n\n        result[...] = vec.reshape(shape)\n\n    return result",
        "begin_line": 253,
        "end_line": 268,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.missing.array_equivalent#374",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing.array_equivalent(left, right, strict_nan: bool=False)",
        "snippet": "def array_equivalent(left, right, strict_nan: bool = False) -> bool:\n    \"\"\"\n    True if two arrays, left and right, have equal non-NaN elements, and NaNs\n    in corresponding locations.  False otherwise. It is assumed that left and\n    right are NumPy arrays of the same dtype. The behavior of this function\n    (particularly with respect to NaNs) is not defined if the dtypes are\n    different.\n\n    Parameters\n    ----------\n    left, right : ndarrays\n    strict_nan : bool, default False\n        If True, consider NaN and None to be different.\n\n    Returns\n    -------\n    b : bool\n        Returns True if the arrays are equivalent.\n\n    Examples\n    --------\n    >>> array_equivalent(\n    ...     np.array([1, 2, np.nan]),\n    ...     np.array([1, 2, np.nan]))\n    True\n    >>> array_equivalent(\n    ...     np.array([1, np.nan, 2]),\n    ...     np.array([1, 2, np.nan]))\n    False\n    \"\"\"\n    left, right = np.asarray(left), np.asarray(right)\n\n    # shape compat\n    if left.shape != right.shape:\n        return False\n\n    # Object arrays can contain None, NaN and NaT.\n    # string dtypes must be come to this path for NumPy 1.7.1 compat\n    if is_string_dtype(left) or is_string_dtype(right):\n\n        if not strict_nan:\n            # isna considers NaN and None to be equivalent.\n            return lib.array_equivalent_object(\n                ensure_object(left.ravel()), ensure_object(right.ravel())\n            )\n\n        for left_value, right_value in zip(left, right):\n            if left_value is NaT and right_value is not NaT:\n                return False\n\n            elif left_value is libmissing.NA and right_value is not libmissing.NA:\n                return False\n\n            elif isinstance(left_value, float) and np.isnan(left_value):\n                if not isinstance(right_value, float) or not np.isnan(right_value):\n                    return False\n            else:\n                try:\n                    if np.any(np.asarray(left_value != right_value)):\n                        return False\n                except TypeError as err:\n                    if \"Cannot compare tz-naive\" in str(err):\n                        # tzawareness compat failure, see GH#28507\n                        return False\n                    elif \"boolean value of NA is ambiguous\" in str(err):\n                        return False\n                    raise\n        return True\n\n    # NaNs can occur in float and complex arrays.\n    if is_float_dtype(left) or is_complex_dtype(left):\n\n        # empty\n        if not (np.prod(left.shape) and np.prod(right.shape)):\n            return True\n        return ((left == right) | (isna(left) & isna(right))).all()\n\n    elif is_datetimelike_v_numeric(left, right):\n        # GH#29553 avoid numpy deprecation warning\n        return False\n\n    elif needs_i8_conversion(left) or needs_i8_conversion(right):\n        # datetime64, timedelta64, Period\n        if not is_dtype_equal(left.dtype, right.dtype):\n            return False\n\n        left = left.view(\"i8\")\n        right = right.view(\"i8\")\n\n    # if we have structured dtypes, compare first\n    if left.dtype.type is np.void or right.dtype.type is np.void:\n        if left.dtype != right.dtype:\n            return False\n\n    return np.array_equal(left, right)",
        "begin_line": 374,
        "end_line": 468,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.construction.extract_array#339",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction.extract_array(obj, extract_numpy: bool=False)",
        "snippet": "def extract_array(obj, extract_numpy: bool = False):\n    \"\"\"\n    Extract the ndarray or ExtensionArray from a Series or Index.\n\n    For all other types, `obj` is just returned as is.\n\n    Parameters\n    ----------\n    obj : object\n        For Series / Index, the underlying ExtensionArray is unboxed.\n        For Numpy-backed ExtensionArrays, the ndarray is extracted.\n\n    extract_numpy : bool, default False\n        Whether to extract the ndarray from a PandasArray\n\n    Returns\n    -------\n    arr : object\n\n    Examples\n    --------\n    >>> extract_array(pd.Series(['a', 'b', 'c'], dtype='category'))\n    [a, b, c]\n    Categories (3, object): [a, b, c]\n\n    Other objects like lists, arrays, and DataFrames are just passed through.\n\n    >>> extract_array([1, 2, 3])\n    [1, 2, 3]\n\n    For an ndarray-backed Series / Index a PandasArray is returned.\n\n    >>> extract_array(pd.Series([1, 2, 3]))\n    <PandasArray>\n    [1, 2, 3]\n    Length: 3, dtype: int64\n\n    To extract all the way down to the ndarray, pass ``extract_numpy=True``.\n\n    >>> extract_array(pd.Series([1, 2, 3]), extract_numpy=True)\n    array([1, 2, 3])\n    \"\"\"\n    if isinstance(obj, (ABCIndexClass, ABCSeries)):\n        obj = obj.array\n\n    if extract_numpy and isinstance(obj, ABCPandasArray):\n        obj = obj.to_numpy()\n\n    return obj",
        "begin_line": 339,
        "end_line": 387,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.construction.sanitize_array#390",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction.sanitize_array(data, index, dtype=None, copy: bool=False, raise_cast_failure: bool=False)",
        "snippet": "def sanitize_array(\n    data, index, dtype=None, copy: bool = False, raise_cast_failure: bool = False\n):\n    \"\"\"\n    Sanitize input data to an ndarray, copy if specified, coerce to the\n    dtype if specified.\n    \"\"\"\n    if dtype is not None:\n        dtype = pandas_dtype(dtype)\n\n    if isinstance(data, ma.MaskedArray):\n        mask = ma.getmaskarray(data)\n        if mask.any():\n            data, fill_value = maybe_upcast(data, copy=True)\n            data.soften_mask()  # set hardmask False if it was True\n            data[mask] = fill_value\n        else:\n            data = data.copy()\n\n    # extract ndarray or ExtensionArray, ensure we have no PandasArray\n    data = extract_array(data, extract_numpy=True)\n\n    # GH#846\n    if isinstance(data, np.ndarray):\n\n        if dtype is not None and is_float_dtype(data.dtype) and is_integer_dtype(dtype):\n            # possibility of nan -> garbage\n            try:\n                subarr = _try_cast(data, dtype, copy, True)\n            except ValueError:\n                if copy:\n                    subarr = data.copy()\n                else:\n                    subarr = np.array(data, copy=False)\n        else:\n            # we will try to copy be-definition here\n            subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n\n    elif isinstance(data, ABCExtensionArray):\n        # it is already ensured above this is not a PandasArray\n        subarr = data\n\n        if dtype is not None:\n            subarr = subarr.astype(dtype, copy=copy)\n        elif copy:\n            subarr = subarr.copy()\n        return subarr\n\n    elif isinstance(data, (list, tuple)) and len(data) > 0:\n        if dtype is not None:\n            subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n        else:\n            subarr = maybe_convert_platform(data)\n\n        subarr = maybe_cast_to_datetime(subarr, dtype)\n\n    elif isinstance(data, range):\n        # GH#16804\n        arr = np.arange(data.start, data.stop, data.step, dtype=\"int64\")\n        subarr = _try_cast(arr, dtype, copy, raise_cast_failure)\n    elif isinstance(data, abc.Set):\n        raise TypeError(\"Set type is unordered\")\n    else:\n        subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n\n    # scalar like, GH\n    if getattr(subarr, \"ndim\", 0) == 0:\n        if isinstance(data, list):  # pragma: no cover\n            subarr = np.array(data, dtype=object)\n        elif index is not None:\n            value = data\n\n            # figure out the dtype from the value (upcast if necessary)\n            if dtype is None:\n                dtype, value = infer_dtype_from_scalar(value)\n            else:\n                # need to possibly convert the value here\n                value = maybe_cast_to_datetime(value, dtype)\n\n            subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype)\n\n        else:\n            return subarr.item()\n\n    # the result that we want\n    elif subarr.ndim == 1:\n        if index is not None:\n\n            # a 1-element ndarray\n            if len(subarr) != len(index) and len(subarr) == 1:\n                subarr = construct_1d_arraylike_from_scalar(\n                    subarr[0], len(index), subarr.dtype\n                )\n\n    elif subarr.ndim > 1:\n        if isinstance(data, np.ndarray):\n            raise Exception(\"Data must be 1-dimensional\")\n        else:\n            subarr = com.asarray_tuplesafe(data, dtype=dtype)\n\n    if not (is_extension_array_dtype(subarr.dtype) or is_extension_array_dtype(dtype)):\n        # This is to prevent mixed-type Series getting all casted to\n        # NumPy string type, e.g. NaN --> '-1#IND'.\n        if issubclass(subarr.dtype.type, str):\n            # GH#16605\n            # If not empty convert the data to dtype\n            # GH#19853: If data is a scalar, subarr has already the result\n            if not lib.is_scalar(data):\n                if not np.all(isna(data)):\n                    data = np.array(data, dtype=dtype, copy=False)\n                subarr = np.array(data, dtype=object, copy=copy)\n\n        if is_object_dtype(subarr.dtype) and not is_object_dtype(dtype):\n            inferred = lib.infer_dtype(subarr, skipna=False)\n            if inferred in {\"interval\", \"period\"}:\n                subarr = array(subarr)\n\n    return subarr",
        "begin_line": 390,
        "end_line": 507,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.construction._try_cast#510",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction._try_cast(arr, dtype: Optional[Union[np.dtype, 'ExtensionDtype']], copy: bool, raise_cast_failure: bool)",
        "snippet": "def _try_cast(\n    arr,\n    dtype: Optional[Union[np.dtype, \"ExtensionDtype\"]],\n    copy: bool,\n    raise_cast_failure: bool,\n):\n    \"\"\"\n    Convert input to numpy ndarray and optionally cast to a given dtype.\n\n    Parameters\n    ----------\n    arr : ndarray, list, tuple, iterator (catchall)\n        Excludes: ExtensionArray, Series, Index.\n    dtype : np.dtype, ExtensionDtype or None\n    copy : bool\n        If False, don't copy the data if not needed.\n    raise_cast_failure : bool\n        If True, and if a dtype is specified, raise errors during casting.\n        Otherwise an object array is returned.\n    \"\"\"\n    # perf shortcut as this is the most common case\n    if isinstance(arr, np.ndarray):\n        if maybe_castable(arr) and not copy and dtype is None:\n            return arr\n\n    try:\n        # GH#15832: Check if we are requesting a numeric dype and\n        # that we can convert the data to the requested dtype.\n        if is_integer_dtype(dtype):\n            subarr = maybe_cast_to_integer_array(arr, dtype)\n\n        subarr = maybe_cast_to_datetime(arr, dtype)\n        # Take care in creating object arrays (but iterators are not\n        # supported):\n        if is_object_dtype(dtype) and (\n            is_list_like(subarr)\n            and not (is_iterator(subarr) or isinstance(subarr, np.ndarray))\n        ):\n            subarr = construct_1d_object_array_from_listlike(subarr)\n        elif not is_extension_array_dtype(subarr):\n            subarr = construct_1d_ndarray_preserving_na(subarr, dtype, copy=copy)\n    except OutOfBoundsDatetime:\n        # in case of out of bound datetime64 -> always raise\n        raise\n    except (ValueError, TypeError):\n        if is_categorical_dtype(dtype):\n            # We *do* allow casting to categorical, since we know\n            # that Categorical is the only array type for 'category'.\n            dtype = cast(CategoricalDtype, dtype)\n            subarr = dtype.construct_array_type()(\n                arr, dtype.categories, ordered=dtype.ordered\n            )\n        elif is_extension_array_dtype(dtype):\n            # create an extension array from its dtype\n            dtype = cast(ExtensionDtype, dtype)\n            array_type = dtype.construct_array_type()._from_sequence\n            subarr = array_type(arr, dtype=dtype, copy=copy)\n        elif dtype is not None and raise_cast_failure:\n            raise\n        else:\n            subarr = np.array(arr, dtype=object, copy=copy)\n    return subarr",
        "begin_line": 510,
        "end_line": 571,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.construction.is_empty_data#574",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction.is_empty_data(data: Any)",
        "snippet": "def is_empty_data(data: Any) -> bool:\n    \"\"\"\n    Utility to check if a Series is instantiated with empty data,\n    which does not contain dtype information.\n\n    Parameters\n    ----------\n    data : array-like, Iterable, dict, or scalar value\n        Contains data stored in Series.\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    is_none = data is None\n    is_list_like_without_dtype = is_list_like(data) and not hasattr(data, \"dtype\")\n    is_simple_empty = is_list_like_without_dtype and not data\n    return is_none or is_simple_empty",
        "begin_line": 574,
        "end_line": 591,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.io.formats.printing.pprint_thing#166",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.pprint_thing(thing: Any, _nest_lvl: int=0, escape_chars: Optional[EscapeChars]=None, default_escapes: bool=False, quote_strings: bool=False, max_seq_items: Optional[int]=None)",
        "snippet": "def pprint_thing(\n    thing: Any,\n    _nest_lvl: int = 0,\n    escape_chars: Optional[EscapeChars] = None,\n    default_escapes: bool = False,\n    quote_strings: bool = False,\n    max_seq_items: Optional[int] = None,\n) -> str:\n    \"\"\"\n    This function is the sanctioned way of converting objects\n    to a string representation and properly handles nested sequences.\n\n    Parameters\n    ----------\n    thing : anything to be formatted\n    _nest_lvl : internal use only. pprint_thing() is mutually-recursive\n        with pprint_sequence, this argument is used to keep track of the\n        current nesting level, and limit it.\n    escape_chars : list or dict, optional\n        Characters to escape. If a dict is passed the values are the\n        replacements\n    default_escapes : bool, default False\n        Whether the input escape characters replaces or adds to the defaults\n    max_seq_items : int or None, default None\n        Pass through to other pretty printers to limit sequence printing\n\n    Returns\n    -------\n    str\n    \"\"\"\n\n    def as_escaped_string(\n        thing: Any, escape_chars: Optional[EscapeChars] = escape_chars\n    ) -> str:\n        translate = {\"\\t\": r\"\\t\", \"\\n\": r\"\\n\", \"\\r\": r\"\\r\"}\n        if isinstance(escape_chars, dict):\n            if default_escapes:\n                translate.update(escape_chars)\n            else:\n                translate = escape_chars\n            escape_chars = list(escape_chars.keys())\n        else:\n            escape_chars = escape_chars or tuple()\n\n        result = str(thing)\n        for c in escape_chars:\n            result = result.replace(c, translate[c])\n        return result\n\n    if hasattr(thing, \"__next__\"):\n        return str(thing)\n    elif isinstance(thing, dict) and _nest_lvl < get_option(\n        \"display.pprint_nest_depth\"\n    ):\n        result = _pprint_dict(\n            thing, _nest_lvl, quote_strings=True, max_seq_items=max_seq_items\n        )\n    elif is_sequence(thing) and _nest_lvl < get_option(\"display.pprint_nest_depth\"):\n        result = _pprint_seq(\n            thing,\n            _nest_lvl,\n            escape_chars=escape_chars,\n            quote_strings=quote_strings,\n            max_seq_items=max_seq_items,\n        )\n    elif isinstance(thing, str) and quote_strings:\n        result = f\"'{as_escaped_string(thing)}'\"\n    else:\n        result = as_escaped_string(thing)\n\n    return result",
        "begin_line": 166,
        "end_line": 236,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.printing.as_escaped_string#197",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.as_escaped_string(thing: Any, escape_chars: Optional[EscapeChars]=escape_chars)",
        "snippet": "    def as_escaped_string(\n        thing: Any, escape_chars: Optional[EscapeChars] = escape_chars\n    ) -> str:\n        translate = {\"\\t\": r\"\\t\", \"\\n\": r\"\\n\", \"\\r\": r\"\\r\"}\n        if isinstance(escape_chars, dict):\n            if default_escapes:\n                translate.update(escape_chars)\n            else:\n                translate = escape_chars\n            escape_chars = list(escape_chars.keys())\n        else:\n            escape_chars = escape_chars or tuple()\n\n        result = str(thing)\n        for c in escape_chars:\n            result = result.replace(c, translate[c])\n        return result",
        "begin_line": 197,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.printing.format_object_summary#284",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.format_object_summary(obj, formatter: Callable, is_justify: bool=True, name: Optional[str]=None, indent_for_name: bool=True, line_break_each_value: bool=False)",
        "snippet": "def format_object_summary(\n    obj,\n    formatter: Callable,\n    is_justify: bool = True,\n    name: Optional[str] = None,\n    indent_for_name: bool = True,\n    line_break_each_value: bool = False,\n) -> str:\n    \"\"\"\n    Return the formatted obj as a unicode string\n\n    Parameters\n    ----------\n    obj : object\n        must be iterable and support __getitem__\n    formatter : callable\n        string formatter for an element\n    is_justify : boolean\n        should justify the display\n    name : name, optional\n        defaults to the class name of the obj\n    indent_for_name : bool, default True\n        Whether subsequent lines should be be indented to\n        align with the name.\n    line_break_each_value : bool, default False\n        If True, inserts a line break for each value of ``obj``.\n        If False, only break lines when the a line of values gets wider\n        than the display width.\n\n        .. versionadded:: 0.25.0\n\n    Returns\n    -------\n    summary string\n    \"\"\"\n    from pandas.io.formats.console import get_console_size\n    from pandas.io.formats.format import _get_adjustment\n\n    display_width, _ = get_console_size()\n    if display_width is None:\n        display_width = get_option(\"display.width\") or 80\n    if name is None:\n        name = type(obj).__name__\n\n    if indent_for_name:\n        name_len = len(name)\n        space1 = f'\\n{(\" \" * (name_len + 1))}'\n        space2 = f'\\n{(\" \" * (name_len + 2))}'\n    else:\n        space1 = \"\\n\"\n        space2 = \"\\n \"  # space for the opening '['\n\n    n = len(obj)\n    if line_break_each_value:\n        # If we want to vertically align on each value of obj, we need to\n        # separate values by a line break and indent the values\n        sep = \",\\n \" + \" \" * len(name)\n    else:\n        sep = \",\"\n    max_seq_items = get_option(\"display.max_seq_items\") or n\n\n    # are we a truncated display\n    is_truncated = n > max_seq_items\n\n    # adj can optionally handle unicode eastern asian width\n    adj = _get_adjustment()\n\n    def _extend_line(\n        s: str, line: str, value: str, display_width: int, next_line_prefix: str\n    ) -> Tuple[str, str]:\n\n        if adj.len(line.rstrip()) + adj.len(value.rstrip()) >= display_width:\n            s += line.rstrip()\n            line = next_line_prefix\n        line += value\n        return s, line\n\n    def best_len(values: List[str]) -> int:\n        if values:\n            return max(adj.len(x) for x in values)\n        else:\n            return 0\n\n    close = \", \"\n\n    if n == 0:\n        summary = f\"[]{close}\"\n    elif n == 1 and not line_break_each_value:\n        first = formatter(obj[0])\n        summary = f\"[{first}]{close}\"\n    elif n == 2 and not line_break_each_value:\n        first = formatter(obj[0])\n        last = formatter(obj[-1])\n        summary = f\"[{first}, {last}]{close}\"\n    else:\n\n        if n > max_seq_items:\n            n = min(max_seq_items // 2, 10)\n            head = [formatter(x) for x in obj[:n]]\n            tail = [formatter(x) for x in obj[-n:]]\n        else:\n            head = []\n            tail = [formatter(x) for x in obj]\n\n        # adjust all values to max length if needed\n        if is_justify:\n            if line_break_each_value:\n                # Justify each string in the values of head and tail, so the\n                # strings will right align when head and tail are stacked\n                # vertically.\n                head, tail = _justify(head, tail)\n            elif is_truncated or not (\n                len(\", \".join(head)) < display_width\n                and len(\", \".join(tail)) < display_width\n            ):\n                # Each string in head and tail should align with each other\n                max_length = max(best_len(head), best_len(tail))\n                head = [x.rjust(max_length) for x in head]\n                tail = [x.rjust(max_length) for x in tail]\n            # If we are not truncated and we are only a single\n            # line, then don't justify\n\n        if line_break_each_value:\n            # Now head and tail are of type List[Tuple[str]]. Below we\n            # convert them into List[str], so there will be one string per\n            # value. Also truncate items horizontally if wider than\n            # max_space\n            max_space = display_width - len(space2)\n            value = tail[0]\n            for max_items in reversed(range(1, len(value) + 1)):\n                pprinted_seq = _pprint_seq(value, max_seq_items=max_items)\n                if len(pprinted_seq) < max_space:\n                    break\n            head = [_pprint_seq(x, max_seq_items=max_items) for x in head]\n            tail = [_pprint_seq(x, max_seq_items=max_items) for x in tail]\n\n        summary = \"\"\n        line = space2\n\n        for max_items in range(len(head)):\n            word = head[max_items] + sep + \" \"\n            summary, line = _extend_line(summary, line, word, display_width, space2)\n\n        if is_truncated:\n            # remove trailing space of last line\n            summary += line.rstrip() + space2 + \"...\"\n            line = space2\n\n        for max_items in range(len(tail) - 1):\n            word = tail[max_items] + sep + \" \"\n            summary, line = _extend_line(summary, line, word, display_width, space2)\n\n        # last value: no sep added + 1 space of width used for trailing ','\n        summary, line = _extend_line(summary, line, tail[-1], display_width - 2, space2)\n        summary += line\n\n        # right now close is either '' or ', '\n        # Now we want to include the ']', but not the maybe space.\n        close = \"]\" + close.rstrip(\" \")\n        summary += close\n\n        if len(summary) > (display_width) or line_break_each_value:\n            summary += space1\n        else:  # one row\n            summary += \" \"\n\n        # remove initial space\n        summary = \"[\" + summary[len(space2) :]\n\n    return summary",
        "begin_line": 284,
        "end_line": 453,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.printing._extend_line#351",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing._extend_line(s: str, line: str, value: str, display_width: int, next_line_prefix: str)",
        "snippet": "    def _extend_line(\n        s: str, line: str, value: str, display_width: int, next_line_prefix: str\n    ) -> Tuple[str, str]:\n\n        if adj.len(line.rstrip()) + adj.len(value.rstrip()) >= display_width:\n            s += line.rstrip()\n            line = next_line_prefix\n        line += value\n        return s, line",
        "begin_line": 351,
        "end_line": 359,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.printing.best_len#361",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.best_len(values: List[str])",
        "snippet": "    def best_len(values: List[str]) -> int:\n        if values:\n            return max(adj.len(x) for x in values)\n        else:\n            return 0",
        "begin_line": 361,
        "end_line": 365,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.io.formats.printing.format_object_attrs#501",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.format_object_attrs(obj: Sequence, include_dtype: bool=True)",
        "snippet": "def format_object_attrs(\n    obj: Sequence, include_dtype: bool = True\n) -> List[Tuple[str, Union[str, int]]]:\n    \"\"\"\n    Return a list of tuples of the (attr, formatted_value)\n    for common attrs, including dtype, name, length\n\n    Parameters\n    ----------\n    obj : object\n        must be iterable\n    include_dtype : bool\n        If False, dtype won't be in the returned list\n\n    Returns\n    -------\n    list of 2-tuple\n\n    \"\"\"\n    attrs: List[Tuple[str, Union[str, int]]] = []\n    if hasattr(obj, \"dtype\") and include_dtype:\n        # error: \"Sequence[Any]\" has no attribute \"dtype\"\n        attrs.append((\"dtype\", f\"'{obj.dtype}'\"))  # type: ignore\n    if getattr(obj, \"name\", None) is not None:\n        # error: \"Sequence[Any]\" has no attribute \"name\"\n        attrs.append((\"name\", default_pprint(obj.name)))  # type: ignore\n    # error: \"Sequence[Any]\" has no attribute \"names\"\n    elif getattr(obj, \"names\", None) is not None and any(obj.names):  # type: ignore\n        # error: \"Sequence[Any]\" has no attribute \"names\"\n        attrs.append((\"names\", default_pprint(obj.names)))  # type: ignore\n    max_seq_items = get_option(\"display.max_seq_items\") or len(obj)\n    if len(obj) > max_seq_items:\n        attrs.append((\"length\", len(obj)))\n    return attrs",
        "begin_line": 501,
        "end_line": 534,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.api.get_objs_combined_axis#65",
        "src_path": "pandas/core/indexes/api.py",
        "class_name": "pandas.core.indexes.api",
        "signature": "pandas.core.indexes.api.get_objs_combined_axis(objs, intersect: bool=False, axis=0, sort: bool=True, copy: bool=False)",
        "snippet": "def get_objs_combined_axis(\n    objs, intersect: bool = False, axis=0, sort: bool = True, copy: bool = False\n) -> Index:\n    \"\"\"\n    Extract combined index: return intersection or union (depending on the\n    value of \"intersect\") of indexes on given axis, or None if all objects\n    lack indexes (e.g. they are numpy arrays).\n\n    Parameters\n    ----------\n    objs : list\n        Series or DataFrame objects, may be mix of the two.\n    intersect : bool, default False\n        If True, calculate the intersection between indexes. Otherwise,\n        calculate the union.\n    axis : {0 or 'index', 1 or 'outer'}, default 0\n        The axis to extract indexes from.\n    sort : bool, default True\n        Whether the result index should come out sorted or not.\n    copy : bool, default False\n        If True, return a copy of the combined index.\n\n    Returns\n    -------\n    Index\n    \"\"\"\n    obs_idxes = [obj._get_axis(axis) for obj in objs]\n    return _get_combined_index(obs_idxes, intersect=intersect, sort=sort, copy=copy)",
        "begin_line": 65,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.api._get_distinct_objs#95",
        "src_path": "pandas/core/indexes/api.py",
        "class_name": "pandas.core.indexes.api",
        "signature": "pandas.core.indexes.api._get_distinct_objs(objs: List[Index])",
        "snippet": "def _get_distinct_objs(objs: List[Index]) -> List[Index]:\n    \"\"\"\n    Return a list with distinct elements of \"objs\" (different ids).\n    Preserves order.\n    \"\"\"\n    ids: Set[int] = set()\n    res = []\n    for obj in objs:\n        if id(obj) not in ids:\n            ids.add(id(obj))\n            res.append(obj)\n    return res",
        "begin_line": 95,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.api._get_combined_index#109",
        "src_path": "pandas/core/indexes/api.py",
        "class_name": "pandas.core.indexes.api",
        "signature": "pandas.core.indexes.api._get_combined_index(indexes: List[Index], intersect: bool=False, sort: bool=False, copy: bool=False)",
        "snippet": "def _get_combined_index(\n    indexes: List[Index],\n    intersect: bool = False,\n    sort: bool = False,\n    copy: bool = False,\n) -> Index:\n    \"\"\"\n    Return the union or intersection of indexes.\n\n    Parameters\n    ----------\n    indexes : list of Index or list objects\n        When intersect=True, do not accept list of lists.\n    intersect : bool, default False\n        If True, calculate the intersection between indexes. Otherwise,\n        calculate the union.\n    sort : bool, default False\n        Whether the result index should come out sorted or not.\n    copy : bool, default False\n        If True, return a copy of the combined index.\n\n    Returns\n    -------\n    Index\n    \"\"\"\n    # TODO: handle index names!\n    indexes = _get_distinct_objs(indexes)\n    if len(indexes) == 0:\n        index = Index([])\n    elif len(indexes) == 1:\n        index = indexes[0]\n    elif intersect:\n        index = indexes[0]\n        for other in indexes[1:]:\n            index = index.intersection(other)\n    else:\n        index = union_indexes(indexes, sort=sort)\n        index = ensure_index(index)\n\n    if sort:\n        try:\n            index = index.sort_values()\n        except TypeError:\n            pass\n\n    # GH 29879\n    if copy:\n        index = index.copy()\n\n    return index",
        "begin_line": 109,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.frame.DataFrame._constructor#416",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame._constructor(self)",
        "snippet": "    def _constructor(self) -> Type[\"DataFrame\"]:\n        return DataFrame",
        "begin_line": 416,
        "end_line": 417,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.frame.DataFrame.__init__#430",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame.__init__(self, data=None, index: Optional[Axes]=None, columns: Optional[Axes]=None, dtype: Optional[Dtype]=None, copy: bool=False)",
        "snippet": "    def __init__(\n        self,\n        data=None,\n        index: Optional[Axes] = None,\n        columns: Optional[Axes] = None,\n        dtype: Optional[Dtype] = None,\n        copy: bool = False,\n    ):\n        if data is None:\n            data = {}\n        if dtype is not None:\n            dtype = self._validate_dtype(dtype)\n\n        if isinstance(data, DataFrame):\n            data = data._mgr\n\n        if isinstance(data, BlockManager):\n            if index is None and columns is None and dtype is None and copy is False:\n                # GH#33357 fastpath\n                NDFrame.__init__(self, data)\n                return\n\n            mgr = self._init_mgr(\n                data, axes=dict(index=index, columns=columns), dtype=dtype, copy=copy\n            )\n        elif isinstance(data, dict):\n            mgr = init_dict(data, index, columns, dtype=dtype)\n        elif isinstance(data, ma.MaskedArray):\n            import numpy.ma.mrecords as mrecords\n\n            # masked recarray\n            if isinstance(data, mrecords.MaskedRecords):\n                mgr = masked_rec_array_to_mgr(data, index, columns, dtype, copy)\n\n            # a masked array\n            else:\n                mask = ma.getmaskarray(data)\n                if mask.any():\n                    data, fill_value = maybe_upcast(data, copy=True)\n                    data.soften_mask()  # set hardmask False if it was True\n                    data[mask] = fill_value\n                else:\n                    data = data.copy()\n                mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n\n        elif isinstance(data, (np.ndarray, Series, Index)):\n            if data.dtype.names:\n                data_columns = list(data.dtype.names)\n                data = {k: data[k] for k in data_columns}\n                if columns is None:\n                    columns = data_columns\n                mgr = init_dict(data, index, columns, dtype=dtype)\n            elif getattr(data, \"name\", None) is not None:\n                mgr = init_dict({data.name: data}, index, columns, dtype=dtype)\n            else:\n                mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n\n        # For data is list-like, or Iterable (will consume into list)\n        elif isinstance(data, abc.Iterable) and not isinstance(data, (str, bytes)):\n            if not isinstance(data, (abc.Sequence, ExtensionArray)):\n                data = list(data)\n            if len(data) > 0:\n                if is_dataclass(data[0]):\n                    data = dataclasses_to_dicts(data)\n                if is_list_like(data[0]) and getattr(data[0], \"ndim\", 1) == 1:\n                    if is_named_tuple(data[0]) and columns is None:\n                        columns = data[0]._fields\n                    arrays, columns = to_arrays(data, columns, dtype=dtype)\n                    columns = ensure_index(columns)\n\n                    # set the index\n                    if index is None:\n                        if isinstance(data[0], Series):\n                            index = get_names_from_index(data)\n                        elif isinstance(data[0], Categorical):\n                            index = ibase.default_index(len(data[0]))\n                        else:\n                            index = ibase.default_index(len(data))\n\n                    mgr = arrays_to_mgr(arrays, columns, index, columns, dtype=dtype)\n                else:\n                    mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n            else:\n                mgr = init_dict({}, index, columns, dtype=dtype)\n        else:\n            try:\n                arr = np.array(data, dtype=dtype, copy=copy)\n            except (ValueError, TypeError) as err:\n                exc = TypeError(\n                    \"DataFrame constructor called with \"\n                    f\"incompatible data and dtype: {err}\"\n                )\n                raise exc from err\n\n            if arr.ndim == 0 and index is not None and columns is not None:\n                values = cast_scalar_to_array(\n                    (len(index), len(columns)), data, dtype=dtype\n                )\n                mgr = init_ndarray(\n                    values, index, columns, dtype=values.dtype, copy=False\n                )\n            else:\n                raise ValueError(\"DataFrame constructor not properly called!\")\n\n        NDFrame.__init__(self, mgr)",
        "begin_line": 430,
        "end_line": 534,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.frame.DataFrame.__getitem__#2611",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        key = lib.item_from_zerodim(key)\n        key = com.apply_if_callable(key, self)\n\n        if is_hashable(key):\n            # shortcut if the key is in columns\n            if self.columns.is_unique and key in self.columns:\n                if self.columns.nlevels > 1:\n                    return self._getitem_multilevel(key)\n                return self._get_item_cache(key)\n\n        # Do we have a slicer (on rows)?\n        indexer = convert_to_index_sliceable(self, key)\n        if indexer is not None:\n            # either we have a slice or we have a string that can be converted\n            #  to a slice for partial-string date indexing\n            return self._slice(indexer, axis=0)\n\n        # Do we have a (boolean) DataFrame?\n        if isinstance(key, DataFrame):\n            return self.where(key)\n\n        # Do we have a (boolean) 1d indexer?\n        if com.is_bool_indexer(key):\n            return self._getitem_bool_array(key)\n\n        # We are left with two options: a single key, and a collection of keys,\n        # We interpret tuples as collections only for non-MultiIndex\n        is_single_key = isinstance(key, tuple) or not is_list_like(key)\n\n        if is_single_key:\n            if self.columns.nlevels > 1:\n                return self._getitem_multilevel(key)\n            indexer = self.columns.get_loc(key)\n            if is_integer(indexer):\n                indexer = [indexer]\n        else:\n            if is_iterator(key):\n                key = list(key)\n            indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]\n\n        # take() does not accept boolean indexers\n        if getattr(indexer, \"dtype\", None) == bool:\n            indexer = np.where(indexer)[0]\n\n        data = self._take_with_is_copy(indexer, axis=1)\n\n        if is_single_key:\n            # What does looking for a single key in a non-unique index return?\n            # The behavior is inconsistent. It returns a Series, except when\n            # - the key itself is repeated (test on data.shape, #9519), or\n            # - we have a MultiIndex on columns (test on self.columns, #21309)\n            if data.shape[1] == 1 and not isinstance(self.columns, ABCMultiIndex):\n                data = data[key]\n\n        return data",
        "begin_line": 2611,
        "end_line": 2666,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.frame.DataFrame._box_item_values#2918",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame._box_item_values(self, key, values)",
        "snippet": "    def _box_item_values(self, key, values):\n        items = self.columns[self.columns.get_loc(key)]\n        if values.ndim == 2:\n            return self._constructor(values.T, columns=items, index=self.index)\n        else:\n            return self._box_col_values(values, items)",
        "begin_line": 2918,
        "end_line": 2923,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.frame.DataFrame._box_col_values#2925",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame._box_col_values(self, values, items)",
        "snippet": "    def _box_col_values(self, values, items):\n        \"\"\"\n        Provide boxed values for a column.\n        \"\"\"\n        klass = self._constructor_sliced\n        return klass(values, index=self.index, name=items, fastpath=True)",
        "begin_line": 2925,
        "end_line": 2930,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.series.Series.__init__#203",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)",
        "snippet": "    def __init__(\n        self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False\n    ):\n\n        if (\n            isinstance(data, SingleBlockManager)\n            and index is None\n            and dtype is None\n            and copy is False\n        ):\n            # GH#33357 called with just the SingleBlockManager\n            NDFrame.__init__(self, data)\n            self.name = name\n            return\n\n        # we are called internally, so short-circuit\n        if fastpath:\n\n            # data is an ndarray, index is defined\n            if not isinstance(data, SingleBlockManager):\n                data = SingleBlockManager.from_array(data, index)\n            if copy:\n                data = data.copy()\n            if index is None:\n                index = data.index\n\n        else:\n\n            name = ibase.maybe_extract_name(name, data, type(self))\n\n            if is_empty_data(data) and dtype is None:\n                # gh-17261\n                warnings.warn(\n                    \"The default dtype for empty Series will be 'object' instead \"\n                    \"of 'float64' in a future version. Specify a dtype explicitly \"\n                    \"to silence this warning.\",\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n                # uncomment the line below when removing the DeprecationWarning\n                # dtype = np.dtype(object)\n\n            if index is not None:\n                index = ensure_index(index)\n\n            if data is None:\n                data = {}\n            if dtype is not None:\n                dtype = self._validate_dtype(dtype)\n\n            if isinstance(data, MultiIndex):\n                raise NotImplementedError(\n                    \"initializing a Series from a MultiIndex is not supported\"\n                )\n            elif isinstance(data, Index):\n\n                if dtype is not None:\n                    # astype copies\n                    data = data.astype(dtype)\n                else:\n                    # need to copy to avoid aliasing issues\n                    data = data._values.copy()\n                    if isinstance(data, ABCDatetimeIndex) and data.tz is not None:\n                        # GH#24096 need copy to be deep for datetime64tz case\n                        # TODO: See if we can avoid these copies\n                        data = data._values.copy(deep=True)\n                copy = False\n\n            elif isinstance(data, np.ndarray):\n                if len(data.dtype):\n                    # GH#13296 we are dealing with a compound dtype, which\n                    #  should be treated as 2D\n                    raise ValueError(\n                        \"Cannot construct a Series from an ndarray with \"\n                        \"compound dtype.  Use DataFrame instead.\"\n                    )\n                pass\n            elif isinstance(data, ABCSeries):\n                if index is None:\n                    index = data.index\n                else:\n                    data = data.reindex(index, copy=copy)\n                data = data._mgr\n            elif is_dict_like(data):\n                data, index = self._init_dict(data, index, dtype)\n                dtype = None\n                copy = False\n            elif isinstance(data, SingleBlockManager):\n                if index is None:\n                    index = data.index\n                elif not data.index.equals(index) or copy:\n                    # GH#19275 SingleBlockManager input should only be called\n                    # internally\n                    raise AssertionError(\n                        \"Cannot pass both SingleBlockManager \"\n                        \"`data` argument and a different \"\n                        \"`index` argument. `copy` must be False.\"\n                    )\n\n            elif is_extension_array_dtype(data):\n                pass\n            elif isinstance(data, (set, frozenset)):\n                raise TypeError(f\"'{type(data).__name__}' type is unordered\")\n            else:\n                data = com.maybe_iterable_to_list(data)\n\n            if index is None:\n                if not is_list_like(data):\n                    data = [data]\n                index = ibase.default_index(len(data))\n            elif is_list_like(data):\n\n                # a scalar numpy array is list-like but doesn't\n                # have a proper length\n                try:\n                    if len(index) != len(data):\n                        raise ValueError(\n                            f\"Length of passed values is {len(data)}, \"\n                            f\"index implies {len(index)}.\"\n                        )\n                except TypeError:\n                    pass\n\n            # create/copy the manager\n            if isinstance(data, SingleBlockManager):\n                if dtype is not None:\n                    data = data.astype(dtype=dtype, errors=\"ignore\", copy=copy)\n                elif copy:\n                    data = data.copy()\n            else:\n                data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)\n\n                data = SingleBlockManager.from_array(data, index)\n\n        generic.NDFrame.__init__(self, data)\n        self.name = name\n        self._set_axis(0, index, fastpath=True)",
        "begin_line": 203,
        "end_line": 339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.series.Series._constructor#388",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._constructor(self)",
        "snippet": "    def _constructor(self) -> Type[\"Series\"]:\n        return Series",
        "begin_line": 388,
        "end_line": 389,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.series.Series._set_axis#404",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._set_axis(self, axis: int, labels, fastpath: bool=False)",
        "snippet": "    def _set_axis(self, axis: int, labels, fastpath: bool = False) -> None:\n        \"\"\"\n        Override generic, we want to set the _typ here.\n\n        This is called from the cython code when we set the `index` attribute\n        directly, e.g. `series.index = [1, 2, 3]`.\n        \"\"\"\n        if not fastpath:\n            labels = ensure_index(labels)\n\n        is_all_dates = labels.is_all_dates\n        if is_all_dates:\n            if not isinstance(labels, (DatetimeIndex, PeriodIndex, TimedeltaIndex)):\n                try:\n                    labels = DatetimeIndex(labels)\n                    # need to set here because we changed the index\n                    if fastpath:\n                        self._mgr.set_axis(axis, labels)\n                except (tslibs.OutOfBoundsDatetime, ValueError):\n                    # labels may exceeds datetime bounds,\n                    # or not be a DatetimeIndex\n                    pass\n\n        object.__setattr__(self, \"_index\", labels)\n        if not fastpath:\n            # The ensure_index call above ensures we have an Index object\n            self._mgr.set_axis(axis, labels)",
        "begin_line": 404,
        "end_line": 430,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.series.Series.dtype#434",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.dtype(self)",
        "snippet": "    def dtype(self) -> DtypeObj:\n        \"\"\"\n        Return the dtype object of the underlying data.\n        \"\"\"\n        return self._mgr.dtype",
        "begin_line": 434,
        "end_line": 438,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.series.Series.name#449",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.name(self)",
        "snippet": "    def name(self) -> Label:\n        \"\"\"\n        Return the name of the Series.\n\n        The name of a Series becomes its index or column name if it is used\n        to form a DataFrame. It is also used whenever displaying the Series\n        using the interpreter.\n\n        Returns\n        -------\n        label (hashable object)\n            The name of the Series, also the column name if part of a DataFrame.\n\n        See Also\n        --------\n        Series.rename : Sets the Series name when given a scalar input.\n        Index.name : Corresponding Index property.\n\n        Examples\n        --------\n        The Series name can be set initially when calling the constructor.\n\n        >>> s = pd.Series([1, 2, 3], dtype=np.int64, name='Numbers')\n        >>> s\n        0    1\n        1    2\n        2    3\n        Name: Numbers, dtype: int64\n        >>> s.name = \"Integers\"\n        >>> s\n        0    1\n        1    2\n        2    3\n        Name: Integers, dtype: int64\n\n        The name of a Series within a DataFrame is its column name.\n\n        >>> df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],\n        ...                   columns=[\"Odd Numbers\", \"Even Numbers\"])\n        >>> df\n           Odd Numbers  Even Numbers\n        0            1             2\n        1            3             4\n        2            5             6\n        >>> df[\"Even Numbers\"].name\n        'Even Numbers'\n        \"\"\"\n        return self._name",
        "begin_line": 449,
        "end_line": 496,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.series.Series.name#499",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.name(self, value: Label)",
        "snippet": "    def name(self, value: Label) -> None:\n        if not is_hashable(value):\n            raise TypeError(\"Series.name must be a hashable type\")\n        object.__setattr__(self, \"_name\", value)",
        "begin_line": 499,
        "end_line": 502,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.series.Series.values#505",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.values(self)",
        "snippet": "    def values(self):\n        \"\"\"\n        Return Series as ndarray or ndarray-like depending on the dtype.\n\n        .. warning::\n\n           We recommend using :attr:`Series.array` or\n           :meth:`Series.to_numpy`, depending on whether you need\n           a reference to the underlying data or a NumPy array.\n\n        Returns\n        -------\n        numpy.ndarray or ndarray-like\n\n        See Also\n        --------\n        Series.array : Reference to the underlying data.\n        Series.to_numpy : A NumPy array representing the underlying data.\n\n        Examples\n        --------\n        >>> pd.Series([1, 2, 3]).values\n        array([1, 2, 3])\n\n        >>> pd.Series(list('aabc')).values\n        array(['a', 'a', 'b', 'c'], dtype=object)\n\n        >>> pd.Series(list('aabc')).astype('category').values\n        [a, a, b, c]\n        Categories (3, object): [a, b, c]\n\n        Timezone aware datetime data is converted to UTC:\n\n        >>> pd.Series(pd.date_range('20130101', periods=3,\n        ...                         tz='US/Eastern')).values\n        array(['2013-01-01T05:00:00.000000000',\n               '2013-01-02T05:00:00.000000000',\n               '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n        \"\"\"\n        return self._mgr.external_values()",
        "begin_line": 505,
        "end_line": 544,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.series.Series._values#547",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._values(self)",
        "snippet": "    def _values(self):\n        \"\"\"\n        Return the internal repr of this data (defined by Block.interval_values).\n        This are the values as stored in the Block (ndarray or ExtensionArray\n        depending on the Block class), with datetime64[ns] and timedelta64[ns]\n        wrapped in ExtensionArrays to match Index._values behavior.\n\n        Differs from the public ``.values`` for certain data types, because of\n        historical backwards compatibility of the public attribute (e.g. period\n        returns object ndarray and datetimetz a datetime64[ns] ndarray for\n        ``.values`` while it returns an ExtensionArray for ``._values`` in those\n        cases).\n\n        Differs from ``.array`` in that this still returns the numpy array if\n        the Block is backed by a numpy array (except for datetime64 and\n        timedelta64 dtypes), while ``.array`` ensures to always return an\n        ExtensionArray.\n\n        Overview:\n\n        dtype       | values        | _values       | array         |\n        ----------- | ------------- | ------------- | ------------- |\n        Numeric     | ndarray       | ndarray       | PandasArray   |\n        Category    | Categorical   | Categorical   | Categorical   |\n        dt64[ns]    | ndarray[M8ns] | DatetimeArray | DatetimeArray |\n        dt64[ns tz] | ndarray[M8ns] | DatetimeArray | DatetimeArray |\n        td64[ns]    | ndarray[m8ns] | TimedeltaArray| ndarray[m8ns] |\n        Period      | ndarray[obj]  | PeriodArray   | PeriodArray   |\n        Nullable    | EA            | EA            | EA            |\n\n        \"\"\"\n        return self._mgr.internal_values()",
        "begin_line": 547,
        "end_line": 578,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.series.Series.array#582",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.array(self)",
        "snippet": "    def array(self) -> ExtensionArray:\n        return self._mgr._block.array_values()",
        "begin_line": 582,
        "end_line": 583,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.series.Series.__len__#601",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__len__(self)",
        "snippet": "    def __len__(self) -> int:\n        \"\"\"\n        Return the length of the Series.\n        \"\"\"\n        return len(self._mgr)",
        "begin_line": 601,
        "end_line": 605,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.series.Series.__array__#756",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__array__(self, dtype=None)",
        "snippet": "    def __array__(self, dtype=None) -> np.ndarray:\n        \"\"\"\n        Return the values as a NumPy array.\n\n        Users should not call this directly. Rather, it is invoked by\n        :func:`numpy.array` and :func:`numpy.asarray`.\n\n        Parameters\n        ----------\n        dtype : str or numpy.dtype, optional\n            The dtype to use for the resulting NumPy array. By default,\n            the dtype is inferred from the data.\n\n        Returns\n        -------\n        numpy.ndarray\n            The values in the series converted to a :class:`numpy.ndarray`\n            with the specified `dtype`.\n\n        See Also\n        --------\n        array : Create a new array from data.\n        Series.array : Zero-copy view to the array backing the Series.\n        Series.to_numpy : Series method for similar behavior.\n\n        Examples\n        --------\n        >>> ser = pd.Series([1, 2, 3])\n        >>> np.asarray(ser)\n        array([1, 2, 3])\n\n        For timezone-aware data, the timezones may be retained with\n        ``dtype='object'``\n\n        >>> tzser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n        >>> np.asarray(tzser, dtype=\"object\")\n        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET', freq='D'),\n               Timestamp('2000-01-02 00:00:00+0100', tz='CET', freq='D')],\n              dtype=object)\n\n        Or the values may be localized to UTC and the tzinfo discarded with\n        ``dtype='datetime64[ns]'``\n\n        >>> np.asarray(tzser, dtype=\"datetime64[ns]\")  # doctest: +ELLIPSIS\n        array(['1999-12-31T23:00:00.000000000', ...],\n              dtype='datetime64[ns]')\n        \"\"\"\n        return np.asarray(self.array, dtype)",
        "begin_line": 756,
        "end_line": 803,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.series.Series.align#3952",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)",
        "snippet": "    def align(\n        self,\n        other,\n        join=\"outer\",\n        axis=None,\n        level=None,\n        copy=True,\n        fill_value=None,\n        method=None,\n        limit=None,\n        fill_axis=0,\n        broadcast_axis=None,\n    ):\n        return super().align(\n            other,\n            join=join,\n            axis=axis,\n            level=level,\n            copy=copy,\n            fill_value=fill_value,\n            method=method,\n            limit=limit,\n            fill_axis=fill_axis,\n            broadcast_axis=broadcast_axis,\n        )",
        "begin_line": 3952,
        "end_line": 3976,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._left_indexer_unique#243",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._left_indexer_unique(self, left, right)",
        "snippet": "    def _left_indexer_unique(self, left, right):\n        return libjoin.left_join_indexer_unique(left, right)",
        "begin_line": 243,
        "end_line": 244,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__new__#287",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__new__(cls, data=None, dtype=None, copy=False, name=None, tupleize_cols=True, **kwargs)",
        "snippet": "    def __new__(\n        cls, data=None, dtype=None, copy=False, name=None, tupleize_cols=True, **kwargs,\n    ) -> \"Index\":\n\n        from pandas.core.indexes.range import RangeIndex\n\n        name = maybe_extract_name(name, data, cls)\n\n        if isinstance(data, ABCPandasArray):\n            # ensure users don't accidentally put a PandasArray in an index.\n            data = data.to_numpy()\n\n        # range\n        if isinstance(data, RangeIndex):\n            return RangeIndex(start=data, copy=copy, dtype=dtype, name=name)\n        elif isinstance(data, range):\n            return RangeIndex.from_range(data, dtype=dtype, name=name)\n\n        # categorical\n        elif is_categorical_dtype(data) or is_categorical_dtype(dtype):\n            # Delay import for perf. https://github.com/pandas-dev/pandas/pull/31423\n            from pandas.core.indexes.category import CategoricalIndex\n\n            return _maybe_asobject(dtype, CategoricalIndex, data, copy, name, **kwargs)\n\n        # interval\n        elif is_interval_dtype(data) or is_interval_dtype(dtype):\n            # Delay import for perf. https://github.com/pandas-dev/pandas/pull/31423\n            from pandas.core.indexes.interval import IntervalIndex\n\n            return _maybe_asobject(dtype, IntervalIndex, data, copy, name, **kwargs)\n\n        elif (\n            is_datetime64_any_dtype(data)\n            or is_datetime64_any_dtype(dtype)\n            or \"tz\" in kwargs\n        ):\n            # Delay import for perf. https://github.com/pandas-dev/pandas/pull/31423\n            from pandas import DatetimeIndex\n\n            return _maybe_asobject(dtype, DatetimeIndex, data, copy, name, **kwargs)\n\n        elif is_timedelta64_dtype(data) or is_timedelta64_dtype(dtype):\n            # Delay import for perf. https://github.com/pandas-dev/pandas/pull/31423\n            from pandas import TimedeltaIndex\n\n            return _maybe_asobject(dtype, TimedeltaIndex, data, copy, name, **kwargs)\n\n        elif is_period_dtype(data) or is_period_dtype(dtype):\n            # Delay import for perf. https://github.com/pandas-dev/pandas/pull/31423\n            from pandas import PeriodIndex\n\n            return _maybe_asobject(dtype, PeriodIndex, data, copy, name, **kwargs)\n\n        # extension dtype\n        elif is_extension_array_dtype(data) or is_extension_array_dtype(dtype):\n            if not (dtype is None or is_object_dtype(dtype)):\n                # coerce to the provided dtype\n                ea_cls = dtype.construct_array_type()\n                data = ea_cls._from_sequence(data, dtype=dtype, copy=False)\n            else:\n                data = np.asarray(data, dtype=object)\n\n            # coerce to the object dtype\n            data = data.astype(object)\n            return Index(data, dtype=object, copy=copy, name=name, **kwargs)\n\n        # index-like\n        elif isinstance(data, (np.ndarray, Index, ABCSeries)):\n            # Delay import for perf. https://github.com/pandas-dev/pandas/pull/31423\n            from pandas.core.indexes.numeric import (\n                Float64Index,\n                Int64Index,\n                UInt64Index,\n            )\n\n            if dtype is not None:\n                # we need to avoid having numpy coerce\n                # things that look like ints/floats to ints unless\n                # they are actually ints, e.g. '0' and 0.0\n                # should not be coerced\n                # GH 11836\n                data = _maybe_cast_with_dtype(data, dtype, copy)\n                dtype = data.dtype  # TODO: maybe not for object?\n\n            # maybe coerce to a sub-class\n            if is_signed_integer_dtype(data.dtype):\n                return Int64Index(data, copy=copy, dtype=dtype, name=name)\n            elif is_unsigned_integer_dtype(data.dtype):\n                return UInt64Index(data, copy=copy, dtype=dtype, name=name)\n            elif is_float_dtype(data.dtype):\n                return Float64Index(data, copy=copy, dtype=dtype, name=name)\n            elif issubclass(data.dtype.type, np.bool) or is_bool_dtype(data):\n                subarr = data.astype(\"object\")\n            else:\n                subarr = com.asarray_tuplesafe(data, dtype=object)\n\n            # asarray_tuplesafe does not always copy underlying data,\n            # so need to make sure that this happens\n            if copy:\n                subarr = subarr.copy()\n\n            if dtype is None:\n                new_data, new_dtype = _maybe_cast_data_without_dtype(subarr)\n                if new_dtype is not None:\n                    return cls(\n                        new_data, dtype=new_dtype, copy=False, name=name, **kwargs\n                    )\n\n            if kwargs:\n                raise TypeError(f\"Unexpected keyword arguments {repr(set(kwargs))}\")\n            if subarr.ndim > 1:\n                # GH#13601, GH#20285, GH#27125\n                raise ValueError(\"Index data must be 1-dimensional\")\n            return cls._simple_new(subarr, name)\n\n        elif data is None or is_scalar(data):\n            raise cls._scalar_data_error(data)\n        elif hasattr(data, \"__array__\"):\n            return Index(np.asarray(data), dtype=dtype, copy=copy, name=name, **kwargs)\n        else:\n            if tupleize_cols and is_list_like(data):\n                # GH21470: convert iterable to list before determining if empty\n                if is_iterator(data):\n                    data = list(data)\n\n                if data and all(isinstance(e, tuple) for e in data):\n                    # we must be all tuples, otherwise don't construct\n                    # 10697\n                    from pandas.core.indexes.multi import MultiIndex\n\n                    return MultiIndex.from_tuples(\n                        data, names=name or kwargs.get(\"names\")\n                    )\n            # other iterable of some kind\n            subarr = com.asarray_tuplesafe(data, dtype=object)\n            return Index(subarr, dtype=dtype, copy=copy, name=name, **kwargs)",
        "begin_line": 287,
        "end_line": 423,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._simple_new#457",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._simple_new(cls, values, name: Label=None)",
        "snippet": "    def _simple_new(cls, values, name: Label = None):\n        \"\"\"\n        We require that we have a dtype compat for the values. If we are passed\n        a non-dtype compat, then coerce using the constructor.\n\n        Must be careful not to recurse.\n        \"\"\"\n        assert isinstance(values, np.ndarray), type(values)\n\n        result = object.__new__(cls)\n        result._data = values\n        # _index_data is a (temporary?) fix to ensure that the direct data\n        # manipulation we do in `_libs/reduction.pyx` continues to work.\n        # We need access to the actual ndarray, since we're messing with\n        # data buffers and strides.\n        result._index_data = values\n        result._name = name\n        result._cache = {}\n\n        return result._reset_identity()",
        "begin_line": 457,
        "end_line": 476,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._shallow_copy#491",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._shallow_copy(self, values=None, name: Label=no_default)",
        "snippet": "    def _shallow_copy(self, values=None, name: Label = no_default):\n        \"\"\"\n        Create a new Index with the same class as the caller, don't copy the\n        data, use the same object attributes with passed in attributes taking\n        precedence.\n\n        *this is an internal non-public method*\n\n        Parameters\n        ----------\n        values : the values to create the new Index, optional\n        name : Label, defaults to self.name\n        \"\"\"\n        name = self.name if name is no_default else name\n        cache = self._cache.copy() if values is None else {}\n        if values is None:\n            values = self.values\n\n        result = self._simple_new(values, name=name)\n        result._cache = cache\n        return result",
        "begin_line": 491,
        "end_line": 511,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_#542",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_(self, other)",
        "snippet": "    def is_(self, other) -> bool:\n        \"\"\"\n        More flexible, faster check like ``is`` but that works through views.\n\n        Note: this is *not* the same as ``Index.identical()``, which checks\n        that metadata is also the same.\n\n        Parameters\n        ----------\n        other : object\n            other object to compare against.\n\n        Returns\n        -------\n        True if both have same underlying data, False otherwise : bool\n        \"\"\"\n        # use something other than None to be clearer\n        return self._id is getattr(other, \"_id\", Ellipsis) and self._id is not None",
        "begin_line": 542,
        "end_line": 559,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._reset_identity#561",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._reset_identity(self)",
        "snippet": "    def _reset_identity(self):\n        \"\"\"\n        Initializes or resets ``_id`` attribute with new object.\n        \"\"\"\n        self._id = _Identity()\n        return self",
        "begin_line": 561,
        "end_line": 566,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._engine#572",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._engine(self)",
        "snippet": "    def _engine(self):\n        # property, for now, slow to look up\n\n        # to avoid a reference cycle, bind `target_values` to a local variable, so\n        # `self` is not passed into the lambda.\n        target_values = self._get_engine_target()\n        return self._engine_type(lambda: target_values, len(self))",
        "begin_line": 572,
        "end_line": 578,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__len__#584",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__len__(self)",
        "snippet": "    def __len__(self) -> int:\n        \"\"\"\n        Return the length of the Index.\n        \"\"\"\n        return len(self._data)",
        "begin_line": 584,
        "end_line": 588,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__array__#590",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__array__(self, dtype=None)",
        "snippet": "    def __array__(self, dtype=None) -> np.ndarray:\n        \"\"\"\n        The array interface, return my values.\n        \"\"\"\n        return np.asarray(self._data, dtype=dtype)",
        "begin_line": 590,
        "end_line": 594,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005617977528089888,
            "pseudo_dstar_susp": 0.0005617977528089888,
            "pseudo_tarantula_susp": 0.0005617977528089888,
            "pseudo_op2_susp": 0.0005605381165919282,
            "pseudo_barinel_susp": 0.0005617977528089888
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.dtype#608",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.dtype(self)",
        "snippet": "    def dtype(self):\n        \"\"\"\n        Return the dtype object of the underlying data.\n        \"\"\"\n        return self._data.dtype",
        "begin_line": 608,
        "end_line": 612,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.view#630",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.view(self, cls=None)",
        "snippet": "    def view(self, cls=None):\n\n        # we need to see if we are subclassing an\n        # index type here\n        if cls is not None and not hasattr(cls, \"_typ\"):\n            result = self._data.view(cls)\n        else:\n            result = self._shallow_copy()\n        if isinstance(result, Index):\n            result._id = self._id\n        return result",
        "begin_line": 630,
        "end_line": 640,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.astype#642",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.astype(self, dtype, copy=True)",
        "snippet": "    def astype(self, dtype, copy=True):\n        \"\"\"\n        Create an Index with values cast to dtypes. The class of a new Index\n        is determined by dtype. When conversion is impossible, a ValueError\n        exception is raised.\n\n        Parameters\n        ----------\n        dtype : numpy dtype or pandas type\n            Note that any signed integer `dtype` is treated as ``'int64'``,\n            and any unsigned integer `dtype` is treated as ``'uint64'``,\n            regardless of the size.\n        copy : bool, default True\n            By default, astype always returns a newly allocated object.\n            If copy is set to False and internal requirements on dtype are\n            satisfied, the original data is used to create a new Index\n            or the original Index is returned.\n\n        Returns\n        -------\n        Index\n            Index with values cast to specified dtype.\n        \"\"\"\n        if is_dtype_equal(self.dtype, dtype):\n            return self.copy() if copy else self\n\n        elif is_categorical_dtype(dtype):\n            from pandas.core.indexes.category import CategoricalIndex\n\n            return CategoricalIndex(self.values, name=self.name, dtype=dtype, copy=copy)\n\n        elif is_extension_array_dtype(dtype):\n            return Index(np.asarray(self), name=self.name, dtype=dtype, copy=copy)\n\n        try:\n            casted = self.values.astype(dtype, copy=copy)\n        except (TypeError, ValueError) as err:\n            raise TypeError(\n                f\"Cannot cast {type(self).__name__} to dtype {dtype}\"\n            ) from err\n        return Index(casted, name=self.name, dtype=dtype)",
        "begin_line": 642,
        "end_line": 682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.copy#804",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.copy(self, name=None, deep=False, dtype=None, names=None)",
        "snippet": "    def copy(self, name=None, deep=False, dtype=None, names=None):\n        \"\"\"\n        Make a copy of this object.\n\n        Name and dtype sets those attributes on the new object.\n\n        Parameters\n        ----------\n        name : Label, optional\n            Set name for new object.\n        deep : bool, default False\n        dtype : numpy dtype or pandas type, optional\n            Set dtype for new object.\n        names : list-like, optional\n            Kept for compatibility with MultiIndex. Should not be used.\n\n        Returns\n        -------\n        Index\n            Index refer to new object which is a copy of this object.\n\n        Notes\n        -----\n        In most cases, there should be no functional difference from using\n        ``deep``, but if ``deep`` is passed it will attempt to deepcopy.\n        \"\"\"\n        if deep:\n            new_index = self._shallow_copy(self._data.copy())\n        else:\n            new_index = self._shallow_copy()\n\n        names = self._validate_names(name=name, names=names, deep=deep)\n        new_index = new_index.set_names(names)\n\n        if dtype:\n            new_index = new_index.astype(dtype)\n        return new_index",
        "begin_line": 804,
        "end_line": 840,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__repr__#857",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__repr__(self)",
        "snippet": "    def __repr__(self) -> str_t:\n        \"\"\"\n        Return a string representation for this object.\n        \"\"\"\n        klass_name = type(self).__name__\n        data = self._format_data()\n        attrs = self._format_attrs()\n        space = self._format_space()\n        attrs_str = [f\"{k}={v}\" for k, v in attrs]\n        prepr = f\",{space}\".join(attrs_str)\n\n        # no data provided, just attributes\n        if data is None:\n            data = \"\"\n\n        res = f\"{klass_name}({data}{prepr})\"\n\n        return res",
        "begin_line": 857,
        "end_line": 874,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._format_space#876",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._format_space(self)",
        "snippet": "    def _format_space(self) -> str_t:\n\n        # using space here controls if the attributes\n        # are line separated or not (the default)\n\n        # max_seq_items = get_option('display.max_seq_items')\n        # if len(self) > max_seq_items:\n        #    space = \"\\n%s\" % (' ' * (len(klass) + 1))\n        return \" \"",
        "begin_line": 876,
        "end_line": 884,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._formatter_func#887",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._formatter_func(self)",
        "snippet": "    def _formatter_func(self):\n        \"\"\"\n        Return the formatter function.\n        \"\"\"\n        return default_pprint",
        "begin_line": 887,
        "end_line": 891,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._format_data#893",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._format_data(self, name=None)",
        "snippet": "    def _format_data(self, name=None) -> str_t:\n        \"\"\"\n        Return the formatted data as a unicode string.\n        \"\"\"\n        # do we want to justify (only do so for non-objects)\n        is_justify = True\n\n        if self.inferred_type == \"string\":\n            is_justify = False\n        elif self.inferred_type == \"categorical\":\n            if is_object_dtype(self.categories):  # type: ignore\n                is_justify = False\n\n        return format_object_summary(\n            self, self._formatter_func, is_justify=is_justify, name=name\n        )",
        "begin_line": 893,
        "end_line": 908,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._format_attrs#910",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._format_attrs(self)",
        "snippet": "    def _format_attrs(self):\n        \"\"\"\n        Return a list of tuples of the (attr,formatted_value).\n        \"\"\"\n        return format_object_attrs(self)",
        "begin_line": 910,
        "end_line": 914,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.name#1149",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.name(self)",
        "snippet": "    def name(self):\n        \"\"\"\n        Return Index or MultiIndex name.\n        \"\"\"\n        return self._name",
        "begin_line": 1149,
        "end_line": 1153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.name#1156",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.name(self, value)",
        "snippet": "    def name(self, value):\n        if self._no_setting_name:\n            # Used in MultiIndex.levels to avoid silently ignoring name updates.\n            raise RuntimeError(\n                \"Cannot set name on a level of a MultiIndex. Use \"\n                \"'MultiIndex.set_names' instead.\"\n            )\n        maybe_extract_name(value, None, type(self))\n        self._name = value",
        "begin_line": 1156,
        "end_line": 1164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._validate_names#1166",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._validate_names(self, name=None, names=None, deep: bool=False)",
        "snippet": "    def _validate_names(self, name=None, names=None, deep: bool = False):\n        \"\"\"\n        Handles the quirks of having a singular 'name' parameter for general\n        Index and plural 'names' parameter for MultiIndex.\n        \"\"\"\n        from copy import deepcopy\n\n        if names is not None and name is not None:\n            raise TypeError(\"Can only provide one of `names` and `name`\")\n        elif names is None and name is None:\n            return deepcopy(self.names) if deep else self.names\n        elif names is not None:\n            if not is_list_like(names):\n                raise TypeError(\"Must pass list-like as `names`.\")\n            return names\n        else:\n            if not is_list_like(name):\n                return [name]\n            return name",
        "begin_line": 1166,
        "end_line": 1184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._get_names#1186",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._get_names(self)",
        "snippet": "    def _get_names(self):\n        return FrozenList((self.name,))",
        "begin_line": 1186,
        "end_line": 1187,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._set_names#1189",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._set_names(self, values, level=None)",
        "snippet": "    def _set_names(self, values, level=None):\n        \"\"\"\n        Set new names on index. Each name has to be a hashable type.\n\n        Parameters\n        ----------\n        values : str or sequence\n            name(s) to set\n        level : int, level name, or sequence of int/level names (default None)\n            If the index is a MultiIndex (hierarchical), level(s) to set (None\n            for all levels).  Otherwise level must be None\n\n        Raises\n        ------\n        TypeError if each name is not hashable.\n        \"\"\"\n        if not is_list_like(values):\n            raise ValueError(\"Names must be a list-like\")\n        if len(values) != 1:\n            raise ValueError(f\"Length of new names must be 1, got {len(values)}\")\n\n        # GH 20527\n        # All items in 'name' need to be hashable:\n        for name in values:\n            if not is_hashable(name):\n                raise TypeError(f\"{type(self).__name__}.name must be a hashable type\")\n        self._name = values[0]",
        "begin_line": 1189,
        "end_line": 1215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.set_names#1219",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.set_names(self, names, level=None, inplace: bool=False)",
        "snippet": "    def set_names(self, names, level=None, inplace: bool = False):\n        \"\"\"\n        Set Index or MultiIndex name.\n\n        Able to set new names partially and by level.\n\n        Parameters\n        ----------\n        names : label or list of label\n            Name(s) to set.\n        level : int, label or list of int or label, optional\n            If the index is a MultiIndex, level(s) to set (None for all\n            levels). Otherwise level must be None.\n        inplace : bool, default False\n            Modifies the object directly, instead of creating a new Index or\n            MultiIndex.\n\n        Returns\n        -------\n        Index\n            The same type as the caller or None if inplace is True.\n\n        See Also\n        --------\n        Index.rename : Able to set new names without level.\n\n        Examples\n        --------\n        >>> idx = pd.Index([1, 2, 3, 4])\n        >>> idx\n        Int64Index([1, 2, 3, 4], dtype='int64')\n        >>> idx.set_names('quarter')\n        Int64Index([1, 2, 3, 4], dtype='int64', name='quarter')\n\n        >>> idx = pd.MultiIndex.from_product([['python', 'cobra'],\n        ...                                   [2018, 2019]])\n        >>> idx\n        MultiIndex([('python', 2018),\n                    ('python', 2019),\n                    ( 'cobra', 2018),\n                    ( 'cobra', 2019)],\n                   )\n        >>> idx.set_names(['kind', 'year'], inplace=True)\n        >>> idx\n        MultiIndex([('python', 2018),\n                    ('python', 2019),\n                    ( 'cobra', 2018),\n                    ( 'cobra', 2019)],\n                   names=['kind', 'year'])\n        >>> idx.set_names('species', level=0)\n        MultiIndex([('python', 2018),\n                    ('python', 2019),\n                    ( 'cobra', 2018),\n                    ( 'cobra', 2019)],\n                   names=['species', 'year'])\n        \"\"\"\n        if level is not None and not isinstance(self, ABCMultiIndex):\n            raise ValueError(\"Level must be None for non-MultiIndex\")\n\n        if level is not None and not is_list_like(level) and is_list_like(names):\n            raise TypeError(\"Names must be a string when a single level is provided.\")\n\n        if not is_list_like(names) and level is None and self.nlevels > 1:\n            raise TypeError(\"Must pass list-like as `names`.\")\n\n        if not is_list_like(names):\n            names = [names]\n        if level is not None and not is_list_like(level):\n            level = [level]\n\n        if inplace:\n            idx = self\n        else:\n            idx = self._shallow_copy()\n        idx._set_names(names, level=level)\n        if not inplace:\n            return idx",
        "begin_line": 1219,
        "end_line": 1295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.nlevels#1352",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.nlevels(self)",
        "snippet": "    def nlevels(self) -> int:\n        \"\"\"\n        Number of levels.\n        \"\"\"\n        return 1",
        "begin_line": 1352,
        "end_line": 1356,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_monotonic#1545",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_monotonic(self)",
        "snippet": "    def is_monotonic(self) -> bool:\n        \"\"\"\n        Alias for is_monotonic_increasing.\n        \"\"\"\n        return self.is_monotonic_increasing",
        "begin_line": 1545,
        "end_line": 1549,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_monotonic_increasing#1552",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_monotonic_increasing(self)",
        "snippet": "    def is_monotonic_increasing(self) -> bool:\n        \"\"\"\n        Return if the index is monotonic increasing (only equal or\n        increasing) values.\n\n        Examples\n        --------\n        >>> Index([1, 2, 3]).is_monotonic_increasing\n        True\n        >>> Index([1, 2, 2]).is_monotonic_increasing\n        True\n        >>> Index([1, 3, 2]).is_monotonic_increasing\n        False\n        \"\"\"\n        return self._engine.is_monotonic_increasing",
        "begin_line": 1552,
        "end_line": 1566,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_unique#1620",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_unique(self)",
        "snippet": "    def is_unique(self) -> bool:\n        \"\"\"\n        Return if the index has unique values.\n        \"\"\"\n        return self._engine.is_unique",
        "begin_line": 1620,
        "end_line": 1624,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_boolean#1658",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_boolean(self)",
        "snippet": "    def is_boolean(self) -> bool:\n        \"\"\"\n        Check if the Index only consists of booleans.\n\n        Returns\n        -------\n        bool\n            Whether or not the Index only consists of booleans.\n\n        See Also\n        --------\n        is_integer : Check if the Index only consists of integers.\n        is_floating : Check if the Index is a floating type.\n        is_numeric : Check if the Index only consists of numeric data.\n        is_object : Check if the Index is of the object dtype.\n        is_categorical : Check if the Index holds categorical data.\n        is_interval : Check if the Index holds Interval objects.\n        is_mixed : Check if the Index holds data with mixed data types.\n\n        Examples\n        --------\n        >>> idx = pd.Index([True, False, True])\n        >>> idx.is_boolean()\n        True\n\n        >>> idx = pd.Index([\"True\", \"False\", \"True\"])\n        >>> idx.is_boolean()\n        False\n\n        >>> idx = pd.Index([True, False, \"True\"])\n        >>> idx.is_boolean()\n        False\n        \"\"\"\n        return self.inferred_type in [\"boolean\"]",
        "begin_line": 1658,
        "end_line": 1691,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_floating#1728",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_floating(self)",
        "snippet": "    def is_floating(self) -> bool:\n        \"\"\"\n        Check if the Index is a floating type.\n\n        The Index may consist of only floats, NaNs, or a mix of floats,\n        integers, or NaNs.\n\n        Returns\n        -------\n        bool\n            Whether or not the Index only consists of only consists of floats, NaNs, or\n            a mix of floats, integers, or NaNs.\n\n        See Also\n        --------\n        is_boolean : Check if the Index only consists of booleans.\n        is_integer : Check if the Index only consists of integers.\n        is_numeric : Check if the Index only consists of numeric data.\n        is_object : Check if the Index is of the object dtype.\n        is_categorical : Check if the Index holds categorical data.\n        is_interval : Check if the Index holds Interval objects.\n        is_mixed : Check if the Index holds data with mixed data types.\n\n        Examples\n        --------\n        >>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])\n        >>> idx.is_floating()\n        True\n\n        >>> idx = pd.Index([1.0, 2.0, np.nan, 4.0])\n        >>> idx.is_floating()\n        True\n\n        >>> idx = pd.Index([1, 2, 3, 4, np.nan])\n        >>> idx.is_floating()\n        True\n\n        >>> idx = pd.Index([1, 2, 3, 4])\n        >>> idx.is_floating()\n        False\n        \"\"\"\n        return self.inferred_type in [\"floating\", \"mixed-integer-float\", \"integer-na\"]",
        "begin_line": 1728,
        "end_line": 1769,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.inferred_type#1974",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.inferred_type(self)",
        "snippet": "    def inferred_type(self) -> str_t:\n        \"\"\"\n        Return a string of the type inferred from the values.\n        \"\"\"\n        return lib.infer_dtype(self, skipna=False)",
        "begin_line": 1974,
        "end_line": 1978,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_all_dates#1981",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_all_dates(self)",
        "snippet": "    def is_all_dates(self) -> bool:\n        \"\"\"\n        Whether or not the index values only consist of dates.\n        \"\"\"\n        return is_datetime_array(ensure_object(self.values))",
        "begin_line": 1981,
        "end_line": 1985,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.get_loc#2828",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.get_loc(self, key, method=None, tolerance=None)",
        "snippet": "    def get_loc(self, key, method=None, tolerance=None):\n        \"\"\"\n        Get integer location, slice or boolean mask for requested label.\n\n        Parameters\n        ----------\n        key : label\n        method : {None, 'pad'/'ffill', 'backfill'/'bfill', 'nearest'}, optional\n            * default: exact matches only.\n            * pad / ffill: find the PREVIOUS index value if no exact match.\n            * backfill / bfill: use NEXT index value if no exact match\n            * nearest: use the NEAREST index value if no exact match. Tied\n              distances are broken by preferring the larger index value.\n        tolerance : int or float, optional\n            Maximum distance from index value for inexact matches. The value of\n            the index at the matching location most satisfy the equation\n            ``abs(index[loc] - key) <= tolerance``.\n\n        Returns\n        -------\n        loc : int if unique index, slice if monotonic index, else mask\n\n        Examples\n        --------\n        >>> unique_index = pd.Index(list('abc'))\n        >>> unique_index.get_loc('b')\n        1\n\n        >>> monotonic_index = pd.Index(list('abbc'))\n        >>> monotonic_index.get_loc('b')\n        slice(1, 3, None)\n\n        >>> non_monotonic_index = pd.Index(list('abcb'))\n        >>> non_monotonic_index.get_loc('b')\n        array([False,  True, False,  True])\n        \"\"\"\n        if method is None:\n            if tolerance is not None:\n                raise ValueError(\n                    \"tolerance argument only valid if using pad, \"\n                    \"backfill or nearest lookups\"\n                )\n            casted_key = self._maybe_cast_indexer(key)\n            try:\n                return self._engine.get_loc(casted_key)\n            except KeyError as err:\n                raise KeyError(key) from err\n\n        if tolerance is not None:\n            tolerance = self._convert_tolerance(tolerance, np.asarray(key))\n\n        indexer = self.get_indexer([key], method=method, tolerance=tolerance)\n        if indexer.ndim > 1 or indexer.size > 1:\n            raise TypeError(\"get_loc requires scalar valued input\")\n        loc = indexer.item()\n        if loc == -1:\n            raise KeyError(key)\n        return loc",
        "begin_line": 2828,
        "end_line": 2885,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.get_indexer#2935",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.get_indexer(self, target, method=None, limit=None, tolerance=None)",
        "snippet": "    def get_indexer(\n        self, target, method=None, limit=None, tolerance=None\n    ) -> np.ndarray:\n        method = missing.clean_reindex_fill_method(method)\n        target = ensure_index(target)\n        if tolerance is not None:\n            tolerance = self._convert_tolerance(tolerance, target)\n\n        # Treat boolean labels passed to a numeric index as not found. Without\n        # this fix False and True would be treated as 0 and 1 respectively.\n        # (GH #16877)\n        if target.is_boolean() and self.is_numeric():\n            return ensure_platform_int(np.repeat(-1, target.size))\n\n        pself, ptarget = self._maybe_promote(target)\n        if pself is not self or ptarget is not target:\n            return pself.get_indexer(\n                ptarget, method=method, limit=limit, tolerance=tolerance\n            )\n\n        if not is_dtype_equal(self.dtype, target.dtype):\n            this = self.astype(object)\n            target = target.astype(object)\n            return this.get_indexer(\n                target, method=method, limit=limit, tolerance=tolerance\n            )\n\n        if not self.is_unique:\n            raise InvalidIndexError(\n                \"Reindexing only valid with uniquely valued Index objects\"\n            )\n\n        if method == \"pad\" or method == \"backfill\":\n            indexer = self._get_fill_indexer(target, method, limit, tolerance)\n        elif method == \"nearest\":\n            indexer = self._get_nearest_indexer(target, limit, tolerance)\n        else:\n            if tolerance is not None:\n                raise ValueError(\n                    \"tolerance argument only valid if doing pad, \"\n                    \"backfill or nearest reindexing\"\n                )\n            if limit is not None:\n                raise ValueError(\n                    \"limit argument only valid if doing pad, \"\n                    \"backfill or nearest reindexing\"\n                )\n\n            indexer = self._engine.get_indexer(target._get_engine_target())\n\n        return ensure_platform_int(indexer)",
        "begin_line": 2935,
        "end_line": 2985,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.join#3390",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.join(self, other, how='left', level=None, return_indexers=False, sort=False)",
        "snippet": "    def join(self, other, how=\"left\", level=None, return_indexers=False, sort=False):\n        \"\"\"\n        Compute join_index and indexers to conform data\n        structures to the new index.\n\n        Parameters\n        ----------\n        other : Index\n        how : {'left', 'right', 'inner', 'outer'}\n        level : int or level name, default None\n        return_indexers : bool, default False\n        sort : bool, default False\n            Sort the join keys lexicographically in the result Index. If False,\n            the order of the join keys depends on the join type (how keyword).\n\n        Returns\n        -------\n        join_index, (left_indexer, right_indexer)\n        \"\"\"\n        other = ensure_index(other)\n        self_is_mi = isinstance(self, ABCMultiIndex)\n        other_is_mi = isinstance(other, ABCMultiIndex)\n\n        # try to figure out the join level\n        # GH3662\n        if level is None and (self_is_mi or other_is_mi):\n\n            # have the same levels/names so a simple join\n            if self.names == other.names:\n                pass\n            else:\n                return self._join_multi(other, how=how, return_indexers=return_indexers)\n\n        # join on the level\n        if level is not None and (self_is_mi or other_is_mi):\n            return self._join_level(\n                other, level, how=how, return_indexers=return_indexers\n            )\n\n        if len(other) == 0 and how in (\"left\", \"outer\"):\n            join_index = self._shallow_copy()\n            if return_indexers:\n                rindexer = np.repeat(-1, len(join_index))\n                return join_index, None, rindexer\n            else:\n                return join_index\n\n        if len(self) == 0 and how in (\"right\", \"outer\"):\n            join_index = other._shallow_copy()\n            if return_indexers:\n                lindexer = np.repeat(-1, len(join_index))\n                return join_index, lindexer, None\n            else:\n                return join_index\n\n        if self._join_precedence < other._join_precedence:\n            how = {\"right\": \"left\", \"left\": \"right\"}.get(how, how)\n            result = other.join(\n                self, how=how, level=level, return_indexers=return_indexers\n            )\n            if return_indexers:\n                x, y, z = result\n                result = x, z, y\n            return result\n\n        if not is_dtype_equal(self.dtype, other.dtype):\n            this = self.astype(\"O\")\n            other = other.astype(\"O\")\n            return this.join(other, how=how, return_indexers=return_indexers)\n\n        _validate_join_method(how)\n\n        if not self.is_unique and not other.is_unique:\n            return self._join_non_unique(\n                other, how=how, return_indexers=return_indexers\n            )\n        elif not self.is_unique or not other.is_unique:\n            if self.is_monotonic and other.is_monotonic:\n                return self._join_monotonic(\n                    other, how=how, return_indexers=return_indexers\n                )\n            else:\n                return self._join_non_unique(\n                    other, how=how, return_indexers=return_indexers\n                )\n        elif self.is_monotonic and other.is_monotonic:\n            try:\n                return self._join_monotonic(\n                    other, how=how, return_indexers=return_indexers\n                )\n            except TypeError:\n                pass\n\n        if how == \"left\":\n            join_index = self\n        elif how == \"right\":\n            join_index = other\n        elif how == \"inner\":\n            # TODO: sort=False here for backwards compat. It may\n            # be better to use the sort parameter passed into join\n            join_index = self.intersection(other, sort=False)\n        elif how == \"outer\":\n            # TODO: sort=True here for backwards compat. It may\n            # be better to use the sort parameter passed into join\n            join_index = self.union(other)\n\n        if sort:\n            join_index = join_index.sort_values()\n\n        if return_indexers:\n            if join_index is self:\n                lindexer = None\n            else:\n                lindexer = self.get_indexer(join_index)\n            if join_index is other:\n                rindexer = None\n            else:\n                rindexer = other.get_indexer(join_index)\n            return join_index, lindexer, rindexer\n        else:\n            return join_index",
        "begin_line": 3390,
        "end_line": 3510,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._join_monotonic#3759",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._join_monotonic(self, other, how='left', return_indexers=False)",
        "snippet": "    def _join_monotonic(self, other, how=\"left\", return_indexers=False):\n        # We only get here with matching dtypes\n        assert other.dtype == self.dtype\n\n        if self.equals(other):\n            ret_index = other if how == \"right\" else self\n            if return_indexers:\n                return ret_index, None, None\n            else:\n                return ret_index\n\n        if is_extension_array_dtype(self.dtype):\n            sv = self._data._values_for_argsort()\n            ov = other._data._values_for_argsort()\n        else:\n            sv = self._values\n            ov = other._values\n\n        if self.is_unique and other.is_unique:\n            # We can perform much better than the general case\n            if how == \"left\":\n                join_index = self\n                lidx = None\n                ridx = self._left_indexer_unique(sv, ov)\n            elif how == \"right\":\n                join_index = other\n                lidx = self._left_indexer_unique(ov, sv)\n                ridx = None\n            elif how == \"inner\":\n                join_index, lidx, ridx = self._inner_indexer(sv, ov)\n                join_index = self._wrap_joined_index(join_index, other)\n            elif how == \"outer\":\n                join_index, lidx, ridx = self._outer_indexer(sv, ov)\n                join_index = self._wrap_joined_index(join_index, other)\n        else:\n            if how == \"left\":\n                join_index, lidx, ridx = self._left_indexer(sv, ov)\n            elif how == \"right\":\n                join_index, ridx, lidx = self._left_indexer(ov, sv)\n            elif how == \"inner\":\n                join_index, lidx, ridx = self._inner_indexer(sv, ov)\n            elif how == \"outer\":\n                join_index, lidx, ridx = self._outer_indexer(sv, ov)\n            join_index = self._wrap_joined_index(join_index, other)\n\n        if return_indexers:\n            lidx = None if lidx is None else ensure_platform_int(lidx)\n            ridx = None if ridx is None else ensure_platform_int(ridx)\n            return join_index, lidx, ridx\n        else:\n            return join_index",
        "begin_line": 3759,
        "end_line": 3809,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.values#3819",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.values(self)",
        "snippet": "    def values(self) -> np.ndarray:\n        \"\"\"\n        Return an array representing the data in the Index.\n\n        .. warning::\n\n           We recommend using :attr:`Index.array` or\n           :meth:`Index.to_numpy`, depending on whether you need\n           a reference to the underlying data or a NumPy array.\n\n        Returns\n        -------\n        array: numpy.ndarray or ExtensionArray\n\n        See Also\n        --------\n        Index.array : Reference to the underlying data.\n        Index.to_numpy : A NumPy array representing the underlying data.\n        \"\"\"\n        return self._data.view(np.ndarray)",
        "begin_line": 3819,
        "end_line": 3838,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._values#3851",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._values(self)",
        "snippet": "    def _values(self) -> Union[ExtensionArray, np.ndarray]:\n        \"\"\"\n        The best array representation.\n\n        This is an ndarray or ExtensionArray.\n\n        ``_values`` are consistent between``Series`` and ``Index``.\n\n        It may differ from the public '.values' method.\n\n        index             | values          | _values       |\n        ----------------- | --------------- | ------------- |\n        Index             | ndarray         | ndarray       |\n        CategoricalIndex  | Categorical     | Categorical   |\n        DatetimeIndex     | ndarray[M8ns]   | DatetimeArray |\n        DatetimeIndex[tz] | ndarray[M8ns]   | DatetimeArray |\n        PeriodIndex       | ndarray[object] | PeriodArray   |\n        IntervalIndex     | IntervalArray   | IntervalArray |\n\n        See Also\n        --------\n        values\n        \"\"\"\n        return self._data",
        "begin_line": 3851,
        "end_line": 3874,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._get_engine_target#3876",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._get_engine_target(self)",
        "snippet": "    def _get_engine_target(self) -> np.ndarray:\n        \"\"\"\n        Get the ndarray that we can pass to the IndexEngine constructor.\n        \"\"\"\n        return self._values",
        "begin_line": 3876,
        "end_line": 3880,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__getitem__#4063",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        \"\"\"\n        Override numpy.ndarray's __getitem__ method to work as desired.\n\n        This function adds lists and Series as valid boolean indexers\n        (ndarrays only supports ndarray with dtype=bool).\n\n        If resulting ndim != 1, plain ndarray is returned instead of\n        corresponding `Index` subclass.\n\n        \"\"\"\n        # There's no custom logic to be implemented in __getslice__, so it's\n        # not overloaded intentionally.\n        getitem = self._data.__getitem__\n        promote = self._shallow_copy\n\n        if is_scalar(key):\n            key = com.cast_scalar_indexer(key)\n            return getitem(key)\n\n        if isinstance(key, slice):\n            # This case is separated from the conditional above to avoid\n            # pessimization of basic indexing.\n            return promote(getitem(key))\n\n        if com.is_bool_indexer(key):\n            key = np.asarray(key, dtype=bool)\n\n        result = getitem(key)\n        if not is_scalar(result):\n            if np.ndim(result) > 1:\n                deprecate_ndim_indexing(result)\n                return result\n            return promote(result)\n        else:\n            return result",
        "begin_line": 4063,
        "end_line": 4098,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.equals#4199",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.equals(self, other: Any)",
        "snippet": "    def equals(self, other: Any) -> bool:\n        \"\"\"\n        Determine if two Index object are equal.\n\n        The things that are being compared are:\n\n        * The elements inside the Index object.\n        * The order of the elements inside the Index object.\n\n        Parameters\n        ----------\n        other : Any\n            The other object to compare against.\n\n        Returns\n        -------\n        bool\n            True if \"other\" is an Index and it has the same elements and order\n            as the calling index; False otherwise.\n\n        Examples\n        --------\n        >>> idx1 = pd.Index([1, 2, 3])\n        >>> idx1\n        Int64Index([1, 2, 3], dtype='int64')\n        >>> idx1.equals(pd.Index([1, 2, 3]))\n        True\n\n        The elements inside are compared\n\n        >>> idx2 = pd.Index([\"1\", \"2\", \"3\"])\n        >>> idx2\n        Index(['1', '2', '3'], dtype='object')\n\n        >>> idx1.equals(idx2)\n        False\n\n        The order is compared\n\n        >>> ascending_idx = pd.Index([1, 2, 3])\n        >>> ascending_idx\n        Int64Index([1, 2, 3], dtype='int64')\n        >>> descending_idx = pd.Index([3, 2, 1])\n        >>> descending_idx\n        Int64Index([3, 2, 1], dtype='int64')\n        >>> ascending_idx.equals(descending_idx)\n        False\n\n        The dtype is *not* compared\n\n        >>> int64_idx = pd.Int64Index([1, 2, 3])\n        >>> int64_idx\n        Int64Index([1, 2, 3], dtype='int64')\n        >>> uint64_idx = pd.UInt64Index([1, 2, 3])\n        >>> uint64_idx\n        UInt64Index([1, 2, 3], dtype='uint64')\n        >>> int64_idx.equals(uint64_idx)\n        True\n        \"\"\"\n        if self.is_(other):\n            return True\n\n        if not isinstance(other, Index):\n            return False\n\n        if is_object_dtype(self.dtype) and not is_object_dtype(other.dtype):\n            # if other is not object, use other's logic for coercion\n            return other.equals(self)\n\n        if isinstance(other, ABCMultiIndex):\n            # d-level MultiIndex can equal d-tuple Index\n            return other.equals(self)\n\n        if is_extension_array_dtype(other.dtype):\n            # All EA-backed Index subclasses override equals\n            return other.equals(self)\n\n        return array_equivalent(self._values, other._values)",
        "begin_line": 4199,
        "end_line": 4276,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._maybe_promote#4696",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._maybe_promote(self, other)",
        "snippet": "    def _maybe_promote(self, other):\n        # A hack, but it works\n\n        if self.inferred_type == \"date\" and isinstance(other, ABCDatetimeIndex):\n            return type(other)(self), other\n        elif self.inferred_type == \"boolean\":\n            if not is_object_dtype(self.dtype):\n                return self.astype(\"object\"), other.astype(\"object\")\n        return self, other",
        "begin_line": 4696,
        "end_line": 4704,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._maybe_cast_indexer#4934",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._maybe_cast_indexer(self, key)",
        "snippet": "    def _maybe_cast_indexer(self, key):\n        \"\"\"\n        If we have a float key and are not a floating index, then try to cast\n        to an int if equivalent.\n        \"\"\"\n        if not self.is_floating():\n            return com.cast_scalar_indexer(key)\n        return key",
        "begin_line": 4934,
        "end_line": 4941,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.ensure_index#5515",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base.ensure_index(index_like, copy: bool=False)",
        "snippet": "def ensure_index(index_like, copy: bool = False):\n    \"\"\"\n    Ensure that we have an index from some index-like object.\n\n    Parameters\n    ----------\n    index_like : sequence\n        An Index or other sequence\n    copy : bool, default False\n\n    Returns\n    -------\n    index : Index or MultiIndex\n\n    See Also\n    --------\n    ensure_index_from_sequences\n\n    Examples\n    --------\n    >>> ensure_index(['a', 'b'])\n    Index(['a', 'b'], dtype='object')\n\n    >>> ensure_index([('a', 'a'),  ('b', 'c')])\n    Index([('a', 'a'), ('b', 'c')], dtype='object')\n\n    >>> ensure_index([['a', 'a'], ['b', 'c']])\n    MultiIndex([('a', 'b'),\n            ('a', 'c')],\n           )\n    \"\"\"\n    if isinstance(index_like, Index):\n        if copy:\n            index_like = index_like.copy()\n        return index_like\n    if hasattr(index_like, \"name\"):\n        return Index(index_like, name=index_like.name, copy=copy)\n\n    if is_iterator(index_like):\n        index_like = list(index_like)\n\n    # must check for exactly list here because of strict type\n    # check in clean_index_list\n    if isinstance(index_like, list):\n        if type(index_like) != list:\n            index_like = list(index_like)\n\n        converted, all_arrays = lib.clean_index_list(index_like)\n\n        if len(converted) > 0 and all_arrays:\n            from pandas.core.indexes.multi import MultiIndex\n\n            return MultiIndex.from_arrays(converted)\n        else:\n            index_like = converted\n    else:\n        # clean_index_list does the equivalent of copying\n        # so only need to do this if not list instance\n        if copy:\n            index_like = copy_func(index_like)\n\n    return Index(index_like)",
        "begin_line": 5515,
        "end_line": 5576,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.base._validate_join_method#5601",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base._validate_join_method(method: str)",
        "snippet": "def _validate_join_method(method: str):\n    if method not in [\"left\", \"right\", \"inner\", \"outer\"]:\n        raise ValueError(f\"do not recognize join method {method}\")",
        "begin_line": 5601,
        "end_line": 5603,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base.default_index#5606",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base.default_index(n)",
        "snippet": "def default_index(n):\n    from pandas.core.indexes.range import RangeIndex\n\n    return RangeIndex(0, n, name=None)",
        "begin_line": 5606,
        "end_line": 5609,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.base.maybe_extract_name#5612",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base.maybe_extract_name(name, obj, cls)",
        "snippet": "def maybe_extract_name(name, obj, cls) -> Label:\n    \"\"\"\n    If no name is passed, then extract it from data, validating hashability.\n    \"\"\"\n    if name is None and isinstance(obj, (Index, ABCSeries)):\n        # Note we don't just check for \"name\" attribute since that would\n        #  pick up e.g. dtype.name\n        name = obj.name\n\n    # GH#29069\n    if not is_hashable(name):\n        raise TypeError(f\"{cls.__name__}.name must be a hashable type\")\n\n    return name",
        "begin_line": 5612,
        "end_line": 5625,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.indexes.base._maybe_cast_with_dtype#5628",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base._maybe_cast_with_dtype(data: np.ndarray, dtype: np.dtype, copy: bool)",
        "snippet": "def _maybe_cast_with_dtype(data: np.ndarray, dtype: np.dtype, copy: bool) -> np.ndarray:\n    \"\"\"\n    If a dtype is passed, cast to the closest matching dtype that is supported\n    by Index.\n\n    Parameters\n    ----------\n    data : np.ndarray\n    dtype : np.dtype\n    copy : bool\n\n    Returns\n    -------\n    np.ndarray\n    \"\"\"\n    # we need to avoid having numpy coerce\n    # things that look like ints/floats to ints unless\n    # they are actually ints, e.g. '0' and 0.0\n    # should not be coerced\n    # GH 11836\n    if is_integer_dtype(dtype):\n        inferred = lib.infer_dtype(data, skipna=False)\n        if inferred == \"integer\":\n            data = maybe_cast_to_integer_array(data, dtype, copy=copy)\n        elif inferred in [\"floating\", \"mixed-integer-float\"]:\n            if isna(data).any():\n                raise ValueError(\"cannot convert float NaN to integer\")\n\n            if inferred == \"mixed-integer-float\":\n                data = maybe_cast_to_integer_array(data, dtype)\n\n            # If we are actually all equal to integers,\n            # then coerce to integer.\n            try:\n                data = _try_convert_to_int_array(data, copy, dtype)\n            except ValueError:\n                data = np.array(data, dtype=np.float64, copy=copy)\n\n        elif inferred == \"string\":\n            pass\n        else:\n            data = data.astype(dtype)\n    elif is_float_dtype(dtype):\n        inferred = lib.infer_dtype(data, skipna=False)\n        if inferred == \"string\":\n            pass\n        else:\n            data = data.astype(dtype)\n    else:\n        data = np.array(data, dtype=dtype, copy=copy)\n\n    return data",
        "begin_line": 5628,
        "end_line": 5679,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base._maybe_cast_data_without_dtype#5682",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base._maybe_cast_data_without_dtype(subarr)",
        "snippet": "def _maybe_cast_data_without_dtype(subarr):\n    \"\"\"\n    If we have an arraylike input but no passed dtype, try to infer\n    a supported dtype.\n\n    Parameters\n    ----------\n    subarr : np.ndarray, Index, or Series\n\n    Returns\n    -------\n    converted : np.ndarray or ExtensionArray\n    dtype : np.dtype or ExtensionDtype\n    \"\"\"\n    # Runtime import needed bc IntervalArray imports Index\n    from pandas.core.arrays import (\n        IntervalArray,\n        PeriodArray,\n        DatetimeArray,\n        TimedeltaArray,\n    )\n\n    inferred = lib.infer_dtype(subarr, skipna=False)\n\n    if inferred == \"integer\":\n        try:\n            data = _try_convert_to_int_array(subarr, False, None)\n            return data, data.dtype\n        except ValueError:\n            pass\n\n        return subarr, object\n\n    elif inferred in [\"floating\", \"mixed-integer-float\", \"integer-na\"]:\n        # TODO: Returns IntegerArray for integer-na case in the future\n        return subarr, np.float64\n\n    elif inferred == \"interval\":\n        try:\n            data = IntervalArray._from_sequence(subarr, copy=False)\n            return data, data.dtype\n        except ValueError:\n            # GH27172: mixed closed Intervals --> object dtype\n            pass\n    elif inferred == \"boolean\":\n        # don't support boolean explicitly ATM\n        pass\n    elif inferred != \"string\":\n        if inferred.startswith(\"datetime\"):\n            try:\n                data = DatetimeArray._from_sequence(subarr, copy=False)\n                return data, data.dtype\n            except (ValueError, OutOfBoundsDatetime):\n                # GH 27011\n                # If we have mixed timezones, just send it\n                # down the base constructor\n                pass\n\n        elif inferred.startswith(\"timedelta\"):\n            data = TimedeltaArray._from_sequence(subarr, copy=False)\n            return data, data.dtype\n        elif inferred == \"period\":\n            try:\n                data = PeriodArray._from_sequence(subarr)\n                return data, data.dtype\n            except IncompatibleFrequency:\n                pass\n\n    return subarr, subarr.dtype",
        "begin_line": 5682,
        "end_line": 5750,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.indexes.base._try_convert_to_int_array#5753",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base._try_convert_to_int_array(data: np.ndarray, copy: bool, dtype: np.dtype)",
        "snippet": "def _try_convert_to_int_array(\n    data: np.ndarray, copy: bool, dtype: np.dtype\n) -> np.ndarray:\n    \"\"\"\n    Attempt to convert an array of data into an integer array.\n\n    Parameters\n    ----------\n    data : The data to convert.\n    copy : bool\n        Whether to copy the data or not.\n    dtype : np.dtype\n\n    Returns\n    -------\n    int_array : data converted to either an ndarray[int64] or ndarray[uint64]\n\n    Raises\n    ------\n    ValueError if the conversion was not successful.\n    \"\"\"\n    if not is_unsigned_integer_dtype(dtype):\n        # skip int64 conversion attempt if uint-like dtype is passed, as\n        # this could return Int64Index when UInt64Index is what's desired\n        try:\n            res = data.astype(\"i8\", copy=False)\n            if (res == data).all():\n                return res  # TODO: might still need to copy\n        except (OverflowError, TypeError, ValueError):\n            pass\n\n    # Conversion to int64 failed (possibly due to overflow) or was skipped,\n    # so let's try now with uint64.\n    try:\n        res = data.astype(\"u8\", copy=False)\n        if (res == data).all():\n            return res  # TODO: might still need to copy\n    except (OverflowError, TypeError, ValueError):\n        pass\n\n    raise ValueError",
        "begin_line": 5753,
        "end_line": 5793,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.dtypes.generic.create_pandas_abc_type#6",
        "src_path": "pandas/core/dtypes/generic.py",
        "class_name": "pandas.core.dtypes.generic",
        "signature": "pandas.core.dtypes.generic.create_pandas_abc_type(name, attr, comp)",
        "snippet": "def create_pandas_abc_type(name, attr, comp):\n\n    # https://github.com/python/mypy/issues/1006\n    # error: 'classmethod' used with a non-method\n    @classmethod  # type: ignore\n    def _check(cls, inst) -> bool:\n        return getattr(inst, attr, \"_typ\") in comp\n\n    dct = dict(__instancecheck__=_check, __subclasscheck__=_check)\n    meta = type(\"ABCBase\", (type,), dct)\n    return meta(name, tuple(), dct)",
        "begin_line": 6,
        "end_line": 16,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.dtypes.generic._check#11",
        "src_path": "pandas/core/dtypes/generic.py",
        "class_name": "pandas.core.dtypes.generic",
        "signature": "pandas.core.dtypes.generic._check(cls, inst)",
        "snippet": "    def _check(cls, inst) -> bool:\n        return getattr(inst, attr, \"_typ\") in comp",
        "begin_line": 11,
        "end_line": 12,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.missing.clean_fill_method#73",
        "src_path": "pandas/core/missing.py",
        "class_name": "pandas.core.missing",
        "signature": "pandas.core.missing.clean_fill_method(method, allow_nearest=False)",
        "snippet": "def clean_fill_method(method, allow_nearest=False):\n    # asfreq is compat for resampling\n    if method in [None, \"asfreq\"]:\n        return None\n\n    if isinstance(method, str):\n        method = method.lower()\n        if method == \"ffill\":\n            method = \"pad\"\n        elif method == \"bfill\":\n            method = \"backfill\"\n\n    valid_methods = [\"pad\", \"backfill\"]\n    expecting = \"pad (ffill) or backfill (bfill)\"\n    if allow_nearest:\n        valid_methods.append(\"nearest\")\n        expecting = \"pad (ffill), backfill (bfill) or nearest\"\n    if method not in valid_methods:\n        raise ValueError(f\"Invalid fill method. Expecting {expecting}. Got {method}\")\n    return method",
        "begin_line": 73,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.missing.clean_reindex_fill_method#601",
        "src_path": "pandas/core/missing.py",
        "class_name": "pandas.core.missing",
        "signature": "pandas.core.missing.clean_reindex_fill_method(method)",
        "snippet": "def clean_reindex_fill_method(method):\n    return clean_fill_method(method, allow_nearest=True)",
        "begin_line": 601,
        "end_line": 602,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.util._validators.validate_bool_kwarg#208",
        "src_path": "pandas/util/_validators.py",
        "class_name": "pandas.util._validators",
        "signature": "pandas.util._validators.validate_bool_kwarg(value, arg_name)",
        "snippet": "def validate_bool_kwarg(value, arg_name):\n    \"\"\" Ensures that argument passed in arg_name is of type bool. \"\"\"\n    if not (is_bool(value) or value is None):\n        raise ValueError(\n            f'For argument \"{arg_name}\" expected type bool, received '\n            f\"type {type(value).__name__}.\"\n        )\n    return value",
        "begin_line": 208,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__init__#198",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__init__(self, data: BlockManager, copy: bool=False, attrs: Optional[Mapping[Optional[Hashable], Any]]=None)",
        "snippet": "    def __init__(\n        self,\n        data: BlockManager,\n        copy: bool = False,\n        attrs: Optional[Mapping[Optional[Hashable], Any]] = None,\n    ):\n        # copy kwarg is retained for mypy compat, is not used\n\n        object.__setattr__(self, \"_is_copy\", None)\n        object.__setattr__(self, \"_mgr\", data)\n        object.__setattr__(self, \"_item_cache\", {})\n        if attrs is None:\n            attrs = {}\n        else:\n            attrs = dict(attrs)\n        object.__setattr__(self, \"_attrs\", attrs)",
        "begin_line": 198,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.attrs#236",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.attrs(self)",
        "snippet": "    def attrs(self) -> Dict[Optional[Hashable], Any]:\n        \"\"\"\n        Dictionary of global attributes on this object.\n\n        .. warning::\n\n           attrs is experimental and may change without warning.\n        \"\"\"\n        if self._attrs is None:\n            self._attrs = {}\n        return self._attrs",
        "begin_line": 236,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._validate_dtype#253",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._validate_dtype(cls, dtype)",
        "snippet": "    def _validate_dtype(cls, dtype):\n        \"\"\" validate the passed dtype \"\"\"\n        if dtype is not None:\n            dtype = pandas_dtype(dtype)\n\n            # a compound dtype\n            if dtype.kind == \"V\":\n                raise NotImplementedError(\n                    \"compound dtypes are not implemented \"\n                    f\"in the {cls.__name__} constructor\"\n                )\n\n        return dtype",
        "begin_line": 253,
        "end_line": 265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_axis_number#356",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_axis_number(cls, axis)",
        "snippet": "    def _get_axis_number(cls, axis):\n        axis = cls._AXIS_ALIASES.get(axis, axis)\n        if is_integer(axis):\n            if axis in cls._AXIS_NAMES:\n                return axis\n        else:\n            try:\n                return cls._AXIS_NUMBERS[axis]\n            except KeyError:\n                pass\n        raise ValueError(f\"No axis named {axis} for object type {cls.__name__}\")",
        "begin_line": 356,
        "end_line": 366,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_axis_name#369",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_axis_name(cls, axis)",
        "snippet": "    def _get_axis_name(cls, axis):\n        axis = cls._AXIS_ALIASES.get(axis, axis)\n        if isinstance(axis, str):\n            if axis in cls._AXIS_NUMBERS:\n                return axis\n        else:\n            try:\n                return cls._AXIS_NAMES[axis]\n            except KeyError:\n                pass\n        raise ValueError(f\"No axis named {axis} for object type {cls.__name__}\")",
        "begin_line": 369,
        "end_line": 379,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_axis#381",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_axis(self, axis)",
        "snippet": "    def _get_axis(self, axis):\n        name = self._get_axis_name(axis)\n        return getattr(self, name)",
        "begin_line": 381,
        "end_line": 383,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_block_manager_axis#386",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_block_manager_axis(cls, axis)",
        "snippet": "    def _get_block_manager_axis(cls, axis):\n        \"\"\"Map the axis to the block_manager axis.\"\"\"\n        axis = cls._get_axis_number(axis)\n        if cls._AXIS_REVERSED:\n            m = cls._AXIS_LEN - 1\n            return m - axis\n        return axis",
        "begin_line": 386,
        "end_line": 392,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._info_axis#451",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._info_axis(self)",
        "snippet": "    def _info_axis(self):\n        return getattr(self, self._info_axis_name)",
        "begin_line": 451,
        "end_line": 452,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._set_axis#565",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._set_axis(self, axis: int, labels: Index)",
        "snippet": "    def _set_axis(self, axis: int, labels: Index) -> None:\n        labels = ensure_index(labels)\n        self._mgr.set_axis(axis, labels)\n        self._clear_item_cache()",
        "begin_line": 565,
        "end_line": 568,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__iter__#1690",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__iter__(self)",
        "snippet": "    def __iter__(self):\n        \"\"\"\n        Iterate over info axis.\n\n        Returns\n        -------\n        iterator\n            Info axis as iterator.\n        \"\"\"\n        return iter(self._info_axis)",
        "begin_line": 1690,
        "end_line": 1699,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._set_as_cached#3195",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._set_as_cached(self, item, cacher)",
        "snippet": "    def _set_as_cached(self, item, cacher) -> None:\n        \"\"\"\n        Set the _cacher attribute on the calling object with a weakref to\n        cacher.\n        \"\"\"\n        self._cacher = (item, weakref.ref(cacher))",
        "begin_line": 3195,
        "end_line": 3200,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._clear_item_cache#3265",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._clear_item_cache(self)",
        "snippet": "    def _clear_item_cache(self) -> None:\n        self._item_cache.clear()",
        "begin_line": 3265,
        "end_line": 3266,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_item_cache#3549",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_item_cache(self, item)",
        "snippet": "    def _get_item_cache(self, item):\n        \"\"\"Return the cached item, item represents a label indexer.\"\"\"\n        cache = self._item_cache\n        res = cache.get(item)\n        if res is None:\n            values = self._mgr.get(item)\n            res = self._box_item_values(item, values)\n            cache[item] = res\n            res._set_as_cached(item, self)\n\n            # for a chain\n            res._is_copy = self._is_copy\n        return res",
        "begin_line": 3549,
        "end_line": 3561,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._reindex_with_indexers#4477",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._reindex_with_indexers(self: FrameOrSeries, reindexers, fill_value=None, copy: bool_t=False, allow_dups: bool_t=False)",
        "snippet": "    def _reindex_with_indexers(\n        self: FrameOrSeries,\n        reindexers,\n        fill_value=None,\n        copy: bool_t = False,\n        allow_dups: bool_t = False,\n    ) -> FrameOrSeries:\n        \"\"\"allow_dups indicates an internal call here \"\"\"\n        # reindex doing multiple operations on different axes if indicated\n        new_data = self._mgr\n        for axis in sorted(reindexers.keys()):\n            index, indexer = reindexers[axis]\n            baxis = self._get_block_manager_axis(axis)\n\n            if index is None:\n                continue\n\n            index = ensure_index(index)\n            if indexer is not None:\n                indexer = ensure_int64(indexer)\n\n            # TODO: speed up on homogeneous DataFrame objects\n            new_data = new_data.reindex_indexer(\n                index,\n                indexer,\n                axis=baxis,\n                fill_value=fill_value,\n                allow_dups=allow_dups,\n                copy=copy,\n            )\n            # If we've made a copy once, no need to make another one\n            copy = False\n\n        if copy and new_data is self._mgr:\n            new_data = new_data.copy()\n\n        return self._constructor(new_data).__finalize__(self)",
        "begin_line": 4477,
        "end_line": 4513,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__finalize__#5138",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__finalize__(self: FrameOrSeries, other, method: Optional[str]=None, **kwargs)",
        "snippet": "    def __finalize__(\n        self: FrameOrSeries, other, method: Optional[str] = None, **kwargs\n    ) -> FrameOrSeries:\n        \"\"\"\n        Propagate metadata from other to self.\n\n        Parameters\n        ----------\n        other : the object from which to get the attributes that we are going\n            to propagate\n        method : str, optional\n            A passed method name providing context on where ``__finalize__``\n            was called.\n\n            .. warning:\n\n               The value passed as `method` are not currently considered\n               stable across pandas releases.\n        \"\"\"\n        if isinstance(other, NDFrame):\n            for name in other.attrs:\n                self.attrs[name] = other.attrs[name]\n            # For subclasses using _metadata.\n            for name in self._metadata:\n                assert isinstance(name, str)\n                object.__setattr__(self, name, getattr(other, name, None))\n        return self",
        "begin_line": 5138,
        "end_line": 5164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__getattr__#5166",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__getattr__(self, name: str)",
        "snippet": "    def __getattr__(self, name: str):\n        \"\"\"\n        After regular attribute access, try looking up the name\n        This allows simpler access to columns for interactive use.\n        \"\"\"\n        # Note: obj.x will always call obj.__getattribute__('x') prior to\n        # calling obj.__getattr__('x').\n        if (\n            name in self._internal_names_set\n            or name in self._metadata\n            or name in self._accessors\n        ):\n            return object.__getattribute__(self, name)\n        else:\n            if self._info_axis._can_hold_identifiers_and_holds_name(name):\n                return self[name]\n            return object.__getattribute__(self, name)",
        "begin_line": 5166,
        "end_line": 5182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__setattr__#5184",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__setattr__(self, name: str, value)",
        "snippet": "    def __setattr__(self, name: str, value) -> None:\n        \"\"\"\n        After regular attribute access, try setting the name\n        This allows simpler access to columns for interactive use.\n        \"\"\"\n        # first try regular attribute access via __getattribute__, so that\n        # e.g. ``obj.x`` and ``obj.x = 4`` will always reference/modify\n        # the same attribute.\n\n        try:\n            object.__getattribute__(self, name)\n            return object.__setattr__(self, name, value)\n        except AttributeError:\n            pass\n\n        # if this fails, go on to more involved attribute setting\n        # (note that this matches __getattr__, above).\n        if name in self._internal_names_set:\n            object.__setattr__(self, name, value)\n        elif name in self._metadata:\n            object.__setattr__(self, name, value)\n        else:\n            try:\n                existing = getattr(self, name)\n                if isinstance(existing, Index):\n                    object.__setattr__(self, name, value)\n                elif name in self._info_axis:\n                    self[name] = value\n                else:\n                    object.__setattr__(self, name, value)\n            except (AttributeError, TypeError):\n                if isinstance(self, ABCDataFrame) and (is_list_like(value)):\n                    warnings.warn(\n                        \"Pandas doesn't allow columns to be \"\n                        \"created via a new attribute name - see \"\n                        \"https://pandas.pydata.org/pandas-docs/\"\n                        \"stable/indexing.html#attribute-access\",\n                        stacklevel=2,\n                    )\n                object.__setattr__(self, name, value)",
        "begin_line": 5184,
        "end_line": 5223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._protect_consolidate#5240",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._protect_consolidate(self, f)",
        "snippet": "    def _protect_consolidate(self, f):\n        \"\"\"\n        Consolidate _mgr -- if the blocks have changed, then clear the\n        cache\n        \"\"\"\n        blocks_before = len(self._mgr.blocks)\n        result = f()\n        if len(self._mgr.blocks) != blocks_before:\n            self._clear_item_cache()\n        return result",
        "begin_line": 5240,
        "end_line": 5249,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._consolidate_inplace#5251",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._consolidate_inplace(self)",
        "snippet": "    def _consolidate_inplace(self) -> None:\n        \"\"\"Consolidate data in place and return None\"\"\"\n\n        def f():\n            self._mgr = self._mgr.consolidate()\n\n        self._protect_consolidate(f)",
        "begin_line": 5251,
        "end_line": 5257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.f#5254",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.f()",
        "snippet": "        def f():\n            self._mgr = self._mgr.consolidate()",
        "begin_line": 5254,
        "end_line": 5255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._consolidate#5259",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._consolidate(self, inplace: bool_t=False)",
        "snippet": "    def _consolidate(self, inplace: bool_t = False):\n        \"\"\"\n        Compute NDFrame with \"consolidated\" internals (data of each dtype\n        grouped together in a single ndarray).\n\n        Parameters\n        ----------\n        inplace : bool, default False\n            If False return new object, otherwise modify existing object.\n\n        Returns\n        -------\n        consolidated : same type as caller\n        \"\"\"\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\n        if inplace:\n            self._consolidate_inplace()\n        else:\n            f = lambda: self._mgr.consolidate()\n            cons_data = self._protect_consolidate(f)\n            return self._constructor(cons_data).__finalize__(self)",
        "begin_line": 5259,
        "end_line": 5279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.align#8241",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)",
        "snippet": "    def align(\n        self,\n        other,\n        join=\"outer\",\n        axis=None,\n        level=None,\n        copy=True,\n        fill_value=None,\n        method=None,\n        limit=None,\n        fill_axis=0,\n        broadcast_axis=None,\n    ):\n        \"\"\"\n        Align two objects on their axes with the specified join method.\n\n        Join method is specified for each axis Index.\n\n        Parameters\n        ----------\n        other : DataFrame or Series\n        join : {{'outer', 'inner', 'left', 'right'}}, default 'outer'\n        axis : allowed axis of the other object, default None\n            Align on index (0), columns (1), or both (None).\n        level : int or level name, default None\n            Broadcast across a level, matching Index values on the\n            passed MultiIndex level.\n        copy : bool, default True\n            Always returns new objects. If copy=False and no reindexing is\n            required then original objects are returned.\n        fill_value : scalar, default np.NaN\n            Value to use for missing values. Defaults to NaN, but can be any\n            \"compatible\" value.\n        method : {{'backfill', 'bfill', 'pad', 'ffill', None}}, default None\n            Method to use for filling holes in reindexed Series:\n\n            - pad / ffill: propagate last valid observation forward to next valid.\n            - backfill / bfill: use NEXT valid observation to fill gap.\n\n        limit : int, default None\n            If method is specified, this is the maximum number of consecutive\n            NaN values to forward/backward fill. In other words, if there is\n            a gap with more than this number of consecutive NaNs, it will only\n            be partially filled. If method is not specified, this is the\n            maximum number of entries along the entire axis where NaNs will be\n            filled. Must be greater than 0 if not None.\n        fill_axis : {axes_single_arg}, default 0\n            Filling axis, method and limit.\n        broadcast_axis : {axes_single_arg}, default None\n            Broadcast values along this axis, if aligning two objects of\n            different dimensions.\n\n        Returns\n        -------\n        (left, right) : ({klass}, type of other)\n            Aligned objects.\n        \"\"\"\n\n        method = missing.clean_fill_method(method)\n\n        if broadcast_axis == 1 and self.ndim != other.ndim:\n            if isinstance(self, ABCSeries):\n                # this means other is a DataFrame, and we need to broadcast\n                # self\n                cons = self._constructor_expanddim\n                df = cons(\n                    {c: self for c in other.columns}, **other._construct_axes_dict()\n                )\n                return df._align_frame(\n                    other,\n                    join=join,\n                    axis=axis,\n                    level=level,\n                    copy=copy,\n                    fill_value=fill_value,\n                    method=method,\n                    limit=limit,\n                    fill_axis=fill_axis,\n                )\n            elif isinstance(other, ABCSeries):\n                # this means self is a DataFrame, and we need to broadcast\n                # other\n                cons = other._constructor_expanddim\n                df = cons(\n                    {c: other for c in self.columns}, **self._construct_axes_dict()\n                )\n                return self._align_frame(\n                    df,\n                    join=join,\n                    axis=axis,\n                    level=level,\n                    copy=copy,\n                    fill_value=fill_value,\n                    method=method,\n                    limit=limit,\n                    fill_axis=fill_axis,\n                )\n\n        if axis is not None:\n            axis = self._get_axis_number(axis)\n        if isinstance(other, ABCDataFrame):\n            return self._align_frame(\n                other,\n                join=join,\n                axis=axis,\n                level=level,\n                copy=copy,\n                fill_value=fill_value,\n                method=method,\n                limit=limit,\n                fill_axis=fill_axis,\n            )\n        elif isinstance(other, ABCSeries):\n            return self._align_series(\n                other,\n                join=join,\n                axis=axis,\n                level=level,\n                copy=copy,\n                fill_value=fill_value,\n                method=method,\n                limit=limit,\n                fill_axis=fill_axis,\n            )\n        else:  # pragma: no cover\n            raise TypeError(f\"unsupported type: {type(other)}\")",
        "begin_line": 8241,
        "end_line": 8366,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._align_frame#8368",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._align_frame(self, other, join='outer', axis=None, level=None, copy: bool_t=True, fill_value=None, method=None, limit=None, fill_axis=0)",
        "snippet": "    def _align_frame(\n        self,\n        other,\n        join=\"outer\",\n        axis=None,\n        level=None,\n        copy: bool_t = True,\n        fill_value=None,\n        method=None,\n        limit=None,\n        fill_axis=0,\n    ):\n        # defaults\n        join_index, join_columns = None, None\n        ilidx, iridx = None, None\n        clidx, cridx = None, None\n\n        is_series = isinstance(self, ABCSeries)\n\n        if axis is None or axis == 0:\n            if not self.index.equals(other.index):\n                join_index, ilidx, iridx = self.index.join(\n                    other.index, how=join, level=level, return_indexers=True\n                )\n\n        if axis is None or axis == 1:\n            if not is_series and not self.columns.equals(other.columns):\n                join_columns, clidx, cridx = self.columns.join(\n                    other.columns, how=join, level=level, return_indexers=True\n                )\n\n        if is_series:\n            reindexers = {0: [join_index, ilidx]}\n        else:\n            reindexers = {0: [join_index, ilidx], 1: [join_columns, clidx]}\n\n        left = self._reindex_with_indexers(\n            reindexers, copy=copy, fill_value=fill_value, allow_dups=True\n        )\n        # other must be always DataFrame\n        right = other._reindex_with_indexers(\n            {0: [join_index, iridx], 1: [join_columns, cridx]},\n            copy=copy,\n            fill_value=fill_value,\n            allow_dups=True,\n        )\n\n        if method is not None:\n            _left = left.fillna(method=method, axis=fill_axis, limit=limit)\n            assert _left is not None  # needed for mypy\n            left = _left\n            right = right.fillna(method=method, axis=fill_axis, limit=limit)\n\n        # if DatetimeIndex have different tz, convert to UTC\n        if is_datetime64tz_dtype(left.index):\n            if left.index.tz != right.index.tz:\n                if join_index is not None:\n                    left.index = join_index\n                    right.index = join_index\n\n        return (\n            left.__finalize__(self),\n            right.__finalize__(other),\n        )",
        "begin_line": 8368,
        "end_line": 8431,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.core.arrays.sparse.dtype.SparseDtype.construct_from_string#186",
        "src_path": "pandas/core/arrays/sparse/dtype.py",
        "class_name": "pandas.core.arrays.sparse.dtype.SparseDtype",
        "signature": "pandas.core.arrays.sparse.dtype.SparseDtype.construct_from_string(cls, string: str)",
        "snippet": "    def construct_from_string(cls, string: str) -> \"SparseDtype\":\n        \"\"\"\n        Construct a SparseDtype from a string form.\n\n        Parameters\n        ----------\n        string : str\n            Can take the following forms.\n\n            string           dtype\n            ================ ============================\n            'int'            SparseDtype[np.int64, 0]\n            'Sparse'         SparseDtype[np.float64, nan]\n            'Sparse[int]'    SparseDtype[np.int64, 0]\n            'Sparse[int, 0]' SparseDtype[np.int64, 0]\n            ================ ============================\n\n            It is not possible to specify non-default fill values\n            with a string. An argument like ``'Sparse[int, 1]'``\n            will raise a ``TypeError`` because the default fill value\n            for integers is 0.\n\n        Returns\n        -------\n        SparseDtype\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\n                f\"'construct_from_string' expects a string, got {type(string)}\"\n            )\n        msg = f\"Cannot construct a 'SparseDtype' from '{string}'\"\n        if string.startswith(\"Sparse\"):\n            try:\n                sub_type, has_fill_value = cls._parse_subtype(string)\n            except ValueError as err:\n                raise TypeError(msg) from err\n            else:\n                result = SparseDtype(sub_type)\n                msg = (\n                    f\"Cannot construct a 'SparseDtype' from '{string}'.\\n\\nIt \"\n                    \"looks like the fill_value in the string is not \"\n                    \"the default for the dtype. Non-default fill_values \"\n                    \"are not supported. Use the 'SparseDtype()' \"\n                    \"constructor instead.\"\n                )\n                if has_fill_value and str(result) != string:\n                    raise TypeError(msg)\n                return result\n        else:\n            raise TypeError(msg)",
        "begin_line": 186,
        "end_line": 235,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.0015748031496062992,
            "pseudo_tarantula_susp": 0.0017331022530329288,
            "pseudo_op2_susp": 0.0015748031496062992,
            "pseudo_barinel_susp": 0.0017331022530329288
        }
    },
    {
        "name": "pandas.conftest.pytest_runtest_setup#64",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.pytest_runtest_setup(item)",
        "snippet": "def pytest_runtest_setup(item):\n    if \"slow\" in item.keywords and item.config.getoption(\"--skip-slow\"):\n        pytest.skip(\"skipping due to --skip-slow\")\n\n    if \"slow\" not in item.keywords and item.config.getoption(\"--only-slow\"):\n        pytest.skip(\"skipping due to --only-slow\")\n\n    if \"network\" in item.keywords and item.config.getoption(\"--skip-network\"):\n        pytest.skip(\"skipping due to --skip-network\")\n\n    if \"db\" in item.keywords and item.config.getoption(\"--skip-db\"):\n        pytest.skip(\"skipping due to --skip-db\")\n\n    if \"high_memory\" in item.keywords and not item.config.getoption(\n        \"--run-high-memory\"\n    ):\n        pytest.skip(\"skipping high memory test since --run-high-memory was not set\")",
        "begin_line": 64,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.conftest.configure_tests#133",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.configure_tests()",
        "snippet": "def configure_tests():\n    \"\"\"\n    Configure settings for all tests and test modules.\n    \"\"\"\n    pd.set_option(\"chained_assignment\", \"raise\")",
        "begin_line": 133,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    },
    {
        "name": "pandas.conftest.add_imports#141",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.add_imports(doctest_namespace)",
        "snippet": "def add_imports(doctest_namespace):\n    \"\"\"\n    Make `np` and `pd` names available for doctests.\n    \"\"\"\n    doctest_namespace[\"np\"] = np\n    doctest_namespace[\"pd\"] = pd",
        "begin_line": 141,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006770480704129993,
            "pseudo_dstar_susp": 0.0006770480704129993,
            "pseudo_tarantula_susp": 0.0006798096532970768,
            "pseudo_op2_susp": 0.0006770480704129993,
            "pseudo_barinel_susp": 0.0006798096532970768
        }
    }
]