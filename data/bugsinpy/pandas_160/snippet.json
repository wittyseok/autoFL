[
    {
        "name": "pandas.core.dtypes.dtypes.Registry.find#82",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.Registry",
        "signature": "pandas.core.dtypes.dtypes.Registry.find(self, dtype: Union[Type[ExtensionDtype], str])",
        "snippet": "    def find(\n        self, dtype: Union[Type[ExtensionDtype], str]\n    ) -> Optional[Type[ExtensionDtype]]:\n        \"\"\"\n        Parameters\n        ----------\n        dtype : Type[ExtensionDtype] or string\n\n        Returns\n        -------\n        return the first matching dtype, otherwise return None\n        \"\"\"\n        if not isinstance(dtype, str):\n            dtype_type = dtype\n            if not isinstance(dtype, type):\n                dtype_type = type(dtype)\n            if issubclass(dtype_type, ExtensionDtype):\n                return dtype\n\n            return None\n\n        for dtype_type in self.dtypes:\n            try:\n                return dtype_type.construct_from_string(dtype)\n            except TypeError:\n                pass\n\n        return None",
        "begin_line": 82,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.DatetimeTZDtype.construct_from_string#722",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.DatetimeTZDtype",
        "signature": "pandas.core.dtypes.dtypes.DatetimeTZDtype.construct_from_string(cls, string)",
        "snippet": "    def construct_from_string(cls, string):\n        \"\"\"\n        Construct a DatetimeTZDtype from a string.\n\n        Parameters\n        ----------\n        string : str\n            The string alias for this DatetimeTZDtype.\n            Should be formatted like ``datetime64[ns, <tz>]``,\n            where ``<tz>`` is the timezone name.\n\n        Examples\n        --------\n        >>> DatetimeTZDtype.construct_from_string('datetime64[ns, UTC]')\n        datetime64[ns, UTC]\n        \"\"\"\n        if isinstance(string, str):\n            msg = \"Could not construct DatetimeTZDtype from '{}'\"\n            try:\n                match = cls._match.match(string)\n                if match:\n                    d = match.groupdict()\n                    return cls(unit=d[\"unit\"], tz=d[\"tz\"])\n            except Exception:\n                # TODO(py3): Change this pass to `raise TypeError(msg) from e`\n                pass\n            raise TypeError(msg.format(string))\n\n        raise TypeError(\"Could not construct DatetimeTZDtype\")",
        "begin_line": 722,
        "end_line": 750,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.PeriodDtype.construct_from_string#871",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.PeriodDtype",
        "signature": "pandas.core.dtypes.dtypes.PeriodDtype.construct_from_string(cls, string)",
        "snippet": "    def construct_from_string(cls, string):\n        \"\"\"\n        Strict construction from a string, raise a TypeError if not\n        possible\n        \"\"\"\n        if (\n            isinstance(string, str)\n            and (string.startswith(\"period[\") or string.startswith(\"Period[\"))\n            or isinstance(string, ABCDateOffset)\n        ):\n            # do not parse string like U as period[U]\n            # avoid tuple to be regarded as freq\n            try:\n                return cls(freq=string)\n            except ValueError:\n                pass\n        raise TypeError(\"could not construct PeriodDtype\")",
        "begin_line": 871,
        "end_line": 887,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.PeriodDtype.is_dtype#917",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.PeriodDtype",
        "signature": "pandas.core.dtypes.dtypes.PeriodDtype.is_dtype(cls, dtype)",
        "snippet": "    def is_dtype(cls, dtype):\n        \"\"\"\n        Return a boolean if we if the passed type is an actual dtype that we\n        can match (via string or type)\n        \"\"\"\n\n        if isinstance(dtype, str):\n            # PeriodDtype can be instantiated from freq string like \"U\",\n            # but doesn't regard freq str like \"U\" as dtype.\n            if dtype.startswith(\"period[\") or dtype.startswith(\"Period[\"):\n                try:\n                    if cls._parse_dtype_strict(dtype) is not None:\n                        return True\n                    else:\n                        return False\n                except ValueError:\n                    return False\n            else:\n                return False\n        return super().is_dtype(dtype)",
        "begin_line": 917,
        "end_line": 936,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.IntervalDtype.construct_from_string#1045",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.IntervalDtype",
        "signature": "pandas.core.dtypes.dtypes.IntervalDtype.construct_from_string(cls, string)",
        "snippet": "    def construct_from_string(cls, string):\n        \"\"\"\n        attempt to construct this type from a string, raise a TypeError\n        if its not possible\n        \"\"\"\n        if not isinstance(string, str):\n            msg = \"a string needs to be passed, got type {typ}\"\n            raise TypeError(msg.format(typ=type(string)))\n\n        if string.lower() == \"interval\" or cls._match.search(string) is not None:\n            return cls(string)\n\n        msg = (\n            \"Incorrectly formatted string passed to constructor. \"\n            \"Valid formats include Interval or Interval[dtype] \"\n            \"where dtype is numeric, datetime, or timedelta\"\n        )\n        raise TypeError(msg)",
        "begin_line": 1045,
        "end_line": 1062,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.IntervalDtype.is_dtype#1097",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.IntervalDtype",
        "signature": "pandas.core.dtypes.dtypes.IntervalDtype.is_dtype(cls, dtype)",
        "snippet": "    def is_dtype(cls, dtype):\n        \"\"\"\n        Return a boolean if we if the passed type is an actual dtype that we\n        can match (via string or type)\n        \"\"\"\n\n        if isinstance(dtype, str):\n            if dtype.lower().startswith(\"interval\"):\n                try:\n                    if cls.construct_from_string(dtype) is not None:\n                        return True\n                    else:\n                        return False\n                except (ValueError, TypeError):\n                    return False\n            else:\n                return False\n        return super().is_dtype(dtype)",
        "begin_line": 1097,
        "end_line": 1114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex.__new__#46",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex.__new__(cls, data=None, dtype=None, copy=False, name=None, fastpath=None)",
        "snippet": "    def __new__(cls, data=None, dtype=None, copy=False, name=None, fastpath=None):\n\n        if fastpath is not None:\n            warnings.warn(\n                \"The 'fastpath' keyword is deprecated, and will be \"\n                \"removed in a future version.\",\n                FutureWarning,\n                stacklevel=2,\n            )\n            if fastpath:\n                return cls._simple_new(data, name=name)\n\n        # is_scalar, generators handled in coerce_to_ndarray\n        data = cls._coerce_to_ndarray(data)\n\n        if issubclass(data.dtype.type, str):\n            cls._string_data_error(data)\n\n        if copy or not is_dtype_equal(data.dtype, cls._default_dtype):\n            subarr = np.array(data, dtype=cls._default_dtype, copy=copy)\n            cls._assert_safe_casting(data, subarr)\n        else:\n            subarr = data\n\n        if name is None and hasattr(data, \"name\"):\n            name = data.name\n        return cls._simple_new(subarr, name=name)",
        "begin_line": 46,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex._shallow_copy#82",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex._shallow_copy(self, values=None, **kwargs)",
        "snippet": "    def _shallow_copy(self, values=None, **kwargs):\n        if values is not None and not self._can_hold_na:\n            # Ensure we are not returning an Int64Index with float data:\n            return self._shallow_copy_with_infer(values=values, **kwargs)\n        return super()._shallow_copy(values=values, **kwargs)",
        "begin_line": 82,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex.is_all_dates#135",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex.is_all_dates(self)",
        "snippet": "    def is_all_dates(self):\n        \"\"\"\n        Checks that all the labels are datetime objects\n        \"\"\"\n        return False",
        "begin_line": 135,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.numeric.Int64Index.inferred_type#229",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.Int64Index",
        "signature": "pandas.core.indexes.numeric.Int64Index.inferred_type(self)",
        "snippet": "    def inferred_type(self):\n        \"\"\"Always 'integer' for ``Int64Index``\"\"\"\n        return \"integer\"",
        "begin_line": 229,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.algorithms._get_take_nd_function#1478",
        "src_path": "pandas/core/algorithms.py",
        "class_name": "pandas.core.algorithms",
        "signature": "pandas.core.algorithms._get_take_nd_function(ndim, arr_dtype, out_dtype, axis=0, mask_info=None)",
        "snippet": "def _get_take_nd_function(ndim, arr_dtype, out_dtype, axis=0, mask_info=None):\n    if ndim <= 2:\n        tup = (arr_dtype.name, out_dtype.name)\n        if ndim == 1:\n            func = _take_1d_dict.get(tup, None)\n        elif ndim == 2:\n            if axis == 0:\n                func = _take_2d_axis0_dict.get(tup, None)\n            else:\n                func = _take_2d_axis1_dict.get(tup, None)\n        if func is not None:\n            return func\n\n        tup = (out_dtype.name, out_dtype.name)\n        if ndim == 1:\n            func = _take_1d_dict.get(tup, None)\n        elif ndim == 2:\n            if axis == 0:\n                func = _take_2d_axis0_dict.get(tup, None)\n            else:\n                func = _take_2d_axis1_dict.get(tup, None)\n        if func is not None:\n            func = _convert_wrapper(func, out_dtype)\n            return func\n\n    def func(arr, indexer, out, fill_value=np.nan):\n        indexer = ensure_int64(indexer)\n        _take_nd_object(\n            arr, indexer, out, axis=axis, fill_value=fill_value, mask_info=mask_info\n        )\n\n    return func",
        "begin_line": 1478,
        "end_line": 1509,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.algorithms.take_nd#1605",
        "src_path": "pandas/core/algorithms.py",
        "class_name": "pandas.core.algorithms",
        "signature": "pandas.core.algorithms.take_nd(arr, indexer, axis=0, out=None, fill_value=np.nan, mask_info=None, allow_fill=True)",
        "snippet": "def take_nd(\n    arr, indexer, axis=0, out=None, fill_value=np.nan, mask_info=None, allow_fill=True\n):\n    \"\"\"\n    Specialized Cython take which sets NaN values in one pass\n\n    This dispatches to ``take`` defined on ExtensionArrays. It does not\n    currently dispatch to ``SparseArray.take`` for sparse ``arr``.\n\n    Parameters\n    ----------\n    arr : array-like\n        Input array.\n    indexer : ndarray\n        1-D array of indices to take, subarrays corresponding to -1 value\n        indices are filed with fill_value\n    axis : int, default 0\n        Axis to take from\n    out : ndarray or None, default None\n        Optional output array, must be appropriate type to hold input and\n        fill_value together, if indexer has any -1 value entries; call\n        _maybe_promote to determine this type for any fill_value\n    fill_value : any, default np.nan\n        Fill value to replace -1 values with\n    mask_info : tuple of (ndarray, boolean)\n        If provided, value should correspond to:\n            (indexer != -1, (indexer != -1).any())\n        If not provided, it will be computed internally if necessary\n    allow_fill : boolean, default True\n        If False, indexer is assumed to contain no -1 values so no filling\n        will be done.  This short-circuits computation of a mask.  Result is\n        undefined if allow_fill == False and -1 is present in indexer.\n\n    Returns\n    -------\n    subarray : array-like\n        May be the same type as the input, or cast to an ndarray.\n    \"\"\"\n\n    if is_extension_array_dtype(arr):\n        return arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\n    if is_sparse(arr):\n        arr = arr.to_dense()\n    elif isinstance(arr, (ABCIndexClass, ABCSeries)):\n        arr = arr._values\n\n    arr = np.asarray(arr)\n\n    if indexer is None:\n        indexer = np.arange(arr.shape[axis], dtype=np.int64)\n        dtype, fill_value = arr.dtype, arr.dtype.type()\n    else:\n        indexer = ensure_int64(indexer, copy=False)\n        if not allow_fill:\n            dtype, fill_value = arr.dtype, arr.dtype.type()\n            mask_info = None, False\n        else:\n            # check for promotion based on types only (do this first because\n            # it's faster than computing a mask)\n            dtype, fill_value = maybe_promote(arr.dtype, fill_value)\n            if dtype != arr.dtype and (out is None or out.dtype != dtype):\n                # check if promotion is actually required based on indexer\n                if mask_info is not None:\n                    mask, needs_masking = mask_info\n                else:\n                    mask = indexer == -1\n                    needs_masking = mask.any()\n                    mask_info = mask, needs_masking\n                if needs_masking:\n                    if out is not None and out.dtype != dtype:\n                        raise TypeError(\"Incompatible type for fill_value\")\n                else:\n                    # if not, then depromote, set fill_value to dummy\n                    # (it won't be used but we don't want the cython code\n                    # to crash when trying to cast it to dtype)\n                    dtype, fill_value = arr.dtype, arr.dtype.type()\n\n    flip_order = False\n    if arr.ndim == 2:\n        if arr.flags.f_contiguous:\n            flip_order = True\n\n    if flip_order:\n        arr = arr.T\n        axis = arr.ndim - axis - 1\n        if out is not None:\n            out = out.T\n\n    # at this point, it's guaranteed that dtype can hold both the arr values\n    # and the fill_value\n    if out is None:\n        out_shape = list(arr.shape)\n        out_shape[axis] = len(indexer)\n        out_shape = tuple(out_shape)\n        if arr.flags.f_contiguous and axis == arr.ndim - 1:\n            # minor tweak that can make an order-of-magnitude difference\n            # for dataframes initialized directly from 2-d ndarrays\n            # (s.t. df.values is c-contiguous and df._data.blocks[0] is its\n            # f-contiguous transpose)\n            out = np.empty(out_shape, dtype=dtype, order=\"F\")\n        else:\n            out = np.empty(out_shape, dtype=dtype)\n\n    func = _get_take_nd_function(\n        arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n    )\n    func(arr, indexer, out, fill_value)\n\n    if flip_order:\n        out = out.T\n    return out",
        "begin_line": 1605,
        "end_line": 1716,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.__init__#126",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.__init__(self, blocks: Sequence[Block], axes: Sequence[Index], do_integrity_check: bool=True)",
        "snippet": "    def __init__(\n        self,\n        blocks: Sequence[Block],\n        axes: Sequence[Index],\n        do_integrity_check: bool = True,\n    ):\n        self.axes = [ensure_index(ax) for ax in axes]\n        self.blocks = tuple(blocks)  # type: Tuple[Block, ...]\n\n        for block in blocks:\n            if self.ndim != block.ndim:\n                raise AssertionError(\n                    \"Number of Block dimensions ({block}) must equal \"\n                    \"number of axes ({self})\".format(block=block.ndim, self=self.ndim)\n                )\n\n        if do_integrity_check:\n            self._verify_integrity()\n\n        self._consolidate_check()\n\n        self._rebuild_blknos_and_blklocs()",
        "begin_line": 126,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.3333333333333333,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.3333333333333333,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.shape#168",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.shape(self)",
        "snippet": "    def shape(self):\n        return tuple(len(ax) for ax in self.axes)",
        "begin_line": 168,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.3333333333333333,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.3333333333333333,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.ndim#172",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.ndim(self)",
        "snippet": "    def ndim(self):\n        return len(self.axes)",
        "begin_line": 172,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.set_axis#175",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.set_axis(self, axis, new_labels)",
        "snippet": "    def set_axis(self, axis, new_labels):\n        new_labels = ensure_index(new_labels)\n        old_len = len(self.axes[axis])\n        new_len = len(new_labels)\n\n        if new_len != old_len:\n            raise ValueError(\n                \"Length mismatch: Expected axis has {old} elements, new \"\n                \"values have {new} elements\".format(old=old_len, new=new_len)\n            )\n\n        self.axes[axis] = new_labels",
        "begin_line": 175,
        "end_line": 186,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._is_single_block#204",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._is_single_block(self)",
        "snippet": "    def _is_single_block(self):\n        if self.ndim == 1:\n            return True\n\n        if len(self.blocks) != 1:\n            return False\n\n        blk = self.blocks[0]\n        return blk.mgr_locs.is_slice_like and blk.mgr_locs.as_slice == slice(\n            0, len(self), 1\n        )",
        "begin_line": 204,
        "end_line": 214,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._rebuild_blknos_and_blklocs#216",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._rebuild_blknos_and_blklocs(self)",
        "snippet": "    def _rebuild_blknos_and_blklocs(self):\n        \"\"\"\n        Update mgr._blknos / mgr._blklocs.\n        \"\"\"\n        new_blknos = np.empty(self.shape[0], dtype=np.int64)\n        new_blklocs = np.empty(self.shape[0], dtype=np.int64)\n        new_blknos.fill(-1)\n        new_blklocs.fill(-1)\n\n        for blkno, blk in enumerate(self.blocks):\n            rl = blk.mgr_locs\n            new_blknos[rl.indexer] = blkno\n            new_blklocs[rl.indexer] = np.arange(len(rl))\n\n        if (new_blknos == -1).any():\n            raise AssertionError(\"Gaps in blk ref_locs\")\n\n        self._blknos = new_blknos\n        self._blklocs = new_blklocs",
        "begin_line": 216,
        "end_line": 234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.items#237",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.items(self)",
        "snippet": "    def items(self):\n        return self.axes[0]",
        "begin_line": 237,
        "end_line": 238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.get_dtypes#255",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.get_dtypes(self)",
        "snippet": "    def get_dtypes(self):\n        dtypes = np.array([blk.dtype for blk in self.blocks])\n        return algos.take_1d(dtypes, self._blknos, allow_fill=False)",
        "begin_line": 255,
        "end_line": 257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02564102564102564,
            "pseudo_dstar_susp": 0.023809523809523808,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.023809523809523808,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.__len__#325",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.__len__(self)",
        "snippet": "    def __len__(self):\n        return len(self.items)",
        "begin_line": 325,
        "end_line": 326,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._verify_integrity#340",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._verify_integrity(self)",
        "snippet": "    def _verify_integrity(self):\n        mgr_shape = self.shape\n        tot_items = sum(len(x.mgr_locs) for x in self.blocks)\n        for block in self.blocks:\n            if block._verify_integrity and block.shape[1:] != mgr_shape[1:]:\n                construction_error(tot_items, block.shape[1:], self.axes)\n        if len(self.items) != tot_items:\n            raise AssertionError(\n                \"Number of manager items must equal union of \"\n                \"block items\\n# manager items: {0}, # \"\n                \"tot_items: {1}\".format(len(self.items), tot_items)\n            )",
        "begin_line": 340,
        "end_line": 351,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.apply#353",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.apply(self, f, axes=None, filter=None, do_integrity_check=False, consolidate=True, **kwargs)",
        "snippet": "    def apply(\n        self,\n        f,\n        axes=None,\n        filter=None,\n        do_integrity_check=False,\n        consolidate=True,\n        **kwargs\n    ):\n        \"\"\"\n        iterate over the blocks, collect and create a new block manager\n\n        Parameters\n        ----------\n        f : the callable or function name to operate on at the block level\n        axes : optional (if not supplied, use self.axes)\n        filter : list, if supplied, only call the block if the filter is in\n                 the block\n        do_integrity_check : boolean, default False. Do the block manager\n            integrity check\n        consolidate: boolean, default True. Join together blocks having same\n            dtype\n\n        Returns\n        -------\n        Block Manager (new object)\n\n        \"\"\"\n\n        result_blocks = []\n\n        # filter kwarg is used in replace-* family of methods\n        if filter is not None:\n            filter_locs = set(self.items.get_indexer_for(filter))\n            if len(filter_locs) == len(self.items):\n                # All items are included, as if there were no filtering\n                filter = None\n            else:\n                kwargs[\"filter\"] = filter_locs\n\n        if consolidate:\n            self._consolidate_inplace()\n\n        if f == \"where\":\n            align_copy = True\n            if kwargs.get(\"align\", True):\n                align_keys = [\"other\", \"cond\"]\n            else:\n                align_keys = [\"cond\"]\n        elif f == \"putmask\":\n            align_copy = False\n            if kwargs.get(\"align\", True):\n                align_keys = [\"new\", \"mask\"]\n            else:\n                align_keys = [\"mask\"]\n        elif f == \"fillna\":\n            # fillna internally does putmask, maybe it's better to do this\n            # at mgr, not block level?\n            align_copy = False\n            align_keys = [\"value\"]\n        else:\n            align_keys = []\n\n        # TODO(EA): may interfere with ExtensionBlock.setitem for blocks\n        # with a .values attribute.\n        aligned_args = {\n            k: kwargs[k]\n            for k in align_keys\n            if not isinstance(kwargs[k], ABCExtensionArray)\n            and hasattr(kwargs[k], \"values\")\n        }\n\n        for b in self.blocks:\n            if filter is not None:\n                if not b.mgr_locs.isin(filter_locs).any():\n                    result_blocks.append(b)\n                    continue\n\n            if aligned_args:\n                b_items = self.items[b.mgr_locs.indexer]\n\n                for k, obj in aligned_args.items():\n                    axis = getattr(obj, \"_info_axis_number\", 0)\n                    kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy)\n\n            applied = getattr(b, f)(**kwargs)\n            result_blocks = _extend_blocks(applied, result_blocks)\n\n        if len(result_blocks) == 0:\n            return self.make_empty(axes or self.axes)\n        bm = self.__class__(\n            result_blocks, axes or self.axes, do_integrity_check=do_integrity_check\n        )\n        bm._consolidate_inplace()\n        return bm",
        "begin_line": 353,
        "end_line": 447,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.is_consolidated#646",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.is_consolidated(self)",
        "snippet": "    def is_consolidated(self):\n        \"\"\"\n        Return True if more than one block with the same dtype\n        \"\"\"\n        if not self._known_consolidated:\n            self._consolidate_check()\n        return self._is_consolidated",
        "begin_line": 646,
        "end_line": 652,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._consolidate_check#654",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._consolidate_check(self)",
        "snippet": "    def _consolidate_check(self):\n        ftypes = [blk.ftype for blk in self.blocks]\n        self._is_consolidated = len(ftypes) == len(set(ftypes))\n        self._known_consolidated = True",
        "begin_line": 654,
        "end_line": 657,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.3333333333333333,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.3333333333333333,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.is_mixed_type#660",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.is_mixed_type(self)",
        "snippet": "    def is_mixed_type(self):\n        # Warning, consolidation needs to get checked upstairs\n        self._consolidate_inplace()\n        return len(self.blocks) > 1",
        "begin_line": 660,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.copy#765",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.copy(self, deep=True)",
        "snippet": "    def copy(self, deep=True):\n        \"\"\"\n        Make deep or shallow copy of BlockManager\n\n        Parameters\n        ----------\n        deep : boolean o rstring, default True\n            If False, return shallow copy (do not copy data)\n            If 'all', copy data and a deep copy of the index\n\n        Returns\n        -------\n        copy : BlockManager\n        \"\"\"\n        # this preserves the notion of view copying of axes\n        if deep:\n            if deep == \"all\":\n                copy = lambda ax: ax.copy(deep=True)\n            else:\n                copy = lambda ax: ax.view()\n            new_axes = [copy(ax) for ax in self.axes]\n        else:\n            new_axes = list(self.axes)\n        return self.apply(\"copy\", axes=new_axes, deep=deep, do_integrity_check=False)",
        "begin_line": 765,
        "end_line": 788,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.as_array#790",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.as_array(self, transpose=False, items=None)",
        "snippet": "    def as_array(self, transpose=False, items=None):\n        \"\"\"Convert the blockmanager data into an numpy array.\n\n        Parameters\n        ----------\n        transpose : boolean, default False\n            If True, transpose the return array\n        items : list of strings or None\n            Names of block items that will be included in the returned\n            array. ``None`` means that all block items will be used\n\n        Returns\n        -------\n        arr : ndarray\n        \"\"\"\n        if len(self.blocks) == 0:\n            arr = np.empty(self.shape, dtype=float)\n            return arr.transpose() if transpose else arr\n\n        if items is not None:\n            mgr = self.reindex_axis(items, axis=0)\n        else:\n            mgr = self\n\n        if self._is_single_block and mgr.blocks[0].is_datetimetz:\n            # TODO(Block.get_values): Make DatetimeTZBlock.get_values\n            # always be object dtype. Some callers seem to want the\n            # DatetimeArray (previously DTI)\n            arr = mgr.blocks[0].get_values(dtype=object)\n        elif self._is_single_block or not self.is_mixed_type:\n            arr = np.asarray(mgr.blocks[0].get_values())\n        else:\n            arr = mgr._interleave()\n\n        return arr.transpose() if transpose else arr",
        "begin_line": 790,
        "end_line": 824,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.fast_xs#878",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.fast_xs(self, loc)",
        "snippet": "    def fast_xs(self, loc):\n        \"\"\"\n        get a cross sectional for a given location in the\n        items ; handle dups\n\n        return the result, is *could* be a view in the case of a\n        single block\n        \"\"\"\n        if len(self.blocks) == 1:\n            return self.blocks[0].iget((slice(None), loc))\n\n        items = self.items\n\n        # non-unique (GH4726)\n        if not items.is_unique:\n            result = self._interleave()\n            if self.ndim == 2:\n                result = result.T\n            return result[loc]\n\n        # unique\n        dtype = _interleaved_dtype(self.blocks)\n\n        n = len(items)\n        if is_extension_array_dtype(dtype):\n            # we'll eventually construct an ExtensionArray.\n            result = np.empty(n, dtype=object)\n        else:\n            result = np.empty(n, dtype=dtype)\n\n        for blk in self.blocks:\n            # Such assignment may incorrectly coerce NaT to None\n            # result[blk.mgr_locs] = blk._slice((slice(None), loc))\n            for i, rl in enumerate(blk.mgr_locs):\n                result[rl] = blk.iget((i, loc))\n\n        if is_extension_array_dtype(dtype):\n            result = dtype.construct_array_type()._from_sequence(result, dtype=dtype)\n\n        return result",
        "begin_line": 878,
        "end_line": 917,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.consolidate#919",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.consolidate(self)",
        "snippet": "    def consolidate(self):\n        \"\"\"\n        Join together blocks having same dtype\n\n        Returns\n        -------\n        y : BlockManager\n        \"\"\"\n        if self.is_consolidated():\n            return self\n\n        bm = self.__class__(self.blocks, self.axes)\n        bm._is_consolidated = False\n        bm._consolidate_inplace()\n        return bm",
        "begin_line": 919,
        "end_line": 933,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007668711656441718,
            "pseudo_dstar_susp": 0.0007668711656441718,
            "pseudo_tarantula_susp": 0.0008403361344537816,
            "pseudo_op2_susp": 0.0007668711656441718,
            "pseudo_barinel_susp": 0.0008403361344537816
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._consolidate_inplace#935",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._consolidate_inplace(self)",
        "snippet": "    def _consolidate_inplace(self):\n        if not self.is_consolidated():\n            self.blocks = tuple(_consolidate(self.blocks))\n            self._is_consolidated = True\n            self._known_consolidated = True\n            self._rebuild_blknos_and_blklocs()",
        "begin_line": 935,
        "end_line": 940,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.iget#971",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.iget(self, i)",
        "snippet": "    def iget(self, i):\n        \"\"\"\n        Return the data as a SingleBlockManager if possible\n\n        Otherwise return as a ndarray\n        \"\"\"\n        block = self.blocks[self._blknos[i]]\n        values = block.iget(self._blklocs[i])\n\n        # shortcut for select a single-dim from a 2-dim BM\n        return SingleBlockManager(\n            [\n                block.make_block_same_class(\n                    values, placement=slice(0, len(values)), ndim=1\n                )\n            ],\n            self.axes[1],\n        )",
        "begin_line": 971,
        "end_line": 988,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.__init__#1468",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.__init__(self, block: Block, axis: Union[Index, List[Index]], do_integrity_check: bool=False, fastpath: bool=False)",
        "snippet": "    def __init__(\n        self,\n        block: Block,\n        axis: Union[Index, List[Index]],\n        do_integrity_check: bool = False,\n        fastpath: bool = False,\n    ):\n        if isinstance(axis, list):\n            if len(axis) != 1:\n                raise ValueError(\n                    \"cannot create SingleBlockManager with more than 1 axis\"\n                )\n            axis = axis[0]\n\n        # passed from constructor, single block, single axis\n        if fastpath:\n            self.axes = [axis]\n            if isinstance(block, list):\n\n                # empty block\n                if len(block) == 0:\n                    block = [np.array([])]\n                elif len(block) != 1:\n                    raise ValueError(\n                        \"Cannot create SingleBlockManager with more than 1 block\"\n                    )\n                block = block[0]\n        else:\n            self.axes = [ensure_index(axis)]\n\n            # create the block here\n            if isinstance(block, list):\n\n                # provide consolidation to the interleaved_dtype\n                if len(block) > 1:\n                    dtype = _interleaved_dtype(block)\n                    block = [b.astype(dtype) for b in block]\n                    block = _consolidate(block)\n\n                if len(block) != 1:\n                    raise ValueError(\n                        \"Cannot create SingleBlockManager with more than 1 block\"\n                    )\n                block = block[0]\n\n        if not isinstance(block, Block):\n            block = make_block(block, placement=slice(0, len(axis)), ndim=1)\n\n        self.blocks = tuple([block])",
        "begin_line": 1468,
        "end_line": 1516,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager._block#1522",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager._block(self)",
        "snippet": "    def _block(self):\n        return self.blocks[0]",
        "begin_line": 1522,
        "end_line": 1523,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.get_slice#1539",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.get_slice(self, slobj, axis=0)",
        "snippet": "    def get_slice(self, slobj, axis=0):\n        if axis >= self.ndim:\n            raise IndexError(\"Requested axis not found in manager\")\n\n        return self.__class__(\n            self._block._slice(slobj), self.index[slobj], fastpath=True\n        )",
        "begin_line": 1539,
        "end_line": 1545,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.index#1548",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.index(self)",
        "snippet": "    def index(self):\n        return self.axes[0]",
        "begin_line": 1548,
        "end_line": 1549,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.dtype#1556",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.dtype(self)",
        "snippet": "    def dtype(self):\n        return self._block.dtype",
        "begin_line": 1556,
        "end_line": 1557,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.external_values#1579",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.external_values(self)",
        "snippet": "    def external_values(self):\n        return self._block.external_values()",
        "begin_line": 1579,
        "end_line": 1580,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.internal_values#1582",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.internal_values(self)",
        "snippet": "    def internal_values(self):\n        return self._block.internal_values()",
        "begin_line": 1582,
        "end_line": 1583,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.get_values#1585",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.get_values(self)",
        "snippet": "    def get_values(self):\n        \"\"\" return a dense type view \"\"\"\n        return np.array(self._block.to_dense(), copy=False)",
        "begin_line": 1585,
        "end_line": 1587,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.is_consolidated#1593",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.is_consolidated(self)",
        "snippet": "    def is_consolidated(self):\n        return True",
        "begin_line": 1593,
        "end_line": 1594,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.concat#1619",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.concat(self, to_concat, new_axis)",
        "snippet": "    def concat(self, to_concat, new_axis):\n        \"\"\"\n        Concatenate a list of SingleBlockManagers into a single\n        SingleBlockManager.\n\n        Used for pd.concat of Series objects with axis=0.\n\n        Parameters\n        ----------\n        to_concat : list of SingleBlockManagers\n        new_axis : Index of the result\n\n        Returns\n        -------\n        SingleBlockManager\n\n        \"\"\"\n        non_empties = [x for x in to_concat if len(x) > 0]\n\n        # check if all series are of the same block type:\n        if len(non_empties) > 0:\n            blocks = [obj.blocks[0] for obj in non_empties]\n            if len({b.dtype for b in blocks}) == 1:\n                new_block = blocks[0].concat_same_type(blocks)\n            else:\n                values = [x.values for x in blocks]\n                values = concat_compat(values)\n                new_block = make_block(values, placement=slice(0, len(values), 1))\n        else:\n            values = [x._block.values for x in to_concat]\n            values = concat_compat(values)\n            new_block = make_block(values, placement=slice(0, len(values), 1))\n\n        mgr = SingleBlockManager(new_block, new_axis)\n        return mgr",
        "begin_line": 1619,
        "end_line": 1653,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.internals.managers.create_block_manager_from_blocks#1660",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers.create_block_manager_from_blocks(blocks, axes)",
        "snippet": "def create_block_manager_from_blocks(blocks, axes):\n    try:\n        if len(blocks) == 1 and not isinstance(blocks[0], Block):\n            # if blocks[0] is of length 0, return empty blocks\n            if not len(blocks[0]):\n                blocks = []\n            else:\n                # It's OK if a single block is passed as values, its placement\n                # is basically \"all items\", but if there're many, don't bother\n                # converting, it's an error anyway.\n                blocks = [\n                    make_block(values=blocks[0], placement=slice(0, len(axes[0])))\n                ]\n\n        mgr = BlockManager(blocks, axes)\n        mgr._consolidate_inplace()\n        return mgr\n\n    except ValueError as e:\n        blocks = [getattr(b, \"values\", b) for b in blocks]\n        tot_items = sum(b.shape[0] for b in blocks)\n        construction_error(tot_items, blocks[0].shape[1:], axes, e)",
        "begin_line": 1660,
        "end_line": 1681,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.managers.create_block_manager_from_arrays#1684",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers.create_block_manager_from_arrays(arrays, names, axes)",
        "snippet": "def create_block_manager_from_arrays(arrays, names, axes):\n\n    try:\n        blocks = form_blocks(arrays, names, axes)\n        mgr = BlockManager(blocks, axes)\n        mgr._consolidate_inplace()\n        return mgr\n    except ValueError as e:\n        construction_error(len(arrays), arrays[0].shape, axes, e)",
        "begin_line": 1684,
        "end_line": 1692,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.managers.form_blocks#1719",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers.form_blocks(arrays, names, axes)",
        "snippet": "def form_blocks(arrays, names, axes):\n    # put \"leftover\" items in float bucket, where else?\n    # generalize?\n    items_dict = defaultdict(list)\n    extra_locs = []\n\n    names_idx = ensure_index(names)\n    if names_idx.equals(axes[0]):\n        names_indexer = np.arange(len(names_idx))\n    else:\n        assert names_idx.intersection(axes[0]).is_unique\n        names_indexer = names_idx.get_indexer_for(axes[0])\n\n    for i, name_idx in enumerate(names_indexer):\n        if name_idx == -1:\n            extra_locs.append(i)\n            continue\n\n        k = names[name_idx]\n        v = arrays[name_idx]\n\n        block_type = get_block_type(v)\n        items_dict[block_type.__name__].append((i, k, v))\n\n    blocks = []\n    if len(items_dict[\"FloatBlock\"]):\n        float_blocks = _multi_blockify(items_dict[\"FloatBlock\"])\n        blocks.extend(float_blocks)\n\n    if len(items_dict[\"ComplexBlock\"]):\n        complex_blocks = _multi_blockify(items_dict[\"ComplexBlock\"])\n        blocks.extend(complex_blocks)\n\n    if len(items_dict[\"TimeDeltaBlock\"]):\n        timedelta_blocks = _multi_blockify(items_dict[\"TimeDeltaBlock\"])\n        blocks.extend(timedelta_blocks)\n\n    if len(items_dict[\"IntBlock\"]):\n        int_blocks = _multi_blockify(items_dict[\"IntBlock\"])\n        blocks.extend(int_blocks)\n\n    if len(items_dict[\"DatetimeBlock\"]):\n        datetime_blocks = _simple_blockify(items_dict[\"DatetimeBlock\"], _NS_DTYPE)\n        blocks.extend(datetime_blocks)\n\n    if len(items_dict[\"DatetimeTZBlock\"]):\n        dttz_blocks = [\n            make_block(array, klass=DatetimeTZBlock, placement=[i])\n            for i, _, array in items_dict[\"DatetimeTZBlock\"]\n        ]\n        blocks.extend(dttz_blocks)\n\n    if len(items_dict[\"BoolBlock\"]):\n        bool_blocks = _simple_blockify(items_dict[\"BoolBlock\"], np.bool_)\n        blocks.extend(bool_blocks)\n\n    if len(items_dict[\"ObjectBlock\"]) > 0:\n        object_blocks = _simple_blockify(items_dict[\"ObjectBlock\"], np.object_)\n        blocks.extend(object_blocks)\n\n    if len(items_dict[\"CategoricalBlock\"]) > 0:\n        cat_blocks = [\n            make_block(array, klass=CategoricalBlock, placement=[i])\n            for i, _, array in items_dict[\"CategoricalBlock\"]\n        ]\n        blocks.extend(cat_blocks)\n\n    if len(items_dict[\"ExtensionBlock\"]):\n\n        external_blocks = [\n            make_block(array, klass=ExtensionBlock, placement=[i])\n            for i, _, array in items_dict[\"ExtensionBlock\"]\n        ]\n\n        blocks.extend(external_blocks)\n\n    if len(items_dict[\"ObjectValuesExtensionBlock\"]):\n        external_blocks = [\n            make_block(array, klass=ObjectValuesExtensionBlock, placement=[i])\n            for i, _, array in items_dict[\"ObjectValuesExtensionBlock\"]\n        ]\n\n        blocks.extend(external_blocks)\n\n    if len(extra_locs):\n        shape = (len(extra_locs),) + tuple(len(x) for x in axes[1:])\n\n        # empty items -> dtype object\n        block_values = np.empty(shape, dtype=object)\n        block_values.fill(np.nan)\n\n        na_block = make_block(block_values, placement=extra_locs)\n        blocks.append(na_block)\n\n    return blocks",
        "begin_line": 1719,
        "end_line": 1813,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.managers._multi_blockify#1830",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._multi_blockify(tuples, dtype=None)",
        "snippet": "def _multi_blockify(tuples, dtype=None):\n    \"\"\" return an array of blocks that potentially have different dtypes \"\"\"\n\n    # group by dtype\n    grouper = itertools.groupby(tuples, lambda x: x[2].dtype)\n\n    new_blocks = []\n    for dtype, tup_block in grouper:\n\n        values, placement = _stack_arrays(list(tup_block), dtype)\n\n        block = make_block(values, placement=placement)\n        new_blocks.append(block)\n\n    return new_blocks",
        "begin_line": 1830,
        "end_line": 1844,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02564102564102564,
            "pseudo_dstar_susp": 0.023809523809523808,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.023809523809523808,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.managers._stack_arrays#1847",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._stack_arrays(tuples, dtype)",
        "snippet": "def _stack_arrays(tuples, dtype):\n\n    # fml\n    def _asarray_compat(x):\n        if isinstance(x, ABCSeries):\n            return x._values\n        else:\n            return np.asarray(x)\n\n    def _shape_compat(x):\n        if isinstance(x, ABCSeries):\n            return (len(x),)\n        else:\n            return x.shape\n\n    placement, names, arrays = zip(*tuples)\n\n    first = arrays[0]\n    shape = (len(arrays),) + _shape_compat(first)\n\n    stacked = np.empty(shape, dtype=dtype)\n    for i, arr in enumerate(arrays):\n        stacked[i] = _asarray_compat(arr)\n\n    return stacked, placement",
        "begin_line": 1847,
        "end_line": 1871,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.managers._asarray_compat#1850",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._asarray_compat(x)",
        "snippet": "    def _asarray_compat(x):\n        if isinstance(x, ABCSeries):\n            return x._values\n        else:\n            return np.asarray(x)",
        "begin_line": 1850,
        "end_line": 1854,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02564102564102564,
            "pseudo_dstar_susp": 0.023809523809523808,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.023809523809523808,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.managers._shape_compat#1856",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._shape_compat(x)",
        "snippet": "    def _shape_compat(x):\n        if isinstance(x, ABCSeries):\n            return (len(x),)\n        else:\n            return x.shape",
        "begin_line": 1856,
        "end_line": 1860,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02564102564102564,
            "pseudo_dstar_susp": 0.023809523809523808,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.023809523809523808,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.reshape.concat.concat#31",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat",
        "signature": "pandas.core.reshape.concat.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=None, copy=True)",
        "snippet": "def concat(\n    objs,\n    axis=0,\n    join=\"outer\",\n    join_axes=None,\n    ignore_index=False,\n    keys=None,\n    levels=None,\n    names=None,\n    verify_integrity=False,\n    sort=None,\n    copy=True,\n):\n    \"\"\"\n    Concatenate pandas objects along a particular axis with optional set logic\n    along the other axes.\n\n    Can also add a layer of hierarchical indexing on the concatenation axis,\n    which may be useful if the labels are the same (or overlapping) on\n    the passed axis number.\n\n    Parameters\n    ----------\n    objs : a sequence or mapping of Series or DataFrame objects\n        If a dict is passed, the sorted keys will be used as the `keys`\n        argument, unless it is passed, in which case the values will be\n        selected (see below). Any None objects will be dropped silently unless\n        they are all None in which case a ValueError will be raised.\n    axis : {0/'index', 1/'columns'}, default 0\n        The axis to concatenate along.\n    join : {'inner', 'outer'}, default 'outer'\n        How to handle indexes on other axis (or axes).\n    join_axes : list of Index objects\n        .. deprecated:: 0.25.0\n\n        Specific indexes to use for the other n - 1 axes instead of performing\n        inner/outer set logic. Use .reindex() before or after concatenation\n        as a replacement.\n    ignore_index : bool, default False\n        If True, do not use the index values along the concatenation axis. The\n        resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n        concatenating objects where the concatenation axis does not have\n        meaningful indexing information. Note the index values on the other\n        axes are still respected in the join.\n    keys : sequence, default None\n        If multiple levels passed, should contain tuples. Construct\n        hierarchical index using the passed keys as the outermost level.\n    levels : list of sequences, default None\n        Specific levels (unique values) to use for constructing a\n        MultiIndex. Otherwise they will be inferred from the keys.\n    names : list, default None\n        Names for the levels in the resulting hierarchical index.\n    verify_integrity : bool, default False\n        Check whether the new concatenated axis contains duplicates. This can\n        be very expensive relative to the actual data concatenation.\n    sort : bool, default None\n        Sort non-concatenation axis if it is not already aligned when `join`\n        is 'outer'. The current default of sorting is deprecated and will\n        change to not-sorting in a future version of pandas.\n\n        Explicitly pass ``sort=True`` to silence the warning and sort.\n        Explicitly pass ``sort=False`` to silence the warning and not sort.\n\n        This has no effect when ``join='inner'``, which already preserves\n        the order of the non-concatenation axis.\n\n        .. versionadded:: 0.23.0\n\n    copy : bool, default True\n        If False, do not copy data unnecessarily.\n\n    Returns\n    -------\n    object, type of objs\n        When concatenating all ``Series`` along the index (axis=0), a\n        ``Series`` is returned. When ``objs`` contains at least one\n        ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n        the columns (axis=1), a ``DataFrame`` is returned.\n\n    See Also\n    --------\n    Series.append : Concatenate Series.\n    DataFrame.append : Concatenate DataFrames.\n    DataFrame.join : Join DataFrames using indexes.\n    DataFrame.merge : Merge DataFrames by indexes or columns.\n\n    Notes\n    -----\n    The keys, levels, and names arguments are all optional.\n\n    A walkthrough of how this method fits in with other tools for combining\n    pandas objects can be found `here\n    <http://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n\n    Examples\n    --------\n    Combine two ``Series``.\n\n    >>> s1 = pd.Series(['a', 'b'])\n    >>> s2 = pd.Series(['c', 'd'])\n    >>> pd.concat([s1, s2])\n    0    a\n    1    b\n    0    c\n    1    d\n    dtype: object\n\n    Clear the existing index and reset it in the result\n    by setting the ``ignore_index`` option to ``True``.\n\n    >>> pd.concat([s1, s2], ignore_index=True)\n    0    a\n    1    b\n    2    c\n    3    d\n    dtype: object\n\n    Add a hierarchical index at the outermost level of\n    the data with the ``keys`` option.\n\n    >>> pd.concat([s1, s2], keys=['s1', 's2'])\n    s1  0    a\n        1    b\n    s2  0    c\n        1    d\n    dtype: object\n\n    Label the index keys you create with the ``names`` option.\n\n    >>> pd.concat([s1, s2], keys=['s1', 's2'],\n    ...           names=['Series name', 'Row ID'])\n    Series name  Row ID\n    s1           0         a\n                 1         b\n    s2           0         c\n                 1         d\n    dtype: object\n\n    Combine two ``DataFrame`` objects with identical columns.\n\n    >>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n    ...                    columns=['letter', 'number'])\n    >>> df1\n      letter  number\n    0      a       1\n    1      b       2\n    >>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n    ...                    columns=['letter', 'number'])\n    >>> df2\n      letter  number\n    0      c       3\n    1      d       4\n    >>> pd.concat([df1, df2])\n      letter  number\n    0      a       1\n    1      b       2\n    0      c       3\n    1      d       4\n\n    Combine ``DataFrame`` objects with overlapping columns\n    and return everything. Columns outside the intersection will\n    be filled with ``NaN`` values.\n\n    >>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n    ...                    columns=['letter', 'number', 'animal'])\n    >>> df3\n      letter  number animal\n    0      c       3    cat\n    1      d       4    dog\n    >>> pd.concat([df1, df3], sort=False)\n      letter  number animal\n    0      a       1    NaN\n    1      b       2    NaN\n    0      c       3    cat\n    1      d       4    dog\n\n    Combine ``DataFrame`` objects with overlapping columns\n    and return only those that are shared by passing ``inner`` to\n    the ``join`` keyword argument.\n\n    >>> pd.concat([df1, df3], join=\"inner\")\n      letter  number\n    0      a       1\n    1      b       2\n    0      c       3\n    1      d       4\n\n    Combine ``DataFrame`` objects horizontally along the x axis by\n    passing in ``axis=1``.\n\n    >>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n    ...                    columns=['animal', 'name'])\n    >>> pd.concat([df1, df4], axis=1)\n      letter  number  animal    name\n    0      a       1    bird   polly\n    1      b       2  monkey  george\n\n    Prevent the result from including duplicate index values with the\n    ``verify_integrity`` option.\n\n    >>> df5 = pd.DataFrame([1], index=['a'])\n    >>> df5\n       0\n    a  1\n    >>> df6 = pd.DataFrame([2], index=['a'])\n    >>> df6\n       0\n    a  2\n    >>> pd.concat([df5, df6], verify_integrity=True)\n    Traceback (most recent call last):\n        ...\n    ValueError: Indexes have overlapping values: ['a']\n    \"\"\"\n    op = _Concatenator(\n        objs,\n        axis=axis,\n        ignore_index=ignore_index,\n        join=join,\n        join_axes=join_axes,\n        keys=keys,\n        levels=levels,\n        names=names,\n        verify_integrity=verify_integrity,\n        copy=copy,\n        sort=sort,\n    )\n\n    return op.get_result()",
        "begin_line": 31,
        "end_line": 258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator.__init__#266",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator.__init__(self, objs, axis=0, join='outer', join_axes=None, keys=None, levels=None, names=None, ignore_index=False, verify_integrity=False, copy=True, sort=False)",
        "snippet": "    def __init__(\n        self,\n        objs,\n        axis=0,\n        join=\"outer\",\n        join_axes=None,\n        keys=None,\n        levels=None,\n        names=None,\n        ignore_index=False,\n        verify_integrity=False,\n        copy=True,\n        sort=False,\n    ):\n        if isinstance(objs, (NDFrame, str)):\n            raise TypeError(\n                \"first argument must be an iterable of pandas \"\n                \"objects, you passed an object of type \"\n                '\"{name}\"'.format(name=type(objs).__name__)\n            )\n\n        if join == \"outer\":\n            self.intersect = False\n        elif join == \"inner\":\n            self.intersect = True\n        else:  # pragma: no cover\n            raise ValueError(\n                \"Only can inner (intersect) or outer (union) join the other axis\"\n            )\n\n        if isinstance(objs, dict):\n            if keys is None:\n                keys = com.dict_keys_to_ordered_list(objs)\n            objs = [objs[k] for k in keys]\n        else:\n            objs = list(objs)\n\n        if len(objs) == 0:\n            raise ValueError(\"No objects to concatenate\")\n\n        if keys is None:\n            objs = list(com.not_none(*objs))\n        else:\n            # #1649\n            clean_keys = []\n            clean_objs = []\n            for k, v in zip(keys, objs):\n                if v is None:\n                    continue\n                clean_keys.append(k)\n                clean_objs.append(v)\n            objs = clean_objs\n            name = getattr(keys, \"name\", None)\n            keys = Index(clean_keys, name=name)\n\n        if len(objs) == 0:\n            raise ValueError(\"All objects passed were None\")\n\n        # consolidate data & figure out what our result ndim is going to be\n        ndims = set()\n        for obj in objs:\n            if not isinstance(obj, (Series, DataFrame)):\n                msg = (\n                    \"cannot concatenate object of type '{}';\"\n                    \" only Series and DataFrame objs are valid\".format(type(obj))\n                )\n                raise TypeError(msg)\n\n            # consolidate\n            obj._consolidate(inplace=True)\n            ndims.add(obj.ndim)\n\n        # get the sample\n        # want the highest ndim that we have, and must be non-empty\n        # unless all objs are empty\n        sample = None\n        if len(ndims) > 1:\n            max_ndim = max(ndims)\n            for obj in objs:\n                if obj.ndim == max_ndim and np.sum(obj.shape):\n                    sample = obj\n                    break\n\n        else:\n            # filter out the empties if we have not multi-index possibilities\n            # note to keep empty Series as it affect to result columns / name\n            non_empties = [\n                obj for obj in objs if sum(obj.shape) > 0 or isinstance(obj, Series)\n            ]\n\n            if len(non_empties) and (\n                keys is None and names is None and levels is None and not self.intersect\n            ):\n                objs = non_empties\n                sample = objs[0]\n\n        if sample is None:\n            sample = objs[0]\n        self.objs = objs\n\n        # Standardize axis parameter to int\n        if isinstance(sample, Series):\n            axis = DataFrame._get_axis_number(axis)\n        else:\n            axis = sample._get_axis_number(axis)\n\n        # Need to flip BlockManager axis in the DataFrame special case\n        self._is_frame = isinstance(sample, DataFrame)\n        if self._is_frame:\n            axis = 1 if axis == 0 else 0\n\n        self._is_series = isinstance(sample, Series)\n        if not 0 <= axis <= sample.ndim:\n            raise AssertionError(\n                \"axis must be between 0 and {ndim}, input was\"\n                \" {axis}\".format(ndim=sample.ndim, axis=axis)\n            )\n\n        # if we have mixed ndims, then convert to highest ndim\n        # creating column numbers as needed\n        if len(ndims) > 1:\n            current_column = 0\n            max_ndim = sample.ndim\n            self.objs, objs = [], self.objs\n            for obj in objs:\n\n                ndim = obj.ndim\n                if ndim == max_ndim:\n                    pass\n\n                elif ndim != max_ndim - 1:\n                    raise ValueError(\n                        \"cannot concatenate unaligned mixed \"\n                        \"dimensional NDFrame objects\"\n                    )\n\n                else:\n                    name = getattr(obj, \"name\", None)\n                    if ignore_index or name is None:\n                        name = current_column\n                        current_column += 1\n\n                    # doing a row-wise concatenation so need everything\n                    # to line up\n                    if self._is_frame and axis == 1:\n                        name = 0\n                    obj = sample._constructor({name: obj})\n\n                self.objs.append(obj)\n\n        # note: this is the BlockManager axis (since DataFrame is transposed)\n        self.axis = axis\n        self.join_axes = join_axes\n        self.keys = keys\n        self.names = names or getattr(keys, \"names\", None)\n        self.levels = levels\n        self.sort = sort\n\n        self.ignore_index = ignore_index\n        self.verify_integrity = verify_integrity\n        self.copy = copy\n\n        self.new_axes = self._get_new_axes()",
        "begin_line": 266,
        "end_line": 428,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator.get_result#430",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator.get_result(self)",
        "snippet": "    def get_result(self):\n\n        # series only\n        if self._is_series:\n\n            # stack blocks\n            if self.axis == 0:\n                name = com.consensus_name_attr(self.objs)\n\n                mgr = self.objs[0]._data.concat(\n                    [x._data for x in self.objs], self.new_axes\n                )\n                cons = _get_series_result_type(mgr, self.objs)\n                return cons(mgr, name=name).__finalize__(self, method=\"concat\")\n\n            # combine as columns in a frame\n            else:\n                data = dict(zip(range(len(self.objs)), self.objs))\n                cons = _get_series_result_type(data)\n\n                index, columns = self.new_axes\n                df = cons(data, index=index)\n                df.columns = columns\n                return df.__finalize__(self, method=\"concat\")\n\n        # combine block managers\n        else:\n            mgrs_indexers = []\n            for obj in self.objs:\n                mgr = obj._data\n                indexers = {}\n                for ax, new_labels in enumerate(self.new_axes):\n                    if ax == self.axis:\n                        # Suppress reindexing on concat axis\n                        continue\n\n                    obj_labels = mgr.axes[ax]\n                    if not new_labels.equals(obj_labels):\n                        indexers[ax] = obj_labels.reindex(new_labels)[1]\n\n                mgrs_indexers.append((obj._data, indexers))\n\n            new_data = concatenate_block_managers(\n                mgrs_indexers, self.new_axes, concat_axis=self.axis, copy=self.copy\n            )\n            if not self.copy:\n                new_data._consolidate_inplace()\n\n            cons = _get_frame_result_type(new_data, self.objs)\n            return cons._from_axes(new_data, self.new_axes).__finalize__(\n                self, method=\"concat\"\n            )",
        "begin_line": 430,
        "end_line": 481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator._get_result_dim#483",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator._get_result_dim(self)",
        "snippet": "    def _get_result_dim(self):\n        if self._is_series and self.axis == 1:\n            return 2\n        else:\n            return self.objs[0].ndim",
        "begin_line": 483,
        "end_line": 487,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator._get_new_axes#489",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator._get_new_axes(self)",
        "snippet": "    def _get_new_axes(self):\n        ndim = self._get_result_dim()\n        new_axes = [None] * ndim\n\n        if self.join_axes is None:\n            for i in range(ndim):\n                if i == self.axis:\n                    continue\n                new_axes[i] = self._get_comb_axis(i)\n\n        else:\n            # GH 21951\n            warnings.warn(\n                \"The join_axes-keyword is deprecated. Use .reindex or \"\n                \".reindex_like on the result to achieve the same \"\n                \"functionality.\",\n                FutureWarning,\n                stacklevel=4,\n            )\n\n            if len(self.join_axes) != ndim - 1:\n                raise AssertionError(\n                    \"length of join_axes must be equal \"\n                    \"to {length}\".format(length=ndim - 1)\n                )\n\n            # ufff...\n            indices = list(range(ndim))\n            indices.remove(self.axis)\n\n            for i, ax in zip(indices, self.join_axes):\n                new_axes[i] = ax\n\n        new_axes[self.axis] = self._get_concat_axis()\n        return new_axes",
        "begin_line": 489,
        "end_line": 523,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator._get_concat_axis#535",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator._get_concat_axis(self)",
        "snippet": "    def _get_concat_axis(self):\n        \"\"\"\n        Return index to be used along concatenation axis.\n        \"\"\"\n        if self._is_series:\n            if self.axis == 0:\n                indexes = [x.index for x in self.objs]\n            elif self.ignore_index:\n                idx = ibase.default_index(len(self.objs))\n                return idx\n            elif self.keys is None:\n                names = [None] * len(self.objs)\n                num = 0\n                has_names = False\n                for i, x in enumerate(self.objs):\n                    if not isinstance(x, Series):\n                        raise TypeError(\n                            \"Cannot concatenate type 'Series' \"\n                            \"with object of type {type!r}\".format(type=type(x).__name__)\n                        )\n                    if x.name is not None:\n                        names[i] = x.name\n                        has_names = True\n                    else:\n                        names[i] = num\n                        num += 1\n                if has_names:\n                    return Index(names)\n                else:\n                    return ibase.default_index(len(self.objs))\n            else:\n                return ensure_index(self.keys).set_names(self.names)\n        else:\n            indexes = [x._data.axes[self.axis] for x in self.objs]\n\n        if self.ignore_index:\n            idx = ibase.default_index(sum(len(i) for i in indexes))\n            return idx\n\n        if self.keys is None:\n            concat_axis = _concat_indexes(indexes)\n        else:\n            concat_axis = _make_concat_multiindex(\n                indexes, self.keys, self.levels, self.names\n            )\n\n        self._maybe_check_integrity(concat_axis)\n\n        return concat_axis",
        "begin_line": 535,
        "end_line": 583,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.reshape.concat._Concatenator._maybe_check_integrity#585",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat._Concatenator",
        "signature": "pandas.core.reshape.concat._Concatenator._maybe_check_integrity(self, concat_index)",
        "snippet": "    def _maybe_check_integrity(self, concat_index):\n        if self.verify_integrity:\n            if not concat_index.is_unique:\n                overlap = concat_index[concat_index.duplicated()].unique()\n                raise ValueError(\n                    \"Indexes have overlapping values: \"\n                    \"{overlap!s}\".format(overlap=overlap)\n                )",
        "begin_line": 585,
        "end_line": 592,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.reshape.concat._concat_indexes#595",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat",
        "signature": "pandas.core.reshape.concat._concat_indexes(indexes)",
        "snippet": "def _concat_indexes(indexes):\n    return indexes[0].append(indexes[1:])",
        "begin_line": 595,
        "end_line": 596,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.reshape.concat._get_series_result_type#713",
        "src_path": "pandas/core/reshape/concat.py",
        "class_name": "pandas.core.reshape.concat",
        "signature": "pandas.core.reshape.concat._get_series_result_type(result, objs=None)",
        "snippet": "def _get_series_result_type(result, objs=None):\n    \"\"\"\n    return appropriate class of Series concat\n    input is either dict or array-like\n    \"\"\"\n    from pandas import SparseSeries, SparseDataFrame, DataFrame\n\n    # concat Series with axis 1\n    if isinstance(result, dict):\n        # concat Series with axis 1\n        if all(isinstance(c, (SparseSeries, SparseDataFrame)) for c in result.values()):\n            return SparseDataFrame\n        else:\n            return DataFrame\n\n    # otherwise it is a SingleBlockManager (axis = 0)\n    return objs[0]._constructor",
        "begin_line": 713,
        "end_line": 729,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.shape#688",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.shape(self)",
        "snippet": "    def shape(self):\n        \"\"\"\n        Return a tuple of the shape of the underlying data.\n        \"\"\"\n        return self._values.shape",
        "begin_line": 688,
        "end_line": 692,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.ndim#695",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.ndim(self)",
        "snippet": "    def ndim(self):\n        \"\"\"\n        Number of dimensions of the underlying data, by definition 1.\n        \"\"\"\n        return 1",
        "begin_line": 695,
        "end_line": 699,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.array#809",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.array(self)",
        "snippet": "    def array(self) -> ExtensionArray:\n        \"\"\"\n        The ExtensionArray of the data backing this Series or Index.\n\n        .. versionadded:: 0.24.0\n\n        Returns\n        -------\n        ExtensionArray\n            An ExtensionArray of the values stored within. For extension\n            types, this is the actual array. For NumPy native types, this\n            is a thin (no copy) wrapper around :class:`numpy.ndarray`.\n\n            ``.array`` differs ``.values`` which may require converting the\n            data to a different form.\n\n        See Also\n        --------\n        Index.to_numpy : Similar method that always returns a NumPy array.\n        Series.to_numpy : Similar method that always returns a NumPy array.\n\n        Notes\n        -----\n        This table lays out the different array types for each extension\n        dtype within pandas.\n\n        ================== =============================\n        dtype              array type\n        ================== =============================\n        category           Categorical\n        period             PeriodArray\n        interval           IntervalArray\n        IntegerNA          IntegerArray\n        datetime64[ns, tz] DatetimeArray\n        ================== =============================\n\n        For any 3rd-party extension types, the array type will be an\n        ExtensionArray.\n\n        For all remaining dtypes ``.array`` will be a\n        :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\n        stored within. If you absolutely need a NumPy array (possibly with\n        copying / coercing data), then use :meth:`Series.to_numpy` instead.\n\n        Examples\n        --------\n\n        For regular NumPy types like int, and float, a PandasArray\n        is returned.\n\n        >>> pd.Series([1, 2, 3]).array\n        <PandasArray>\n        [1, 2, 3]\n        Length: 3, dtype: int64\n\n        For extension types, like Categorical, the actual ExtensionArray\n        is returned\n\n        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n        >>> ser.array\n        [a, b, a]\n        Categories (2, object): [a, b]\n        \"\"\"\n        # As a mixin, we depend on the mixing class having _values.\n        # Special mixin syntax may be developed in the future:\n        # https://github.com/python/typing/issues/246\n        result = self._values  # type: ignore\n\n        if is_datetime64_ns_dtype(result.dtype):\n            from pandas.arrays import DatetimeArray\n\n            result = DatetimeArray(result)\n        elif is_timedelta64_ns_dtype(result.dtype):\n            from pandas.arrays import TimedeltaArray\n\n            result = TimedeltaArray(result)\n\n        elif not is_extension_array_dtype(result.dtype):\n            from pandas.core.arrays.numpy_ import PandasArray\n\n            result = PandasArray(result)\n\n        return result",
        "begin_line": 809,
        "end_line": 891,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin._ndarray_values#990",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin._ndarray_values(self)",
        "snippet": "    def _ndarray_values(self) -> np.ndarray:\n        \"\"\"\n        The data as an ndarray, possibly losing information.\n\n        The expectation is that this is cheap to compute, and is primarily\n        used for interacting with our indexers.\n\n        - categorical -> codes\n        \"\"\"\n        if is_extension_array_dtype(self):\n            return self.array._ndarray_values\n        # As a mixin, we depend on the mixing class having values.\n        # Special mixin syntax may be developed in the future:\n        # https://github.com/python/typing/issues/246\n        return self.values  # type: ignore",
        "begin_line": 990,
        "end_line": 1004,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.__iter__#1162",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.__iter__(self)",
        "snippet": "    def __iter__(self):\n        \"\"\"\n        Return an iterator of the values.\n\n        These are each a scalar type, which is a Python scalar\n        (for str, int, float) or a pandas scalar\n        (for Timestamp/Timedelta/Interval/Period)\n\n        Returns\n        -------\n        iterator\n        \"\"\"\n        # We are explicitly making element iterators.\n        if is_datetimelike(self._values):\n            return map(com.maybe_box_datetimelike, self._values)\n        elif is_extension_array_dtype(self._values):\n            return iter(self._values)\n        else:\n            return map(self._values.item, range(self._values.size))",
        "begin_line": 1162,
        "end_line": 1180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.ops.missing.fill_zeros#33",
        "src_path": "pandas/core/ops/missing.py",
        "class_name": "pandas.core.ops.missing",
        "signature": "pandas.core.ops.missing.fill_zeros(result, x, y, name, fill)",
        "snippet": "def fill_zeros(result, x, y, name, fill):\n    \"\"\"\n    If this is a reversed op, then flip x,y\n\n    If we have an integer value (or array in y)\n    and we have 0's, fill them with the fill,\n    return the result.\n\n    Mask the nan's from x.\n    \"\"\"\n    if fill is None or is_float_dtype(result):\n        return result\n\n    if name.startswith((\"r\", \"__r\")):\n        x, y = y, x\n\n    is_variable_type = hasattr(y, \"dtype\") or hasattr(y, \"type\")\n    is_scalar_type = is_scalar(y)\n\n    if not is_variable_type and not is_scalar_type:\n        return result\n\n    if is_scalar_type:\n        y = np.array(y)\n\n    if is_integer_dtype(y):\n\n        if (y == 0).any():\n\n            # GH#7325, mask and nans must be broadcastable (also: GH#9308)\n            # Raveling and then reshaping makes np.putmask faster\n            mask = ((y == 0) & ~np.isnan(result)).ravel()\n\n            shape = result.shape\n            result = result.astype(\"float64\", copy=False).ravel()\n\n            np.putmask(result, mask, fill)\n\n            # if we have a fill of inf, then sign it correctly\n            # (GH#6178 and GH#9308)\n            if np.isinf(fill):\n                signs = y if name.startswith((\"r\", \"__r\")) else x\n                signs = np.sign(signs.astype(\"float\", copy=False))\n                negative_inf_mask = (signs.ravel() < 0) & mask\n                np.putmask(result, negative_inf_mask, -fill)\n\n            if \"floordiv\" in name:  # (GH#9308)\n                nan_mask = ((y == 0) & (x == 0)).ravel()\n                np.putmask(result, nan_mask, np.nan)\n\n            result = result.reshape(shape)\n\n    return result",
        "begin_line": 33,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.000543773790103317,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.ops.missing.dispatch_fill_zeros#151",
        "src_path": "pandas/core/ops/missing.py",
        "class_name": "pandas.core.ops.missing",
        "signature": "pandas.core.ops.missing.dispatch_fill_zeros(op, left, right, result)",
        "snippet": "def dispatch_fill_zeros(op, left, right, result):\n    \"\"\"\n    Call fill_zeros with the appropriate fill value depending on the operation,\n    with special logic for divmod and rdivmod.\n\n    Parameters\n    ----------\n    op : function (operator.add, operator.div, ...)\n    left : object (np.ndarray for non-reversed ops)\n    right : object (np.ndarray for reversed ops)\n    result : ndarray\n\n    Returns\n    -------\n    result : np.ndarray\n\n    Notes\n    -----\n    For divmod and rdivmod, the `result` parameter and returned `result`\n    is a 2-tuple of ndarray objects.\n    \"\"\"\n    if op is divmod:\n        result = (\n            mask_zero_div_zero(left, right, result[0]),\n            fill_zeros(result[1], left, right, \"__mod__\", np.nan),\n        )\n    elif op is rdivmod:\n        result = (\n            mask_zero_div_zero(right, left, result[0]),\n            fill_zeros(result[1], left, right, \"__rmod__\", np.nan),\n        )\n    elif op is operator.floordiv:\n        # Note: no need to do this for truediv; in py3 numpy behaves the way\n        #  we want.\n        result = mask_zero_div_zero(left, right, result)\n    elif op is op is rfloordiv:\n        # Note: no need to do this for rtruediv; in py3 numpy behaves the way\n        #  we want.\n        result = mask_zero_div_zero(right, left, result)\n    elif op is operator.mod:\n        result = fill_zeros(result, left, right, \"__mod__\", np.nan)\n    elif op is rmod:\n        result = fill_zeros(result, left, right, \"__rmod__\", np.nan)\n    return result",
        "begin_line": 151,
        "end_line": 194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasDtype.__init__#41",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasDtype",
        "signature": "pandas.core.arrays.numpy_.PandasDtype.__init__(self, dtype)",
        "snippet": "    def __init__(self, dtype):\n        dtype = np.dtype(dtype)\n        self._dtype = dtype\n        self._name = dtype.name\n        self._type = dtype.type",
        "begin_line": 41,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.__init__#124",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.__init__(self, values, copy=False)",
        "snippet": "    def __init__(self, values, copy=False):\n        if isinstance(values, type(self)):\n            values = values._ndarray\n        if not isinstance(values, np.ndarray):\n            raise ValueError(\n                \"'values' must be a NumPy array, not {typ}\".format(\n                    typ=type(values).__name__\n                )\n            )\n\n        if values.ndim != 1:\n            raise ValueError(\"PandasArray must be 1-dimensional.\")\n\n        if copy:\n            values = values.copy()\n\n        self._ndarray = values\n        self._dtype = PandasDtype(values.dtype)",
        "begin_line": 124,
        "end_line": 141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.to_numpy#408",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.to_numpy(self, dtype=None, copy=False)",
        "snippet": "    def to_numpy(self, dtype=None, copy=False):\n        \"\"\"\n        Convert the PandasArray to a :class:`numpy.ndarray`.\n\n        By default, this requires no coercion or copying of data.\n\n        Parameters\n        ----------\n        dtype : numpy.dtype\n            The NumPy dtype to pass to :func:`numpy.asarray`.\n        copy : bool, default False\n            Whether to copy the underlying data.\n\n        Returns\n        -------\n        ndarray\n        \"\"\"\n        result = np.asarray(self._ndarray, dtype=dtype)\n        if copy and result is self._ndarray:\n            result = result.copy()\n\n        return result",
        "begin_line": 408,
        "end_line": 429,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.common.consensus_name_attr#64",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.consensus_name_attr(objs)",
        "snippet": "def consensus_name_attr(objs):\n    name = objs[0].name\n    for obj in objs[1:]:\n        try:\n            if obj.name != name:\n                name = None\n        except ValueError:\n            name = None\n    return name",
        "begin_line": 64,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.common.is_bool_indexer#99",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.is_bool_indexer(key: Any)",
        "snippet": "def is_bool_indexer(key: Any) -> bool:\n    \"\"\"\n    Check whether `key` is a valid boolean indexer.\n\n    Parameters\n    ----------\n    key : Any\n        Only list-likes may be considered boolean indexers.\n        All other types are not considered a boolean indexer.\n        For array-like input, boolean ndarrays or ExtensionArrays\n        with ``_is_boolean`` set are considered boolean indexers.\n\n    Returns\n    -------\n    bool\n\n    Raises\n    ------\n    ValueError\n        When the array is an object-dtype ndarray or ExtensionArray\n        and contains missing values.\n    \"\"\"\n    na_msg = \"cannot index with vector containing NA / NaN values\"\n    if isinstance(key, (ABCSeries, np.ndarray, ABCIndex)) or (\n        is_array_like(key) and is_extension_array_dtype(key.dtype)\n    ):\n        if key.dtype == np.object_:\n            key = np.asarray(values_from_object(key))\n\n            if not lib.is_bool_array(key):\n                if isna(key).any():\n                    raise ValueError(na_msg)\n                return False\n            return True\n        elif is_bool_dtype(key.dtype):\n            # an ndarray with bool-dtype by definition has no missing values.\n            # So we only need to check for NAs in ExtensionArrays\n            if is_extension_array_dtype(key.dtype):\n                if np.any(key.isna()):\n                    raise ValueError(na_msg)\n            return True\n    elif isinstance(key, list):\n        try:\n            arr = np.asarray(key)\n            return arr.dtype == np.bool_ and len(arr) == len(key)\n        except TypeError:  # pragma: no cover\n            return False\n\n    return False",
        "begin_line": 99,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.common.cast_scalar_indexer#150",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.cast_scalar_indexer(val)",
        "snippet": "def cast_scalar_indexer(val):\n    \"\"\"\n    To avoid numpy DeprecationWarnings, cast float to integer where valid.\n\n    Parameters\n    ----------\n    val : scalar\n\n    Returns\n    -------\n    outval : scalar\n    \"\"\"\n    # assumes lib.is_scalar(val)\n    if lib.is_float(val) and val == int(val):\n        return int(val)\n    return val",
        "begin_line": 150,
        "end_line": 165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.common.not_none#168",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.not_none(*args)",
        "snippet": "def not_none(*args):\n    \"\"\"\n    Returns a generator consisting of the arguments that are not None.\n    \"\"\"\n    return (arg for arg in args if arg is not None)",
        "begin_line": 168,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.common.dict_keys_to_ordered_list#218",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.dict_keys_to_ordered_list(mapping)",
        "snippet": "def dict_keys_to_ordered_list(mapping):\n    # when pandas drops support for Python < 3.6, this function\n    # can be replaced by a simple list(mapping.keys())\n    if PY36 or isinstance(mapping, OrderedDict):\n        keys = list(mapping.keys())\n    else:\n        keys = try_sort(mapping)\n    return keys",
        "begin_line": 218,
        "end_line": 225,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.common.asarray_tuplesafe#228",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.asarray_tuplesafe(values, dtype=None)",
        "snippet": "def asarray_tuplesafe(values, dtype=None):\n\n    if not (isinstance(values, (list, tuple)) or hasattr(values, \"__array__\")):\n        values = list(values)\n    elif isinstance(values, ABCIndexClass):\n        return values.values\n\n    if isinstance(values, list) and dtype in [np.object_, object]:\n        return construct_1d_object_array_from_listlike(values)\n\n    result = np.asarray(values, dtype=dtype)\n\n    if issubclass(result.dtype.type, str):\n        result = np.asarray(values, dtype=object)\n\n    if result.ndim == 2:\n        # Avoid building an array of arrays:\n        values = [tuple(x) for x in values]\n        result = construct_1d_object_array_from_listlike(values)\n\n    return result",
        "begin_line": 228,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.common.maybe_iterable_to_list#284",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.maybe_iterable_to_list(obj: Union[Iterable, Any])",
        "snippet": "def maybe_iterable_to_list(obj: Union[Iterable, Any]) -> Union[list, Any]:\n    \"\"\"\n    If obj is Iterable but not list-like, consume into list.\n    \"\"\"\n    if isinstance(obj, abc.Iterable) and not isinstance(obj, abc.Sized):\n        return list(obj)\n    return obj",
        "begin_line": 284,
        "end_line": 290,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.common.is_null_slice#293",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.is_null_slice(obj)",
        "snippet": "def is_null_slice(obj):\n    \"\"\"\n    We have a null slice.\n    \"\"\"\n    return (\n        isinstance(obj, slice)\n        and obj.start is None\n        and obj.stop is None\n        and obj.step is None\n    )",
        "begin_line": 293,
        "end_line": 302,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.common.apply_if_callable#339",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.apply_if_callable(maybe_callable, obj, **kwargs)",
        "snippet": "def apply_if_callable(maybe_callable, obj, **kwargs):\n    \"\"\"\n    Evaluate possibly callable input using obj and kwargs if it is callable,\n    otherwise return as it is.\n\n    Parameters\n    ----------\n    maybe_callable : possibly a callable\n    obj : NDFrame\n    **kwargs\n    \"\"\"\n\n    if callable(maybe_callable):\n        return maybe_callable(obj, **kwargs)\n\n    return maybe_callable",
        "begin_line": 339,
        "end_line": 354,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_number#29",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_number(obj)",
        "snippet": "def is_number(obj):\n    \"\"\"\n    Check if the object is a number.\n\n    Returns True when the object is a number, and False if is not.\n\n    Parameters\n    ----------\n    obj : any type\n        The object to check if is a number.\n\n    Returns\n    -------\n    is_number : bool\n        Whether `obj` is a number or not.\n\n    See Also\n    --------\n    api.types.is_integer: Checks a subgroup of numbers.\n\n    Examples\n    --------\n    >>> pd.api.types.is_number(1)\n    True\n    >>> pd.api.types.is_number(7.15)\n    True\n\n    Booleans are valid because they are int subclass.\n\n    >>> pd.api.types.is_number(False)\n    True\n\n    >>> pd.api.types.is_number(\"foo\")\n    False\n    >>> pd.api.types.is_number(\"5\")\n    False\n    \"\"\"\n\n    return isinstance(obj, (Number, np.number))",
        "begin_line": 29,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_iterator#120",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_iterator(obj)",
        "snippet": "def is_iterator(obj):\n    \"\"\"\n    Check if the object is an iterator.\n\n    For example, lists are considered iterators\n    but not strings or datetime objects.\n\n    Parameters\n    ----------\n    obj : The object to check\n\n    Returns\n    -------\n    is_iter : bool\n        Whether `obj` is an iterator.\n\n    Examples\n    --------\n    >>> is_iterator([1, 2, 3])\n    True\n    >>> is_iterator(datetime(2017, 1, 1))\n    False\n    >>> is_iterator(\"foo\")\n    False\n    >>> is_iterator(1)\n    False\n    \"\"\"\n\n    if not hasattr(obj, \"__iter__\"):\n        return False\n\n    return hasattr(obj, \"__next__\")",
        "begin_line": 120,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_array_like#246",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_array_like(obj)",
        "snippet": "def is_array_like(obj):\n    \"\"\"\n    Check if the object is array-like.\n\n    For an object to be considered array-like, it must be list-like and\n    have a `dtype` attribute.\n\n    Parameters\n    ----------\n    obj : The object to check\n\n    Returns\n    -------\n    is_array_like : bool\n        Whether `obj` has array-like properties.\n\n    Examples\n    --------\n    >>> is_array_like(np.array([1, 2, 3]))\n    True\n    >>> is_array_like(pd.Series([\"a\", \"b\"]))\n    True\n    >>> is_array_like(pd.Index([\"2016-01-01\"]))\n    True\n    >>> is_array_like([1, 2, 3])\n    False\n    >>> is_array_like((\"a\", \"b\"))\n    False\n    \"\"\"\n\n    return is_list_like(obj) and hasattr(obj, \"dtype\")",
        "begin_line": 246,
        "end_line": 276,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_hashable#386",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_hashable(obj)",
        "snippet": "def is_hashable(obj):\n    \"\"\"\n    Return True if hash(obj) will succeed, False otherwise.\n\n    Some types will pass a test against collections.abc.Hashable but fail when\n    they are actually hashed with hash().\n\n    Distinguish between these and other types by trying the call to hash() and\n    seeing if they raise TypeError.\n\n    Returns\n    -------\n    bool\n\n    Examples\n    --------\n    >>> a = ([],)\n    >>> isinstance(a, collections.abc.Hashable)\n    True\n    >>> is_hashable(a)\n    False\n    \"\"\"\n    # Unfortunately, we can't use isinstance(obj, collections.abc.Hashable),\n    # which can be faster than calling hash. That is because numpy scalars\n    # fail this test.\n\n    # Reconsider this decision once this numpy bug is fixed:\n    # https://github.com/numpy/numpy/issues/5562\n\n    try:\n        hash(obj)\n    except TypeError:\n        return False\n    else:\n        return True",
        "begin_line": 386,
        "end_line": 420,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_sequence#423",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_sequence(obj)",
        "snippet": "def is_sequence(obj):\n    \"\"\"\n    Check if the object is a sequence of objects.\n    String types are not included as sequences here.\n\n    Parameters\n    ----------\n    obj : The object to check\n\n    Returns\n    -------\n    is_sequence : bool\n        Whether `obj` is a sequence of objects.\n\n    Examples\n    --------\n    >>> l = [1, 2, 3]\n    >>>\n    >>> is_sequence(l)\n    True\n    >>> is_sequence(iter(l))\n    False\n    \"\"\"\n\n    try:\n        iter(obj)  # Can iterate over it.\n        len(obj)  # Has a length associated with it.\n        return not isinstance(obj, (str, bytes))\n    except (TypeError, AttributeError):\n        return False",
        "begin_line": 423,
        "end_line": 452,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._simple_new#149",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._simple_new(cls, values, name=None, dtype=None, **kwargs)",
        "snippet": "    def _simple_new(cls, values, name=None, dtype=None, **kwargs):\n        result = object.__new__(cls)\n\n        # handle passed None, non-integers\n        if values is None:\n            # empty\n            values = range(0, 0, 1)\n        elif not isinstance(values, range):\n            return Index(values, dtype=dtype, name=name, **kwargs)\n\n        result._range = values\n\n        result.name = name\n        for k, v in kwargs.items():\n            setattr(result, k, v)\n\n        result._reset_identity()\n        return result",
        "begin_line": 149,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.013513513513513514,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.0008718395815170009,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.0008718395815170009
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._data#182",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._data(self)",
        "snippet": "    def _data(self):\n        \"\"\"\n        An int array that for performance reasons is created only when needed.\n\n        The constructed array is saved in ``_cached_data``. This allows us to\n        check if the array has been created without accessing ``_data`` and\n        triggering the construction.\n        \"\"\"\n        if self._cached_data is None:\n            self._cached_data = np.arange(\n                self.start, self.stop, self.step, dtype=np.int64\n            )\n        return self._cached_data",
        "begin_line": 182,
        "end_line": 194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.start#237",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.start(self)",
        "snippet": "    def start(self):\n        \"\"\"\n        The value of the `start` parameter (``0`` if this was not supplied)\n        \"\"\"\n        # GH 25710\n        return self._range.start",
        "begin_line": 237,
        "end_line": 242,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.stop#260",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.stop(self)",
        "snippet": "    def stop(self):\n        \"\"\"\n        The value of the `stop` parameter\n        \"\"\"\n        return self._range.stop",
        "begin_line": 260,
        "end_line": 264,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.step#283",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.step(self)",
        "snippet": "    def step(self):\n        \"\"\"\n        The value of the `step` parameter (``1`` if this was not supplied)\n        \"\"\"\n        # GH 25710\n        return self._range.step",
        "begin_line": 283,
        "end_line": 288,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.dtype#343",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.dtype(self)",
        "snippet": "    def dtype(self):\n        return np.dtype(np.int64)",
        "begin_line": 343,
        "end_line": 344,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.is_unique#347",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.is_unique(self)",
        "snippet": "    def is_unique(self):\n        \"\"\" return if the index has unique values \"\"\"\n        return True",
        "begin_line": 347,
        "end_line": 349,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._shallow_copy#411",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._shallow_copy(self, values=None, **kwargs)",
        "snippet": "    def _shallow_copy(self, values=None, **kwargs):\n        if values is None:\n            name = kwargs.get(\"name\", self.name)\n            return self._simple_new(self._range, name=name)\n        else:\n            kwargs.setdefault(\"name\", self.name)\n            return self._int64index._shallow_copy(values, **kwargs)",
        "begin_line": 411,
        "end_line": 417,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.equals#467",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.equals(self, other)",
        "snippet": "    def equals(self, other):\n        \"\"\"\n        Determines if two Index objects contain the same elements.\n        \"\"\"\n        if isinstance(other, RangeIndex):\n            return self._range == other._range\n        return super().equals(other)",
        "begin_line": 467,
        "end_line": 473,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._concat_same_dtype#649",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._concat_same_dtype(self, indexes, name)",
        "snippet": "    def _concat_same_dtype(self, indexes, name):\n        \"\"\"\n        Concatenates multiple RangeIndex instances. All members of \"indexes\" must\n        be of type RangeIndex; result will be RangeIndex if possible, Int64Index\n        otherwise. E.g.:\n        indexes = [RangeIndex(3), RangeIndex(3, 6)] -> RangeIndex(6)\n        indexes = [RangeIndex(3), RangeIndex(4, 6)] -> Int64Index([0,1,2,4,5])\n        \"\"\"\n        start = step = next_ = None\n\n        # Filter the empty indexes\n        non_empty_indexes = [obj for obj in indexes if len(obj)]\n\n        for obj in non_empty_indexes:\n            rng = obj._range  # type: range\n\n            if start is None:\n                # This is set by the first non-empty index\n                start = rng.start\n                if step is None and len(rng) > 1:\n                    step = rng.step\n            elif step is None:\n                # First non-empty index had only one element\n                if rng.start == start:\n                    result = Int64Index(np.concatenate([x._values for x in indexes]))\n                    return result.rename(name)\n\n                step = rng.start - start\n\n            non_consecutive = (step != rng.step and len(rng) > 1) or (\n                next_ is not None and rng.start != next_\n            )\n            if non_consecutive:\n                result = Int64Index(np.concatenate([x._values for x in indexes]))\n                return result.rename(name)\n\n            if step is not None:\n                next_ = rng[-1] + step\n\n        if non_empty_indexes:\n            # Get the stop value from \"next\" or alternatively\n            # from the last non-empty index\n            stop = non_empty_indexes[-1].stop if next_ is None else next_\n            return RangeIndex(start, stop, step).rename(name)\n\n        # Here all \"indexes\" had 0 length, i.e. were empty.\n        # In this case return an empty range index.\n        return RangeIndex(0, 0).rename(name)",
        "begin_line": 649,
        "end_line": 696,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.__len__#698",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.__len__(self)",
        "snippet": "    def __len__(self):\n        \"\"\"\n        return the length of the RangeIndex\n        \"\"\"\n        return len(self._range)",
        "begin_line": 698,
        "end_line": 702,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.__getitem__#708",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        \"\"\"\n        Conserve RangeIndex type for scalar and slice keys.\n        \"\"\"\n        if isinstance(key, slice):\n            new_range = self._range[key]\n            return self._simple_new(new_range, name=self.name)\n        elif is_integer(key):\n            new_key = int(key)\n            try:\n                return self._range[new_key]\n            except IndexError:\n                raise IndexError(\n                    \"index {key} is out of bounds for axis 0 \"\n                    \"with size {size}\".format(key=key, size=len(self))\n                )\n        elif is_scalar(key):\n            raise IndexError(\n                \"only integers, slices (`:`), \"\n                \"ellipsis (`...`), numpy.newaxis (`None`) \"\n                \"and integer or boolean \"\n                \"arrays are valid indices\"\n            )\n        # fall back to Int64Index\n        return super().__getitem__(key)",
        "begin_line": 708,
        "end_line": 732,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.frozen.FrozenList.__eq__#89",
        "src_path": "pandas/core/indexes/frozen.py",
        "class_name": "pandas.core.indexes.frozen.FrozenList",
        "signature": "pandas.core.indexes.frozen.FrozenList.__eq__(self, other)",
        "snippet": "    def __eq__(self, other):\n        if isinstance(other, (tuple, FrozenList)):\n            other = list(other)\n        return super().__eq__(other)",
        "begin_line": 89,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter.__init__#229",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter.__init__(self, series: 'Series', buf: Optional[IO[str]]=None, length: bool=True, header: bool=True, index: bool=True, na_rep: str='NaN', name: bool=False, float_format: Optional[str]=None, dtype: bool=True, max_rows: Optional[int]=None, min_rows: Optional[int]=None)",
        "snippet": "    def __init__(\n        self,\n        series: \"Series\",\n        buf: Optional[IO[str]] = None,\n        length: bool = True,\n        header: bool = True,\n        index: bool = True,\n        na_rep: str = \"NaN\",\n        name: bool = False,\n        float_format: Optional[str] = None,\n        dtype: bool = True,\n        max_rows: Optional[int] = None,\n        min_rows: Optional[int] = None,\n    ):\n        self.series = series\n        self.buf = buf if buf is not None else StringIO()\n        self.name = name\n        self.na_rep = na_rep\n        self.header = header\n        self.length = length\n        self.index = index\n        self.max_rows = max_rows\n        self.min_rows = min_rows\n\n        if float_format is None:\n            float_format = get_option(\"display.float_format\")\n        self.float_format = float_format\n        self.dtype = dtype\n        self.adj = _get_adjustment()\n\n        self._chk_truncate()",
        "begin_line": 229,
        "end_line": 259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter._chk_truncate#261",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter._chk_truncate(self)",
        "snippet": "    def _chk_truncate(self) -> None:\n        from pandas.core.reshape.concat import concat\n\n        min_rows = self.min_rows\n        max_rows = self.max_rows\n        # truncation determined by max_rows, actual truncated number of rows\n        # used below by min_rows\n        truncate_v = max_rows and (len(self.series) > max_rows)\n        series = self.series\n        if truncate_v:\n            max_rows = cast(int, max_rows)\n            if min_rows:\n                # if min_rows is set (not None or 0), set max_rows to minimum\n                # of both\n                max_rows = min(min_rows, max_rows)\n            if max_rows == 1:\n                row_num = max_rows\n                series = series.iloc[:max_rows]\n            else:\n                row_num = max_rows // 2\n                series = concat((series.iloc[:row_num], series.iloc[-row_num:]))\n            self.tr_row_num = row_num  # type: Optional[int]\n        else:\n            self.tr_row_num = None\n        self.tr_series = series\n        self.truncate_v = truncate_v",
        "begin_line": 261,
        "end_line": 286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter._get_footer#288",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter._get_footer(self)",
        "snippet": "    def _get_footer(self) -> str:\n        name = self.series.name\n        footer = \"\"\n\n        if getattr(self.series.index, \"freq\", None) is not None:\n            footer += \"Freq: {freq}\".format(freq=self.series.index.freqstr)\n\n        if self.name is not False and name is not None:\n            if footer:\n                footer += \", \"\n\n            series_name = pprint_thing(name, escape_chars=(\"\\t\", \"\\r\", \"\\n\"))\n            footer += (\n                (\"Name: {sname}\".format(sname=series_name)) if name is not None else \"\"\n            )\n\n        if self.length is True or (self.length == \"truncate\" and self.truncate_v):\n            if footer:\n                footer += \", \"\n            footer += \"Length: {length}\".format(length=len(self.series))\n\n        if self.dtype is not False and self.dtype is not None:\n            name = getattr(self.tr_series.dtype, \"name\", None)\n            if name:\n                if footer:\n                    footer += \", \"\n                footer += \"dtype: {typ}\".format(typ=pprint_thing(name))\n\n        # level infos are added to the end and in a new line, like it is done\n        # for Categoricals\n        if is_categorical_dtype(self.tr_series.dtype):\n            level_info = self.tr_series._values._repr_categories_info()\n            if footer:\n                footer += \"\\n\"\n            footer += level_info\n\n        return str(footer)",
        "begin_line": 288,
        "end_line": 324,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter._get_formatted_index#326",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter._get_formatted_index(self)",
        "snippet": "    def _get_formatted_index(self) -> Tuple[List[str], bool]:\n        index = self.tr_series.index\n        is_multi = isinstance(index, ABCMultiIndex)\n\n        if is_multi:\n            have_header = any(name for name in index.names)\n            fmt_index = index.format(names=True)\n        else:\n            have_header = index.name is not None\n            fmt_index = index.format(name=True)\n        return fmt_index, have_header",
        "begin_line": 326,
        "end_line": 336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter._get_formatted_values#338",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter._get_formatted_values(self)",
        "snippet": "    def _get_formatted_values(self) -> List[str]:\n        return format_array(\n            self.tr_series._values,\n            None,\n            float_format=self.float_format,\n            na_rep=self.na_rep,\n        )",
        "begin_line": 338,
        "end_line": 344,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter.to_string#346",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter.to_string(self)",
        "snippet": "    def to_string(self) -> str:\n        series = self.tr_series\n        footer = self._get_footer()\n\n        if len(series) == 0:\n            return \"{name}([], {footer})\".format(\n                name=self.series.__class__.__name__, footer=footer\n            )\n\n        fmt_index, have_header = self._get_formatted_index()\n        fmt_values = self._get_formatted_values()\n\n        if self.truncate_v:\n            n_header_rows = 0\n            row_num = self.tr_row_num\n            row_num = cast(int, row_num)\n            width = self.adj.len(fmt_values[row_num - 1])\n            if width > 3:\n                dot_str = \"...\"\n            else:\n                dot_str = \"..\"\n            # Series uses mode=center because it has single value columns\n            # DataFrame uses mode=left\n            dot_str = self.adj.justify([dot_str], width, mode=\"center\")[0]\n            fmt_values.insert(row_num + n_header_rows, dot_str)\n            fmt_index.insert(row_num + 1, \"\")\n\n        if self.index:\n            result = self.adj.adjoin(3, *[fmt_index[1:], fmt_values])\n        else:\n            result = self.adj.adjoin(3, fmt_values)\n\n        if self.header and have_header:\n            result = fmt_index[0] + \"\\n\" + result\n\n        if footer:\n            result += \"\\n\" + footer\n\n        return str(\"\".join(result))",
        "begin_line": 346,
        "end_line": 384,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.TextAdjustment.__init__#388",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.TextAdjustment",
        "signature": "pandas.io.formats.format.TextAdjustment.__init__(self)",
        "snippet": "    def __init__(self):\n        self.encoding = get_option(\"display.encoding\")",
        "begin_line": 388,
        "end_line": 389,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.TextAdjustment.len#391",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.TextAdjustment",
        "signature": "pandas.io.formats.format.TextAdjustment.len(self, text: str)",
        "snippet": "    def len(self, text: str) -> int:\n        return len(text)",
        "begin_line": 391,
        "end_line": 392,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.TextAdjustment.justify#394",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.TextAdjustment",
        "signature": "pandas.io.formats.format.TextAdjustment.justify(self, texts: Any, max_len: int, mode: str='right')",
        "snippet": "    def justify(self, texts: Any, max_len: int, mode: str = \"right\") -> List[str]:\n        return justify(texts, max_len, mode=mode)",
        "begin_line": 394,
        "end_line": 395,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.TextAdjustment.adjoin#397",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.TextAdjustment",
        "signature": "pandas.io.formats.format.TextAdjustment.adjoin(self, space: int, *lists, **kwargs)",
        "snippet": "    def adjoin(self, space: int, *lists, **kwargs) -> str:\n        return adjoin(space, *lists, strlen=self.len, justfunc=self.justify, **kwargs)",
        "begin_line": 397,
        "end_line": 398,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format._get_adjustment#440",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format._get_adjustment()",
        "snippet": "def _get_adjustment() -> TextAdjustment:\n    use_east_asian_width = get_option(\"display.unicode.east_asian_width\")\n    if use_east_asian_width:\n        return EastAsianTextAdjustment()\n    else:\n        return TextAdjustment()",
        "begin_line": 440,
        "end_line": 445,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.format_array#1054",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format.format_array(values: Any, formatter: Optional[Callable], float_format: Optional[float_format_type]=None, na_rep: str='NaN', digits: Optional[int]=None, space: Optional[Union[str, int]]=None, justify: str='right', decimal: str='.', leading_space: Optional[bool]=None)",
        "snippet": "def format_array(\n    values: Any,\n    formatter: Optional[Callable],\n    float_format: Optional[float_format_type] = None,\n    na_rep: str = \"NaN\",\n    digits: Optional[int] = None,\n    space: Optional[Union[str, int]] = None,\n    justify: str = \"right\",\n    decimal: str = \".\",\n    leading_space: Optional[bool] = None,\n) -> List[str]:\n    \"\"\"\n    Format an array for printing.\n\n    Parameters\n    ----------\n    values\n    formatter\n    float_format\n    na_rep\n    digits\n    space\n    justify\n    decimal\n    leading_space : bool, optional\n        Whether the array should be formatted with a leading space.\n        When an array as a column of a Series or DataFrame, we do want\n        the leading space to pad between columns.\n\n        When formatting an Index subclass\n        (e.g. IntervalIndex._format_native_types), we don't want the\n        leading space since it should be left-aligned.\n\n    Returns\n    -------\n    List[str]\n    \"\"\"\n\n    if is_datetime64_dtype(values.dtype):\n        fmt_klass = Datetime64Formatter  # type: Type[GenericArrayFormatter]\n    elif is_datetime64tz_dtype(values):\n        fmt_klass = Datetime64TZFormatter\n    elif is_timedelta64_dtype(values.dtype):\n        fmt_klass = Timedelta64Formatter\n    elif is_extension_array_dtype(values.dtype):\n        fmt_klass = ExtensionArrayFormatter\n    elif is_float_dtype(values.dtype) or is_complex_dtype(values.dtype):\n        fmt_klass = FloatArrayFormatter\n    elif is_integer_dtype(values.dtype):\n        fmt_klass = IntArrayFormatter\n    else:\n        fmt_klass = GenericArrayFormatter\n\n    if space is None:\n        space = get_option(\"display.column_space\")\n\n    if float_format is None:\n        float_format = get_option(\"display.float_format\")\n\n    if digits is None:\n        digits = get_option(\"display.precision\")\n\n    fmt_obj = fmt_klass(\n        values,\n        digits=digits,\n        na_rep=na_rep,\n        float_format=float_format,\n        formatter=formatter,\n        space=space,\n        justify=justify,\n        decimal=decimal,\n        leading_space=leading_space,\n    )\n\n    return fmt_obj.get_result()",
        "begin_line": 1054,
        "end_line": 1128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.GenericArrayFormatter.__init__#1132",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.GenericArrayFormatter",
        "signature": "pandas.io.formats.format.GenericArrayFormatter.__init__(self, values: Any, digits: int=7, formatter: Optional[Callable]=None, na_rep: str='NaN', space: Union[str, int]=12, float_format: Optional[float_format_type]=None, justify: str='right', decimal: str='.', quoting: Optional[int]=None, fixed_width: bool=True, leading_space: Optional[bool]=None)",
        "snippet": "    def __init__(\n        self,\n        values: Any,\n        digits: int = 7,\n        formatter: Optional[Callable] = None,\n        na_rep: str = \"NaN\",\n        space: Union[str, int] = 12,\n        float_format: Optional[float_format_type] = None,\n        justify: str = \"right\",\n        decimal: str = \".\",\n        quoting: Optional[int] = None,\n        fixed_width: bool = True,\n        leading_space: Optional[bool] = None,\n    ):\n        self.values = values\n        self.digits = digits\n        self.na_rep = na_rep\n        self.space = space\n        self.formatter = formatter\n        self.float_format = float_format\n        self.justify = justify\n        self.decimal = decimal\n        self.quoting = quoting\n        self.fixed_width = fixed_width\n        self.leading_space = leading_space",
        "begin_line": 1132,
        "end_line": 1156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.GenericArrayFormatter.get_result#1158",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.GenericArrayFormatter",
        "signature": "pandas.io.formats.format.GenericArrayFormatter.get_result(self)",
        "snippet": "    def get_result(self) -> List[str]:\n        fmt_values = self._format_strings()\n        return _make_fixed_width(fmt_values, self.justify)",
        "begin_line": 1158,
        "end_line": 1160,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.FloatArrayFormatter.__init__#1232",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.FloatArrayFormatter",
        "signature": "pandas.io.formats.format.FloatArrayFormatter.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        GenericArrayFormatter.__init__(self, *args, **kwargs)\n\n        # float_format is expected to be a string\n        # formatter should be used to pass a function\n        if self.float_format is not None and self.formatter is None:\n            # GH21625, GH22270\n            self.fixed_width = False\n            if callable(self.float_format):\n                self.formatter = self.float_format\n                self.float_format = None",
        "begin_line": 1232,
        "end_line": 1242,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.FloatArrayFormatter._value_formatter#1244",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.FloatArrayFormatter",
        "signature": "pandas.io.formats.format.FloatArrayFormatter._value_formatter(self, float_format: Optional[float_format_type]=None, threshold: Optional[Union[float, int]]=None)",
        "snippet": "    def _value_formatter(\n        self,\n        float_format: Optional[float_format_type] = None,\n        threshold: Optional[Union[float, int]] = None,\n    ) -> Callable:\n        \"\"\"Returns a function to be applied on each value to format it\n        \"\"\"\n\n        # the float_format parameter supersedes self.float_format\n        if float_format is None:\n            float_format = self.float_format\n\n        # we are going to compose different functions, to first convert to\n        # a string, then replace the decimal symbol, and finally chop according\n        # to the threshold\n\n        # when there is no float_format, we use str instead of '%g'\n        # because str(0.0) = '0.0' while '%g' % 0.0 = '0'\n        if float_format:\n\n            def base_formatter(v):\n                return float_format(value=v) if notna(v) else self.na_rep\n\n        else:\n\n            def base_formatter(v):\n                return str(v) if notna(v) else self.na_rep\n\n        if self.decimal != \".\":\n\n            def decimal_formatter(v):\n                return base_formatter(v).replace(\".\", self.decimal, 1)\n\n        else:\n            decimal_formatter = base_formatter\n\n        if threshold is None:\n            return decimal_formatter\n\n        def formatter(value):\n            if notna(value):\n                if abs(value) > threshold:\n                    return decimal_formatter(value)\n                else:\n                    return decimal_formatter(0.0)\n            else:\n                return self.na_rep\n\n        return formatter",
        "begin_line": 1244,
        "end_line": 1292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.FloatArrayFormatter.base_formatter#1264",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.FloatArrayFormatter",
        "signature": "pandas.io.formats.format.FloatArrayFormatter.base_formatter(v)",
        "snippet": "            def base_formatter(v):\n                return float_format(value=v) if notna(v) else self.na_rep",
        "begin_line": 1264,
        "end_line": 1265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.FloatArrayFormatter.get_result_as_array#1294",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.FloatArrayFormatter",
        "signature": "pandas.io.formats.format.FloatArrayFormatter.get_result_as_array(self)",
        "snippet": "    def get_result_as_array(self) -> np.ndarray:\n        \"\"\"\n        Returns the float values converted into strings using\n        the parameters given at initialisation, as a numpy array\n        \"\"\"\n\n        if self.formatter is not None:\n            return np.array([self.formatter(x) for x in self.values])\n\n        if self.fixed_width:\n            threshold = get_option(\"display.chop_threshold\")\n        else:\n            threshold = None\n\n        # if we have a fixed_width, we'll need to try different float_format\n        def format_values_with(float_format):\n            formatter = self._value_formatter(float_format, threshold)\n\n            # default formatter leaves a space to the left when formatting\n            # floats, must be consistent for left-justifying NaNs (GH #25061)\n            if self.justify == \"left\":\n                na_rep = \" \" + self.na_rep\n            else:\n                na_rep = self.na_rep\n\n            # separate the wheat from the chaff\n            values = self.values\n            is_complex = is_complex_dtype(values)\n            mask = isna(values)\n            if hasattr(values, \"to_dense\"):  # sparse numpy ndarray\n                values = values.to_dense()\n            values = np.array(values, dtype=\"object\")\n            values[mask] = na_rep\n            imask = (~mask).ravel()\n            values.flat[imask] = np.array(\n                [formatter(val) for val in values.ravel()[imask]]\n            )\n\n            if self.fixed_width:\n                if is_complex:\n                    result = _trim_zeros_complex(values, na_rep)\n                else:\n                    result = _trim_zeros_float(values, na_rep)\n                return np.asarray(result, dtype=\"object\")\n\n            return values\n\n        # There is a special default string when we are fixed-width\n        # The default is otherwise to use str instead of a formatting string\n        if self.float_format is None:\n            if self.fixed_width:\n                float_format = partial(\n                    \"{value: .{digits:d}f}\".format, digits=self.digits\n                )  # type: Optional[float_format_type]\n            else:\n                float_format = self.float_format\n        else:\n            float_format = lambda value: self.float_format % value\n\n        formatted_values = format_values_with(float_format)\n\n        if not self.fixed_width:\n            return formatted_values\n\n        # we need do convert to engineering format if some values are too small\n        # and would appear as 0, or if some values are too big and take too\n        # much space\n\n        if len(formatted_values) > 0:\n            maxlen = max(len(x) for x in formatted_values)\n            too_long = maxlen > self.digits + 6\n        else:\n            too_long = False\n\n        with np.errstate(invalid=\"ignore\"):\n            abs_vals = np.abs(self.values)\n            # this is pretty arbitrary for now\n            # large values: more that 8 characters including decimal symbol\n            # and first digit, hence > 1e6\n            has_large_values = (abs_vals > 1e6).any()\n            has_small_values = (\n                (abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)\n            ).any()\n\n        if has_small_values or (too_long and has_large_values):\n            float_format = partial(\"{value: .{digits:d}e}\".format, digits=self.digits)\n            formatted_values = format_values_with(float_format)\n\n        return formatted_values",
        "begin_line": 1294,
        "end_line": 1382,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.FloatArrayFormatter.format_values_with#1309",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.FloatArrayFormatter",
        "signature": "pandas.io.formats.format.FloatArrayFormatter.format_values_with(float_format)",
        "snippet": "        def format_values_with(float_format):\n            formatter = self._value_formatter(float_format, threshold)\n\n            # default formatter leaves a space to the left when formatting\n            # floats, must be consistent for left-justifying NaNs (GH #25061)\n            if self.justify == \"left\":\n                na_rep = \" \" + self.na_rep\n            else:\n                na_rep = self.na_rep\n\n            # separate the wheat from the chaff\n            values = self.values\n            is_complex = is_complex_dtype(values)\n            mask = isna(values)\n            if hasattr(values, \"to_dense\"):  # sparse numpy ndarray\n                values = values.to_dense()\n            values = np.array(values, dtype=\"object\")\n            values[mask] = na_rep\n            imask = (~mask).ravel()\n            values.flat[imask] = np.array(\n                [formatter(val) for val in values.ravel()[imask]]\n            )\n\n            if self.fixed_width:\n                if is_complex:\n                    result = _trim_zeros_complex(values, na_rep)\n                else:\n                    result = _trim_zeros_float(values, na_rep)\n                return np.asarray(result, dtype=\"object\")\n\n            return values",
        "begin_line": 1309,
        "end_line": 1339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.FloatArrayFormatter._format_strings#1384",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.FloatArrayFormatter",
        "signature": "pandas.io.formats.format.FloatArrayFormatter._format_strings(self)",
        "snippet": "    def _format_strings(self) -> List[str]:\n        # shortcut\n        if self.formatter is not None:\n            return [self.formatter(x) for x in self.values]\n\n        return list(self.get_result_as_array())",
        "begin_line": 1384,
        "end_line": 1389,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.IntArrayFormatter._format_strings#1393",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.IntArrayFormatter",
        "signature": "pandas.io.formats.format.IntArrayFormatter._format_strings(self)",
        "snippet": "    def _format_strings(self) -> List[str]:\n        formatter = self.formatter or (lambda x: \"{x: d}\".format(x=x))\n        fmt_values = [formatter(x) for x in self.values]\n        return fmt_values",
        "begin_line": 1393,
        "end_line": 1396,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format._make_fixed_width#1686",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format._make_fixed_width(strings: List[str], justify: str='right', minimum: Optional[int]=None, adj: Optional[TextAdjustment]=None)",
        "snippet": "def _make_fixed_width(\n    strings: List[str],\n    justify: str = \"right\",\n    minimum: Optional[int] = None,\n    adj: Optional[TextAdjustment] = None,\n) -> List[str]:\n\n    if len(strings) == 0 or justify == \"all\":\n        return strings\n\n    if adj is None:\n        adj = _get_adjustment()\n\n    max_len = max(adj.len(x) for x in strings)\n\n    if minimum is not None:\n        max_len = max(minimum, max_len)\n\n    conf_max = get_option(\"display.max_colwidth\")\n    if conf_max is not None and max_len > conf_max:\n        max_len = conf_max\n\n    def just(x):\n        if conf_max is not None:\n            if (conf_max > 3) & (adj.len(x) > max_len):\n                x = x[: max_len - 3] + \"...\"\n        return x\n\n    strings = [just(x) for x in strings]\n    result = adj.justify(strings, max_len, mode=justify)\n    return result",
        "begin_line": 1686,
        "end_line": 1716,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format.just#1708",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format.just(x)",
        "snippet": "    def just(x):\n        if conf_max is not None:\n            if (conf_max > 3) & (adj.len(x) > max_len):\n                x = x[: max_len - 3] + \"...\"\n        return x",
        "begin_line": 1708,
        "end_line": 1712,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format._trim_zeros_float#1730",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format._trim_zeros_float(str_floats: Union[np.ndarray, List[str]], na_rep: str='NaN')",
        "snippet": "def _trim_zeros_float(\n    str_floats: Union[np.ndarray, List[str]], na_rep: str = \"NaN\"\n) -> List[str]:\n    \"\"\"\n    Trims zeros, leaving just one before the decimal points if need be.\n    \"\"\"\n    trimmed = str_floats\n\n    def _is_number(x):\n        return x != na_rep and not x.endswith(\"inf\")\n\n    def _cond(values):\n        finite = [x for x in values if _is_number(x)]\n        return (\n            len(finite) > 0\n            and all(x.endswith(\"0\") for x in finite)\n            and not (any((\"e\" in x) or (\"E\" in x) for x in finite))\n        )\n\n    while _cond(trimmed):\n        trimmed = [x[:-1] if _is_number(x) else x for x in trimmed]\n\n    # leave one 0 after the decimal points if need be.\n    return [x + \"0\" if x.endswith(\".\") and _is_number(x) else x for x in trimmed]",
        "begin_line": 1730,
        "end_line": 1753,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format._is_number#1738",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format._is_number(x)",
        "snippet": "    def _is_number(x):\n        return x != na_rep and not x.endswith(\"inf\")",
        "begin_line": 1738,
        "end_line": 1739,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.format._cond#1741",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format._cond(values)",
        "snippet": "    def _cond(values):\n        finite = [x for x in values if _is_number(x)]\n        return (\n            len(finite) > 0\n            and all(x.endswith(\"0\") for x in finite)\n            and not (any((\"e\" in x) or (\"E\" in x) for x in finite))\n        )",
        "begin_line": 1741,
        "end_line": 1747,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.__init__#113",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.__init__(self, values, placement, ndim=None)",
        "snippet": "    def __init__(self, values, placement, ndim=None):\n        self.ndim = self._check_ndim(values, ndim)\n        self.mgr_locs = placement\n        self.values = values\n\n        if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):\n            raise ValueError(\n                \"Wrong number of items passed {val}, placement implies \"\n                \"{mgr}\".format(val=len(self.values), mgr=len(self.mgr_locs))\n            )",
        "begin_line": 113,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block._check_ndim#124",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block._check_ndim(self, values, ndim)",
        "snippet": "    def _check_ndim(self, values, ndim):\n        \"\"\"\n        ndim inference and validation.\n\n        Infers ndim from 'values' if not provided to __init__.\n        Validates that values.ndim and ndim are consistent if and only if\n        the class variable '_validate_ndim' is True.\n\n        Parameters\n        ----------\n        values : array-like\n        ndim : int or None\n\n        Returns\n        -------\n        ndim : int\n\n        Raises\n        ------\n        ValueError : the number of dimensions do not match\n        \"\"\"\n        if ndim is None:\n            ndim = values.ndim\n\n        if self._validate_ndim and values.ndim != ndim:\n            msg = \"Wrong number of dimensions. values.ndim != ndim [{} != {}]\"\n            raise ValueError(msg.format(values.ndim, ndim))\n\n        return ndim",
        "begin_line": 124,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.external_values#196",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.external_values(self, dtype=None)",
        "snippet": "    def external_values(self, dtype=None):\n        \"\"\" return an outside world format, currently just the ndarray \"\"\"\n        return self.values",
        "begin_line": 196,
        "end_line": 198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.internal_values#200",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.internal_values(self, dtype=None)",
        "snippet": "    def internal_values(self, dtype=None):\n        \"\"\" return an internal format, currently just the ndarray\n        this should be the pure internal API format\n        \"\"\"\n        return self.values",
        "begin_line": 200,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.get_values#206",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.get_values(self, dtype=None)",
        "snippet": "    def get_values(self, dtype=None):\n        \"\"\"\n        return an internal format, currently just the ndarray\n        this is often overridden to handle to_dense like operations\n        \"\"\"\n        if is_object_dtype(dtype):\n            return self.values.astype(object)\n        return self.values",
        "begin_line": 206,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.to_dense#221",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.to_dense(self)",
        "snippet": "    def to_dense(self):\n        return self.values.view()",
        "begin_line": 221,
        "end_line": 222,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.mgr_locs#229",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.mgr_locs(self)",
        "snippet": "    def mgr_locs(self):\n        return self._mgr_locs",
        "begin_line": 229,
        "end_line": 230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.mgr_locs#233",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.mgr_locs(self, new_mgr_locs)",
        "snippet": "    def mgr_locs(self, new_mgr_locs):\n        if not isinstance(new_mgr_locs, libinternals.BlockPlacement):\n            new_mgr_locs = libinternals.BlockPlacement(new_mgr_locs)\n\n        self._mgr_locs = new_mgr_locs",
        "begin_line": 233,
        "end_line": 237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.make_block_same_class#256",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.make_block_same_class(self, values, placement=None, ndim=None, dtype=None)",
        "snippet": "    def make_block_same_class(self, values, placement=None, ndim=None, dtype=None):\n        \"\"\" Wrap given values in a block of same type as self. \"\"\"\n        if dtype is not None:\n            # issue 19431 fastparquet is passing this\n            warnings.warn(\n                \"dtype argument is deprecated, will be removed in a future release.\",\n                FutureWarning,\n            )\n        if placement is None:\n            placement = self.mgr_locs\n        if ndim is None:\n            ndim = self.ndim\n        return make_block(\n            values, placement=placement, ndim=ndim, klass=self.__class__, dtype=dtype\n        )",
        "begin_line": 256,
        "end_line": 270,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block._slice#304",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block._slice(self, slicer)",
        "snippet": "    def _slice(self, slicer):\n        \"\"\" return a slice of my values \"\"\"\n        return self.values[slicer]",
        "begin_line": 304,
        "end_line": 306,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.shape#329",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.shape(self)",
        "snippet": "    def shape(self):\n        return self.values.shape",
        "begin_line": 329,
        "end_line": 330,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.dtype#333",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.dtype(self)",
        "snippet": "    def dtype(self):\n        return self.values.dtype",
        "begin_line": 333,
        "end_line": 334,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.ftype#337",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.ftype(self)",
        "snippet": "    def ftype(self):\n        if getattr(self.values, \"_pandas_ftype\", False):\n            dtype = self.dtype.subtype\n        else:\n            dtype = self.dtype\n        return \"{dtype}:{ftype}\".format(dtype=dtype, ftype=self._ftype)",
        "begin_line": 337,
        "end_line": 342,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.concat_same_type#347",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.concat_same_type(self, to_concat, placement=None)",
        "snippet": "    def concat_same_type(self, to_concat, placement=None):\n        \"\"\"\n        Concatenate list of single blocks of the same type.\n        \"\"\"\n        values = self._concatenator(\n            [blk.values for blk in to_concat], axis=self.ndim - 1\n        )\n        return self.make_block_same_class(\n            values, placement=placement or slice(0, len(values), 1)\n        )",
        "begin_line": 347,
        "end_line": 356,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.iget#358",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.iget(self, i)",
        "snippet": "    def iget(self, i):\n        return self.values[i]",
        "begin_line": 358,
        "end_line": 359,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.copy#720",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.copy(self, deep=True)",
        "snippet": "    def copy(self, deep=True):\n        \"\"\" copy constructor \"\"\"\n        values = self.values\n        if deep:\n            values = values.copy()\n        return self.make_block_same_class(values, ndim=self.ndim)",
        "begin_line": 720,
        "end_line": 725,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.blocks.ObjectBlock.__init__#2616",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.ObjectBlock",
        "signature": "pandas.core.internals.blocks.ObjectBlock.__init__(self, values, placement=None, ndim=2)",
        "snippet": "    def __init__(self, values, placement=None, ndim=2):\n        if issubclass(values.dtype.type, str):\n            values = np.array(values, dtype=object)\n\n        super().__init__(values, ndim=ndim, placement=placement)",
        "begin_line": 2616,
        "end_line": 2620,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.blocks.get_block_type#3030",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks.get_block_type(values, dtype=None)",
        "snippet": "def get_block_type(values, dtype=None):\n    \"\"\"\n    Find the appropriate Block subclass to use for the given values and dtype.\n\n    Parameters\n    ----------\n    values : ndarray-like\n    dtype : numpy or pandas dtype\n\n    Returns\n    -------\n    cls : class, subclass of Block\n    \"\"\"\n    dtype = dtype or values.dtype\n    vtype = dtype.type\n\n    if is_sparse(dtype):\n        # Need this first(ish) so that Sparse[datetime] is sparse\n        cls = ExtensionBlock\n    elif is_categorical(values):\n        cls = CategoricalBlock\n    elif issubclass(vtype, np.datetime64):\n        assert not is_datetime64tz_dtype(values)\n        cls = DatetimeBlock\n    elif is_datetime64tz_dtype(values):\n        cls = DatetimeTZBlock\n    elif is_interval_dtype(dtype) or is_period_dtype(dtype):\n        cls = ObjectValuesExtensionBlock\n    elif is_extension_array_dtype(values):\n        cls = ExtensionBlock\n    elif issubclass(vtype, np.floating):\n        cls = FloatBlock\n    elif issubclass(vtype, np.timedelta64):\n        assert issubclass(vtype, np.integer)\n        cls = TimeDeltaBlock\n    elif issubclass(vtype, np.complexfloating):\n        cls = ComplexBlock\n    elif issubclass(vtype, np.integer):\n        cls = IntBlock\n    elif dtype == np.bool_:\n        cls = BoolBlock\n    else:\n        cls = ObjectBlock\n    return cls",
        "begin_line": 3030,
        "end_line": 3073,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.blocks.make_block#3076",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks.make_block(values, placement, klass=None, ndim=None, dtype=None, fastpath=None)",
        "snippet": "def make_block(values, placement, klass=None, ndim=None, dtype=None, fastpath=None):\n    # Ensure that we don't allow PandasArray / PandasDtype in internals.\n    # For now, blocks should be backed by ndarrays when possible.\n    if isinstance(values, ABCPandasArray):\n        values = values.to_numpy()\n        if ndim and ndim > 1:\n            values = np.atleast_2d(values)\n\n    if isinstance(dtype, PandasDtype):\n        dtype = dtype.numpy_dtype\n\n    if fastpath is not None:\n        # GH#19265 pyarrow is passing this\n        warnings.warn(\n            \"fastpath argument is deprecated, will be removed in a future release.\",\n            FutureWarning,\n        )\n    if klass is None:\n        dtype = dtype or values.dtype\n        klass = get_block_type(values, dtype)\n\n    elif klass is DatetimeTZBlock and not is_datetime64tz_dtype(values):\n        # TODO: This is no longer hit internally; does it need to be retained\n        #  for e.g. pyarrow?\n        values = DatetimeArray._simple_new(values, dtype=dtype)\n\n    return klass(values, ndim=ndim, placement=placement)",
        "begin_line": 3076,
        "end_line": 3102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.internals.blocks._extend_blocks#3108",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks._extend_blocks(result, blocks=None)",
        "snippet": "def _extend_blocks(result, blocks=None):\n    \"\"\" return a new extended blocks, givin the result \"\"\"\n    from pandas.core.internals import BlockManager\n\n    if blocks is None:\n        blocks = []\n    if isinstance(result, list):\n        for r in result:\n            if isinstance(r, list):\n                blocks.extend(r)\n            else:\n                blocks.append(r)\n    elif isinstance(result, BlockManager):\n        blocks.extend(result.blocks)\n    else:\n        blocks.append(result)\n    return blocks",
        "begin_line": 3108,
        "end_line": 3124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.base.ExtensionDtype.construct_from_string#181",
        "src_path": "pandas/core/dtypes/base.py",
        "class_name": "pandas.core.dtypes.base.ExtensionDtype",
        "signature": "pandas.core.dtypes.base.ExtensionDtype.construct_from_string(cls, string: str)",
        "snippet": "    def construct_from_string(cls, string: str):\n        r\"\"\"\n        Construct this type from a string.\n\n        This is useful mainly for data types that accept parameters.\n        For example, a period dtype accepts a frequency parameter that\n        can be set as ``period[H]`` (where H means hourly frequency).\n\n        By default, in the abstract class, just the name of the type is\n        expected. But subclasses can overwrite this method to accept\n        parameters.\n\n        Parameters\n        ----------\n        string : str\n            The name of the type, for example ``category``.\n\n        Returns\n        -------\n        ExtensionDtype\n            Instance of the dtype.\n\n        Raises\n        ------\n        TypeError\n            If a class cannot be constructed from this 'string'.\n\n        Examples\n        --------\n        For extension dtypes with arguments the following may be an\n        adequate implementation.\n\n        >>> @classmethod\n        ... def construct_from_string(cls, string):\n        ...     pattern = re.compile(r\"^my_type\\[(?P<arg_name>.+)\\]$\")\n        ...     match = pattern.match(string)\n        ...     if match:\n        ...         return cls(**match.groupdict())\n        ...     else:\n        ...         raise TypeError(\"Cannot construct a '{}' from \"\n        ...                         \"'{}'\".format(cls.__name__, string))\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\"Expects a string, got {}\".format(type(string)))\n        if string != cls.name:\n            raise TypeError(\n                \"Cannot construct a '{}' from '{}'\".format(cls.__name__, string)\n            )\n        return cls()",
        "begin_line": 181,
        "end_line": 229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.base.ExtensionDtype.is_dtype#232",
        "src_path": "pandas/core/dtypes/base.py",
        "class_name": "pandas.core.dtypes.base.ExtensionDtype",
        "signature": "pandas.core.dtypes.base.ExtensionDtype.is_dtype(cls, dtype)",
        "snippet": "    def is_dtype(cls, dtype) -> bool:\n        \"\"\"Check if we match 'dtype'.\n\n        Parameters\n        ----------\n        dtype : object\n            The object to check.\n\n        Returns\n        -------\n        is_dtype : bool\n\n        Notes\n        -----\n        The default implementation is True if\n\n        1. ``cls.construct_from_string(dtype)`` is an instance\n           of ``cls``.\n        2. ``dtype`` is an object and is an instance of ``cls``\n        3. ``dtype`` has a ``dtype`` attribute, and any of the above\n           conditions is true for ``dtype.dtype``.\n        \"\"\"\n        dtype = getattr(dtype, \"dtype\", dtype)\n\n        if isinstance(dtype, (ABCSeries, ABCIndexClass, ABCDataFrame, np.dtype)):\n            # https://github.com/pandas-dev/pandas/issues/22960\n            # avoid passing data to `construct_from_string`. This could\n            # cause a FutureWarning from numpy about failing elementwise\n            # comparison from, e.g., comparing DataFrame == 'category'.\n            return False\n        elif dtype is None:\n            return False\n        elif isinstance(dtype, cls):\n            return True\n        try:\n            return cls.construct_from_string(dtype) is not None\n        except TypeError:\n            return False",
        "begin_line": 232,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas._config.config._get_single_key#83",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_single_key(pat, silent)",
        "snippet": "def _get_single_key(pat, silent):\n    keys = _select_options(pat)\n    if len(keys) == 0:\n        if not silent:\n            _warn_if_deprecated(pat)\n        raise OptionError(\"No such keys(s): {pat!r}\".format(pat=pat))\n    if len(keys) > 1:\n        raise OptionError(\"Pattern matched multiple keys\")\n    key = keys[0]\n\n    if not silent:\n        _warn_if_deprecated(key)\n\n    key = _translate_key(key)\n\n    return key",
        "begin_line": 83,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.013513513513513514,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.0008718395815170009,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.0008718395815170009
        }
    },
    {
        "name": "pandas._config.config._get_option#101",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_option(pat, silent=False)",
        "snippet": "def _get_option(pat, silent=False):\n    key = _get_single_key(pat, silent)\n\n    # walk the nested dict\n    root, k = _get_root(key)\n    return root[k]",
        "begin_line": 101,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas._config.config._set_option#109",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._set_option(*args, **kwargs)",
        "snippet": "def _set_option(*args, **kwargs):\n    # must at least 1 arg deal with constraints later\n    nargs = len(args)\n    if not nargs or nargs % 2 != 0:\n        raise ValueError(\"Must provide an even number of non-keyword arguments\")\n\n    # default to false\n    silent = kwargs.pop(\"silent\", False)\n\n    if kwargs:\n        msg = '_set_option() got an unexpected keyword argument \"{kwarg}\"'\n        raise TypeError(msg.format(list(kwargs.keys())[0]))\n\n    for k, v in zip(args[::2], args[1::2]):\n        key = _get_single_key(k, silent)\n\n        o = _get_registered_option(key)\n        if o and o.validator:\n            o.validator(v)\n\n        # walk the nested dict\n        root, k = _get_root(key)\n        root[k] = v\n\n        if o.cb:\n            if silent:\n                with warnings.catch_warnings(record=True):\n                    o.cb(key)\n            else:\n                o.cb(key)",
        "begin_line": 109,
        "end_line": 138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas._config.config.CallableDynamicDoc.__call__#232",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config.CallableDynamicDoc",
        "signature": "pandas._config.config.CallableDynamicDoc.__call__(self, *args, **kwds)",
        "snippet": "    def __call__(self, *args, **kwds):\n        return self.__func__(*args, **kwds)",
        "begin_line": 232,
        "end_line": 233,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.013513513513513514,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.0008718395815170009,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.0008718395815170009
        }
    },
    {
        "name": "pandas._config.config._select_options#535",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._select_options(pat)",
        "snippet": "def _select_options(pat):\n    \"\"\"returns a list of keys matching `pat`\n\n    if pat==\"all\", returns all registered options\n    \"\"\"\n\n    # short-circuit for exact key\n    if pat in _registered_options:\n        return [pat]\n\n    # else look through all of them\n    keys = sorted(_registered_options.keys())\n    if pat == \"all\":  # reserved key\n        return keys\n\n    return [k for k in keys if re.search(pat, k, re.I)]",
        "begin_line": 535,
        "end_line": 550,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.013513513513513514,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas._config.config._get_root#553",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_root(key)",
        "snippet": "def _get_root(key):\n    path = key.split(\".\")\n    cursor = _global_config\n    for p in path[:-1]:\n        cursor = cursor[p]\n    return cursor, path[-1]",
        "begin_line": 553,
        "end_line": 558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.013513513513513514,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.0008718395815170009,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.0008718395815170009
        }
    },
    {
        "name": "pandas._config.config._get_deprecated_option#568",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_deprecated_option(key)",
        "snippet": "def _get_deprecated_option(key):\n    \"\"\"\n    Retrieves the metadata for a deprecated option, if `key` is deprecated.\n\n    Returns\n    -------\n    DeprecatedOption (namedtuple) if key is deprecated, None otherwise\n    \"\"\"\n\n    try:\n        d = _deprecated_options[key]\n    except KeyError:\n        return None\n    else:\n        return d",
        "begin_line": 568,
        "end_line": 582,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.013513513513513514,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.0008718395815170009,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.0008718395815170009
        }
    },
    {
        "name": "pandas._config.config._get_registered_option#585",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_registered_option(key)",
        "snippet": "def _get_registered_option(key):\n    \"\"\"\n    Retrieves the option metadata if `key` is a registered option.\n\n    Returns\n    -------\n    RegisteredOption (namedtuple) if key is deprecated, None otherwise\n    \"\"\"\n    return _registered_options.get(key)",
        "begin_line": 585,
        "end_line": 593,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas._config.config._translate_key#596",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._translate_key(key)",
        "snippet": "def _translate_key(key):\n    \"\"\"\n    if key id deprecated and a replacement key defined, will return the\n    replacement key, otherwise returns `key` as - is\n    \"\"\"\n\n    d = _get_deprecated_option(key)\n    if d:\n        return d.rkey or key\n    else:\n        return key",
        "begin_line": 596,
        "end_line": 606,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.013513513513513514,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.0008718395815170009,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.0008718395815170009
        }
    },
    {
        "name": "pandas._config.config._warn_if_deprecated#609",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._warn_if_deprecated(key)",
        "snippet": "def _warn_if_deprecated(key):\n    \"\"\"\n    Checks if `key` is a deprecated option and if so, prints a warning.\n\n    Returns\n    -------\n    bool - True if `key` is deprecated, False otherwise.\n    \"\"\"\n\n    d = _get_deprecated_option(key)\n    if d:\n        if d.msg:\n            print(d.msg)\n            warnings.warn(d.msg, FutureWarning)\n        else:\n            msg = \"'{key}' is deprecated\".format(key=key)\n            if d.removal_ver:\n                msg += \" and will be removed in {version}\".format(version=d.removal_ver)\n            if d.rkey:\n                msg += \", please use '{rkey}' instead.\".format(rkey=d.rkey)\n            else:\n                msg += \", please refrain from using it.\"\n\n            warnings.warn(msg, FutureWarning)\n        return True\n    return False",
        "begin_line": 609,
        "end_line": 634,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.013513513513513514,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.0008718395815170009,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.0008718395815170009
        }
    },
    {
        "name": "pandas._config.config.inner#810",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config.inner(x)",
        "snippet": "    def inner(x):\n        if x not in legal_values:\n\n            if not any(c(x) for c in callables):\n                uvals = [str(lval) for lval in legal_values]\n                pp_values = \"|\".join(uvals)\n                msg = \"Value must be one of {pp_values}\"\n                if len(callables):\n                    msg += \" or a callable\"\n                raise ValueError(msg.format(pp_values=pp_values))",
        "begin_line": 810,
        "end_line": 819,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_castable#885",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_castable(arr)",
        "snippet": "def maybe_castable(arr):\n    # return False to force a non-fastpath\n\n    # check datetime64[ns]/timedelta64[ns] are valid\n    # otherwise try to coerce\n    kind = arr.dtype.kind\n    if kind == \"M\":\n        return is_datetime64_ns_dtype(arr.dtype)\n    elif kind == \"m\":\n        return is_timedelta64_ns_dtype(arr.dtype)\n\n    return arr.dtype.name not in _POSSIBLY_CAST_DTYPES",
        "begin_line": 885,
        "end_line": 896,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_cast_to_datetime#1005",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_cast_to_datetime(value, dtype, errors='raise')",
        "snippet": "def maybe_cast_to_datetime(value, dtype, errors=\"raise\"):\n    \"\"\" try to cast the array/value to a datetimelike dtype, converting float\n    nan to iNaT\n    \"\"\"\n    from pandas.core.tools.timedeltas import to_timedelta\n    from pandas.core.tools.datetimes import to_datetime\n\n    if dtype is not None:\n        if isinstance(dtype, str):\n            dtype = np.dtype(dtype)\n\n        is_datetime64 = is_datetime64_dtype(dtype)\n        is_datetime64tz = is_datetime64tz_dtype(dtype)\n        is_timedelta64 = is_timedelta64_dtype(dtype)\n\n        if is_datetime64 or is_datetime64tz or is_timedelta64:\n\n            # Force the dtype if needed.\n            msg = (\n                \"The '{dtype}' dtype has no unit. \"\n                \"Please pass in '{dtype}[ns]' instead.\"\n            )\n\n            if is_datetime64 and not is_dtype_equal(dtype, _NS_DTYPE):\n                if dtype.name in (\"datetime64\", \"datetime64[ns]\"):\n                    if dtype.name == \"datetime64\":\n                        raise ValueError(msg.format(dtype=dtype.name))\n                    dtype = _NS_DTYPE\n                else:\n                    raise TypeError(\n                        \"cannot convert datetimelike to \"\n                        \"dtype [{dtype}]\".format(dtype=dtype)\n                    )\n            elif is_datetime64tz:\n\n                # our NaT doesn't support tz's\n                # this will coerce to DatetimeIndex with\n                # a matching dtype below\n                if is_scalar(value) and isna(value):\n                    value = [value]\n\n            elif is_timedelta64 and not is_dtype_equal(dtype, _TD_DTYPE):\n                if dtype.name in (\"timedelta64\", \"timedelta64[ns]\"):\n                    if dtype.name == \"timedelta64\":\n                        raise ValueError(msg.format(dtype=dtype.name))\n                    dtype = _TD_DTYPE\n                else:\n                    raise TypeError(\n                        \"cannot convert timedeltalike to \"\n                        \"dtype [{dtype}]\".format(dtype=dtype)\n                    )\n\n            if is_scalar(value):\n                if value == iNaT or isna(value):\n                    value = iNaT\n            else:\n                value = np.array(value, copy=False)\n\n                # have a scalar array-like (e.g. NaT)\n                if value.ndim == 0:\n                    value = iNaT\n\n                # we have an array of datetime or timedeltas & nulls\n                elif np.prod(value.shape) or not is_dtype_equal(value.dtype, dtype):\n                    try:\n                        if is_datetime64:\n                            value = to_datetime(value, errors=errors)\n                            # GH 25843: Remove tz information since the dtype\n                            # didn't specify one\n                            if value.tz is not None:\n                                value = value.tz_localize(None)\n                            value = value._values\n                        elif is_datetime64tz:\n                            # The string check can be removed once issue #13712\n                            # is solved. String data that is passed with a\n                            # datetime64tz is assumed to be naive which should\n                            # be localized to the timezone.\n                            is_dt_string = is_string_dtype(value)\n                            value = to_datetime(value, errors=errors).array\n                            if is_dt_string:\n                                # Strings here are naive, so directly localize\n                                value = value.tz_localize(dtype.tz)\n                            else:\n                                # Numeric values are UTC at this point,\n                                # so localize and convert\n                                value = value.tz_localize(\"UTC\").tz_convert(dtype.tz)\n                        elif is_timedelta64:\n                            value = to_timedelta(value, errors=errors)._values\n                    except OutOfBoundsDatetime:\n                        raise\n                    except (AttributeError, ValueError, TypeError):\n                        pass\n\n        # coerce datetimelike to object\n        elif is_datetime64_dtype(value) and not is_datetime64_dtype(dtype):\n            if is_object_dtype(dtype):\n                if value.dtype != _NS_DTYPE:\n                    value = value.astype(_NS_DTYPE)\n                ints = np.asarray(value).view(\"i8\")\n                return tslib.ints_to_pydatetime(ints)\n\n            # we have a non-castable dtype that was passed\n            raise TypeError(\"Cannot cast datetime64 to {dtype}\".format(dtype=dtype))\n\n    else:\n\n        is_array = isinstance(value, np.ndarray)\n\n        # catch a datetime/timedelta that is not of ns variety\n        # and no coercion specified\n        if is_array and value.dtype.kind in [\"M\", \"m\"]:\n            dtype = value.dtype\n\n            if dtype.kind == \"M\" and dtype != _NS_DTYPE:\n                value = tslibs.conversion.ensure_datetime64ns(value)\n\n            elif dtype.kind == \"m\" and dtype != _TD_DTYPE:\n                value = to_timedelta(value)\n\n        # only do this if we have an array and the dtype of the array is not\n        # setup already we are not an integer/object, so don't bother with this\n        # conversion\n        elif not (\n            is_array\n            and not (\n                issubclass(value.dtype.type, np.integer) or value.dtype == np.object_\n            )\n        ):\n            value = maybe_infer_to_datetimelike(value)\n\n    return value",
        "begin_line": 1005,
        "end_line": 1135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.cast.construct_1d_object_array_from_listlike#1258",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.construct_1d_object_array_from_listlike(values)",
        "snippet": "def construct_1d_object_array_from_listlike(values):\n    \"\"\"\n    Transform any list-like object in a 1-dimensional numpy array of object\n    dtype.\n\n    Parameters\n    ----------\n    values : any iterable which has a len()\n\n    Raises\n    ------\n    TypeError\n        * If `values` does not have a len()\n\n    Returns\n    -------\n    1-dimensional numpy array of dtype object\n    \"\"\"\n    # numpy will try to interpret nested lists as further dimensions, hence\n    # making a 1D array that contains list-likes is a bit tricky:\n    result = np.empty(len(values), dtype=\"object\")\n    result[:] = values\n    return result",
        "begin_line": 1258,
        "end_line": 1280,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.cast.construct_1d_ndarray_preserving_na#1283",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.construct_1d_ndarray_preserving_na(values, dtype=None, copy=False)",
        "snippet": "def construct_1d_ndarray_preserving_na(values, dtype=None, copy=False):\n    \"\"\"\n    Construct a new ndarray, coercing `values` to `dtype`, preserving NA.\n\n    Parameters\n    ----------\n    values : Sequence\n    dtype : numpy.dtype, optional\n    copy : bool, default False\n        Note that copies may still be made with ``copy=False`` if casting\n        is required.\n\n    Returns\n    -------\n    arr : ndarray[dtype]\n\n    Examples\n    --------\n    >>> np.array([1.0, 2.0, None], dtype='str')\n    array(['1.0', '2.0', 'None'], dtype='<U4')\n\n    >>> construct_1d_ndarray_preserving_na([1.0, 2.0, None], dtype='str')\n\n\n    \"\"\"\n    subarr = np.array(values, dtype=dtype, copy=copy)\n\n    if dtype is not None and dtype.kind in (\"U\", \"S\"):\n        # GH-21083\n        # We can't just return np.array(subarr, dtype='str') since\n        # NumPy will convert the non-string objects into strings\n        # Including NA values. Se we have to go\n        # string -> object -> update NA, which requires an\n        # additional pass over the data.\n        na_values = isna(values)\n        subarr2 = subarr.astype(object)\n        subarr2[na_values] = np.asarray(values, dtype=object)[na_values]\n        subarr = subarr2\n\n    return subarr",
        "begin_line": 1283,
        "end_line": 1322,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.ops.array_ops.na_op#99",
        "src_path": "pandas/core/ops/array_ops.py",
        "class_name": "pandas.core.ops.array_ops",
        "signature": "pandas.core.ops.array_ops.na_op(x, y)",
        "snippet": "    def na_op(x, y):\n        \"\"\"\n        Return the result of evaluating op on the passed in values.\n\n        If native types are not compatible, try coersion to object dtype.\n\n        Parameters\n        ----------\n        x : array-like\n        y : array-like or scalar\n\n        Returns\n        -------\n        array-like\n\n        Raises\n        ------\n        TypeError : invalid operation\n        \"\"\"\n        import pandas.core.computation.expressions as expressions\n\n        try:\n            result = expressions.evaluate(op, str_rep, x, y, **eval_kwargs)\n        except TypeError:\n            result = masked_arith_op(x, y, op)\n\n        return missing.dispatch_fill_zeros(op, x, y, result)",
        "begin_line": 99,
        "end_line": 125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.ops.__init__.get_op_result_name#75",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.get_op_result_name(left, right)",
        "snippet": "def get_op_result_name(left, right):\n    \"\"\"\n    Find the appropriate name to pin to an operation result.  This result\n    should always be either an Index or a Series.\n\n    Parameters\n    ----------\n    left : {Series, Index}\n    right : object\n\n    Returns\n    -------\n    name : object\n        Usually a string\n    \"\"\"\n    # `left` is always a Series when called from within ops\n    if isinstance(right, (ABCSeries, ABCIndexClass)):\n        name = _maybe_match_name(left, right)\n    else:\n        name = left.name\n    return name",
        "begin_line": 75,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.ops.__init__.maybe_upcast_for_op#133",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.maybe_upcast_for_op(obj, shape: Tuple[int, ...])",
        "snippet": "def maybe_upcast_for_op(obj, shape: Tuple[int, ...]):\n    \"\"\"\n    Cast non-pandas objects to pandas types to unify behavior of arithmetic\n    and comparison operations.\n\n    Parameters\n    ----------\n    obj: object\n    shape : tuple[int]\n\n    Returns\n    -------\n    out : object\n\n    Notes\n    -----\n    Be careful to call this *after* determining the `name` attribute to be\n    attached to the result of the arithmetic operation.\n    \"\"\"\n    if type(obj) is datetime.timedelta:\n        # GH#22390  cast up to Timedelta to rely on Timedelta\n        # implementation; otherwise operation against numeric-dtype\n        # raises TypeError\n        return Timedelta(obj)\n    elif isinstance(obj, np.timedelta64):\n        if isna(obj):\n            # wrapping timedelta64(\"NaT\") in Timedelta returns NaT,\n            #  which would incorrectly be treated as a datetime-NaT, so\n            #  we broadcast and wrap in a Series\n            right = np.broadcast_to(obj, shape)\n\n            # Note: we use Series instead of TimedeltaIndex to avoid having\n            #  to worry about catching NullFrequencyError.\n            return pd.Series(right)\n\n        # In particular non-nanosecond timedelta64 needs to be cast to\n        #  nanoseconds, or else we get undesired behavior like\n        #  np.timedelta64(3, 'D') / 2 == np.timedelta64(1, 'D')\n        return Timedelta(obj)\n\n    elif isinstance(obj, np.ndarray) and is_timedelta64_dtype(obj):\n        # GH#22390 Unfortunately we need to special-case right-hand\n        # timedelta64 dtypes because numpy casts integer dtypes to\n        # timedelta64 when operating with timedelta64\n        return pd.TimedeltaIndex(obj)\n    return obj",
        "begin_line": 133,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.ops.__init__.should_extension_dispatch#399",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.should_extension_dispatch(left: ABCSeries, right: Any)",
        "snippet": "def should_extension_dispatch(left: ABCSeries, right: Any) -> bool:\n    \"\"\"\n    Identify cases where Series operation should use dispatch_to_extension_op.\n\n    Parameters\n    ----------\n    left : Series\n    right : object\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    if (\n        is_extension_array_dtype(left.dtype)\n        or is_datetime64_dtype(left.dtype)\n        or is_timedelta64_dtype(left.dtype)\n    ):\n        return True\n\n    if is_extension_array_dtype(right) and not is_scalar(right):\n        # GH#22378 disallow scalar to exclude e.g. \"category\", \"Int64\"\n        return True\n\n    return False",
        "begin_line": 399,
        "end_line": 423,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.ops.__init__.dispatch_to_series#464",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.dispatch_to_series(left, right, func, str_rep=None, axis=None)",
        "snippet": "def dispatch_to_series(left, right, func, str_rep=None, axis=None):\n    \"\"\"\n    Evaluate the frame operation func(left, right) by evaluating\n    column-by-column, dispatching to the Series implementation.\n\n    Parameters\n    ----------\n    left : DataFrame\n    right : scalar or DataFrame\n    func : arithmetic or comparison operator\n    str_rep : str or None, default None\n    axis : {None, 0, 1, \"index\", \"columns\"}\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    # Note: we use iloc to access columns for compat with cases\n    #       with non-unique columns.\n    import pandas.core.computation.expressions as expressions\n\n    right = lib.item_from_zerodim(right)\n    if lib.is_scalar(right) or np.ndim(right) == 0:\n\n        def column_op(a, b):\n            return {i: func(a.iloc[:, i], b) for i in range(len(a.columns))}\n\n    elif isinstance(right, ABCDataFrame):\n        assert right._indexed_same(left)\n\n        def column_op(a, b):\n            return {i: func(a.iloc[:, i], b.iloc[:, i]) for i in range(len(a.columns))}\n\n    elif isinstance(right, ABCSeries) and axis == \"columns\":\n        # We only get here if called via left._combine_match_columns,\n        # in which case we specifically want to operate row-by-row\n        assert right.index.equals(left.columns)\n\n        def column_op(a, b):\n            return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}\n\n    elif isinstance(right, ABCSeries):\n        assert right.index.equals(left.index)  # Handle other cases later\n\n        def column_op(a, b):\n            return {i: func(a.iloc[:, i], b) for i in range(len(a.columns))}\n\n    else:\n        # Remaining cases have less-obvious dispatch rules\n        raise NotImplementedError(right)\n\n    new_data = expressions.evaluate(column_op, str_rep, left, right)\n\n    result = left._constructor(new_data, index=left.index, copy=False)\n    # Pin columns instead of passing to constructor for compat with\n    # non-unique columns case\n    result.columns = left.columns\n    return result",
        "begin_line": 464,
        "end_line": 521,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.ops.__init__.column_op#502",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.column_op(a, b)",
        "snippet": "        def column_op(a, b):\n            return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}",
        "begin_line": 502,
        "end_line": 503,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02564102564102564,
            "pseudo_dstar_susp": 0.023809523809523808,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.023809523809523808,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.ops.__init__._align_method_SERIES#559",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__._align_method_SERIES(left, right, align_asobject=False)",
        "snippet": "def _align_method_SERIES(left, right, align_asobject=False):\n    \"\"\" align lhs and rhs Series \"\"\"\n\n    # ToDo: Different from _align_method_FRAME, list, tuple and ndarray\n    # are not coerced here\n    # because Series has inconsistencies described in #13637\n\n    if isinstance(right, ABCSeries):\n        # avoid repeated alignment\n        if not left.index.equals(right.index):\n\n            if align_asobject:\n                # to keep original value's dtype for bool ops\n                left = left.astype(object)\n                right = right.astype(object)\n\n            left, right = left.align(right, copy=False)\n\n    return left, right",
        "begin_line": 559,
        "end_line": 577,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.ops.__init__._construct_result#580",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__._construct_result(left, result, index, name, dtype=None)",
        "snippet": "def _construct_result(left, result, index, name, dtype=None):\n    \"\"\"\n    If the raw op result has a non-None name (e.g. it is an Index object) and\n    the name argument is None, then passing name to the constructor will\n    not be enough; we still need to override the name attribute.\n    \"\"\"\n    out = left._constructor(result, index=index, dtype=dtype)\n    out = out.__finalize__(left)\n    out.name = name\n    return out",
        "begin_line": 580,
        "end_line": 589,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.ops.__init__.wrapper#615",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.wrapper(left, right)",
        "snippet": "    def wrapper(left, right):\n        if isinstance(right, ABCDataFrame):\n            return NotImplemented\n\n        left, right = _align_method_SERIES(left, right)\n        res_name = get_op_result_name(left, right)\n        right = maybe_upcast_for_op(right, left.shape)\n\n        if should_extension_dispatch(left, right):\n            result = dispatch_to_extension_op(op, left, right)\n\n        elif is_timedelta64_dtype(right) or isinstance(\n            right, (ABCDatetimeArray, ABCDatetimeIndex)\n        ):\n            # We should only get here with td64 right with non-scalar values\n            #  for right upcast by maybe_upcast_for_op\n            assert not isinstance(right, (np.timedelta64, np.ndarray))\n            result = op(left._values, right)\n\n        else:\n            lvalues = extract_array(left, extract_numpy=True)\n            rvalues = extract_array(right, extract_numpy=True)\n\n            with np.errstate(all=\"ignore\"):\n                result = na_op(lvalues, rvalues)\n\n        # We do not pass dtype to ensure that the Series constructor\n        #  does inference in the case where `result` has object-dtype.\n        return construct_result(left, result, index=left.index, name=res_name)",
        "begin_line": 615,
        "end_line": 643,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.ops.__init__._combine_series_frame#882",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__._combine_series_frame(self, other, func, fill_value=None, axis=None, level=None)",
        "snippet": "def _combine_series_frame(self, other, func, fill_value=None, axis=None, level=None):\n    \"\"\"\n    Apply binary operator `func` to self, other using alignment and fill\n    conventions determined by the fill_value, axis, and level kwargs.\n\n    Parameters\n    ----------\n    self : DataFrame\n    other : Series\n    func : binary operator\n    fill_value : object, default None\n    axis : {0, 1, 'columns', 'index', None}, default None\n    level : int or None, default None\n\n    Returns\n    -------\n    result : DataFrame\n    \"\"\"\n    if fill_value is not None:\n        raise NotImplementedError(\n            \"fill_value {fill} not supported.\".format(fill=fill_value)\n        )\n\n    if axis is not None:\n        axis = self._get_axis_number(axis)\n        if axis == 0:\n            return self._combine_match_index(other, func, level=level)\n        else:\n            return self._combine_match_columns(other, func, level=level)\n    else:\n        if not len(other):\n            return self * np.nan\n\n        if not len(self):\n            # Ambiguous case, use _series so works with DataFrame\n            return self._constructor(\n                data=self._series, index=self.index, columns=self.columns\n            )\n\n        # default axis is columns\n        return self._combine_match_columns(other, func, level=level)",
        "begin_line": 882,
        "end_line": 922,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.ops.__init__._align_method_FRAME#925",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__._align_method_FRAME(left, right, axis)",
        "snippet": "def _align_method_FRAME(left, right, axis):\n    \"\"\" convert rhs to meet lhs dims if input is list, tuple or np.ndarray \"\"\"\n\n    def to_series(right):\n        msg = \"Unable to coerce to Series, length must be {req_len}: given {given_len}\"\n        if axis is not None and left._get_axis_name(axis) == \"index\":\n            if len(left.index) != len(right):\n                raise ValueError(\n                    msg.format(req_len=len(left.index), given_len=len(right))\n                )\n            right = left._constructor_sliced(right, index=left.index)\n        else:\n            if len(left.columns) != len(right):\n                raise ValueError(\n                    msg.format(req_len=len(left.columns), given_len=len(right))\n                )\n            right = left._constructor_sliced(right, index=left.columns)\n        return right\n\n    if isinstance(right, np.ndarray):\n\n        if right.ndim == 1:\n            right = to_series(right)\n\n        elif right.ndim == 2:\n            if right.shape == left.shape:\n                right = left._constructor(right, index=left.index, columns=left.columns)\n\n            elif right.shape[0] == left.shape[0] and right.shape[1] == 1:\n                # Broadcast across columns\n                right = np.broadcast_to(right, left.shape)\n                right = left._constructor(right, index=left.index, columns=left.columns)\n\n            elif right.shape[1] == left.shape[1] and right.shape[0] == 1:\n                # Broadcast along rows\n                right = to_series(right[0, :])\n\n            else:\n                raise ValueError(\n                    \"Unable to coerce to DataFrame, shape \"\n                    \"must be {req_shape}: given {given_shape}\".format(\n                        req_shape=left.shape, given_shape=right.shape\n                    )\n                )\n\n        elif right.ndim > 2:\n            raise ValueError(\n                \"Unable to coerce to Series/DataFrame, dim \"\n                \"must be <= 2: {dim}\".format(dim=right.shape)\n            )\n\n    elif is_list_like(right) and not isinstance(right, (ABCSeries, ABCDataFrame)):\n        # GH17901\n        right = to_series(right)\n\n    return right",
        "begin_line": 925,
        "end_line": 980,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.ops.__init__.to_series#928",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.to_series(right)",
        "snippet": "    def to_series(right):\n        msg = \"Unable to coerce to Series, length must be {req_len}: given {given_len}\"\n        if axis is not None and left._get_axis_name(axis) == \"index\":\n            if len(left.index) != len(right):\n                raise ValueError(\n                    msg.format(req_len=len(left.index), given_len=len(right))\n                )\n            right = left._constructor_sliced(right, index=left.index)\n        else:\n            if len(left.columns) != len(right):\n                raise ValueError(\n                    msg.format(req_len=len(left.columns), given_len=len(right))\n                )\n            right = left._constructor_sliced(right, index=left.columns)\n        return right",
        "begin_line": 928,
        "end_line": 942,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.ops.__init__._arith_method_FRAME#983",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__._arith_method_FRAME(cls, op, special)",
        "snippet": "def _arith_method_FRAME(cls, op, special):\n    str_rep = _get_opstr(op, cls)\n    op_name = _get_op_name(op, special)\n    eval_kwargs = _gen_eval_kwargs(op_name)\n    default_axis = _get_frame_op_default_axis(op_name)\n\n    na_op = define_na_arithmetic_op(op, str_rep, eval_kwargs)\n\n    if op_name in _op_descriptions:\n        # i.e. include \"add\" but not \"__add__\"\n        doc = _make_flex_doc(op_name, \"dataframe\")\n    else:\n        doc = _arith_doc_FRAME % op_name\n\n    @Appender(doc)\n    def f(self, other, axis=default_axis, level=None, fill_value=None):\n\n        other = _align_method_FRAME(self, other, axis)\n\n        if isinstance(other, ABCDataFrame):\n            # Another DataFrame\n            pass_op = op if should_series_dispatch(self, other, op) else na_op\n            return self._combine_frame(other, pass_op, fill_value, level)\n        elif isinstance(other, ABCSeries):\n            # For these values of `axis`, we end up dispatching to Series op,\n            # so do not want the masked op.\n            pass_op = op if axis in [0, \"columns\", None] else na_op\n            return _combine_series_frame(\n                self, other, pass_op, fill_value=fill_value, axis=axis, level=level\n            )\n        else:\n            if fill_value is not None:\n                self = self.fillna(fill_value)\n\n            assert np.ndim(other) == 0\n            return self._combine_const(other, op)\n\n    f.__name__ = op_name\n\n    return f",
        "begin_line": 983,
        "end_line": 1022,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.ops.__init__.f#998",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.f(self, other, axis=default_axis, level=None, fill_value=None)",
        "snippet": "    def f(self, other, axis=default_axis, level=None, fill_value=None):\n\n        other = _align_method_FRAME(self, other, axis)\n\n        if isinstance(other, ABCDataFrame):\n            # Another DataFrame\n            pass_op = op if should_series_dispatch(self, other, op) else na_op\n            return self._combine_frame(other, pass_op, fill_value, level)\n        elif isinstance(other, ABCSeries):\n            # For these values of `axis`, we end up dispatching to Series op,\n            # so do not want the masked op.\n            pass_op = op if axis in [0, \"columns\", None] else na_op\n            return _combine_series_frame(\n                self, other, pass_op, fill_value=fill_value, axis=axis, level=level\n            )\n        else:\n            if fill_value is not None:\n                self = self.fillna(fill_value)\n\n            assert np.ndim(other) == 0\n            return self._combine_const(other, op)",
        "begin_line": 998,
        "end_line": 1018,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.missing.isna#50",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing.isna(obj)",
        "snippet": "def isna(obj):\n    \"\"\"\n    Detect missing values for an array-like object.\n\n    This function takes a scalar or array-like object and indicates\n    whether values are missing (``NaN`` in numeric arrays, ``None`` or ``NaN``\n    in object arrays, ``NaT`` in datetimelike).\n\n    Parameters\n    ----------\n    obj : scalar or array-like\n        Object to check for null or missing values.\n\n    Returns\n    -------\n    bool or array-like of bool\n        For scalar input, returns a scalar boolean.\n        For array input, returns an array of boolean indicating whether each\n        corresponding element is missing.\n\n    See Also\n    --------\n    notna : Boolean inverse of pandas.isna.\n    Series.isna : Detect missing values in a Series.\n    DataFrame.isna : Detect missing values in a DataFrame.\n    Index.isna : Detect missing values in an Index.\n\n    Examples\n    --------\n    Scalar arguments (including strings) result in a scalar boolean.\n\n    >>> pd.isna('dog')\n    False\n\n    >>> pd.isna(np.nan)\n    True\n\n    ndarrays result in an ndarray of booleans.\n\n    >>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n    >>> array\n    array([[ 1., nan,  3.],\n           [ 4.,  5., nan]])\n    >>> pd.isna(array)\n    array([[False,  True, False],\n           [False, False,  True]])\n\n    For indexes, an ndarray of booleans is returned.\n\n    >>> index = pd.DatetimeIndex([\"2017-07-05\", \"2017-07-06\", None,\n    ...                           \"2017-07-08\"])\n    >>> index\n    DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],\n                  dtype='datetime64[ns]', freq=None)\n    >>> pd.isna(index)\n    array([False, False,  True, False])\n\n    For Series and DataFrame, the same type is returned, containing booleans.\n\n    >>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])\n    >>> df\n         0     1    2\n    0  ant   bee  cat\n    1  dog  None  fly\n    >>> pd.isna(df)\n           0      1      2\n    0  False  False  False\n    1  False   True  False\n\n    >>> pd.isna(df[1])\n    0    False\n    1     True\n    Name: 1, dtype: bool\n    \"\"\"\n    return _isna(obj)",
        "begin_line": 50,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.missing._isna_new#130",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing._isna_new(obj)",
        "snippet": "def _isna_new(obj):\n    if is_scalar(obj):\n        return libmissing.checknull(obj)\n    # hack (for now) because MI registers as ndarray\n    elif isinstance(obj, ABCMultiIndex):\n        raise NotImplementedError(\"isna is not defined for MultiIndex\")\n    elif isinstance(\n        obj,\n        (\n            ABCSeries,\n            np.ndarray,\n            ABCIndexClass,\n            ABCExtensionArray,\n            ABCDatetimeArray,\n            ABCTimedeltaArray,\n        ),\n    ):\n        return _isna_ndarraylike(obj)\n    elif isinstance(obj, ABCGeneric):\n        return obj._constructor(obj._data.isna(func=isna))\n    elif isinstance(obj, list):\n        return _isna_ndarraylike(np.asarray(obj, dtype=object))\n    elif hasattr(obj, \"__array__\"):\n        return _isna_ndarraylike(np.asarray(obj))\n    else:\n        return obj is None",
        "begin_line": 130,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.missing._isna_ndarraylike#215",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing._isna_ndarraylike(obj)",
        "snippet": "def _isna_ndarraylike(obj):\n    is_extension = is_extension_array_dtype(obj)\n\n    if not is_extension:\n        # Avoid accessing `.values` on things like\n        # PeriodIndex, which may be expensive.\n        values = getattr(obj, \"values\", obj)\n    else:\n        values = obj\n\n    dtype = values.dtype\n\n    if is_extension:\n        if isinstance(obj, (ABCIndexClass, ABCSeries)):\n            values = obj._values\n        else:\n            values = obj\n        result = values.isna()\n    elif isinstance(obj, ABCDatetimeArray):\n        return obj.isna()\n    elif is_string_dtype(dtype):\n        # Working around NumPy ticket 1542\n        shape = values.shape\n\n        if is_string_like_dtype(dtype):\n            # object array of strings\n            result = np.zeros(values.shape, dtype=bool)\n        else:\n            # object array of non-strings\n            result = np.empty(shape, dtype=bool)\n            vec = libmissing.isnaobj(values.ravel())\n            result[...] = vec.reshape(shape)\n\n    elif needs_i8_conversion(dtype):\n        # this is the NaT pattern\n        result = values.view(\"i8\") == iNaT\n    else:\n        result = np.isnan(values)\n\n    # box\n    if isinstance(obj, ABCSeries):\n        result = obj._constructor(result, index=obj.index, name=obj.name, copy=False)\n\n    return result",
        "begin_line": 215,
        "end_line": 258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.missing.notna#289",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing.notna(obj)",
        "snippet": "def notna(obj):\n    \"\"\"\n    Detect non-missing values for an array-like object.\n\n    This function takes a scalar or array-like object and indicates\n    whether values are valid (not missing, which is ``NaN`` in numeric\n    arrays, ``None`` or ``NaN`` in object arrays, ``NaT`` in datetimelike).\n\n    Parameters\n    ----------\n    obj : array-like or object value\n        Object to check for *not* null or *non*-missing values.\n\n    Returns\n    -------\n    bool or array-like of bool\n        For scalar input, returns a scalar boolean.\n        For array input, returns an array of boolean indicating whether each\n        corresponding element is valid.\n\n    See Also\n    --------\n    isna : Boolean inverse of pandas.notna.\n    Series.notna : Detect valid values in a Series.\n    DataFrame.notna : Detect valid values in a DataFrame.\n    Index.notna : Detect valid values in an Index.\n\n    Examples\n    --------\n    Scalar arguments (including strings) result in a scalar boolean.\n\n    >>> pd.notna('dog')\n    True\n\n    >>> pd.notna(np.nan)\n    False\n\n    ndarrays result in an ndarray of booleans.\n\n    >>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n    >>> array\n    array([[ 1., nan,  3.],\n           [ 4.,  5., nan]])\n    >>> pd.notna(array)\n    array([[ True, False,  True],\n           [ True,  True, False]])\n\n    For indexes, an ndarray of booleans is returned.\n\n    >>> index = pd.DatetimeIndex([\"2017-07-05\", \"2017-07-06\", None,\n    ...                          \"2017-07-08\"])\n    >>> index\n    DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],\n                  dtype='datetime64[ns]', freq=None)\n    >>> pd.notna(index)\n    array([ True,  True, False,  True])\n\n    For Series and DataFrame, the same type is returned, containing booleans.\n\n    >>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])\n    >>> df\n         0     1    2\n    0  ant   bee  cat\n    1  dog  None  fly\n    >>> pd.notna(df)\n          0      1     2\n    0  True   True  True\n    1  True  False  True\n\n    >>> pd.notna(df[1])\n    0     True\n    1    False\n    Name: 1, dtype: bool\n    \"\"\"\n    res = isna(obj)\n    if is_scalar(res):\n        return not res\n    return ~res",
        "begin_line": 289,
        "end_line": 366,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.missing.array_equivalent#389",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing.array_equivalent(left, right, strict_nan=False)",
        "snippet": "def array_equivalent(left, right, strict_nan=False):\n    \"\"\"\n    True if two arrays, left and right, have equal non-NaN elements, and NaNs\n    in corresponding locations.  False otherwise. It is assumed that left and\n    right are NumPy arrays of the same dtype. The behavior of this function\n    (particularly with respect to NaNs) is not defined if the dtypes are\n    different.\n\n    Parameters\n    ----------\n    left, right : ndarrays\n    strict_nan : bool, default False\n        If True, consider NaN and None to be different.\n\n    Returns\n    -------\n    b : bool\n        Returns True if the arrays are equivalent.\n\n    Examples\n    --------\n    >>> array_equivalent(\n    ...     np.array([1, 2, np.nan]),\n    ...     np.array([1, 2, np.nan]))\n    True\n    >>> array_equivalent(\n    ...     np.array([1, np.nan, 2]),\n    ...     np.array([1, 2, np.nan]))\n    False\n    \"\"\"\n\n    left, right = np.asarray(left), np.asarray(right)\n\n    # shape compat\n    if left.shape != right.shape:\n        return False\n\n    # Object arrays can contain None, NaN and NaT.\n    # string dtypes must be come to this path for NumPy 1.7.1 compat\n    if is_string_dtype(left) or is_string_dtype(right):\n\n        if not strict_nan:\n            # isna considers NaN and None to be equivalent.\n            return lib.array_equivalent_object(\n                ensure_object(left.ravel()), ensure_object(right.ravel())\n            )\n\n        for left_value, right_value in zip(left, right):\n            if left_value is NaT and right_value is not NaT:\n                return False\n\n            elif isinstance(left_value, float) and np.isnan(left_value):\n                if not isinstance(right_value, float) or not np.isnan(right_value):\n                    return False\n            else:\n                if left_value != right_value:\n                    return False\n        return True\n\n    # NaNs can occur in float and complex arrays.\n    if is_float_dtype(left) or is_complex_dtype(left):\n\n        # empty\n        if not (np.prod(left.shape) and np.prod(right.shape)):\n            return True\n        return ((left == right) | (isna(left) & isna(right))).all()\n\n    # numpy will will not allow this type of datetimelike vs integer comparison\n    elif is_datetimelike_v_numeric(left, right):\n        return False\n\n    # M8/m8\n    elif needs_i8_conversion(left) and needs_i8_conversion(right):\n        if not is_dtype_equal(left.dtype, right.dtype):\n            return False\n\n        left = left.view(\"i8\")\n        right = right.view(\"i8\")\n\n    # if we have structured dtypes, compare first\n    if left.dtype.type is np.void or right.dtype.type is np.void:\n        if left.dtype != right.dtype:\n            return False\n\n    return np.array_equal(left, right)",
        "begin_line": 389,
        "end_line": 473,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.dtypes.common.classes#210",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.classes(*klasses)",
        "snippet": "def classes(*klasses) -> Callable:\n    \"\"\" evaluate if the tipo is a subclass of the klasses \"\"\"\n    return lambda tipo: issubclass(tipo, klasses)",
        "begin_line": 210,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.classes_and_not_datetimelike#215",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.classes_and_not_datetimelike(*klasses)",
        "snippet": "def classes_and_not_datetimelike(*klasses) -> Callable:\n    \"\"\"\n    evaluate if the tipo is a subclass of the klasses\n    and not a datetimelike\n    \"\"\"\n    return lambda tipo: (\n        issubclass(tipo, klasses)\n        and not issubclass(tipo, (np.datetime64, np.timedelta64))\n    )",
        "begin_line": 215,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02564102564102564,
            "pseudo_dstar_susp": 0.023809523809523808,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.023809523809523808,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_object_dtype#226",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_object_dtype(arr_or_dtype)",
        "snippet": "def is_object_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether an array-like or dtype is of the object dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the object dtype.\n\n    Examples\n    --------\n    >>> is_object_dtype(object)\n    True\n    >>> is_object_dtype(int)\n    False\n    >>> is_object_dtype(np.array([], dtype=object))\n    True\n    >>> is_object_dtype(np.array([], dtype=int))\n    False\n    >>> is_object_dtype([1, 2, 3])\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.object_))",
        "begin_line": 226,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_sparse#256",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_sparse(arr)",
        "snippet": "def is_sparse(arr):\n    \"\"\"\n    Check whether an array-like is a 1-D pandas sparse array.\n\n    Check that the one-dimensional array-like is a pandas sparse array.\n    Returns True if it is a pandas sparse array, not another type of\n    sparse array.\n\n    Parameters\n    ----------\n    arr : array-like\n        Array-like to check.\n\n    Returns\n    -------\n    bool\n        Whether or not the array-like is a pandas sparse array.\n\n    See Also\n    --------\n    DataFrame.to_sparse : Convert DataFrame to a SparseDataFrame.\n    Series.to_sparse : Convert Series to SparseSeries.\n    Series.to_dense : Return dense representation of a Series.\n\n    Examples\n    --------\n    Returns `True` if the parameter is a 1-D pandas sparse array.\n\n    >>> is_sparse(pd.SparseArray([0, 0, 1, 0]))\n    True\n    >>> is_sparse(pd.SparseSeries([0, 0, 1, 0]))\n    True\n\n    Returns `False` if the parameter is not sparse.\n\n    >>> is_sparse(np.array([0, 0, 1, 0]))\n    False\n    >>> is_sparse(pd.Series([0, 1, 0, 0]))\n    False\n\n    Returns `False` if the parameter is not a pandas sparse array.\n\n    >>> from scipy.sparse import bsr_matrix\n    >>> is_sparse(bsr_matrix([0, 1, 0, 0]))\n    False\n\n    Returns `False` if the parameter has more than one dimension.\n\n    >>> df = pd.SparseDataFrame([389., 24., 80.5, np.nan],\n                                columns=['max_speed'],\n                                index=['falcon', 'parrot', 'lion', 'monkey'])\n    >>> is_sparse(df)\n    False\n    >>> is_sparse(df.max_speed)\n    True\n    \"\"\"\n    from pandas.core.arrays.sparse import SparseDtype\n\n    dtype = getattr(arr, \"dtype\", arr)\n    return isinstance(dtype, SparseDtype)",
        "begin_line": 256,
        "end_line": 315,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_categorical#358",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_categorical(arr)",
        "snippet": "def is_categorical(arr) -> bool:\n    \"\"\"\n    Check whether an array-like is a Categorical instance.\n\n    Parameters\n    ----------\n    arr : array-like\n        The array-like to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like is of a Categorical instance.\n\n    Examples\n    --------\n    >>> is_categorical([1, 2, 3])\n    False\n\n    Categoricals, Series Categoricals, and CategoricalIndex will return True.\n\n    >>> cat = pd.Categorical([1, 2, 3])\n    >>> is_categorical(cat)\n    True\n    >>> is_categorical(pd.Series(cat))\n    True\n    >>> is_categorical(pd.CategoricalIndex([1, 2, 3]))\n    True\n    \"\"\"\n\n    return isinstance(arr, ABCCategorical) or is_categorical_dtype(arr)",
        "begin_line": 358,
        "end_line": 388,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64_dtype#509",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether an array-like or dtype is of the datetime64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the datetime64 dtype.\n\n    Examples\n    --------\n    >>> is_datetime64_dtype(object)\n    False\n    >>> is_datetime64_dtype(np.datetime64)\n    True\n    >>> is_datetime64_dtype(np.array([], dtype=int))\n    False\n    >>> is_datetime64_dtype(np.array([], dtype=np.datetime64))\n    True\n    >>> is_datetime64_dtype([1, 2, 3])\n    False\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes(np.datetime64))",
        "begin_line": 509,
        "end_line": 537,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64tz_dtype#540",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64tz_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64tz_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether an array-like or dtype is of a DatetimeTZDtype dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of a DatetimeTZDtype dtype.\n\n    Examples\n    --------\n    >>> is_datetime64tz_dtype(object)\n    False\n    >>> is_datetime64tz_dtype([1, 2, 3])\n    False\n    >>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3]))  # tz-naive\n    False\n    >>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    True\n\n    >>> dtype = DatetimeTZDtype(\"ns\", tz=\"US/Eastern\")\n    >>> s = pd.Series([], dtype=dtype)\n    >>> is_datetime64tz_dtype(dtype)\n    True\n    >>> is_datetime64tz_dtype(s)\n    True\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    return DatetimeTZDtype.is_dtype(arr_or_dtype)",
        "begin_line": 540,
        "end_line": 575,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_timedelta64_dtype#578",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_timedelta64_dtype(arr_or_dtype)",
        "snippet": "def is_timedelta64_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether an array-like or dtype is of the timedelta64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the timedelta64 dtype.\n\n    Examples\n    --------\n    >>> is_timedelta64_dtype(object)\n    False\n    >>> is_timedelta64_dtype(np.timedelta64)\n    True\n    >>> is_timedelta64_dtype([1, 2, 3])\n    False\n    >>> is_timedelta64_dtype(pd.Series([], dtype=\"timedelta64[ns]\"))\n    True\n    >>> is_timedelta64_dtype('0 days')\n    False\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes(np.timedelta64))",
        "begin_line": 578,
        "end_line": 606,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_period_dtype#609",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_period_dtype(arr_or_dtype)",
        "snippet": "def is_period_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether an array-like or dtype is of the Period dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Period dtype.\n\n    Examples\n    --------\n    >>> is_period_dtype(object)\n    False\n    >>> is_period_dtype(PeriodDtype(freq=\"D\"))\n    True\n    >>> is_period_dtype([1, 2, 3])\n    False\n    >>> is_period_dtype(pd.Period(\"2017-01-01\"))\n    False\n    >>> is_period_dtype(pd.PeriodIndex([], freq=\"A\"))\n    True\n    \"\"\"\n\n    # TODO: Consider making Period an instance of PeriodDtype\n    if arr_or_dtype is None:\n        return False\n    return PeriodDtype.is_dtype(arr_or_dtype)",
        "begin_line": 609,
        "end_line": 640,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_interval_dtype#643",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_interval_dtype(arr_or_dtype)",
        "snippet": "def is_interval_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether an array-like or dtype is of the Interval dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Interval dtype.\n\n    Examples\n    --------\n    >>> is_interval_dtype(object)\n    False\n    >>> is_interval_dtype(IntervalDtype())\n    True\n    >>> is_interval_dtype([1, 2, 3])\n    False\n    >>>\n    >>> interval = pd.Interval(1, 2, closed=\"right\")\n    >>> is_interval_dtype(interval)\n    False\n    >>> is_interval_dtype(pd.IntervalIndex([interval]))\n    True\n    \"\"\"\n\n    # TODO: Consider making Interval an instance of IntervalDtype\n    if arr_or_dtype is None:\n        return False\n    return IntervalDtype.is_dtype(arr_or_dtype)",
        "begin_line": 643,
        "end_line": 676,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_categorical_dtype#679",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_categorical_dtype(arr_or_dtype)",
        "snippet": "def is_categorical_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Categorical dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Categorical dtype.\n\n    Examples\n    --------\n    >>> is_categorical_dtype(object)\n    False\n    >>> is_categorical_dtype(CategoricalDtype())\n    True\n    >>> is_categorical_dtype([1, 2, 3])\n    False\n    >>> is_categorical_dtype(pd.Categorical([1, 2, 3]))\n    True\n    >>> is_categorical_dtype(pd.CategoricalIndex([1, 2, 3]))\n    True\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    return CategoricalDtype.is_dtype(arr_or_dtype)",
        "begin_line": 679,
        "end_line": 709,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_string_dtype#712",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_string_dtype(arr_or_dtype)",
        "snippet": "def is_string_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether the provided array or dtype is of the string dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the string dtype.\n\n    Examples\n    --------\n    >>> is_string_dtype(str)\n    True\n    >>> is_string_dtype(object)\n    True\n    >>> is_string_dtype(int)\n    False\n    >>>\n    >>> is_string_dtype(np.array(['a', 'b']))\n    True\n    >>> is_string_dtype(pd.Series([1, 2]))\n    False\n    \"\"\"\n\n    # TODO: gh-15585: consider making the checks stricter.\n    def condition(dtype):\n        return dtype.kind in (\"O\", \"S\", \"U\") and not is_period_dtype(dtype)\n\n    return _is_dtype(arr_or_dtype, condition)",
        "begin_line": 712,
        "end_line": 745,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.condition#742",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.condition(dtype)",
        "snippet": "    def condition(dtype):\n        return dtype.kind in (\"O\", \"S\", \"U\") and not is_period_dtype(dtype)",
        "begin_line": 742,
        "end_line": 743,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetimelike#815",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetimelike(arr)",
        "snippet": "def is_datetimelike(arr):\n    \"\"\"\n    Check whether an array-like is a datetime-like array-like.\n\n    Acceptable datetime-like objects are (but not limited to) datetime\n    indices, periodic indices, and timedelta indices.\n\n    Parameters\n    ----------\n    arr : array-like\n        The array-like to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like is a datetime-like array-like.\n\n    Examples\n    --------\n    >>> is_datetimelike([1, 2, 3])\n    False\n    >>> is_datetimelike(pd.Index([1, 2, 3]))\n    False\n    >>> is_datetimelike(pd.DatetimeIndex([1, 2, 3]))\n    True\n    >>> is_datetimelike(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    True\n    >>> is_datetimelike(pd.PeriodIndex([], freq=\"A\"))\n    True\n    >>> is_datetimelike(np.array([], dtype=np.datetime64))\n    True\n    >>> is_datetimelike(pd.Series([], dtype=\"timedelta64[ns]\"))\n    True\n    >>>\n    >>> dtype = DatetimeTZDtype(\"ns\", tz=\"US/Eastern\")\n    >>> s = pd.Series([], dtype=dtype)\n    >>> is_datetimelike(s)\n    True\n    \"\"\"\n\n    return (\n        is_datetime64_dtype(arr)\n        or is_datetime64tz_dtype(arr)\n        or is_timedelta64_dtype(arr)\n        or isinstance(arr, ABCPeriodIndex)\n    )",
        "begin_line": 815,
        "end_line": 860,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_dtype_equal#863",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_dtype_equal(source, target)",
        "snippet": "def is_dtype_equal(source, target):\n    \"\"\"\n    Check if two dtypes are equal.\n\n    Parameters\n    ----------\n    source : The first dtype to compare\n    target : The second dtype to compare\n\n    Returns\n    -------\n    boolean\n        Whether or not the two dtypes are equal.\n\n    Examples\n    --------\n    >>> is_dtype_equal(int, float)\n    False\n    >>> is_dtype_equal(\"int\", int)\n    True\n    >>> is_dtype_equal(object, \"category\")\n    False\n    >>> is_dtype_equal(CategoricalDtype(), \"category\")\n    True\n    >>> is_dtype_equal(DatetimeTZDtype(), \"datetime64\")\n    False\n    \"\"\"\n\n    try:\n        source = _get_dtype(source)\n        target = _get_dtype(target)\n        return source == target\n    except (TypeError, AttributeError):\n\n        # invalid comparison\n        # object == category will hit this\n        return False",
        "begin_line": 863,
        "end_line": 899,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_integer_dtype#952",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_integer_dtype(arr_or_dtype)",
        "snippet": "def is_integer_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether the provided array or dtype is of an integer dtype.\n\n    Unlike in `in_any_int_dtype`, timedelta64 instances will return False.\n\n    .. versionchanged:: 0.24.0\n\n       The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\n       as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of an integer dtype and\n        not an instance of timedelta64.\n\n    Examples\n    --------\n    >>> is_integer_dtype(str)\n    False\n    >>> is_integer_dtype(int)\n    True\n    >>> is_integer_dtype(float)\n    False\n    >>> is_integer_dtype(np.uint64)\n    True\n    >>> is_integer_dtype('int8')\n    True\n    >>> is_integer_dtype('Int8')\n    True\n    >>> is_integer_dtype(pd.Int8Dtype)\n    True\n    >>> is_integer_dtype(np.datetime64)\n    False\n    >>> is_integer_dtype(np.timedelta64)\n    False\n    >>> is_integer_dtype(np.array(['a', 'b']))\n    False\n    >>> is_integer_dtype(pd.Series([1, 2]))\n    True\n    >>> is_integer_dtype(np.array([], dtype=np.timedelta64))\n    False\n    >>> is_integer_dtype(pd.Index([1, 2.]))  # float\n    False\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes_and_not_datetimelike(np.integer))",
        "begin_line": 952,
        "end_line": 1004,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_signed_integer_dtype#1007",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_signed_integer_dtype(arr_or_dtype)",
        "snippet": "def is_signed_integer_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether the provided array or dtype is of a signed integer dtype.\n\n    Unlike in `in_any_int_dtype`, timedelta64 instances will return False.\n\n    .. versionchanged:: 0.24.0\n\n       The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\n       as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a signed integer dtype\n        and not an instance of timedelta64.\n\n    Examples\n    --------\n    >>> is_signed_integer_dtype(str)\n    False\n    >>> is_signed_integer_dtype(int)\n    True\n    >>> is_signed_integer_dtype(float)\n    False\n    >>> is_signed_integer_dtype(np.uint64)  # unsigned\n    False\n    >>> is_signed_integer_dtype('int8')\n    True\n    >>> is_signed_integer_dtype('Int8')\n    True\n    >>> is_signed_dtype(pd.Int8Dtype)\n    True\n    >>> is_signed_integer_dtype(np.datetime64)\n    False\n    >>> is_signed_integer_dtype(np.timedelta64)\n    False\n    >>> is_signed_integer_dtype(np.array(['a', 'b']))\n    False\n    >>> is_signed_integer_dtype(pd.Series([1, 2]))\n    True\n    >>> is_signed_integer_dtype(np.array([], dtype=np.timedelta64))\n    False\n    >>> is_signed_integer_dtype(pd.Index([1, 2.]))  # float\n    False\n    >>> is_signed_integer_dtype(np.array([1, 2], dtype=np.uint32))  # unsigned\n    False\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes_and_not_datetimelike(np.signedinteger))",
        "begin_line": 1007,
        "end_line": 1061,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_unsigned_integer_dtype#1064",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_unsigned_integer_dtype(arr_or_dtype)",
        "snippet": "def is_unsigned_integer_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether the provided array or dtype is of an unsigned integer dtype.\n\n    .. versionchanged:: 0.24.0\n\n       The nullable Integer dtypes (e.g. pandas.UInt64Dtype) are also\n       considered as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of an unsigned integer dtype.\n\n    Examples\n    --------\n    >>> is_unsigned_integer_dtype(str)\n    False\n    >>> is_unsigned_integer_dtype(int)  # signed\n    False\n    >>> is_unsigned_integer_dtype(float)\n    False\n    >>> is_unsigned_integer_dtype(np.uint64)\n    True\n    >>> is_unsigned_integer_dtype('uint8')\n    True\n    >>> is_unsigned_integer_dtype('UInt8')\n    True\n    >>> is_unsigned_integer_dtype(pd.UInt8Dtype)\n    True\n    >>> is_unsigned_integer_dtype(np.array(['a', 'b']))\n    False\n    >>> is_unsigned_integer_dtype(pd.Series([1, 2]))  # signed\n    False\n    >>> is_unsigned_integer_dtype(pd.Index([1, 2.]))  # float\n    False\n    >>> is_unsigned_integer_dtype(np.array([1, 2], dtype=np.uint32))\n    True\n    \"\"\"\n    return _is_dtype_type(\n        arr_or_dtype, classes_and_not_datetimelike(np.unsignedinteger)\n    )",
        "begin_line": 1064,
        "end_line": 1110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64_any_dtype#1164",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64_any_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64_any_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of the datetime64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the datetime64 dtype.\n\n    Examples\n    --------\n    >>> is_datetime64_any_dtype(str)\n    False\n    >>> is_datetime64_any_dtype(int)\n    False\n    >>> is_datetime64_any_dtype(np.datetime64)  # can be tz-naive\n    True\n    >>> is_datetime64_any_dtype(DatetimeTZDtype(\"ns\", \"US/Eastern\"))\n    True\n    >>> is_datetime64_any_dtype(np.array(['a', 'b']))\n    False\n    >>> is_datetime64_any_dtype(np.array([1, 2]))\n    False\n    >>> is_datetime64_any_dtype(np.array([], dtype=np.datetime64))\n    True\n    >>> is_datetime64_any_dtype(pd.DatetimeIndex([1, 2, 3],\n                                dtype=np.datetime64))\n    True\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    return is_datetime64_dtype(arr_or_dtype) or is_datetime64tz_dtype(arr_or_dtype)",
        "begin_line": 1164,
        "end_line": 1201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64_ns_dtype#1204",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64_ns_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64_ns_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether the provided array or dtype is of the datetime64[ns] dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the datetime64[ns] dtype.\n\n    Examples\n    --------\n    >>> is_datetime64_ns_dtype(str)\n    False\n    >>> is_datetime64_ns_dtype(int)\n    False\n    >>> is_datetime64_ns_dtype(np.datetime64)  # no unit\n    False\n    >>> is_datetime64_ns_dtype(DatetimeTZDtype(\"ns\", \"US/Eastern\"))\n    True\n    >>> is_datetime64_ns_dtype(np.array(['a', 'b']))\n    False\n    >>> is_datetime64_ns_dtype(np.array([1, 2]))\n    False\n    >>> is_datetime64_ns_dtype(np.array([], dtype=np.datetime64))  # no unit\n    False\n    >>> is_datetime64_ns_dtype(np.array([],\n                               dtype=\"datetime64[ps]\"))  # wrong unit\n    False\n    >>> is_datetime64_ns_dtype(pd.DatetimeIndex([1, 2, 3],\n                               dtype=np.datetime64))  # has 'ns' unit\n    True\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    try:\n        tipo = _get_dtype(arr_or_dtype)\n    except TypeError:\n        if is_datetime64tz_dtype(arr_or_dtype):\n            tipo = _get_dtype(arr_or_dtype.dtype)\n        else:\n            return False\n    return tipo == _NS_DTYPE or getattr(tipo, \"base\", None) == _NS_DTYPE",
        "begin_line": 1204,
        "end_line": 1251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_timedelta64_ns_dtype#1254",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_timedelta64_ns_dtype(arr_or_dtype)",
        "snippet": "def is_timedelta64_ns_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether the provided array or dtype is of the timedelta64[ns] dtype.\n\n    This is a very specific dtype, so generic ones like `np.timedelta64`\n    will return False if passed into this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the timedelta64[ns] dtype.\n\n    Examples\n    --------\n    >>> is_timedelta64_ns_dtype(np.dtype('m8[ns]'))\n    True\n    >>> is_timedelta64_ns_dtype(np.dtype('m8[ps]'))  # Wrong frequency\n    False\n    >>> is_timedelta64_ns_dtype(np.array([1, 2], dtype='m8[ns]'))\n    True\n    >>> is_timedelta64_ns_dtype(np.array([1, 2], dtype=np.timedelta64))\n    False\n    \"\"\"\n    return _is_dtype(arr_or_dtype, lambda dtype: dtype == _TD_DTYPE)",
        "begin_line": 1254,
        "end_line": 1282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02564102564102564,
            "pseudo_dstar_susp": 0.023809523809523808,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.023809523809523808,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime_or_timedelta_dtype#1285",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime_or_timedelta_dtype(arr_or_dtype)",
        "snippet": "def is_datetime_or_timedelta_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether the provided array or dtype is of\n    a timedelta64 or datetime64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a timedelta64,\n        or datetime64 dtype.\n\n    Examples\n    --------\n    >>> is_datetime_or_timedelta_dtype(str)\n    False\n    >>> is_datetime_or_timedelta_dtype(int)\n    False\n    >>> is_datetime_or_timedelta_dtype(np.datetime64)\n    True\n    >>> is_datetime_or_timedelta_dtype(np.timedelta64)\n    True\n    >>> is_datetime_or_timedelta_dtype(np.array(['a', 'b']))\n    False\n    >>> is_datetime_or_timedelta_dtype(pd.Series([1, 2]))\n    False\n    >>> is_datetime_or_timedelta_dtype(np.array([], dtype=np.timedelta64))\n    True\n    >>> is_datetime_or_timedelta_dtype(np.array([], dtype=np.datetime64))\n    True\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes(np.datetime64, np.timedelta64))",
        "begin_line": 1285,
        "end_line": 1321,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetimelike_v_numeric#1408",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetimelike_v_numeric(a, b)",
        "snippet": "def is_datetimelike_v_numeric(a, b):\n    \"\"\"\n    Check if we are comparing a datetime-like object to a numeric object.\n\n    By \"numeric,\" we mean an object that is either of an int or float dtype.\n\n    Parameters\n    ----------\n    a : array-like, scalar\n        The first object to check.\n    b : array-like, scalar\n        The second object to check.\n\n    Returns\n    -------\n    boolean\n        Whether we return a comparing a datetime-like to a numeric object.\n\n    Examples\n    --------\n    >>> dt = np.datetime64(pd.datetime(2017, 1, 1))\n    >>>\n    >>> is_datetimelike_v_numeric(1, 1)\n    False\n    >>> is_datetimelike_v_numeric(dt, dt)\n    False\n    >>> is_datetimelike_v_numeric(1, dt)\n    True\n    >>> is_datetimelike_v_numeric(dt, 1)  # symmetric check\n    True\n    >>> is_datetimelike_v_numeric(np.array([dt]), 1)\n    True\n    >>> is_datetimelike_v_numeric(np.array([1]), dt)\n    True\n    >>> is_datetimelike_v_numeric(np.array([dt]), np.array([1]))\n    True\n    >>> is_datetimelike_v_numeric(np.array([1]), np.array([2]))\n    False\n    >>> is_datetimelike_v_numeric(np.array([dt]), np.array([dt]))\n    False\n    \"\"\"\n\n    if not hasattr(a, \"dtype\"):\n        a = np.asarray(a)\n    if not hasattr(b, \"dtype\"):\n        b = np.asarray(b)\n\n    def is_numeric(x):\n        \"\"\"\n        Check if an object has a numeric dtype (i.e. integer or float).\n        \"\"\"\n        return is_integer_dtype(x) or is_float_dtype(x)\n\n    is_datetimelike = needs_i8_conversion\n    return (is_datetimelike(a) and is_numeric(b)) or (\n        is_datetimelike(b) and is_numeric(a)\n    )",
        "begin_line": 1408,
        "end_line": 1464,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_numeric#1455",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_numeric(x)",
        "snippet": "    def is_numeric(x):\n        \"\"\"\n        Check if an object has a numeric dtype (i.e. integer or float).\n        \"\"\"\n        return is_integer_dtype(x) or is_float_dtype(x)",
        "begin_line": 1455,
        "end_line": 1459,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.dtypes.common.needs_i8_conversion#1467",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.needs_i8_conversion(arr_or_dtype)",
        "snippet": "def needs_i8_conversion(arr_or_dtype):\n    \"\"\"\n    Check whether the array or dtype should be converted to int64.\n\n    An array-like or dtype \"needs\" such a conversion if the array-like\n    or dtype is of a datetime-like dtype\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype should be converted to int64.\n\n    Examples\n    --------\n    >>> needs_i8_conversion(str)\n    False\n    >>> needs_i8_conversion(np.int64)\n    False\n    >>> needs_i8_conversion(np.datetime64)\n    True\n    >>> needs_i8_conversion(np.array(['a', 'b']))\n    False\n    >>> needs_i8_conversion(pd.Series([1, 2]))\n    False\n    >>> needs_i8_conversion(pd.Series([], dtype=\"timedelta64[ns]\"))\n    True\n    >>> needs_i8_conversion(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    True\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    return (\n        is_datetime_or_timedelta_dtype(arr_or_dtype)\n        or is_datetime64tz_dtype(arr_or_dtype)\n        or is_period_dtype(arr_or_dtype)\n    )",
        "begin_line": 1467,
        "end_line": 1508,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_float_dtype#1586",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_float_dtype(arr_or_dtype)",
        "snippet": "def is_float_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether the provided array or dtype is of a float dtype.\n\n    This function is internal and should not be exposed in the public API.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a float dtype.\n\n    Examples\n    --------\n    >>> is_float_dtype(str)\n    False\n    >>> is_float_dtype(int)\n    False\n    >>> is_float_dtype(float)\n    True\n    >>> is_float_dtype(np.array(['a', 'b']))\n    False\n    >>> is_float_dtype(pd.Series([1, 2]))\n    False\n    >>> is_float_dtype(pd.Index([1, 2.]))\n    True\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.floating))",
        "begin_line": 1586,
        "end_line": 1617,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_bool_dtype#1620",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_bool_dtype(arr_or_dtype)",
        "snippet": "def is_bool_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a boolean dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a boolean dtype.\n\n    Notes\n    -----\n    An ExtensionArray is considered boolean when the ``_is_boolean``\n    attribute is set to True.\n\n    Examples\n    --------\n    >>> is_bool_dtype(str)\n    False\n    >>> is_bool_dtype(int)\n    False\n    >>> is_bool_dtype(bool)\n    True\n    >>> is_bool_dtype(np.bool)\n    True\n    >>> is_bool_dtype(np.array(['a', 'b']))\n    False\n    >>> is_bool_dtype(pd.Series([1, 2]))\n    False\n    >>> is_bool_dtype(np.array([True, False]))\n    True\n    >>> is_bool_dtype(pd.Categorical([True, False]))\n    True\n    >>> is_bool_dtype(pd.SparseArray([True, False]))\n    True\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    try:\n        dtype = _get_dtype(arr_or_dtype)\n    except TypeError:\n        return False\n\n    if isinstance(arr_or_dtype, CategoricalDtype):\n        arr_or_dtype = arr_or_dtype.categories\n        # now we use the special definition for Index\n\n    if isinstance(arr_or_dtype, ABCIndexClass):\n\n        # TODO(jreback)\n        # we don't have a boolean Index class\n        # so its object, we need to infer to\n        # guess this\n        return arr_or_dtype.is_object and arr_or_dtype.inferred_type == \"boolean\"\n    elif is_extension_array_dtype(arr_or_dtype):\n        dtype = getattr(arr_or_dtype, \"dtype\", arr_or_dtype)\n        return dtype._is_boolean\n\n    return issubclass(dtype.type, np.bool_)",
        "begin_line": 1620,
        "end_line": 1682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_extension_type#1685",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_extension_type(arr)",
        "snippet": "def is_extension_type(arr):\n    \"\"\"\n    Check whether an array-like is of a pandas extension class instance.\n\n    Extension classes include categoricals, pandas sparse objects (i.e.\n    classes represented within the pandas library and not ones external\n    to it like scipy sparse matrices), and datetime-like arrays.\n\n    Parameters\n    ----------\n    arr : array-like\n        The array-like to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like is of a pandas extension class instance.\n\n    Examples\n    --------\n    >>> is_extension_type([1, 2, 3])\n    False\n    >>> is_extension_type(np.array([1, 2, 3]))\n    False\n    >>>\n    >>> cat = pd.Categorical([1, 2, 3])\n    >>>\n    >>> is_extension_type(cat)\n    True\n    >>> is_extension_type(pd.Series(cat))\n    True\n    >>> is_extension_type(pd.SparseArray([1, 2, 3]))\n    True\n    >>> is_extension_type(pd.SparseSeries([1, 2, 3]))\n    True\n    >>>\n    >>> from scipy.sparse import bsr_matrix\n    >>> is_extension_type(bsr_matrix([1, 2, 3]))\n    False\n    >>> is_extension_type(pd.DatetimeIndex([1, 2, 3]))\n    False\n    >>> is_extension_type(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    True\n    >>>\n    >>> dtype = DatetimeTZDtype(\"ns\", tz=\"US/Eastern\")\n    >>> s = pd.Series([], dtype=dtype)\n    >>> is_extension_type(s)\n    True\n    \"\"\"\n\n    if is_categorical(arr):\n        return True\n    elif is_sparse(arr):\n        return True\n    elif is_datetime64tz_dtype(arr):\n        return True\n    return False",
        "begin_line": 1685,
        "end_line": 1741,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_extension_array_dtype#1744",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_extension_array_dtype(arr_or_dtype)",
        "snippet": "def is_extension_array_dtype(arr_or_dtype):\n    \"\"\"\n    Check if an object is a pandas extension array type.\n\n    See the :ref:`Use Guide <extending.extension-types>` for more.\n\n    Parameters\n    ----------\n    arr_or_dtype : object\n        For array-like input, the ``.dtype`` attribute will\n        be extracted.\n\n    Returns\n    -------\n    bool\n        Whether the `arr_or_dtype` is an extension array type.\n\n    Notes\n    -----\n    This checks whether an object implements the pandas extension\n    array interface. In pandas, this includes:\n\n    * Categorical\n    * Sparse\n    * Interval\n    * Period\n    * DatetimeArray\n    * TimedeltaArray\n\n    Third-party libraries may implement arrays or types satisfying\n    this interface as well.\n\n    Examples\n    --------\n    >>> from pandas.api.types import is_extension_array_dtype\n    >>> arr = pd.Categorical(['a', 'b'])\n    >>> is_extension_array_dtype(arr)\n    True\n    >>> is_extension_array_dtype(arr.dtype)\n    True\n\n    >>> arr = np.array(['a', 'b'])\n    >>> is_extension_array_dtype(arr.dtype)\n    False\n    \"\"\"\n    dtype = getattr(arr_or_dtype, \"dtype\", arr_or_dtype)\n    return isinstance(dtype, ExtensionDtype) or registry.find(dtype) is not None",
        "begin_line": 1744,
        "end_line": 1790,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_complex_dtype#1793",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_complex_dtype(arr_or_dtype)",
        "snippet": "def is_complex_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a complex dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a complex dtype.\n\n    Examples\n    --------\n    >>> is_complex_dtype(str)\n    False\n    >>> is_complex_dtype(int)\n    False\n    >>> is_complex_dtype(np.complex)\n    True\n    >>> is_complex_dtype(np.array(['a', 'b']))\n    False\n    >>> is_complex_dtype(pd.Series([1, 2]))\n    False\n    >>> is_complex_dtype(np.array([1 + 1j, 5]))\n    True\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes(np.complexfloating))",
        "begin_line": 1793,
        "end_line": 1823,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common._is_dtype#1826",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._is_dtype(arr_or_dtype, condition)",
        "snippet": "def _is_dtype(arr_or_dtype, condition) -> bool:\n    \"\"\"\n    Return a boolean if the condition is satisfied for the arr_or_dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like, str, np.dtype, or ExtensionArrayType\n        The array-like or dtype object whose dtype we want to extract.\n    condition : callable[Union[np.dtype, ExtensionDtype]]\n\n    Returns\n    -------\n    bool\n\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    try:\n        dtype = _get_dtype(arr_or_dtype)\n    except (TypeError, ValueError, UnicodeEncodeError):\n        return False\n    return condition(dtype)",
        "begin_line": 1826,
        "end_line": 1848,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.common._get_dtype#1851",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._get_dtype(arr_or_dtype)",
        "snippet": "def _get_dtype(arr_or_dtype):\n    \"\"\"\n    Get the dtype instance associated with an array\n    or dtype object.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype object whose dtype we want to extract.\n\n    Returns\n    -------\n    obj_dtype : The extract dtype instance from the\n                passed in array or dtype object.\n\n    Raises\n    ------\n    TypeError : The passed in object is None.\n    \"\"\"\n\n    if arr_or_dtype is None:\n        raise TypeError(\"Cannot deduce dtype from null object\")\n\n    # fastpath\n    elif isinstance(arr_or_dtype, np.dtype):\n        return arr_or_dtype\n    elif isinstance(arr_or_dtype, type):\n        return np.dtype(arr_or_dtype)\n\n    # if we have an array-like\n    elif hasattr(arr_or_dtype, \"dtype\"):\n        arr_or_dtype = arr_or_dtype.dtype\n\n    return pandas_dtype(arr_or_dtype)",
        "begin_line": 1851,
        "end_line": 1884,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common._is_dtype_type#1887",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._is_dtype_type(arr_or_dtype, condition)",
        "snippet": "def _is_dtype_type(arr_or_dtype, condition) -> bool:\n    \"\"\"\n    Return a boolean if the condition is satisfied for the arr_or_dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype object whose dtype we want to extract.\n    condition : callable[Union[np.dtype, ExtensionDtypeType]]\n\n    Returns\n    -------\n    bool : if the condition is satisfied for the arr_or_dtype\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return condition(type(None))\n\n    # fastpath\n    if isinstance(arr_or_dtype, np.dtype):\n        return condition(arr_or_dtype.type)\n    elif isinstance(arr_or_dtype, type):\n        if issubclass(arr_or_dtype, ExtensionDtype):\n            arr_or_dtype = arr_or_dtype.type\n        return condition(np.dtype(arr_or_dtype).type)\n\n    # if we have an array-like\n    if hasattr(arr_or_dtype, \"dtype\"):\n        arr_or_dtype = arr_or_dtype.dtype\n\n    # we are not possibly a dtype\n    elif is_list_like(arr_or_dtype):\n        return condition(type(None))\n\n    try:\n        tipo = pandas_dtype(arr_or_dtype).type\n    except (TypeError, ValueError, UnicodeEncodeError):\n        if is_scalar(arr_or_dtype):\n            return condition(type(None))\n\n        return False\n\n    return condition(tipo)",
        "begin_line": 1887,
        "end_line": 1929,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.dtypes.common.pandas_dtype#2021",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.pandas_dtype(dtype)",
        "snippet": "def pandas_dtype(dtype):\n    \"\"\"\n    Convert input into a pandas only dtype object or a numpy dtype object.\n\n    Parameters\n    ----------\n    dtype : object to be converted\n\n    Returns\n    -------\n    np.dtype or a pandas dtype\n\n    Raises\n    ------\n    TypeError if not a dtype\n    \"\"\"\n    # short-circuit\n    if isinstance(dtype, np.ndarray):\n        return dtype.dtype\n    elif isinstance(dtype, (np.dtype, ExtensionDtype)):\n        return dtype\n\n    # registered extension types\n    result = registry.find(dtype)\n    if result is not None:\n        return result\n\n    # try a numpy dtype\n    # raise a consistent TypeError if failed\n    try:\n        npdtype = np.dtype(dtype)\n    except Exception:\n        # we don't want to force a repr of the non-string\n        if not isinstance(dtype, str):\n            raise TypeError(\"data type not understood\")\n        raise TypeError(\"data type '{}' not understood\".format(dtype))\n\n    # Any invalid dtype (such as pd.Timestamp) should raise an error.\n    # np.dtype(invalid_type).kind = 0 for such objects. However, this will\n    # also catch some valid dtypes such as object, np.object_ and 'object'\n    # which we safeguard against by catching them earlier and returning\n    # np.dtype(valid_dtype) before this condition is evaluated.\n    if is_hashable(dtype) and dtype in [object, np.object_, \"object\", \"O\"]:\n        # check hashability to avoid errors/DeprecationWarning when we get\n        # here and `dtype` is an array\n        return npdtype\n    elif npdtype.kind == \"O\":\n        raise TypeError(\"dtype '{}' not understood\".format(dtype))\n\n    return npdtype",
        "begin_line": 2021,
        "end_line": 2070,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.construction.arrays_to_mgr#58",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction.arrays_to_mgr(arrays, arr_names, index, columns, dtype=None)",
        "snippet": "def arrays_to_mgr(arrays, arr_names, index, columns, dtype=None):\n    \"\"\"\n    Segregate Series based on type and coerce into matrices.\n\n    Needs to handle a lot of exceptional cases.\n    \"\"\"\n    # figure out the index, if necessary\n    if index is None:\n        index = extract_index(arrays)\n    else:\n        index = ensure_index(index)\n\n    # don't force copy because getting jammed in an ndarray anyway\n    arrays = _homogenize(arrays, index, dtype)\n\n    # from BlockManager perspective\n    axes = [ensure_index(columns), index]\n\n    return create_block_manager_from_arrays(arrays, arr_names, axes)",
        "begin_line": 58,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.construction.init_ndarray#122",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction.init_ndarray(values, index, columns, dtype=None, copy=False)",
        "snippet": "def init_ndarray(values, index, columns, dtype=None, copy=False):\n    # input must be a ndarray, list, Series, index\n\n    if isinstance(values, ABCSeries):\n        if columns is None:\n            if values.name is not None:\n                columns = [values.name]\n        if index is None:\n            index = values.index\n        else:\n            values = values.reindex(index)\n\n        # zero len case (GH #2234)\n        if not len(values) and columns is not None and len(columns):\n            values = np.empty((0, 1), dtype=object)\n\n    # we could have a categorical type passed or coerced to 'category'\n    # recast this to an arrays_to_mgr\n    if is_categorical_dtype(getattr(values, \"dtype\", None)) or is_categorical_dtype(\n        dtype\n    ):\n\n        if not hasattr(values, \"dtype\"):\n            values = prep_ndarray(values, copy=copy)\n            values = values.ravel()\n        elif copy:\n            values = values.copy()\n\n        index, columns = _get_axes(len(values), 1, index, columns)\n        return arrays_to_mgr([values], columns, index, columns, dtype=dtype)\n    elif is_extension_array_dtype(values):\n        # GH#19157\n        if columns is None:\n            columns = [0]\n        return arrays_to_mgr([values], columns, index, columns, dtype=dtype)\n\n    # by definition an array here\n    # the dtypes will be coerced to a single dtype\n    values = prep_ndarray(values, copy=copy)\n\n    if dtype is not None:\n        if not is_dtype_equal(values.dtype, dtype):\n            try:\n                values = values.astype(dtype)\n            except Exception as orig:\n                e = ValueError(\n                    \"failed to cast to '{dtype}' (Exception \"\n                    \"was: {orig})\".format(dtype=dtype, orig=orig)\n                )\n                raise_with_traceback(e)\n\n    index, columns = _get_axes(*values.shape, index=index, columns=columns)\n    values = values.T\n\n    # if we don't have a dtype specified, then try to convert objects\n    # on the entire block; this is to convert if we have datetimelike's\n    # embedded in an object type\n    if dtype is None and is_object_dtype(values):\n\n        if values.ndim == 2 and values.shape[0] != 1:\n            # transpose and separate blocks\n\n            dvals_list = [maybe_infer_to_datetimelike(row) for row in values]\n            for n in range(len(dvals_list)):\n                if isinstance(dvals_list[n], np.ndarray):\n                    dvals_list[n] = dvals_list[n].reshape(1, -1)\n\n            from pandas.core.internals.blocks import make_block\n\n            # TODO: What about re-joining object columns?\n            block_values = [\n                make_block(dvals_list[n], placement=[n]) for n in range(len(dvals_list))\n            ]\n\n        else:\n            datelike_vals = maybe_infer_to_datetimelike(values)\n            block_values = [datelike_vals]\n    else:\n        block_values = [values]\n\n    return create_block_manager_from_blocks(block_values, [columns, index])",
        "begin_line": 122,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.construction.init_dict#205",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction.init_dict(data, index, columns, dtype=None)",
        "snippet": "def init_dict(data, index, columns, dtype=None):\n    \"\"\"\n    Segregate Series based on type and coerce into matrices.\n    Needs to handle a lot of exceptional cases.\n    \"\"\"\n    if columns is not None:\n        from pandas.core.series import Series\n\n        arrays = Series(data, index=columns, dtype=object)\n        data_names = arrays.index\n\n        missing = arrays.isna()\n        if index is None:\n            # GH10856\n            # raise ValueError if only scalars in dict\n            index = extract_index(arrays[~missing])\n        else:\n            index = ensure_index(index)\n\n        # no obvious \"empty\" int column\n        if missing.any() and not is_integer_dtype(dtype):\n            if dtype is None or np.issubdtype(dtype, np.flexible):\n                # GH#1783\n                nan_dtype = object\n            else:\n                nan_dtype = dtype\n            val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype)\n            arrays.loc[missing] = [val] * missing.sum()\n\n    else:\n        keys = com.dict_keys_to_ordered_list(data)\n        columns = data_names = Index(keys)\n        arrays = (com.maybe_iterable_to_list(data[k]) for k in keys)\n        # GH#24096 need copy to be deep for datetime64tz case\n        # TODO: See if we can avoid these copies\n        arrays = [\n            arr if not isinstance(arr, ABCIndexClass) else arr._data for arr in arrays\n        ]\n        arrays = [\n            arr if not is_datetime64tz_dtype(arr) else arr.copy() for arr in arrays\n        ]\n    return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)",
        "begin_line": 205,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02564102564102564,
            "pseudo_dstar_susp": 0.023809523809523808,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.023809523809523808,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.construction.prep_ndarray#252",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction.prep_ndarray(values, copy=True)",
        "snippet": "def prep_ndarray(values, copy=True):\n    if not isinstance(values, (np.ndarray, ABCSeries, Index)):\n        if len(values) == 0:\n            return np.empty((0, 0), dtype=object)\n\n        def convert(v):\n            return maybe_convert_platform(v)\n\n        # we could have a 1-dim or 2-dim list here\n        # this is equiv of np.asarray, but does object conversion\n        # and platform dtype preservation\n        try:\n            if is_list_like(values[0]) or hasattr(values[0], \"len\"):\n                values = np.array([convert(v) for v in values])\n            elif isinstance(values[0], np.ndarray) and values[0].ndim == 0:\n                # GH#21861\n                values = np.array([convert(v) for v in values])\n            else:\n                values = convert(values)\n        except (ValueError, TypeError):\n            values = convert(values)\n\n    else:\n\n        # drop subclass info, do not copy data\n        values = np.asarray(values)\n        if copy:\n            values = values.copy()\n\n    if values.ndim == 1:\n        values = values.reshape((values.shape[0], 1))\n    elif values.ndim != 2:\n        raise ValueError(\"Must pass 2-d input\")\n\n    return values",
        "begin_line": 252,
        "end_line": 286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.internals.construction._homogenize#289",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction._homogenize(data, index, dtype=None)",
        "snippet": "def _homogenize(data, index, dtype=None):\n    oindex = None\n    homogenized = []\n\n    for val in data:\n        if isinstance(val, ABCSeries):\n            if dtype is not None:\n                val = val.astype(dtype)\n            if val.index is not index:\n                # Forces alignment. No need to copy data since we\n                # are putting it into an ndarray later\n                val = val.reindex(index, copy=False)\n        else:\n            if isinstance(val, dict):\n                if oindex is None:\n                    oindex = index.astype(\"O\")\n\n                if isinstance(index, (ABCDatetimeIndex, ABCTimedeltaIndex)):\n                    val = com.dict_compat(val)\n                else:\n                    val = dict(val)\n                val = lib.fast_multiget(val, oindex.values, default=np.nan)\n            val = sanitize_array(\n                val, index, dtype=dtype, copy=False, raise_cast_failure=False\n            )\n\n        homogenized.append(val)\n\n    return homogenized",
        "begin_line": 289,
        "end_line": 317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.internals.construction._get_axes#409",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction._get_axes(N, K, index, columns)",
        "snippet": "def _get_axes(N, K, index, columns):\n    # helper to create the axes as indexes\n    # return axes or defaults\n\n    if index is None:\n        index = ibase.default_index(N)\n    else:\n        index = ensure_index(index)\n\n    if columns is None:\n        columns = ibase.default_index(K)\n    else:\n        columns = ensure_index(columns)\n    return index, columns",
        "begin_line": 409,
        "end_line": 422,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.construction.extract_array#317",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction.extract_array(obj, extract_numpy=False)",
        "snippet": "def extract_array(obj, extract_numpy=False):\n    \"\"\"\n    Extract the ndarray or ExtensionArray from a Series or Index.\n\n    For all other types, `obj` is just returned as is.\n\n    Parameters\n    ----------\n    obj : object\n        For Series / Index, the underlying ExtensionArray is unboxed.\n        For Numpy-backed ExtensionArrays, the ndarray is extracted.\n\n    extract_numpy : bool, default False\n        Whether to extract the ndarray from a PandasArray\n\n    Returns\n    -------\n    arr : object\n\n    Examples\n    --------\n    >>> extract_array(pd.Series(['a', 'b', 'c'], dtype='category'))\n    [a, b, c]\n    Categories (3, object): [a, b, c]\n\n    Other objects like lists, arrays, and DataFrames are just passed through.\n\n    >>> extract_array([1, 2, 3])\n    [1, 2, 3]\n\n    For an ndarray-backed Series / Index a PandasArray is returned.\n\n    >>> extract_array(pd.Series([1, 2, 3]))\n    <PandasArray>\n    [1, 2, 3]\n    Length: 3, dtype: int64\n\n    To extract all the way down to the ndarray, pass ``extract_numpy=True``.\n\n    >>> extract_array(pd.Series([1, 2, 3]), extract_numpy=True)\n    array([1, 2, 3])\n    \"\"\"\n    if isinstance(obj, (ABCIndexClass, ABCSeries)):\n        obj = obj.array\n\n    if extract_numpy and isinstance(obj, ABCPandasArray):\n        obj = obj.to_numpy()\n\n    return obj",
        "begin_line": 317,
        "end_line": 365,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.construction.sanitize_array#368",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction.sanitize_array(data, index, dtype=None, copy=False, raise_cast_failure=False)",
        "snippet": "def sanitize_array(data, index, dtype=None, copy=False, raise_cast_failure=False):\n    \"\"\"\n    Sanitize input data to an ndarray, copy if specified, coerce to the\n    dtype if specified.\n    \"\"\"\n    if dtype is not None:\n        dtype = pandas_dtype(dtype)\n\n    if isinstance(data, ma.MaskedArray):\n        mask = ma.getmaskarray(data)\n        if mask.any():\n            data, fill_value = maybe_upcast(data, copy=True)\n            data.soften_mask()  # set hardmask False if it was True\n            data[mask] = fill_value\n        else:\n            data = data.copy()\n\n    # extract ndarray or ExtensionArray, ensure we have no PandasArray\n    data = extract_array(data, extract_numpy=True)\n\n    # GH#846\n    if isinstance(data, np.ndarray):\n\n        if dtype is not None and is_float_dtype(data.dtype) and is_integer_dtype(dtype):\n            # possibility of nan -> garbage\n            try:\n                subarr = _try_cast(data, dtype, copy, True)\n            except ValueError:\n                if copy:\n                    subarr = data.copy()\n                else:\n                    subarr = np.array(data, copy=False)\n        else:\n            # we will try to copy be-definition here\n            subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n\n    elif isinstance(data, ABCExtensionArray):\n        # it is already ensured above this is not a PandasArray\n        subarr = data\n\n        if dtype is not None:\n            subarr = subarr.astype(dtype, copy=copy)\n        elif copy:\n            subarr = subarr.copy()\n        return subarr\n\n    elif isinstance(data, (list, tuple)) and len(data) > 0:\n        if dtype is not None:\n            try:\n                subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n            except Exception:\n                if raise_cast_failure:  # pragma: no cover\n                    raise\n                subarr = np.array(data, dtype=object, copy=copy)\n                subarr = lib.maybe_convert_objects(subarr)\n\n        else:\n            subarr = maybe_convert_platform(data)\n\n        subarr = maybe_cast_to_datetime(subarr, dtype)\n\n    elif isinstance(data, range):\n        # GH#16804\n        arr = np.arange(data.start, data.stop, data.step, dtype=\"int64\")\n        subarr = _try_cast(arr, dtype, copy, raise_cast_failure)\n    else:\n        subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n\n    # scalar like, GH\n    if getattr(subarr, \"ndim\", 0) == 0:\n        if isinstance(data, list):  # pragma: no cover\n            subarr = np.array(data, dtype=object)\n        elif index is not None:\n            value = data\n\n            # figure out the dtype from the value (upcast if necessary)\n            if dtype is None:\n                dtype, value = infer_dtype_from_scalar(value)\n            else:\n                # need to possibly convert the value here\n                value = maybe_cast_to_datetime(value, dtype)\n\n            subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype)\n\n        else:\n            return subarr.item()\n\n    # the result that we want\n    elif subarr.ndim == 1:\n        if index is not None:\n\n            # a 1-element ndarray\n            if len(subarr) != len(index) and len(subarr) == 1:\n                subarr = construct_1d_arraylike_from_scalar(\n                    subarr[0], len(index), subarr.dtype\n                )\n\n    elif subarr.ndim > 1:\n        if isinstance(data, np.ndarray):\n            raise Exception(\"Data must be 1-dimensional\")\n        else:\n            subarr = com.asarray_tuplesafe(data, dtype=dtype)\n\n    if not (is_extension_array_dtype(subarr.dtype) or is_extension_array_dtype(dtype)):\n        # This is to prevent mixed-type Series getting all casted to\n        # NumPy string type, e.g. NaN --> '-1#IND'.\n        if issubclass(subarr.dtype.type, str):\n            # GH#16605\n            # If not empty convert the data to dtype\n            # GH#19853: If data is a scalar, subarr has already the result\n            if not lib.is_scalar(data):\n                if not np.all(isna(data)):\n                    data = np.array(data, dtype=dtype, copy=False)\n                subarr = np.array(data, dtype=object, copy=copy)\n\n        if is_object_dtype(subarr.dtype) and not is_object_dtype(dtype):\n            inferred = lib.infer_dtype(subarr, skipna=False)\n            if inferred == \"period\":\n                from pandas.core.arrays import period_array\n\n                try:\n                    subarr = period_array(subarr)\n                except IncompatibleFrequency:\n                    pass\n\n    return subarr",
        "begin_line": 368,
        "end_line": 493,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.construction._try_cast#496",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction._try_cast(arr, dtype, copy, raise_cast_failure)",
        "snippet": "def _try_cast(arr, dtype, copy, raise_cast_failure):\n    \"\"\"\n    Convert input to numpy ndarray and optionally cast to a given dtype.\n\n    Parameters\n    ----------\n    arr : array-like\n    dtype : np.dtype, ExtensionDtype or None\n    copy : bool\n        If False, don't copy the data if not needed.\n    raise_cast_failure : bool\n        If True, and if a dtype is specified, raise errors during casting.\n        Otherwise an object array is returned.\n    \"\"\"\n    # perf shortcut as this is the most common case\n    if isinstance(arr, np.ndarray):\n        if maybe_castable(arr) and not copy and dtype is None:\n            return arr\n\n    try:\n        # GH#15832: Check if we are requesting a numeric dype and\n        # that we can convert the data to the requested dtype.\n        if is_integer_dtype(dtype):\n            subarr = maybe_cast_to_integer_array(arr, dtype)\n\n        subarr = maybe_cast_to_datetime(arr, dtype)\n        # Take care in creating object arrays (but iterators are not\n        # supported):\n        if is_object_dtype(dtype) and (\n            is_list_like(subarr)\n            and not (is_iterator(subarr) or isinstance(subarr, np.ndarray))\n        ):\n            subarr = construct_1d_object_array_from_listlike(subarr)\n        elif not is_extension_type(subarr):\n            subarr = construct_1d_ndarray_preserving_na(subarr, dtype, copy=copy)\n    except OutOfBoundsDatetime:\n        # in case of out of bound datetime64 -> always raise\n        raise\n    except (ValueError, TypeError):\n        if is_categorical_dtype(dtype):\n            # We *do* allow casting to categorical, since we know\n            # that Categorical is the only array type for 'category'.\n            subarr = dtype.construct_array_type()(\n                arr, dtype.categories, ordered=dtype._ordered\n            )\n        elif is_extension_array_dtype(dtype):\n            # create an extension array from its dtype\n            array_type = dtype.construct_array_type()._from_sequence\n            subarr = array_type(arr, dtype=dtype, copy=copy)\n        elif dtype is not None and raise_cast_failure:\n            raise\n        else:\n            subarr = np.array(arr, dtype=object, copy=copy)\n    return subarr",
        "begin_line": 496,
        "end_line": 549,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexers.is_list_like_indexer#13",
        "src_path": "pandas/core/indexers.py",
        "class_name": "pandas.core.indexers",
        "signature": "pandas.core.indexers.is_list_like_indexer(key)",
        "snippet": "def is_list_like_indexer(key) -> bool:\n    \"\"\"\n    Check if we have a list-like indexer that is *not* a NamedTuple.\n\n    Parameters\n    ----------\n    key : object\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    # allow a list_like, but exclude NamedTuples which can be indexers\n    return is_list_like(key) and not (isinstance(key, tuple) and type(key) is not tuple)",
        "begin_line": 13,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.io.formats.printing.adjoin#13",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.adjoin(space: int, *lists: List[str], **kwargs)",
        "snippet": "def adjoin(space: int, *lists: List[str], **kwargs) -> str:\n    \"\"\"\n    Glues together two sets of strings using the amount of space requested.\n    The idea is to prettify.\n\n    ----------\n    space : int\n        number of spaces for padding\n    lists : str\n        list of str which being joined\n    strlen : callable\n        function used to calculate the length of each str. Needed for unicode\n        handling.\n    justfunc : callable\n        function used to justify str. Needed for unicode handling.\n    \"\"\"\n    strlen = kwargs.pop(\"strlen\", len)\n    justfunc = kwargs.pop(\"justfunc\", justify)\n\n    out_lines = []\n    newLists = []\n    lengths = [max(map(strlen, x)) + space for x in lists[:-1]]\n    # not the last one\n    lengths.append(max(map(len, lists[-1])))\n    maxLen = max(map(len, lists))\n    for i, lst in enumerate(lists):\n        nl = justfunc(lst, lengths[i], mode=\"left\")\n        nl.extend([\" \" * lengths[i]] * (maxLen - len(lst)))\n        newLists.append(nl)\n    toJoin = zip(*newLists)\n    for lines in toJoin:\n        out_lines.append(\"\".join(lines))\n    return \"\\n\".join(out_lines)",
        "begin_line": 13,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.printing.justify#48",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.justify(texts: Iterable[str], max_len: int, mode: str='right')",
        "snippet": "def justify(texts: Iterable[str], max_len: int, mode: str = \"right\") -> List[str]:\n    \"\"\"\n    Perform ljust, center, rjust against string or list-like\n    \"\"\"\n    if mode == \"left\":\n        return [x.ljust(max_len) for x in texts]\n    elif mode == \"center\":\n        return [x.center(max_len) for x in texts]\n    else:\n        return [x.rjust(max_len) for x in texts]",
        "begin_line": 48,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.printing.pprint_thing#150",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.pprint_thing(thing, _nest_lvl: int=0, escape_chars: Optional[Union[Dict[str, str], Iterable[str]]]=None, default_escapes: bool=False, quote_strings: bool=False, max_seq_items: Optional[int]=None)",
        "snippet": "def pprint_thing(\n    thing,\n    _nest_lvl: int = 0,\n    escape_chars: Optional[Union[Dict[str, str], Iterable[str]]] = None,\n    default_escapes: bool = False,\n    quote_strings: bool = False,\n    max_seq_items: Optional[int] = None,\n) -> str:\n    \"\"\"\n    This function is the sanctioned way of converting objects\n    to a unicode representation.\n\n    properly handles nested sequences containing unicode strings\n    (unicode(object) does not)\n\n    Parameters\n    ----------\n    thing : anything to be formatted\n    _nest_lvl : internal use only. pprint_thing() is mutually-recursive\n        with pprint_sequence, this argument is used to keep track of the\n        current nesting level, and limit it.\n    escape_chars : list or dict, optional\n        Characters to escape. If a dict is passed the values are the\n        replacements\n    default_escapes : bool, default False\n        Whether the input escape characters replaces or adds to the defaults\n    max_seq_items : False, int, default None\n        Pass thru to other pretty printers to limit sequence printing\n\n    Returns\n    -------\n    result - unicode str\n\n    \"\"\"\n\n    def as_escaped_unicode(thing, escape_chars=escape_chars):\n        # Unicode is fine, else we try to decode using utf-8 and 'replace'\n        # if that's not it either, we have no way of knowing and the user\n        # should deal with it himself.\n\n        try:\n            result = str(thing)  # we should try this first\n        except UnicodeDecodeError:\n            # either utf-8 or we replace errors\n            result = str(thing).decode(\"utf-8\", \"replace\")\n\n        translate = {\"\\t\": r\"\\t\", \"\\n\": r\"\\n\", \"\\r\": r\"\\r\"}\n        if isinstance(escape_chars, dict):\n            if default_escapes:\n                translate.update(escape_chars)\n            else:\n                translate = escape_chars\n            escape_chars = list(escape_chars.keys())\n        else:\n            escape_chars = escape_chars or tuple()\n        for c in escape_chars:\n            result = result.replace(c, translate[c])\n\n        return str(result)\n\n    if hasattr(thing, \"__next__\"):\n        return str(thing)\n    elif isinstance(thing, dict) and _nest_lvl < get_option(\n        \"display.pprint_nest_depth\"\n    ):\n        result = _pprint_dict(\n            thing, _nest_lvl, quote_strings=True, max_seq_items=max_seq_items\n        )\n    elif is_sequence(thing) and _nest_lvl < get_option(\"display.pprint_nest_depth\"):\n        result = _pprint_seq(\n            thing,\n            _nest_lvl,\n            escape_chars=escape_chars,\n            quote_strings=quote_strings,\n            max_seq_items=max_seq_items,\n        )\n    elif isinstance(thing, str) and quote_strings:\n        result = \"'{thing}'\".format(thing=as_escaped_unicode(thing))\n    else:\n        result = as_escaped_unicode(thing)\n\n    return str(result)  # always unicode",
        "begin_line": 150,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.io.formats.printing.as_escaped_unicode#185",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.as_escaped_unicode(thing, escape_chars=escape_chars)",
        "snippet": "    def as_escaped_unicode(thing, escape_chars=escape_chars):\n        # Unicode is fine, else we try to decode using utf-8 and 'replace'\n        # if that's not it either, we have no way of knowing and the user\n        # should deal with it himself.\n\n        try:\n            result = str(thing)  # we should try this first\n        except UnicodeDecodeError:\n            # either utf-8 or we replace errors\n            result = str(thing).decode(\"utf-8\", \"replace\")\n\n        translate = {\"\\t\": r\"\\t\", \"\\n\": r\"\\n\", \"\\r\": r\"\\r\"}\n        if isinstance(escape_chars, dict):\n            if default_escapes:\n                translate.update(escape_chars)\n            else:\n                translate = escape_chars\n            escape_chars = list(escape_chars.keys())\n        else:\n            escape_chars = escape_chars or tuple()\n        for c in escape_chars:\n            result = result.replace(c, translate[c])\n\n        return str(result)",
        "begin_line": 185,
        "end_line": 208,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.frame.DataFrame._constructor#377",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame._constructor(self)",
        "snippet": "    def _constructor(self):\n        return DataFrame",
        "begin_line": 377,
        "end_line": 378,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.frame.DataFrame.__init__#393",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame.__init__(self, data=None, index=None, columns=None, dtype=None, copy=False)",
        "snippet": "    def __init__(self, data=None, index=None, columns=None, dtype=None, copy=False):\n        if data is None:\n            data = {}\n        if dtype is not None:\n            dtype = self._validate_dtype(dtype)\n\n        if isinstance(data, DataFrame):\n            data = data._data\n\n        if isinstance(data, BlockManager):\n            mgr = self._init_mgr(\n                data, axes=dict(index=index, columns=columns), dtype=dtype, copy=copy\n            )\n        elif isinstance(data, dict):\n            mgr = init_dict(data, index, columns, dtype=dtype)\n        elif isinstance(data, ma.MaskedArray):\n            import numpy.ma.mrecords as mrecords\n\n            # masked recarray\n            if isinstance(data, mrecords.MaskedRecords):\n                mgr = masked_rec_array_to_mgr(data, index, columns, dtype, copy)\n\n            # a masked array\n            else:\n                mask = ma.getmaskarray(data)\n                if mask.any():\n                    data, fill_value = maybe_upcast(data, copy=True)\n                    data.soften_mask()  # set hardmask False if it was True\n                    data[mask] = fill_value\n                else:\n                    data = data.copy()\n                mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n\n        elif isinstance(data, (np.ndarray, Series, Index)):\n            if data.dtype.names:\n                data_columns = list(data.dtype.names)\n                data = {k: data[k] for k in data_columns}\n                if columns is None:\n                    columns = data_columns\n                mgr = init_dict(data, index, columns, dtype=dtype)\n            elif getattr(data, \"name\", None) is not None:\n                mgr = init_dict({data.name: data}, index, columns, dtype=dtype)\n            else:\n                mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n\n        # For data is list-like, or Iterable (will consume into list)\n        elif isinstance(data, abc.Iterable) and not isinstance(data, (str, bytes)):\n            if not isinstance(data, abc.Sequence):\n                data = list(data)\n            if len(data) > 0:\n                if is_list_like(data[0]) and getattr(data[0], \"ndim\", 1) == 1:\n                    if is_named_tuple(data[0]) and columns is None:\n                        columns = data[0]._fields\n                    arrays, columns = to_arrays(data, columns, dtype=dtype)\n                    columns = ensure_index(columns)\n\n                    # set the index\n                    if index is None:\n                        if isinstance(data[0], Series):\n                            index = get_names_from_index(data)\n                        elif isinstance(data[0], Categorical):\n                            index = ibase.default_index(len(data[0]))\n                        else:\n                            index = ibase.default_index(len(data))\n\n                    mgr = arrays_to_mgr(arrays, columns, index, columns, dtype=dtype)\n                else:\n                    mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n            else:\n                mgr = init_dict({}, index, columns, dtype=dtype)\n        else:\n            try:\n                arr = np.array(data, dtype=dtype, copy=copy)\n            except (ValueError, TypeError) as e:\n                exc = TypeError(\n                    \"DataFrame constructor called with \"\n                    \"incompatible data and dtype: {e}\".format(e=e)\n                )\n                raise_with_traceback(exc)\n\n            if arr.ndim == 0 and index is not None and columns is not None:\n                values = cast_scalar_to_array(\n                    (len(index), len(columns)), data, dtype=dtype\n                )\n                mgr = init_ndarray(\n                    values, index, columns, dtype=values.dtype, copy=False\n                )\n            else:\n                raise ValueError(\"DataFrame constructor not properly called!\")\n\n        NDFrame.__init__(self, mgr, fastpath=True)",
        "begin_line": 393,
        "end_line": 483,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.frame.DataFrame.axes#488",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame.axes(self)",
        "snippet": "    def axes(self):\n        \"\"\"\n        Return a list representing the axes of the DataFrame.\n\n        It has the row axis labels and column axis labels as the only members.\n        They are returned in that order.\n\n        Examples\n        --------\n        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n        >>> df.axes\n        [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\n        dtype='object')]\n        \"\"\"\n        return [self.index, self.columns]",
        "begin_line": 488,
        "end_line": 502,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.frame.DataFrame.shape#505",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame.shape(self)",
        "snippet": "    def shape(self):\n        \"\"\"\n        Return a tuple representing the dimensionality of the DataFrame.\n\n        See Also\n        --------\n        ndarray.shape\n\n        Examples\n        --------\n        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n        >>> df.shape\n        (2, 2)\n\n        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n        ...                    'col3': [5, 6]})\n        >>> df.shape\n        (2, 3)\n        \"\"\"\n        return len(self.index), len(self.columns)",
        "begin_line": 505,
        "end_line": 524,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.frame.DataFrame._ixs#2769",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame._ixs(self, i: int, axis: int=0)",
        "snippet": "    def _ixs(self, i: int, axis: int = 0):\n        \"\"\"\n        Parameters\n        ----------\n        i : int\n        axis : int\n\n        Notes\n        -----\n        If slice passed, the resulting data will be a view.\n        \"\"\"\n        # irow\n        if axis == 0:\n            label = self.index[i]\n            new_values = self._data.fast_xs(i)\n\n            # if we are a copy, mark as such\n            copy = isinstance(new_values, np.ndarray) and new_values.base is None\n            result = self._constructor_sliced(\n                new_values,\n                index=self.columns,\n                name=self.index[i],\n                dtype=new_values.dtype,\n            )\n            result._set_is_copy(self, copy=copy)\n            return result\n\n        # icol\n        else:\n            label = self.columns[i]\n\n            # if the values returned are not the same length\n            # as the index (iow a not found value), iget returns\n            # a 0-len ndarray. This is effectively catching\n            # a numpy error (as numpy should really raise)\n            values = self._data.iget(i)\n\n            if len(self.index) and not len(values):\n                values = np.array([np.nan] * len(self.index), dtype=object)\n            result = self._box_col_values(values, label)\n\n            # this is a cached value, mark it so\n            result._set_as_cached(label, self)\n\n            return result",
        "begin_line": 2769,
        "end_line": 2813,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.frame.DataFrame._box_col_values#3118",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame._box_col_values(self, values, items)",
        "snippet": "    def _box_col_values(self, values, items):\n        \"\"\"\n        Provide boxed values for a column.\n        \"\"\"\n        klass = self._constructor_sliced\n        return klass(values, index=self.index, name=items, fastpath=True)",
        "begin_line": 3118,
        "end_line": 3123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.frame.DataFrame.align#3856",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame.align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)",
        "snippet": "    def align(\n        self,\n        other,\n        join=\"outer\",\n        axis=None,\n        level=None,\n        copy=True,\n        fill_value=None,\n        method=None,\n        limit=None,\n        fill_axis=0,\n        broadcast_axis=None,\n    ):\n        return super().align(\n            other,\n            join=join,\n            axis=axis,\n            level=level,\n            copy=copy,\n            fill_value=fill_value,\n            method=method,\n            limit=limit,\n            fill_axis=fill_axis,\n            broadcast_axis=broadcast_axis,\n        )",
        "begin_line": 3856,
        "end_line": 3880,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.frame.DataFrame._combine_match_index#5313",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame._combine_match_index(self, other, func, level=None)",
        "snippet": "    def _combine_match_index(self, other, func, level=None):\n        left, right = self.align(other, join=\"outer\", axis=0, level=level, copy=False)\n        assert left.index.equals(right.index)\n\n        if left._is_mixed_type or right._is_mixed_type:\n            # operate column-wise; avoid costly object-casting in `.values`\n            return ops.dispatch_to_series(left, right, func)\n        else:\n            # fastpath --> operate directly on values\n            with np.errstate(all=\"ignore\"):\n                new_data = func(left.values.T, right.values).T\n            return self._constructor(\n                new_data, index=left.index, columns=self.columns, copy=False\n            )",
        "begin_line": 5313,
        "end_line": 5326,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.frame.DataFrame._combine_match_columns#5328",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame._combine_match_columns(self, other, func, level=None)",
        "snippet": "    def _combine_match_columns(self, other, func, level=None):\n        assert isinstance(other, Series)\n        left, right = self.align(other, join=\"outer\", axis=1, level=level, copy=False)\n        assert left.columns.equals(right.index)\n        return ops.dispatch_to_series(left, right, func, axis=\"columns\")",
        "begin_line": 5328,
        "end_line": 5332,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.series.Series.__init__#193",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)",
        "snippet": "    def __init__(\n        self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False\n    ):\n\n        # we are called internally, so short-circuit\n        if fastpath:\n\n            # data is an ndarray, index is defined\n            if not isinstance(data, SingleBlockManager):\n                data = SingleBlockManager(data, index, fastpath=True)\n            if copy:\n                data = data.copy()\n            if index is None:\n                index = data.index\n\n        else:\n\n            if index is not None:\n                index = ensure_index(index)\n\n            if data is None:\n                data = {}\n            if dtype is not None:\n                # GH 26336: explicitly handle 'category' to avoid warning\n                # TODO: Remove after CategoricalDtype defaults to ordered=False\n                if (\n                    isinstance(dtype, str)\n                    and dtype == \"category\"\n                    and is_categorical(data)\n                ):\n                    dtype = data.dtype\n\n                dtype = self._validate_dtype(dtype)\n\n            if isinstance(data, MultiIndex):\n                raise NotImplementedError(\n                    \"initializing a Series from a MultiIndex is not supported\"\n                )\n            elif isinstance(data, Index):\n                if name is None:\n                    name = data.name\n\n                if dtype is not None:\n                    # astype copies\n                    data = data.astype(dtype)\n                else:\n                    # need to copy to avoid aliasing issues\n                    data = data._values.copy()\n                    if isinstance(data, ABCDatetimeIndex) and data.tz is not None:\n                        # GH#24096 need copy to be deep for datetime64tz case\n                        # TODO: See if we can avoid these copies\n                        data = data._values.copy(deep=True)\n                copy = False\n\n            elif isinstance(data, np.ndarray):\n                pass\n            elif isinstance(data, (ABCSeries, ABCSparseSeries)):\n                if name is None:\n                    name = data.name\n                if index is None:\n                    index = data.index\n                else:\n                    data = data.reindex(index, copy=copy)\n                data = data._data\n            elif isinstance(data, dict):\n                data, index = self._init_dict(data, index, dtype)\n                dtype = None\n                copy = False\n            elif isinstance(data, SingleBlockManager):\n                if index is None:\n                    index = data.index\n                elif not data.index.equals(index) or copy:\n                    # GH#19275 SingleBlockManager input should only be called\n                    # internally\n                    raise AssertionError(\n                        \"Cannot pass both SingleBlockManager \"\n                        \"`data` argument and a different \"\n                        \"`index` argument.  `copy` must \"\n                        \"be False.\"\n                    )\n\n            elif is_extension_array_dtype(data):\n                pass\n            elif isinstance(data, (set, frozenset)):\n                raise TypeError(\n                    \"{0!r} type is unordered\".format(data.__class__.__name__)\n                )\n            elif isinstance(data, ABCSparseArray):\n                # handle sparse passed here (and force conversion)\n                data = data.to_dense()\n            else:\n                data = com.maybe_iterable_to_list(data)\n\n            if index is None:\n                if not is_list_like(data):\n                    data = [data]\n                index = ibase.default_index(len(data))\n            elif is_list_like(data):\n\n                # a scalar numpy array is list-like but doesn't\n                # have a proper length\n                try:\n                    if len(index) != len(data):\n                        raise ValueError(\n                            \"Length of passed values is {val}, \"\n                            \"index implies {ind}\".format(val=len(data), ind=len(index))\n                        )\n                except TypeError:\n                    pass\n\n            # create/copy the manager\n            if isinstance(data, SingleBlockManager):\n                if dtype is not None:\n                    data = data.astype(dtype=dtype, errors=\"ignore\", copy=copy)\n                elif copy:\n                    data = data.copy()\n            else:\n                data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)\n\n                data = SingleBlockManager(data, index, fastpath=True)\n\n        generic.NDFrame.__init__(self, data, fastpath=True)\n\n        self.name = name\n        self._set_axis(0, index, fastpath=True)",
        "begin_line": 193,
        "end_line": 317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.series.Series._constructor#399",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._constructor(self)",
        "snippet": "    def _constructor(self):\n        return Series",
        "begin_line": 399,
        "end_line": 400,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.series.Series._set_axis#415",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._set_axis(self, axis, labels, fastpath=False)",
        "snippet": "    def _set_axis(self, axis, labels, fastpath=False):\n        \"\"\"\n        Override generic, we want to set the _typ here.\n        \"\"\"\n\n        if not fastpath:\n            labels = ensure_index(labels)\n\n        is_all_dates = labels.is_all_dates\n        if is_all_dates:\n            if not isinstance(labels, (DatetimeIndex, PeriodIndex, TimedeltaIndex)):\n                try:\n                    labels = DatetimeIndex(labels)\n                    # need to set here because we changed the index\n                    if fastpath:\n                        self._data.set_axis(axis, labels)\n                except (tslibs.OutOfBoundsDatetime, ValueError):\n                    # labels may exceeds datetime bounds,\n                    # or not be a DatetimeIndex\n                    pass\n\n        self._set_subtyp(is_all_dates)\n\n        object.__setattr__(self, \"_index\", labels)\n        if not fastpath:\n            self._data.set_axis(axis, labels)",
        "begin_line": 415,
        "end_line": 440,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.series.Series._set_subtyp#442",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._set_subtyp(self, is_all_dates)",
        "snippet": "    def _set_subtyp(self, is_all_dates):\n        if is_all_dates:\n            object.__setattr__(self, \"_subtyp\", \"time_series\")\n        else:\n            object.__setattr__(self, \"_subtyp\", \"series\")",
        "begin_line": 442,
        "end_line": 446,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.series.Series.name#453",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.name(self)",
        "snippet": "    def name(self):\n        \"\"\"\n        Return name of the Series.\n        \"\"\"\n        return self._name",
        "begin_line": 453,
        "end_line": 457,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.series.Series.name#460",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.name(self, value)",
        "snippet": "    def name(self, value):\n        if value is not None and not is_hashable(value):\n            raise TypeError(\"Series.name must be a hashable type\")\n        object.__setattr__(self, \"_name\", value)",
        "begin_line": 460,
        "end_line": 463,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.series.Series.dtype#467",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.dtype(self)",
        "snippet": "    def dtype(self):\n        \"\"\"\n        Return the dtype object of the underlying data.\n        \"\"\"\n        return self._data.dtype",
        "begin_line": 467,
        "end_line": 471,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.series.Series.dtypes#474",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.dtypes(self)",
        "snippet": "    def dtypes(self):\n        \"\"\"\n        Return the dtype object of the underlying data.\n        \"\"\"\n        return self._data.dtype",
        "begin_line": 474,
        "end_line": 478,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.series.Series.values#517",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.values(self)",
        "snippet": "    def values(self):\n        \"\"\"\n        Return Series as ndarray or ndarray-like depending on the dtype.\n\n        .. warning::\n\n           We recommend using :attr:`Series.array` or\n           :meth:`Series.to_numpy`, depending on whether you need\n           a reference to the underlying data or a NumPy array.\n\n        Returns\n        -------\n        numpy.ndarray or ndarray-like\n\n        See Also\n        --------\n        Series.array : Reference to the underlying data.\n        Series.to_numpy : A NumPy array representing the underlying data.\n\n        Examples\n        --------\n        >>> pd.Series([1, 2, 3]).values\n        array([1, 2, 3])\n\n        >>> pd.Series(list('aabc')).values\n        array(['a', 'a', 'b', 'c'], dtype=object)\n\n        >>> pd.Series(list('aabc')).astype('category').values\n        [a, a, b, c]\n        Categories (3, object): [a, b, c]\n\n        Timezone aware datetime data is converted to UTC:\n\n        >>> pd.Series(pd.date_range('20130101', periods=3,\n        ...                         tz='US/Eastern')).values\n        array(['2013-01-01T05:00:00.000000000',\n               '2013-01-02T05:00:00.000000000',\n               '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n        \"\"\"\n        return self._data.external_values()",
        "begin_line": 517,
        "end_line": 556,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.series.Series._values#559",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._values(self)",
        "snippet": "    def _values(self):\n        \"\"\"\n        Return the internal repr of this data.\n        \"\"\"\n        return self._data.internal_values()",
        "begin_line": 559,
        "end_line": 563,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.series.Series._internal_get_values#585",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._internal_get_values(self)",
        "snippet": "    def _internal_get_values(self):\n        return self._data.get_values()",
        "begin_line": 585,
        "end_line": 586,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.series.Series.__len__#712",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__len__(self)",
        "snippet": "    def __len__(self):\n        \"\"\"\n        Return the length of the Series.\n        \"\"\"\n        return len(self._data)",
        "begin_line": 712,
        "end_line": 716,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.series.Series._ixs#1057",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._ixs(self, i: int, axis: int=0)",
        "snippet": "    def _ixs(self, i: int, axis: int = 0):\n        \"\"\"\n        Return the i-th value or values in the Series by location.\n\n        Parameters\n        ----------\n        i : int\n\n        Returns\n        -------\n        scalar (int) or Series (slice, sequence)\n        \"\"\"\n\n        # dispatch to the values if we need\n        values = self._values\n        if isinstance(values, np.ndarray):\n            return libindex.get_value_at(values, i)\n        else:\n            return values[i]",
        "begin_line": 1057,
        "end_line": 1075,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.series.Series._slice#1077",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._slice(self, slobj: slice, axis: int=0, kind=None)",
        "snippet": "    def _slice(self, slobj: slice, axis: int = 0, kind=None):\n        slobj = self.index._convert_slice_indexer(slobj, kind=kind or \"getitem\")\n        return self._get_values(slobj)",
        "begin_line": 1077,
        "end_line": 1079,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.series.Series._get_values#1190",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._get_values(self, indexer)",
        "snippet": "    def _get_values(self, indexer):\n        try:\n            return self._constructor(\n                self._data.get_slice(indexer), fastpath=True\n            ).__finalize__(self)\n        except Exception:\n            return self._values[indexer]",
        "begin_line": 1190,
        "end_line": 1196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.series.Series._is_mixed_type#1361",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._is_mixed_type(self)",
        "snippet": "    def _is_mixed_type(self):\n        return False",
        "begin_line": 1361,
        "end_line": 1362,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.series.Series.__repr__#1558",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__repr__(self)",
        "snippet": "    def __repr__(self):\n        \"\"\"\n        Return a string representation for a particular Series.\n        \"\"\"\n        buf = StringIO(\"\")\n        width, height = get_terminal_size()\n        max_rows = (\n            height\n            if get_option(\"display.max_rows\") == 0\n            else get_option(\"display.max_rows\")\n        )\n        min_rows = (\n            height\n            if get_option(\"display.max_rows\") == 0\n            else get_option(\"display.min_rows\")\n        )\n        show_dimensions = get_option(\"display.show_dimensions\")\n\n        self.to_string(\n            buf=buf,\n            name=self.name,\n            dtype=self.dtype,\n            min_rows=min_rows,\n            max_rows=max_rows,\n            length=show_dimensions,\n        )\n        result = buf.getvalue()\n\n        return result",
        "begin_line": 1558,
        "end_line": 1586,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.series.Series.to_string#1588",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None, min_rows=None)",
        "snippet": "    def to_string(\n        self,\n        buf=None,\n        na_rep=\"NaN\",\n        float_format=None,\n        header=True,\n        index=True,\n        length=False,\n        dtype=False,\n        name=False,\n        max_rows=None,\n        min_rows=None,\n    ):\n        \"\"\"\n        Render a string representation of the Series.\n\n        Parameters\n        ----------\n        buf : StringIO-like, optional\n            Buffer to write to.\n        na_rep : str, optional\n            String representation of NaN to use, default 'NaN'.\n        float_format : one-parameter function, optional\n            Formatter function to apply to columns' elements if they are\n            floats, default None.\n        header : bool, default True\n            Add the Series header (index name).\n        index : bool, optional\n            Add index (row) labels, default True.\n        length : bool, default False\n            Add the Series length.\n        dtype : bool, default False\n            Add the Series dtype.\n        name : bool, default False\n            Add the Series name if not None.\n        max_rows : int, optional\n            Maximum number of rows to show before truncating. If None, show\n            all.\n        min_rows : int, optional\n            The number of rows to display in a truncated repr (when number\n            of rows is above `max_rows`).\n\n        Returns\n        -------\n        str or None\n            String representation of Series if ``buf=None``, otherwise None.\n        \"\"\"\n\n        formatter = fmt.SeriesFormatter(\n            self,\n            name=name,\n            length=length,\n            header=header,\n            index=index,\n            dtype=dtype,\n            na_rep=na_rep,\n            float_format=float_format,\n            min_rows=min_rows,\n            max_rows=max_rows,\n        )\n        result = formatter.to_string()\n\n        # catch contract violations\n        if not isinstance(result, str):\n            raise AssertionError(\n                \"result must be of type unicode, type\"\n                \" of result is {0!r}\"\n                \"\".format(result.__class__.__name__)\n            )\n\n        if buf is None:\n            return result\n        else:\n            try:\n                buf.write(result)\n            except AttributeError:\n                with open(buf, \"w\") as f:\n                    f.write(result)",
        "begin_line": 1588,
        "end_line": 1665,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__new__#256",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__new__(cls, data=None, dtype=None, copy=False, name=None, fastpath=None, tupleize_cols=True, **kwargs)",
        "snippet": "    def __new__(\n        cls,\n        data=None,\n        dtype=None,\n        copy=False,\n        name=None,\n        fastpath=None,\n        tupleize_cols=True,\n        **kwargs\n    ):\n\n        if name is None and hasattr(data, \"name\"):\n            name = data.name\n\n        if fastpath is not None:\n            warnings.warn(\n                \"The 'fastpath' keyword is deprecated, and will be \"\n                \"removed in a future version.\",\n                FutureWarning,\n                stacklevel=2,\n            )\n            if fastpath:\n                return cls._simple_new(data, name)\n\n        from .range import RangeIndex\n\n        if isinstance(data, ABCPandasArray):\n            # ensure users don't accidentally put a PandasArray in an index.\n            data = data.to_numpy()\n\n        # range\n        if isinstance(data, RangeIndex):\n            return RangeIndex(start=data, copy=copy, dtype=dtype, name=name)\n        elif isinstance(data, range):\n            return RangeIndex.from_range(data, dtype=dtype, name=name)\n\n        # categorical\n        elif is_categorical_dtype(data) or is_categorical_dtype(dtype):\n            from .category import CategoricalIndex\n\n            return CategoricalIndex(data, dtype=dtype, copy=copy, name=name, **kwargs)\n\n        # interval\n        elif (\n            is_interval_dtype(data) or is_interval_dtype(dtype)\n        ) and not is_object_dtype(dtype):\n            from .interval import IntervalIndex\n\n            closed = kwargs.get(\"closed\", None)\n            return IntervalIndex(data, dtype=dtype, name=name, copy=copy, closed=closed)\n\n        elif (\n            is_datetime64_any_dtype(data)\n            or is_datetime64_any_dtype(dtype)\n            or \"tz\" in kwargs\n        ):\n            from pandas import DatetimeIndex\n\n            if is_dtype_equal(_o_dtype, dtype):\n                # GH#23524 passing `dtype=object` to DatetimeIndex is invalid,\n                #  will raise in the where `data` is already tz-aware.  So\n                #  we leave it out of this step and cast to object-dtype after\n                #  the DatetimeIndex construction.\n                # Note we can pass copy=False because the .astype below\n                #  will always make a copy\n                result = DatetimeIndex(data, copy=False, name=name, **kwargs)\n                return result.astype(object)\n            else:\n                result = DatetimeIndex(\n                    data, copy=copy, name=name, dtype=dtype, **kwargs\n                )\n                return result\n\n        elif is_timedelta64_dtype(data) or is_timedelta64_dtype(dtype):\n            from pandas import TimedeltaIndex\n\n            if is_dtype_equal(_o_dtype, dtype):\n                # Note we can pass copy=False because the .astype below\n                #  will always make a copy\n                result = TimedeltaIndex(data, copy=False, name=name, **kwargs)\n                return result.astype(object)\n            else:\n                result = TimedeltaIndex(\n                    data, copy=copy, name=name, dtype=dtype, **kwargs\n                )\n                return result\n\n        elif is_period_dtype(data) and not is_object_dtype(dtype):\n            from pandas import PeriodIndex\n\n            result = PeriodIndex(data, copy=copy, name=name, **kwargs)\n            return result\n\n        # extension dtype\n        elif is_extension_array_dtype(data) or is_extension_array_dtype(dtype):\n            data = np.asarray(data)\n            if not (dtype is None or is_object_dtype(dtype)):\n                # coerce to the provided dtype\n                ea_cls = dtype.construct_array_type()\n                data = ea_cls._from_sequence(data, dtype=dtype, copy=False)\n\n            # coerce to the object dtype\n            data = data.astype(object)\n            return Index(data, dtype=object, copy=copy, name=name, **kwargs)\n\n        # index-like\n        elif isinstance(data, (np.ndarray, Index, ABCSeries)):\n            if dtype is not None:\n                # we need to avoid having numpy coerce\n                # things that look like ints/floats to ints unless\n                # they are actually ints, e.g. '0' and 0.0\n                # should not be coerced\n                # GH 11836\n                if is_integer_dtype(dtype):\n                    inferred = lib.infer_dtype(data, skipna=False)\n                    if inferred == \"integer\":\n                        data = maybe_cast_to_integer_array(data, dtype, copy=copy)\n                    elif inferred in [\"floating\", \"mixed-integer-float\"]:\n                        if isna(data).any():\n                            raise ValueError(\"cannot convert float NaN to integer\")\n\n                        if inferred == \"mixed-integer-float\":\n                            data = maybe_cast_to_integer_array(data, dtype)\n\n                        # If we are actually all equal to integers,\n                        # then coerce to integer.\n                        try:\n                            return cls._try_convert_to_int_index(\n                                data, copy, name, dtype\n                            )\n                        except ValueError:\n                            pass\n\n                        # Return an actual float index.\n                        from .numeric import Float64Index\n\n                        return Float64Index(data, copy=copy, dtype=dtype, name=name)\n\n                    elif inferred == \"string\":\n                        pass\n                    else:\n                        data = data.astype(dtype)\n                elif is_float_dtype(dtype):\n                    inferred = lib.infer_dtype(data, skipna=False)\n                    if inferred == \"string\":\n                        pass\n                    else:\n                        data = data.astype(dtype)\n                else:\n                    data = np.array(data, dtype=dtype, copy=copy)\n\n            # maybe coerce to a sub-class\n            from pandas.core.indexes.period import PeriodIndex, IncompatibleFrequency\n\n            if is_signed_integer_dtype(data.dtype):\n                from .numeric import Int64Index\n\n                return Int64Index(data, copy=copy, dtype=dtype, name=name)\n            elif is_unsigned_integer_dtype(data.dtype):\n                from .numeric import UInt64Index\n\n                return UInt64Index(data, copy=copy, dtype=dtype, name=name)\n            elif is_float_dtype(data.dtype):\n                from .numeric import Float64Index\n\n                return Float64Index(data, copy=copy, dtype=dtype, name=name)\n            elif issubclass(data.dtype.type, np.bool) or is_bool_dtype(data):\n                subarr = data.astype(\"object\")\n            else:\n                subarr = com.asarray_tuplesafe(data, dtype=object)\n\n            # asarray_tuplesafe does not always copy underlying data,\n            # so need to make sure that this happens\n            if copy:\n                subarr = subarr.copy()\n\n            if dtype is None:\n                inferred = lib.infer_dtype(subarr, skipna=False)\n                if inferred == \"integer\":\n                    try:\n                        return cls._try_convert_to_int_index(subarr, copy, name, dtype)\n                    except ValueError:\n                        pass\n\n                    return Index(subarr, copy=copy, dtype=object, name=name)\n                elif inferred in [\"floating\", \"mixed-integer-float\", \"integer-na\"]:\n                    # TODO: Returns IntegerArray for integer-na case in the future\n                    from .numeric import Float64Index\n\n                    return Float64Index(subarr, copy=copy, name=name)\n                elif inferred == \"interval\":\n                    from .interval import IntervalIndex\n\n                    try:\n                        return IntervalIndex(subarr, name=name, copy=copy)\n                    except ValueError:\n                        # GH27172: mixed closed Intervals --> object dtype\n                        pass\n                elif inferred == \"boolean\":\n                    # don't support boolean explicitly ATM\n                    pass\n                elif inferred != \"string\":\n                    if inferred.startswith(\"datetime\"):\n                        from pandas import DatetimeIndex\n\n                        try:\n                            return DatetimeIndex(subarr, copy=copy, name=name, **kwargs)\n                        except (ValueError, OutOfBoundsDatetime):\n                            # GH 27011\n                            # If we have mixed timezones, just send it\n                            # down the base constructor\n                            pass\n\n                    elif inferred.startswith(\"timedelta\"):\n                        from pandas import TimedeltaIndex\n\n                        return TimedeltaIndex(subarr, copy=copy, name=name, **kwargs)\n                    elif inferred == \"period\":\n                        try:\n                            return PeriodIndex(subarr, name=name, **kwargs)\n                        except IncompatibleFrequency:\n                            pass\n            return cls._simple_new(subarr, name)\n\n        elif hasattr(data, \"__array__\"):\n            return Index(np.asarray(data), dtype=dtype, copy=copy, name=name, **kwargs)\n        elif data is None or is_scalar(data):\n            cls._scalar_data_error(data)\n        else:\n            if tupleize_cols and is_list_like(data):\n                # GH21470: convert iterable to list before determining if empty\n                if is_iterator(data):\n                    data = list(data)\n\n                if data and all(isinstance(e, tuple) for e in data):\n                    # we must be all tuples, otherwise don't construct\n                    # 10697\n                    from .multi import MultiIndex\n\n                    return MultiIndex.from_tuples(\n                        data, names=name or kwargs.get(\"names\")\n                    )\n            # other iterable of some kind\n            subarr = com.asarray_tuplesafe(data, dtype=object)\n            return Index(subarr, dtype=dtype, copy=copy, name=name, **kwargs)",
        "begin_line": 256,
        "end_line": 500,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02564102564102564,
            "pseudo_dstar_susp": 0.023809523809523808,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.023809523809523808,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._simple_new#534",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._simple_new(cls, values, name=None, dtype=None, **kwargs)",
        "snippet": "    def _simple_new(cls, values, name=None, dtype=None, **kwargs):\n        \"\"\"\n        We require that we have a dtype compat for the values. If we are passed\n        a non-dtype compat, then coerce using the constructor.\n\n        Must be careful not to recurse.\n        \"\"\"\n        if isinstance(values, (ABCSeries, ABCIndexClass)):\n            # Index._data must always be an ndarray.\n            # This is no-copy for when _values is an ndarray,\n            # which should be always at this point.\n            values = np.asarray(values._values)\n\n        result = object.__new__(cls)\n        result._data = values\n        # _index_data is a (temporary?) fix to ensure that the direct data\n        # manipulation we do in `_libs/reduction.pyx` continues to work.\n        # We need access to the actual ndarray, since we're messing with\n        # data buffers and strides. We don't re-use `_ndarray_values`, since\n        # we actually set this value too.\n        result._index_data = values\n        result.name = name\n        for k, v in kwargs.items():\n            setattr(result, k, v)\n        return result._reset_identity()",
        "begin_line": 534,
        "end_line": 558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.009523809523809525,
            "pseudo_tarantula_susp": 0.0008481764206955047,
            "pseudo_op2_susp": 0.009523809523809525,
            "pseudo_barinel_susp": 0.0008481764206955047
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._get_attributes_dict#567",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._get_attributes_dict(self)",
        "snippet": "    def _get_attributes_dict(self):\n        \"\"\"\n        Return an attributes dict for my class.\n        \"\"\"\n        return {k: getattr(self, k, None) for k in self._attributes}",
        "begin_line": 567,
        "end_line": 571,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 1.0,
            "pseudo_dstar_susp": 1.0,
            "pseudo_tarantula_susp": 0.0008718395815170009,
            "pseudo_op2_susp": 1.0,
            "pseudo_barinel_susp": 0.0008718395815170009
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._shallow_copy#589",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._shallow_copy(self, values=None, **kwargs)",
        "snippet": "    def _shallow_copy(self, values=None, **kwargs):\n        if values is None:\n            values = self.values\n        attributes = self._get_attributes_dict()\n        attributes.update(kwargs)\n        if not len(values) and \"dtype\" not in kwargs:\n            attributes[\"dtype\"] = self.dtype\n\n        # _simple_new expects an the type of self._data\n        values = getattr(values, \"_values\", values)\n        if isinstance(values, ABCDatetimeArray):\n            # `self.values` returns `self` for tz-aware, so we need to unwrap\n            #  more specifically\n            values = values.asi8\n\n        return self._simple_new(values, **attributes)",
        "begin_line": 589,
        "end_line": 604,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.013513513513513514,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.0008718395815170009,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.0008718395815170009
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_#635",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_(self, other)",
        "snippet": "    def is_(self, other):\n        \"\"\"\n        More flexible, faster check like ``is`` but that works through views.\n\n        Note: this is *not* the same as ``Index.identical()``, which checks\n        that metadata is also the same.\n\n        Parameters\n        ----------\n        other : object\n            other object to compare against.\n\n        Returns\n        -------\n        True if both have same underlying data, False otherwise : bool\n        \"\"\"\n        # use something other than None to be clearer\n        return self._id is getattr(other, \"_id\", Ellipsis) and self._id is not None",
        "begin_line": 635,
        "end_line": 652,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._reset_identity#654",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._reset_identity(self)",
        "snippet": "    def _reset_identity(self):\n        \"\"\"\n        Initializes or resets ``_id`` attribute with new object.\n        \"\"\"\n        self._id = _Identity()\n        return self",
        "begin_line": 654,
        "end_line": 659,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.009523809523809525,
            "pseudo_tarantula_susp": 0.0008481764206955047,
            "pseudo_op2_susp": 0.009523809523809525,
            "pseudo_barinel_susp": 0.0008481764206955047
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._engine#665",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._engine(self)",
        "snippet": "    def _engine(self):\n        # property, for now, slow to look up\n\n        # to avoid a reference cycle, bind `_ndarray_values` to a local variable, so\n        # `self` is not passed into the lambda.\n        _ndarray_values = self._ndarray_values\n        return self._engine_type(lambda: _ndarray_values, len(self))",
        "begin_line": 665,
        "end_line": 671,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__len__#677",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__len__(self)",
        "snippet": "    def __len__(self):\n        \"\"\"\n        Return the length of the Index.\n        \"\"\"\n        return len(self._data)",
        "begin_line": 677,
        "end_line": 681,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.dtype#701",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.dtype(self)",
        "snippet": "    def dtype(self):\n        \"\"\"\n        Return the dtype object of the underlying data.\n        \"\"\"\n        return self._data.dtype",
        "begin_line": 701,
        "end_line": 705,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.view#737",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.view(self, cls=None)",
        "snippet": "    def view(self, cls=None):\n\n        # we need to see if we are subclassing an\n        # index type here\n        if cls is not None and not hasattr(cls, \"_typ\"):\n            result = self._data.view(cls)\n        else:\n            result = self._shallow_copy()\n        if isinstance(result, Index):\n            result._id = self._id\n        return result",
        "begin_line": 737,
        "end_line": 747,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.format#1044",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.format(self, name=False, formatter=None, **kwargs)",
        "snippet": "    def format(self, name=False, formatter=None, **kwargs):\n        \"\"\"\n        Render a string representation of the Index.\n        \"\"\"\n        header = []\n        if name:\n            header.append(\n                pprint_thing(self.name, escape_chars=(\"\\t\", \"\\r\", \"\\n\"))\n                if self.name is not None\n                else \"\"\n            )\n\n        if formatter is not None:\n            return header + list(self.map(formatter))\n\n        return self._format_with_header(header, **kwargs)",
        "begin_line": 1044,
        "end_line": 1059,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._format_with_header#1061",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._format_with_header(self, header, na_rep='NaN', **kwargs)",
        "snippet": "    def _format_with_header(self, header, na_rep=\"NaN\", **kwargs):\n        values = self.values\n\n        from pandas.io.formats.format import format_array\n\n        if is_categorical_dtype(values.dtype):\n            values = np.array(values)\n\n        elif is_object_dtype(values.dtype):\n            values = lib.maybe_convert_objects(values, safe=1)\n\n        if is_object_dtype(values.dtype):\n            result = [pprint_thing(x, escape_chars=(\"\\t\", \"\\r\", \"\\n\")) for x in values]\n\n            # could have nans\n            mask = isna(values)\n            if mask.any():\n                result = np.array(result)\n                result[mask] = na_rep\n                result = result.tolist()\n\n        else:\n            result = _trim_front(format_array(values, None, justify=\"left\"))\n        return header + result",
        "begin_line": 1061,
        "end_line": 1084,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._get_names#1306",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._get_names(self)",
        "snippet": "    def _get_names(self):\n        return FrozenList((self.name,))",
        "begin_line": 1306,
        "end_line": 1307,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._set_names#1309",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._set_names(self, values, level=None)",
        "snippet": "    def _set_names(self, values, level=None):\n        \"\"\"\n        Set new names on index. Each name has to be a hashable type.\n\n        Parameters\n        ----------\n        values : str or sequence\n            name(s) to set\n        level : int, level name, or sequence of int/level names (default None)\n            If the index is a MultiIndex (hierarchical), level(s) to set (None\n            for all levels).  Otherwise level must be None\n\n        Raises\n        ------\n        TypeError if each name is not hashable.\n        \"\"\"\n        if not is_list_like(values):\n            raise ValueError(\"Names must be a list-like\")\n        if len(values) != 1:\n            raise ValueError(\"Length of new names must be 1, got %d\" % len(values))\n\n        # GH 20527\n        # All items in 'name' need to be hashable:\n        for name in values:\n            if not is_hashable(name):\n                raise TypeError(\n                    \"{}.name must be a hashable type\".format(self.__class__.__name__)\n                )\n        self.name = values[0]",
        "begin_line": 1309,
        "end_line": 1337,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.set_names#1341",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.set_names(self, names, level=None, inplace=False)",
        "snippet": "    def set_names(self, names, level=None, inplace=False):\n        \"\"\"\n        Set Index or MultiIndex name.\n\n        Able to set new names partially and by level.\n\n        Parameters\n        ----------\n        names : label or list of label\n            Name(s) to set.\n        level : int, label or list of int or label, optional\n            If the index is a MultiIndex, level(s) to set (None for all\n            levels). Otherwise level must be None.\n        inplace : bool, default False\n            Modifies the object directly, instead of creating a new Index or\n            MultiIndex.\n\n        Returns\n        -------\n        Index\n            The same type as the caller or None if inplace is True.\n\n        See Also\n        --------\n        Index.rename : Able to set new names without level.\n\n        Examples\n        --------\n        >>> idx = pd.Index([1, 2, 3, 4])\n        >>> idx\n        Int64Index([1, 2, 3, 4], dtype='int64')\n        >>> idx.set_names('quarter')\n        Int64Index([1, 2, 3, 4], dtype='int64', name='quarter')\n\n        >>> idx = pd.MultiIndex.from_product([['python', 'cobra'],\n        ...                                   [2018, 2019]])\n        >>> idx\n        MultiIndex([('python', 2018),\n                    ('python', 2019),\n                    ( 'cobra', 2018),\n                    ( 'cobra', 2019)],\n                   )\n        >>> idx.set_names(['kind', 'year'], inplace=True)\n        >>> idx\n        MultiIndex([('python', 2018),\n                    ('python', 2019),\n                    ( 'cobra', 2018),\n                    ( 'cobra', 2019)],\n                   names=['kind', 'year'])\n        >>> idx.set_names('species', level=0)\n        MultiIndex([('python', 2018),\n                    ('python', 2019),\n                    ( 'cobra', 2018),\n                    ( 'cobra', 2019)],\n                   names=['species', 'year'])\n        \"\"\"\n\n        if level is not None and not isinstance(self, ABCMultiIndex):\n            raise ValueError(\"Level must be None for non-MultiIndex\")\n\n        if level is not None and not is_list_like(level) and is_list_like(names):\n            msg = \"Names must be a string when a single level is provided.\"\n            raise TypeError(msg)\n\n        if not is_list_like(names) and level is None and self.nlevels > 1:\n            raise TypeError(\"Must pass list-like as `names`.\")\n\n        if not is_list_like(names):\n            names = [names]\n        if level is not None and not is_list_like(level):\n            level = [level]\n\n        if inplace:\n            idx = self\n        else:\n            idx = self._shallow_copy()\n        idx._set_names(names, level=level)\n        if not inplace:\n            return idx",
        "begin_line": 1341,
        "end_line": 1419,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.rename#1421",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.rename(self, name, inplace=False)",
        "snippet": "    def rename(self, name, inplace=False):\n        \"\"\"\n        Alter Index or MultiIndex name.\n\n        Able to set new names without level. Defaults to returning new index.\n        Length of names must match number of levels in MultiIndex.\n\n        Parameters\n        ----------\n        name : label or list of labels\n            Name(s) to set.\n        inplace : boolean, default False\n            Modifies the object directly, instead of creating a new Index or\n            MultiIndex.\n\n        Returns\n        -------\n        Index\n            The same type as the caller or None if inplace is True.\n\n        See Also\n        --------\n        Index.set_names : Able to set new names partially and by level.\n\n        Examples\n        --------\n        >>> idx = pd.Index(['A', 'C', 'A', 'B'], name='score')\n        >>> idx.rename('grade')\n        Index(['A', 'C', 'A', 'B'], dtype='object', name='grade')\n\n        >>> idx = pd.MultiIndex.from_product([['python', 'cobra'],\n        ...                                   [2018, 2019]],\n        ...                                   names=['kind', 'year'])\n        >>> idx\n        MultiIndex([('python', 2018),\n                    ('python', 2019),\n                    ( 'cobra', 2018),\n                    ( 'cobra', 2019)],\n                   names=['kind', 'year'])\n        >>> idx.rename(['species', 'year'])\n        MultiIndex([('python', 2018),\n                    ('python', 2019),\n                    ( 'cobra', 2018),\n                    ( 'cobra', 2019)],\n                   names=['species', 'year'])\n        >>> idx.rename('species')\n        Traceback (most recent call last):\n        TypeError: Must pass list-like as `names`.\n        \"\"\"\n        return self.set_names([name], inplace=inplace)",
        "begin_line": 1421,
        "end_line": 1470,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.nlevels#1476",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.nlevels(self)",
        "snippet": "    def nlevels(self):\n        \"\"\"\n        Number of levels.\n        \"\"\"\n        return 1",
        "begin_line": 1476,
        "end_line": 1480,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.inferred_type#1829",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.inferred_type(self)",
        "snippet": "    def inferred_type(self):\n        \"\"\"\n        Return a string of the type inferred from the values.\n        \"\"\"\n        return lib.infer_dtype(self, skipna=False)",
        "begin_line": 1829,
        "end_line": 1833,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_all_dates#1836",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_all_dates(self)",
        "snippet": "    def is_all_dates(self):\n        return is_datetime_array(ensure_object(self.values))",
        "begin_line": 1836,
        "end_line": 1837,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._convert_slice_indexer#3107",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._convert_slice_indexer(self, key: slice, kind=None)",
        "snippet": "    def _convert_slice_indexer(self, key: slice, kind=None):\n        assert kind in [\"ix\", \"loc\", \"getitem\", \"iloc\", None]\n\n        # validate iloc\n        if kind == \"iloc\":\n            return slice(\n                self._validate_indexer(\"slice\", key.start, kind),\n                self._validate_indexer(\"slice\", key.stop, kind),\n                self._validate_indexer(\"slice\", key.step, kind),\n            )\n\n        # potentially cast the bounds to integers\n        start, stop, step = key.start, key.stop, key.step\n\n        # figure out if this is a positional indexer\n        def is_int(v):\n            return v is None or is_integer(v)\n\n        is_null_slicer = start is None and stop is None\n        is_index_slice = is_int(start) and is_int(stop)\n        is_positional = is_index_slice and not self.is_integer()\n\n        if kind == \"getitem\":\n            \"\"\"\n            called from the getitem slicers, validate that we are in fact\n            integers\n            \"\"\"\n            if self.is_integer() or is_index_slice:\n                return slice(\n                    self._validate_indexer(\"slice\", key.start, kind),\n                    self._validate_indexer(\"slice\", key.stop, kind),\n                    self._validate_indexer(\"slice\", key.step, kind),\n                )\n\n        # convert the slice to an indexer here\n\n        # if we are mixed and have integers\n        try:\n            if is_positional and self.is_mixed():\n                # Validate start & stop\n                if start is not None:\n                    self.get_loc(start)\n                if stop is not None:\n                    self.get_loc(stop)\n                is_positional = False\n        except KeyError:\n            if self.inferred_type in [\"mixed-integer-float\", \"integer-na\"]:\n                raise\n\n        if is_null_slicer:\n            indexer = key\n        elif is_positional:\n            indexer = key\n        else:\n            try:\n                indexer = self.slice_indexer(start, stop, step, kind=kind)\n            except Exception:\n                if is_index_slice:\n                    if self.is_integer():\n                        raise\n                    else:\n                        indexer = key\n                else:\n                    raise\n\n        return indexer",
        "begin_line": 3107,
        "end_line": 3172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.values#3846",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.values(self)",
        "snippet": "    def values(self):\n        \"\"\"\n        Return an array representing the data in the Index.\n\n        .. warning::\n\n           We recommend using :attr:`Index.array` or\n           :meth:`Index.to_numpy`, depending on whether you need\n           a reference to the underlying data or a NumPy array.\n\n        Returns\n        -------\n        array: numpy.ndarray or ExtensionArray\n\n        See Also\n        --------\n        Index.array : Reference to the underlying data.\n        Index.to_numpy : A NumPy array representing the underlying data.\n        \"\"\"\n        return self._data.view(np.ndarray)",
        "begin_line": 3846,
        "end_line": 3865,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._values#3868",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._values(self)",
        "snippet": "    def _values(self) -> Union[ExtensionArray, ABCIndexClass, np.ndarray]:\n        # TODO(EA): remove index types as they become extension arrays\n        \"\"\"\n        The best array representation.\n\n        This is an ndarray, ExtensionArray, or Index subclass. This differs\n        from ``_ndarray_values``, which always returns an ndarray.\n\n        Both ``_values`` and ``_ndarray_values`` are consistent between\n        ``Series`` and ``Index``.\n\n        It may differ from the public '.values' method.\n\n        index             | values          | _values       | _ndarray_values |\n        ----------------- | --------------- | ------------- | --------------- |\n        Index             | ndarray         | ndarray       | ndarray         |\n        CategoricalIndex  | Categorical     | Categorical   | ndarray[int]    |\n        DatetimeIndex     | ndarray[M8ns]   | ndarray[M8ns] | ndarray[M8ns]   |\n        DatetimeIndex[tz] | ndarray[M8ns]   | DTI[tz]       | ndarray[M8ns]   |\n        PeriodIndex       | ndarray[object] | PeriodArray   | ndarray[int]    |\n        IntervalIndex     | IntervalArray   | IntervalArray | ndarray[object] |\n\n        See Also\n        --------\n        values\n        _ndarray_values\n        \"\"\"\n        return self._data",
        "begin_line": 3868,
        "end_line": 3895,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._try_convert_to_int_index#4003",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._try_convert_to_int_index(cls, data, copy, name, dtype)",
        "snippet": "    def _try_convert_to_int_index(cls, data, copy, name, dtype):\n        \"\"\"\n        Attempt to convert an array of data into an integer index.\n\n        Parameters\n        ----------\n        data : The data to convert.\n        copy : Whether to copy the data or not.\n        name : The name of the index returned.\n\n        Returns\n        -------\n        int_index : data converted to either an Int64Index or a\n                    UInt64Index\n\n        Raises\n        ------\n        ValueError if the conversion was not successful.\n        \"\"\"\n\n        from .numeric import Int64Index, UInt64Index\n\n        if not is_unsigned_integer_dtype(dtype):\n            # skip int64 conversion attempt if uint-like dtype is passed, as\n            # this could return Int64Index when UInt64Index is what's desired\n            try:\n                res = data.astype(\"i8\", copy=False)\n                if (res == data).all():\n                    return Int64Index(res, copy=copy, name=name)\n            except (OverflowError, TypeError, ValueError):\n                pass\n\n        # Conversion to int64 failed (possibly due to overflow) or was skipped,\n        # so let's try now with uint64.\n        try:\n            res = data.astype(\"u8\", copy=False)\n            if (res == data).all():\n                return UInt64Index(res, copy=copy, name=name)\n        except (OverflowError, TypeError, ValueError):\n            pass\n\n        raise ValueError",
        "begin_line": 4003,
        "end_line": 4044,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._coerce_to_ndarray#4061",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._coerce_to_ndarray(cls, data)",
        "snippet": "    def _coerce_to_ndarray(cls, data):\n        \"\"\"\n        Coerces data to ndarray.\n\n        Converts other iterables to list first and then to array.\n        Does not touch ndarrays.\n\n        Raises\n        ------\n        TypeError\n            When the data passed in is a scalar.\n        \"\"\"\n\n        if not isinstance(data, (np.ndarray, Index)):\n            if data is None or is_scalar(data):\n                cls._scalar_data_error(data)\n\n            # other iterable of some kind\n            if not isinstance(data, (ABCSeries, list, tuple)):\n                data = list(data)\n            data = np.asarray(data)\n        return data",
        "begin_line": 4061,
        "end_line": 4082,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__contains__#4171",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__contains__(self, key)",
        "snippet": "    def __contains__(self, key):\n        hash(key)\n        try:\n            return key in self._engine\n        except (OverflowError, TypeError, ValueError):\n            return False",
        "begin_line": 4171,
        "end_line": 4176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__getitem__#4204",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        \"\"\"\n        Override numpy.ndarray's __getitem__ method to work as desired.\n\n        This function adds lists and Series as valid boolean indexers\n        (ndarrays only supports ndarray with dtype=bool).\n\n        If resulting ndim != 1, plain ndarray is returned instead of\n        corresponding `Index` subclass.\n\n        \"\"\"\n        # There's no custom logic to be implemented in __getslice__, so it's\n        # not overloaded intentionally.\n        getitem = self._data.__getitem__\n        promote = self._shallow_copy\n\n        if is_scalar(key):\n            key = com.cast_scalar_indexer(key)\n            return getitem(key)\n\n        if isinstance(key, slice):\n            # This case is separated from the conditional above to avoid\n            # pessimization of basic indexing.\n            return promote(getitem(key))\n\n        if com.is_bool_indexer(key):\n            key = np.asarray(key, dtype=bool)\n\n        key = com.values_from_object(key)\n        result = getitem(key)\n        if not is_scalar(result):\n            return promote(result)\n        else:\n            return result",
        "begin_line": 4204,
        "end_line": 4237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.append#4252",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.append(self, other)",
        "snippet": "    def append(self, other):\n        \"\"\"\n        Append a collection of Index options together.\n\n        Parameters\n        ----------\n        other : Index or list/tuple of indices\n\n        Returns\n        -------\n        appended : Index\n        \"\"\"\n\n        to_concat = [self]\n\n        if isinstance(other, (list, tuple)):\n            to_concat = to_concat + list(other)\n        else:\n            to_concat.append(other)\n\n        for obj in to_concat:\n            if not isinstance(obj, Index):\n                raise TypeError(\"all inputs must be Index\")\n\n        names = {obj.name for obj in to_concat}\n        name = None if len(names) > 1 else self.name\n\n        return self._concat(to_concat, name)",
        "begin_line": 4252,
        "end_line": 4279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._concat#4281",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._concat(self, to_concat, name)",
        "snippet": "    def _concat(self, to_concat, name):\n\n        typs = _concat.get_dtype_kinds(to_concat)\n\n        if len(typs) == 1:\n            return self._concat_same_dtype(to_concat, name=name)\n        return Index._concat_same_dtype(self, to_concat, name=name)",
        "begin_line": 4281,
        "end_line": 4287,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.equals#4330",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.equals(self, other)",
        "snippet": "    def equals(self, other):\n        \"\"\"\n        Determine if two Index objects contain the same elements.\n\n        Returns\n        -------\n        bool\n            True if \"other\" is an Index and it has the same elements as calling\n            index; False otherwise.\n        \"\"\"\n        if self.is_(other):\n            return True\n\n        if not isinstance(other, Index):\n            return False\n\n        if is_object_dtype(self) and not is_object_dtype(other):\n            # if other is not object, use other's logic for coercion\n            return other.equals(self)\n\n        try:\n            return array_equivalent(\n                com.values_from_object(self), com.values_from_object(other)\n            )\n        except Exception:\n            return False",
        "begin_line": 4330,
        "end_line": 4355,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._validate_indexer#5005",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._validate_indexer(self, form, key, kind)",
        "snippet": "    def _validate_indexer(self, form, key, kind):\n        \"\"\"\n        If we are positional indexer, validate that we have appropriate\n        typed bounds must be an integer.\n        \"\"\"\n        assert kind in [\"ix\", \"loc\", \"getitem\", \"iloc\"]\n\n        if key is None:\n            pass\n        elif is_integer(key):\n            pass\n        elif kind in [\"iloc\", \"getitem\"]:\n            self._invalid_indexer(form, key)\n        return key",
        "begin_line": 5005,
        "end_line": 5018,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexes.base.ensure_index#5562",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base.ensure_index(index_like, copy=False)",
        "snippet": "def ensure_index(index_like, copy=False):\n    \"\"\"\n    Ensure that we have an index from some index-like object.\n\n    Parameters\n    ----------\n    index : sequence\n        An Index or other sequence\n    copy : bool\n\n    Returns\n    -------\n    index : Index or MultiIndex\n\n    Examples\n    --------\n    >>> ensure_index(['a', 'b'])\n    Index(['a', 'b'], dtype='object')\n\n    >>> ensure_index([('a', 'a'),  ('b', 'c')])\n    Index([('a', 'a'), ('b', 'c')], dtype='object')\n\n    >>> ensure_index([['a', 'a'], ['b', 'c']])\n    MultiIndex([('a', 'b'),\n                ('a', 'c')],\n               dtype='object')\n               )\n\n    See Also\n    --------\n    ensure_index_from_sequences\n    \"\"\"\n    if isinstance(index_like, Index):\n        if copy:\n            index_like = index_like.copy()\n        return index_like\n    if hasattr(index_like, \"name\"):\n        return Index(index_like, name=index_like.name, copy=copy)\n\n    if is_iterator(index_like):\n        index_like = list(index_like)\n\n    # must check for exactly list here because of strict type\n    # check in clean_index_list\n    if isinstance(index_like, list):\n        if type(index_like) != list:\n            index_like = list(index_like)\n\n        converted, all_arrays = lib.clean_index_list(index_like)\n\n        if len(converted) > 0 and all_arrays:\n            from .multi import MultiIndex\n\n            return MultiIndex.from_arrays(converted)\n        else:\n            index_like = converted\n    else:\n        # clean_index_list does the equivalent of copying\n        # so only need to do this if not list instance\n        if copy:\n            from copy import copy\n\n            index_like = copy(index_like)\n\n    return Index(index_like)",
        "begin_line": 5562,
        "end_line": 5626,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexes.base._trim_front#5641",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base._trim_front(strings)",
        "snippet": "def _trim_front(strings):\n    \"\"\"\n    Trims zeros and decimal points.\n    \"\"\"\n    trimmed = strings\n    while len(strings) > 0 and all(x[0] == \" \" for x in trimmed):\n        trimmed = [x[1:] for x in trimmed]\n    return trimmed",
        "begin_line": 5641,
        "end_line": 5648,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.058823529411764705,
            "pseudo_dstar_susp": 0.05,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.05,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.dtypes.concat.get_dtype_kinds#31",
        "src_path": "pandas/core/dtypes/concat.py",
        "class_name": "pandas.core.dtypes.concat",
        "signature": "pandas.core.dtypes.concat.get_dtype_kinds(l)",
        "snippet": "def get_dtype_kinds(l):\n    \"\"\"\n    Parameters\n    ----------\n    l : list of arrays\n\n    Returns\n    -------\n    a set of kinds that exist in this list of arrays\n    \"\"\"\n\n    typs = set()\n    for arr in l:\n\n        dtype = arr.dtype\n        if is_categorical_dtype(dtype):\n            typ = \"category\"\n        elif is_sparse(arr):\n            typ = \"sparse\"\n        elif isinstance(arr, ABCRangeIndex):\n            typ = \"range\"\n        elif is_datetime64tz_dtype(arr):\n            # if to_concat contains different tz,\n            # the result must be object dtype\n            typ = str(arr.dtype)\n        elif is_datetime64_dtype(dtype):\n            typ = \"datetime\"\n        elif is_timedelta64_dtype(dtype):\n            typ = \"timedelta\"\n        elif is_object_dtype(dtype):\n            typ = \"object\"\n        elif is_bool_dtype(dtype):\n            typ = \"bool\"\n        elif is_extension_array_dtype(dtype):\n            typ = str(arr.dtype)\n        else:\n            typ = dtype.kind\n        typs.add(typ)\n    return typs",
        "begin_line": 31,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.dtypes.generic.create_pandas_abc_type#6",
        "src_path": "pandas/core/dtypes/generic.py",
        "class_name": "pandas.core.dtypes.generic",
        "signature": "pandas.core.dtypes.generic.create_pandas_abc_type(name, attr, comp)",
        "snippet": "def create_pandas_abc_type(name, attr, comp):\n    @classmethod\n    def _check(cls, inst):\n        return getattr(inst, attr, \"_typ\") in comp\n\n    dct = dict(__instancecheck__=_check, __subclasscheck__=_check)\n    meta = type(\"ABCBase\", (type,), dct)\n    return meta(name, tuple(), dct)",
        "begin_line": 6,
        "end_line": 13,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.dtypes.generic._check#8",
        "src_path": "pandas/core/dtypes/generic.py",
        "class_name": "pandas.core.dtypes.generic",
        "signature": "pandas.core.dtypes.generic._check(cls, inst)",
        "snippet": "    def _check(cls, inst):\n        return getattr(inst, attr, \"_typ\") in comp",
        "begin_line": 8,
        "end_line": 9,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._get_loc#160",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._get_loc(self, key: int, axis: int)",
        "snippet": "    def _get_loc(self, key: int, axis: int):\n        return self.obj._ixs(key, axis=axis)",
        "begin_line": 160,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._slice#163",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._slice(self, obj, axis: int, kind=None)",
        "snippet": "    def _slice(self, obj, axis: int, kind=None):\n        return self.obj._slice(obj, axis=axis, kind=kind)",
        "begin_line": 163,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._has_valid_tuple#227",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._has_valid_tuple(self, key: Tuple)",
        "snippet": "    def _has_valid_tuple(self, key: Tuple):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.ndim:\n                raise IndexingError(\"Too many indexers\")\n            try:\n                self._validate_key(k, i)\n            except ValueError:\n                raise ValueError(\n                    \"Location based indexing can only have \"\n                    \"[{types}] types\".format(types=self._valid_types)\n                )",
        "begin_line": 227,
        "end_line": 238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._is_nested_tuple_indexer#240",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._is_nested_tuple_indexer(self, tup: Tuple)",
        "snippet": "    def _is_nested_tuple_indexer(self, tup: Tuple):\n        if any(isinstance(ax, MultiIndex) for ax in self.obj.axes):\n            return any(is_nested_tuple(tup, ax) for ax in self.obj.axes)\n        return False",
        "begin_line": 240,
        "end_line": 243,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._convert_slice_indexer#268",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._convert_slice_indexer(self, key: slice, axis: int)",
        "snippet": "    def _convert_slice_indexer(self, key: slice, axis: int):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, kind=self.name)",
        "begin_line": 268,
        "end_line": 271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._getitem_lowerdim#889",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._getitem_lowerdim(self, tup: Tuple)",
        "snippet": "    def _getitem_lowerdim(self, tup: Tuple):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        # ...but iloc should handle the tuple as simple integer-location\n        # instead of checking it as multiindex representation (GH 13797)\n        if isinstance(ax0, MultiIndex) and self.name != \"iloc\":\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not is_list_like_indexer(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1 :]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1 :]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (\n                        isinstance(section, ABCDataFrame)\n                        and i > 0\n                        and len(new_key) == 2\n                    ):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key = new_key[0]\n\n                # Slices should return views, but calling iloc/loc with a null\n                # slice returns a new object.\n                if com.is_null_slice(new_key):\n                    return section\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError(\"not applicable\")",
        "begin_line": 889,
        "end_line": 951,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._get_slice_axis#1275",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._get_slice_axis(self, slice_obj: slice, axis: int)",
        "snippet": "    def _get_slice_axis(self, slice_obj: slice, axis: int):\n        # caller is responsible for ensuring non-None axis\n        obj = self.obj\n\n        if not need_slice(slice_obj):\n            return obj.copy(deep=False)\n\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n        return self._slice(indexer, axis=axis, kind=\"iloc\")",
        "begin_line": 1275,
        "end_line": 1283,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexing._LocationIndexer.__getitem__#1385",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._LocationIndexer",
        "signature": "pandas.core.indexing._LocationIndexer.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        if type(key) is tuple:\n            key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n            if self._is_scalar_access(key):\n                try:\n                    return self._getitem_scalar(key)\n                except (KeyError, IndexError, AttributeError):\n                    pass\n            return self._getitem_tuple(key)\n        else:\n            # we by definition only have the 0th axis\n            axis = self.axis or 0\n\n            maybe_callable = com.apply_if_callable(key, self.obj)\n            return self._getitem_axis(maybe_callable, axis=axis)",
        "begin_line": 1385,
        "end_line": 1399,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexing._iLocIndexer._validate_key#1971",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._iLocIndexer",
        "signature": "pandas.core.indexing._iLocIndexer._validate_key(self, key, axis: int)",
        "snippet": "    def _validate_key(self, key, axis: int):\n        if com.is_bool_indexer(key):\n            if hasattr(key, \"index\") and isinstance(key.index, Index):\n                if key.index.inferred_type == \"integer\":\n                    raise NotImplementedError(\n                        \"iLocation based boolean \"\n                        \"indexing on an integer type \"\n                        \"is not available\"\n                    )\n                raise ValueError(\n                    \"iLocation based boolean indexing cannot use \"\n                    \"an indexable as a mask\"\n                )\n            return\n\n        if isinstance(key, slice):\n            return\n        elif is_integer(key):\n            self._validate_integer(key, axis)\n        elif isinstance(key, tuple):\n            # a tuple should already have been caught by this point\n            # so don't treat a tuple as a valid indexer\n            raise IndexingError(\"Too many indexers\")\n        elif is_list_like_indexer(key):\n            arr = np.array(key)\n            len_axis = len(self.obj._get_axis(axis))\n\n            # check that the key has a numeric dtype\n            if not is_numeric_dtype(arr.dtype):\n                raise IndexError(\n                    \".iloc requires numeric indexers, got {arr}\".format(arr=arr)\n                )\n\n            # check that the key does not exceed the maximum size of the index\n            if len(arr) and (arr.max() >= len_axis or arr.min() < -len_axis):\n                raise IndexError(\"positional indexers are out-of-bounds\")\n        else:\n            raise ValueError(\n                \"Can only index by location with \"\n                \"a [{types}]\".format(types=self._valid_types)\n            )",
        "begin_line": 1971,
        "end_line": 2011,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexing._iLocIndexer._is_scalar_access#2016",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._iLocIndexer",
        "signature": "pandas.core.indexing._iLocIndexer._is_scalar_access(self, key: Tuple)",
        "snippet": "    def _is_scalar_access(self, key: Tuple):\n        # this is a shortcut accessor to both .loc and .iloc\n        # that provide the equivalent access of .at and .iat\n        # a) avoid getting things via sections and (to minimize dtype changes)\n        # b) provide a performant path\n        if len(key) != self.ndim:\n            return False\n\n        for i, k in enumerate(key):\n            if not is_integer(k):\n                return False\n\n            ax = self.obj.axes[i]\n            if not ax.is_unique:\n                return False\n\n        return True",
        "begin_line": 2016,
        "end_line": 2032,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.indexing._iLocIndexer._validate_integer#2040",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._iLocIndexer",
        "signature": "pandas.core.indexing._iLocIndexer._validate_integer(self, key: int, axis: int)",
        "snippet": "    def _validate_integer(self, key: int, axis: int):\n        \"\"\"\n        Check that 'key' is a valid position in the desired axis.\n\n        Parameters\n        ----------\n        key : int\n            Requested position\n        axis : int\n            Desired axis\n\n        Returns\n        -------\n        None\n\n        Raises\n        ------\n        IndexError\n            If 'key' is not a valid position in axis 'axis'\n        \"\"\"\n\n        len_axis = len(self.obj._get_axis(axis))\n        if key >= len_axis or key < -len_axis:\n            raise IndexError(\"single positional indexer is out-of-bounds\")",
        "begin_line": 2040,
        "end_line": 2063,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexing._iLocIndexer._getitem_tuple#2065",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._iLocIndexer",
        "signature": "pandas.core.indexing._iLocIndexer._getitem_tuple(self, tup: Tuple)",
        "snippet": "    def _getitem_tuple(self, tup: Tuple):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        retval = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n            if com.is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim < self.ndim:\n                # TODO: this is never reached in tests; can we confirm that\n                #  it is impossible?\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval",
        "begin_line": 2065,
        "end_line": 2091,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexing._iLocIndexer._getitem_axis#2112",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._iLocIndexer",
        "signature": "pandas.core.indexing._iLocIndexer._getitem_axis(self, key, axis: int)",
        "snippet": "    def _getitem_axis(self, key, axis: int):\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n\n        if isinstance(key, list):\n            key = np.asarray(key)\n\n        if com.is_bool_indexer(key):\n            self._validate_key(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a list of integers\n        elif is_list_like_indexer(key):\n            return self._get_list_axis(key, axis=axis)\n\n        # a single integer\n        else:\n            key = item_from_zerodim(key)\n            if not is_integer(key):\n                raise TypeError(\"Cannot index by location index with a non-integer key\")\n\n            # validate the location\n            self._validate_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)",
        "begin_line": 2112,
        "end_line": 2136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.indexing.is_label_like#2479",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing",
        "signature": "pandas.core.indexing.is_label_like(key)",
        "snippet": "def is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not is_list_like_indexer(key)",
        "begin_line": 2479,
        "end_line": 2481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.indexing.need_slice#2484",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing",
        "signature": "pandas.core.indexing.need_slice(obj)",
        "snippet": "def need_slice(obj):\n    return (\n        obj.start is not None\n        or obj.stop is not None\n        or (obj.step is not None and obj.step != 1)\n    )",
        "begin_line": 2484,
        "end_line": 2489,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.missing.clean_fill_method#75",
        "src_path": "pandas/core/missing.py",
        "class_name": "pandas.core.missing",
        "signature": "pandas.core.missing.clean_fill_method(method, allow_nearest=False)",
        "snippet": "def clean_fill_method(method, allow_nearest=False):\n    # asfreq is compat for resampling\n    if method in [None, \"asfreq\"]:\n        return None\n\n    if isinstance(method, str):\n        method = method.lower()\n        if method == \"ffill\":\n            method = \"pad\"\n        elif method == \"bfill\":\n            method = \"backfill\"\n\n    valid_methods = [\"pad\", \"backfill\"]\n    expecting = \"pad (ffill) or backfill (bfill)\"\n    if allow_nearest:\n        valid_methods.append(\"nearest\")\n        expecting = \"pad (ffill), backfill (bfill) or nearest\"\n    if method not in valid_methods:\n        msg = \"Invalid fill method. Expecting {expecting}. Got {method}\".format(\n            expecting=expecting, method=method\n        )\n        raise ValueError(msg)\n    return method",
        "begin_line": 75,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.util.testing._check_isinstance#369",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing._check_isinstance(left, right, cls)",
        "snippet": "def _check_isinstance(left, right, cls):\n    \"\"\"\n    Helper method for our assert_* methods that ensures that\n    the two objects being compared have the right type before\n    proceeding with the comparison.\n\n    Parameters\n    ----------\n    left : The first object being compared.\n    right : The second object being compared.\n    cls : The class type to check against.\n\n    Raises\n    ------\n    AssertionError : Either `left` or `right` is not an instance of `cls`.\n    \"\"\"\n\n    err_msg = \"{name} Expected type {exp_type}, found {act_type} instead\"\n    cls_name = cls.__name__\n\n    if not isinstance(left, cls):\n        raise AssertionError(\n            err_msg.format(name=cls_name, exp_type=cls, act_type=type(left))\n        )\n    if not isinstance(right, cls):\n        raise AssertionError(\n            err_msg.format(name=cls_name, exp_type=cls, act_type=type(right))\n        )",
        "begin_line": 369,
        "end_line": 396,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.util.testing.assert_index_equal#573",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.assert_index_equal(left: Index, right: Index, exact: Union[bool, str]='equiv', check_names: bool=True, check_less_precise: Union[bool, int]=False, check_exact: bool=True, check_categorical: bool=True, obj: str='Index')",
        "snippet": "def assert_index_equal(\n    left: Index,\n    right: Index,\n    exact: Union[bool, str] = \"equiv\",\n    check_names: bool = True,\n    check_less_precise: Union[bool, int] = False,\n    check_exact: bool = True,\n    check_categorical: bool = True,\n    obj: str = \"Index\",\n) -> None:\n    \"\"\"Check that left and right Index are equal.\n\n    Parameters\n    ----------\n    left : Index\n    right : Index\n    exact : bool / string {'equiv'}, default 'equiv'\n        Whether to check the Index class, dtype and inferred_type\n        are identical. If 'equiv', then RangeIndex can be substituted for\n        Int64Index as well.\n    check_names : bool, default True\n        Whether to check the names attribute.\n    check_less_precise : bool or int, default False\n        Specify comparison precision. Only used when check_exact is False.\n        5 digits (False) or 3 digits (True) after decimal points are compared.\n        If int, then specify the digits to compare\n    check_exact : bool, default True\n        Whether to compare number exactly.\n    check_categorical : bool, default True\n        Whether to compare internal Categorical exactly.\n    obj : str, default 'Index'\n        Specify object name being compared, internally used to show appropriate\n        assertion message\n    \"\"\"\n    __tracebackhide__ = True\n\n    def _check_types(l, r, obj=\"Index\"):\n        if exact:\n            assert_class_equal(l, r, exact=exact, obj=obj)\n\n            # Skip exact dtype checking when `check_categorical` is False\n            if check_categorical:\n                assert_attr_equal(\"dtype\", l, r, obj=obj)\n\n            # allow string-like to have different inferred_types\n            if l.inferred_type in (\"string\", \"unicode\"):\n                assert r.inferred_type in (\"string\", \"unicode\")\n            else:\n                assert_attr_equal(\"inferred_type\", l, r, obj=obj)\n\n    def _get_ilevel_values(index, level):\n        # accept level number only\n        unique = index.levels[level]\n        labels = index.codes[level]\n        filled = take_1d(unique.values, labels, fill_value=unique._na_value)\n        values = unique._shallow_copy(filled, name=index.names[level])\n        return values\n\n    # instance validation\n    _check_isinstance(left, right, Index)\n\n    # class / dtype comparison\n    _check_types(left, right, obj=obj)\n\n    # level comparison\n    if left.nlevels != right.nlevels:\n        msg1 = \"{obj} levels are different\".format(obj=obj)\n        msg2 = \"{nlevels}, {left}\".format(nlevels=left.nlevels, left=left)\n        msg3 = \"{nlevels}, {right}\".format(nlevels=right.nlevels, right=right)\n        raise_assert_detail(obj, msg1, msg2, msg3)\n\n    # length comparison\n    if len(left) != len(right):\n        msg1 = \"{obj} length are different\".format(obj=obj)\n        msg2 = \"{length}, {left}\".format(length=len(left), left=left)\n        msg3 = \"{length}, {right}\".format(length=len(right), right=right)\n        raise_assert_detail(obj, msg1, msg2, msg3)\n\n    # MultiIndex special comparison for little-friendly error messages\n    if left.nlevels > 1:\n        left = cast(MultiIndex, left)\n        right = cast(MultiIndex, right)\n\n        for level in range(left.nlevels):\n            # cannot use get_level_values here because it can change dtype\n            llevel = _get_ilevel_values(left, level)\n            rlevel = _get_ilevel_values(right, level)\n\n            lobj = \"MultiIndex level [{level}]\".format(level=level)\n            assert_index_equal(\n                llevel,\n                rlevel,\n                exact=exact,\n                check_names=check_names,\n                check_less_precise=check_less_precise,\n                check_exact=check_exact,\n                obj=lobj,\n            )\n            # get_level_values may change dtype\n            _check_types(left.levels[level], right.levels[level], obj=obj)\n\n    # skip exact index checking when `check_categorical` is False\n    if check_exact and check_categorical:\n        if not left.equals(right):\n            diff = np.sum((left.values != right.values).astype(int)) * 100.0 / len(left)\n            msg = \"{obj} values are different ({pct} %)\".format(\n                obj=obj, pct=np.round(diff, 5)\n            )\n            raise_assert_detail(obj, msg, left, right)\n    else:\n        _testing.assert_almost_equal(\n            left.values,\n            right.values,\n            check_less_precise=check_less_precise,\n            check_dtype=exact,\n            obj=obj,\n            lobj=left,\n            robj=right,\n        )\n\n    # metadata comparison\n    if check_names:\n        assert_attr_equal(\"names\", left, right, obj=obj)\n    if isinstance(left, pd.PeriodIndex) or isinstance(right, pd.PeriodIndex):\n        assert_attr_equal(\"freq\", left, right, obj=obj)\n    if isinstance(left, pd.IntervalIndex) or isinstance(right, pd.IntervalIndex):\n        assert_interval_array_equal(left.values, right.values)\n\n    if check_categorical:\n        if is_categorical_dtype(left) or is_categorical_dtype(right):\n            assert_categorical_equal(\n                left.values, right.values, obj=\"{obj} category\".format(obj=obj)\n            )",
        "begin_line": 573,
        "end_line": 705,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.util.testing._check_types#609",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing._check_types(l, r, obj='Index')",
        "snippet": "    def _check_types(l, r, obj=\"Index\"):\n        if exact:\n            assert_class_equal(l, r, exact=exact, obj=obj)\n\n            # Skip exact dtype checking when `check_categorical` is False\n            if check_categorical:\n                assert_attr_equal(\"dtype\", l, r, obj=obj)\n\n            # allow string-like to have different inferred_types\n            if l.inferred_type in (\"string\", \"unicode\"):\n                assert r.inferred_type in (\"string\", \"unicode\")\n            else:\n                assert_attr_equal(\"inferred_type\", l, r, obj=obj)",
        "begin_line": 609,
        "end_line": 621,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.util.testing._get_ilevel_values#623",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing._get_ilevel_values(index, level)",
        "snippet": "    def _get_ilevel_values(index, level):\n        # accept level number only\n        unique = index.levels[level]\n        labels = index.codes[level]\n        filled = take_1d(unique.values, labels, fill_value=unique._na_value)\n        values = unique._shallow_copy(filled, name=index.names[level])\n        return values",
        "begin_line": 623,
        "end_line": 629,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.util.testing.assert_class_equal#708",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.assert_class_equal(left, right, exact=True, obj='Input')",
        "snippet": "def assert_class_equal(left, right, exact=True, obj=\"Input\"):\n    \"\"\"checks classes are equal.\"\"\"\n    __tracebackhide__ = True\n\n    def repr_class(x):\n        if isinstance(x, Index):\n            # return Index as it is to include values in the error message\n            return x\n\n        try:\n            return x.__class__.__name__\n        except AttributeError:\n            return repr(type(x))\n\n    if exact == \"equiv\":\n        if type(left) != type(right):\n            # allow equivalence of Int64Index/RangeIndex\n            types = {type(left).__name__, type(right).__name__}\n            if len(types - {\"Int64Index\", \"RangeIndex\"}):\n                msg = \"{obj} classes are not equivalent\".format(obj=obj)\n                raise_assert_detail(obj, msg, repr_class(left), repr_class(right))\n    elif exact:\n        if type(left) != type(right):\n            msg = \"{obj} classes are different\".format(obj=obj)\n            raise_assert_detail(obj, msg, repr_class(left), repr_class(right))",
        "begin_line": 708,
        "end_line": 732,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.util.testing.repr_class#712",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.repr_class(x)",
        "snippet": "    def repr_class(x):\n        if isinstance(x, Index):\n            # return Index as it is to include values in the error message\n            return x\n\n        try:\n            return x.__class__.__name__\n        except AttributeError:\n            return repr(type(x))",
        "begin_line": 712,
        "end_line": 720,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.util.testing.assert_attr_equal#735",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.assert_attr_equal(attr, left, right, obj='Attributes')",
        "snippet": "def assert_attr_equal(attr, left, right, obj=\"Attributes\"):\n    \"\"\"checks attributes are equal. Both objects must have attribute.\n\n    Parameters\n    ----------\n    attr : str\n        Attribute name being compared.\n    left : object\n    right : object\n    obj : str, default 'Attributes'\n        Specify object name being compared, internally used to show appropriate\n        assertion message\n    \"\"\"\n    __tracebackhide__ = True\n\n    left_attr = getattr(left, attr)\n    right_attr = getattr(right, attr)\n\n    if left_attr is right_attr:\n        return True\n    elif (\n        is_number(left_attr)\n        and np.isnan(left_attr)\n        and is_number(right_attr)\n        and np.isnan(right_attr)\n    ):\n        # np.nan\n        return True\n\n    try:\n        result = left_attr == right_attr\n    except TypeError:\n        # datetimetz on rhs may raise TypeError\n        result = False\n    if not isinstance(result, bool):\n        result = result.all()\n\n    if result:\n        return True\n    else:\n        msg = 'Attribute \"{attr}\" are different'.format(attr=attr)\n        raise_assert_detail(obj, msg, left_attr, right_attr)",
        "begin_line": 735,
        "end_line": 776,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.util.testing.assert_series_equal#1071",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.assert_series_equal(left, right, check_dtype=True, check_index_type='equiv', check_series_type=True, check_less_precise=False, check_names=True, check_exact=False, check_datetimelike_compat=False, check_categorical=True, obj='Series')",
        "snippet": "def assert_series_equal(\n    left,\n    right,\n    check_dtype=True,\n    check_index_type=\"equiv\",\n    check_series_type=True,\n    check_less_precise=False,\n    check_names=True,\n    check_exact=False,\n    check_datetimelike_compat=False,\n    check_categorical=True,\n    obj=\"Series\",\n):\n    \"\"\"Check that left and right Series are equal.\n\n    Parameters\n    ----------\n    left : Series\n    right : Series\n    check_dtype : bool, default True\n        Whether to check the Series dtype is identical.\n    check_index_type : bool / string {'equiv'}, default 'equiv'\n        Whether to check the Index class, dtype and inferred_type\n        are identical.\n    check_series_type : bool, default True\n        Whether to check the Series class is identical.\n    check_less_precise : bool or int, default False\n        Specify comparison precision. Only used when check_exact is False.\n        5 digits (False) or 3 digits (True) after decimal points are compared.\n        If int, then specify the digits to compare.\n\n        When comparing two numbers, if the first number has magnitude less\n        than 1e-5, we compare the two numbers directly and check whether\n        they are equivalent within the specified precision. Otherwise, we\n        compare the **ratio** of the second number to the first number and\n        check whether it is equivalent to 1 within the specified precision.\n    check_names : bool, default True\n        Whether to check the Series and Index names attribute.\n    check_exact : bool, default False\n        Whether to compare number exactly.\n    check_datetimelike_compat : bool, default False\n        Compare datetime-like which is comparable ignoring dtype.\n    check_categorical : bool, default True\n        Whether to compare internal Categorical exactly.\n    obj : str, default 'Series'\n        Specify object name being compared, internally used to show appropriate\n        assertion message.\n    \"\"\"\n    __tracebackhide__ = True\n\n    # instance validation\n    _check_isinstance(left, right, Series)\n\n    if check_series_type:\n        # ToDo: There are some tests using rhs is sparse\n        # lhs is dense. Should use assert_class_equal in future\n        assert isinstance(left, type(right))\n        # assert_class_equal(left, right, obj=obj)\n\n    # length comparison\n    if len(left) != len(right):\n        msg1 = \"{len}, {left}\".format(len=len(left), left=left.index)\n        msg2 = \"{len}, {right}\".format(len=len(right), right=right.index)\n        raise_assert_detail(obj, \"Series length are different\", msg1, msg2)\n\n    # index comparison\n    assert_index_equal(\n        left.index,\n        right.index,\n        exact=check_index_type,\n        check_names=check_names,\n        check_less_precise=check_less_precise,\n        check_exact=check_exact,\n        check_categorical=check_categorical,\n        obj=\"{obj}.index\".format(obj=obj),\n    )\n\n    if check_dtype:\n        # We want to skip exact dtype checking when `check_categorical`\n        # is False. We'll still raise if only one is a `Categorical`,\n        # regardless of `check_categorical`\n        if (\n            is_categorical_dtype(left)\n            and is_categorical_dtype(right)\n            and not check_categorical\n        ):\n            pass\n        else:\n            assert_attr_equal(\"dtype\", left, right)\n\n    if check_exact:\n        assert_numpy_array_equal(\n            left._internal_get_values(),\n            right._internal_get_values(),\n            check_dtype=check_dtype,\n            obj=\"{obj}\".format(obj=obj),\n        )\n    elif check_datetimelike_compat:\n        # we want to check only if we have compat dtypes\n        # e.g. integer and M|m are NOT compat, but we can simply check\n        # the values in that case\n        if needs_i8_conversion(left) or needs_i8_conversion(right):\n\n            # datetimelike may have different objects (e.g. datetime.datetime\n            # vs Timestamp) but will compare equal\n            if not Index(left.values).equals(Index(right.values)):\n                msg = (\n                    \"[datetimelike_compat=True] {left} is not equal to \" \"{right}.\"\n                ).format(left=left.values, right=right.values)\n                raise AssertionError(msg)\n        else:\n            assert_numpy_array_equal(\n                left._internal_get_values(),\n                right._internal_get_values(),\n                check_dtype=check_dtype,\n            )\n    elif is_interval_dtype(left) or is_interval_dtype(right):\n        assert_interval_array_equal(left.array, right.array)\n    elif is_extension_array_dtype(left.dtype) and is_datetime64tz_dtype(left.dtype):\n        # .values is an ndarray, but ._values is the ExtensionArray.\n        # TODO: Use .array\n        assert is_extension_array_dtype(right.dtype)\n        assert_extension_array_equal(left._values, right._values)\n    elif (\n        is_extension_array_dtype(left)\n        and not is_categorical_dtype(left)\n        and is_extension_array_dtype(right)\n        and not is_categorical_dtype(right)\n    ):\n        assert_extension_array_equal(left.array, right.array)\n    else:\n        _testing.assert_almost_equal(\n            left._internal_get_values(),\n            right._internal_get_values(),\n            check_less_precise=check_less_precise,\n            check_dtype=check_dtype,\n            obj=\"{obj}\".format(obj=obj),\n        )\n\n    # metadata comparison\n    if check_names:\n        assert_attr_equal(\"name\", left, right, obj=obj)\n\n    if check_categorical:\n        if is_categorical_dtype(left) or is_categorical_dtype(right):\n            assert_categorical_equal(\n                left.values, right.values, obj=\"{obj} category\".format(obj=obj)\n            )",
        "begin_line": 1071,
        "end_line": 1218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.util.testing.assert_frame_equal#1222",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.assert_frame_equal(left, right, check_dtype=True, check_index_type='equiv', check_column_type='equiv', check_frame_type=True, check_less_precise=False, check_names=True, by_blocks=False, check_exact=False, check_datetimelike_compat=False, check_categorical=True, check_like=False, obj='DataFrame')",
        "snippet": "def assert_frame_equal(\n    left,\n    right,\n    check_dtype=True,\n    check_index_type=\"equiv\",\n    check_column_type=\"equiv\",\n    check_frame_type=True,\n    check_less_precise=False,\n    check_names=True,\n    by_blocks=False,\n    check_exact=False,\n    check_datetimelike_compat=False,\n    check_categorical=True,\n    check_like=False,\n    obj=\"DataFrame\",\n):\n    \"\"\"\n    Check that left and right DataFrame are equal.\n\n    This function is intended to compare two DataFrames and output any\n    differences. Is is mostly intended for use in unit tests.\n    Additional parameters allow varying the strictness of the\n    equality checks performed.\n\n    Parameters\n    ----------\n    left : DataFrame\n        First DataFrame to compare.\n    right : DataFrame\n        Second DataFrame to compare.\n    check_dtype : bool, default True\n        Whether to check the DataFrame dtype is identical.\n    check_index_type : bool / string {'equiv'}, default 'equiv'\n        Whether to check the Index class, dtype and inferred_type\n        are identical.\n    check_column_type : bool / string {'equiv'}, default 'equiv'\n        Whether to check the columns class, dtype and inferred_type\n        are identical. Is passed as the ``exact`` argument of\n        :func:`assert_index_equal`.\n    check_frame_type : bool, default True\n        Whether to check the DataFrame class is identical.\n    check_less_precise : bool or int, default False\n        Specify comparison precision. Only used when check_exact is False.\n        5 digits (False) or 3 digits (True) after decimal points are compared.\n        If int, then specify the digits to compare.\n\n        When comparing two numbers, if the first number has magnitude less\n        than 1e-5, we compare the two numbers directly and check whether\n        they are equivalent within the specified precision. Otherwise, we\n        compare the **ratio** of the second number to the first number and\n        check whether it is equivalent to 1 within the specified precision.\n    check_names : bool, default True\n        Whether to check that the `names` attribute for both the `index`\n        and `column` attributes of the DataFrame is identical, i.e.\n\n        * left.index.names == right.index.names\n        * left.columns.names == right.columns.names\n    by_blocks : bool, default False\n        Specify how to compare internal data. If False, compare by columns.\n        If True, compare by blocks.\n    check_exact : bool, default False\n        Whether to compare number exactly.\n    check_datetimelike_compat : bool, default False\n        Compare datetime-like which is comparable ignoring dtype.\n    check_categorical : bool, default True\n        Whether to compare internal Categorical exactly.\n    check_like : bool, default False\n        If True, ignore the order of index & columns.\n        Note: index labels must match their respective rows\n        (same as in columns) - same labels must be with the same data.\n    obj : str, default 'DataFrame'\n        Specify object name being compared, internally used to show appropriate\n        assertion message.\n\n    See Also\n    --------\n    assert_series_equal : Equivalent method for asserting Series equality.\n    DataFrame.equals : Check DataFrame equality.\n\n    Examples\n    --------\n    This example shows comparing two DataFrames that are equal\n    but with columns of differing dtypes.\n\n    >>> from pandas.util.testing import assert_frame_equal\n    >>> df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n    >>> df2 = pd.DataFrame({'a': [1, 2], 'b': [3.0, 4.0]})\n\n    df1 equals itself.\n\n    >>> assert_frame_equal(df1, df1)\n\n    df1 differs from df2 as column 'b' is of a different type.\n\n    >>> assert_frame_equal(df1, df2)\n    Traceback (most recent call last):\n    AssertionError: Attributes are different\n    ...\n    Attribute \"dtype\" are different\n    [left]:  int64\n    [right]: float64\n\n    Ignore differing dtypes in columns with check_dtype.\n\n    >>> assert_frame_equal(df1, df2, check_dtype=False)\n    \"\"\"\n    __tracebackhide__ = True\n\n    # instance validation\n    _check_isinstance(left, right, DataFrame)\n\n    if check_frame_type:\n        # ToDo: There are some tests using rhs is SparseDataFrame\n        # lhs is DataFrame. Should use assert_class_equal in future\n        assert isinstance(left, type(right))\n        # assert_class_equal(left, right, obj=obj)\n\n    # shape comparison\n    if left.shape != right.shape:\n        raise_assert_detail(\n            obj,\n            \"{obj} shape mismatch\".format(obj=obj),\n            \"{shape!r}\".format(shape=left.shape),\n            \"{shape!r}\".format(shape=right.shape),\n        )\n\n    if check_like:\n        left, right = left.reindex_like(right), right\n\n    # index comparison\n    assert_index_equal(\n        left.index,\n        right.index,\n        exact=check_index_type,\n        check_names=check_names,\n        check_less_precise=check_less_precise,\n        check_exact=check_exact,\n        check_categorical=check_categorical,\n        obj=\"{obj}.index\".format(obj=obj),\n    )\n\n    # column comparison\n    assert_index_equal(\n        left.columns,\n        right.columns,\n        exact=check_column_type,\n        check_names=check_names,\n        check_less_precise=check_less_precise,\n        check_exact=check_exact,\n        check_categorical=check_categorical,\n        obj=\"{obj}.columns\".format(obj=obj),\n    )\n\n    # compare by blocks\n    if by_blocks:\n        rblocks = right._to_dict_of_blocks()\n        lblocks = left._to_dict_of_blocks()\n        for dtype in list(set(list(lblocks.keys()) + list(rblocks.keys()))):\n            assert dtype in lblocks\n            assert dtype in rblocks\n            assert_frame_equal(\n                lblocks[dtype], rblocks[dtype], check_dtype=check_dtype, obj=obj\n            )\n\n    # compare by columns\n    else:\n        for i, col in enumerate(left.columns):\n            assert col in right\n            lcol = left.iloc[:, i]\n            rcol = right.iloc[:, i]\n            assert_series_equal(\n                lcol,\n                rcol,\n                check_dtype=check_dtype,\n                check_index_type=check_index_type,\n                check_less_precise=check_less_precise,\n                check_exact=check_exact,\n                check_names=check_names,\n                check_datetimelike_compat=check_datetimelike_compat,\n                check_categorical=check_categorical,\n                obj=\"{obj}.iloc[:, {idx}]\".format(obj=obj, idx=i),\n            )",
        "begin_line": 1222,
        "end_line": 1403,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.util._validators.validate_bool_kwarg#231",
        "src_path": "pandas/util/_validators.py",
        "class_name": "pandas.util._validators",
        "signature": "pandas.util._validators.validate_bool_kwarg(value, arg_name)",
        "snippet": "def validate_bool_kwarg(value, arg_name):\n    \"\"\" Ensures that argument passed in arg_name is of type bool. \"\"\"\n    if not (is_bool(value) or value is None):\n        raise ValueError(\n            'For argument \"{arg}\" expected type bool, received '\n            \"type {typ}.\".format(arg=arg_name, typ=type(value).__name__)\n        )\n    return value",
        "begin_line": 231,
        "end_line": 238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.computation.expressions.set_use_numexpr#40",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions.set_use_numexpr(v=True)",
        "snippet": "def set_use_numexpr(v=True):\n    # set/unset to use numexpr\n    global _USE_NUMEXPR\n    if _NUMEXPR_INSTALLED:\n        _USE_NUMEXPR = v\n\n    # choose what we are going to do\n    global _evaluate, _where\n    if not _USE_NUMEXPR:\n        _evaluate = _evaluate_standard\n        _where = _where_standard\n    else:\n        _evaluate = _evaluate_numexpr\n        _where = _where_numexpr",
        "begin_line": 40,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.computation.expressions._evaluate_standard#65",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions._evaluate_standard(op, op_str, a, b, **eval_kwargs)",
        "snippet": "def _evaluate_standard(op, op_str, a, b, **eval_kwargs):\n    \"\"\" standard evaluation \"\"\"\n    if _TEST_MODE:\n        _store_test_result(False)\n    with np.errstate(all=\"ignore\"):\n        return op(a, b)",
        "begin_line": 65,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.computation.expressions._can_use_numexpr#73",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions._can_use_numexpr(op, op_str, a, b, dtype_check)",
        "snippet": "def _can_use_numexpr(op, op_str, a, b, dtype_check):\n    \"\"\" return a boolean if we WILL be using numexpr \"\"\"\n    if op_str is not None:\n\n        # required min elements (otherwise we are adding overhead)\n        if np.prod(a.shape) > _MIN_ELEMENTS:\n\n            # check for dtype compatibility\n            dtypes = set()\n            for o in [a, b]:\n                if hasattr(o, \"dtypes\"):\n                    s = o.dtypes.value_counts()\n                    if len(s) > 1:\n                        return False\n                    dtypes |= set(s.index.astype(str))\n                elif isinstance(o, np.ndarray):\n                    dtypes |= {o.dtype.name}\n\n            # allowed are a superset\n            if not len(dtypes) or _ALLOWED_DTYPES[dtype_check] >= dtypes:\n                return True\n\n    return False",
        "begin_line": 73,
        "end_line": 95,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.computation.expressions._evaluate_numexpr#98",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions._evaluate_numexpr(op, op_str, a, b, truediv=True, reversed=False, **eval_kwargs)",
        "snippet": "def _evaluate_numexpr(op, op_str, a, b, truediv=True, reversed=False, **eval_kwargs):\n    result = None\n\n    if _can_use_numexpr(op, op_str, a, b, \"evaluate\"):\n        if reversed:\n            # we were originally called by a reversed op method\n            a, b = b, a\n\n        a_value = getattr(a, \"values\", a)\n        b_value = getattr(b, \"values\", b)\n        try:\n            result = ne.evaluate(\n                \"a_value {op} b_value\".format(op=op_str),\n                local_dict={\"a_value\": a_value, \"b_value\": b_value},\n                casting=\"safe\",\n                truediv=truediv,\n                **eval_kwargs\n            )\n        except ValueError as detail:\n            if \"unknown type object\" in str(detail):\n                pass\n\n    if _TEST_MODE:\n        _store_test_result(result is not None)\n\n    if result is None:\n        result = _evaluate_standard(op, op_str, a, b)\n\n    return result",
        "begin_line": 98,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.computation.expressions._has_bool_dtype#169",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions._has_bool_dtype(x)",
        "snippet": "def _has_bool_dtype(x):\n    try:\n        if isinstance(x, ABCDataFrame):\n            return \"bool\" in x.dtypes\n        else:\n            return x.dtype == bool\n    except AttributeError:\n        return isinstance(x, (bool, np.bool_))",
        "begin_line": 169,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.computation.expressions._bool_arith_check#179",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions._bool_arith_check(op_str, a, b, not_allowed=frozenset(('/', '//', '**')), unsupported=None)",
        "snippet": "def _bool_arith_check(\n    op_str, a, b, not_allowed=frozenset((\"/\", \"//\", \"**\")), unsupported=None\n):\n    if unsupported is None:\n        unsupported = {\"+\": \"|\", \"*\": \"&\", \"-\": \"^\"}\n\n    if _has_bool_dtype(a) and _has_bool_dtype(b):\n        if op_str in unsupported:\n            warnings.warn(\n                \"evaluating in Python space because the {op!r} \"\n                \"operator is not supported by numexpr for \"\n                \"the bool dtype, use {alt_op!r} instead\".format(\n                    op=op_str, alt_op=unsupported[op_str]\n                )\n            )\n            return False\n\n        if op_str in not_allowed:\n            raise NotImplementedError(\n                \"operator {op!r} not implemented for bool dtypes\".format(op=op_str)\n            )\n    return True",
        "begin_line": 179,
        "end_line": 200,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.computation.expressions.evaluate#203",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions.evaluate(op, op_str, a, b, use_numexpr=True, **eval_kwargs)",
        "snippet": "def evaluate(op, op_str, a, b, use_numexpr=True, **eval_kwargs):\n    \"\"\"\n    Evaluate and return the expression of the op on a and b.\n\n    Parameters\n    ----------\n    op : the actual operand\n    op_str : str\n        The string version of the op.\n    a : left operand\n    b : right operand\n    use_numexpr : bool, default True\n        Whether to try to use numexpr.\n    \"\"\"\n\n    use_numexpr = use_numexpr and _bool_arith_check(op_str, a, b)\n    if use_numexpr:\n        return _evaluate(op, op_str, a, b, **eval_kwargs)\n    return _evaluate_standard(op, op_str, a, b)",
        "begin_line": 203,
        "end_line": 221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__init__#164",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__init__(self, data: BlockManager, axes: Optional[List[Index]]=None, copy: bool=False, dtype: Optional[Dtype]=None, fastpath: bool=False)",
        "snippet": "    def __init__(\n        self,\n        data: BlockManager,\n        axes: Optional[List[Index]] = None,\n        copy: bool = False,\n        dtype: Optional[Dtype] = None,\n        fastpath: bool = False,\n    ):\n\n        if not fastpath:\n            if dtype is not None:\n                data = data.astype(dtype)\n            elif copy:\n                data = data.copy()\n\n            if axes is not None:\n                for i, ax in enumerate(axes):\n                    data = data.reindex_axis(ax, axis=i)\n\n        object.__setattr__(self, \"_is_copy\", None)\n        object.__setattr__(self, \"_data\", data)\n        object.__setattr__(self, \"_item_cache\", {})",
        "begin_line": 164,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._init_mgr#187",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._init_mgr(self, mgr, axes=None, dtype=None, copy=False)",
        "snippet": "    def _init_mgr(self, mgr, axes=None, dtype=None, copy=False):\n        \"\"\" passed a manager and a axes dict \"\"\"\n        for a, axe in axes.items():\n            if axe is not None:\n                mgr = mgr.reindex_axis(\n                    axe, axis=self._get_block_manager_axis(a), copy=False\n                )\n\n        # make a copy if explicitly requested\n        if copy:\n            mgr = mgr.copy()\n        if dtype is not None:\n            # avoid further copies if we can\n            if len(mgr.blocks) > 1 or mgr.blocks[0].values.dtype != dtype:\n                mgr = mgr.astype(dtype=dtype)\n        return mgr",
        "begin_line": 187,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._validate_dtype#229",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._validate_dtype(self, dtype)",
        "snippet": "    def _validate_dtype(self, dtype):\n        \"\"\" validate the passed dtype \"\"\"\n\n        if dtype is not None:\n            dtype = pandas_dtype(dtype)\n\n            # a compound dtype\n            if dtype.kind == \"V\":\n                raise NotImplementedError(\n                    \"compound dtypes are not implemented\"\n                    \" in the {0} constructor\".format(self.__class__.__name__)\n                )\n\n        return dtype",
        "begin_line": 229,
        "end_line": 242,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_axis_number#404",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_axis_number(cls, axis)",
        "snippet": "    def _get_axis_number(cls, axis):\n        axis = cls._AXIS_ALIASES.get(axis, axis)\n        if is_integer(axis):\n            if axis in cls._AXIS_NAMES:\n                return axis\n        else:\n            try:\n                return cls._AXIS_NUMBERS[axis]\n            except KeyError:\n                pass\n        raise ValueError(\"No axis named {0} for object type {1}\".format(axis, cls))",
        "begin_line": 404,
        "end_line": 414,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_axis_name#417",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_axis_name(cls, axis)",
        "snippet": "    def _get_axis_name(cls, axis):\n        axis = cls._AXIS_ALIASES.get(axis, axis)\n        if isinstance(axis, str):\n            if axis in cls._AXIS_NUMBERS:\n                return axis\n        else:\n            try:\n                return cls._AXIS_NAMES[axis]\n            except KeyError:\n                pass\n        raise ValueError(\"No axis named {0} for object type {1}\".format(axis, cls))",
        "begin_line": 417,
        "end_line": 427,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_axis#429",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_axis(self, axis)",
        "snippet": "    def _get_axis(self, axis):\n        name = self._get_axis_name(axis)\n        return getattr(self, name)",
        "begin_line": 429,
        "end_line": 431,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._info_axis#490",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._info_axis(self)",
        "snippet": "    def _info_axis(self):\n        return getattr(self, self._info_axis_name)",
        "begin_line": 490,
        "end_line": 491,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.ndim#514",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.ndim(self)",
        "snippet": "    def ndim(self):\n        \"\"\"\n        Return an int representing the number of axes / array dimensions.\n\n        Return 1 if Series. Otherwise return 2 if DataFrame.\n\n        See Also\n        --------\n        ndarray.ndim : Number of array dimensions.\n\n        Examples\n        --------\n        >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n        >>> s.ndim\n        1\n\n        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n        >>> df.ndim\n        2\n        \"\"\"\n        return self._data.ndim",
        "begin_line": 514,
        "end_line": 534,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._set_axis#669",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._set_axis(self, axis, labels)",
        "snippet": "    def _set_axis(self, axis, labels):\n        self._data.set_axis(axis, labels)\n        self._clear_item_cache()",
        "begin_line": 669,
        "end_line": 671,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__contains__#1909",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__contains__(self, key)",
        "snippet": "    def __contains__(self, key):\n        \"\"\"True if the key is in the info axis\"\"\"\n        return key in self._info_axis",
        "begin_line": 1909,
        "end_line": 1911,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._set_as_cached#3220",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._set_as_cached(self, item, cacher)",
        "snippet": "    def _set_as_cached(self, item, cacher):\n        \"\"\"Set the _cacher attribute on the calling object with a weakref to\n        cacher.\n        \"\"\"\n        self._cacher = (item, weakref.ref(cacher))",
        "begin_line": 3220,
        "end_line": 3224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._clear_item_cache#3281",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._clear_item_cache(self)",
        "snippet": "    def _clear_item_cache(self):\n        self._item_cache.clear()",
        "begin_line": 3281,
        "end_line": 3282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._set_is_copy#3590",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._set_is_copy(self, ref=None, copy=True)",
        "snippet": "    def _set_is_copy(self, ref=None, copy=True):\n        if not copy:\n            self._is_copy = None\n        else:\n            if ref is not None:\n                self._is_copy = weakref.ref(ref)\n            else:\n                self._is_copy = None",
        "begin_line": 3590,
        "end_line": 3597,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__finalize__#5119",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__finalize__(self, other, method=None, **kwargs)",
        "snippet": "    def __finalize__(self, other, method=None, **kwargs):\n        \"\"\"\n        Propagate metadata from other to self.\n\n        Parameters\n        ----------\n        other : the object from which to get the attributes that we are going\n            to propagate\n        method : optional, a passed method name ; possibly to take different\n            types of propagation actions based on this\n\n        \"\"\"\n        if isinstance(other, NDFrame):\n            for name in self._metadata:\n                object.__setattr__(self, name, getattr(other, name, None))\n        return self",
        "begin_line": 5119,
        "end_line": 5134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008045052292839903,
            "pseudo_dstar_susp": 0.006024096385542169,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.006024096385542169,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__getattr__#5136",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__getattr__(self, name)",
        "snippet": "    def __getattr__(self, name):\n        \"\"\"After regular attribute access, try looking up the name\n        This allows simpler access to columns for interactive use.\n        \"\"\"\n\n        # Note: obj.x will always call obj.__getattribute__('x') prior to\n        # calling obj.__getattr__('x').\n\n        if (\n            name in self._internal_names_set\n            or name in self._metadata\n            or name in self._accessors\n        ):\n            return object.__getattribute__(self, name)\n        else:\n            if self._info_axis._can_hold_identifiers_and_holds_name(name):\n                return self[name]\n            return object.__getattribute__(self, name)",
        "begin_line": 5136,
        "end_line": 5153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__setattr__#5155",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__setattr__(self, name, value)",
        "snippet": "    def __setattr__(self, name, value):\n        \"\"\"After regular attribute access, try setting the name\n        This allows simpler access to columns for interactive use.\n        \"\"\"\n\n        # first try regular attribute access via __getattribute__, so that\n        # e.g. ``obj.x`` and ``obj.x = 4`` will always reference/modify\n        # the same attribute.\n\n        try:\n            object.__getattribute__(self, name)\n            return object.__setattr__(self, name, value)\n        except AttributeError:\n            pass\n\n        # if this fails, go on to more involved attribute setting\n        # (note that this matches __getattr__, above).\n        if name in self._internal_names_set:\n            object.__setattr__(self, name, value)\n        elif name in self._metadata:\n            object.__setattr__(self, name, value)\n        else:\n            try:\n                existing = getattr(self, name)\n                if isinstance(existing, Index):\n                    object.__setattr__(self, name, value)\n                elif name in self._info_axis:\n                    self[name] = value\n                else:\n                    object.__setattr__(self, name, value)\n            except (AttributeError, TypeError):\n                if isinstance(self, ABCDataFrame) and (is_list_like(value)):\n                    warnings.warn(\n                        \"Pandas doesn't allow columns to be \"\n                        \"created via a new attribute name - see \"\n                        \"https://pandas.pydata.org/pandas-docs/\"\n                        \"stable/indexing.html#attribute-access\",\n                        stacklevel=2,\n                    )\n                object.__setattr__(self, name, value)",
        "begin_line": 5155,
        "end_line": 5194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._protect_consolidate#5210",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._protect_consolidate(self, f)",
        "snippet": "    def _protect_consolidate(self, f):\n        \"\"\"Consolidate _data -- if the blocks have changed, then clear the\n        cache\n        \"\"\"\n        blocks_before = len(self._data.blocks)\n        result = f()\n        if len(self._data.blocks) != blocks_before:\n            self._clear_item_cache()\n        return result",
        "begin_line": 5210,
        "end_line": 5218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007668711656441718,
            "pseudo_dstar_susp": 0.0007668711656441718,
            "pseudo_tarantula_susp": 0.0008403361344537816,
            "pseudo_op2_susp": 0.0007668711656441718,
            "pseudo_barinel_susp": 0.0008403361344537816
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._consolidate_inplace#5220",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._consolidate_inplace(self)",
        "snippet": "    def _consolidate_inplace(self):\n        \"\"\"Consolidate data in place and return None\"\"\"\n\n        def f():\n            self._data = self._data.consolidate()\n\n        self._protect_consolidate(f)",
        "begin_line": 5220,
        "end_line": 5226,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007668711656441718,
            "pseudo_dstar_susp": 0.0007668711656441718,
            "pseudo_tarantula_susp": 0.0008403361344537816,
            "pseudo_op2_susp": 0.0007668711656441718,
            "pseudo_barinel_susp": 0.0008403361344537816
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.f#5223",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.f()",
        "snippet": "        def f():\n            self._data = self._data.consolidate()",
        "begin_line": 5223,
        "end_line": 5224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.009009009009009009,
            "pseudo_tarantula_susp": 0.0008403361344537816,
            "pseudo_op2_susp": 0.009009009009009009,
            "pseudo_barinel_susp": 0.0008403361344537816
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._consolidate#5228",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._consolidate(self, inplace=False)",
        "snippet": "    def _consolidate(self, inplace=False):\n        \"\"\"\n        Compute NDFrame with \"consolidated\" internals (data of each dtype\n        grouped together in a single ndarray).\n\n        Parameters\n        ----------\n        inplace : bool, default False\n            If False return new object, otherwise modify existing object.\n\n        Returns\n        -------\n        consolidated : same type as caller\n        \"\"\"\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\n        if inplace:\n            self._consolidate_inplace()\n        else:\n            f = lambda: self._data.consolidate()\n            cons_data = self._protect_consolidate(f)\n            return self._constructor(cons_data).__finalize__(self)",
        "begin_line": 5228,
        "end_line": 5248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026246719160104987,
            "pseudo_dstar_susp": 0.002012072434607646,
            "pseudo_tarantula_susp": 0.003424657534246575,
            "pseudo_op2_susp": 0.002012072434607646,
            "pseudo_barinel_susp": 0.003424657534246575
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._is_mixed_type#5251",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._is_mixed_type(self)",
        "snippet": "    def _is_mixed_type(self):\n        f = lambda: self._data.is_mixed_type\n        return self._protect_consolidate(f)",
        "begin_line": 5251,
        "end_line": 5253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.values#5343",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.values(self)",
        "snippet": "    def values(self):\n        \"\"\"\n        Return a Numpy representation of the DataFrame.\n\n        .. warning::\n\n           We recommend using :meth:`DataFrame.to_numpy` instead.\n\n        Only the values in the DataFrame will be returned, the axes labels\n        will be removed.\n\n        Returns\n        -------\n        numpy.ndarray\n            The values of the DataFrame.\n\n        See Also\n        --------\n        DataFrame.to_numpy : Recommended alternative to this method.\n        DataFrame.index : Retrieve the index labels.\n        DataFrame.columns : Retrieving the column names.\n\n        Notes\n        -----\n        The dtype will be a lower-common-denominator dtype (implicit\n        upcasting); that is to say if the dtypes (even of numeric types)\n        are mixed, the one that accommodates all will be chosen. Use this\n        with care if you are not dealing with the blocks.\n\n        e.g. If the dtypes are float16 and float32, dtype will be upcast to\n        float32.  If dtypes are int32 and uint8, dtype will be upcast to\n        int32. By :func:`numpy.find_common_type` convention, mixing int64\n        and uint64 will result in a float64 dtype.\n\n        Examples\n        --------\n        A DataFrame where all columns are the same type (e.g., int64) results\n        in an array of the same type.\n\n        >>> df = pd.DataFrame({'age':    [ 3,  29],\n        ...                    'height': [94, 170],\n        ...                    'weight': [31, 115]})\n        >>> df\n           age  height  weight\n        0    3      94      31\n        1   29     170     115\n        >>> df.dtypes\n        age       int64\n        height    int64\n        weight    int64\n        dtype: object\n        >>> df.values\n        array([[  3,  94,  31],\n               [ 29, 170, 115]], dtype=int64)\n\n        A DataFrame with mixed type columns(e.g., str/object, int64, float32)\n        results in an ndarray of the broadest type that accommodates these\n        mixed types (e.g., object).\n\n        >>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),\n        ...                     ('lion',     80.5, 1),\n        ...                     ('monkey', np.nan, None)],\n        ...                   columns=('name', 'max_speed', 'rank'))\n        >>> df2.dtypes\n        name          object\n        max_speed    float64\n        rank          object\n        dtype: object\n        >>> df2.values\n        array([['parrot', 24.0, 'second'],\n               ['lion', 80.5, 1],\n               ['monkey', nan, None]], dtype=object)\n        \"\"\"\n        self._consolidate_inplace()\n        return self._data.as_array(transpose=self._AXIS_REVERSED)",
        "begin_line": 5343,
        "end_line": 5417,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005058168942842691,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.0005058168942842691,
            "pseudo_op2_susp": 0.0005302226935312832,
            "pseudo_barinel_susp": 0.0005058168942842691
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.dtypes#5578",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.dtypes(self)",
        "snippet": "    def dtypes(self):\n        \"\"\"\n        Return the dtypes in the DataFrame.\n\n        This returns a Series with the data type of each column.\n        The result's index is the original DataFrame's columns. Columns\n        with mixed types are stored with the ``object`` dtype. See\n        :ref:`the User Guide <basics.dtypes>` for more.\n\n        Returns\n        -------\n        pandas.Series\n            The data type of each column.\n\n        See Also\n        --------\n        DataFrame.ftypes : Dtype and sparsity information.\n\n        Examples\n        --------\n        >>> df = pd.DataFrame({'float': [1.0],\n        ...                    'int': [1],\n        ...                    'datetime': [pd.Timestamp('20180310')],\n        ...                    'string': ['foo']})\n        >>> df.dtypes\n        float              float64\n        int                  int64\n        datetime    datetime64[ns]\n        string              object\n        dtype: object\n        \"\"\"\n        from pandas import Series\n\n        return Series(self._data.get_dtypes(), index=self._info_axis, dtype=np.object_)",
        "begin_line": 5578,
        "end_line": 5611,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.copy#5866",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.copy(self, deep=True)",
        "snippet": "    def copy(self, deep=True):\n        \"\"\"\n        Make a copy of this object's indices and data.\n\n        When ``deep=True`` (default), a new object will be created with a\n        copy of the calling object's data and indices. Modifications to\n        the data or indices of the copy will not be reflected in the\n        original object (see notes below).\n\n        When ``deep=False``, a new object will be created without copying\n        the calling object's data or index (only references to the data\n        and index are copied). Any changes to the data of the original\n        will be reflected in the shallow copy (and vice versa).\n\n        Parameters\n        ----------\n        deep : bool, default True\n            Make a deep copy, including a copy of the data and the indices.\n            With ``deep=False`` neither the indices nor the data are copied.\n\n        Returns\n        -------\n        copy : Series or DataFrame\n            Object type matches caller.\n\n        Notes\n        -----\n        When ``deep=True``, data is copied but actual Python objects\n        will not be copied recursively, only the reference to the object.\n        This is in contrast to `copy.deepcopy` in the Standard Library,\n        which recursively copies object data (see examples below).\n\n        While ``Index`` objects are copied when ``deep=True``, the underlying\n        numpy array is not copied for performance reasons. Since ``Index`` is\n        immutable, the underlying data can be safely shared and a copy\n        is not needed.\n\n        Examples\n        --------\n        >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n        >>> s\n        a    1\n        b    2\n        dtype: int64\n\n        >>> s_copy = s.copy()\n        >>> s_copy\n        a    1\n        b    2\n        dtype: int64\n\n        **Shallow copy versus default (deep) copy:**\n\n        >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n        >>> deep = s.copy()\n        >>> shallow = s.copy(deep=False)\n\n        Shallow copy shares data and index with original.\n\n        >>> s is shallow\n        False\n        >>> s.values is shallow.values and s.index is shallow.index\n        True\n\n        Deep copy has own copy of data and index.\n\n        >>> s is deep\n        False\n        >>> s.values is deep.values or s.index is deep.index\n        False\n\n        Updates to the data shared by shallow copy and original is reflected\n        in both; deep copy remains unchanged.\n\n        >>> s[0] = 3\n        >>> shallow[1] = 4\n        >>> s\n        a    3\n        b    4\n        dtype: int64\n        >>> shallow\n        a    3\n        b    4\n        dtype: int64\n        >>> deep\n        a    1\n        b    2\n        dtype: int64\n\n        Note that when copying an object containing Python objects, a deep copy\n        will copy the data, but will not do so recursively. Updating a nested\n        data object will be reflected in the deep copy.\n\n        >>> s = pd.Series([[1, 2], [3, 4]])\n        >>> deep = s.copy()\n        >>> s[0][0] = 10\n        >>> s\n        0    [10, 2]\n        1     [3, 4]\n        dtype: object\n        >>> deep\n        0    [10, 2]\n        1     [3, 4]\n        dtype: object\n        \"\"\"\n        data = self._data.copy(deep=deep)\n        return self._constructor(data).__finalize__(self)",
        "begin_line": 5866,
        "end_line": 5972,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.align#8704",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)",
        "snippet": "    def align(\n        self,\n        other,\n        join=\"outer\",\n        axis=None,\n        level=None,\n        copy=True,\n        fill_value=None,\n        method=None,\n        limit=None,\n        fill_axis=0,\n        broadcast_axis=None,\n    ):\n        method = missing.clean_fill_method(method)\n\n        if broadcast_axis == 1 and self.ndim != other.ndim:\n            if isinstance(self, ABCSeries):\n                # this means other is a DataFrame, and we need to broadcast\n                # self\n                cons = self._constructor_expanddim\n                df = cons(\n                    {c: self for c in other.columns}, **other._construct_axes_dict()\n                )\n                return df._align_frame(\n                    other,\n                    join=join,\n                    axis=axis,\n                    level=level,\n                    copy=copy,\n                    fill_value=fill_value,\n                    method=method,\n                    limit=limit,\n                    fill_axis=fill_axis,\n                )\n            elif isinstance(other, ABCSeries):\n                # this means self is a DataFrame, and we need to broadcast\n                # other\n                cons = other._constructor_expanddim\n                df = cons(\n                    {c: other for c in self.columns}, **self._construct_axes_dict()\n                )\n                return self._align_frame(\n                    df,\n                    join=join,\n                    axis=axis,\n                    level=level,\n                    copy=copy,\n                    fill_value=fill_value,\n                    method=method,\n                    limit=limit,\n                    fill_axis=fill_axis,\n                )\n\n        if axis is not None:\n            axis = self._get_axis_number(axis)\n        if isinstance(other, ABCDataFrame):\n            return self._align_frame(\n                other,\n                join=join,\n                axis=axis,\n                level=level,\n                copy=copy,\n                fill_value=fill_value,\n                method=method,\n                limit=limit,\n                fill_axis=fill_axis,\n            )\n        elif isinstance(other, ABCSeries):\n            return self._align_series(\n                other,\n                join=join,\n                axis=axis,\n                level=level,\n                copy=copy,\n                fill_value=fill_value,\n                method=method,\n                limit=limit,\n                fill_axis=fill_axis,\n            )\n        else:  # pragma: no cover\n            raise TypeError(\"unsupported type: %s\" % type(other))",
        "begin_line": 8704,
        "end_line": 8784,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._align_series#8846",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._align_series(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0)",
        "snippet": "    def _align_series(\n        self,\n        other,\n        join=\"outer\",\n        axis=None,\n        level=None,\n        copy=True,\n        fill_value=None,\n        method=None,\n        limit=None,\n        fill_axis=0,\n    ):\n\n        is_series = isinstance(self, ABCSeries)\n\n        # series/series compat, other must always be a Series\n        if is_series:\n            if axis:\n                raise ValueError(\"cannot align series to a series other than axis 0\")\n\n            # equal\n            if self.index.equals(other.index):\n                join_index, lidx, ridx = None, None, None\n            else:\n                join_index, lidx, ridx = self.index.join(\n                    other.index, how=join, level=level, return_indexers=True\n                )\n\n            left = self._reindex_indexer(join_index, lidx, copy)\n            right = other._reindex_indexer(join_index, ridx, copy)\n\n        else:\n            # one has > 1 ndim\n            fdata = self._data\n            if axis == 0:\n                join_index = self.index\n                lidx, ridx = None, None\n                if not self.index.equals(other.index):\n                    join_index, lidx, ridx = self.index.join(\n                        other.index, how=join, level=level, return_indexers=True\n                    )\n\n                if lidx is not None:\n                    fdata = fdata.reindex_indexer(join_index, lidx, axis=1)\n\n            elif axis == 1:\n                join_index = self.columns\n                lidx, ridx = None, None\n                if not self.columns.equals(other.index):\n                    join_index, lidx, ridx = self.columns.join(\n                        other.index, how=join, level=level, return_indexers=True\n                    )\n\n                if lidx is not None:\n                    fdata = fdata.reindex_indexer(join_index, lidx, axis=0)\n            else:\n                raise ValueError(\"Must specify axis=0 or 1\")\n\n            if copy and fdata is self._data:\n                fdata = fdata.copy()\n\n            left = self._constructor(fdata)\n\n            if ridx is None:\n                right = other\n            else:\n                right = other.reindex(join_index, level=level)\n\n        # fill\n        fill_na = notna(fill_value) or (method is not None)\n        if fill_na:\n            left = left.fillna(fill_value, method=method, limit=limit, axis=fill_axis)\n            right = right.fillna(fill_value, method=method, limit=limit)\n\n        # if DatetimeIndex have different tz, convert to UTC\n        if is_series or (not is_series and axis == 0):\n            if is_datetime64tz_dtype(left.index):\n                if left.index.tz != right.index.tz:\n                    if join_index is not None:\n                        left.index = join_index\n                        right.index = join_index\n\n        return left.__finalize__(self), right.__finalize__(other)",
        "begin_line": 8846,
        "end_line": 8928,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001081081081081081,
            "pseudo_dstar_susp": 0.0009652509652509653,
            "pseudo_tarantula_susp": 0.0011723329425556857,
            "pseudo_op2_susp": 0.0009652509652509653,
            "pseudo_barinel_susp": 0.0011723329425556857
        }
    },
    {
        "name": "pandas.conftest.pytest_runtest_setup#48",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.pytest_runtest_setup(item)",
        "snippet": "def pytest_runtest_setup(item):\n    if \"slow\" in item.keywords and item.config.getoption(\"--skip-slow\"):\n        pytest.skip(\"skipping due to --skip-slow\")\n\n    if \"slow\" not in item.keywords and item.config.getoption(\"--only-slow\"):\n        pytest.skip(\"skipping due to --only-slow\")\n\n    if \"network\" in item.keywords and item.config.getoption(\"--skip-network\"):\n        pytest.skip(\"skipping due to --skip-network\")\n\n    if \"db\" in item.keywords and item.config.getoption(\"--skip-db\"):\n        pytest.skip(\"skipping due to --skip-db\")\n\n    if \"high_memory\" in item.keywords and not item.config.getoption(\n        \"--run-high-memory\"\n    ):\n        pytest.skip(\"skipping high memory test since --run-high-memory was not set\")",
        "begin_line": 48,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.conftest.configure_tests#71",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.configure_tests()",
        "snippet": "def configure_tests():\n    pd.set_option(\"chained_assignment\", \"raise\")",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    },
    {
        "name": "pandas.conftest.add_imports#79",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.add_imports(doctest_namespace)",
        "snippet": "def add_imports(doctest_namespace):\n    doctest_namespace[\"np\"] = np\n    doctest_namespace[\"pd\"] = pd",
        "begin_line": 79,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006357279084551812,
            "pseudo_dstar_susp": 0.0006357279084551812,
            "pseudo_tarantula_susp": 0.0006596306068601583,
            "pseudo_op2_susp": 0.0006357279084551812,
            "pseudo_barinel_susp": 0.0006596306068601583
        }
    }
]