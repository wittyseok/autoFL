coverage run -m pytest pandas/tests/io/test_pickle.py::test_pickle_buffer_roundtrip
============================= test session starts ==============================
platform linux -- Python 3.8.3, pytest-5.4.3, py-1.8.1, pluggy-0.13.1
rootdir: /home/user/BugsInPy/temp/projects/pandas, inifile: setup.cfg
plugins: hypothesis-5.16.0
collected 1 item

pandas/tests/io/test_pickle.py F                                         [100%]

=================================== FAILURES ===================================
_________________________ test_pickle_buffer_roundtrip _________________________

    def test_pickle_buffer_roundtrip():
        with tm.ensure_clean() as path:
            df = tm.makeDataFrame()
            with open(path, "wb") as fh:
>               df.to_pickle(fh)

pandas/tests/io/test_pickle.py:405: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
pandas/core/generic.py:2702: in to_pickle
    to_pickle(self, path, compression=compression, protocol=protocol)
pandas/io/pickle.py:67: in to_pickle
    f, fh = get_handle(path, "wb", compression=compression, is_text=False)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = <_io.BufferedWriter name='/tmp/tmpnq19uo9e'>, mode = 'wb'
encoding = None, compression = 'infer', memory_map = False, is_text = False

    def get_handle(
        path_or_buf,
        mode: str,
        encoding=None,
        compression: Optional[Union[str, Mapping[str, Any]]] = None,
        memory_map: bool = False,
        is_text: bool = True,
    ):
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        compression : str or dict, default None
            If string, specifies compression mode. If dict, value at key 'method'
            specifies compression mode. Compression mode must be one of {'infer',
            'gzip', 'bz2', 'zip', 'xz', None}. If compression mode is 'infer'
            and `filepath_or_buffer` is path-like, then detect compression from
            the following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise
            no compression). If dict and compression mode is 'zip' or inferred as
            'zip', other entries passed as additional compression options.
    
            .. versionchanged:: 1.0.0
    
               May now be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
        memory_map : boolean, default False
            See parsers._parser_params for more information.
        is_text : boolean, default True
            whether file/buffer is in text format (csv, json, etc.), or in binary
            mode (pickle, etc.).
    
        Returns
        -------
        f : file-like
            A file-like object.
        handles : list of file-like objects
            A list of file-like object that were opened in this function.
        """
        try:
            from s3fs import S3File
    
            need_text_wrapping = (BufferedIOBase, S3File)
        except ImportError:
            need_text_wrapping = BufferedIOBase  # type: ignore
    
        handles: List[IO] = list()
        f = path_or_buf
    
        # Convert pathlib.Path/py.path.local or string
        path_or_buf = stringify_path(path_or_buf)
        is_path = isinstance(path_or_buf, str)
    
        compression, compression_args = get_compression_method(compression)
        if is_path:
            compression = infer_compression(path_or_buf, compression)
    
        if compression:
    
            # GZ Compression
            if compression == "gzip":
                if is_path:
                    f = gzip.open(path_or_buf, mode)
                else:
                    f = gzip.GzipFile(fileobj=path_or_buf)
    
            # BZ Compression
            elif compression == "bz2":
                if is_path:
                    f = bz2.BZ2File(path_or_buf, mode)
                else:
                    f = bz2.BZ2File(path_or_buf)
    
            # ZIP Compression
            elif compression == "zip":
                zf = _BytesZipFile(path_or_buf, mode, **compression_args)
                # Ensure the container is closed as well.
                handles.append(zf)
                if zf.mode == "w":
                    f = zf
                elif zf.mode == "r":
                    zip_names = zf.namelist()
                    if len(zip_names) == 1:
                        f = zf.open(zip_names.pop())
                    elif len(zip_names) == 0:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file."
                            f" Only one file per ZIP: {zip_names}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                f = _get_lzma_file(lzma)(path_or_buf, mode)
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
>               raise ValueError(msg)
E               ValueError: Unrecognized compression type: infer

pandas/io/common.py:421: ValueError
=========================== short test summary info ============================
FAILED pandas/tests/io/test_pickle.py::test_pickle_buffer_roundtrip - ValueEr...
============================== 1 failed in 0.46s ===============================

coverage run -m pytest pandas/tests/io/test_pickle.py::test_pickle_generalurl_read
============================= test session starts ==============================
platform linux -- Python 3.8.3, pytest-5.4.3, py-1.8.1, pluggy-0.13.1
rootdir: /home/user/BugsInPy/temp/projects/pandas, inifile: setup.cfg
plugins: hypothesis-5.16.0
collected 3 items

pandas/tests/io/test_pickle.py FFF                                       [100%]

=================================== FAILURES ===================================
_________________ test_pickle_generalurl_read[http://url.com] __________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f94835e7850>
mockurl = 'http://url.com'

    @pytest.mark.parametrize(
        "mockurl", ["http://url.com", "ftp://test.com", "http://gzip.com"]
    )
    def test_pickle_generalurl_read(monkeypatch, mockurl):
        def python_pickler(obj, path):
            with open(path, "wb") as fh:
                pickle.dump(obj, fh, protocol=-1)
    
        class MockReadResponse:
            def __init__(self, path):
                self.file = open(path, "rb")
                if "gzip" in path:
                    self.headers = {"Content-Encoding": "gzip"}
                else:
                    self.headers = {"Content-Encoding": None}
    
            def read(self):
                return self.file.read()
    
            def close(self):
                return self.file.close()
    
        with tm.ensure_clean() as path:
    
            def mock_urlopen_read(*args, **kwargs):
                return MockReadResponse(path)
    
            df = tm.makeDataFrame()
            python_pickler(df, path)
            monkeypatch.setattr("urllib.request.urlopen", mock_urlopen_read)
>           result = pd.read_pickle(mockurl)

pandas/tests/io/test_pickle.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
pandas/io/pickle.py:138: in read_pickle
    f, fh = get_handle(path, "rb", compression=compression, is_text=False)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'http://url.com', mode = 'rb', encoding = None, compression = None
memory_map = False, is_text = False

    def get_handle(
        path_or_buf,
        mode: str,
        encoding=None,
        compression: Optional[Union[str, Mapping[str, Any]]] = None,
        memory_map: bool = False,
        is_text: bool = True,
    ):
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        compression : str or dict, default None
            If string, specifies compression mode. If dict, value at key 'method'
            specifies compression mode. Compression mode must be one of {'infer',
            'gzip', 'bz2', 'zip', 'xz', None}. If compression mode is 'infer'
            and `filepath_or_buffer` is path-like, then detect compression from
            the following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise
            no compression). If dict and compression mode is 'zip' or inferred as
            'zip', other entries passed as additional compression options.
    
            .. versionchanged:: 1.0.0
    
               May now be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
        memory_map : boolean, default False
            See parsers._parser_params for more information.
        is_text : boolean, default True
            whether file/buffer is in text format (csv, json, etc.), or in binary
            mode (pickle, etc.).
    
        Returns
        -------
        f : file-like
            A file-like object.
        handles : list of file-like objects
            A list of file-like object that were opened in this function.
        """
        try:
            from s3fs import S3File
    
            need_text_wrapping = (BufferedIOBase, S3File)
        except ImportError:
            need_text_wrapping = BufferedIOBase  # type: ignore
    
        handles: List[IO] = list()
        f = path_or_buf
    
        # Convert pathlib.Path/py.path.local or string
        path_or_buf = stringify_path(path_or_buf)
        is_path = isinstance(path_or_buf, str)
    
        compression, compression_args = get_compression_method(compression)
        if is_path:
            compression = infer_compression(path_or_buf, compression)
    
        if compression:
    
            # GZ Compression
            if compression == "gzip":
                if is_path:
                    f = gzip.open(path_or_buf, mode)
                else:
                    f = gzip.GzipFile(fileobj=path_or_buf)
    
            # BZ Compression
            elif compression == "bz2":
                if is_path:
                    f = bz2.BZ2File(path_or_buf, mode)
                else:
                    f = bz2.BZ2File(path_or_buf)
    
            # ZIP Compression
            elif compression == "zip":
                zf = _BytesZipFile(path_or_buf, mode, **compression_args)
                # Ensure the container is closed as well.
                handles.append(zf)
                if zf.mode == "w":
                    f = zf
                elif zf.mode == "r":
                    zip_names = zf.namelist()
                    if len(zip_names) == 1:
                        f = zf.open(zip_names.pop())
                    elif len(zip_names) == 0:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file."
                            f" Only one file per ZIP: {zip_names}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                f = _get_lzma_file(lzma)(path_or_buf, mode)
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            handles.append(f)
    
        elif is_path:
            if encoding:
                # Encoding
                f = open(path_or_buf, mode, encoding=encoding, newline="")
            elif is_text:
                # No explicit encoding
                f = open(path_or_buf, mode, errors="replace", newline="")
            else:
                # Binary mode
>               f = open(path_or_buf, mode)
E               FileNotFoundError: [Errno 2] No such file or directory: 'http://url.com'

pandas/io/common.py:434: FileNotFoundError
_________________ test_pickle_generalurl_read[ftp://test.com] __________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f948348eca0>
mockurl = 'ftp://test.com'

    @pytest.mark.parametrize(
        "mockurl", ["http://url.com", "ftp://test.com", "http://gzip.com"]
    )
    def test_pickle_generalurl_read(monkeypatch, mockurl):
        def python_pickler(obj, path):
            with open(path, "wb") as fh:
                pickle.dump(obj, fh, protocol=-1)
    
        class MockReadResponse:
            def __init__(self, path):
                self.file = open(path, "rb")
                if "gzip" in path:
                    self.headers = {"Content-Encoding": "gzip"}
                else:
                    self.headers = {"Content-Encoding": None}
    
            def read(self):
                return self.file.read()
    
            def close(self):
                return self.file.close()
    
        with tm.ensure_clean() as path:
    
            def mock_urlopen_read(*args, **kwargs):
                return MockReadResponse(path)
    
            df = tm.makeDataFrame()
            python_pickler(df, path)
            monkeypatch.setattr("urllib.request.urlopen", mock_urlopen_read)
>           result = pd.read_pickle(mockurl)

pandas/tests/io/test_pickle.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
pandas/io/pickle.py:138: in read_pickle
    f, fh = get_handle(path, "rb", compression=compression, is_text=False)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'ftp://test.com', mode = 'rb', encoding = None, compression = None
memory_map = False, is_text = False

    def get_handle(
        path_or_buf,
        mode: str,
        encoding=None,
        compression: Optional[Union[str, Mapping[str, Any]]] = None,
        memory_map: bool = False,
        is_text: bool = True,
    ):
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        compression : str or dict, default None
            If string, specifies compression mode. If dict, value at key 'method'
            specifies compression mode. Compression mode must be one of {'infer',
            'gzip', 'bz2', 'zip', 'xz', None}. If compression mode is 'infer'
            and `filepath_or_buffer` is path-like, then detect compression from
            the following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise
            no compression). If dict and compression mode is 'zip' or inferred as
            'zip', other entries passed as additional compression options.
    
            .. versionchanged:: 1.0.0
    
               May now be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
        memory_map : boolean, default False
            See parsers._parser_params for more information.
        is_text : boolean, default True
            whether file/buffer is in text format (csv, json, etc.), or in binary
            mode (pickle, etc.).
    
        Returns
        -------
        f : file-like
            A file-like object.
        handles : list of file-like objects
            A list of file-like object that were opened in this function.
        """
        try:
            from s3fs import S3File
    
            need_text_wrapping = (BufferedIOBase, S3File)
        except ImportError:
            need_text_wrapping = BufferedIOBase  # type: ignore
    
        handles: List[IO] = list()
        f = path_or_buf
    
        # Convert pathlib.Path/py.path.local or string
        path_or_buf = stringify_path(path_or_buf)
        is_path = isinstance(path_or_buf, str)
    
        compression, compression_args = get_compression_method(compression)
        if is_path:
            compression = infer_compression(path_or_buf, compression)
    
        if compression:
    
            # GZ Compression
            if compression == "gzip":
                if is_path:
                    f = gzip.open(path_or_buf, mode)
                else:
                    f = gzip.GzipFile(fileobj=path_or_buf)
    
            # BZ Compression
            elif compression == "bz2":
                if is_path:
                    f = bz2.BZ2File(path_or_buf, mode)
                else:
                    f = bz2.BZ2File(path_or_buf)
    
            # ZIP Compression
            elif compression == "zip":
                zf = _BytesZipFile(path_or_buf, mode, **compression_args)
                # Ensure the container is closed as well.
                handles.append(zf)
                if zf.mode == "w":
                    f = zf
                elif zf.mode == "r":
                    zip_names = zf.namelist()
                    if len(zip_names) == 1:
                        f = zf.open(zip_names.pop())
                    elif len(zip_names) == 0:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file."
                            f" Only one file per ZIP: {zip_names}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                f = _get_lzma_file(lzma)(path_or_buf, mode)
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            handles.append(f)
    
        elif is_path:
            if encoding:
                # Encoding
                f = open(path_or_buf, mode, encoding=encoding, newline="")
            elif is_text:
                # No explicit encoding
                f = open(path_or_buf, mode, errors="replace", newline="")
            else:
                # Binary mode
>               f = open(path_or_buf, mode)
E               FileNotFoundError: [Errno 2] No such file or directory: 'ftp://test.com'

pandas/io/common.py:434: FileNotFoundError
_________________ test_pickle_generalurl_read[http://gzip.com] _________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f9483533550>
mockurl = 'http://gzip.com'

    @pytest.mark.parametrize(
        "mockurl", ["http://url.com", "ftp://test.com", "http://gzip.com"]
    )
    def test_pickle_generalurl_read(monkeypatch, mockurl):
        def python_pickler(obj, path):
            with open(path, "wb") as fh:
                pickle.dump(obj, fh, protocol=-1)
    
        class MockReadResponse:
            def __init__(self, path):
                self.file = open(path, "rb")
                if "gzip" in path:
                    self.headers = {"Content-Encoding": "gzip"}
                else:
                    self.headers = {"Content-Encoding": None}
    
            def read(self):
                return self.file.read()
    
            def close(self):
                return self.file.close()
    
        with tm.ensure_clean() as path:
    
            def mock_urlopen_read(*args, **kwargs):
                return MockReadResponse(path)
    
            df = tm.makeDataFrame()
            python_pickler(df, path)
            monkeypatch.setattr("urllib.request.urlopen", mock_urlopen_read)
>           result = pd.read_pickle(mockurl)

pandas/tests/io/test_pickle.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
pandas/io/pickle.py:138: in read_pickle
    f, fh = get_handle(path, "rb", compression=compression, is_text=False)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'http://gzip.com', mode = 'rb', encoding = None
compression = None, memory_map = False, is_text = False

    def get_handle(
        path_or_buf,
        mode: str,
        encoding=None,
        compression: Optional[Union[str, Mapping[str, Any]]] = None,
        memory_map: bool = False,
        is_text: bool = True,
    ):
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        compression : str or dict, default None
            If string, specifies compression mode. If dict, value at key 'method'
            specifies compression mode. Compression mode must be one of {'infer',
            'gzip', 'bz2', 'zip', 'xz', None}. If compression mode is 'infer'
            and `filepath_or_buffer` is path-like, then detect compression from
            the following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise
            no compression). If dict and compression mode is 'zip' or inferred as
            'zip', other entries passed as additional compression options.
    
            .. versionchanged:: 1.0.0
    
               May now be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
        memory_map : boolean, default False
            See parsers._parser_params for more information.
        is_text : boolean, default True
            whether file/buffer is in text format (csv, json, etc.), or in binary
            mode (pickle, etc.).
    
        Returns
        -------
        f : file-like
            A file-like object.
        handles : list of file-like objects
            A list of file-like object that were opened in this function.
        """
        try:
            from s3fs import S3File
    
            need_text_wrapping = (BufferedIOBase, S3File)
        except ImportError:
            need_text_wrapping = BufferedIOBase  # type: ignore
    
        handles: List[IO] = list()
        f = path_or_buf
    
        # Convert pathlib.Path/py.path.local or string
        path_or_buf = stringify_path(path_or_buf)
        is_path = isinstance(path_or_buf, str)
    
        compression, compression_args = get_compression_method(compression)
        if is_path:
            compression = infer_compression(path_or_buf, compression)
    
        if compression:
    
            # GZ Compression
            if compression == "gzip":
                if is_path:
                    f = gzip.open(path_or_buf, mode)
                else:
                    f = gzip.GzipFile(fileobj=path_or_buf)
    
            # BZ Compression
            elif compression == "bz2":
                if is_path:
                    f = bz2.BZ2File(path_or_buf, mode)
                else:
                    f = bz2.BZ2File(path_or_buf)
    
            # ZIP Compression
            elif compression == "zip":
                zf = _BytesZipFile(path_or_buf, mode, **compression_args)
                # Ensure the container is closed as well.
                handles.append(zf)
                if zf.mode == "w":
                    f = zf
                elif zf.mode == "r":
                    zip_names = zf.namelist()
                    if len(zip_names) == 1:
                        f = zf.open(zip_names.pop())
                    elif len(zip_names) == 0:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file."
                            f" Only one file per ZIP: {zip_names}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                f = _get_lzma_file(lzma)(path_or_buf, mode)
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            handles.append(f)
    
        elif is_path:
            if encoding:
                # Encoding
                f = open(path_or_buf, mode, encoding=encoding, newline="")
            elif is_text:
                # No explicit encoding
                f = open(path_or_buf, mode, errors="replace", newline="")
            else:
                # Binary mode
>               f = open(path_or_buf, mode)
E               FileNotFoundError: [Errno 2] No such file or directory: 'http://gzip.com'

pandas/io/common.py:434: FileNotFoundError
=========================== short test summary info ============================
FAILED pandas/tests/io/test_pickle.py::test_pickle_generalurl_read[http://url.com]
FAILED pandas/tests/io/test_pickle.py::test_pickle_generalurl_read[ftp://test.com]
FAILED pandas/tests/io/test_pickle.py::test_pickle_generalurl_read[http://gzip.com]
============================== 3 failed in 0.58s ===============================
