[
    {
        "name": "pandas.tests.io.excel.conftest.frame#11",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.frame(float_frame)",
        "snippet": "def frame(float_frame):\n    \"\"\"\n    Returns the first ten items in fixture \"float_frame\".\n    \"\"\"\n    return float_frame[:10]",
        "begin_line": 11,
        "end_line": 15,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.tsframe#19",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.tsframe()",
        "snippet": "def tsframe():\n    return tm.makeTimeDataFrame()[:5]",
        "begin_line": 19,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.merge_cells#24",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.merge_cells(request)",
        "snippet": "def merge_cells(request):\n    return request.param",
        "begin_line": 24,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.df_ref#29",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.df_ref(datapath)",
        "snippet": "def df_ref(datapath):\n    \"\"\"\n    Obtain the reference data from read_csv with the Python engine.\n    \"\"\"\n    filepath = datapath(\"io\", \"data\", \"csv\", \"test1.csv\")\n    df_ref = read_csv(filepath, index_col=0, parse_dates=True, engine=\"python\")\n    return df_ref",
        "begin_line": 29,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.read_ext#39",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.read_ext(request)",
        "snippet": "def read_ext(request):\n    \"\"\"\n    Valid extensions for reading Excel files.\n    \"\"\"\n    return request.param",
        "begin_line": 39,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.check_for_file_leaks#47",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.check_for_file_leaks()",
        "snippet": "def check_for_file_leaks():\n    \"\"\"\n    Fixture to run around every test to ensure that we are not leaking files.\n\n    See also\n    --------\n    _test_decorators.check_file_leaks\n    \"\"\"\n    # GH#30162\n    psutil = td.safe_import(\"psutil\")\n    if not psutil:\n        yield\n\n    else:\n        proc = psutil.Process()\n        flist = proc.open_files()\n        yield\n        flist2 = proc.open_files()\n        assert flist == flist2",
        "begin_line": 47,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.pytables.conftest.setup_mode#13",
        "src_path": "pandas/tests/io/pytables/conftest.py",
        "class_name": "pandas.tests.io.pytables.conftest",
        "signature": "pandas.tests.io.pytables.conftest.setup_mode()",
        "snippet": "def setup_mode():\n    \"\"\" Reset testing mode fixture\"\"\"\n    tm.reset_testing_mode()\n    yield\n    tm.set_testing_mode()",
        "begin_line": 13,
        "end_line": 17,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.conftest.salaries_table#23",
        "src_path": "pandas/tests/io/conftest.py",
        "class_name": "pandas.tests.io.conftest",
        "signature": "pandas.tests.io.conftest.salaries_table(datapath)",
        "snippet": "def salaries_table(datapath):\n    \"\"\"DataFrame with the salaries dataset\"\"\"\n    return read_csv(datapath(\"io\", \"parser\", \"data\", \"salaries.csv\"), sep=\"\\t\")",
        "begin_line": 23,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.current_pickle_data#37",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.current_pickle_data()",
        "snippet": "def current_pickle_data():\n    # our current version pickle data\n    from pandas.tests.io.generate_legacy_storage_files import create_pickle_data\n\n    return create_pickle_data()",
        "begin_line": 37,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.compare_element#47",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.compare_element(result, expected, typ, version=None)",
        "snippet": "def compare_element(result, expected, typ, version=None):\n    if isinstance(expected, Index):\n        tm.assert_index_equal(expected, result)\n        return\n\n    if typ.startswith(\"sp_\"):\n        comparator = tm.assert_equal\n        comparator(result, expected)\n    elif typ == \"timestamp\":\n        if expected is pd.NaT:\n            assert result is pd.NaT\n        else:\n            assert result == expected\n            assert result.freq == expected.freq\n    else:\n        comparator = getattr(\n            tm, \"assert_{typ}_equal\".format(typ=typ), tm.assert_almost_equal\n        )\n        comparator(result, expected)",
        "begin_line": 47,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.compare#68",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.compare(data, vf, version)",
        "snippet": "def compare(data, vf, version):\n\n    data = pd.read_pickle(vf)\n\n    m = globals()\n    for typ, dv in data.items():\n        for dt, result in dv.items():\n            expected = data[typ][dt]\n\n            # use a specific comparator\n            # if available\n            comparator = \"compare_{typ}_{dt}\".format(typ=typ, dt=dt)\n\n            comparator = m.get(comparator, m[\"compare_element\"])\n            comparator(result, expected, typ, version)\n    return data",
        "begin_line": 68,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.compare_series_ts#86",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.compare_series_ts(result, expected, typ, version)",
        "snippet": "def compare_series_ts(result, expected, typ, version):\n    # GH 7748\n    tm.assert_series_equal(result, expected)\n    assert result.index.freq == expected.index.freq\n    assert not result.index.freq.normalize\n    tm.assert_series_equal(result > 0, expected > 0)\n\n    # GH 9291\n    freq = result.index.freq\n    assert freq + Day(1) == Day(2)\n\n    res = freq + pd.Timedelta(hours=1)\n    assert isinstance(res, pd.Timedelta)\n    assert res == pd.Timedelta(days=1, hours=1)\n\n    res = freq + pd.Timedelta(nanoseconds=1)\n    assert isinstance(res, pd.Timedelta)\n    assert res == pd.Timedelta(days=1, nanoseconds=1)",
        "begin_line": 86,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.compare_series_dt_tz#106",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.compare_series_dt_tz(result, expected, typ, version)",
        "snippet": "def compare_series_dt_tz(result, expected, typ, version):\n    tm.assert_series_equal(result, expected)",
        "begin_line": 106,
        "end_line": 107,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.compare_series_cat#110",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.compare_series_cat(result, expected, typ, version)",
        "snippet": "def compare_series_cat(result, expected, typ, version):\n    tm.assert_series_equal(result, expected)",
        "begin_line": 110,
        "end_line": 111,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.compare_frame_dt_mixed_tzs#114",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.compare_frame_dt_mixed_tzs(result, expected, typ, version)",
        "snippet": "def compare_frame_dt_mixed_tzs(result, expected, typ, version):\n    tm.assert_frame_equal(result, expected)",
        "begin_line": 114,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.compare_frame_cat_onecol#118",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.compare_frame_cat_onecol(result, expected, typ, version)",
        "snippet": "def compare_frame_cat_onecol(result, expected, typ, version):\n    tm.assert_frame_equal(result, expected)",
        "begin_line": 118,
        "end_line": 119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.compare_frame_cat_and_float#122",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.compare_frame_cat_and_float(result, expected, typ, version)",
        "snippet": "def compare_frame_cat_and_float(result, expected, typ, version):\n    compare_frame_cat_onecol(result, expected, typ, version)",
        "begin_line": 122,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.compare_index_period#126",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.compare_index_period(result, expected, typ, version)",
        "snippet": "def compare_index_period(result, expected, typ, version):\n    tm.assert_index_equal(result, expected)\n    assert isinstance(result.freq, MonthEnd)\n    assert result.freq == MonthEnd()\n    assert result.freqstr == \"M\"\n    tm.assert_index_equal(result.shift(2), expected.shift(2))",
        "begin_line": 126,
        "end_line": 131,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.legacy_pickle#140",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.legacy_pickle(request, datapath)",
        "snippet": "def legacy_pickle(request, datapath):\n    return datapath(request.param)",
        "begin_line": 140,
        "end_line": 141,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.test_pickles#147",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.test_pickles(current_pickle_data, legacy_pickle)",
        "snippet": "def test_pickles(current_pickle_data, legacy_pickle):\n    if not is_platform_little_endian():\n        pytest.skip(\"known failure on non-little endian\")\n\n    version = os.path.basename(os.path.dirname(legacy_pickle))\n    with catch_warnings(record=True):\n        simplefilter(\"ignore\")\n        compare(current_pickle_data, legacy_pickle, version)",
        "begin_line": 147,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.test_round_trip_current#157",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.test_round_trip_current(current_pickle_data)",
        "snippet": "def test_round_trip_current(current_pickle_data):\n    def python_pickler(obj, path):\n        with open(path, \"wb\") as fh:\n            pickle.dump(obj, fh, protocol=-1)\n\n    def python_unpickler(path):\n        with open(path, \"rb\") as fh:\n            fh.seek(0)\n            return pickle.load(fh)\n\n    data = current_pickle_data\n    for typ, dv in data.items():\n        for dt, expected in dv.items():\n\n            for writer in [pd.to_pickle, python_pickler]:\n                if writer is None:\n                    continue\n\n                with tm.ensure_clean() as path:\n\n                    # test writing with each pickler\n                    writer(expected, path)\n\n                    # test reading with each unpickler\n                    result = pd.read_pickle(path)\n                    compare_element(result, expected, typ)\n\n                    result = python_unpickler(path)\n                    compare_element(result, expected, typ)",
        "begin_line": 157,
        "end_line": 185,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.python_pickler#158",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.python_pickler(obj, path)",
        "snippet": "    def python_pickler(obj, path):\n        with open(path, \"wb\") as fh:\n            pickle.dump(obj, fh, protocol=-1)",
        "begin_line": 158,
        "end_line": 160,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.python_unpickler#162",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.python_unpickler(path)",
        "snippet": "    def python_unpickler(path):\n        with open(path, \"rb\") as fh:\n            fh.seek(0)\n            return pickle.load(fh)",
        "begin_line": 162,
        "end_line": 165,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.test_pickle_path_pathlib#188",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.test_pickle_path_pathlib()",
        "snippet": "def test_pickle_path_pathlib():\n    df = tm.makeDataFrame()\n    result = tm.round_trip_pathlib(df.to_pickle, pd.read_pickle)\n    tm.assert_frame_equal(df, result)",
        "begin_line": 188,
        "end_line": 191,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.test_pickle_path_localpath#194",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.test_pickle_path_localpath()",
        "snippet": "def test_pickle_path_localpath():\n    df = tm.makeDataFrame()\n    result = tm.round_trip_localpath(df.to_pickle, pd.read_pickle)\n    tm.assert_frame_equal(df, result)",
        "begin_line": 194,
        "end_line": 197,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.test_legacy_sparse_warning#200",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.test_legacy_sparse_warning(datapath)",
        "snippet": "def test_legacy_sparse_warning(datapath):\n    \"\"\"\n\n    Generated with\n\n    >>> df = pd.DataFrame({\"A\": [1, 2, 3, 4], \"B\": [0, 0, 1, 1]}).to_sparse()\n    >>> df.to_pickle(\"pandas/tests/io/data/pickle/sparseframe-0.20.3.pickle.gz\",\n    ...              compression=\"gzip\")\n\n    >>> s = df['B']\n    >>> s.to_pickle(\"pandas/tests/io/data/pickle/sparseseries-0.20.3.pickle.gz\",\n    ...             compression=\"gzip\")\n    \"\"\"\n    with tm.assert_produces_warning(FutureWarning):\n        simplefilter(\"ignore\", DeprecationWarning)  # from boto\n        pd.read_pickle(\n            datapath(\"io\", \"data\", \"pickle\", \"sparseseries-0.20.3.pickle.gz\"),\n            compression=\"gzip\",\n        )\n\n    with tm.assert_produces_warning(FutureWarning):\n        simplefilter(\"ignore\", DeprecationWarning)  # from boto\n        pd.read_pickle(\n            datapath(\"io\", \"data\", \"pickle\", \"sparseframe-0.20.3.pickle.gz\"),\n            compression=\"gzip\",\n        )",
        "begin_line": 200,
        "end_line": 225,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.get_random_path#234",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.get_random_path()",
        "snippet": "def get_random_path():\n    return \"__{}__.pickle\".format(tm.rands(10))",
        "begin_line": 234,
        "end_line": 235,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.TestCompression.compress_file#248",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.TestCompression",
        "signature": "pandas.tests.io.test_pickle.TestCompression.compress_file(self, src_path, dest_path, compression)",
        "snippet": "    def compress_file(self, src_path, dest_path, compression):\n        if compression is None:\n            shutil.copyfile(src_path, dest_path)\n            return\n\n        if compression == \"gzip\":\n            f = gzip.open(dest_path, \"w\")\n        elif compression == \"bz2\":\n            f = bz2.BZ2File(dest_path, \"w\")\n        elif compression == \"zip\":\n            with zipfile.ZipFile(dest_path, \"w\", compression=zipfile.ZIP_DEFLATED) as f:\n                f.write(src_path, os.path.basename(src_path))\n        elif compression == \"xz\":\n            f = _get_lzma_file(lzma)(dest_path, \"w\")\n        else:\n            msg = \"Unrecognized compression type: {}\".format(compression)\n            raise ValueError(msg)\n\n        if compression != \"zip\":\n            with open(src_path, \"rb\") as fh, f:\n                f.write(fh.read())",
        "begin_line": 248,
        "end_line": 268,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.TestCompression.test_write_explicit#270",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.TestCompression",
        "signature": "pandas.tests.io.test_pickle.TestCompression.test_write_explicit(self, compression, get_random_path)",
        "snippet": "    def test_write_explicit(self, compression, get_random_path):\n        base = get_random_path\n        path1 = base + \".compressed\"\n        path2 = base + \".raw\"\n\n        with tm.ensure_clean(path1) as p1, tm.ensure_clean(path2) as p2:\n            df = tm.makeDataFrame()\n\n            # write to compressed file\n            df.to_pickle(p1, compression=compression)\n\n            # decompress\n            with tm.decompress_file(p1, compression=compression) as f:\n                with open(p2, \"wb\") as fh:\n                    fh.write(f.read())\n\n            # read decompressed file\n            df2 = pd.read_pickle(p2, compression=None)\n\n            tm.assert_frame_equal(df, df2)",
        "begin_line": 270,
        "end_line": 289,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.TestCompression.test_write_explicit_bad#292",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.TestCompression",
        "signature": "pandas.tests.io.test_pickle.TestCompression.test_write_explicit_bad(self, compression, get_random_path)",
        "snippet": "    def test_write_explicit_bad(self, compression, get_random_path):\n        with pytest.raises(ValueError, match=\"Unrecognized compression type\"):\n            with tm.ensure_clean(get_random_path) as path:\n                df = tm.makeDataFrame()\n                df.to_pickle(path, compression=compression)",
        "begin_line": 292,
        "end_line": 296,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.TestCompression.test_write_infer#299",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.TestCompression",
        "signature": "pandas.tests.io.test_pickle.TestCompression.test_write_infer(self, ext, get_random_path)",
        "snippet": "    def test_write_infer(self, ext, get_random_path):\n        base = get_random_path\n        path1 = base + ext\n        path2 = base + \".raw\"\n        compression = None\n        for c in self._compression_to_extension:\n            if self._compression_to_extension[c] == ext:\n                compression = c\n                break\n\n        with tm.ensure_clean(path1) as p1, tm.ensure_clean(path2) as p2:\n            df = tm.makeDataFrame()\n\n            # write to compressed file by inferred compression method\n            df.to_pickle(p1)\n\n            # decompress\n            with tm.decompress_file(p1, compression=compression) as f:\n                with open(p2, \"wb\") as fh:\n                    fh.write(f.read())\n\n            # read decompressed file\n            df2 = pd.read_pickle(p2, compression=None)\n\n            tm.assert_frame_equal(df, df2)",
        "begin_line": 299,
        "end_line": 323,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.TestCompression.test_read_explicit#325",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.TestCompression",
        "signature": "pandas.tests.io.test_pickle.TestCompression.test_read_explicit(self, compression, get_random_path)",
        "snippet": "    def test_read_explicit(self, compression, get_random_path):\n        base = get_random_path\n        path1 = base + \".raw\"\n        path2 = base + \".compressed\"\n\n        with tm.ensure_clean(path1) as p1, tm.ensure_clean(path2) as p2:\n            df = tm.makeDataFrame()\n\n            # write to uncompressed file\n            df.to_pickle(p1, compression=None)\n\n            # compress\n            self.compress_file(p1, p2, compression=compression)\n\n            # read compressed file\n            df2 = pd.read_pickle(p2, compression=compression)\n\n            tm.assert_frame_equal(df, df2)",
        "begin_line": 325,
        "end_line": 342,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.TestCompression.test_read_infer#345",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.TestCompression",
        "signature": "pandas.tests.io.test_pickle.TestCompression.test_read_infer(self, ext, get_random_path)",
        "snippet": "    def test_read_infer(self, ext, get_random_path):\n        base = get_random_path\n        path1 = base + \".raw\"\n        path2 = base + ext\n        compression = None\n        for c in self._compression_to_extension:\n            if self._compression_to_extension[c] == ext:\n                compression = c\n                break\n\n        with tm.ensure_clean(path1) as p1, tm.ensure_clean(path2) as p2:\n            df = tm.makeDataFrame()\n\n            # write to uncompressed file\n            df.to_pickle(p1, compression=None)\n\n            # compress\n            self.compress_file(p1, p2, compression=compression)\n\n            # read compressed file by inferred compression method\n            df2 = pd.read_pickle(p2)\n\n            tm.assert_frame_equal(df, df2)",
        "begin_line": 345,
        "end_line": 367,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.TestProtocol.test_read#377",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.TestProtocol",
        "signature": "pandas.tests.io.test_pickle.TestProtocol.test_read(self, protocol, get_random_path)",
        "snippet": "    def test_read(self, protocol, get_random_path):\n        with tm.ensure_clean(get_random_path) as path:\n            df = tm.makeDataFrame()\n            df.to_pickle(path, protocol=protocol)\n            df2 = pd.read_pickle(path)\n            tm.assert_frame_equal(df, df2)",
        "begin_line": 377,
        "end_line": 382,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.test_unicode_decode_error#385",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.test_unicode_decode_error(datapath)",
        "snippet": "def test_unicode_decode_error(datapath):\n    # pickle file written with py27, should be readable without raising\n    #  UnicodeDecodeError, see GH#28645\n    path = datapath(\"io\", \"data\", \"pickle\", \"test_py27.pkl\")\n    df = pd.read_pickle(path)\n\n    # just test the columns are correct since the values are random\n    excols = pd.Index([\"a\", \"b\", \"c\"])\n    tm.assert_index_equal(df.columns, excols)",
        "begin_line": 385,
        "end_line": 393,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.test_pickle_buffer_roundtrip#401",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.test_pickle_buffer_roundtrip()",
        "snippet": "def test_pickle_buffer_roundtrip():\n    with tm.ensure_clean() as path:\n        df = tm.makeDataFrame()\n        with open(path, \"wb\") as fh:\n            df.to_pickle(fh)\n        with open(path, \"rb\") as fh:\n            result = pd.read_pickle(fh)\n        tm.assert_frame_equal(df, result)",
        "begin_line": 401,
        "end_line": 408,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.test_pickle_generalurl_read#419",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.test_pickle_generalurl_read(monkeypatch, mockurl)",
        "snippet": "def test_pickle_generalurl_read(monkeypatch, mockurl):\n    def python_pickler(obj, path):\n        with open(path, \"wb\") as fh:\n            pickle.dump(obj, fh, protocol=-1)\n\n    class MockReadResponse:\n        def __init__(self, path):\n            self.file = open(path, \"rb\")\n            if \"gzip\" in path:\n                self.headers = {\"Content-Encoding\": \"gzip\"}\n            else:\n                self.headers = {\"Content-Encoding\": None}\n\n        def read(self):\n            return self.file.read()\n\n        def close(self):\n            return self.file.close()\n\n    with tm.ensure_clean() as path:\n\n        def mock_urlopen_read(*args, **kwargs):\n            return MockReadResponse(path)\n\n        df = tm.makeDataFrame()\n        python_pickler(df, path)\n        monkeypatch.setattr(\"urllib.request.urlopen\", mock_urlopen_read)\n        result = pd.read_pickle(mockurl)\n        tm.assert_frame_equal(df, result)",
        "begin_line": 419,
        "end_line": 447,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.python_pickler#420",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.python_pickler(obj, path)",
        "snippet": "    def python_pickler(obj, path):\n        with open(path, \"wb\") as fh:\n            pickle.dump(obj, fh, protocol=-1)",
        "begin_line": 420,
        "end_line": 422,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.MockReadResponse.test_pickle_generalurl_read#419",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.MockReadResponse",
        "signature": "pandas.tests.io.test_pickle.MockReadResponse.test_pickle_generalurl_read(monkeypatch, mockurl)",
        "snippet": "def test_pickle_generalurl_read(monkeypatch, mockurl):\n    def python_pickler(obj, path):\n        with open(path, \"wb\") as fh:\n            pickle.dump(obj, fh, protocol=-1)\n\n    class MockReadResponse:\n        def __init__(self, path):\n            self.file = open(path, \"rb\")\n            if \"gzip\" in path:\n                self.headers = {\"Content-Encoding\": \"gzip\"}\n            else:\n                self.headers = {\"Content-Encoding\": None}\n\n        def read(self):\n            return self.file.read()\n\n        def close(self):\n            return self.file.close()\n\n    with tm.ensure_clean() as path:\n\n        def mock_urlopen_read(*args, **kwargs):\n            return MockReadResponse(path)\n\n        df = tm.makeDataFrame()\n        python_pickler(df, path)\n        monkeypatch.setattr(\"urllib.request.urlopen\", mock_urlopen_read)\n        result = pd.read_pickle(mockurl)\n        tm.assert_frame_equal(df, result)",
        "begin_line": 419,
        "end_line": 447,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.MockReadResponse.__init__#425",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.MockReadResponse",
        "signature": "pandas.tests.io.test_pickle.MockReadResponse.__init__(self, path)",
        "snippet": "        def __init__(self, path):\n            self.file = open(path, \"rb\")\n            if \"gzip\" in path:\n                self.headers = {\"Content-Encoding\": \"gzip\"}\n            else:\n                self.headers = {\"Content-Encoding\": None}",
        "begin_line": 425,
        "end_line": 430,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.MockReadResponse.read#432",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.MockReadResponse",
        "signature": "pandas.tests.io.test_pickle.MockReadResponse.read(self)",
        "snippet": "        def read(self):\n            return self.file.read()",
        "begin_line": 432,
        "end_line": 433,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.MockReadResponse.close#435",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.MockReadResponse",
        "signature": "pandas.tests.io.test_pickle.MockReadResponse.close(self)",
        "snippet": "        def close(self):\n            return self.file.close()",
        "begin_line": 435,
        "end_line": 436,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.mock_urlopen_read#440",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.mock_urlopen_read(*args, **kwargs)",
        "snippet": "        def mock_urlopen_read(*args, **kwargs):\n            return MockReadResponse(path)",
        "begin_line": 440,
        "end_line": 441,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.test_pickle_gcsurl_roundtrip#452",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.test_pickle_gcsurl_roundtrip(monkeypatch, mockurl)",
        "snippet": "def test_pickle_gcsurl_roundtrip(monkeypatch, mockurl):\n    with tm.ensure_clean() as path:\n\n        class MockGCSFileSystem:\n            def __init__(self, *args, **kwargs):\n                pass\n\n            def open(self, *args):\n                mode = args[1] or None\n                f = open(path, mode)\n                return f\n\n        monkeypatch.setattr(\"gcsfs.GCSFileSystem\", MockGCSFileSystem)\n        df = tm.makeDataFrame()\n        df.to_pickle(mockurl)\n        result = pd.read_pickle(mockurl)\n        tm.assert_frame_equal(df, result)",
        "begin_line": 452,
        "end_line": 468,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.MockGCSFileSystem.test_pickle_gcsurl_roundtrip#452",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.MockGCSFileSystem",
        "signature": "pandas.tests.io.test_pickle.MockGCSFileSystem.test_pickle_gcsurl_roundtrip(monkeypatch, mockurl)",
        "snippet": "def test_pickle_gcsurl_roundtrip(monkeypatch, mockurl):\n    with tm.ensure_clean() as path:\n\n        class MockGCSFileSystem:\n            def __init__(self, *args, **kwargs):\n                pass\n\n            def open(self, *args):\n                mode = args[1] or None\n                f = open(path, mode)\n                return f\n\n        monkeypatch.setattr(\"gcsfs.GCSFileSystem\", MockGCSFileSystem)\n        df = tm.makeDataFrame()\n        df.to_pickle(mockurl)\n        result = pd.read_pickle(mockurl)\n        tm.assert_frame_equal(df, result)",
        "begin_line": 452,
        "end_line": 468,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.MockGCSFileSystem.__init__#456",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.MockGCSFileSystem",
        "signature": "pandas.tests.io.test_pickle.MockGCSFileSystem.__init__(self, *args, **kwargs)",
        "snippet": "            def __init__(self, *args, **kwargs):\n                pass",
        "begin_line": 456,
        "end_line": 457,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.MockGCSFileSystem.open#459",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.MockGCSFileSystem",
        "signature": "pandas.tests.io.test_pickle.MockGCSFileSystem.open(self, *args)",
        "snippet": "            def open(self, *args):\n                mode = args[1] or None\n                f = open(path, mode)\n                return f",
        "begin_line": 459,
        "end_line": 462,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.test_pickle_s3url_roundtrip#473",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle",
        "signature": "pandas.tests.io.test_pickle.test_pickle_s3url_roundtrip(monkeypatch, mockurl)",
        "snippet": "def test_pickle_s3url_roundtrip(monkeypatch, mockurl):\n    with tm.ensure_clean() as path:\n\n        class MockS3FileSystem:\n            def __init__(self, *args, **kwargs):\n                pass\n\n            def open(self, *args):\n                mode = args[1] or None\n                f = open(path, mode)\n                return f\n\n        monkeypatch.setattr(\"s3fs.S3FileSystem\", MockS3FileSystem)\n        df = tm.makeDataFrame()\n        df.to_pickle(mockurl)\n        result = pd.read_pickle(mockurl)\n        tm.assert_frame_equal(df, result)",
        "begin_line": 473,
        "end_line": 489,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.MockS3FileSystem.test_pickle_s3url_roundtrip#473",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.MockS3FileSystem",
        "signature": "pandas.tests.io.test_pickle.MockS3FileSystem.test_pickle_s3url_roundtrip(monkeypatch, mockurl)",
        "snippet": "def test_pickle_s3url_roundtrip(monkeypatch, mockurl):\n    with tm.ensure_clean() as path:\n\n        class MockS3FileSystem:\n            def __init__(self, *args, **kwargs):\n                pass\n\n            def open(self, *args):\n                mode = args[1] or None\n                f = open(path, mode)\n                return f\n\n        monkeypatch.setattr(\"s3fs.S3FileSystem\", MockS3FileSystem)\n        df = tm.makeDataFrame()\n        df.to_pickle(mockurl)\n        result = pd.read_pickle(mockurl)\n        tm.assert_frame_equal(df, result)",
        "begin_line": 473,
        "end_line": 489,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.MockS3FileSystem.__init__#477",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.MockS3FileSystem",
        "signature": "pandas.tests.io.test_pickle.MockS3FileSystem.__init__(self, *args, **kwargs)",
        "snippet": "            def __init__(self, *args, **kwargs):\n                pass",
        "begin_line": 477,
        "end_line": 478,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_pickle.MockS3FileSystem.open#480",
        "src_path": "pandas/tests/io/test_pickle.py",
        "class_name": "pandas.tests.io.test_pickle.MockS3FileSystem",
        "signature": "pandas.tests.io.test_pickle.MockS3FileSystem.open(self, *args)",
        "snippet": "            def open(self, *args):\n                mode = args[1] or None\n                f = open(path, mode)\n                return f",
        "begin_line": 480,
        "end_line": 483,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.update_kwargs#14",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.update_kwargs(self, kwargs)",
        "snippet": "    def update_kwargs(self, kwargs):\n        kwargs = kwargs.copy()\n        kwargs.update(dict(engine=self.engine, low_memory=self.low_memory))\n\n        return kwargs",
        "begin_line": 14,
        "end_line": 18,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.read_csv#20",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.read_csv(self, *args, **kwargs)",
        "snippet": "    def read_csv(self, *args, **kwargs):\n        kwargs = self.update_kwargs(kwargs)\n        return read_csv(*args, **kwargs)",
        "begin_line": 20,
        "end_line": 22,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.read_table#24",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.read_table(self, *args, **kwargs)",
        "snippet": "    def read_table(self, *args, **kwargs):\n        kwargs = self.update_kwargs(kwargs)\n        return read_table(*args, **kwargs)",
        "begin_line": 24,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.csv_dir_path#48",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.csv_dir_path(datapath)",
        "snippet": "def csv_dir_path(datapath):\n    \"\"\"\n    The directory path to the data files needed for parser tests.\n    \"\"\"\n    return datapath(\"io\", \"parser\", \"data\")",
        "begin_line": 48,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.csv1#56",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.csv1(csv_dir_path)",
        "snippet": "def csv1(csv_dir_path):\n    \"\"\"\n    The path to the data file \"test1.csv\" needed for parser tests.\n    \"\"\"\n    return os.path.join(csv_dir_path, \"test1.csv\")",
        "begin_line": 56,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.all_parsers#77",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.all_parsers(request)",
        "snippet": "def all_parsers(request):\n    \"\"\"\n    Fixture all of the CSV parsers.\n    \"\"\"\n    return request.param",
        "begin_line": 77,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.c_parser_only#85",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.c_parser_only(request)",
        "snippet": "def c_parser_only(request):\n    \"\"\"\n    Fixture all of the CSV parsers using the C engine.\n    \"\"\"\n    return request.param",
        "begin_line": 85,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.python_parser_only#93",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.python_parser_only(request)",
        "snippet": "def python_parser_only(request):\n    \"\"\"\n    Fixture all of the CSV parsers using the Python engine.\n    \"\"\"\n    return request.param",
        "begin_line": 93,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.utf_value#111",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.utf_value(request)",
        "snippet": "def utf_value(request):\n    \"\"\"\n    Fixture for all possible integer values for a UTF encoding.\n    \"\"\"\n    return request.param",
        "begin_line": 111,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.encoding_fmt#119",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.encoding_fmt(request)",
        "snippet": "def encoding_fmt(request):\n    \"\"\"\n    Fixture for all possible string formats of a UTF encoding.\n    \"\"\"\n    return request.param",
        "begin_line": 119,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.conftest.orient#5",
        "src_path": "pandas/tests/io/json/conftest.py",
        "class_name": "pandas.tests.io.json.conftest",
        "signature": "pandas.tests.io.json.conftest.orient(request)",
        "snippet": "def orient(request):\n    \"\"\"\n    Fixture for orients excluding the table format.\n    \"\"\"\n    return request.param",
        "begin_line": 5,
        "end_line": 9,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_series#96",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_series()",
        "snippet": "def _create_sp_series():\n    nan = np.nan\n\n    # nan-based\n    arr = np.arange(15, dtype=np.float64)\n    arr[7:12] = nan\n    arr[-1:] = nan\n\n    bseries = Series(SparseArray(arr, kind=\"block\"))\n    bseries.name = \"bseries\"\n    return bseries",
        "begin_line": 96,
        "end_line": 106,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_tsseries#109",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_tsseries()",
        "snippet": "def _create_sp_tsseries():\n    nan = np.nan\n\n    # nan-based\n    arr = np.arange(15, dtype=np.float64)\n    arr[7:12] = nan\n    arr[-1:] = nan\n\n    date_index = bdate_range(\"1/1/2011\", periods=len(arr))\n    bseries = Series(SparseArray(arr, kind=\"block\"), index=date_index)\n    bseries.name = \"btsseries\"\n    return bseries",
        "begin_line": 109,
        "end_line": 120,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_frame#123",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_frame()",
        "snippet": "def _create_sp_frame():\n    nan = np.nan\n\n    data = {\n        \"A\": [nan, nan, nan, 0, 1, 2, 3, 4, 5, 6],\n        \"B\": [0, 1, 2, nan, nan, nan, 3, 4, 5, 6],\n        \"C\": np.arange(10).astype(np.int64),\n        \"D\": [0, 1, 2, 3, 4, 5, nan, nan, nan, nan],\n    }\n\n    dates = bdate_range(\"1/1/2011\", periods=10)\n    return DataFrame(data, index=dates).apply(SparseArray)",
        "begin_line": 123,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.create_data#137",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.create_data()",
        "snippet": "def create_data():\n    \"\"\" create the pickle data \"\"\"\n\n    data = {\n        \"A\": [0.0, 1.0, 2.0, 3.0, np.nan],\n        \"B\": [0, 1, 0, 1, 0],\n        \"C\": [\"foo1\", \"foo2\", \"foo3\", \"foo4\", \"foo5\"],\n        \"D\": date_range(\"1/1/2009\", periods=5),\n        \"E\": [0.0, 1, Timestamp(\"20100101\"), \"foo\", 2.0],\n    }\n\n    scalars = dict(timestamp=Timestamp(\"20130101\"), period=Period(\"2012\", \"M\"))\n\n    index = dict(\n        int=Index(np.arange(10)),\n        date=date_range(\"20130101\", periods=10),\n        period=period_range(\"2013-01-01\", freq=\"M\", periods=10),\n        float=Index(np.arange(10, dtype=np.float64)),\n        uint=Index(np.arange(10, dtype=np.uint64)),\n        timedelta=timedelta_range(\"00:00:00\", freq=\"30T\", periods=10),\n    )\n\n    index[\"range\"] = RangeIndex(10)\n\n    if _loose_version >= LooseVersion(\"0.21\"):\n        from pandas import interval_range\n\n        index[\"interval\"] = interval_range(0, periods=10)\n\n    mi = dict(\n        reg2=MultiIndex.from_tuples(\n            tuple(\n                zip(\n                    *[\n                        [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n                        [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n                    ]\n                )\n            ),\n            names=[\"first\", \"second\"],\n        )\n    )\n\n    series = dict(\n        float=Series(data[\"A\"]),\n        int=Series(data[\"B\"]),\n        mixed=Series(data[\"E\"]),\n        ts=Series(\n            np.arange(10).astype(np.int64), index=date_range(\"20130101\", periods=10)\n        ),\n        mi=Series(\n            np.arange(5).astype(np.float64),\n            index=MultiIndex.from_tuples(\n                tuple(zip(*[[1, 1, 2, 2, 2], [3, 4, 3, 4, 5]])), names=[\"one\", \"two\"]\n            ),\n        ),\n        dup=Series(np.arange(5).astype(np.float64), index=[\"A\", \"B\", \"C\", \"D\", \"A\"]),\n        cat=Series(Categorical([\"foo\", \"bar\", \"baz\"])),\n        dt=Series(date_range(\"20130101\", periods=5)),\n        dt_tz=Series(date_range(\"20130101\", periods=5, tz=\"US/Eastern\")),\n        period=Series([Period(\"2000Q1\")] * 5),\n    )\n\n    mixed_dup_df = DataFrame(data)\n    mixed_dup_df.columns = list(\"ABCDA\")\n    frame = dict(\n        float=DataFrame({\"A\": series[\"float\"], \"B\": series[\"float\"] + 1}),\n        int=DataFrame({\"A\": series[\"int\"], \"B\": series[\"int\"] + 1}),\n        mixed=DataFrame({k: data[k] for k in [\"A\", \"B\", \"C\", \"D\"]}),\n        mi=DataFrame(\n            {\"A\": np.arange(5).astype(np.float64), \"B\": np.arange(5).astype(np.int64)},\n            index=MultiIndex.from_tuples(\n                tuple(\n                    zip(\n                        *[\n                            [\"bar\", \"bar\", \"baz\", \"baz\", \"baz\"],\n                            [\"one\", \"two\", \"one\", \"two\", \"three\"],\n                        ]\n                    )\n                ),\n                names=[\"first\", \"second\"],\n            ),\n        ),\n        dup=DataFrame(\n            np.arange(15).reshape(5, 3).astype(np.float64), columns=[\"A\", \"B\", \"A\"]\n        ),\n        cat_onecol=DataFrame({\"A\": Categorical([\"foo\", \"bar\"])}),\n        cat_and_float=DataFrame(\n            {\n                \"A\": Categorical([\"foo\", \"bar\", \"baz\"]),\n                \"B\": np.arange(3).astype(np.int64),\n            }\n        ),\n        mixed_dup=mixed_dup_df,\n        dt_mixed_tzs=DataFrame(\n            {\n                \"A\": Timestamp(\"20130102\", tz=\"US/Eastern\"),\n                \"B\": Timestamp(\"20130603\", tz=\"CET\"),\n            },\n            index=range(5),\n        ),\n        dt_mixed2_tzs=DataFrame(\n            {\n                \"A\": Timestamp(\"20130102\", tz=\"US/Eastern\"),\n                \"B\": Timestamp(\"20130603\", tz=\"CET\"),\n                \"C\": Timestamp(\"20130603\", tz=\"UTC\"),\n            },\n            index=range(5),\n        ),\n    )\n\n    cat = dict(\n        int8=Categorical(list(\"abcdefg\")),\n        int16=Categorical(np.arange(1000)),\n        int32=Categorical(np.arange(10000)),\n    )\n\n    timestamp = dict(\n        normal=Timestamp(\"2011-01-01\"),\n        nat=NaT,\n        tz=Timestamp(\"2011-01-01\", tz=\"US/Eastern\"),\n    )\n\n    timestamp[\"freq\"] = Timestamp(\"2011-01-01\", freq=\"D\")\n    timestamp[\"both\"] = Timestamp(\"2011-01-01\", tz=\"Asia/Tokyo\", freq=\"M\")\n\n    off = {\n        \"DateOffset\": DateOffset(years=1),\n        \"DateOffset_h_ns\": DateOffset(hour=6, nanoseconds=5824),\n        \"BusinessDay\": BusinessDay(offset=timedelta(seconds=9)),\n        \"BusinessHour\": BusinessHour(normalize=True, n=6, end=\"15:14\"),\n        \"CustomBusinessDay\": CustomBusinessDay(weekmask=\"Mon Fri\"),\n        \"SemiMonthBegin\": SemiMonthBegin(day_of_month=9),\n        \"SemiMonthEnd\": SemiMonthEnd(day_of_month=24),\n        \"MonthBegin\": MonthBegin(1),\n        \"MonthEnd\": MonthEnd(1),\n        \"QuarterBegin\": QuarterBegin(1),\n        \"QuarterEnd\": QuarterEnd(1),\n        \"Day\": Day(1),\n        \"YearBegin\": YearBegin(1),\n        \"YearEnd\": YearEnd(1),\n        \"Week\": Week(1),\n        \"Week_Tues\": Week(2, normalize=False, weekday=1),\n        \"WeekOfMonth\": WeekOfMonth(week=3, weekday=4),\n        \"LastWeekOfMonth\": LastWeekOfMonth(n=1, weekday=3),\n        \"FY5253\": FY5253(n=2, weekday=6, startingMonth=7, variation=\"last\"),\n        \"Easter\": Easter(),\n        \"Hour\": Hour(1),\n        \"Minute\": Minute(1),\n    }\n\n    return dict(\n        series=series,\n        frame=frame,\n        index=index,\n        scalars=scalars,\n        mi=mi,\n        sp_series=dict(float=_create_sp_series(), ts=_create_sp_tsseries()),\n        sp_frame=dict(float=_create_sp_frame()),\n        cat=cat,\n        timestamp=timestamp,\n        offsets=off,\n    )",
        "begin_line": 137,
        "end_line": 299,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.create_pickle_data#302",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.create_pickle_data()",
        "snippet": "def create_pickle_data():\n    data = create_data()\n\n    return data",
        "begin_line": 302,
        "end_line": 305,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.platform_name#308",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.platform_name()",
        "snippet": "def platform_name():\n    return \"_\".join(\n        [\n            str(pandas.__version__),\n            str(pl.machine()),\n            str(pl.system().lower()),\n            str(pl.python_version()),\n        ]\n    )",
        "begin_line": 308,
        "end_line": 316,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.write_legacy_pickles#319",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.write_legacy_pickles(output_dir)",
        "snippet": "def write_legacy_pickles(output_dir):\n\n    version = pandas.__version__\n\n    print(\n        \"This script generates a storage file for the current arch, system, \"\n        \"and python version\"\n    )\n    print(\"  pandas version: {0}\".format(version))\n    print(\"  output dir    : {0}\".format(output_dir))\n    print(\"  storage format: pickle\")\n\n    pth = \"{0}.pickle\".format(platform_name())\n\n    fh = open(os.path.join(output_dir, pth), \"wb\")\n    pickle.dump(create_pickle_data(), fh, pickle.HIGHEST_PROTOCOL)\n    fh.close()\n\n    print(\"created pickle file: {pth}\".format(pth=pth))",
        "begin_line": 319,
        "end_line": 337,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.write_legacy_file#340",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.write_legacy_file()",
        "snippet": "def write_legacy_file():\n    # force our cwd to be the first searched\n    sys.path.insert(0, \".\")\n\n    if not (3 <= len(sys.argv) <= 4):\n        exit(\n            \"Specify output directory and storage type: generate_legacy_\"\n            \"storage_files.py <output_dir> <storage_type> \"\n        )\n\n    output_dir = str(sys.argv[1])\n    storage_type = str(sys.argv[2])\n\n    if storage_type == \"pickle\":\n        write_legacy_pickles(output_dir=output_dir)\n    else:\n        exit(\"storage_type must be one of {'pickle'}\")",
        "begin_line": 340,
        "end_line": 356,
        "comment": "",
        "is_bug": false
    }
]