[
    {
        "name": "spacy.tests.conftest.pytest_runtest_setup#12",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pytest_runtest_setup(item)",
        "snippet": "def pytest_runtest_setup(item):\n    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)\n\n    for opt in [\"slow\"]:\n        if opt in item.keywords and not getopt(opt):\n            pytest.skip(\"need --%s option to run\" % opt)",
        "begin_line": 12,
        "end_line": 24,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.getopt#13",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.getopt(opt)",
        "snippet": "    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)",
        "begin_line": 13,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tokenizer#31",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tokenizer()",
        "snippet": "def tokenizer():\n    return get_lang_class(\"xx\").Defaults.create_tokenizer()",
        "begin_line": 31,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ar_tokenizer#36",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ar_tokenizer()",
        "snippet": "def ar_tokenizer():\n    return get_lang_class(\"ar\").Defaults.create_tokenizer()",
        "begin_line": 36,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.bn_tokenizer#41",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.bn_tokenizer()",
        "snippet": "def bn_tokenizer():\n    return get_lang_class(\"bn\").Defaults.create_tokenizer()",
        "begin_line": 41,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ca_tokenizer#46",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ca_tokenizer()",
        "snippet": "def ca_tokenizer():\n    return get_lang_class(\"ca\").Defaults.create_tokenizer()",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.da_tokenizer#51",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.da_tokenizer()",
        "snippet": "def da_tokenizer():\n    return get_lang_class(\"da\").Defaults.create_tokenizer()",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.de_tokenizer#56",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.de_tokenizer()",
        "snippet": "def de_tokenizer():\n    return get_lang_class(\"de\").Defaults.create_tokenizer()",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.el_tokenizer#61",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.el_tokenizer()",
        "snippet": "def el_tokenizer():\n    return get_lang_class(\"el\").Defaults.create_tokenizer()",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_tokenizer#66",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_tokenizer()",
        "snippet": "def en_tokenizer():\n    return get_lang_class(\"en\").Defaults.create_tokenizer()",
        "begin_line": 66,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_vocab#71",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_vocab()",
        "snippet": "def en_vocab():\n    return get_lang_class(\"en\").Defaults.create_vocab()",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.es_tokenizer#82",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.es_tokenizer()",
        "snippet": "def es_tokenizer():\n    return get_lang_class(\"es\").Defaults.create_tokenizer()",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fi_tokenizer#87",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fi_tokenizer()",
        "snippet": "def fi_tokenizer():\n    return get_lang_class(\"fi\").Defaults.create_tokenizer()",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fr_tokenizer#92",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fr_tokenizer()",
        "snippet": "def fr_tokenizer():\n    return get_lang_class(\"fr\").Defaults.create_tokenizer()",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ga_tokenizer#97",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ga_tokenizer()",
        "snippet": "def ga_tokenizer():\n    return get_lang_class(\"ga\").Defaults.create_tokenizer()",
        "begin_line": 97,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.he_tokenizer#102",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.he_tokenizer()",
        "snippet": "def he_tokenizer():\n    return get_lang_class(\"he\").Defaults.create_tokenizer()",
        "begin_line": 102,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.hu_tokenizer#112",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.hu_tokenizer()",
        "snippet": "def hu_tokenizer():\n    return get_lang_class(\"hu\").Defaults.create_tokenizer()",
        "begin_line": 112,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.id_tokenizer#117",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.id_tokenizer()",
        "snippet": "def id_tokenizer():\n    return get_lang_class(\"id\").Defaults.create_tokenizer()",
        "begin_line": 117,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.it_tokenizer#122",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.it_tokenizer()",
        "snippet": "def it_tokenizer():\n    return get_lang_class(\"it\").Defaults.create_tokenizer()",
        "begin_line": 122,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.lt_tokenizer#139",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.lt_tokenizer()",
        "snippet": "def lt_tokenizer():\n    return get_lang_class(\"lt\").Defaults.create_tokenizer()",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nb_tokenizer#144",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nb_tokenizer()",
        "snippet": "def nb_tokenizer():\n    return get_lang_class(\"nb\").Defaults.create_tokenizer()",
        "begin_line": 144,
        "end_line": 145,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nl_tokenizer#149",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nl_tokenizer()",
        "snippet": "def nl_tokenizer():\n    return get_lang_class(\"nl\").Defaults.create_tokenizer()",
        "begin_line": 149,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.pl_tokenizer#154",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pl_tokenizer()",
        "snippet": "def pl_tokenizer():\n    return get_lang_class(\"pl\").Defaults.create_tokenizer()",
        "begin_line": 154,
        "end_line": 155,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ro_tokenizer#164",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ro_tokenizer()",
        "snippet": "def ro_tokenizer():\n    return get_lang_class(\"ro\").Defaults.create_tokenizer()",
        "begin_line": 164,
        "end_line": 165,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sr_tokenizer#181",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sr_tokenizer()",
        "snippet": "def sr_tokenizer():\n    return get_lang_class(\"sr\").Defaults.create_tokenizer()",
        "begin_line": 181,
        "end_line": 182,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sv_tokenizer#186",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sv_tokenizer()",
        "snippet": "def sv_tokenizer():\n    return get_lang_class(\"sv\").Defaults.create_tokenizer()",
        "begin_line": 186,
        "end_line": 187,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tt_tokenizer#202",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tt_tokenizer()",
        "snippet": "def tt_tokenizer():\n    return get_lang_class(\"tt\").Defaults.create_tokenizer()",
        "begin_line": 202,
        "end_line": 203,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ur_tokenizer#214",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ur_tokenizer()",
        "snippet": "def ur_tokenizer():\n    return get_lang_class(\"ur\").Defaults.create_tokenizer()",
        "begin_line": 214,
        "end_line": 215,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.doc#15",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.doc(en_tokenizer)",
        "snippet": "def doc(en_tokenizer):\n    # fmt: off\n    text = \"This is a sentence. This is another sentence. And a third.\"\n    heads = [1, 0, 1, -2, -3, 1, 0, 1, -2, -3, 0, 1, -2, -1]\n    deps = [\"nsubj\", \"ROOT\", \"det\", \"attr\", \"punct\", \"nsubj\", \"ROOT\", \"det\",\n            \"attr\", \"punct\", \"ROOT\", \"det\", \"npadvmod\", \"punct\"]\n    # fmt: on\n    tokens = en_tokenizer(text)\n    return get_doc(tokens.vocab, words=[t.text for t in tokens], heads=heads, deps=deps)",
        "begin_line": 15,
        "end_line": 23,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.doc_not_parsed#27",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.doc_not_parsed(en_tokenizer)",
        "snippet": "def doc_not_parsed(en_tokenizer):\n    text = \"This is a sentence. This is another sentence. And a third.\"\n    tokens = en_tokenizer(text)\n    doc = Doc(tokens.vocab, words=[t.text for t in tokens])\n    doc.is_parsed = False\n    return doc",
        "begin_line": 27,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_spans_sent_spans#35",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_spans_sent_spans(doc)",
        "snippet": "def test_spans_sent_spans(doc):\n    sents = list(doc.sents)\n    assert sents[0].start == 0\n    assert sents[0].end == 5\n    assert len(sents) == 3\n    assert sum(len(sent) for sent in sents) == len(doc)",
        "begin_line": 35,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_spans_root#43",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_spans_root(doc)",
        "snippet": "def test_spans_root(doc):\n    span = doc[2:4]\n    assert len(span) == 2\n    assert span.text == \"a sentence\"\n    assert span.root.text == \"sentence\"\n    assert span.root.head.text == \"is\"",
        "begin_line": 43,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_spans_string_fn#51",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_spans_string_fn(doc)",
        "snippet": "def test_spans_string_fn(doc):\n    span = doc[0:4]\n    assert len(span) == 4\n    assert span.text == \"This is a sentence\"\n    assert span.upper_ == \"THIS IS A SENTENCE\"\n    assert span.lower_ == \"this is a sentence\"",
        "begin_line": 51,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_spans_root2#59",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_spans_root2(en_tokenizer)",
        "snippet": "def test_spans_root2(en_tokenizer):\n    text = \"through North and South Carolina\"\n    heads = [0, 3, -1, -2, -4]\n    tokens = en_tokenizer(text)\n    doc = get_doc(tokens.vocab, words=[t.text for t in tokens], heads=heads)\n    assert doc[-2:].root.text == \"Carolina\"",
        "begin_line": 59,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_spans_span_sent#67",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_spans_span_sent(doc, doc_not_parsed)",
        "snippet": "def test_spans_span_sent(doc, doc_not_parsed):\n    \"\"\"Test span.sent property\"\"\"\n    assert len(list(doc.sents))\n    assert doc[:2].sent.root.text == \"is\"\n    assert doc[:2].sent.text == \"This is a sentence .\"\n    assert doc[6:7].sent.root.left_edge.text == \"This\"\n    # test on manual sbd\n    doc_not_parsed[0].is_sent_start = True\n    doc_not_parsed[5].is_sent_start = True\n    assert doc_not_parsed[1:3].sent == doc_not_parsed[0:5]\n    assert doc_not_parsed[10:14].sent == doc_not_parsed[5:]",
        "begin_line": 67,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_spans_lca_matrix#80",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_spans_lca_matrix(en_tokenizer)",
        "snippet": "def test_spans_lca_matrix(en_tokenizer):\n    \"\"\"Test span's lca matrix generation\"\"\"\n    tokens = en_tokenizer(\"the lazy dog slept\")\n    doc = get_doc(tokens.vocab, words=[t.text for t in tokens], heads=[2, 1, 1, 0])\n    lca = doc[:2].get_lca_matrix()\n    assert lca.shape == (2, 2)\n    assert lca[0, 0] == 0  # the & the -> the\n    assert lca[0, 1] == -1  # the & lazy -> dog (out of span)\n    assert lca[1, 0] == -1  # lazy & the -> dog (out of span)\n    assert lca[1, 1] == 1  # lazy & lazy -> lazy\n\n    lca = doc[1:].get_lca_matrix()\n    assert lca.shape == (3, 3)\n    assert lca[0, 0] == 0  # lazy & lazy -> lazy\n    assert lca[0, 1] == 1  # lazy & dog -> dog\n    assert lca[0, 2] == 2  # lazy & slept -> slept\n\n    lca = doc[2:].get_lca_matrix()\n    assert lca.shape == (2, 2)\n    assert lca[0, 0] == 0  # dog & dog -> dog\n    assert lca[0, 1] == 1  # dog & slept -> slept\n    assert lca[1, 0] == 1  # slept & dog -> slept\n    assert lca[1, 1] == 1  # slept & slept -> slept",
        "begin_line": 80,
        "end_line": 102,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_span_similarity_match#105",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_span_similarity_match()",
        "snippet": "def test_span_similarity_match():\n    doc = Doc(Vocab(), words=[\"a\", \"b\", \"a\", \"b\"])\n    span1 = doc[:2]\n    span2 = doc[2:]\n    with pytest.warns(ModelsWarning):\n        assert span1.similarity(span2) == 1.0\n        assert span1.similarity(doc) == 0.0\n        assert span1[:1].similarity(doc.vocab[\"a\"]) == 1.0",
        "begin_line": 105,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_spans_default_sentiment#115",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_spans_default_sentiment(en_tokenizer)",
        "snippet": "def test_spans_default_sentiment(en_tokenizer):\n    \"\"\"Test span.sentiment property's default averaging behaviour\"\"\"\n    text = \"good stuff bad stuff\"\n    tokens = en_tokenizer(text)\n    tokens.vocab[tokens[0].text].sentiment = 3.0\n    tokens.vocab[tokens[2].text].sentiment = -2.0\n    doc = Doc(tokens.vocab, words=[t.text for t in tokens])\n    assert doc[:2].sentiment == 3.0 / 2\n    assert doc[-2:].sentiment == -2.0 / 2\n    assert doc[:-1].sentiment == (3.0 + -2) / 3.0",
        "begin_line": 115,
        "end_line": 124,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_spans_override_sentiment#127",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_spans_override_sentiment(en_tokenizer)",
        "snippet": "def test_spans_override_sentiment(en_tokenizer):\n    \"\"\"Test span.sentiment property's default averaging behaviour\"\"\"\n    text = \"good stuff bad stuff\"\n    tokens = en_tokenizer(text)\n    tokens.vocab[tokens[0].text].sentiment = 3.0\n    tokens.vocab[tokens[2].text].sentiment = -2.0\n    doc = Doc(tokens.vocab, words=[t.text for t in tokens])\n    doc.user_span_hooks[\"sentiment\"] = lambda span: 10.0\n    assert doc[:2].sentiment == 10.0\n    assert doc[-2:].sentiment == 10.0\n    assert doc[:-1].sentiment == 10.0",
        "begin_line": 127,
        "end_line": 137,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_spans_are_hashable#140",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_spans_are_hashable(en_tokenizer)",
        "snippet": "def test_spans_are_hashable(en_tokenizer):\n    \"\"\"Test spans can be hashed.\"\"\"\n    text = \"good stuff bad stuff\"\n    tokens = en_tokenizer(text)\n    span1 = tokens[:2]\n    span2 = tokens[2:4]\n    assert hash(span1) != hash(span2)\n    span3 = tokens[0:2]\n    assert hash(span3) == hash(span1)",
        "begin_line": 140,
        "end_line": 148,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_spans_by_character#151",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_spans_by_character(doc)",
        "snippet": "def test_spans_by_character(doc):\n    span1 = doc[1:-2]\n    span2 = doc.char_span(span1.start_char, span1.end_char, label=\"GPE\")\n    assert span1.start_char == span2.start_char\n    assert span1.end_char == span2.end_char\n    assert span2.label_ == \"GPE\"",
        "begin_line": 151,
        "end_line": 156,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_span_to_array#159",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_span_to_array(doc)",
        "snippet": "def test_span_to_array(doc):\n    span = doc[1:-2]\n    arr = span.to_array([ORTH, LENGTH])\n    assert arr.shape == (len(span), 2)\n    assert arr[0, 0] == span[0].orth\n    assert arr[0, 1] == len(span[0])",
        "begin_line": 159,
        "end_line": 164,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_span_as_doc#167",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_span_as_doc(doc)",
        "snippet": "def test_span_as_doc(doc):\n    span = doc[4:10]\n    span_doc = span.as_doc()\n    assert span.text == span_doc.text.strip()\n    assert isinstance(span_doc, doc.__class__)\n    assert span_doc is not doc\n    assert span_doc[0].idx == 0",
        "begin_line": 167,
        "end_line": 173,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_span_as_doc_user_data#176",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_span_as_doc_user_data(doc)",
        "snippet": "def test_span_as_doc_user_data(doc):\n    \"\"\"Test that the user_data can be preserved (but not by default). \"\"\"\n    my_key = \"my_info\"\n    my_value = 342\n    doc.user_data[my_key] = my_value\n\n    span = doc[4:10]\n    span_doc_with = span.as_doc(copy_user_data=True)\n    span_doc_without = span.as_doc()\n\n    assert doc.user_data.get(my_key, None) is my_value\n    assert span_doc_with.user_data.get(my_key, None) is my_value\n    assert span_doc_without.user_data.get(my_key, None) is None",
        "begin_line": 176,
        "end_line": 188,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_span_string_label_kb_id#191",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_span_string_label_kb_id(doc)",
        "snippet": "def test_span_string_label_kb_id(doc):\n    span = Span(doc, 0, 1, label=\"hello\", kb_id=\"Q342\")\n    assert span.label_ == \"hello\"\n    assert span.label == doc.vocab.strings[\"hello\"]\n    assert span.kb_id_ == \"Q342\"\n    assert span.kb_id == doc.vocab.strings[\"Q342\"]",
        "begin_line": 191,
        "end_line": 196,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_span_label_readonly#199",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_span_label_readonly(doc)",
        "snippet": "def test_span_label_readonly(doc):\n    span = Span(doc, 0, 1)\n    with pytest.raises(NotImplementedError):\n        span.label_ = \"hello\"",
        "begin_line": 199,
        "end_line": 202,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_span_kb_id_readonly#205",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_span_kb_id_readonly(doc)",
        "snippet": "def test_span_kb_id_readonly(doc):\n    span = Span(doc, 0, 1)\n    with pytest.raises(NotImplementedError):\n        span.kb_id_ = \"Q342\"",
        "begin_line": 205,
        "end_line": 208,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_span_ents_property#211",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_span_ents_property(doc)",
        "snippet": "def test_span_ents_property(doc):\n    \"\"\"Test span.ents for the \"\"\"\n    doc.ents = [\n        (doc.vocab.strings[\"PRODUCT\"], 0, 1),\n        (doc.vocab.strings[\"PRODUCT\"], 7, 8),\n        (doc.vocab.strings[\"PRODUCT\"], 11, 14),\n    ]\n    assert len(list(doc.ents)) == 3\n    sentences = list(doc.sents)\n    assert len(sentences) == 3\n    assert len(sentences[0].ents) == 1\n    # First sentence, also tests start of sentence\n    assert sentences[0].ents[0].text == \"This\"\n    assert sentences[0].ents[0].label_ == \"PRODUCT\"\n    assert sentences[0].ents[0].start == 0\n    assert sentences[0].ents[0].end == 1\n    # Second sentence\n    assert len(sentences[1].ents) == 1\n    assert sentences[1].ents[0].text == \"another\"\n    assert sentences[1].ents[0].label_ == \"PRODUCT\"\n    assert sentences[1].ents[0].start == 7\n    assert sentences[1].ents[0].end == 8\n    # Third sentence ents, Also tests end of sentence\n    assert sentences[2].ents[0].text == \"a third .\"\n    assert sentences[2].ents[0].label_ == \"PRODUCT\"\n    assert sentences[2].ents[0].start == 11\n    assert sentences[2].ents[0].end == 14",
        "begin_line": 211,
        "end_line": 237,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.doc.test_span.test_filter_spans#240",
        "src_path": "spacy/tests/doc/test_span.py",
        "class_name": "spacy.tests.doc.test_span",
        "signature": "spacy.tests.doc.test_span.test_filter_spans(doc)",
        "snippet": "def test_filter_spans(doc):\n    # Test filtering duplicates\n    spans = [doc[1:4], doc[6:8], doc[1:4], doc[10:14]]\n    filtered = filter_spans(spans)\n    assert len(filtered) == 3\n    assert filtered[0].start == 1 and filtered[0].end == 4\n    assert filtered[1].start == 6 and filtered[1].end == 8\n    assert filtered[2].start == 10 and filtered[2].end == 14\n    # Test filtering overlaps with longest preference\n    spans = [doc[1:4], doc[1:3], doc[5:10], doc[7:9], doc[1:4]]\n    filtered = filter_spans(spans)\n    assert len(filtered) == 2\n    assert len(filtered[0]) == 3\n    assert len(filtered[1]) == 5\n    assert filtered[0].start == 1 and filtered[0].end == 4\n    assert filtered[1].start == 5 and filtered[1].end == 10\n    # Test filtering overlaps with earlier preference for identical length\n    spans = [doc[1:4], doc[2:5], doc[5:10], doc[7:9], doc[1:4]]\n    filtered = filter_spans(spans)\n    assert len(filtered) == 2\n    assert len(filtered[0]) == 3\n    assert len(filtered[1]) == 5\n    assert filtered[0].start == 1 and filtered[0].end == 4\n    assert filtered[1].start == 5 and filtered[1].end == 10",
        "begin_line": 240,
        "end_line": 263,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.make_tempdir#23",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.make_tempdir()",
        "snippet": "def make_tempdir():\n    d = Path(tempfile.mkdtemp())\n    yield d\n    shutil.rmtree(path2str(d))",
        "begin_line": 23,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_doc#29",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None)",
        "snippet": "def get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None):\n    \"\"\"Create Doc object from given vocab, words and annotations.\"\"\"\n    pos = pos or [\"\"] * len(words)\n    tags = tags or [\"\"] * len(words)\n    heads = heads or [0] * len(words)\n    deps = deps or [\"\"] * len(words)\n    for value in deps + tags + pos:\n        vocab.strings.add(value)\n\n    doc = Doc(vocab, words=words)\n    attrs = doc.to_array([POS, HEAD, DEP])\n    for i, (p, head, dep) in enumerate(zip(pos, heads, deps)):\n        attrs[i, 0] = doc.vocab.strings[p]\n        attrs[i, 1] = head\n        attrs[i, 2] = doc.vocab.strings[dep]\n    doc.from_array([POS, HEAD, DEP], attrs)\n    if ents:\n        doc.ents = [\n            Span(doc, start, end, label=doc.vocab.strings[label])\n            for start, end, label in ents\n        ]\n    if tags:\n        for token in doc:\n            token.tag_ = tags[token.i]\n    return doc",
        "begin_line": 29,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.add_vecs_to_vocab#68",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.add_vecs_to_vocab(vocab, vectors)",
        "snippet": "def add_vecs_to_vocab(vocab, vectors):\n    \"\"\"Add list of vector tuples to given vocab. All vectors need to have the\n    same length. Format: [(\"text\", [1, 2, 3])]\"\"\"\n    length = len(vectors[0][1])\n    vocab.reset_vectors(width=length)\n    for word, vec in vectors:\n        vocab.set_vector(word, vector=vec)\n    return vocab",
        "begin_line": 68,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_cosine#78",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_cosine(vec1, vec2)",
        "snippet": "def get_cosine(vec1, vec2):\n    \"\"\"Get cosine for two given vectors\"\"\"\n    return numpy.dot(vec1, vec2) / (numpy.linalg.norm(vec1) * numpy.linalg.norm(vec2))",
        "begin_line": 78,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.assert_docs_equal#83",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.assert_docs_equal(doc1, doc2)",
        "snippet": "def assert_docs_equal(doc1, doc2):\n    \"\"\"Compare two Doc objects and assert that they're equal. Tests for tokens,\n    tags, dependencies and entities.\"\"\"\n    assert [t.orth for t in doc1] == [t.orth for t in doc2]\n\n    assert [t.pos for t in doc1] == [t.pos for t in doc2]\n    assert [t.tag for t in doc1] == [t.tag for t in doc2]\n\n    assert [t.head.i for t in doc1] == [t.head.i for t in doc2]\n    assert [t.dep for t in doc1] == [t.dep for t in doc2]\n    if doc1.is_parsed and doc2.is_parsed:\n        assert [s for s in doc1.sents] == [s for s in doc2.sents]\n\n    assert [t.ent_type for t in doc1] == [t.ent_type for t in doc2]\n    assert [t.ent_iob for t in doc1] == [t.ent_iob for t in doc2]\n    assert [ent for ent in doc1.ents] == [ent for ent in doc2.ents]",
        "begin_line": 83,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    }
]