[
    {
        "name": "tests.keras.backend.reference_operations.wrapper#13",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.wrapper(*args, **kwargs)",
        "snippet": "    def wrapper(*args, **kwargs):\n        x = args[0]\n        w = args[1]\n        if x.ndim == 3:\n            w = np.flipud(w)\n            w = np.transpose(w, (1, 2, 0))\n            if kwargs['data_format'] == 'channels_last':\n                x = np.transpose(x, (0, 2, 1))\n        elif x.ndim == 4:\n            w = np.fliplr(np.flipud(w))\n            w = np.transpose(w, (2, 3, 0, 1))\n            if kwargs['data_format'] == 'channels_last':\n                x = np.transpose(x, (0, 3, 1, 2))\n        else:\n            w = np.flip(np.fliplr(np.flipud(w)), axis=2)\n            w = np.transpose(w, (3, 4, 0, 1, 2))\n            if kwargs['data_format'] == 'channels_last':\n                x = np.transpose(x, (0, 4, 1, 2, 3))\n\n        dilation_rate = kwargs.pop('dilation_rate', 1)\n        if isinstance(dilation_rate, int):\n            dilation_rate = (dilation_rate,) * (x.ndim - 2)\n        for (i, d) in enumerate(dilation_rate):\n            if d > 1:\n                for j in range(w.shape[2 + i] - 1):\n                    w = np.insert(w, 2 * j + 1, 0, axis=2 + i)\n\n        y = func(x, w, **kwargs)\n\n        if kwargs['data_format'] == 'channels_last':\n            if y.ndim == 3:\n                y = np.transpose(y, (0, 2, 1))\n            elif y.ndim == 4:\n                y = np.transpose(y, (0, 2, 3, 1))\n            else:\n                y = np.transpose(y, (0, 2, 3, 4, 1))\n\n        return y",
        "begin_line": 13,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.conv#56",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.conv(x, w, padding, data_format)",
        "snippet": "def conv(x, w, padding, data_format):\n    y = []\n    for i in range(x.shape[0]):\n        _y = []\n        for j in range(w.shape[1]):\n            __y = []\n            for k in range(w.shape[0]):\n                __y.append(signal.convolve(x[i, k], w[k, j], mode=padding))\n            _y.append(np.sum(np.stack(__y, axis=-1), axis=-1))\n        y.append(_y)\n    y = np.array(y)\n    return y",
        "begin_line": 56,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.depthwise_conv#71",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.depthwise_conv(x, w, padding, data_format)",
        "snippet": "def depthwise_conv(x, w, padding, data_format):\n    y = []\n    for i in range(x.shape[0]):\n        _y = []\n        for j in range(w.shape[0]):\n            __y = []\n            for k in range(w.shape[1]):\n                __y.append(signal.convolve(x[i, j], w[j, k], mode=padding))\n            _y.append(np.stack(__y, axis=0))\n        y.append(np.concatenate(_y, axis=0))\n    y = np.array(y)\n    return y",
        "begin_line": 71,
        "end_line": 82,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.separable_conv#85",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.separable_conv(x, w1, w2, padding, data_format)",
        "snippet": "def separable_conv(x, w1, w2, padding, data_format):\n    x2 = depthwise_conv(x, w1, padding=padding, data_format=data_format)\n    return conv(x2, w2, padding=padding, data_format=data_format)",
        "begin_line": 85,
        "end_line": 87,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.conv_transpose#90",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.conv_transpose(x, w, output_shape, padding, data_format, dilation_rate=1)",
        "snippet": "def conv_transpose(x, w, output_shape, padding, data_format, dilation_rate=1):\n    if x.ndim == 4:\n        w = np.fliplr(np.flipud(w))\n        w = np.transpose(w, (0, 1, 3, 2))\n    else:\n        w = np.flip(np.fliplr(np.flipud(w)), axis=2)\n        w = np.transpose(w, (0, 1, 2, 4, 3))\n\n    if isinstance(dilation_rate, int):\n        dilation_rate = (dilation_rate,) * (x.ndim - 2)\n    for (i, d) in enumerate(dilation_rate):\n        if d > 1:\n            for j in range(w.shape[i] - 1):\n                w = np.insert(w, 2 * j + 1, 0, axis=i)\n\n    return conv(x, w, padding=padding, data_format=data_format)",
        "begin_line": 90,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.pool#118",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.pool(x, pool_size, strides, padding, data_format, pool_mode)",
        "snippet": "def pool(x, pool_size, strides, padding, data_format, pool_mode):\n    if data_format == 'channels_last':\n        if x.ndim == 3:\n            x = np.transpose(x, (0, 2, 1))\n        elif x.ndim == 4:\n            x = np.transpose(x, (0, 3, 1, 2))\n        else:\n            x = np.transpose(x, (0, 4, 1, 2, 3))\n\n    if padding == 'same':\n        pad = [(0, 0), (0, 0)] + [(s // 2, s // 2) for s in pool_size]\n        x = np.pad(x, pad, 'constant', constant_values=-np.inf)\n\n    # indexing trick\n    x = np.pad(x, [(0, 0), (0, 0)] + [(0, 1) for _ in pool_size],\n               'constant', constant_values=0)\n\n    if x.ndim == 3:\n        y = [x[:, :, k:k1:strides[0]]\n             for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0))]\n    elif x.ndim == 4:\n        y = []\n        for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n            for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n                y.append(x[:, :, k:k1:strides[0], l:l1:strides[1]])\n    else:\n        y = []\n        for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n            for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n                for (m, m1) in zip(range(pool_size[2]), range(-pool_size[2], 0)):\n                    y.append(x[:,\n                               :,\n                               k:k1:strides[0],\n                               l:l1:strides[1],\n                               m:m1:strides[2]])\n    y = np.stack(y, axis=-1)\n    if pool_mode == 'avg':\n        y = np.mean(np.ma.masked_invalid(y), axis=-1).data\n    elif pool_mode == 'max':\n        y = np.max(y, axis=-1)\n\n    if data_format == 'channels_last':\n        if y.ndim == 3:\n            y = np.transpose(y, (0, 2, 1))\n        elif y.ndim == 4:\n            y = np.transpose(y, (0, 2, 3, 1))\n        else:\n            y = np.transpose(y, (0, 2, 3, 4, 1))\n\n    return y",
        "begin_line": 118,
        "end_line": 167,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.bias_add#174",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.bias_add(x, y, data_format)",
        "snippet": "def bias_add(x, y, data_format):\n    if data_format == 'channels_first':\n        if y.ndim > 1:\n            y = np.reshape(y, y.shape[::-1])\n        for _ in range(x.ndim - y.ndim - 1):\n            y = np.expand_dims(y, -1)\n    else:\n        for _ in range(x.ndim - y.ndim - 1):\n            y = np.expand_dims(y, 0)\n    return x + y",
        "begin_line": 174,
        "end_line": 183,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.rnn#186",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.rnn(x, w, init, go_backwards=False, mask=None, unroll=False, input_length=None)",
        "snippet": "def rnn(x, w, init, go_backwards=False, mask=None, unroll=False, input_length=None):\n    w_i, w_h, w_o = w\n    h = []\n    o = []\n\n    if go_backwards:\n        t_list = range(x.shape[1] - 1, -1, -1)\n    else:\n        t_list = range(x.shape[1])\n\n    if mask is not None:\n        from keras import backend as K\n        np_mask = K.eval(mask)\n    else:\n        np_mask = None\n\n    for (i, t) in enumerate(t_list):\n        h_t = np.dot(x[:, t], w_i)\n\n        if w_h is not None:\n            prev = h[i - 1] if i > 0 else init\n            h_t1 = np.dot(prev, w_h)\n            if np_mask is not None:\n                h_t1[np_mask[:, t] == 0] = prev[np_mask[:, t] == 0]\n        else:\n            h_t1 = 0\n\n        o_t = h_t + h_t1\n        if w_o is not None:\n            o_t = np.dot(o_t, w_o)\n        o.append(o_t)\n\n        if np_mask is not None:\n            h_t = h_t * np_mask[:, t].reshape(-1, 1)\n        h.append(h_t + h_t1)\n\n    return o[-1], np.stack(o, axis=1), np.stack(h, axis=1)",
        "begin_line": 186,
        "end_line": 222,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.in_train_phase#237",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.in_train_phase(x, alt, training=None)",
        "snippet": "def in_train_phase(x, alt, training=None):\n    if training is None:\n        training = learning_phase()\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n    else:\n        if callable(alt):\n            return alt()\n        else:\n            return alt",
        "begin_line": 237,
        "end_line": 250,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.in_test_phase#253",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.in_test_phase(x, alt, training=None)",
        "snippet": "def in_test_phase(x, alt, training=None):\n    return in_train_phase(alt, x, training=training)",
        "begin_line": 253,
        "end_line": 254,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.relu#257",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.relu(x, alpha=0.0, max_value=None, threshold=0.0)",
        "snippet": "def relu(x, alpha=0., max_value=None, threshold=0.):\n    y = x * (x >= threshold)\n    if max_value is not None:\n        y = np.clip(y, 0.0, max_value)\n    y += alpha * (x - threshold) * (x < threshold)\n    return y",
        "begin_line": 257,
        "end_line": 262,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.switch#265",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.switch(condition, then_expression, else_expression)",
        "snippet": "def switch(condition, then_expression, else_expression):\n    cond_float = condition.astype(floatx())\n    while cond_float.ndim < then_expression.ndim:\n        cond_float = cond_float[..., None]\n    return cond_float * then_expression + (1 - cond_float) * else_expression",
        "begin_line": 265,
        "end_line": 269,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.softplus#272",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.softplus(x)",
        "snippet": "def softplus(x):\n    return np.log(1. + np.exp(x))",
        "begin_line": 272,
        "end_line": 273,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.elu#276",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.elu(x, alpha=1.0)",
        "snippet": "def elu(x, alpha=1.):\n    return x * (x > 0) + alpha * (np.exp(x) - 1.) * (x < 0)",
        "begin_line": 276,
        "end_line": 277,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.sigmoid#280",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.sigmoid(x)",
        "snippet": "def sigmoid(x):\n    return 1. / (1. + np.exp(-x))",
        "begin_line": 280,
        "end_line": 281,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.hard_sigmoid#284",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.hard_sigmoid(x)",
        "snippet": "def hard_sigmoid(x):\n    y = 0.2 * x + 0.5\n    y = np.minimum(y, 1.)\n    y = np.maximum(y, 0.)\n    return y",
        "begin_line": 284,
        "end_line": 288,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.tanh#291",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.tanh(x)",
        "snippet": "def tanh(x):\n    return np.tanh(x)",
        "begin_line": 291,
        "end_line": 292,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.softmax#295",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.softmax(x, axis=-1)",
        "snippet": "def softmax(x, axis=-1):\n    y = np.exp(x - np.max(x, axis, keepdims=True))\n    return y / np.sum(y, axis, keepdims=True)",
        "begin_line": 295,
        "end_line": 297,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.l2_normalize#300",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.l2_normalize(x, axis=-1)",
        "snippet": "def l2_normalize(x, axis=-1):\n    y = np.max(np.sum(x ** 2, axis, keepdims=True), axis, keepdims=True)\n    return x / np.sqrt(y)",
        "begin_line": 300,
        "end_line": 302,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.binary_crossentropy#305",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.binary_crossentropy(target, output, from_logits=False)",
        "snippet": "def binary_crossentropy(target, output, from_logits=False):\n    if not from_logits:\n        output = np.clip(output, 1e-7, 1 - 1e-7)\n        output = np.log(output / (1 - output))\n    return (target * -np.log(sigmoid(output)) +\n            (1 - target) * -np.log(1 - sigmoid(output)))",
        "begin_line": 305,
        "end_line": 310,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.categorical_crossentropy#313",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.categorical_crossentropy(target, output, from_logits=False)",
        "snippet": "def categorical_crossentropy(target, output, from_logits=False):\n    if from_logits:\n        output = softmax(output)\n    else:\n        output /= output.sum(axis=-1, keepdims=True)\n    output = np.clip(output, 1e-7, 1 - 1e-7)\n    return np.sum(target * -np.log(output), axis=-1, keepdims=False)",
        "begin_line": 313,
        "end_line": 319,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.max#322",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.max(x, axis=None, keepdims=False)",
        "snippet": "def max(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.max(x, axis=axis, keepdims=keepdims)",
        "begin_line": 322,
        "end_line": 325,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.min#328",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.min(x, axis=None, keepdims=False)",
        "snippet": "def min(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.min(x, axis=axis, keepdims=keepdims)",
        "begin_line": 328,
        "end_line": 331,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.mean#334",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.mean(x, axis=None, keepdims=False)",
        "snippet": "def mean(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.mean(x, axis=axis, keepdims=keepdims)",
        "begin_line": 334,
        "end_line": 337,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.var#340",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.var(x, axis=None, keepdims=False)",
        "snippet": "def var(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.var(x, axis=axis, keepdims=keepdims)",
        "begin_line": 340,
        "end_line": 343,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.std#346",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.std(x, axis=None, keepdims=False)",
        "snippet": "def std(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.std(x, axis=axis, keepdims=keepdims)",
        "begin_line": 346,
        "end_line": 349,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.logsumexp#352",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.logsumexp(x, axis=None, keepdims=False)",
        "snippet": "def logsumexp(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return sp.misc.logsumexp(x, axis=axis, keepdims=keepdims)",
        "begin_line": 352,
        "end_line": 355,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.cumsum#370",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.cumsum(x, axis=0)",
        "snippet": "def cumsum(x, axis=0):\n    return np.cumsum(x, axis=axis)",
        "begin_line": 370,
        "end_line": 371,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.cumprod#374",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.cumprod(x, axis=0)",
        "snippet": "def cumprod(x, axis=0):\n    return np.cumprod(x, axis=axis)",
        "begin_line": 374,
        "end_line": 375,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.concatenate#412",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.concatenate(tensors, axis=-1)",
        "snippet": "def concatenate(tensors, axis=-1):\n    return np.concatenate(tensors, axis)",
        "begin_line": 412,
        "end_line": 413,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.permute_dimensions#416",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.permute_dimensions(x, pattern)",
        "snippet": "def permute_dimensions(x, pattern):\n    return np.transpose(x, pattern)",
        "begin_line": 416,
        "end_line": 417,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.reshape#420",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.reshape(x, shape)",
        "snippet": "def reshape(x, shape):\n    return np.reshape(x, shape)",
        "begin_line": 420,
        "end_line": 421,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.repeat_elements#424",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.repeat_elements(x, rep, axis)",
        "snippet": "def repeat_elements(x, rep, axis):\n    return np.repeat(x, rep, axis=axis)",
        "begin_line": 424,
        "end_line": 425,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.repeat#428",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.repeat(x, n)",
        "snippet": "def repeat(x, n):\n    y = np.expand_dims(x, 1)\n    y = np.repeat(y, n, axis=1)\n    return y",
        "begin_line": 428,
        "end_line": 431,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.tile#434",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.tile(x, n)",
        "snippet": "def tile(x, n):\n    return np.tile(x, n)",
        "begin_line": 434,
        "end_line": 435,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.arange#438",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.arange(start, stop=None, step=1, dtype='int32')",
        "snippet": "def arange(start, stop=None, step=1, dtype='int32'):\n    return np.arange(start, stop, step, dtype)",
        "begin_line": 438,
        "end_line": 439,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.flatten#442",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.flatten(x)",
        "snippet": "def flatten(x):\n    return np.reshape(x, (-1,))",
        "begin_line": 442,
        "end_line": 443,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.batch_flatten#446",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.batch_flatten(x)",
        "snippet": "def batch_flatten(x):\n    return np.reshape(x, (x.shape[0], -1))",
        "begin_line": 446,
        "end_line": 447,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.eval#450",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.eval(x)",
        "snippet": "def eval(x):\n    return x",
        "begin_line": 450,
        "end_line": 451,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.dtype#454",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.dtype(x)",
        "snippet": "def dtype(x):\n    return x.dtype.name",
        "begin_line": 454,
        "end_line": 455,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.constant#458",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.constant(value, dtype=None, shape=None, name=None)",
        "snippet": "def constant(value, dtype=None, shape=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    if shape is None:\n        shape = ()\n    np_value = value * np.ones(shape)\n    np_value.astype(dtype)\n    return np_value",
        "begin_line": 458,
        "end_line": 465,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.print_tensor#468",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.print_tensor(x, message='')",
        "snippet": "def print_tensor(x, message=''):\n    print(x, message)\n    return x",
        "begin_line": 468,
        "end_line": 470,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.dot#473",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.dot(x, y)",
        "snippet": "def dot(x, y):\n    return np.dot(x, y)",
        "begin_line": 473,
        "end_line": 474,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.transpose#477",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.transpose(x)",
        "snippet": "def transpose(x):\n    return np.transpose(x)",
        "begin_line": 477,
        "end_line": 478,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.reverse#481",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.reverse(x, axes)",
        "snippet": "def reverse(x, axes):\n    if isinstance(axes, int):\n        axes = [axes]\n    for a in axes:\n        x = np.flip(x, a)\n    return x",
        "begin_line": 481,
        "end_line": 486,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.variable#489",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.variable(value, dtype=None, name=None, constraint=None)",
        "snippet": "def variable(value, dtype=None, name=None, constraint=None):\n    if constraint is not None:\n        raise TypeError(\"Constraint must be None when \"\n                        \"using the NumPy backend.\")\n    return np.array(value, dtype)",
        "begin_line": 489,
        "end_line": 493,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.greater_equal#508",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.greater_equal(x, y)",
        "snippet": "def greater_equal(x, y):\n    return x >= y",
        "begin_line": 508,
        "end_line": 509,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.random_uniform_variable#532",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)",
        "snippet": "def random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None):\n    return (high - low) * np.random.random(shape).astype(dtype) + low",
        "begin_line": 532,
        "end_line": 533,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.random_normal_variable#536",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)",
        "snippet": "def random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None):\n    return scale * np.random.randn(*shape).astype(dtype) + mean",
        "begin_line": 536,
        "end_line": 537,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.zeros#540",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.zeros(shape, dtype=floatx(), name=None)",
        "snippet": "def zeros(shape, dtype=floatx(), name=None):\n    return np.zeros(shape, dtype=dtype)",
        "begin_line": 540,
        "end_line": 541,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.zeros_like#544",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.zeros_like(x, dtype=floatx(), name=None)",
        "snippet": "def zeros_like(x, dtype=floatx(), name=None):\n    return np.zeros_like(x, dtype=dtype)",
        "begin_line": 544,
        "end_line": 545,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.ones#548",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.ones(shape, dtype=floatx(), name=None)",
        "snippet": "def ones(shape, dtype=floatx(), name=None):\n    return np.ones(shape, dtype=dtype)",
        "begin_line": 548,
        "end_line": 549,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.ones_like#552",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.ones_like(x, dtype=floatx(), name=None)",
        "snippet": "def ones_like(x, dtype=floatx(), name=None):\n    return np.ones_like(x, dtype=dtype)",
        "begin_line": 552,
        "end_line": 553,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.eye#556",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.eye(size, dtype=None, name=None)",
        "snippet": "def eye(size, dtype=None, name=None):\n    return np.eye(size, dtype=dtype)",
        "begin_line": 556,
        "end_line": 557,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.resize_images#560",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.resize_images(x, height_factor, width_factor, data_format)",
        "snippet": "def resize_images(x, height_factor, width_factor, data_format):\n    if data_format == 'channels_first':\n        x = repeat_elements(x, height_factor, axis=2)\n        x = repeat_elements(x, width_factor, axis=3)\n    elif data_format == 'channels_last':\n        x = repeat_elements(x, height_factor, axis=1)\n        x = repeat_elements(x, width_factor, axis=2)\n    return x",
        "begin_line": 560,
        "end_line": 567,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.resize_volumes#570",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.resize_volumes(x, depth_factor, height_factor, width_factor, data_format)",
        "snippet": "def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    if data_format == 'channels_first':\n        x = repeat_elements(x, depth_factor, axis=2)\n        x = repeat_elements(x, height_factor, axis=3)\n        x = repeat_elements(x, width_factor, axis=4)\n    elif data_format == 'channels_last':\n        x = repeat_elements(x, depth_factor, axis=1)\n        x = repeat_elements(x, height_factor, axis=2)\n        x = repeat_elements(x, width_factor, axis=3)\n    return x",
        "begin_line": 570,
        "end_line": 579,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.__init__#24",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.__init__(self, batch_size, sequence_length=12)",
        "snippet": "    def __init__(self, batch_size, sequence_length=12):\n        self.batch_size = batch_size\n        self.sequence_length = sequence_length\n        self.logs = []  # It will work for use_multiprocessing=False",
        "begin_line": 24,
        "end_line": 27,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.__len__#29",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.__len__(self)",
        "snippet": "    def __len__(self):\n        return self.sequence_length",
        "begin_line": 29,
        "end_line": 30,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.__getitem__#32",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.__getitem__(self, idx)",
        "snippet": "    def __getitem__(self, idx):\n        self.logs.append(idx)\n        return ([np.random.random((self.batch_size, 3)),\n                 np.random.random((self.batch_size, 3))],\n                [np.random.random((self.batch_size, 4)),\n                 np.random.random((self.batch_size, 3))])",
        "begin_line": 32,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.on_epoch_end#39",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.on_epoch_end(self)",
        "snippet": "    def on_epoch_end(self):\n        pass",
        "begin_line": 39,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.threadsafe_iter.__init__#48",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.threadsafe_iter",
        "signature": "tests.keras.engine.test_training.threadsafe_iter.__init__(self, it)",
        "snippet": "    def __init__(self, it):\n        self.it = it\n        self.lock = threading.Lock()",
        "begin_line": 48,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.threadsafe_iter.__iter__#52",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.threadsafe_iter",
        "signature": "tests.keras.engine.test_training.threadsafe_iter.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return self",
        "begin_line": 52,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.threadsafe_iter.__next__#55",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.threadsafe_iter",
        "signature": "tests.keras.engine.test_training.threadsafe_iter.__next__(self)",
        "snippet": "    def __next__(self):\n        return self.next()",
        "begin_line": 55,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.threadsafe_iter.next#58",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.threadsafe_iter",
        "signature": "tests.keras.engine.test_training.threadsafe_iter.next(self)",
        "snippet": "    def next(self):\n        with self.lock:\n            return next(self.it)",
        "begin_line": 58,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.threadsafe_generator#63",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.threadsafe_generator(f)",
        "snippet": "def threadsafe_generator(f):\n    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n    \"\"\"\n\n    def g(*a, **kw):\n        return threadsafe_iter(f(*a, **kw))\n\n    return g",
        "begin_line": 63,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.g#67",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.g(*a, **kw)",
        "snippet": "    def g(*a, **kw):\n        return threadsafe_iter(f(*a, **kw))",
        "begin_line": 67,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_array_length_consistency#73",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_array_length_consistency()",
        "snippet": "def test_check_array_length_consistency():\n    training_utils.check_array_length_consistency(None, None, None)\n    a_np = np.random.random((4, 3, 3))\n    training_utils.check_array_length_consistency(a_np, a_np, a_np)\n    training_utils.check_array_length_consistency(\n        [a_np, a_np], [a_np, a_np], [a_np, a_np])\n    training_utils.check_array_length_consistency([None], [None], [None])\n\n    b_np = np.random.random((3, 4))\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency(a_np, None, None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency(a_np, a_np, None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency([a_np], [None], None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency([a_np], [b_np], None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency([a_np], None, [b_np])",
        "begin_line": 73,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.testslice_arrays#94",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.testslice_arrays()",
        "snippet": "def testslice_arrays():\n    input_a = np.random.random((10, 3))\n    slice_arrays(None)\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)\n    input_a = [None, [1, 1], None, [1, 1]]\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)\n    input_a = [None]\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)\n    input_a = None\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)",
        "begin_line": 94,
        "end_line": 111,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_weighted_masked_objective#114",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_weighted_masked_objective()",
        "snippet": "def test_weighted_masked_objective():\n    a = Input(shape=(3,), name='input_a')\n\n    # weighted_masked_objective\n    def mask_dummy(y_true=None, y_pred=None, weight=None):\n        return K.placeholder(y_true.shape)\n\n    weighted_function = training_utils.weighted_masked_objective(\n        losses.categorical_crossentropy)\n    weighted_function(a, a, None)",
        "begin_line": 114,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.mask_dummy#118",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.mask_dummy(y_true=None, y_pred=None, weight=None)",
        "snippet": "    def mask_dummy(y_true=None, y_pred=None, weight=None):\n        return K.placeholder(y_true.shape)",
        "begin_line": 118,
        "end_line": 119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_methods#126",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_methods()",
        "snippet": "def test_model_methods():\n    a = Input(shape=(3,), name='input_a')\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    model = Model([a, b], [a_2, b_2])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    # training/testing doesn't work before compiling.\n    with pytest.raises(RuntimeError):\n        model.train_on_batch([input_a_np, input_b_np],\n                             [output_a_np, output_b_np])\n\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    # test train_on_batch\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                               {'dense_1': output_a_np, 'dropout': output_b_np})\n\n    # test fit\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np], epochs=1, batch_size=4)\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    [output_a_np, output_b_np], epochs=1, batch_size=4)\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    {'dense_1': output_a_np, 'dropout': output_b_np},\n                    epochs=1, batch_size=4)\n\n    # test validation_split\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5)\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5)\n\n    # test validation data\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4,\n                    validation_data=([input_a_np, input_b_np],\n                                     [output_a_np, output_b_np]))\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5,\n                    validation_data=({'input_a': input_a_np,\n                                      'input_b': input_b_np},\n                                     [output_a_np, output_b_np]))\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    {'dense_1': output_a_np, 'dropout': output_b_np},\n                    epochs=1, batch_size=4, validation_split=0.5,\n                    validation_data=(\n                        {'input_a': input_a_np, 'input_b': input_b_np},\n                        {'dense_1': output_a_np, 'dropout': output_b_np}))\n\n    # test_on_batch\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                              [output_a_np, output_b_np])\n    out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                              {'dense_1': output_a_np, 'dropout': output_b_np})\n\n    # predict_on_batch\n    out = model.predict_on_batch([input_a_np, input_b_np])\n    out = model.predict_on_batch({'input_a': input_a_np,\n                                  'input_b': input_b_np})\n\n    # predict, evaluate\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.evaluate([input_a_np, input_b_np],\n                         [output_a_np, output_b_np],\n                         batch_size=4)\n    out = model.predict([input_a_np, input_b_np], batch_size=4)\n\n    # with sample_weight\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    sample_weight = [None, np.random.random((10,))]\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               sample_weight=sample_weight)\n\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np],\n                              sample_weight=sample_weight)\n\n    # test accuracy metric\n    model.compile(optimizer, loss, metrics=['acc'],\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 5\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 5\n\n    # this should also work\n    model.compile(optimizer, loss, metrics={'dense_1': 'acc'},\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 4\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 4\n\n    # and this as well\n    model.compile(optimizer, loss, metrics={'dense_1': ['acc']},\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 4\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 4\n\n    # test starting from non-zero initial epoch\n    trained_epochs = []\n    trained_batches = []\n\n    # define tracer callback\n    def on_epoch_begin(epoch, logs):\n        trained_epochs.append(epoch)\n\n    def on_batch_begin(batch, logs):\n        trained_batches.append(batch)\n\n    tracker_cb = LambdaCallback(on_epoch_begin=on_epoch_begin,\n                                on_batch_begin=on_batch_begin)\n\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np], epochs=5, batch_size=4,\n                    initial_epoch=2, callbacks=[tracker_cb])\n    assert trained_epochs == [2, 3, 4]\n\n    # test starting from non-zero initial epoch for generator too\n    trained_epochs = []\n\n    @threadsafe_generator\n    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)),\n                    np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)),\n                    np.random.random((batch_sz, 3))])\n\n    out = model.fit_generator(gen_data(4), steps_per_epoch=3, epochs=5,\n                              initial_epoch=2, callbacks=[tracker_cb])\n    assert trained_epochs == [2, 3, 4]\n\n    # test with a custom metric function\n    def mse(y_true, y_pred):\n        return K.mean(K.pow(y_true - y_pred, 2))\n\n    model.compile(optimizer, loss, metrics=[mse],\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    out_len = 1 + 2 * (1 + 1)  # total loss + 2 outputs * (loss + metric)\n    assert len(out) == out_len\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == out_len\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    batch_size=4, epochs=1)\n    out = model.evaluate([input_a_np, input_b_np],\n                         [output_a_np, output_b_np],\n                         batch_size=4)\n    out = model.predict([input_a_np, input_b_np], batch_size=4)\n\n    # enable verbose for evaluate_generator\n    out = model.evaluate_generator(gen_data(4), steps=3, verbose=1)\n\n    # empty batch\n    with pytest.raises(ValueError):\n        @threadsafe_generator\n        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))\n\n        out = model.evaluate_generator(gen_data(), steps=1)\n\n    # x is not a list of numpy arrays.\n    with pytest.raises(ValueError):\n        out = model.predict([None])\n\n    # x does not match _feed_input_names.\n    with pytest.raises(ValueError):\n        out = model.predict([input_a_np, None, input_b_np])\n    with pytest.raises(ValueError):\n        out = model.predict([None, input_a_np, input_b_np])\n\n    # all input/output/weight arrays should have the same number of samples.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np[:2]],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=sample_weight)\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np[:2]],\n                                   sample_weight=sample_weight)\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=[sample_weight[1],\n                                                  sample_weight[1][:2]])\n\n    # `sample_weight` is neither a dict nor a list.\n    with pytest.raises(TypeError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=tuple(sample_weight))\n\n    # `validation_data` is neither a tuple nor a triple.\n    with pytest.raises(ValueError):\n        out = model.fit([input_a_np, input_b_np],\n                        [output_a_np, output_b_np],\n                        epochs=1, batch_size=4,\n                        validation_data=([input_a_np, input_b_np],))\n\n    # `loss` does not match outputs.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=['mse', 'mae', 'mape'])\n\n    # `loss_weights` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', loss_weights={'lstm': 0.5})\n\n    # `loss_weights` does not match outputs.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', loss_weights=[0.5])\n\n    # `loss_weights` is invalid type.\n    with pytest.raises(TypeError):\n        model.compile(optimizer, loss='mse', loss_weights=(0.5, 0.5))\n\n    # `sample_weight_mode` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse',\n                      sample_weight_mode={'lstm': 'temporal'})\n\n    # `sample_weight_mode` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', sample_weight_mode=['temporal'])\n\n    # `sample_weight_mode` matches output_names partially.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse',\n                      sample_weight_mode={'dense_1': 'temporal'})\n\n    # `loss` does not exist.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=[])\n\n    model.compile(optimizer, loss=['mse', 'mae'])\n    model.compile(optimizer, loss='mse', loss_weights={'dense_1': 0.2,\n                                                       'dropout': 0.8})\n    model.compile(optimizer, loss='mse', loss_weights=[0.2, 0.8])\n\n    # the rank of weight arrays should be 1.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch(\n            [input_a_np, input_b_np],\n            [output_a_np, output_b_np],\n            sample_weight=[None, np.random.random((10, 20, 30))])\n\n    model.compile(optimizer, loss='mse',\n                  sample_weight_mode={'dense_1': None, 'dropout': 'temporal'})\n    model.compile(optimizer, loss='mse', sample_weight_mode=[None, 'temporal'])\n\n    # the rank of output arrays should be at least 3D.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=sample_weight)\n\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n    trained_epochs = []\n    trained_batches = []\n    val_seq = RandomSequence(4)\n    out = model.fit_generator(generator=RandomSequence(3),\n                              steps_per_epoch=3,\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              validation_steps=3,\n                              max_queue_size=1,\n                              callbacks=[tracker_cb])\n    assert trained_epochs == [0, 1, 2, 3, 4]\n    assert trained_batches == list(range(3)) * 5\n    assert len(val_seq.logs) <= 4 * 5\n\n    # steps_per_epoch will be equal to len of sequence if it's unspecified\n    trained_epochs = []\n    trained_batches = []\n    val_seq = RandomSequence(4)\n    out = model.fit_generator(generator=RandomSequence(3),\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              callbacks=[tracker_cb])\n    assert trained_epochs == [0, 1, 2, 3, 4]\n    assert trained_batches == list(range(12)) * 5\n    assert len(val_seq.logs) == 12 * 5\n\n    # test for workers = 0\n    trained_epochs = []\n    trained_batches = []\n    val_seq = RandomSequence(4)\n    out = model.fit_generator(generator=RandomSequence(3),\n                              epochs=5,\n                              validation_data=val_seq,\n                              callbacks=[tracker_cb],\n                              workers=0)\n    assert trained_epochs == [0, 1, 2, 3, 4]\n    assert trained_batches == list(range(12)) * 5\n    assert len(val_seq.logs) == 12 * 5\n\n    # fit_generator will throw an exception\n    # if steps is unspecified for regular generator\n    with pytest.raises(ValueError):\n        @threadsafe_generator\n        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))\n\n        out = model.fit_generator(generator=gen_data(), epochs=5,\n                                  initial_epoch=0, validation_data=gen_data(),\n                                  callbacks=[tracker_cb])\n\n    # Check if generator is only accessed an expected number of times\n    gen_counters = [0, 0]\n\n    @threadsafe_generator\n    def gen_data(i):\n        while True:\n            gen_counters[i] += 1\n            yield ([np.random.random((1, 3)), np.random.random((1, 3))],\n                   [np.random.random((1, 4)), np.random.random((1, 3))])\n    out = model.fit_generator(generator=gen_data(0), epochs=3,\n                              steps_per_epoch=2,\n                              validation_data=gen_data(1),\n                              validation_steps=1,\n                              max_queue_size=2,\n                              workers=2)\n\n    # Need range check here as filling\n    # of the queue depends on sleep in the enqueuers\n    max_train = 3 * 2 + 2 * 2\n    min_train = 2 * 3\n    assert min_train <= gen_counters[0] <= max_train\n    # 12 = (epoch * workers * validation steps * max_queue_size)\n    assert 3 <= gen_counters[1] <= 12\n\n    gen_counters = [0]\n    out = model.fit_generator(generator=RandomSequence(3), epochs=3,\n                              validation_data=gen_data(0),\n                              validation_steps=1,\n                              max_queue_size=2,\n                              workers=2)\n\n    # 12 = (epoch * workers * validation steps * max_queue_size)\n    # Need range check here as filling\n    # of the queue depends on sleep in the enqueuers\n    assert 3 <= gen_counters[0] <= 12\n\n    # predict_generator output shape behavior should be consistent\n    def expected_shape(batch_size, n_batches):\n        return (batch_size * n_batches, 4), (batch_size * n_batches, 3)\n\n    # Multiple outputs and one step.\n    batch_size = 5\n    sequence_length = 1\n    shape_0, shape_1 = expected_shape(batch_size, sequence_length)\n    out = model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n\n    # Multiple outputs and multiple steps.\n    batch_size = 5\n    sequence_length = 2\n    shape_0, shape_1 = expected_shape(batch_size, sequence_length)\n    out = model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n\n    # Create a model with a single output.\n    single_output_model = Model([a, b], a_2)\n    single_output_model.compile(optimizer, loss,\n                                metrics=[], sample_weight_mode=None)\n\n    # Single output and one step.\n    batch_size = 5\n    sequence_length = 1\n    shape_0, _ = expected_shape(batch_size, sequence_length)\n    out = single_output_model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out) == shape_0\n\n    # Single output and multiple steps.\n    batch_size = 5\n    sequence_length = 2\n    shape_0, _ = expected_shape(batch_size, sequence_length)\n    out = single_output_model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out) == shape_0",
        "begin_line": 126,
        "end_line": 571,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.on_epoch_begin#277",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.on_epoch_begin(epoch, logs)",
        "snippet": "    def on_epoch_begin(epoch, logs):\n        trained_epochs.append(epoch)",
        "begin_line": 277,
        "end_line": 278,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.on_batch_begin#280",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.on_batch_begin(batch, logs)",
        "snippet": "    def on_batch_begin(batch, logs):\n        trained_batches.append(batch)",
        "begin_line": 280,
        "end_line": 281,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#295",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data(batch_sz)",
        "snippet": "    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)),\n                    np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)),\n                    np.random.random((batch_sz, 3))])",
        "begin_line": 295,
        "end_line": 300,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.mse#307",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.mse(y_true, y_pred)",
        "snippet": "    def mse(y_true, y_pred):\n        return K.mean(K.pow(y_true - y_pred, 2))",
        "begin_line": 307,
        "end_line": 308,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#341",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data()",
        "snippet": "        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))",
        "begin_line": 341,
        "end_line": 343,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#488",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data()",
        "snippet": "        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))",
        "begin_line": 488,
        "end_line": 490,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#500",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data(i)",
        "snippet": "    def gen_data(i):\n        while True:\n            gen_counters[i] += 1\n            yield ([np.random.random((1, 3)), np.random.random((1, 3))],\n                   [np.random.random((1, 4)), np.random.random((1, 3))])",
        "begin_line": 500,
        "end_line": 504,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.expected_shape#533",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.expected_shape(batch_size, n_batches)",
        "snippet": "    def expected_shape(batch_size, n_batches):\n        return (batch_size * n_batches, 4), (batch_size * n_batches, 3)",
        "begin_line": 533,
        "end_line": 534,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_warnings#576",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_warnings()",
        "snippet": "def test_warnings():\n    a = Input(shape=(3,), name='input_a')\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    model = Model([a, b], [a_2, b_2])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    @threadsafe_generator\n    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)),\n                    np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)),\n                    np.random.random((batch_sz, 3))])\n\n    with pytest.warns(Warning) as w:\n        out = model.fit_generator(gen_data(4),\n                                  steps_per_epoch=10,\n                                  use_multiprocessing=True,\n                                  workers=2)\n    warning_raised = any(['Sequence' in str(w_.message) for w_ in w])\n    assert warning_raised, 'No warning raised when using generator with processes.'\n\n    with pytest.warns(None) as w:\n        out = model.fit_generator(RandomSequence(3),\n                                  steps_per_epoch=4,\n                                  use_multiprocessing=True,\n                                  workers=2)\n    assert all(['Sequence' not in str(w_.message) for w_ in w]), (\n        'A warning was raised for Sequence.')",
        "begin_line": 576,
        "end_line": 614,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#593",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data(batch_sz)",
        "snippet": "    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)),\n                    np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)),\n                    np.random.random((batch_sz, 3))])",
        "begin_line": 593,
        "end_line": 598,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_sparse_inputs_targets#617",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_sparse_inputs_targets()",
        "snippet": "def test_sparse_inputs_targets():\n    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n    in1 = Input(shape=(3,))\n    in2 = Input(shape=(3,))\n    out1 = Dropout(0.5, name='dropout')(in1)\n    out2 = Dense(4, name='dense_1')(in2)\n    model = Model([in1, in2], [out1, out2])\n    model.predict(test_inputs, batch_size=2)\n    model.compile('rmsprop', 'mse')\n    model.fit(test_inputs, test_outputs,\n              epochs=1, batch_size=2, validation_split=0.5)\n    model.evaluate(test_inputs, test_outputs, batch_size=2)",
        "begin_line": 617,
        "end_line": 629,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_sparse_placeholder_fit#634",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_sparse_placeholder_fit()",
        "snippet": "def test_sparse_placeholder_fit():\n    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n    in1 = Input(shape=(3,))\n    in2 = Input(shape=(3,), sparse=True)\n    out1 = Dropout(0.5, name='dropout')(in1)\n    out2 = Dense(4, name='dense_1')(in2)\n    model = Model([in1, in2], [out1, out2])\n    model.predict(test_inputs, batch_size=2)\n    model.compile('rmsprop', 'mse')\n    model.fit(test_inputs, test_outputs,\n              epochs=1, batch_size=2, validation_split=0.5)\n    model.evaluate(test_inputs, test_outputs, batch_size=2)",
        "begin_line": 634,
        "end_line": 646,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_trainable_argument#649",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_trainable_argument()",
        "snippet": "def test_trainable_argument():\n    x = np.random.random((5, 3))\n    y = np.random.random((5, 2))\n\n    model = Sequential()\n    model.add(Dense(2, input_dim=3, trainable=False))\n    model.compile('rmsprop', 'mse')\n    out = model.predict(x)\n    model.train_on_batch(x, y)\n    out_2 = model.predict(x)\n    assert_allclose(out, out_2)\n\n    # test with nesting\n    inputs = Input(shape=(3,))\n    outputs = model(inputs)\n    model = Model(inputs, outputs)\n    model.compile('rmsprop', 'mse')\n    out = model.predict(x)\n    model.train_on_batch(x, y)\n    out_2 = model.predict(x)\n    assert_allclose(out, out_2)",
        "begin_line": 649,
        "end_line": 669,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_with_list_as_targets#672",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_with_list_as_targets()",
        "snippet": "def test_with_list_as_targets():\n    model = Sequential()\n    model.add(Dense(1, input_dim=3, trainable=False))\n    model.compile('rmsprop', 'mse')\n\n    x = np.random.random((2, 3))\n    y = [0, 1]\n    model.train_on_batch(x, y)",
        "begin_line": 672,
        "end_line": 679,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_not_failing#682",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_not_failing()",
        "snippet": "def test_check_not_failing():\n    a = np.random.random((2, 1, 3))\n    training_utils.check_loss_and_target_compatibility(\n        [a], [losses.categorical_crossentropy], [a.shape])\n    training_utils.check_loss_and_target_compatibility(\n        [a], [losses.categorical_crossentropy], [(2, None, 3)])",
        "begin_line": 682,
        "end_line": 687,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_last_is_one#690",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_last_is_one()",
        "snippet": "def test_check_last_is_one():\n    a = np.random.random((2, 3, 1))\n    with pytest.raises(ValueError) as exc:\n        training_utils.check_loss_and_target_compatibility(\n            [a], [losses.categorical_crossentropy], [a.shape])\n\n    assert 'You are passing a target array' in str(exc)",
        "begin_line": 690,
        "end_line": 696,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_bad_shape#699",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_bad_shape()",
        "snippet": "def test_check_bad_shape():\n    a = np.random.random((2, 3, 5))\n    with pytest.raises(ValueError) as exc:\n        training_utils.check_loss_and_target_compatibility(\n            [a], [losses.categorical_crossentropy], [(2, 3, 6)])\n\n    assert 'targets to have the same shape' in str(exc)",
        "begin_line": 699,
        "end_line": 705,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_input_feed_tensor#710",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_input_feed_tensor()",
        "snippet": "def test_model_with_input_feed_tensor():\n    \"\"\"We test building a model with a TF variable as input.\n    We should be able to call fit, evaluate, predict,\n    by only passing them data for the placeholder inputs\n    in the model.\n    \"\"\"\n    import tensorflow as tf\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    model = Model([a, b], [a_2, b_2])\n    model.summary()\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n    model.compile(optimizer, loss, metrics=['mean_squared_error'],\n                  loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    # test train_on_batch\n    out = model.train_on_batch(input_b_np,\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({'input_b': input_b_np},\n                               [output_a_np, output_b_np])\n    out = model.test_on_batch({'input_b': input_b_np},\n                              [output_a_np, output_b_np])\n    out = model.predict_on_batch({'input_b': input_b_np})\n\n    # test fit\n    out = model.fit({'input_b': input_b_np},\n                    [output_a_np, output_b_np], epochs=1, batch_size=10)\n    out = model.fit(input_b_np,\n                    [output_a_np, output_b_np], epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate({'input_b': input_b_np},\n                         [output_a_np, output_b_np], batch_size=10)\n    out = model.evaluate(input_b_np,\n                         [output_a_np, output_b_np], batch_size=10)\n\n    # test predict\n    out = model.predict({'input_b': input_b_np}, batch_size=10)\n    out = model.predict(input_b_np, batch_size=10)\n    assert len(out) == 2\n\n    # Now test a model with a single input\n    # i.e. we don't pass any data to fit the model.\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    a_2 = Dense(4, name='dense_1')(a)\n    a_2 = Dropout(0.5, name='dropout')(a_2)\n    model = Model(a, a_2)\n    model.summary()\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    model.compile(optimizer, loss, metrics=['mean_squared_error'])\n\n    # test train_on_batch\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.test_on_batch(None,\n                              output_a_np)\n    out = model.predict_on_batch(None)\n    out = model.train_on_batch([],\n                               output_a_np)\n    out = model.train_on_batch({},\n                               output_a_np)\n\n    # test fit\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n\n    # test predict\n    out = model.predict(None, steps=3)\n    out = model.predict(None, steps=3)\n    assert out.shape == (10 * 3, 4)\n\n    # Same, without learning phase\n    # i.e. we don't pass any data to fit the model.\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    a_2 = Dense(4, name='dense_1')(a)\n    model = Model(a, a_2)\n    model.summary()\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    model.compile(optimizer, loss, metrics=['mean_squared_error'])\n\n    # test train_on_batch\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.test_on_batch(None,\n                              output_a_np)\n    out = model.predict_on_batch(None)\n    out = model.train_on_batch([],\n                               output_a_np)\n    out = model.train_on_batch({},\n                               output_a_np)\n\n    # test fit\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n\n    # test predict\n    out = model.predict(None, steps=3)\n    out = model.predict(None, steps=3)\n    assert out.shape == (10 * 3, 4)",
        "begin_line": 710,
        "end_line": 848,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_partial_loss#851",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_partial_loss()",
        "snippet": "def test_model_with_partial_loss():\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    a_3 = dp(a_2)\n    model = Model(a, [a_2, a_3])\n\n    optimizer = 'rmsprop'\n    loss = {'dropout': 'mse'}\n    model.compile(optimizer, loss, metrics=['mae'])\n\n    input_a_np = np.random.random((10, 3))\n    output_a_np = np.random.random((10, 4))\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, output_a_np)\n    out = model.test_on_batch(input_a_np, output_a_np)\n    # fit\n    out = model.fit(input_a_np, [output_a_np])\n    # evaluate\n    out = model.evaluate(input_a_np, [output_a_np])\n\n    # Same without dropout.\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1')(a)\n    a_3 = Dense(4, name='dense_2')(a_2)\n    model = Model(a, [a_2, a_3])\n\n    optimizer = 'rmsprop'\n    loss = {'dense_2': 'mse'}\n    model.compile(optimizer, loss, metrics={'dense_1': 'mae'})\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, output_a_np)\n    out = model.test_on_batch(input_a_np, output_a_np)\n    # fit\n    out = model.fit(input_a_np, [output_a_np])\n    # evaluate\n    out = model.evaluate(input_a_np, [output_a_np])",
        "begin_line": 851,
        "end_line": 889,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_external_loss#894",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_external_loss()",
        "snippet": "def test_model_with_external_loss():\n    # None loss, only regularization loss.\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1',\n                kernel_regularizer='l1',\n                bias_regularizer='l2')(a)\n    dp = Dropout(0.5, name='dropout')\n    a_3 = dp(a_2)\n\n    model = Model(a, [a_2, a_3])\n\n    optimizer = 'rmsprop'\n    loss = None\n    model.compile(optimizer, loss, metrics=['mae'])\n\n    input_a_np = np.random.random((10, 3))\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, None)\n    out = model.test_on_batch(input_a_np, None)\n    # fit\n    out = model.fit(input_a_np, None)\n    # evaluate\n    out = model.evaluate(input_a_np, None)\n\n    # No dropout, external loss.\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1')(a)\n    a_3 = Dense(4, name='dense_2')(a)\n\n    model = Model(a, [a_2, a_3])\n    model.add_loss(K.mean(a_3 + a_2))\n\n    optimizer = 'rmsprop'\n    loss = None\n    model.compile(optimizer, loss, metrics=['mae'])\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, None)\n    out = model.test_on_batch(input_a_np, None)\n    # fit\n    out = model.fit(input_a_np, None)\n    # evaluate\n    out = model.evaluate(input_a_np, None)\n\n    # Test fit with no external data at all.\n    if K.backend() == 'tensorflow':\n        import tensorflow as tf\n\n        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n        a_2 = Dense(4, name='dense_1')(a)\n        a_2 = Dropout(0.5, name='dropout')(a_2)\n        model = Model(a, a_2)\n        model.add_loss(K.mean(a_2))\n\n        model.compile(optimizer='rmsprop',\n                      loss=None,\n                      metrics=['mean_squared_error'])\n\n        # test train_on_batch\n        out = model.train_on_batch(None, None)\n        out = model.test_on_batch(None, None)\n        out = model.predict_on_batch(None)\n\n        # test fit\n        with pytest.raises(ValueError):\n            out = model.fit(None, None, epochs=1, batch_size=10)\n        out = model.fit(None, None, epochs=1, steps_per_epoch=1)\n\n        # define a generator to produce x=None and y=None\n        @threadsafe_generator\n        def data_tensors_generator():\n            while True:\n                yield (None, None)\n\n        generator = data_tensors_generator()\n\n        # test fit_generator for framework-native data tensors\n        out = model.fit_generator(generator, epochs=1,\n                                  steps_per_epoch=3)\n\n        # test evaluate_generator for framework-native data tensors\n        out = model.evaluate_generator(generator, steps=3)\n\n        # test fit with validation data\n        with pytest.raises(ValueError):\n            out = model.fit(None, None,\n                            epochs=1,\n                            steps_per_epoch=None,\n                            validation_steps=2)\n        out = model.fit(None, None,\n                        epochs=1,\n                        steps_per_epoch=2,\n                        validation_steps=2)\n\n        # test evaluate\n        with pytest.raises(ValueError):\n            out = model.evaluate(None, None, batch_size=10)\n        out = model.evaluate(None, None, steps=3)\n\n        # test predict\n        with pytest.raises(ValueError):\n            out = model.predict(None, batch_size=10)\n        out = model.predict(None, steps=3)\n        assert out.shape == (10 * 3, 4)\n\n        # Test multi-output model without external data.\n        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n        a_1 = Dense(4, name='dense_1')(a)\n        a_2 = Dropout(0.5, name='dropout')(a_1)\n        model = Model(a, [a_1, a_2])\n        model.add_loss(K.mean(a_2))\n        model.compile(optimizer='rmsprop',\n                      loss=None,\n                      metrics=['mean_squared_error'])\n\n        # test train_on_batch\n        out = model.train_on_batch(None, None)\n        out = model.test_on_batch(None, None)\n        out = model.predict_on_batch(None)\n\n        # test fit\n        with pytest.raises(ValueError):\n            out = model.fit(None, None, epochs=1, batch_size=10)\n        out = model.fit(None, None, epochs=1, steps_per_epoch=1)\n\n        # test fit with validation data\n        with pytest.raises(ValueError):\n            out = model.fit(None, None,\n                            epochs=1,\n                            steps_per_epoch=None,\n                            validation_steps=2)\n        out = model.fit(None, None,\n                        epochs=1,\n                        steps_per_epoch=2,\n                        validation_steps=2)\n\n        # test evaluate\n        with pytest.raises(ValueError):\n            out = model.evaluate(None, None, batch_size=10)\n        out = model.evaluate(None, None, steps=3)\n\n        # test predict\n        with pytest.raises(ValueError):\n            out = model.predict(None, batch_size=10)\n        out = model.predict(None, steps=3)\n        assert len(out) == 2\n        assert out[0].shape == (10 * 3, 4)\n        assert out[1].shape == (10 * 3, 4)",
        "begin_line": 894,
        "end_line": 1042,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.data_tensors_generator#965",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.data_tensors_generator()",
        "snippet": "        def data_tensors_generator():\n            while True:\n                yield (None, None)",
        "begin_line": 965,
        "end_line": 967,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_target_tensors#1045",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_target_tensors()",
        "snippet": "def test_target_tensors():\n    # single-output, as list\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(4, input_shape=(4,), name='dense'))\n    input_val = np.random.random((10, 4))\n    target_val = np.random.random((10, 4))\n    target = keras.backend.variable(target_val)\n    model.compile(optimizer='rmsprop', loss='mse', target_tensors=[target])\n    model.train_on_batch(input_val, None)\n\n    # single-output, as dict\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors={'dense': target})\n    model.train_on_batch(input_val, None)\n\n    # single-output, as tensor\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors=target)\n    model.train_on_batch(input_val, None)\n\n    # test invalid arguments\n    with pytest.raises(TypeError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=set())\n    with pytest.raises(ValueError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=[target, target])\n    with pytest.raises(ValueError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors={'dense2': None})\n    with pytest.raises(ValueError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=[target])\n        model.train_on_batch(input_val, target_val)\n\n    # multi-output, as list\n    input_val = np.random.random((10, 4))\n    target_val_a = np.random.random((10, 4))\n    target_val_b = np.random.random((10, 4))\n    target_a = keras.backend.variable(target_val_a)\n    target_b = keras.backend.variable(target_val_b)\n\n    inputs = keras.layers.Input(shape=(4,))\n    output_a = keras.layers.Dense(4, name='dense_a')(inputs)\n    output_b = keras.layers.Dense(4, name='dense_b')(inputs)\n    model = keras.models.Model(inputs, [output_a, output_b])\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors=[target_a, target_b])\n    model.train_on_batch(input_val, None)\n\n    # multi-output, as dict\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors={'dense_a': target_a,\n                                  'dense_b': target_b})\n    model.train_on_batch(input_val, None)\n\n    # multi-output, not enough target tensors when `target_tensors` is not a dict\n    with pytest.raises(ValueError,\n                       match='When passing a list as `target_tensors`, it should '\n                             'have one entry per model output. The model has \\d '\n                             'outputs, but you passed target_tensors='):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=[target_a])\n    with pytest.raises(ValueError,\n                       match='The model has \\d outputs, but you passed a single '\n                             'tensor as `target_tensors`. Expected a list or '\n                             'a dict of tensors.'):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=target_a)\n\n    # test with sample weights\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors=[target_a, target_b])\n    model.train_on_batch(input_val, None,\n                         sample_weight={'dense_a': np.random.random((10,))})",
        "begin_line": 1045,
        "end_line": 1119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_custom_target_tensors#1122",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_custom_target_tensors()",
        "snippet": "def test_model_custom_target_tensors():\n    a = Input(shape=(3,), name='input_a')\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    y = K.placeholder([10, 4], name='y')\n    y1 = K.placeholder([10, 3], name='y1')\n    y2 = K.placeholder([7, 5], name='y2')\n    model = Model([a, b], [a_2, b_2])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n\n    # test list of target tensors\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                      sample_weight_mode=None, target_tensors=[y, y1, y2])\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None, target_tensors=[y, y1])\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               {y: np.random.random((10, 4)),\n                                y1: np.random.random((10, 3))})\n    # test dictionary of target_tensors\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss,\n                      metrics=[],\n                      loss_weights=loss_weights,\n                      sample_weight_mode=None,\n                      target_tensors={'does_not_exist': y2})\n    # test dictionary of target_tensors\n    model.compile(optimizer, loss,\n                  metrics=[],\n                  loss_weights=loss_weights,\n                  sample_weight_mode=None,\n                  target_tensors={'dense_1': y, 'dropout': y1})\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               {y: np.random.random((10, 4)),\n                                y1: np.random.random((10, 3))})\n\n    if K.backend() == 'tensorflow':\n        import tensorflow as tf\n        # test with custom TF placeholder as target\n        pl_target_a = tf.placeholder('float32', shape=(None, 4))\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors={'dense_1': pl_target_a})\n        model.train_on_batch([input_a_np, input_b_np],\n                             [output_a_np, output_b_np])",
        "begin_line": 1122,
        "end_line": 1180,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_trainable_weights_count_consistency#1185",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_trainable_weights_count_consistency()",
        "snippet": "def test_trainable_weights_count_consistency():\n    \"\"\"Tests the trainable weights consistency check of Model.\n\n    This verifies that a warning is shown if model.trainable is modified\n    and the model is summarized/run without a new call to .compile()\n\n    Reproduce issue #8121\n    \"\"\"\n    a = Input(shape=(3,), name='input_a')\n    model1 = Model(inputs=a, outputs=Dense(1)(a))\n\n    model1.trainable = False\n    b = Input(shape=(3,), name='input_b')\n    y = model1(b)\n    model2 = Model(inputs=b, outputs=Dense(1)(y))\n\n    model2.compile(optimizer='adam', loss='mse')\n\n    model1.trainable = True\n\n    # Should warn on .summary()\n    with pytest.warns(UserWarning) as w:\n        model2.summary()\n    warning_raised = any(['Discrepancy' in str(w_.message) for w_ in w])\n    assert warning_raised, (\n        'No warning raised when trainable is modified without .compile.')\n\n    # And on .fit()\n    with pytest.warns(UserWarning) as w:\n        model2.fit(x=np.zeros((5, 3)), y=np.zeros((5, 1)))\n    warning_raised = any(['Discrepancy' in str(w_.message) for w_ in w])\n    assert warning_raised, (\n        'No warning raised when trainable is modified without .compile.')\n\n    # And shouldn't warn if we recompile\n    model2.compile(optimizer='adam', loss='mse')\n    with pytest.warns(None) as w:\n        model2.summary()\n    assert len(w) == 0, (\n        'Warning raised even when .compile() is called after modifying .trainable')",
        "begin_line": 1185,
        "end_line": 1224,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_pandas_dataframe#1227",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_pandas_dataframe()",
        "snippet": "def test_pandas_dataframe():\n    input_a = Input(shape=(3,), name='input_a')\n    input_b = Input(shape=(3,), name='input_b')\n\n    x = Dense(4, name='dense_1')(input_a)\n    y = Dense(3, name='desne_2')(input_b)\n\n    model_1 = Model(inputs=input_a, outputs=x)\n    model_2 = Model(inputs=[input_a, input_b], outputs=[x, y])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n\n    model_1.compile(optimizer=optimizer, loss=loss)\n    model_2.compile(optimizer=optimizer, loss=loss)\n\n    input_a_df = pd.DataFrame(np.random.random((10, 3)))\n    input_b_df = pd.DataFrame(np.random.random((10, 3)))\n\n    output_a_df = pd.DataFrame(np.random.random((10, 4)))\n    output_b_df = pd.DataFrame(np.random.random((10, 3)))\n\n    model_1.fit(input_a_df,\n                output_a_df)\n    model_2.fit([input_a_df, input_b_df],\n                [output_a_df, output_b_df])\n    model_1.fit([input_a_df],\n                [output_a_df])\n    model_1.fit({'input_a': input_a_df},\n                output_a_df)\n    model_2.fit({'input_a': input_a_df, 'input_b': input_b_df},\n                [output_a_df, output_b_df])\n\n    model_1.predict(input_a_df)\n    model_2.predict([input_a_df, input_b_df])\n    model_1.predict([input_a_df])\n    model_1.predict({'input_a': input_a_df})\n    model_2.predict({'input_a': input_a_df, 'input_b': input_b_df})\n\n    model_1.predict_on_batch(input_a_df)\n    model_2.predict_on_batch([input_a_df, input_b_df])\n    model_1.predict_on_batch([input_a_df])\n    model_1.predict_on_batch({'input_a': input_a_df})\n    model_2.predict_on_batch({'input_a': input_a_df, 'input_b': input_b_df})\n\n    model_1.evaluate(input_a_df,\n                     output_a_df)\n    model_2.evaluate([input_a_df, input_b_df],\n                     [output_a_df, output_b_df])\n    model_1.evaluate([input_a_df],\n                     [output_a_df])\n    model_1.evaluate({'input_a': input_a_df},\n                     output_a_df)\n    model_2.evaluate({'input_a': input_a_df, 'input_b': input_b_df},\n                     [output_a_df, output_b_df])\n\n    model_1.train_on_batch(input_a_df,\n                           output_a_df)\n    model_2.train_on_batch([input_a_df, input_b_df],\n                           [output_a_df, output_b_df])\n    model_1.train_on_batch([input_a_df],\n                           [output_a_df])\n    model_1.train_on_batch({'input_a': input_a_df},\n                           output_a_df)\n    model_2.train_on_batch({'input_a': input_a_df, 'input_b': input_b_df},\n                           [output_a_df, output_b_df])\n\n    model_1.test_on_batch(input_a_df,\n                          output_a_df)\n    model_2.test_on_batch([input_a_df, input_b_df],\n                          [output_a_df, output_b_df])\n    model_1.test_on_batch([input_a_df],\n                          [output_a_df])\n    model_1.test_on_batch({'input_a': input_a_df},\n                          output_a_df)\n    model_2.test_on_batch({'input_a': input_a_df, 'input_b': input_b_df},\n                          [output_a_df, output_b_df])",
        "begin_line": 1227,
        "end_line": 1303,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_training_and_eval_methods_on_symbolic_tensors_single_io#1311",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_training_and_eval_methods_on_symbolic_tensors_single_io()",
        "snippet": "def test_training_and_eval_methods_on_symbolic_tensors_single_io():\n    x = keras.layers.Input(shape=(3,), name='input')\n    y = keras.layers.Dense(4, name='dense')(x)\n    model = keras.Model(x, y)\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    metrics = ['mae']\n    model.compile(optimizer, loss, metrics=metrics)\n\n    inputs = keras.backend.zeros(shape=(10, 3))\n    targets = keras.backend.zeros(shape=(10, 4))\n\n    model.fit(inputs, targets, epochs=1, steps_per_epoch=2, verbose=0)\n    model.evaluate(inputs, targets, steps=2, verbose=0)\n    model.predict(inputs, steps=2)\n    model.train_on_batch(inputs, targets)\n    model.test_on_batch(inputs, targets)\n    model.fit(inputs, targets,\n              epochs=1, steps_per_epoch=2, verbose=1,\n              validation_data=(inputs, targets), validation_steps=2)",
        "begin_line": 1311,
        "end_line": 1331,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_training_and_eval_methods_on_symbolic_tensors_multi_io#1339",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_training_and_eval_methods_on_symbolic_tensors_multi_io()",
        "snippet": "def test_training_and_eval_methods_on_symbolic_tensors_multi_io():\n    a = keras.layers.Input(shape=(3,), name='input_a')\n    b = keras.layers.Input(shape=(3,), name='input_b')\n\n    dense = keras.layers.Dense(4, name='dense')\n    c = dense(a)\n    d = dense(b)\n    e = keras.layers.Dropout(0.5, name='dropout')(c)\n\n    model = keras.models.Model([a, b], [d, e])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n    metrics = ['mae']\n    model.compile(optimizer, loss, metrics=metrics, loss_weights=loss_weights)\n\n    input_a_tf = keras.backend.zeros(shape=(10, 3))\n    input_b_tf = keras.backend.zeros(shape=(10, 3))\n\n    output_d_tf = keras.backend.zeros(shape=(10, 4))\n    output_e_tf = keras.backend.zeros(shape=(10, 4))\n\n    model.fit(\n        [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n        epochs=1,\n        steps_per_epoch=2,\n        verbose=0)\n    with pytest.raises(ValueError) as excinfo:\n        model.fit(\n            [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n            epochs=1,\n            batch_size=5,\n            verbose=0)\n    assert 'should specify the `steps_per_epoch`' in str(excinfo.value)\n    model.train_on_batch([input_a_tf, input_b_tf], [output_d_tf, output_e_tf])\n\n    # Test with dictionary inputs\n    model.fit(\n        {'input_a': input_a_tf,\n         'input_b': input_b_tf},\n        {'dense': output_d_tf,\n         'dropout': output_e_tf},\n        epochs=1,\n        steps_per_epoch=2,\n        verbose=0)\n    model.fit(\n        {'input_a': input_a_tf,\n         'input_b': input_b_tf},\n        {'dense': output_d_tf,\n         'dropout': output_e_tf},\n        validation_data=({'input_a': input_a_tf,\n                          'input_b': input_b_tf},\n                         {'dense': output_d_tf,\n                          'dropout': output_e_tf}),\n        epochs=1,\n        steps_per_epoch=2,\n        validation_steps=2,\n        verbose=0)\n    model.train_on_batch(\n        {'input_a': input_a_tf,\n         'input_b': input_b_tf},\n        {'dense': output_d_tf,\n         'dropout': output_e_tf})\n\n    # Test with validation data\n    model.fit(\n        [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n        validation_data=([input_a_tf, input_b_tf],\n                         [output_d_tf, output_e_tf]),\n        epochs=1,\n        steps_per_epoch=2,\n        validation_steps=2,\n        verbose=0)\n    # Test with validation split\n    with pytest.raises(ValueError) as excinfo:\n        model.fit(\n            [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n            epochs=2,\n            steps_per_epoch=2,\n            verbose=0,\n            validation_split=0.2,\n            validation_steps=2)\n    assert 'you cannot use `validation_split`' in str(excinfo.value)\n\n    # Test evaluation / prediction methods\n    model.evaluate([input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n                   steps=2, verbose=0)\n    model.predict([input_a_tf, input_b_tf], steps=2)\n    model.test_on_batch([input_a_tf, input_b_tf], [output_d_tf, output_e_tf])",
        "begin_line": 1339,
        "end_line": 1428,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_crossentropy_losses_channels_first#1431",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_crossentropy_losses_channels_first()",
        "snippet": "def test_model_with_crossentropy_losses_channels_first():\n    \"\"\"Tests use of all crossentropy losses with `channels_first`.\n\n    Tests `sparse_categorical_crossentropy`, `categorical_crossentropy`,\n    and `binary_crossentropy`.\n    Verifies that evaluate gives the same result with either\n    `channels_first` or `channels_last` image_data_format.\n    Tests PR #9715.\n    \"\"\"\n\n    def prepare_simple_model(input_tensor, loss_name, target):\n        axis = 1 if K.image_data_format() == 'channels_first' else -1\n        if loss_name == 'sparse_categorical_crossentropy':\n            loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(\n                y_true, y_pred, axis=axis)\n            num_channels = np.amax(target) + 1\n            activation = 'softmax'\n        elif loss_name == 'categorical_crossentropy':\n            loss = lambda y_true, y_pred: K.categorical_crossentropy(\n                y_true, y_pred, axis=axis)\n            num_channels = target.shape[axis]\n            activation = 'softmax'\n        elif loss_name == 'binary_crossentropy':\n            loss = lambda y_true, y_pred: K.binary_crossentropy(y_true, y_pred)\n            num_channels = target.shape[axis]\n            activation = 'sigmoid'\n        predictions = Conv2D(num_channels, 1, activation=activation,\n                             kernel_initializer='ones',\n                             bias_initializer='ones')(input_tensor)\n        simple_model = Model(inputs=input_tensor, outputs=predictions)\n        simple_model.compile(optimizer='rmsprop', loss=loss)\n        return simple_model\n\n    losses_to_test = ['sparse_categorical_crossentropy',\n                      'categorical_crossentropy', 'binary_crossentropy']\n\n    data_channels_first = np.array([[[[8., 7.1, 0.], [4.5, 2.6, 0.55],\n                                      [0.9, 4.2, 11.2]]]], dtype=np.float32)\n    # Labels for testing 4-class sparse_categorical_crossentropy, 4-class\n    # categorical_crossentropy, and 2-class binary_crossentropy:\n    labels_channels_first = [np.array([[[[0, 1, 3], [2, 1, 0], [2, 2, 1]]]]),\n                             np.array([[[[0, 1, 0], [0, 1, 0], [0, 0, 0]],\n                                        [[1, 0, 0], [0, 0, 1], [0, 1, 0]],\n                                        [[0, 0, 0], [1, 0, 0], [0, 0, 1]],\n                                        [[0, 0, 1], [0, 0, 0], [1, 0, 0]]]]),\n                             np.array([[[[0, 1, 0], [0, 1, 0], [0, 0, 1]],\n                                        [[1, 0, 1], [1, 0, 1], [1, 1, 0]]]])]\n    # Compute one loss for each loss function in the list `losses_to_test`:\n    loss_channels_last = [0., 0., 0.]\n    loss_channels_first = [0., 0., 0.]\n\n    old_data_format = K.image_data_format()\n\n    # Evaluate a simple network with channels last, with all three loss\n    # functions:\n    K.set_image_data_format('channels_last')\n    data = np.moveaxis(data_channels_first, 1, -1)\n    for index, loss_function in enumerate(losses_to_test):\n        labels = np.moveaxis(labels_channels_first[index], 1, -1)\n        inputs = Input(shape=(3, 3, 1))\n        model = prepare_simple_model(inputs, loss_function, labels)\n        loss_channels_last[index] = model.evaluate(x=data, y=labels,\n                                                   batch_size=1, verbose=0)\n\n    # Evaluate the same network with channels first, with all three loss\n    # functions:\n    K.set_image_data_format('channels_first')\n    data = data_channels_first\n    for index, loss_function in enumerate(losses_to_test):\n        labels = labels_channels_first[index]\n        inputs = Input(shape=(1, 3, 3))\n        model = prepare_simple_model(inputs, loss_function, labels)\n        loss_channels_first[index] = model.evaluate(x=data, y=labels,\n                                                    batch_size=1, verbose=0)\n\n    K.set_image_data_format(old_data_format)\n\n    assert_allclose(loss_channels_first, loss_channels_last,\n                    err_msg='{}{}'.format('Computed different losses for ',\n                                          'channels_first and channels_last.'))",
        "begin_line": 1431,
        "end_line": 1510,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.prepare_simple_model#1441",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.prepare_simple_model(input_tensor, loss_name, target)",
        "snippet": "    def prepare_simple_model(input_tensor, loss_name, target):\n        axis = 1 if K.image_data_format() == 'channels_first' else -1\n        if loss_name == 'sparse_categorical_crossentropy':\n            loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(\n                y_true, y_pred, axis=axis)\n            num_channels = np.amax(target) + 1\n            activation = 'softmax'\n        elif loss_name == 'categorical_crossentropy':\n            loss = lambda y_true, y_pred: K.categorical_crossentropy(\n                y_true, y_pred, axis=axis)\n            num_channels = target.shape[axis]\n            activation = 'softmax'\n        elif loss_name == 'binary_crossentropy':\n            loss = lambda y_true, y_pred: K.binary_crossentropy(y_true, y_pred)\n            num_channels = target.shape[axis]\n            activation = 'sigmoid'\n        predictions = Conv2D(num_channels, 1, activation=activation,\n                             kernel_initializer='ones',\n                             bias_initializer='ones')(input_tensor)\n        simple_model = Model(inputs=input_tensor, outputs=predictions)\n        simple_model.compile(optimizer='rmsprop', loss=loss)\n        return simple_model",
        "begin_line": 1441,
        "end_line": 1462,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_dynamic_set_inputs#1513",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_dynamic_set_inputs()",
        "snippet": "def test_dynamic_set_inputs():\n    model = Sequential()\n    model.add(Dense(16, input_dim=32))\n    model.add(Activation('relu'))\n\n    model2 = Sequential()\n    model2.add(model.layers[-1])\n    model2.add(Dense(8))\n    preds2 = model2.predict([np.random.random((1, 32))])\n    assert preds2.shape == (1, 8)\n\n    model3 = Model(inputs=model.inputs, outputs=model.outputs)\n    with pytest.raises(ValueError):\n        model3._set_inputs(model.inputs)\n\n    model3.inputs = None\n    model3._set_inputs(model.inputs)\n    preds3 = model3.predict([np.random.random((1, 32))])\n    assert preds3.shape == (1, 16)\n\n    model3.inputs = None\n    model3._set_inputs(model.input)\n    preds3 = model3.predict(np.random.random((1, 32)))\n    assert preds3.shape == (1, 16)\n\n    aux_input = Input(shape=(5,), name='aux_input')\n    aux_model = Dense(3)(aux_input)\n    model4 = Model(inputs=model.inputs + [aux_input],\n                   outputs=Concatenate()(model.outputs + [aux_model]))\n    model4.inputs = None\n    model4._set_inputs(model.inputs + [aux_input])\n    preds4 = model4.predict([np.random.random((1, 32)),\n                             np.random.random((1, 5))])\n    assert preds4.shape == (1, 19)",
        "begin_line": 1513,
        "end_line": 1546,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.conftest.clear_session_after_test#6",
        "src_path": "tests/conftest.py",
        "class_name": "tests.conftest",
        "signature": "tests.conftest.clear_session_after_test()",
        "snippet": "def clear_session_after_test():\n    \"\"\"Test wrapper to clean up after TensorFlow and CNTK tests.\n\n    This wrapper runs for all the tests in the keras test suite.\n    \"\"\"\n    yield\n    if K.backend() == 'tensorflow' or K.backend() == 'cntk':\n        K.clear_session()",
        "begin_line": 6,
        "end_line": 13,
        "comment": "",
        "is_bug": false
    }
]