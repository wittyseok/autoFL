[
    {
        "name": "tests.keras.test_callbacks.test_TerminateOnNaN#35",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TerminateOnNaN()",
        "snippet": "def test_TerminateOnNaN():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    cbks = [callbacks.TerminateOnNaN()]\n    model = Sequential()\n    initializer = initializers.Constant(value=1e5)\n    for _ in range(5):\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu',\n                        kernel_initializer=initializer))\n    model.add(Dense(num_classes, activation='linear'))\n    model.compile(loss='mean_squared_error',\n                  optimizer='rmsprop')\n\n    # case 1 fit\n    history = model.fit(X_train, y_train, batch_size=batch_size,\n                        validation_data=(X_test, y_test), callbacks=cbks, epochs=20)\n    loss = history.history['loss']\n    assert len(loss) == 1\n    assert loss[0] == np.inf\n\n    # case 2 fit_generator\n    def data_generator():\n        max_batch_index = len(X_train) // batch_size\n        i = 0\n        while 1:\n            yield (X_train[i * batch_size: (i + 1) * batch_size],\n                   y_train[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index\n    history = model.fit_generator(data_generator(),\n                                  len(X_train),\n                                  validation_data=(X_test, y_test),\n                                  callbacks=cbks,\n                                  epochs=20)\n    loss = history.history['loss']\n    assert len(loss) == 1\n    assert loss[0] == np.inf or np.isnan(loss[0])",
        "begin_line": 35,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#63",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator()",
        "snippet": "    def data_generator():\n        max_batch_index = len(X_train) // batch_size\n        i = 0\n        while 1:\n            yield (X_train[i * batch_size: (i + 1) * batch_size],\n                   y_train[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index",
        "begin_line": 63,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_stop_training_csv#82",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_stop_training_csv(tmpdir)",
        "snippet": "def test_stop_training_csv(tmpdir):\n    np.random.seed(1337)\n    fp = str(tmpdir / 'test.csv')\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    cbks = [callbacks.TerminateOnNaN(), callbacks.CSVLogger(fp)]\n    model = Sequential()\n    for _ in range(5):\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='linear'))\n    model.compile(loss='mean_squared_error',\n                  optimizer='rmsprop')\n\n    def data_generator():\n        i = 0\n        max_batch_index = len(X_train) // batch_size\n        tot = 0\n        while 1:\n            if tot > 3 * len(X_train):\n                yield np.ones([batch_size, input_dim]) * np.nan, np.ones([batch_size, num_classes]) * np.nan\n            else:\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            tot += 1\n            i = i % max_batch_index\n\n    history = model.fit_generator(data_generator(),\n                                  len(X_train) // batch_size,\n                                  validation_data=(X_test, y_test),\n                                  callbacks=cbks,\n                                  epochs=20)\n    loss = history.history['loss']\n    assert len(loss) > 1\n    assert loss[-1] == np.inf or np.isnan(loss[-1])\n\n    values = []\n    with open(fp) as f:\n        for x in reader(f):\n            values.append(x)\n\n    assert 'nan' in values[-1], 'The last epoch was not logged.'\n    os.remove(fp)",
        "begin_line": 82,
        "end_line": 130,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#101",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator()",
        "snippet": "    def data_generator():\n        i = 0\n        max_batch_index = len(X_train) // batch_size\n        tot = 0\n        while 1:\n            if tot > 3 * len(X_train):\n                yield np.ones([batch_size, input_dim]) * np.nan, np.ones([batch_size, num_classes]) * np.nan\n            else:\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            tot += 1\n            i = i % max_batch_index",
        "begin_line": 101,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_ModelCheckpoint#134",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_ModelCheckpoint(tmpdir)",
        "snippet": "def test_ModelCheckpoint(tmpdir):\n    np.random.seed(1337)\n    filepath = str(tmpdir / 'checkpoint.h5')\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    # case 1\n    monitor = 'val_loss'\n    save_best_only = False\n    mode = 'auto'\n\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 2\n    mode = 'min'\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 3\n    mode = 'max'\n    monitor = 'val_acc'\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 4\n    save_best_only = True\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 5\n    save_best_only = False\n    period = 2\n    mode = 'auto'\n    filepath = 'checkpoint.{epoch:02d}.h5'\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode,\n                                      period=period)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=4)\n    assert os.path.isfile(filepath.format(epoch=2))\n    assert os.path.isfile(filepath.format(epoch=4))\n    assert not os.path.exists(filepath.format(epoch=1))\n    assert not os.path.exists(filepath.format(epoch=3))\n    os.remove(filepath.format(epoch=2))\n    os.remove(filepath.format(epoch=4))\n    assert not tmpdir.listdir()",
        "begin_line": 134,
        "end_line": 207,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_EarlyStopping#211",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_EarlyStopping()",
        "snippet": "def test_EarlyStopping():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    mode = 'max'\n    monitor = 'val_acc'\n    patience = 0\n    cbks = [callbacks.EarlyStopping(patience=patience, monitor=monitor, mode=mode)]\n    history = model.fit(X_train, y_train, batch_size=batch_size,\n                        validation_data=(X_test, y_test), callbacks=cbks, epochs=20)\n\n    mode = 'auto'\n    monitor = 'val_acc'\n    patience = 2\n    cbks = [callbacks.EarlyStopping(patience=patience, monitor=monitor, mode=mode)]\n    history = model.fit(X_train, y_train, batch_size=batch_size,\n                        validation_data=(X_test, y_test), callbacks=cbks, epochs=20)",
        "begin_line": 211,
        "end_line": 238,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_EarlyStopping_reuse#242",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_EarlyStopping_reuse()",
        "snippet": "def test_EarlyStopping_reuse():\n    np.random.seed(1337)\n    patience = 3\n    data = np.random.random((100, 1))\n    labels = np.where(data > 0.5, 1, 0)\n    model = Sequential((\n        Dense(1, input_dim=1, activation='relu'),\n        Dense(1, activation='sigmoid'),\n    ))\n    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n    stopper = callbacks.EarlyStopping(monitor='acc', patience=patience)\n    weights = model.get_weights()\n\n    hist = model.fit(data, labels, callbacks=[stopper], epochs=20)\n    assert len(hist.epoch) >= patience\n\n    # This should allow training to go for at least `patience` epochs\n    model.set_weights(weights)\n    hist = model.fit(data, labels, callbacks=[stopper], epochs=20)\n    assert len(hist.epoch) >= patience",
        "begin_line": 242,
        "end_line": 261,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_EarlyStopping_patience#265",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_EarlyStopping_patience()",
        "snippet": "def test_EarlyStopping_patience():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n\n        def get_weights(self):\n            return []\n\n        def set_weights(self, weights):\n            pass\n\n    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)\n    early_stop.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040, 0.1019]\n\n    # Should stop after epoch 3, as the loss has not improved after patience=2 epochs.\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    assert epochs_trained == 3",
        "begin_line": 265,
        "end_line": 292,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.test_EarlyStopping_patience#265",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.test_EarlyStopping_patience()",
        "snippet": "def test_EarlyStopping_patience():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n\n        def get_weights(self):\n            return []\n\n        def set_weights(self, weights):\n            pass\n\n    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)\n    early_stop.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040, 0.1019]\n\n    # Should stop after epoch 3, as the loss has not improved after patience=2 epochs.\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    assert epochs_trained == 3",
        "begin_line": 265,
        "end_line": 292,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.__init__#267",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.__init__(self)",
        "snippet": "        def __init__(self):\n            self.stop_training = False",
        "begin_line": 267,
        "end_line": 268,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.get_weights#270",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.get_weights(self)",
        "snippet": "        def get_weights(self):\n            return []",
        "begin_line": 270,
        "end_line": 271,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.set_weights#273",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.set_weights(self, weights)",
        "snippet": "        def set_weights(self, weights):\n            pass",
        "begin_line": 273,
        "end_line": 274,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_EarlyStopping_baseline#296",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_EarlyStopping_baseline()",
        "snippet": "def test_EarlyStopping_baseline():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n\n        def get_weights(self):\n            return []\n\n        def set_weights(self, weights):\n            pass\n\n    def baseline_tester(acc_levels):\n        early_stop = callbacks.EarlyStopping(monitor='val_acc', baseline=0.75, patience=2)\n        early_stop.model = DummyModel()\n        epochs_trained = 0\n        early_stop.on_train_begin()\n        for epoch in range(len(acc_levels)):\n            epochs_trained += 1\n            early_stop.on_epoch_end(epoch, logs={'val_acc': acc_levels[epoch]})\n            if early_stop.model.stop_training:\n                break\n        return epochs_trained\n\n    acc_levels = [0.55, 0.76, 0.81, 0.81]\n    baseline_met = baseline_tester(acc_levels)\n    acc_levels = [0.55, 0.74, 0.81, 0.81]\n    baseline_not_met = baseline_tester(acc_levels)\n\n    # All epochs should run because baseline was met in second epoch\n    assert baseline_met == 4\n    # Baseline was not met by second epoch and should stop\n    assert baseline_not_met == 2",
        "begin_line": 296,
        "end_line": 327,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.test_EarlyStopping_baseline#296",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.test_EarlyStopping_baseline()",
        "snippet": "def test_EarlyStopping_baseline():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n\n        def get_weights(self):\n            return []\n\n        def set_weights(self, weights):\n            pass\n\n    def baseline_tester(acc_levels):\n        early_stop = callbacks.EarlyStopping(monitor='val_acc', baseline=0.75, patience=2)\n        early_stop.model = DummyModel()\n        epochs_trained = 0\n        early_stop.on_train_begin()\n        for epoch in range(len(acc_levels)):\n            epochs_trained += 1\n            early_stop.on_epoch_end(epoch, logs={'val_acc': acc_levels[epoch]})\n            if early_stop.model.stop_training:\n                break\n        return epochs_trained\n\n    acc_levels = [0.55, 0.76, 0.81, 0.81]\n    baseline_met = baseline_tester(acc_levels)\n    acc_levels = [0.55, 0.74, 0.81, 0.81]\n    baseline_not_met = baseline_tester(acc_levels)\n\n    # All epochs should run because baseline was met in second epoch\n    assert baseline_met == 4\n    # Baseline was not met by second epoch and should stop\n    assert baseline_not_met == 2",
        "begin_line": 296,
        "end_line": 327,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.__init__#298",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.__init__(self)",
        "snippet": "        def __init__(self):\n            self.stop_training = False",
        "begin_line": 298,
        "end_line": 299,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.get_weights#301",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.get_weights(self)",
        "snippet": "        def get_weights(self):\n            return []",
        "begin_line": 301,
        "end_line": 302,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.set_weights#304",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.set_weights(self, weights)",
        "snippet": "        def set_weights(self, weights):\n            pass",
        "begin_line": 304,
        "end_line": 305,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.baseline_tester#307",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.baseline_tester(acc_levels)",
        "snippet": "    def baseline_tester(acc_levels):\n        early_stop = callbacks.EarlyStopping(monitor='val_acc', baseline=0.75, patience=2)\n        early_stop.model = DummyModel()\n        epochs_trained = 0\n        early_stop.on_train_begin()\n        for epoch in range(len(acc_levels)):\n            epochs_trained += 1\n            early_stop.on_epoch_end(epoch, logs={'val_acc': acc_levels[epoch]})\n            if early_stop.model.stop_training:\n                break\n        return epochs_trained",
        "begin_line": 307,
        "end_line": 317,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_EarlyStopping_final_weights#331",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_EarlyStopping_final_weights()",
        "snippet": "def test_EarlyStopping_final_weights():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n            self.weights = -1\n\n        def get_weights(self):\n            return self.weights\n\n        def set_weights(self, weights):\n            self.weights = weights\n\n        def set_weight_to_epoch(self, epoch):\n            self.weights = epoch\n\n    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)\n    early_stop.model = DummyModel()\n\n    losses = [0.2, 0.15, 0.1, 0.11, 0.12]\n\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.model.set_weight_to_epoch(epoch=epoch)\n        early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    # The best configuration is in the epoch 2 (loss = 0.1000),\n    # so with patience=2 we need to end up at epoch 4\n    assert early_stop.model.get_weights() == 4",
        "begin_line": 331,
        "end_line": 364,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.test_EarlyStopping_final_weights#331",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.test_EarlyStopping_final_weights()",
        "snippet": "def test_EarlyStopping_final_weights():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n            self.weights = -1\n\n        def get_weights(self):\n            return self.weights\n\n        def set_weights(self, weights):\n            self.weights = weights\n\n        def set_weight_to_epoch(self, epoch):\n            self.weights = epoch\n\n    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)\n    early_stop.model = DummyModel()\n\n    losses = [0.2, 0.15, 0.1, 0.11, 0.12]\n\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.model.set_weight_to_epoch(epoch=epoch)\n        early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    # The best configuration is in the epoch 2 (loss = 0.1000),\n    # so with patience=2 we need to end up at epoch 4\n    assert early_stop.model.get_weights() == 4",
        "begin_line": 331,
        "end_line": 364,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.__init__#333",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.__init__(self)",
        "snippet": "        def __init__(self):\n            self.stop_training = False\n            self.weights = -1",
        "begin_line": 333,
        "end_line": 335,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.get_weights#337",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.get_weights(self)",
        "snippet": "        def get_weights(self):\n            return self.weights",
        "begin_line": 337,
        "end_line": 338,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.set_weights#340",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.set_weights(self, weights)",
        "snippet": "        def set_weights(self, weights):\n            self.weights = weights",
        "begin_line": 340,
        "end_line": 341,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.set_weight_to_epoch#343",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.set_weight_to_epoch(self, epoch)",
        "snippet": "        def set_weight_to_epoch(self, epoch):\n            self.weights = epoch",
        "begin_line": 343,
        "end_line": 344,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_EarlyStopping_final_weights_when_restoring_model_weights#368",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_EarlyStopping_final_weights_when_restoring_model_weights()",
        "snippet": "def test_EarlyStopping_final_weights_when_restoring_model_weights():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n            self.weights = -1\n\n        def get_weights(self):\n            return self.weights\n\n        def set_weights(self, weights):\n            self.weights = weights\n\n        def set_weight_to_epoch(self, epoch):\n            self.weights = epoch\n\n    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2,\n                                         restore_best_weights=True)\n    early_stop.model = DummyModel()\n\n    losses = [0.2, 0.15, 0.1, 0.11, 0.12]\n\n    # The best configuration is in the epoch 2 (loss = 0.1000).\n\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.model.set_weight_to_epoch(epoch=epoch)\n        early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    # The best configuration is in epoch 2 (loss = 0.1000),\n    # and while patience = 2, we're restoring the best weights,\n    # so we end up at the epoch with the best weights, i.e. epoch 2\n    assert early_stop.model.get_weights() == 2",
        "begin_line": 368,
        "end_line": 405,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.test_EarlyStopping_final_weights_when_restoring_model_weights#368",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.test_EarlyStopping_final_weights_when_restoring_model_weights()",
        "snippet": "def test_EarlyStopping_final_weights_when_restoring_model_weights():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n            self.weights = -1\n\n        def get_weights(self):\n            return self.weights\n\n        def set_weights(self, weights):\n            self.weights = weights\n\n        def set_weight_to_epoch(self, epoch):\n            self.weights = epoch\n\n    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2,\n                                         restore_best_weights=True)\n    early_stop.model = DummyModel()\n\n    losses = [0.2, 0.15, 0.1, 0.11, 0.12]\n\n    # The best configuration is in the epoch 2 (loss = 0.1000).\n\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.model.set_weight_to_epoch(epoch=epoch)\n        early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    # The best configuration is in epoch 2 (loss = 0.1000),\n    # and while patience = 2, we're restoring the best weights,\n    # so we end up at the epoch with the best weights, i.e. epoch 2\n    assert early_stop.model.get_weights() == 2",
        "begin_line": 368,
        "end_line": 405,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.__init__#370",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.__init__(self)",
        "snippet": "        def __init__(self):\n            self.stop_training = False\n            self.weights = -1",
        "begin_line": 370,
        "end_line": 372,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.get_weights#374",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.get_weights(self)",
        "snippet": "        def get_weights(self):\n            return self.weights",
        "begin_line": 374,
        "end_line": 375,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.set_weights#377",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.set_weights(self, weights)",
        "snippet": "        def set_weights(self, weights):\n            self.weights = weights",
        "begin_line": 377,
        "end_line": 378,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.set_weight_to_epoch#380",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.set_weight_to_epoch(self, epoch)",
        "snippet": "        def set_weight_to_epoch(self, epoch):\n            self.weights = epoch",
        "begin_line": 380,
        "end_line": 381,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_LearningRateScheduler#409",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_LearningRateScheduler()",
        "snippet": "def test_LearningRateScheduler():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    cbks = [callbacks.LearningRateScheduler(lambda x: 1. / (1. + x))]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=5)\n    assert (float(K.get_value(model.optimizer.lr)) - 0.2) < K.epsilon()",
        "begin_line": 409,
        "end_line": 428,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_ReduceLROnPlateau#432",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_ReduceLROnPlateau()",
        "snippet": "def test_ReduceLROnPlateau():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n        model.add(Dense(num_classes, activation='softmax'))\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=['accuracy'])\n        return model\n\n    model = make_model()\n\n    # This should reduce the LR after the first epoch (due to high epsilon).\n    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=10, patience=1, cooldown=5)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=5, verbose=2)\n    assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.01, atol=K.epsilon())\n\n    model = make_model()\n    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=0, patience=1, cooldown=5)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=5, verbose=2)\n    assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.1, atol=K.epsilon())",
        "begin_line": 432,
        "end_line": 465,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.make_model#442",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.make_model()",
        "snippet": "    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n        model.add(Dense(num_classes, activation='softmax'))\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=['accuracy'])\n        return model",
        "begin_line": 442,
        "end_line": 451,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_ReduceLROnPlateau_patience#469",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_ReduceLROnPlateau_patience()",
        "snippet": "def test_ReduceLROnPlateau_patience():\n    class DummyOptimizer(object):\n        def __init__(self):\n            self.lr = K.variable(1.0)\n\n    class DummyModel(object):\n        def __init__(self):\n            self.optimizer = DummyOptimizer()\n\n    reduce_on_plateau = callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                    patience=2)\n    reduce_on_plateau.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040]\n    lrs = []\n\n    for epoch in range(len(losses)):\n        reduce_on_plateau.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n        lrs.append(K.get_value(reduce_on_plateau.model.optimizer.lr))\n\n    # The learning rates should be 1.0 except the last one\n    assert all([lr == 1.0 for lr in lrs[:-1]]) and lrs[-1] < 1.0",
        "begin_line": 469,
        "end_line": 490,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyOptimizer.test_ReduceLROnPlateau_patience#469",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyOptimizer",
        "signature": "tests.keras.test_callbacks.DummyOptimizer.test_ReduceLROnPlateau_patience()",
        "snippet": "def test_ReduceLROnPlateau_patience():\n    class DummyOptimizer(object):\n        def __init__(self):\n            self.lr = K.variable(1.0)\n\n    class DummyModel(object):\n        def __init__(self):\n            self.optimizer = DummyOptimizer()\n\n    reduce_on_plateau = callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                    patience=2)\n    reduce_on_plateau.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040]\n    lrs = []\n\n    for epoch in range(len(losses)):\n        reduce_on_plateau.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n        lrs.append(K.get_value(reduce_on_plateau.model.optimizer.lr))\n\n    # The learning rates should be 1.0 except the last one\n    assert all([lr == 1.0 for lr in lrs[:-1]]) and lrs[-1] < 1.0",
        "begin_line": 469,
        "end_line": 490,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyOptimizer.__init__#471",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyOptimizer",
        "signature": "tests.keras.test_callbacks.DummyOptimizer.__init__(self)",
        "snippet": "        def __init__(self):\n            self.lr = K.variable(1.0)",
        "begin_line": 471,
        "end_line": 472,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.test_ReduceLROnPlateau_patience#469",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.test_ReduceLROnPlateau_patience()",
        "snippet": "def test_ReduceLROnPlateau_patience():\n    class DummyOptimizer(object):\n        def __init__(self):\n            self.lr = K.variable(1.0)\n\n    class DummyModel(object):\n        def __init__(self):\n            self.optimizer = DummyOptimizer()\n\n    reduce_on_plateau = callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                    patience=2)\n    reduce_on_plateau.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040]\n    lrs = []\n\n    for epoch in range(len(losses)):\n        reduce_on_plateau.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n        lrs.append(K.get_value(reduce_on_plateau.model.optimizer.lr))\n\n    # The learning rates should be 1.0 except the last one\n    assert all([lr == 1.0 for lr in lrs[:-1]]) and lrs[-1] < 1.0",
        "begin_line": 469,
        "end_line": 490,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.__init__#475",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.__init__(self)",
        "snippet": "        def __init__(self):\n            self.optimizer = DummyOptimizer()",
        "begin_line": 475,
        "end_line": 476,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_ReduceLROnPlateau_backwards_compatibility#494",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_ReduceLROnPlateau_backwards_compatibility()",
        "snippet": "def test_ReduceLROnPlateau_backwards_compatibility():\n    import warnings\n    with warnings.catch_warnings(record=True) as ws:\n        reduce_on_plateau = callbacks.ReduceLROnPlateau(epsilon=1e-13)\n        # Check if warnings are disabled\n        if os.environ.get(\"PYTHONWARNINGS\") != \"ignore\":\n            assert \"`epsilon` argument is deprecated\" in str(ws[0].message)\n    assert not hasattr(reduce_on_plateau, 'epsilon')\n    assert hasattr(reduce_on_plateau, 'min_delta')\n    assert reduce_on_plateau.min_delta == 1e-13",
        "begin_line": 494,
        "end_line": 503,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_CSVLogger#507",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_CSVLogger(tmpdir)",
        "snippet": "def test_CSVLogger(tmpdir):\n    np.random.seed(1337)\n    filepath = str(tmpdir / 'log.tsv')\n    sep = '\\t'\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n        model.add(Dense(num_classes, activation='softmax'))\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=['accuracy'])\n        return model\n\n    # case 1, create new file with defined separator\n    model = make_model()\n    cbks = [callbacks.CSVLogger(filepath, separator=sep)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    assert os.path.isfile(filepath)\n    with open(filepath) as csvfile:\n        dialect = Sniffer().sniff(csvfile.read())\n    assert dialect.delimiter == sep\n    del model\n    del cbks\n\n    # case 2, append data to existing file, skip header\n    model = make_model()\n    cbks = [callbacks.CSVLogger(filepath, separator=sep, append=True)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    # case 3, reuse of CSVLogger object\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    import re\n    with open(filepath) as csvfile:\n        output = \" \".join(csvfile.readlines())\n        assert len(re.findall('epoch', output)) == 1\n\n    os.remove(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 507,
        "end_line": 559,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.make_model#519",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.make_model()",
        "snippet": "    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n        model.add(Dense(num_classes, activation='softmax'))\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=['accuracy'])\n        return model",
        "begin_line": 519,
        "end_line": 528,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_TensorBoard#563",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TensorBoard(tmpdir)",
        "snippet": "def test_TensorBoard(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_test_data(\n        num_train=train_samples,\n        num_test=test_samples,\n        input_shape=(input_dim,),\n        classification=True,\n        num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index\n\n    class DummyStatefulMetric(Layer):\n\n        def __init__(self, name='dummy_stateful_metric', **kwargs):\n            super(DummyStatefulMetric, self).__init__(name=name, **kwargs)\n            self.stateful = True\n            self.state = K.variable(value=0, dtype='int32')\n\n        def reset_states(self):\n            pass\n\n        def __call__(self, y_true, y_pred):\n            return self.state\n\n    inp = Input((input_dim,))\n    hidden = Dense(num_hidden, activation='relu')(inp)\n    hidden = Dropout(0.1)(hidden)\n    output = Dense(num_classes, activation='softmax')(hidden)\n    model = Model(inputs=inp, outputs=output)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy', DummyStatefulMetric()])\n\n    # we must generate new callbacks for each test, as they aren't stateless\n    def callbacks_factory(histogram_freq, embeddings_freq=1):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=embeddings_freq,\n                                      embeddings_layer_names=['dense_1'],\n                                      embeddings_data=X_test,\n                                      batch_size=5)]\n\n    # fit without validation data\n    model.fit(X_train, y_train, batch_size=batch_size,\n              callbacks=callbacks_factory(histogram_freq=0, embeddings_freq=0),\n              epochs=3)\n\n    # fit with validation data and accuracy\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test),\n              callbacks=callbacks_factory(histogram_freq=0), epochs=2)\n\n    # fit generator without validation data\n    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                        callbacks=callbacks_factory(histogram_freq=0,\n                                                    embeddings_freq=0))\n\n    # fit generator with validation data and accuracy\n    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                        validation_data=(X_test, y_test),\n                        callbacks=callbacks_factory(histogram_freq=1))\n\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 563,
        "end_line": 647,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#576",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator(train)",
        "snippet": "    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index",
        "begin_line": 576,
        "end_line": 591,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyStatefulMetric.test_TensorBoard#563",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyStatefulMetric",
        "signature": "tests.keras.test_callbacks.DummyStatefulMetric.test_TensorBoard(tmpdir)",
        "snippet": "def test_TensorBoard(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_test_data(\n        num_train=train_samples,\n        num_test=test_samples,\n        input_shape=(input_dim,),\n        classification=True,\n        num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index\n\n    class DummyStatefulMetric(Layer):\n\n        def __init__(self, name='dummy_stateful_metric', **kwargs):\n            super(DummyStatefulMetric, self).__init__(name=name, **kwargs)\n            self.stateful = True\n            self.state = K.variable(value=0, dtype='int32')\n\n        def reset_states(self):\n            pass\n\n        def __call__(self, y_true, y_pred):\n            return self.state\n\n    inp = Input((input_dim,))\n    hidden = Dense(num_hidden, activation='relu')(inp)\n    hidden = Dropout(0.1)(hidden)\n    output = Dense(num_classes, activation='softmax')(hidden)\n    model = Model(inputs=inp, outputs=output)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy', DummyStatefulMetric()])\n\n    # we must generate new callbacks for each test, as they aren't stateless\n    def callbacks_factory(histogram_freq, embeddings_freq=1):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=embeddings_freq,\n                                      embeddings_layer_names=['dense_1'],\n                                      embeddings_data=X_test,\n                                      batch_size=5)]\n\n    # fit without validation data\n    model.fit(X_train, y_train, batch_size=batch_size,\n              callbacks=callbacks_factory(histogram_freq=0, embeddings_freq=0),\n              epochs=3)\n\n    # fit with validation data and accuracy\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test),\n              callbacks=callbacks_factory(histogram_freq=0), epochs=2)\n\n    # fit generator without validation data\n    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                        callbacks=callbacks_factory(histogram_freq=0,\n                                                    embeddings_freq=0))\n\n    # fit generator with validation data and accuracy\n    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                        validation_data=(X_test, y_test),\n                        callbacks=callbacks_factory(histogram_freq=1))\n\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 563,
        "end_line": 647,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyStatefulMetric.__init__#595",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyStatefulMetric",
        "signature": "tests.keras.test_callbacks.DummyStatefulMetric.__init__(self, name='dummy_stateful_metric', **kwargs)",
        "snippet": "        def __init__(self, name='dummy_stateful_metric', **kwargs):\n            super(DummyStatefulMetric, self).__init__(name=name, **kwargs)\n            self.stateful = True\n            self.state = K.variable(value=0, dtype='int32')",
        "begin_line": 595,
        "end_line": 598,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyStatefulMetric.reset_states#600",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyStatefulMetric",
        "signature": "tests.keras.test_callbacks.DummyStatefulMetric.reset_states(self)",
        "snippet": "        def reset_states(self):\n            pass",
        "begin_line": 600,
        "end_line": 601,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyStatefulMetric.__call__#603",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyStatefulMetric",
        "signature": "tests.keras.test_callbacks.DummyStatefulMetric.__call__(self, y_true, y_pred)",
        "snippet": "        def __call__(self, y_true, y_pred):\n            return self.state",
        "begin_line": 603,
        "end_line": 604,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.callbacks_factory#616",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.callbacks_factory(histogram_freq, embeddings_freq=1)",
        "snippet": "    def callbacks_factory(histogram_freq, embeddings_freq=1):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=embeddings_freq,\n                                      embeddings_layer_names=['dense_1'],\n                                      embeddings_data=X_test,\n                                      batch_size=5)]",
        "begin_line": 616,
        "end_line": 623,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_TensorBoard_histogram_freq_must_have_validation_data#653",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TensorBoard_histogram_freq_must_have_validation_data(tmpdir)",
        "snippet": "def test_TensorBoard_histogram_freq_must_have_validation_data(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_test_data(\n        num_train=train_samples,\n        num_test=test_samples,\n        input_shape=(input_dim,),\n        classification=True,\n        num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index\n\n    inp = Input((input_dim,))\n    hidden = Dense(num_hidden, activation='relu')(inp)\n    hidden = Dropout(0.1)(hidden)\n    output = Dense(num_classes, activation='softmax')(hidden)\n    model = Model(inputs=inp, outputs=output)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    # we must generate new callbacks for each test, as they aren't stateless\n    def callbacks_factory(histogram_freq, embeddings_freq=1):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=embeddings_freq,\n                                      embeddings_layer_names=['dense_1'],\n                                      embeddings_data=X_test,\n                                      batch_size=5)]\n\n    # fit without validation data should raise ValueError if histogram_freq > 0\n    with pytest.raises(ValueError) as raised_exception:\n        model.fit(X_train, y_train, batch_size=batch_size,\n                  callbacks=callbacks_factory(histogram_freq=1), epochs=3)\n    assert 'validation_data must be provided' in str(raised_exception.value)\n\n    # fit generator without validation data should raise ValueError if\n    # histogram_freq > 0\n    with pytest.raises(ValueError) as raised_exception:\n        model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                            callbacks=callbacks_factory(histogram_freq=1))\n    assert 'validation_data must be provided' in str(raised_exception.value)\n\n    # fit generator with validation data generator should raise ValueError if\n    # histogram_freq > 0\n    with pytest.raises(ValueError) as raised_exception:\n        model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                            validation_data=data_generator(False),\n                            validation_steps=1,\n                            callbacks=callbacks_factory(histogram_freq=1))\n    assert 'validation_data must be provided' in str(raised_exception.value)",
        "begin_line": 653,
        "end_line": 722,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#666",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator(train)",
        "snippet": "    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index",
        "begin_line": 666,
        "end_line": 681,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.callbacks_factory#693",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.callbacks_factory(histogram_freq, embeddings_freq=1)",
        "snippet": "    def callbacks_factory(histogram_freq, embeddings_freq=1):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=embeddings_freq,\n                                      embeddings_layer_names=['dense_1'],\n                                      embeddings_data=X_test,\n                                      batch_size=5)]",
        "begin_line": 693,
        "end_line": 700,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_TensorBoard_multi_input_output#726",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TensorBoard_multi_input_output(tmpdir)",
        "snippet": "def test_TensorBoard_multi_input_output(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_test_data(\n        num_train=train_samples,\n        num_test=test_samples,\n        input_shape=(input_dim, input_dim),\n        classification=True,\n        num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield ([X_train[i * batch_size: (i + 1) * batch_size]] * 2,\n                       [y_train[i * batch_size: (i + 1) * batch_size]] * 2)\n            else:\n                yield ([X_test[i * batch_size: (i + 1) * batch_size]] * 2,\n                       [y_test[i * batch_size: (i + 1) * batch_size]] * 2)\n            i += 1\n            i = i % max_batch_index\n\n    inp1 = Input((input_dim, input_dim))\n    inp2 = Input((input_dim, input_dim))\n    inp_3d = add([inp1, inp2])\n    inp_2d = GlobalAveragePooling1D()(inp_3d)\n    inp_pair = Lambda(lambda x: x)([inp_3d, inp_2d])  # test a layer with a list of output tensors\n    hidden = dot(inp_pair, axes=-1)\n    hidden = Dense(num_hidden, activation='relu')(hidden)\n    hidden = Dropout(0.1)(hidden)\n    output1 = Dense(num_classes, activation='softmax')(hidden)\n    output2 = Dense(num_classes, activation='softmax')(hidden)\n    model = Model(inputs=[inp1, inp2], outputs=[output1, output2])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    # we must generate new callbacks for each test, as they aren't stateless\n    def callbacks_factory(histogram_freq, embeddings_freq=1):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=embeddings_freq,\n                                      embeddings_layer_names=['dense_1'],\n                                      embeddings_data=[X_test] * 2,\n                                      batch_size=5)]\n\n    # fit without validation data\n    model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,\n              callbacks=callbacks_factory(histogram_freq=0, embeddings_freq=0),\n              epochs=3)\n\n    # fit with validation data and accuracy\n    model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,\n              validation_data=([X_test] * 2, [y_test] * 2),\n              callbacks=callbacks_factory(histogram_freq=1), epochs=2)\n\n    # fit generator without validation data\n    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                        callbacks=callbacks_factory(histogram_freq=0,\n                                                    embeddings_freq=0))\n\n    # fit generator with validation data and accuracy\n    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                        validation_data=([X_test] * 2, [y_test] * 2),\n                        callbacks=callbacks_factory(histogram_freq=1))\n\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 726,
        "end_line": 803,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#739",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator(train)",
        "snippet": "    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield ([X_train[i * batch_size: (i + 1) * batch_size]] * 2,\n                       [y_train[i * batch_size: (i + 1) * batch_size]] * 2)\n            else:\n                yield ([X_test[i * batch_size: (i + 1) * batch_size]] * 2,\n                       [y_test[i * batch_size: (i + 1) * batch_size]] * 2)\n            i += 1\n            i = i % max_batch_index",
        "begin_line": 739,
        "end_line": 754,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.callbacks_factory#772",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.callbacks_factory(histogram_freq, embeddings_freq=1)",
        "snippet": "    def callbacks_factory(histogram_freq, embeddings_freq=1):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=embeddings_freq,\n                                      embeddings_layer_names=['dense_1'],\n                                      embeddings_data=[X_test] * 2,\n                                      batch_size=5)]",
        "begin_line": 772,
        "end_line": 779,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_TensorBoard_convnet#807",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TensorBoard_convnet(tmpdir)",
        "snippet": "def test_TensorBoard_convnet(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    input_shape = (16, 16, 3)\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=500,\n                                                         num_test=200,\n                                                         input_shape=input_shape,\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_train = np_utils.to_categorical(y_train)\n    y_test = np_utils.to_categorical(y_test)\n\n    model = Sequential([\n        Conv2D(filters=8, kernel_size=3,\n               activation='relu',\n               input_shape=input_shape),\n        MaxPooling2D(pool_size=2),\n        Conv2D(filters=4, kernel_size=(3, 3),\n               activation='relu', padding='same'),\n        GlobalAveragePooling2D(),\n        Dense(num_classes, activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1,\n                                write_images=True, write_grads=True,\n                                batch_size=16)\n    cbks = [tsb]\n    model.summary()\n    history = model.fit(x_train, y_train, epochs=2, batch_size=16,\n                        validation_data=(x_test, y_test),\n                        callbacks=cbks,\n                        verbose=0)\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 807,
        "end_line": 844,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_CallbackValData#848",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_CallbackValData()",
        "snippet": "def test_CallbackValData():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    cbk = callbacks.LambdaCallback(on_train_end=lambda x: 1)\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=[cbk], epochs=1)\n\n    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index\n\n    cbk2 = callbacks.LambdaCallback(on_train_end=lambda x: 1)\n    model.fit_generator(data_generator(True), len(X_train), epochs=1,\n                        validation_data=(X_test, y_test),\n                        callbacks=[cbk2])\n\n    # callback validation data should always have x, y, and sample weights\n    assert len(cbk.validation_data) == len(cbk2.validation_data) == 3\n    assert cbk.validation_data[0] is cbk2.validation_data[0]\n    assert cbk.validation_data[1] is cbk2.validation_data[1]\n    assert cbk.validation_data[2].shape == cbk2.validation_data[2].shape",
        "begin_line": 848,
        "end_line": 893,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#868",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator(train)",
        "snippet": "    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index",
        "begin_line": 868,
        "end_line": 882,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_LambdaCallback#897",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_LambdaCallback()",
        "snippet": "def test_LambdaCallback():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    # Start an arbitrary process that should run during model training and be terminated after training has completed.\n    def f():\n        while True:\n            pass\n\n    p = multiprocessing.Process(target=f)\n    p.start()\n    cleanup_callback = callbacks.LambdaCallback(on_train_end=lambda logs: p.terminate())\n\n    cbks = [cleanup_callback]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=5)\n    p.join()\n    assert not p.is_alive()",
        "begin_line": 897,
        "end_line": 926,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.f#914",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.f()",
        "snippet": "    def f():\n        while True:\n            pass",
        "begin_line": 914,
        "end_line": 916,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_TensorBoard_with_ReduceLROnPlateau#930",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TensorBoard_with_ReduceLROnPlateau(tmpdir)",
        "snippet": "def test_TensorBoard_with_ReduceLROnPlateau(tmpdir):\n    import shutil\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='binary_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    cbks = [\n        callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=4,\n            verbose=1),\n        callbacks.TensorBoard(\n            log_dir=filepath)]\n\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=2)\n\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 930,
        "end_line": 964,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.tests_RemoteMonitor#968",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.tests_RemoteMonitor()",
        "snippet": "def tests_RemoteMonitor():\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    cbks = [callbacks.RemoteMonitor()]\n\n    with patch('requests.post'):\n        model.fit(X_train, y_train, batch_size=batch_size,\n                  validation_data=(X_test, y_test), callbacks=cbks, epochs=1)",
        "begin_line": 968,
        "end_line": 986,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.tests_RemoteMonitorWithJsonPayload#990",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.tests_RemoteMonitorWithJsonPayload()",
        "snippet": "def tests_RemoteMonitorWithJsonPayload():\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    cbks = [callbacks.RemoteMonitor(send_as_json=True)]\n\n    with patch('requests.post'):\n        model.fit(X_train, y_train, batch_size=batch_size,\n                  validation_data=(X_test, y_test), callbacks=cbks, epochs=1)",
        "begin_line": 990,
        "end_line": 1008,
        "comment": "",
        "is_bug": false
    }
]