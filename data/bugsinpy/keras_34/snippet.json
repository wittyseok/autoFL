[
    {
        "name": "keras.layers.noise.GaussianNoise.__init__#37",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianNoise",
        "signature": "keras.layers.noise.GaussianNoise.__init__(self, stddev, **kwargs)",
        "snippet": "    def __init__(self, stddev, **kwargs):\n        super(GaussianNoise, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.stddev = stddev",
        "begin_line": 37,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.GaussianNoise.call#42",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianNoise",
        "signature": "keras.layers.noise.GaussianNoise.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        def noised():\n            return inputs + K.random_normal(shape=K.shape(inputs),\n                                            mean=0.,\n                                            stddev=self.stddev)\n        return K.in_train_phase(noised, inputs, training=training)",
        "begin_line": 42,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.GaussianNoise.noised#43",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianNoise",
        "signature": "keras.layers.noise.GaussianNoise.noised()",
        "snippet": "        def noised():\n            return inputs + K.random_normal(shape=K.shape(inputs),\n                                            mean=0.,\n                                            stddev=self.stddev)",
        "begin_line": 43,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.GaussianNoise.get_config#49",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianNoise",
        "signature": "keras.layers.noise.GaussianNoise.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'stddev': self.stddev}\n        base_config = super(GaussianNoise, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 49,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.GaussianNoise.compute_output_shape#54",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianNoise",
        "signature": "keras.layers.noise.GaussianNoise.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 54,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.GaussianDropout.__init__#81",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianDropout",
        "signature": "keras.layers.noise.GaussianDropout.__init__(self, rate, **kwargs)",
        "snippet": "    def __init__(self, rate, **kwargs):\n        super(GaussianDropout, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.rate = rate",
        "begin_line": 81,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.GaussianDropout.call#86",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianDropout",
        "signature": "keras.layers.noise.GaussianDropout.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        if 0 < self.rate < 1:\n            def noised():\n                stddev = np.sqrt(self.rate / (1.0 - self.rate))\n                return inputs * K.random_normal(shape=K.shape(inputs),\n                                                mean=1.0,\n                                                stddev=stddev)\n            return K.in_train_phase(noised, inputs, training=training)\n        return inputs",
        "begin_line": 86,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.GaussianDropout.noised#88",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianDropout",
        "signature": "keras.layers.noise.GaussianDropout.noised()",
        "snippet": "            def noised():\n                stddev = np.sqrt(self.rate / (1.0 - self.rate))\n                return inputs * K.random_normal(shape=K.shape(inputs),\n                                                mean=1.0,\n                                                stddev=stddev)",
        "begin_line": 88,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.GaussianDropout.get_config#96",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianDropout",
        "signature": "keras.layers.noise.GaussianDropout.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'rate': self.rate}\n        base_config = super(GaussianDropout, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 96,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.GaussianDropout.compute_output_shape#101",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianDropout",
        "signature": "keras.layers.noise.GaussianDropout.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 101,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout.__init__#131",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout.__init__(self, rate, noise_shape=None, seed=None, **kwargs)",
        "snippet": "    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n        super(AlphaDropout, self).__init__(**kwargs)\n        self.rate = rate\n        self.noise_shape = noise_shape\n        self.seed = seed\n        self.supports_masking = True",
        "begin_line": 131,
        "end_line": 136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout._get_noise_shape#138",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout._get_noise_shape(self, inputs)",
        "snippet": "    def _get_noise_shape(self, inputs):\n        return self.noise_shape if self.noise_shape else K.shape(inputs)",
        "begin_line": 138,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout.call#141",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        if 0. < self.rate < 1.:\n            noise_shape = self._get_noise_shape(inputs)\n\n            def dropped_inputs(inputs=inputs, rate=self.rate, seed=self.seed):\n                alpha = 1.6732632423543772848170429916717\n                scale = 1.0507009873554804934193349852946\n                alpha_p = -alpha * scale\n\n                kept_idx = K.greater_equal(K.random_uniform(noise_shape,\n                                                            seed=seed), rate)\n                kept_idx = K.cast(kept_idx, K.floatx())\n\n                # Get affine transformation params\n                a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5\n                b = -a * alpha_p * rate\n\n                # Apply mask\n                x = inputs * kept_idx + alpha_p * (1 - kept_idx)\n\n                # Do affine transformation\n                return a * x + b\n\n            return K.in_train_phase(dropped_inputs, inputs, training=training)\n        return inputs",
        "begin_line": 141,
        "end_line": 165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout.dropped_inputs#145",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout.dropped_inputs(inputs=inputs, rate=self.rate, seed=self.seed)",
        "snippet": "            def dropped_inputs(inputs=inputs, rate=self.rate, seed=self.seed):\n                alpha = 1.6732632423543772848170429916717\n                scale = 1.0507009873554804934193349852946\n                alpha_p = -alpha * scale\n\n                kept_idx = K.greater_equal(K.random_uniform(noise_shape,\n                                                            seed=seed), rate)\n                kept_idx = K.cast(kept_idx, K.floatx())\n\n                # Get affine transformation params\n                a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5\n                b = -a * alpha_p * rate\n\n                # Apply mask\n                x = inputs * kept_idx + alpha_p * (1 - kept_idx)\n\n                # Do affine transformation\n                return a * x + b",
        "begin_line": 145,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout.get_config#167",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'rate': self.rate}\n        base_config = super(AlphaDropout, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 167,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout.compute_output_shape#172",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 172,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.save_model#35",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.save_model(model, filepath, overwrite=True, include_optimizer=True)",
        "snippet": "def save_model(model, filepath, overwrite=True, include_optimizer=True):\n    \"\"\"Save a model to a HDF5 file.\n\n    The saved model contains:\n        - the model's configuration (topology)\n        - the model's weights\n        - the model's optimizer's state (if any)\n\n    Thus the saved model can be reinstantiated in\n    the exact same state, without any of the code\n    used for model definition or training.\n\n    # Arguments\n        model: Keras model instance to be saved.\n        filepath: String, path where to save the model.\n        overwrite: Whether we should overwrite any existing\n            model at the target location, or instead\n            ask the user with a manual prompt.\n        include_optimizer: If True, save optimizer's state together.\n\n    # Raises\n        ImportError: if h5py is not available.\n    \"\"\"\n\n    if h5py is None:\n        raise ImportError('`save_model` requires h5py.')\n\n    def get_json_type(obj):\n        \"\"\"Serialize any object to a JSON-serializable structure.\n\n        # Arguments\n            obj: the object to serialize\n\n        # Returns\n            JSON-serializable structure representing `obj`.\n\n        # Raises\n            TypeError: if `obj` cannot be serialized.\n        \"\"\"\n        # if obj is a serializable Keras class instance\n        # e.g. optimizer, layer\n        if hasattr(obj, 'get_config'):\n            return {'class_name': obj.__class__.__name__,\n                    'config': obj.get_config()}\n\n        # if obj is any numpy type\n        if type(obj).__module__ == np.__name__:\n            if isinstance(obj, np.ndarray):\n                return {'type': type(obj),\n                        'value': obj.tolist()}\n            else:\n                return obj.item()\n\n        # misc functions (e.g. loss function)\n        if callable(obj):\n            return obj.__name__\n\n        # if obj is a python 'type'\n        if type(obj).__name__ == type.__name__:\n            return obj.__name__\n\n        raise TypeError('Not JSON Serializable:', obj)\n\n    from . import __version__ as keras_version\n\n    # If file exists and should not be overwritten.\n    if not overwrite and os.path.isfile(filepath):\n        proceed = ask_to_proceed_with_overwrite(filepath)\n        if not proceed:\n            return\n\n    with h5py.File(filepath, mode='w') as f:\n        f.attrs['keras_version'] = str(keras_version).encode('utf8')\n        f.attrs['backend'] = K.backend().encode('utf8')\n        f.attrs['model_config'] = json.dumps({\n            'class_name': model.__class__.__name__,\n            'config': model.get_config()\n        }, default=get_json_type).encode('utf8')\n\n        model_weights_group = f.create_group('model_weights')\n        if legacy_models.needs_legacy_support(model):\n            model_layers = legacy_models.legacy_sequential_layers(model)\n        else:\n            model_layers = model.layers\n        topology.save_weights_to_hdf5_group(model_weights_group, model_layers)\n\n        if include_optimizer and hasattr(model, 'optimizer'):\n            if isinstance(model.optimizer, optimizers.TFOptimizer):\n                warnings.warn(\n                    'TensorFlow optimizers do not '\n                    'make it possible to access '\n                    'optimizer attributes or optimizer state '\n                    'after instantiation. '\n                    'As a result, we cannot save the optimizer '\n                    'as part of the model save file.'\n                    'You will have to compile your model again '\n                    'after loading it. '\n                    'Prefer using a Keras optimizer instead '\n                    '(see keras.io/optimizers).')\n            else:\n                f.attrs['training_config'] = json.dumps({\n                    'optimizer_config': {\n                        'class_name': model.optimizer.__class__.__name__,\n                        'config': model.optimizer.get_config()\n                    },\n                    'loss': model.loss,\n                    'metrics': model.metrics,\n                    'sample_weight_mode': model.sample_weight_mode,\n                    'loss_weights': model.loss_weights,\n                }, default=get_json_type).encode('utf8')\n\n                # Save optimizer weights.\n                symbolic_weights = getattr(model.optimizer, 'weights')\n                if symbolic_weights:\n                    optimizer_weights_group = f.create_group('optimizer_weights')\n                    weight_values = K.batch_get_value(symbolic_weights)\n                    weight_names = []\n                    for i, (w, val) in enumerate(zip(symbolic_weights,\n                                                     weight_values)):\n                        # Default values of symbolic_weights is /variable\n                        # for Theano and CNTK\n                        if K.backend() == 'theano' or K.backend() == 'cntk':\n                            if hasattr(w, 'name'):\n                                if w.name.split('/')[-1] == 'variable':\n                                    name = str(w.name) + '_' + str(i)\n                                else:\n                                    name = str(w.name)\n                            else:\n                                name = 'param_' + str(i)\n                        else:\n                            if hasattr(w, 'name') and w.name:\n                                name = str(w.name)\n                            else:\n                                name = 'param_' + str(i)\n                        weight_names.append(name.encode('utf8'))\n                    optimizer_weights_group.attrs['weight_names'] = weight_names\n                    for name, val in zip(weight_names, weight_values):\n                        param_dset = optimizer_weights_group.create_dataset(\n                            name,\n                            val.shape,\n                            dtype=val.dtype)\n                        if not val.shape:\n                            # scalar\n                            param_dset[()] = val\n                        else:\n                            param_dset[:] = val\n        f.flush()",
        "begin_line": 35,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.get_json_type#62",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.get_json_type(obj)",
        "snippet": "    def get_json_type(obj):\n        \"\"\"Serialize any object to a JSON-serializable structure.\n\n        # Arguments\n            obj: the object to serialize\n\n        # Returns\n            JSON-serializable structure representing `obj`.\n\n        # Raises\n            TypeError: if `obj` cannot be serialized.\n        \"\"\"\n        # if obj is a serializable Keras class instance\n        # e.g. optimizer, layer\n        if hasattr(obj, 'get_config'):\n            return {'class_name': obj.__class__.__name__,\n                    'config': obj.get_config()}\n\n        # if obj is any numpy type\n        if type(obj).__module__ == np.__name__:\n            if isinstance(obj, np.ndarray):\n                return {'type': type(obj),\n                        'value': obj.tolist()}\n            else:\n                return obj.item()\n\n        # misc functions (e.g. loss function)\n        if callable(obj):\n            return obj.__name__\n\n        # if obj is a python 'type'\n        if type(obj).__name__ == type.__name__:\n            return obj.__name__\n\n        raise TypeError('Not JSON Serializable:', obj)",
        "begin_line": 62,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.load_model#184",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.load_model(filepath, custom_objects=None, compile=True)",
        "snippet": "def load_model(filepath, custom_objects=None, compile=True):\n    \"\"\"Loads a model saved via `save_model`.\n\n    # Arguments\n        filepath: String, path to the saved model.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n        compile: Boolean, whether to compile the model\n            after loading.\n\n    # Returns\n        A Keras model instance. If an optimizer was found\n        as part of the saved model, the model is already\n        compiled. Otherwise, the model is uncompiled and\n        a warning will be displayed. When `compile` is set\n        to False, the compilation is omitted without any\n        warning.\n\n    # Raises\n        ImportError: if h5py is not available.\n        ValueError: In case of an invalid savefile.\n    \"\"\"\n    if h5py is None:\n        raise ImportError('`load_model` requires h5py.')\n\n    if not custom_objects:\n        custom_objects = {}\n\n    def convert_custom_objects(obj):\n        \"\"\"Handles custom object lookup.\n\n        # Arguments\n            obj: object, dict, or list.\n\n        # Returns\n            The same structure, where occurrences\n                of a custom object name have been replaced\n                with the custom object.\n        \"\"\"\n        if isinstance(obj, list):\n            deserialized = []\n            for value in obj:\n                deserialized.append(convert_custom_objects(value))\n            return deserialized\n        if isinstance(obj, dict):\n            deserialized = {}\n            for key, value in obj.items():\n                deserialized[key] = convert_custom_objects(value)\n            return deserialized\n        if obj in custom_objects:\n            return custom_objects[obj]\n        return obj\n    with h5py.File(filepath, mode='r') as f:\n        # instantiate model\n        model_config = f.attrs.get('model_config')\n        if model_config is None:\n            raise ValueError('No model found in config file.')\n        model_config = json.loads(model_config.decode('utf-8'))\n        model = model_from_config(model_config, custom_objects=custom_objects)\n\n        # set weights\n        topology.load_weights_from_hdf5_group(f['model_weights'], model.layers)\n\n        # Early return if compilation is not required.\n        if not compile:\n            return model\n\n        # instantiate optimizer\n        training_config = f.attrs.get('training_config')\n        if training_config is None:\n            warnings.warn('No training configuration found in save file: '\n                          'the model was *not* compiled. Compile it manually.')\n            return model\n        training_config = json.loads(training_config.decode('utf-8'))\n        optimizer_config = training_config['optimizer_config']\n        optimizer = optimizers.deserialize(optimizer_config,\n                                           custom_objects=custom_objects)\n\n        # Recover loss functions and metrics.\n        loss = convert_custom_objects(training_config['loss'])\n        metrics = convert_custom_objects(training_config['metrics'])\n        sample_weight_mode = training_config['sample_weight_mode']\n        loss_weights = training_config['loss_weights']\n\n        # Compile model.\n        model.compile(optimizer=optimizer,\n                      loss=loss,\n                      metrics=metrics,\n                      loss_weights=loss_weights,\n                      sample_weight_mode=sample_weight_mode)\n\n        # Set optimizer weights.\n        if 'optimizer_weights' in f:\n            # Build train function (to get weight updates).\n            if isinstance(model, Sequential):\n                model.model._make_train_function()\n            else:\n                model._make_train_function()\n            optimizer_weights_group = f['optimizer_weights']\n            optimizer_weight_names = [n.decode('utf8') for n in\n                                      optimizer_weights_group.attrs['weight_names']]\n            optimizer_weight_values = [optimizer_weights_group[n] for n in\n                                       optimizer_weight_names]\n            try:\n                model.optimizer.set_weights(optimizer_weight_values)\n            except ValueError:\n                warnings.warn('Error in loading the saved optimizer '\n                              'state. As a result, your model is '\n                              'starting with a freshly initialized '\n                              'optimizer.')\n    return model",
        "begin_line": 184,
        "end_line": 295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.convert_custom_objects#213",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.convert_custom_objects(obj)",
        "snippet": "    def convert_custom_objects(obj):\n        \"\"\"Handles custom object lookup.\n\n        # Arguments\n            obj: object, dict, or list.\n\n        # Returns\n            The same structure, where occurrences\n                of a custom object name have been replaced\n                with the custom object.\n        \"\"\"\n        if isinstance(obj, list):\n            deserialized = []\n            for value in obj:\n                deserialized.append(convert_custom_objects(value))\n            return deserialized\n        if isinstance(obj, dict):\n            deserialized = {}\n            for key, value in obj.items():\n                deserialized[key] = convert_custom_objects(value)\n            return deserialized\n        if obj in custom_objects:\n            return custom_objects[obj]\n        return obj",
        "begin_line": 213,
        "end_line": 236,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.model_from_config#298",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.model_from_config(config, custom_objects=None)",
        "snippet": "def model_from_config(config, custom_objects=None):\n    \"\"\"Instantiates a Keras model from its config.\n\n    # Arguments\n        config: Configuration dictionary.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    # Returns\n        A Keras model instance (uncompiled).\n\n    # Raises\n        TypeError: if `config` is not a dictionary.\n    \"\"\"\n    if isinstance(config, list):\n        raise TypeError('`model_from_config` expects a dictionary, not a list. '\n                        'Maybe you meant to use '\n                        '`Sequential.from_config(config)`?')\n    return layer_module.deserialize(config, custom_objects=custom_objects)",
        "begin_line": 298,
        "end_line": 317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.120178643930166e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.model_from_yaml#320",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.model_from_yaml(yaml_string, custom_objects=None)",
        "snippet": "def model_from_yaml(yaml_string, custom_objects=None):\n    \"\"\"Parses a yaml model configuration file and returns a model instance.\n\n    # Arguments\n        yaml_string: YAML string encoding a model configuration.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    # Returns\n        A Keras model instance (uncompiled).\n    \"\"\"\n    config = yaml.load(yaml_string)\n    return layer_module.deserialize(config, custom_objects=custom_objects)",
        "begin_line": 320,
        "end_line": 333,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027397260273972603,
            "pseudo_dstar_susp": 0.0006734006734006734,
            "pseudo_tarantula_susp": 0.003257328990228013,
            "pseudo_op2_susp": 0.0006734006734006734,
            "pseudo_barinel_susp": 0.003257328990228013
        }
    },
    {
        "name": "keras.models.model_from_json#336",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.model_from_json(json_string, custom_objects=None)",
        "snippet": "def model_from_json(json_string, custom_objects=None):\n    \"\"\"Parses a JSON model configuration file and returns a model instance.\n\n    # Arguments\n        json_string: JSON string encoding a model configuration.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    # Returns\n        A Keras model instance (uncompiled).\n    \"\"\"\n    config = json.loads(json_string)\n    return layer_module.deserialize(config, custom_objects=custom_objects)",
        "begin_line": 336,
        "end_line": 349,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0019083969465648854,
            "pseudo_dstar_susp": 0.0006361323155216285,
            "pseudo_tarantula_susp": 0.002531645569620253,
            "pseudo_op2_susp": 0.0006361323155216285,
            "pseudo_barinel_susp": 0.002531645569620253
        }
    },
    {
        "name": "keras.models.Sequential.__init__#389",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.__init__(self, layers=None, name=None)",
        "snippet": "    def __init__(self, layers=None, name=None):\n        self.layers = []  # Stack of layers.\n        self.model = None  # Internal Model instance.\n        self.inputs = []  # List of input tensors\n        self.outputs = []  # List of length 1: the output tensor (unique).\n        self._trainable = True\n        self._initial_weights = None\n\n        # Model attributes.\n        self._inbound_nodes = []\n        self._outbound_nodes = []\n        self.built = False\n\n        # Set model name.\n        if not name:\n            prefix = 'sequential_'\n            name = prefix + str(K.get_uid(prefix))\n        self.name = name\n\n        # Add to the model any layers passed to the constructor.\n        if layers:\n            for layer in layers:\n                self.add(layer)",
        "begin_line": 389,
        "end_line": 411,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007892659826361484,
            "pseudo_dstar_susp": 0.0018018018018018018,
            "pseudo_tarantula_susp": 0.0007347538574577516,
            "pseudo_op2_susp": 0.0018018018018018018,
            "pseudo_barinel_susp": 0.0007347538574577516
        }
    },
    {
        "name": "keras.models.Sequential.add#413",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.add(self, layer)",
        "snippet": "    def add(self, layer):\n        \"\"\"Adds a layer instance on top of the layer stack.\n\n        # Arguments\n            layer: layer instance.\n\n        # Raises\n            TypeError: If `layer` is not a layer instance.\n            ValueError: In case the `layer` argument does not\n                know its input shape.\n            ValueError: In case the `layer` argument has\n                multiple output tensors, or is already connected\n                somewhere else (forbidden in `Sequential` models).\n        \"\"\"\n        if not isinstance(layer, Layer):\n            raise TypeError('The added layer must be '\n                            'an instance of class Layer. '\n                            'Found: ' + str(layer))\n        if not self.outputs:\n            # First layer in model: check that it is an input layer.\n            if not isinstance(layer, (InputLayer, legacy_layers.Merge)):\n                # Create an input layer.\n                # First, we need to infer its expected input shape and dtype.\n                if isinstance(layer, (Model, Sequential)):\n                    # We were passed a model as first layer.\n                    # This requires a specific way to figure out the\n                    # input shape and dtype.\n                    if not layer.layers:\n                        raise ValueError('Cannot add an empty model '\n                                         'to a `Sequential` model.')\n                    # In case of nested models: recover the first layer\n                    # of the deepest model to infer input shape and dtype.\n                    first_layer = layer.layers[0]\n                    while isinstance(first_layer, (Model, Sequential)):\n                        first_layer = first_layer.layers[0]\n                    batch_shape = first_layer.batch_input_shape\n                    dtype = first_layer.dtype\n                else:\n                    # We were passed a regular layer, and it should\n                    # know about its input shape. Otherwise, that's an error.\n                    if not hasattr(layer, 'batch_input_shape'):\n                        raise ValueError('The first layer in a '\n                                         'Sequential model must '\n                                         'get an `input_shape` or '\n                                         '`batch_input_shape` argument.')\n                    batch_shape = layer.batch_input_shape\n                    dtype = layer.dtype\n                # Instantiate the input layer.\n                x = Input(batch_shape=batch_shape,\n                          dtype=dtype,\n                          name=layer.name + '_input')\n                # This will build the current layer\n                # and create the node connecting the current layer\n                # to the input layer we just created.\n                layer(x)\n\n            if len(layer._inbound_nodes[-1].output_tensors) != 1:\n                raise ValueError('All layers in a Sequential model '\n                                 'should have a single output tensor. '\n                                 'For multi-output layers, '\n                                 'use the functional API.')\n\n            self.outputs = [layer._inbound_nodes[-1].output_tensors[0]]\n            self.inputs = topology.get_source_inputs(self.outputs[0])\n\n            # We create an input node, which we will keep updated\n            # as we add more layers\n            topology.Node(outbound_layer=self,\n                          inbound_layers=[],\n                          node_indices=[],\n                          tensor_indices=[],\n                          input_tensors=self.inputs,\n                          output_tensors=self.outputs,\n                          # no model-level masking for now\n                          input_masks=[None for _ in self.inputs],\n                          output_masks=[None],\n                          input_shapes=[x._keras_shape for x in self.inputs],\n                          output_shapes=[self.outputs[0]._keras_shape])\n        else:\n            output_tensor = layer(self.outputs[0])\n            if isinstance(output_tensor, list):\n                raise TypeError('All layers in a Sequential model '\n                                'should have a single output tensor. '\n                                'For multi-output layers, '\n                                'use the functional API.')\n            self.outputs = [output_tensor]\n            # update self._inbound_nodes\n            self._inbound_nodes[0].output_tensors = self.outputs\n            self._inbound_nodes[0].output_shapes = [self.outputs[0]._keras_shape]\n\n        self.layers.append(layer)\n        self.built = False",
        "begin_line": 413,
        "end_line": 504,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001697792869269949,
            "pseudo_dstar_susp": 0.018518518518518517,
            "pseudo_tarantula_susp": 0.0009285051067780873,
            "pseudo_op2_susp": 0.018518518518518517,
            "pseudo_barinel_susp": 0.0009285051067780873
        }
    },
    {
        "name": "keras.models.Sequential.pop#506",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.pop(self)",
        "snippet": "    def pop(self):\n        \"\"\"Removes the last layer in the model.\n\n        # Raises\n            TypeError: if there are no layers in the model.\n        \"\"\"\n        if not self.layers:\n            raise TypeError('There are no layers in the model.')\n\n        self.layers.pop()\n        if not self.layers:\n            self.outputs = []\n            self._inbound_nodes = []\n            self._outbound_nodes = []\n        else:\n            self.layers[-1]._outbound_nodes = []\n            self.outputs = [self.layers[-1].output]\n            # update self._inbound_nodes\n            self._inbound_nodes[0].output_tensors = self.outputs\n            self._inbound_nodes[0].output_shapes = [self.outputs[0]._keras_shape]\n        self.built = False",
        "begin_line": 506,
        "end_line": 526,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.get_layer#528",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_layer(self, name=None, index=None)",
        "snippet": "    def get_layer(self, name=None, index=None):\n        \"\"\"Retrieve a layer that is part of the model.\n\n        Returns a layer based on either its name (unique)\n        or its index in the graph. Indices are based on\n        order of horizontal graph traversal (bottom-up).\n\n        # Arguments\n            name: string, name of layer.\n            index: integer, index of layer.\n\n        # Returns\n            A layer instance.\n        \"\"\"\n        if not self.built:\n            self.build()\n        return self.model.get_layer(name, index)",
        "begin_line": 528,
        "end_line": 544,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.call#546",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        if not self.built:\n            self.build()\n        return self.model.call(inputs, mask)",
        "begin_line": 546,
        "end_line": 549,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.build#551",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.build(self, input_shape=None)",
        "snippet": "    def build(self, input_shape=None):\n        if not self.inputs or not self.outputs:\n            raise TypeError('Sequential model cannot be built: model is empty.'\n                            ' Add some layers first.')\n        # actually create the model\n        self.model = Model(self.inputs, self.outputs[0],\n                           name=self.name + '_model')\n        self.model.trainable = self.trainable\n\n        # mirror model attributes\n        self.supports_masking = self.model.supports_masking\n        self._output_mask_cache = self.model._output_mask_cache\n        self._output_tensor_cache = self.model._output_tensor_cache\n        self._output_shape_cache = self.model._output_shape_cache\n        self.input_layers = self.model.input_layers\n        self.input_layers_node_indices = self.model.input_layers_node_indices\n        self.input_layers_tensor_indices = self.model.input_layers_tensor_indices\n        self.output_layers = self.model.output_layers\n        self.output_layers_node_indices = self.model.output_layers_node_indices\n        self.output_layers_tensor_indices = self.model.output_layers_tensor_indices\n        self._nodes_by_depth = self.model._nodes_by_depth\n        self.output_names = self.model.output_names\n        self.input_names = self.model.input_names\n        self._feed_input_names = self.model._feed_input_names\n        self._feed_inputs = self.model._feed_inputs\n        self._container_nodes = self.model._container_nodes\n\n        # Make sure child model callbacks\n        # will call the parent Sequential model.\n        self.model.callback_model = self\n        self.built = True",
        "begin_line": 551,
        "end_line": 581,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005249343832020997,
            "pseudo_dstar_susp": 0.0010741138560687433,
            "pseudo_tarantula_susp": 0.0004965243296921549,
            "pseudo_op2_susp": 0.0010741138560687433,
            "pseudo_barinel_susp": 0.0004965243296921549
        }
    },
    {
        "name": "keras.models.Sequential.uses_learning_phase#584",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.uses_learning_phase(self)",
        "snippet": "    def uses_learning_phase(self):\n        if not self.built:\n            self.build()\n        return self.model.uses_learning_phase",
        "begin_line": 584,
        "end_line": 587,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential._flattened_layers#590",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential._flattened_layers(self)",
        "snippet": "    def _flattened_layers(self):\n        layers = []\n        if self.layers:\n            # Support for legacy models\n            if isinstance(self.layers[0], legacy_layers.Merge):\n                merge = self.layers[0]\n                for layer in merge.layers:\n                    if hasattr(layer, '_flattened_layers'):\n                        for sublayer in layer._flattened_layers:\n                            if sublayer not in layers:\n                                layers.append(sublayer)\n                    elif hasattr(layer, 'layers'):\n                        for sublayer in layer.layers:\n                            if sublayer not in layers:\n                                layers.append(sublayer)\n                    else:\n                        if layer not in layers:\n                            layers.append(layer)\n            else:\n                if self.layers[0] not in layers:\n                    layers.append(self.layers[0])\n            for layer in self.layers[1:]:\n                if layer not in layers:\n                    layers.append(layer)\n        return layers",
        "begin_line": 590,
        "end_line": 614,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential._gather_list_attr#616",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential._gather_list_attr(self, attr)",
        "snippet": "    def _gather_list_attr(self, attr):\n        all_attrs = []\n        for layer in self._flattened_layers:\n            all_attrs += getattr(layer, attr, [])\n        return all_attrs",
        "begin_line": 616,
        "end_line": 620,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.366482504604051e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.trainable#623",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.trainable(self)",
        "snippet": "    def trainable(self):\n        return self._trainable",
        "begin_line": 623,
        "end_line": 624,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005216484089723526,
            "pseudo_dstar_susp": 0.0010604453870625664,
            "pseudo_tarantula_susp": 0.0004911591355599214,
            "pseudo_op2_susp": 0.0010604453870625664,
            "pseudo_barinel_susp": 0.0004911591355599214
        }
    },
    {
        "name": "keras.models.Sequential.trainable#627",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.trainable(self, value)",
        "snippet": "    def trainable(self, value):\n        if self.built:\n            self.model.trainable = value\n        self._trainable = value",
        "begin_line": 627,
        "end_line": 630,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.trainable_weights#633",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        # Support for legacy behavior\n        return self._gather_list_attr('trainable_weights')",
        "begin_line": 633,
        "end_line": 637,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.non_trainable_weights#640",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        # Support for legacy behavior\n        weights = self._gather_list_attr('non_trainable_weights')\n        if not self.trainable:\n            trainable_weights = self._gather_list_attr('trainable_weights')\n            return trainable_weights + weights\n        return weights",
        "begin_line": 640,
        "end_line": 646,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.updates#649",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.updates(self)",
        "snippet": "    def updates(self):\n        if not self.built:\n            self.build()\n        return self.model.updates",
        "begin_line": 649,
        "end_line": 652,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.get_updates_for#660",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_updates_for(self, inputs)",
        "snippet": "    def get_updates_for(self, inputs):\n        if not self.built:\n            self.build()\n        return self.model.get_updates_for(inputs)",
        "begin_line": 660,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.losses#666",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.losses(self)",
        "snippet": "    def losses(self):\n        if not self.built:\n            self.build()\n        return self.model.losses",
        "begin_line": 666,
        "end_line": 669,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.get_losses_for#671",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_losses_for(self, inputs)",
        "snippet": "    def get_losses_for(self, inputs):\n        if not self.built:\n            self.build()\n        return self.model.get_losses_for(inputs)",
        "begin_line": 671,
        "end_line": 674,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.get_weights#682",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_weights(self)",
        "snippet": "    def get_weights(self):\n        \"\"\"Retrieves the weights of the model.\n\n        # Returns\n            A flat list of Numpy arrays\n            (one array per model weight).\n        \"\"\"\n        # Legacy support\n        if legacy_models.needs_legacy_support(self):\n            layers = legacy_models.legacy_sequential_layers(self)\n            weights = []\n            for layer in layers:\n                weights.append(layer.get_weights())\n            return weights\n\n        if not self.built:\n            self.build()\n        return self.model.get_weights()",
        "begin_line": 682,
        "end_line": 699,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.set_weights#701",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the model.\n\n        # Arguments\n            weights: Should be a list\n                of Numpy arrays with shapes and types matching\n                the output of `model.get_weights()`.\n        \"\"\"\n        # Legacy support\n        if legacy_models.needs_legacy_support(self):\n            layers = legacy_models.legacy_sequential_layers(self)\n            for layer in layers:\n                nb_param = len(layer.weights)\n                layer.set_weights(weights[:nb_param])\n                weights = weights[nb_param:]\n\n        if not self.built:\n            self.build()\n        self.model.set_weights(weights)",
        "begin_line": 701,
        "end_line": 719,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.659900421294524e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.load_weights#721",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False)",
        "snippet": "    def load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False):\n        if h5py is None:\n            raise ImportError('`load_weights` requires h5py.')\n        with h5py.File(filepath, mode='r') as f:\n            if 'layer_names' not in f.attrs and 'model_weights' in f:\n                f = f['model_weights']\n\n            # Legacy support\n            if legacy_models.needs_legacy_support(self):\n                layers = legacy_models.legacy_sequential_layers(self)\n            else:\n                layers = self.layers\n            if by_name:\n                topology.load_weights_from_hdf5_group_by_name(f, layers,\n                                                              skip_mismatch=skip_mismatch,\n                                                              reshape=reshape)\n            else:\n                topology.load_weights_from_hdf5_group(f, layers, reshape=reshape)",
        "begin_line": 721,
        "end_line": 738,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.save_weights#740",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.save_weights(self, filepath, overwrite=True)",
        "snippet": "    def save_weights(self, filepath, overwrite=True):\n        if h5py is None:\n            raise ImportError('`save_weights` requires h5py.')\n        # If file exists and should not be overwritten:\n        if not overwrite and os.path.isfile(filepath):\n            proceed = ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n        # Legacy support\n        if legacy_models.needs_legacy_support(self):\n            layers = legacy_models.legacy_sequential_layers(self)\n        else:\n            layers = self.layers\n\n        with h5py.File(filepath, 'w') as f:\n            topology.save_weights_to_hdf5_group(f, layers)\n            f.flush()",
        "begin_line": 740,
        "end_line": 756,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.compile#758",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.compile(self, optimizer, loss, metrics=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)",
        "snippet": "    def compile(self, optimizer, loss,\n                metrics=None,\n                sample_weight_mode=None,\n                weighted_metrics=None,\n                target_tensors=None,\n                **kwargs):\n        \"\"\"Configures the model for training.\n\n        # Arguments\n            optimizer: String (name of optimizer) or optimizer object.\n                See [optimizers](/optimizers).\n            loss: String (name of objective function) or objective function.\n                See [losses](/losses).\n                If the model has multiple outputs, you can use a different loss\n                on each output by passing a dictionary or a list of losses.\n                The loss value that will be minimized by the model\n                will then be the sum of all individual losses.\n            metrics: List of metrics to be evaluated by the model\n                during training and testing.\n                Typically you will use `metrics=['accuracy']`.\n                To specify different metrics for different outputs of a\n                multi-output model, you could also pass a dictionary,\n                such as `metrics={'output_a': 'accuracy'}`.\n            sample_weight_mode: If you need to do timestep-wise\n                sample weighting (2D weights), set this to `\"temporal\"`.\n                `None` defaults to sample-wise weights (1D).\n                If the model has multiple outputs, you can use a different\n                `sample_weight_mode` on each output by passing a\n                dictionary or a list of modes.\n            weighted_metrics: List of metrics to be evaluated and weighted\n                by sample_weight or class_weight during training and testing.\n            target_tensors: By default, Keras will create a placeholder for the\n                model's target, which will be fed with the target data during\n                training. If instead you would like to use your own\n                target tensor (in turn, Keras will not expect external\n                Numpy data for these targets at training time), you\n                can specify them via the `target_tensors` argument.\n                It should be a single tensor\n                (for a single-output `Sequential` model).\n            **kwargs: When using the Theano/CNTK backends, these arguments\n                are passed into `K.function`.\n                When using the TensorFlow backend,\n                these arguments are passed into `tf.Session.run`.\n\n        # Raises\n            ValueError: In case of invalid arguments for\n                `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n\n        # Example\n            ```python\n                model = Sequential()\n                model.add(Dense(32, input_shape=(500,)))\n                model.add(Dense(10, activation='softmax'))\n                model.compile(optimizer='rmsprop',\n                              loss='categorical_crossentropy',\n                              metrics=['accuracy'])\n            ```\n        \"\"\"\n        # create the underlying model\n        self.build()\n        # call compile method of Model class\n        self.model.compile(optimizer, loss,\n                           metrics=metrics,\n                           sample_weight_mode=sample_weight_mode,\n                           weighted_metrics=weighted_metrics,\n                           target_tensors=target_tensors,\n                           **kwargs)\n        self.optimizer = self.model.optimizer\n        self.loss = self.model.loss\n        self.metrics = self.model.metrics\n        self.loss_weights = self.model.loss_weights\n        self.sample_weight_mode = self.model.sample_weight_mode\n        self.weighted_metrics = self.model.weighted_metrics\n        self.targets = self.model.targets\n        self.metrics_tensors = self.model.metrics_tensors\n        self.metrics_names = self.model.metrics_names\n        self.sample_weights = self.model.sample_weights\n        self.total_loss = self.model.total_loss",
        "begin_line": 758,
        "end_line": 835,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005313496280552603,
            "pseudo_dstar_susp": 0.0010976948408342481,
            "pseudo_tarantula_susp": 0.0005055611729019212,
            "pseudo_op2_susp": 0.0010976948408342481,
            "pseudo_barinel_susp": 0.0005055611729019212
        }
    },
    {
        "name": "keras.models.Sequential.fit#837",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs)",
        "snippet": "    def fit(self,\n            x=None,\n            y=None,\n            batch_size=None,\n            epochs=1,\n            verbose=1,\n            callbacks=None,\n            validation_split=0.,\n            validation_data=None,\n            shuffle=True,\n            class_weight=None,\n            sample_weight=None,\n            initial_epoch=0,\n            steps_per_epoch=None,\n            validation_steps=None,\n            **kwargs):\n        \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n\n        # Arguments\n            x: Numpy array of training data.\n                If the input layer in the model is named, you can also pass a\n                dictionary mapping the input name to a Numpy array.\n                `x` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            y: Numpy array of target (label) data.\n                If the output layer in the model is named, you can also pass a\n                dictionary mapping the output name to a Numpy array.\n                `y` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            batch_size: Integer or `None`.\n                Number of samples per gradient update.\n                If unspecified, it will default to 32.\n            epochs: Integer. Number of epochs to train the model.\n                An epoch is an iteration over the entire `x` and `y`\n                data provided.\n                Note that in conjunction with `initial_epoch`,\n                `epochs` is to be understood as \"final epoch\".\n                The model is not trained for a number of iterations\n                given by `epochs`, but merely until the epoch\n                of index `epochs` is reached.\n            verbose: 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = progress bar, 2 = one line per epoch.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during training.\n                See [callbacks](/callbacks).\n            validation_split: Float between 0 and 1.\n                Fraction of the training data to be used as validation data.\n                The model will set apart this fraction of the training data,\n                will not train on it, and will evaluate\n                the loss and any model metrics\n                on this data at the end of each epoch.\n                The validation data is selected from the last samples\n                in the `x` and `y` data provided, before shuffling.\n            validation_data: tuple `(x_val, y_val)` or tuple\n                `(x_val, y_val, val_sample_weights)` on which to evaluate\n                the loss and any model metrics at the end of each epoch.\n                The model will not be trained on this data.\n                This will override `validation_split`.\n            shuffle: Boolean (whether to shuffle the training data\n                before each epoch) or str (for 'batch').\n                'batch' is a special option for dealing with the\n                limitations of HDF5 data; it shuffles in batch-sized chunks.\n                Has no effect when `steps_per_epoch` is not `None`.\n            class_weight: Optional dictionary mapping class indices (integers)\n                to a weight (float) value, used for weighting the loss function\n                (during training only).\n                This can be useful to tell the model to\n                \"pay more attention\" to samples from\n                an under-represented class.\n            sample_weight: Optional Numpy array of weights for\n                the training samples, used for weighting the loss function\n                (during training only). You can either pass a flat (1D)\n                Numpy array with the same length as the input samples\n                (1:1 mapping between weights and samples),\n                or in the case of temporal data,\n                you can pass a 2D array with shape\n                `(samples, sequence_length)`,\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                `sample_weight_mode=\"temporal\"` in `compile()`.\n            initial_epoch: Epoch at which to start training\n                (useful for resuming a previous training run).\n            steps_per_epoch: Total number of steps (batches of samples)\n                before declaring one epoch finished and starting the\n                next epoch. When training with input tensors such as\n                TensorFlow data tensors, the default `None` is equal to\n                the number of samples in your dataset divided by\n                the batch size, or 1 if that cannot be determined.\n            validation_steps: Only relevant if `steps_per_epoch`\n                is specified. Total number of steps (batches of samples)\n                to validate before stopping.\n\n        # Returns\n            A `History` object. Its `History.history` attribute is\n            a record of training loss values and metrics values\n            at successive epochs, as well as validation loss values\n            and validation metrics values (if applicable).\n\n        # Raises\n            RuntimeError: If the model was never compiled.\n            ValueError: In case of mismatch between the provided input data\n                and what the model expects.\n        \"\"\"\n        # Legacy support\n        if 'nb_epoch' in kwargs:\n            warnings.warn('The `nb_epoch` argument in `fit` '\n                          'has been renamed `epochs`.')\n            epochs = kwargs.pop('nb_epoch')\n        if kwargs:\n            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.fit(x, y,\n                              batch_size=batch_size,\n                              epochs=epochs,\n                              verbose=verbose,\n                              callbacks=callbacks,\n                              validation_split=validation_split,\n                              validation_data=validation_data,\n                              shuffle=shuffle,\n                              class_weight=class_weight,\n                              sample_weight=sample_weight,\n                              initial_epoch=initial_epoch,\n                              steps_per_epoch=steps_per_epoch,\n                              validation_steps=validation_steps)",
        "begin_line": 837,
        "end_line": 963,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.evaluate#965",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)",
        "snippet": "    def evaluate(self, x=None, y=None,\n                 batch_size=None,\n                 verbose=1,\n                 sample_weight=None,\n                 steps=None):\n        \"\"\"Computes the loss on some input data, batch by batch.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n                `x` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            y: labels, as a Numpy array.\n                `y` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            batch_size: Integer. If unspecified, it will default to 32.\n            verbose: verbosity mode, 0 or 1.\n            sample_weight: sample weights, as a Numpy array.\n            steps: Integer or `None`.\n                Total number of steps (batches of samples)\n                before declaring the evaluation round finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            Scalar test loss (if the model has no metrics)\n            or list of scalars (if the model computes other metrics).\n            The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n        \"\"\"\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.evaluate(x, y,\n                                   batch_size=batch_size,\n                                   verbose=verbose,\n                                   sample_weight=sample_weight,\n                                   steps=steps)",
        "begin_line": 965,
        "end_line": 1004,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.predict#1006",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.predict(self, x, batch_size=None, verbose=0, steps=None)",
        "snippet": "    def predict(self, x, batch_size=None, verbose=0, steps=None):\n        \"\"\"Generates output predictions for the input samples.\n\n        The input samples are processed batch by batch.\n\n        # Arguments\n            x: the input data, as a Numpy array.\n            batch_size: Integer. If unspecified, it will default to 32.\n            verbose: verbosity mode, 0 or 1.\n            steps: Total number of steps (batches of samples)\n                before declaring the prediction round finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            A Numpy array of predictions.\n        \"\"\"\n        if not self.built:\n            self.build()\n        return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n                                  steps=steps)",
        "begin_line": 1006,
        "end_line": 1025,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.43052459503641e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.predict_on_batch#1027",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.predict_on_batch(self, x)",
        "snippet": "    def predict_on_batch(self, x):\n        \"\"\"Returns predictions for a single batch of samples.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n\n        # Returns\n            A Numpy array of predictions.\n        \"\"\"\n        if not self.built:\n            self.build()\n        return self.model.predict_on_batch(x)",
        "begin_line": 1027,
        "end_line": 1039,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.train_on_batch#1041",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.train_on_batch(self, x, y, class_weight=None, sample_weight=None)",
        "snippet": "    def train_on_batch(self, x, y, class_weight=None,\n                       sample_weight=None):\n        \"\"\"Single gradient update over one batch of samples.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            y: labels, as a Numpy array.\n            class_weight: dictionary mapping classes to a weight value,\n                used for scaling the loss function (during training only).\n            sample_weight: sample weights, as a Numpy array.\n\n        # Returns\n            Scalar training loss (if the model has no metrics)\n            or list of scalars (if the model computes other metrics).\n            The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n        \"\"\"\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.train_on_batch(x, y,\n                                         sample_weight=sample_weight,\n                                         class_weight=class_weight)",
        "begin_line": 1041,
        "end_line": 1067,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.test_on_batch#1069",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.test_on_batch(self, x, y, sample_weight=None)",
        "snippet": "    def test_on_batch(self, x, y,\n                      sample_weight=None):\n        \"\"\"Evaluates the model over a single batch of samples.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            y: labels, as a Numpy array.\n            sample_weight: sample weights, as a Numpy array.\n\n        # Returns\n            Scalar test loss (if the model has no metrics)\n            or list of scalars (if the model computes other metrics).\n            The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n        \"\"\"\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.test_on_batch(x, y,\n                                        sample_weight=sample_weight)",
        "begin_line": 1069,
        "end_line": 1092,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.predict_proba#1094",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.predict_proba(self, x, batch_size=None, verbose=0, steps=None)",
        "snippet": "    def predict_proba(self, x, batch_size=None, verbose=0, steps=None):\n        \"\"\"Generates class probability predictions for the input samples.\n\n        The input samples are processed batch by batch.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            batch_size: Integer. If unspecified, it will default to 32.\n            verbose: verbosity mode, 0 or 1.\n            steps: Total number of steps (batches of samples)\n                before declaring the prediction round finished.\n                Ignored with the default value of `None`.\n\n\n        # Returns\n            A Numpy array of probability predictions.\n        \"\"\"\n        preds = self.predict(x, batch_size, verbose, steps=steps)\n        if preds.min() < 0. or preds.max() > 1.:\n            warnings.warn('Network returning invalid probability values. '\n                          'The last layer might not normalize predictions '\n                          'into probabilities '\n                          '(like softmax or sigmoid would).')\n        return preds",
        "begin_line": 1094,
        "end_line": 1118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.predict_classes#1120",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.predict_classes(self, x, batch_size=None, verbose=0, steps=None)",
        "snippet": "    def predict_classes(self, x, batch_size=None, verbose=0, steps=None):\n        \"\"\"Generate class predictions for the input samples.\n\n        The input samples are processed batch by batch.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            batch_size: Integer. If unspecified, it will default to 32.\n            verbose: verbosity mode, 0 or 1.\n            steps: Total number of steps (batches of samples)\n                before declaring the prediction round finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            A numpy array of class predictions.\n        \"\"\"\n        proba = self.predict(x, batch_size=batch_size, verbose=verbose,\n                             steps=steps)\n        if proba.shape[-1] > 1:\n            return proba.argmax(axis=-1)\n        else:\n            return (proba > 0.5).astype('int32')",
        "begin_line": 1120,
        "end_line": 1142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.fit_generator#1145",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)",
        "snippet": "    def fit_generator(self, generator,\n                      steps_per_epoch=None,\n                      epochs=1,\n                      verbose=1,\n                      callbacks=None,\n                      validation_data=None,\n                      validation_steps=None,\n                      class_weight=None,\n                      max_queue_size=10,\n                      workers=1,\n                      use_multiprocessing=False,\n                      shuffle=True,\n                      initial_epoch=0):\n        \"\"\"Fits the model on data generated batch-by-batch by a Python generator.\n\n        The generator is run in parallel to the model, for efficiency.\n        For instance, this allows you to do real-time data augmentation\n        on images on CPU in parallel to training your model on GPU.\n\n        # Arguments\n            generator: A generator.\n                The output of the generator must be either\n                - a tuple (inputs, targets)\n                - a tuple (inputs, targets, sample_weights).\n                All arrays should contain the same number of samples.\n                The generator is expected to loop over its data\n                indefinitely. An epoch finishes when `steps_per_epoch`\n                batches have been seen by the model.\n            steps_per_epoch: Total number of steps (batches of samples)\n                to yield from `generator` before declaring one epoch\n                finished and starting the next epoch. It should typically\n                be equal to the number of samples of your dataset\n                divided by the batch size.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n            epochs: Integer, total number of iterations on the data.\n                Note that in conjunction with initial_epoch, the parameter\n                epochs is to be understood as \"final epoch\". The model is\n                not trained for n steps given by epochs, but until the\n                epoch of index `epochs` is reached.\n            verbose: Verbosity mode, 0, 1, or 2.\n            callbacks: List of callbacks to be called during training.\n            validation_data: This can be either\n                - A generator for the validation data\n                - A tuple (inputs, targets)\n                - A tuple (inputs, targets, sample_weights).\n            validation_steps: Only relevant if `validation_data`\n                is a generator.\n                Number of steps to yield from validation generator\n                at the end of every epoch. It should typically\n                be equal to the number of samples of your\n                validation dataset divided by the batch size.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(validation_data)` as a number of steps.\n            class_weight: Dictionary mapping class indices to a weight\n                for the class.\n            max_queue_size: Maximum size for the generator queue\n            workers: Maximum number of processes to spin up\n            use_multiprocessing: if True, use process based threading.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can't be passed\n                easily to children processes.\n            shuffle: Whether to shuffle the order of the batches at\n                the beginning of each epoch. Only used with instances\n                of `Sequence` (keras.utils.Sequence).\n            initial_epoch: Epoch at which to start training\n                (useful for resuming a previous training run).\n\n        # Returns\n            A `History` object.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n\n        # Example\n\n        ```python\n            def generate_arrays_from_file(path):\n                while 1:\n                    with open(path) as f:\n                        for line in f:\n                            # create Numpy arrays of input data\n                            # and labels, from each line in the file\n                            x, y = process_line(line)\n                            yield (x, y)\n\n            model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n                                steps_per_epoch=1000, epochs=10)\n        ```\n        \"\"\"\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.fit_generator(generator,\n                                        steps_per_epoch,\n                                        epochs,\n                                        verbose=verbose,\n                                        callbacks=callbacks,\n                                        validation_data=validation_data,\n                                        validation_steps=validation_steps,\n                                        class_weight=class_weight,\n                                        max_queue_size=max_queue_size,\n                                        workers=workers,\n                                        use_multiprocessing=use_multiprocessing,\n                                        shuffle=shuffle,\n                                        initial_epoch=initial_epoch)",
        "begin_line": 1145,
        "end_line": 1253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002506265664160401,
            "pseudo_dstar_susp": 0.0006596306068601583,
            "pseudo_tarantula_susp": 0.0029585798816568047,
            "pseudo_op2_susp": 0.0006596306068601583,
            "pseudo_barinel_susp": 0.0029585798816568047
        }
    },
    {
        "name": "keras.models.Sequential.evaluate_generator#1256",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.evaluate_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False)",
        "snippet": "    def evaluate_generator(self, generator, steps=None,\n                           max_queue_size=10, workers=1,\n                           use_multiprocessing=False):\n        \"\"\"Evaluates the model on a data generator.\n\n        The generator should return the same kind of data\n        as accepted by `test_on_batch`.\n\n        # Arguments\n            generator: Generator yielding tuples (inputs, targets)\n                or (inputs, targets, sample_weights)\n            steps: Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n            max_queue_size: maximum size for the generator queue\n            workers: maximum number of processes to spin up\n            use_multiprocessing: if True, use process based threading.\n                Note that because this implementation\n                relies on multiprocessing, you should not pass\n                non picklable arguments to the generator\n                as they can't be passed easily to children processes.\n\n        # Returns\n            Scalar test loss (if the model has no metrics)\n            or list of scalars (if the model computes other metrics).\n            The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n        \"\"\"\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.evaluate_generator(generator,\n                                             steps,\n                                             max_queue_size=max_queue_size,\n                                             workers=workers,\n                                             use_multiprocessing=use_multiprocessing)",
        "begin_line": 1256,
        "end_line": 1295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.predict_generator#1298",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)",
        "snippet": "    def predict_generator(self, generator, steps=None,\n                          max_queue_size=10, workers=1,\n                          use_multiprocessing=False, verbose=0):\n        \"\"\"Generates predictions for the input samples from a data generator.\n\n        The generator should return the same kind of data as accepted by\n        `predict_on_batch`.\n\n        # Arguments\n            generator: generator yielding batches of input samples.\n            steps: Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n            max_queue_size: maximum size for the generator queue\n            workers: maximum number of processes to spin up\n            use_multiprocessing: if True, use process based threading.\n                Note that because this implementation\n                relies on multiprocessing, you should not pass\n                non picklable arguments to the generator\n                as they can't be passed easily to children processes.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            A Numpy array of predictions.\n        \"\"\"\n        if not self.built:\n            self.build()\n        return self.model.predict_generator(generator, steps,\n                                            max_queue_size=max_queue_size,\n                                            workers=workers,\n                                            use_multiprocessing=use_multiprocessing,\n                                            verbose=verbose)",
        "begin_line": 1298,
        "end_line": 1330,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.get_config#1332",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_config(self)",
        "snippet": "    def get_config(self):\n        if isinstance(self.layers[0], legacy_layers.Merge):\n            return self.legacy_get_config()\n\n        config = []\n        for layer in self.layers:\n            config.append({'class_name': layer.__class__.__name__,\n                           'config': layer.get_config()})\n        return copy.deepcopy(config)",
        "begin_line": 1332,
        "end_line": 1340,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.from_config#1343",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        if 'class_name' not in config[0] or config[0]['class_name'] == 'Merge':\n            return cls.legacy_from_config(config)\n\n        model = cls()\n        for conf in config:\n            layer = layer_module.deserialize(conf, custom_objects=custom_objects)\n            model.add(layer)\n        return model",
        "begin_line": 1343,
        "end_line": 1351,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.legacy_get_config#1353",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.legacy_get_config(self)",
        "snippet": "    def legacy_get_config(self):\n        \"\"\"Retrieves the model configuration as a Python list.\n\n        # Returns\n            A list of dicts (each dict is a layer config).\n        \"\"\"\n        config = []\n        if isinstance(self.layers[0], legacy_layers.Merge):\n            assert hasattr(self.layers[0], 'layers')\n            layers = []\n            for layer in self.layers[0].layers:\n                layer_config = {'class_name': layer.__class__.__name__,\n                                'config': layer.get_config()}\n                layers.append(layer_config)\n            merge_config = self.layers[0].get_config()\n            merge_config['layers'] = layers\n            config.append({'class_name': 'Merge', 'config': merge_config})\n        else:\n            config.append({'class_name': self.layers[0].__class__.__name__,\n                           'config': self.layers[0].get_config()})\n        for layer in self.layers[1:]:\n            config.append({'class_name': layer.__class__.__name__,\n                           'config': layer.get_config()})\n        return copy.deepcopy(config)",
        "begin_line": 1353,
        "end_line": 1376,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.legacy_from_config#1379",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.legacy_from_config(cls, config, layer_cache=None)",
        "snippet": "    def legacy_from_config(cls, config, layer_cache=None):\n        \"\"\"Load a model from a legacy configuration.\n\n        # Arguments\n            config: dictionary with configuration.\n            layer_cache: cache to draw pre-existing layer.\n\n        # Returns\n            The loaded Model.\n        \"\"\"\n        if not layer_cache:\n            layer_cache = {}\n\n        def normalize_legacy_config(conf):\n            if 'class_name' not in conf:\n                class_name = conf['name']\n                name = conf.get('custom_name')\n                conf['name'] = name\n                return {'class_name': class_name,\n                        'config': conf}\n            return conf\n\n        # the model we will return\n        model = cls()\n\n        def get_or_create_layer(layer_data):\n            name = layer_data['config'].get('name')\n            if name in layer_cache:\n                return layer_cache[name]\n            layer = layer_module.deserialize(layer_data)\n            layer_cache[name] = layer\n            return layer\n\n        first_layer = config[0]\n        first_layer = normalize_legacy_config(first_layer)\n        if first_layer['class_name'] == 'Merge':\n            merge_inputs = []\n            first_layer_config = first_layer['config']\n            for merge_input_config in first_layer_config.pop('layers'):\n                merge_input = layer_module.deserialize(merge_input_config)\n                merge_inputs.append(merge_input)\n            first_layer_config['layers'] = merge_inputs\n            merge = legacy_layers.Merge.from_config(first_layer_config)\n            model.add(merge)\n        else:\n            layer = get_or_create_layer(first_layer)\n            model.add(layer)\n\n        for conf in config[1:]:\n            conf = normalize_legacy_config(conf)\n            layer = get_or_create_layer(conf)\n            model.add(layer)\n        return model",
        "begin_line": 1379,
        "end_line": 1431,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.normalize_legacy_config#1392",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.normalize_legacy_config(conf)",
        "snippet": "        def normalize_legacy_config(conf):\n            if 'class_name' not in conf:\n                class_name = conf['name']\n                name = conf.get('custom_name')\n                conf['name'] = name\n                return {'class_name': class_name,\n                        'config': conf}\n            return conf",
        "begin_line": 1392,
        "end_line": 1399,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.Sequential.get_or_create_layer#1404",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_or_create_layer(layer_data)",
        "snippet": "        def get_or_create_layer(layer_data):\n            name = layer_data['config'].get('name')\n            if name in layer_cache:\n                return layer_cache[name]\n            layer = layer_module.deserialize(layer_data)\n            layer_cache[name] = layer\n            return layer",
        "begin_line": 1404,
        "end_line": 1410,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models._clone_functional_model#1434",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models._clone_functional_model(model, input_tensors=None)",
        "snippet": "def _clone_functional_model(model, input_tensors=None):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError('Expected `model` argument '\n                         'to be a `Model` instance, got ', model)\n    if isinstance(model, Sequential):\n        raise ValueError('Expected `model` argument '\n                         'to be a functional `Model` instance, '\n                         'got a `Sequential` instance instead:', model)\n\n    layer_map = {}  # Cache for created layers.\n    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers = []\n        input_tensors = []\n        for layer in model.input_layers:\n            input_tensor = Input(batch_shape=layer.batch_input_shape,\n                                 dtype=layer.dtype,\n                                 sparse=layer.sparse,\n                                 name=layer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer = input_tensor._keras_history[0]\n            layer_map[layer] = newly_created_input_layer\n        for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):\n            layer_map[original_input_layer] = cloned_input_layer\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors = topology._to_list(input_tensors)\n        _input_tensors = []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name = model.input_layers[i].name\n                input_tensor = Input(tensor=x,\n                                     name='input_wrapper_for_' + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer = x._keras_history[0]\n                newly_created_input_layer = input_tensor._keras_history[0]\n                layer_map[original_input_layer] = newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors = _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] = (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys = list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse=True)\n    for depth in depth_keys:\n        nodes = model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer = node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer = layer.__class__.from_config(layer.get_config())\n                layer_map[layer] = new_layer\n                layer = new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer = layer_map[layer]\n                # Don't call InputLayer multiple times.\n                if isinstance(layer, topology.InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors = node.input_tensors\n            reference_output_tensors = node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data = []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) == len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs = node.arguments\n                else:\n                    kwargs = {}\n                if len(computed_data) == 1:\n                    computed_tensor, computed_mask = computed_data[0]\n                    if has_arg(layer.call, 'mask'):\n                        if 'mask' not in kwargs:\n                            kwargs['mask'] = computed_mask\n                    output_tensors = topology._to_list(\n                        layer(computed_tensor, **kwargs))\n                    output_masks = topology._to_list(\n                        layer.compute_mask(computed_tensor,\n                                           computed_mask))\n                    computed_tensors = [computed_tensor]\n                    computed_masks = [computed_mask]\n                else:\n                    computed_tensors = [x[0] for x in computed_data]\n                    computed_masks = [x[1] for x in computed_data]\n                    if has_arg(layer.call, 'mask'):\n                        if 'mask' not in kwargs:\n                            kwargs['mask'] = computed_masks\n                    output_tensors = topology._to_list(\n                        layer(computed_tensors, **kwargs))\n                    output_masks = topology._to_list(\n                        layer.compute_mask(computed_tensors,\n                                           computed_masks))\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] = (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors = []\n    for x in model.outputs:\n        assert x in tensor_map, 'Could not compute output ' + str(x)\n        tensor, _ = tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name=model.name)",
        "begin_line": 1434,
        "end_line": 1577,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models._clone_sequential_model#1580",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models._clone_sequential_model(model, input_tensors=None)",
        "snippet": "def _clone_sequential_model(model, input_tensors=None):\n    \"\"\"Clone a `Sequential` model instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Sequential`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Sequential` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Sequential):\n        raise ValueError('Expected `model` argument '\n                         'to be a `Sequential` model instance, '\n                         'but got:', model)\n\n    def clone(layer):\n        return layer.__class__.from_config(layer.get_config())\n\n    layers = [clone(layer) for layer in model.layers]\n    if input_tensors is None:\n        return Sequential(layers=layers, name=model.name)\n    else:\n        if len(topology._to_list(input_tensors)) != 1:\n            raise ValueError('To clone a `Sequential` model, we expect '\n                             ' at most one tensor '\n                             'as part of `input_tensors`.')\n        x = topology._to_list(input_tensors)[0]\n        if K.is_keras_tensor(x):\n            origin_layer = x._keras_history[0]\n            if isinstance(origin_layer, topology.InputLayer):\n                return Sequential(layers=[origin_layer] + layers,\n                                  name=model.name)\n            else:\n                raise ValueError('Cannot clone a `Sequential` model on top '\n                                 'of a tensor that comes from a Keras layer '\n                                 'other than an `InputLayer`. '\n                                 'Use the functional API instead.')\n        input_tensor = Input(tensor=x,\n                             name='input_wrapper_for_' + str(x.name))\n        input_layer = input_tensor._keras_history[0]\n        return Sequential(layers=[input_layer] + layers, name=model.name)",
        "begin_line": 1580,
        "end_line": 1631,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.clone#1606",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.clone(layer)",
        "snippet": "    def clone(layer):\n        return layer.__class__.from_config(layer.get_config())",
        "begin_line": 1606,
        "end_line": 1607,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.models.clone_model#1634",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.clone_model(model, input_tensors=None)",
        "snippet": "def clone_model(model, input_tensors=None):\n    \"\"\"Clone any `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`\n            (could be a functional model or a Sequential model).\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if isinstance(model, Sequential):\n        return _clone_sequential_model(model, input_tensors=input_tensors)\n    else:\n        return _clone_functional_model(model, input_tensors=input_tensors)",
        "begin_line": 1634,
        "end_line": 1659,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent._CuDNNRNN.__init__#30",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent._CuDNNRNN",
        "signature": "keras.layers.cudnn_recurrent._CuDNNRNN.__init__(self, return_sequences=False, return_state=False, go_backwards=False, stateful=False, **kwargs)",
        "snippet": "    def __init__(self,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 **kwargs):\n        if K.backend() != 'tensorflow':\n            raise RuntimeError('CuDNN RNNs are only available '\n                               'with the TensorFlow backend.')\n        super(RNN, self).__init__(**kwargs)\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.supports_masking = False\n        self.input_spec = [InputSpec(ndim=3)]\n        if hasattr(self.cell.state_size, '__len__'):\n            state_size = self.cell.state_size\n        else:\n            state_size = [self.cell.state_size]\n        self.state_spec = [InputSpec(shape=(None, dim))\n                           for dim in state_size]\n        self.constants_spec = None\n        self._states = None\n        self._num_constants = None",
        "begin_line": 30,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent._CuDNNRNN._canonical_to_params#56",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent._CuDNNRNN",
        "signature": "keras.layers.cudnn_recurrent._CuDNNRNN._canonical_to_params(self, weights, biases)",
        "snippet": "    def _canonical_to_params(self, weights, biases):\n        import tensorflow as tf\n        weights = [tf.reshape(x, (-1,)) for x in weights]\n        biases = [tf.reshape(x, (-1,)) for x in biases]\n        return tf.concat(weights + biases, 0)",
        "begin_line": 56,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent._CuDNNRNN.call#62",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent._CuDNNRNN",
        "signature": "keras.layers.cudnn_recurrent._CuDNNRNN.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        if isinstance(mask, list):\n            mask = mask[0]\n        if mask is not None:\n            raise ValueError('Masking is not supported for CuDNN RNNs.')\n\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            initial_state = inputs[1:]\n            inputs = inputs[0]\n        elif initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if len(initial_state) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_state)) +\n                             ' initial states.')\n\n        if self.go_backwards:\n            # Reverse time axis.\n            inputs = K.reverse(inputs, 1)\n        output, states = self._process_batch(inputs, initial_state)\n\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        if self.return_state:\n            return [output] + states\n        else:\n            return output",
        "begin_line": 62,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent._CuDNNRNN.get_config#103",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent._CuDNNRNN",
        "signature": "keras.layers.cudnn_recurrent._CuDNNRNN.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'return_sequences': self.return_sequences,\n                  'return_state': self.return_state,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful}\n        base_config = super(RNN, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 103,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent._CuDNNRNN.get_losses_for#131",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent._CuDNNRNN",
        "signature": "keras.layers.cudnn_recurrent._CuDNNRNN.get_losses_for(self, inputs=None)",
        "snippet": "    def get_losses_for(self, inputs=None):\n        return super(RNN, self).get_losses_for(inputs=inputs)",
        "begin_line": 131,
        "end_line": 132,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent.CuDNNGRU.__init__#179",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent.CuDNNGRU",
        "signature": "keras.layers.cudnn_recurrent.CuDNNGRU.__init__(self, units, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, return_state=False, stateful=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 return_sequences=False,\n                 return_state=False,\n                 stateful=False,\n                 **kwargs):\n        self.units = units\n        super(CuDNNGRU, self).__init__(\n            return_sequences=return_sequences,\n            return_state=return_state,\n            stateful=stateful,\n            **kwargs)\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)",
        "begin_line": 179,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent.CuDNNGRU.build#220",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent.CuDNNGRU",
        "signature": "keras.layers.cudnn_recurrent.CuDNNGRU.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        super(CuDNNGRU, self).build(input_shape)\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n        input_dim = input_shape[-1]\n\n        from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n        self._cudnn_gru = cudnn_rnn_ops.CudnnGRU(\n            num_layers=1,\n            num_units=self.units,\n            input_size=input_dim,\n            input_mode='linear_input')\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 3),\n                                      name='kernel',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 3),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        self.bias = self.add_weight(shape=(self.units * 6,),\n                                    name='bias',\n                                    initializer=self.bias_initializer,\n                                    regularizer=self.bias_regularizer,\n                                    constraint=self.bias_constraint)\n\n        self.kernel_z = self.kernel[:, :self.units]\n        self.recurrent_kernel_z = self.recurrent_kernel[:, :self.units]\n        self.kernel_r = self.kernel[:, self.units: self.units * 2]\n        self.recurrent_kernel_r = self.recurrent_kernel[:,\n                                                        self.units:\n                                                        self.units * 2]\n        self.kernel_h = self.kernel[:, self.units * 2:]\n        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2:]\n\n        self.bias_z_i = self.bias[:self.units]\n        self.bias_r_i = self.bias[self.units: self.units * 2]\n        self.bias_h_i = self.bias[self.units * 2: self.units * 3]\n        self.bias_z = self.bias[self.units * 3: self.units * 4]\n        self.bias_r = self.bias[self.units * 4: self.units * 5]\n        self.bias_h = self.bias[self.units * 5:]\n\n        self.built = True",
        "begin_line": 220,
        "end_line": 267,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent.CuDNNGRU._process_batch#269",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent.CuDNNGRU",
        "signature": "keras.layers.cudnn_recurrent.CuDNNGRU._process_batch(self, inputs, initial_state)",
        "snippet": "    def _process_batch(self, inputs, initial_state):\n        import tensorflow as tf\n        inputs = tf.transpose(inputs, (1, 0, 2))\n        input_h = initial_state[0]\n        input_h = tf.expand_dims(input_h, axis=0)\n\n        params = self._canonical_to_params(\n            weights=[\n                self.kernel_r,\n                self.kernel_z,\n                self.kernel_h,\n                self.recurrent_kernel_r,\n                self.recurrent_kernel_z,\n                self.recurrent_kernel_h,\n            ],\n            biases=[\n                self.bias_r_i,\n                self.bias_z_i,\n                self.bias_h_i,\n                self.bias_r,\n                self.bias_z,\n                self.bias_h,\n            ],\n        )\n        outputs, h = self._cudnn_gru(\n            inputs,\n            input_h=input_h,\n            params=params,\n            is_training=True)\n\n        if self.stateful or self.return_state:\n            h = h[0]\n        if self.return_sequences:\n            output = tf.transpose(outputs, (1, 0, 2))\n        else:\n            output = outputs[-1]\n        return output, [h]",
        "begin_line": 269,
        "end_line": 305,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent.CuDNNGRU.get_config#307",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent.CuDNNGRU",
        "signature": "keras.layers.cudnn_recurrent.CuDNNGRU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'units': self.units,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)}\n        base_config = super(CuDNNGRU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 307,
        "end_line": 321,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent.CuDNNLSTM.__init__#371",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent.CuDNNLSTM",
        "signature": "keras.layers.cudnn_recurrent.CuDNNLSTM.__init__(self, units, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, return_state=False, stateful=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 return_sequences=False,\n                 return_state=False,\n                 stateful=False,\n                 **kwargs):\n        self.units = units\n        super(CuDNNLSTM, self).__init__(\n            return_sequences=return_sequences,\n            return_state=return_state,\n            stateful=stateful,\n            **kwargs)\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)",
        "begin_line": 371,
        "end_line": 406,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent.CuDNNLSTM.build#414",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent.CuDNNLSTM",
        "signature": "keras.layers.cudnn_recurrent.CuDNNLSTM.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        super(CuDNNLSTM, self).build(input_shape)\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n        input_dim = input_shape[-1]\n\n        from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n        self._cudnn_lstm = cudnn_rnn_ops.CudnnLSTM(\n            num_layers=1,\n            num_units=self.units,\n            input_size=input_dim,\n            input_mode='linear_input')\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n                                      name='kernel',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 4),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        if self.unit_forget_bias:\n            def bias_initializer(shape, *args, **kwargs):\n                return K.concatenate([\n                    self.bias_initializer((self.units * 5,), *args, **kwargs),\n                    initializers.Ones()((self.units,), *args, **kwargs),\n                    self.bias_initializer((self.units * 2,), *args, **kwargs),\n                ])\n        else:\n            bias_initializer = self.bias_initializer\n        self.bias = self.add_weight(shape=(self.units * 8,),\n                                    name='bias',\n                                    initializer=bias_initializer,\n                                    regularizer=self.bias_regularizer,\n                                    constraint=self.bias_constraint)\n\n        self.kernel_i = self.kernel[:, :self.units]\n        self.kernel_f = self.kernel[:, self.units: self.units * 2]\n        self.kernel_c = self.kernel[:, self.units * 2: self.units * 3]\n        self.kernel_o = self.kernel[:, self.units * 3:]\n\n        self.recurrent_kernel_i = self.recurrent_kernel[:, :self.units]\n        self.recurrent_kernel_f = self.recurrent_kernel[:, self.units: self.units * 2]\n        self.recurrent_kernel_c = self.recurrent_kernel[:, self.units * 2: self.units * 3]\n        self.recurrent_kernel_o = self.recurrent_kernel[:, self.units * 3:]\n\n        self.bias_i_i = self.bias[:self.units]\n        self.bias_f_i = self.bias[self.units: self.units * 2]\n        self.bias_c_i = self.bias[self.units * 2: self.units * 3]\n        self.bias_o_i = self.bias[self.units * 3: self.units * 4]\n        self.bias_i = self.bias[self.units * 4: self.units * 5]\n        self.bias_f = self.bias[self.units * 5: self.units * 6]\n        self.bias_c = self.bias[self.units * 6: self.units * 7]\n        self.bias_o = self.bias[self.units * 7:]\n\n        self.built = True",
        "begin_line": 414,
        "end_line": 473,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent.CuDNNLSTM._process_batch#475",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent.CuDNNLSTM",
        "signature": "keras.layers.cudnn_recurrent.CuDNNLSTM._process_batch(self, inputs, initial_state)",
        "snippet": "    def _process_batch(self, inputs, initial_state):\n        import tensorflow as tf\n        inputs = tf.transpose(inputs, (1, 0, 2))\n        input_h = initial_state[0]\n        input_c = initial_state[1]\n        input_h = tf.expand_dims(input_h, axis=0)\n        input_c = tf.expand_dims(input_c, axis=0)\n\n        params = self._canonical_to_params(\n            weights=[\n                self.kernel_i,\n                self.kernel_f,\n                self.kernel_c,\n                self.kernel_o,\n                self.recurrent_kernel_i,\n                self.recurrent_kernel_f,\n                self.recurrent_kernel_c,\n                self.recurrent_kernel_o,\n            ],\n            biases=[\n                self.bias_i_i,\n                self.bias_f_i,\n                self.bias_c_i,\n                self.bias_o_i,\n                self.bias_i,\n                self.bias_f,\n                self.bias_c,\n                self.bias_o,\n            ],\n        )\n        outputs, h, c = self._cudnn_lstm(\n            inputs,\n            input_h=input_h,\n            input_c=input_c,\n            params=params,\n            is_training=True)\n\n        if self.stateful or self.return_state:\n            h = h[0]\n            c = c[0]\n        if self.return_sequences:\n            output = tf.transpose(outputs, (1, 0, 2))\n        else:\n            output = outputs[-1]\n        return output, [h, c]",
        "begin_line": 475,
        "end_line": 519,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.cudnn_recurrent.CuDNNLSTM.get_config#521",
        "src_path": "keras/layers/cudnn_recurrent.py",
        "class_name": "keras.layers.cudnn_recurrent.CuDNNLSTM",
        "signature": "keras.layers.cudnn_recurrent.CuDNNLSTM.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'units': self.units,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'unit_forget_bias': self.unit_forget_bias,\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)}\n        base_config = super(CuDNNLSTM, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 521,
        "end_line": 536,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.models.needs_legacy_support#8",
        "src_path": "keras/legacy/models.py",
        "class_name": "keras.legacy.models",
        "signature": "keras.legacy.models.needs_legacy_support(model)",
        "snippet": "def needs_legacy_support(model):\n    return isinstance(model.layers[0], Merge)",
        "begin_line": 8,
        "end_line": 9,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.44324525493115e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.models.legacy_sequential_layers#12",
        "src_path": "keras/legacy/models.py",
        "class_name": "keras.legacy.models",
        "signature": "keras.legacy.models.legacy_sequential_layers(model)",
        "snippet": "def legacy_sequential_layers(model):\n    layers = []\n    if model.layers:\n        if isinstance(model.layers[0], Merge):\n            merge = model.layers[0]\n            for layer in merge.layers:\n                if hasattr(layer, 'layers'):\n                    for sublayer in layer.layers:\n                        if sublayer not in layers:\n                            layers.append(sublayer)\n                else:\n                    if layer not in layers:\n                        layers.append(layer)\n        else:\n            if model.layers[0] not in layers:\n                layers.append(model.layers[0])\n        for layer in model.layers[1:]:\n            if layer not in layers:\n                layers.append(layer)\n    return layers",
        "begin_line": 12,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.datasets.imdb.load_data#14",
        "src_path": "keras/datasets/imdb.py",
        "class_name": "keras.datasets.imdb",
        "signature": "keras.datasets.imdb.load_data(path='imdb.npz', num_words=None, skip_top=0, maxlen=None, seed=113, start_char=1, oov_char=2, index_from=3, **kwargs)",
        "snippet": "def load_data(path='imdb.npz', num_words=None, skip_top=0,\n              maxlen=None, seed=113,\n              start_char=1, oov_char=2, index_from=3, **kwargs):\n    \"\"\"Loads the IMDB dataset.\n\n    # Arguments\n        path: where to cache the data (relative to `~/.keras/dataset`).\n        num_words: max number of words to include. Words are ranked\n            by how often they occur (in the training set) and only\n            the most frequent words are kept\n        skip_top: skip the top N most frequently occurring words\n            (which may not be informative).\n        maxlen: sequences longer than this will be filtered out.\n        seed: random seed for sample shuffling.\n        start_char: The start of a sequence will be marked with this character.\n            Set to 1 because 0 is usually the padding character.\n        oov_char: words that were cut out because of the `num_words`\n            or `skip_top` limit will be replaced with this character.\n        index_from: index actual words with this index and higher.\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n\n    # Raises\n        ValueError: in case `maxlen` is so low\n            that no input sequence could be kept.\n\n    Note that the 'out of vocabulary' character is only used for\n    words that were present in the training set but are not included\n    because they're not making the `num_words` cut here.\n    Words that were not seen in the training set but are in the test set\n    have simply been skipped.\n    \"\"\"\n    # Legacy support\n    if 'nb_words' in kwargs:\n        warnings.warn('The `nb_words` argument in `load_data` '\n                      'has been renamed `num_words`.')\n        num_words = kwargs.pop('nb_words')\n    if kwargs:\n        raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n\n    path = get_file(path,\n                    origin='https://s3.amazonaws.com/text-datasets/imdb.npz',\n                    file_hash='599dadb1135973df5b59232a0e9a887c')\n    with np.load(path) as f:\n        x_train, labels_train = f['x_train'], f['y_train']\n        x_test, labels_test = f['x_test'], f['y_test']\n\n    np.random.seed(seed)\n    indices = np.arange(len(x_train))\n    np.random.shuffle(indices)\n    x_train = x_train[indices]\n    labels_train = labels_train[indices]\n\n    indices = np.arange(len(x_test))\n    np.random.shuffle(indices)\n    x_test = x_test[indices]\n    labels_test = labels_test[indices]\n\n    xs = np.concatenate([x_train, x_test])\n    labels = np.concatenate([labels_train, labels_test])\n\n    if start_char is not None:\n        xs = [[start_char] + [w + index_from for w in x] for x in xs]\n    elif index_from:\n        xs = [[w + index_from for w in x] for x in xs]\n\n    if maxlen:\n        xs, labels = _remove_long_seq(maxlen, xs, labels)\n        if not xs:\n            raise ValueError('After filtering for sequences shorter than maxlen=' +\n                             str(maxlen) + ', no sequence was kept. '\n                             'Increase maxlen.')\n    if not num_words:\n        num_words = max([max(x) for x in xs])\n\n    # by convention, use 2 as OOV word\n    # reserve 'index_from' (=3 by default) characters:\n    # 0 (padding), 1 (start), 2 (OOV)\n    if oov_char is not None:\n        xs = [[w if (skip_top <= w < num_words) else oov_char for w in x] for x in xs]\n    else:\n        xs = [[w for w in x if skip_top <= w < num_words] for x in xs]\n\n    idx = len(x_train)\n    x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n    x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n\n    return (x_train, y_train), (x_test, y_test)",
        "begin_line": 14,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.datasets.imdb.get_word_index#105",
        "src_path": "keras/datasets/imdb.py",
        "class_name": "keras.datasets.imdb",
        "signature": "keras.datasets.imdb.get_word_index(path='imdb_word_index.json')",
        "snippet": "def get_word_index(path='imdb_word_index.json'):\n    \"\"\"Retrieves the dictionary mapping word indices back to words.\n\n    # Arguments\n        path: where to cache the data (relative to `~/.keras/dataset`).\n\n    # Returns\n        The word index dictionary.\n    \"\"\"\n    path = get_file(path,\n                    origin='https://s3.amazonaws.com/text-datasets/imdb_word_index.json',\n                    file_hash='bfafd718b763782e994055a2d397834f')\n    with open(path) as f:\n        return json.load(f)",
        "begin_line": 105,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.mean_squared_error#13",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.mean_squared_error(y_true, y_pred)",
        "snippet": "def mean_squared_error(y_true, y_pred):\n    return K.mean(K.square(y_pred - y_true), axis=-1)",
        "begin_line": 13,
        "end_line": 14,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003694126339120798,
            "pseudo_dstar_susp": 0.0003694126339120798,
            "pseudo_tarantula_susp": 0.0003705075954057058,
            "pseudo_op2_susp": 0.0003694126339120798,
            "pseudo_barinel_susp": 0.0003705075954057058
        }
    },
    {
        "name": "keras.losses.mean_absolute_error#17",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.mean_absolute_error(y_true, y_pred)",
        "snippet": "def mean_absolute_error(y_true, y_pred):\n    return K.mean(K.abs(y_pred - y_true), axis=-1)",
        "begin_line": 17,
        "end_line": 18,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.mean_absolute_percentage_error#21",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.mean_absolute_percentage_error(y_true, y_pred)",
        "snippet": "def mean_absolute_percentage_error(y_true, y_pred):\n    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n                                            K.epsilon(),\n                                            None))\n    return 100. * K.mean(diff, axis=-1)",
        "begin_line": 21,
        "end_line": 25,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.mean_squared_logarithmic_error#28",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.mean_squared_logarithmic_error(y_true, y_pred)",
        "snippet": "def mean_squared_logarithmic_error(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n    return K.mean(K.square(first_log - second_log), axis=-1)",
        "begin_line": 28,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.squared_hinge#34",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.squared_hinge(y_true, y_pred)",
        "snippet": "def squared_hinge(y_true, y_pred):\n    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)), axis=-1)",
        "begin_line": 34,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.hinge#38",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.hinge(y_true, y_pred)",
        "snippet": "def hinge(y_true, y_pred):\n    return K.mean(K.maximum(1. - y_true * y_pred, 0.), axis=-1)",
        "begin_line": 38,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.categorical_hinge#42",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.categorical_hinge(y_true, y_pred)",
        "snippet": "def categorical_hinge(y_true, y_pred):\n    pos = K.sum(y_true * y_pred, axis=-1)\n    neg = K.max((1. - y_true) * y_pred, axis=-1)\n    return K.maximum(0., neg - pos + 1.)",
        "begin_line": 42,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.logcosh#48",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.logcosh(y_true, y_pred)",
        "snippet": "def logcosh(y_true, y_pred):\n    \"\"\"Logarithm of the hyperbolic cosine of the prediction error.\n\n    `log(cosh(x))` is approximately equal to `(x ** 2) / 2` for small `x` and\n    to `abs(x) - log(2)` for large `x`. This means that 'logcosh' works mostly\n    like the mean squared error, but will not be so strongly affected by the\n    occasional wildly incorrect prediction.\n\n    # Arguments\n        y_true: tensor of true targets.\n        y_pred: tensor of predicted targets.\n\n    # Returns\n        Tensor with one scalar loss entry per sample.\n    \"\"\"\n    def _logcosh(x):\n        return x + K.softplus(-2. * x) - K.log(2.)\n    return K.mean(_logcosh(y_pred - y_true), axis=-1)",
        "begin_line": 48,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses._logcosh#63",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses._logcosh(x)",
        "snippet": "    def _logcosh(x):\n        return x + K.softplus(-2. * x) - K.log(2.)",
        "begin_line": 63,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.categorical_crossentropy#68",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.categorical_crossentropy(y_true, y_pred)",
        "snippet": "def categorical_crossentropy(y_true, y_pred):\n    return K.categorical_crossentropy(y_true, y_pred)",
        "begin_line": 68,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000425531914893617,
            "pseudo_dstar_susp": 0.00041841004184100416,
            "pseudo_tarantula_susp": 0.0006706908115358819,
            "pseudo_op2_susp": 0.00041841004184100416,
            "pseudo_barinel_susp": 0.0006706908115358819
        }
    },
    {
        "name": "keras.losses.sparse_categorical_crossentropy#72",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.sparse_categorical_crossentropy(y_true, y_pred)",
        "snippet": "def sparse_categorical_crossentropy(y_true, y_pred):\n    return K.sparse_categorical_crossentropy(y_true, y_pred)",
        "begin_line": 72,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.binary_crossentropy#76",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.binary_crossentropy(y_true, y_pred)",
        "snippet": "def binary_crossentropy(y_true, y_pred):\n    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)",
        "begin_line": 76,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.kullback_leibler_divergence#80",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.kullback_leibler_divergence(y_true, y_pred)",
        "snippet": "def kullback_leibler_divergence(y_true, y_pred):\n    y_true = K.clip(y_true, K.epsilon(), 1)\n    y_pred = K.clip(y_pred, K.epsilon(), 1)\n    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)",
        "begin_line": 80,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.poisson#86",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.poisson(y_true, y_pred)",
        "snippet": "def poisson(y_true, y_pred):\n    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)",
        "begin_line": 86,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.cosine_proximity#90",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.cosine_proximity(y_true, y_pred)",
        "snippet": "def cosine_proximity(y_true, y_pred):\n    y_true = K.l2_normalize(y_true, axis=-1)\n    y_pred = K.l2_normalize(y_pred, axis=-1)\n    return -K.sum(y_true * y_pred, axis=-1)",
        "begin_line": 90,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.serialize#106",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.serialize(loss)",
        "snippet": "def serialize(loss):\n    return serialize_keras_object(loss)",
        "begin_line": 106,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.losses.deserialize#110",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.deserialize(name, custom_objects=None)",
        "snippet": "def deserialize(name, custom_objects=None):\n    return deserialize_keras_object(name,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='loss function')",
        "begin_line": 110,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048590864917395527,
            "pseudo_dstar_susp": 0.0010070493454179255,
            "pseudo_tarantula_susp": 0.0004060089321965083,
            "pseudo_op2_susp": 0.0010070493454179255,
            "pseudo_barinel_susp": 0.0004060089321965083
        }
    },
    {
        "name": "keras.losses.get#117",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.get(identifier)",
        "snippet": "def get(identifier):\n    if identifier is None:\n        return None\n    if isinstance(identifier, six.string_types):\n        identifier = str(identifier)\n        return deserialize(identifier)\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret '\n                         'loss function identifier:', identifier)",
        "begin_line": 117,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004911591355599214,
            "pseudo_dstar_susp": 0.001017293997965412,
            "pseudo_tarantula_susp": 0.00040766408479412964,
            "pseudo_op2_susp": 0.001017293997965412,
            "pseudo_barinel_susp": 0.00040766408479412964
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.__init__#60",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.__init__(self, axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None, **kwargs)",
        "snippet": "    def __init__(self,\n                 axis=-1,\n                 momentum=0.99,\n                 epsilon=1e-3,\n                 center=True,\n                 scale=True,\n                 beta_initializer='zeros',\n                 gamma_initializer='ones',\n                 moving_mean_initializer='zeros',\n                 moving_variance_initializer='ones',\n                 beta_regularizer=None,\n                 gamma_regularizer=None,\n                 beta_constraint=None,\n                 gamma_constraint=None,\n                 **kwargs):\n        super(BatchNormalization, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.axis = axis\n        self.momentum = momentum\n        self.epsilon = epsilon\n        self.center = center\n        self.scale = scale\n        self.beta_initializer = initializers.get(beta_initializer)\n        self.gamma_initializer = initializers.get(gamma_initializer)\n        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\n        self.moving_variance_initializer = initializers.get(moving_variance_initializer)\n        self.beta_regularizer = regularizers.get(beta_regularizer)\n        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n        self.beta_constraint = constraints.get(beta_constraint)\n        self.gamma_constraint = constraints.get(gamma_constraint)",
        "begin_line": 60,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.build#91",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        dim = input_shape[self.axis]\n        if dim is None:\n            raise ValueError('Axis ' + str(self.axis) + ' of '\n                             'input tensor should have a defined dimension '\n                             'but the layer received an input with shape ' +\n                             str(input_shape) + '.')\n        self.input_spec = InputSpec(ndim=len(input_shape),\n                                    axes={self.axis: dim})\n        shape = (dim,)\n\n        if self.scale:\n            self.gamma = self.add_weight(shape=shape,\n                                         name='gamma',\n                                         initializer=self.gamma_initializer,\n                                         regularizer=self.gamma_regularizer,\n                                         constraint=self.gamma_constraint)\n        else:\n            self.gamma = None\n        if self.center:\n            self.beta = self.add_weight(shape=shape,\n                                        name='beta',\n                                        initializer=self.beta_initializer,\n                                        regularizer=self.beta_regularizer,\n                                        constraint=self.beta_constraint)\n        else:\n            self.beta = None\n        self.moving_mean = self.add_weight(\n            shape=shape,\n            name='moving_mean',\n            initializer=self.moving_mean_initializer,\n            trainable=False)\n        self.moving_variance = self.add_weight(\n            shape=shape,\n            name='moving_variance',\n            initializer=self.moving_variance_initializer,\n            trainable=False)\n        self.built = True",
        "begin_line": 91,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.call#130",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        input_shape = K.int_shape(inputs)\n        # Prepare broadcasting shape.\n        ndim = len(input_shape)\n        reduction_axes = list(range(len(input_shape)))\n        del reduction_axes[self.axis]\n        broadcast_shape = [1] * len(input_shape)\n        broadcast_shape[self.axis] = input_shape[self.axis]\n\n        # Determines whether broadcasting is needed.\n        needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])\n\n        def normalize_inference():\n            if needs_broadcasting:\n                # In this case we must explicitly broadcast all parameters.\n                broadcast_moving_mean = K.reshape(self.moving_mean,\n                                                  broadcast_shape)\n                broadcast_moving_variance = K.reshape(self.moving_variance,\n                                                      broadcast_shape)\n                if self.center:\n                    broadcast_beta = K.reshape(self.beta, broadcast_shape)\n                else:\n                    broadcast_beta = None\n                if self.scale:\n                    broadcast_gamma = K.reshape(self.gamma,\n                                                broadcast_shape)\n                else:\n                    broadcast_gamma = None\n                return K.batch_normalization(\n                    inputs,\n                    broadcast_moving_mean,\n                    broadcast_moving_variance,\n                    broadcast_beta,\n                    broadcast_gamma,\n                    epsilon=self.epsilon)\n            else:\n                return K.batch_normalization(\n                    inputs,\n                    self.moving_mean,\n                    self.moving_variance,\n                    self.beta,\n                    self.gamma,\n                    epsilon=self.epsilon)\n\n        # If the learning phase is *static* and set to inference:\n        if training in {0, False}:\n            return normalize_inference()\n\n        # If the learning is either dynamic, or set to training:\n        normed_training, mean, variance = K.normalize_batch_in_training(\n            inputs, self.gamma, self.beta, reduction_axes,\n            epsilon=self.epsilon)\n\n        if K.backend() != 'cntk':\n            sample_size = K.prod([K.shape(inputs)[axis]\n                                  for axis in reduction_axes])\n            sample_size = K.cast(sample_size, dtype=K.dtype(inputs))\n\n            # sample variance - unbiased estimator of population variance\n            variance *= sample_size / (sample_size - (1.0 + self.epsilon))\n\n        self.add_update([K.moving_average_update(self.moving_mean,\n                                                 mean,\n                                                 self.momentum),\n                         K.moving_average_update(self.moving_variance,\n                                                 variance,\n                                                 self.momentum)],\n                        inputs)\n\n        # Pick the normalized form corresponding to the training phase.\n        return K.in_train_phase(normed_training,\n                                normalize_inference,\n                                training=training)",
        "begin_line": 130,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.normalize_inference#142",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.normalize_inference()",
        "snippet": "        def normalize_inference():\n            if needs_broadcasting:\n                # In this case we must explicitly broadcast all parameters.\n                broadcast_moving_mean = K.reshape(self.moving_mean,\n                                                  broadcast_shape)\n                broadcast_moving_variance = K.reshape(self.moving_variance,\n                                                      broadcast_shape)\n                if self.center:\n                    broadcast_beta = K.reshape(self.beta, broadcast_shape)\n                else:\n                    broadcast_beta = None\n                if self.scale:\n                    broadcast_gamma = K.reshape(self.gamma,\n                                                broadcast_shape)\n                else:\n                    broadcast_gamma = None\n                return K.batch_normalization(\n                    inputs,\n                    broadcast_moving_mean,\n                    broadcast_moving_variance,\n                    broadcast_beta,\n                    broadcast_gamma,\n                    epsilon=self.epsilon)\n            else:\n                return K.batch_normalization(\n                    inputs,\n                    self.moving_mean,\n                    self.moving_variance,\n                    self.beta,\n                    self.gamma,\n                    epsilon=self.epsilon)",
        "begin_line": 142,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.get_config#204",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'axis': self.axis,\n            'momentum': self.momentum,\n            'epsilon': self.epsilon,\n            'center': self.center,\n            'scale': self.scale,\n            'beta_initializer': initializers.serialize(self.beta_initializer),\n            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n            'moving_mean_initializer': initializers.serialize(self.moving_mean_initializer),\n            'moving_variance_initializer': initializers.serialize(self.moving_variance_initializer),\n            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n            'beta_constraint': constraints.serialize(self.beta_constraint),\n            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n        }\n        base_config = super(BatchNormalization, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 204,
        "end_line": 221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.compute_output_shape#223",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 223,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.877737513786041e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.generate_legacy_interface#13",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.generate_legacy_interface(allowed_positional_args=None, conversions=None, preprocessor=None, value_conversions=None, object_type='class')",
        "snippet": "def generate_legacy_interface(allowed_positional_args=None,\n                              conversions=None,\n                              preprocessor=None,\n                              value_conversions=None,\n                              object_type='class'):\n    if allowed_positional_args is None:\n        check_positional_args = False\n    else:\n        check_positional_args = True\n    allowed_positional_args = allowed_positional_args or []\n    conversions = conversions or []\n    value_conversions = value_conversions or []\n\n    def legacy_support(func):\n        @six.wraps(func)\n        def wrapper(*args, **kwargs):\n            if object_type == 'class':\n                object_name = args[0].__class__.__name__\n            else:\n                object_name = func.__name__\n            if preprocessor:\n                args, kwargs, converted = preprocessor(args, kwargs)\n            else:\n                converted = []\n            if check_positional_args:\n                if len(args) > len(allowed_positional_args) + 1:\n                    raise TypeError('`' + object_name +\n                                    '` can accept only ' +\n                                    str(len(allowed_positional_args)) +\n                                    ' positional arguments ' +\n                                    str(tuple(allowed_positional_args)) +\n                                    ', but you passed the following '\n                                    'positional arguments: ' +\n                                    str(list(args[1:])))\n            for key in value_conversions:\n                if key in kwargs:\n                    old_value = kwargs[key]\n                    if old_value in value_conversions[key]:\n                        kwargs[key] = value_conversions[key][old_value]\n            for old_name, new_name in conversions:\n                if old_name in kwargs:\n                    value = kwargs.pop(old_name)\n                    if new_name in kwargs:\n                        raise_duplicate_arg_error(old_name, new_name)\n                    kwargs[new_name] = value\n                    converted.append((new_name, old_name))\n            if converted:\n                signature = '`' + object_name + '('\n                for i, value in enumerate(args[1:]):\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(args[1:]) - 1 or kwargs:\n                        signature += ', '\n                for i, (name, value) in enumerate(kwargs.items()):\n                    signature += name + '='\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(kwargs) - 1:\n                        signature += ', '\n                signature += ')`'\n                warnings.warn('Update your `' + object_name +\n                              '` call to the Keras 2 API: ' + signature, stacklevel=2)\n            return func(*args, **kwargs)\n        wrapper._original_function = func\n        return wrapper\n    return legacy_support",
        "begin_line": 13,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.legacy_support#26",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.legacy_support(func)",
        "snippet": "    def legacy_support(func):\n        @six.wraps(func)\n        def wrapper(*args, **kwargs):\n            if object_type == 'class':\n                object_name = args[0].__class__.__name__\n            else:\n                object_name = func.__name__\n            if preprocessor:\n                args, kwargs, converted = preprocessor(args, kwargs)\n            else:\n                converted = []\n            if check_positional_args:\n                if len(args) > len(allowed_positional_args) + 1:\n                    raise TypeError('`' + object_name +\n                                    '` can accept only ' +\n                                    str(len(allowed_positional_args)) +\n                                    ' positional arguments ' +\n                                    str(tuple(allowed_positional_args)) +\n                                    ', but you passed the following '\n                                    'positional arguments: ' +\n                                    str(list(args[1:])))\n            for key in value_conversions:\n                if key in kwargs:\n                    old_value = kwargs[key]\n                    if old_value in value_conversions[key]:\n                        kwargs[key] = value_conversions[key][old_value]\n            for old_name, new_name in conversions:\n                if old_name in kwargs:\n                    value = kwargs.pop(old_name)\n                    if new_name in kwargs:\n                        raise_duplicate_arg_error(old_name, new_name)\n                    kwargs[new_name] = value\n                    converted.append((new_name, old_name))\n            if converted:\n                signature = '`' + object_name + '('\n                for i, value in enumerate(args[1:]):\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(args[1:]) - 1 or kwargs:\n                        signature += ', '\n                for i, (name, value) in enumerate(kwargs.items()):\n                    signature += name + '='\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(kwargs) - 1:\n                        signature += ', '\n                signature += ')`'\n                warnings.warn('Update your `' + object_name +\n                              '` call to the Keras 2 API: ' + signature, stacklevel=2)\n            return func(*args, **kwargs)\n        wrapper._original_function = func\n        return wrapper",
        "begin_line": 26,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006863417982155113,
            "pseudo_dstar_susp": 0.0019305019305019305,
            "pseudo_tarantula_susp": 0.00047961630695443646,
            "pseudo_op2_susp": 0.0019305019305019305,
            "pseudo_barinel_susp": 0.00047961630695443646
        }
    },
    {
        "name": "keras.legacy.interfaces.wrapper#28",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.wrapper(*args, **kwargs)",
        "snippet": "        def wrapper(*args, **kwargs):\n            if object_type == 'class':\n                object_name = args[0].__class__.__name__\n            else:\n                object_name = func.__name__\n            if preprocessor:\n                args, kwargs, converted = preprocessor(args, kwargs)\n            else:\n                converted = []\n            if check_positional_args:\n                if len(args) > len(allowed_positional_args) + 1:\n                    raise TypeError('`' + object_name +\n                                    '` can accept only ' +\n                                    str(len(allowed_positional_args)) +\n                                    ' positional arguments ' +\n                                    str(tuple(allowed_positional_args)) +\n                                    ', but you passed the following '\n                                    'positional arguments: ' +\n                                    str(list(args[1:])))\n            for key in value_conversions:\n                if key in kwargs:\n                    old_value = kwargs[key]\n                    if old_value in value_conversions[key]:\n                        kwargs[key] = value_conversions[key][old_value]\n            for old_name, new_name in conversions:\n                if old_name in kwargs:\n                    value = kwargs.pop(old_name)\n                    if new_name in kwargs:\n                        raise_duplicate_arg_error(old_name, new_name)\n                    kwargs[new_name] = value\n                    converted.append((new_name, old_name))\n            if converted:\n                signature = '`' + object_name + '('\n                for i, value in enumerate(args[1:]):\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(args[1:]) - 1 or kwargs:\n                        signature += ', '\n                for i, (name, value) in enumerate(kwargs.items()):\n                    signature += name + '='\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(kwargs) - 1:\n                        signature += ', '\n                signature += ')`'\n                warnings.warn('Update your `' + object_name +\n                              '` call to the Keras 2 API: ' + signature, stacklevel=2)\n            return func(*args, **kwargs)",
        "begin_line": 28,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000992063492063492,
            "pseudo_dstar_susp": 0.002386634844868735,
            "pseudo_tarantula_susp": 0.0013513513513513514,
            "pseudo_op2_susp": 0.002386634844868735,
            "pseudo_barinel_susp": 0.0013513513513513514
        }
    },
    {
        "name": "keras.legacy.interfaces.raise_duplicate_arg_error#101",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.raise_duplicate_arg_error(old_arg, new_arg)",
        "snippet": "def raise_duplicate_arg_error(old_arg, new_arg):\n    raise TypeError('For the `' + new_arg + '` argument, '\n                    'the layer received both '\n                    'the legacy keyword argument '\n                    '`' + old_arg + '` and the Keras 2 keyword argument '\n                    '`' + new_arg + '`. Stick to the latter!')",
        "begin_line": 101,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.embedding_kwargs_preprocessor#124",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.embedding_kwargs_preprocessor(args, kwargs)",
        "snippet": "def embedding_kwargs_preprocessor(args, kwargs):\n    converted = []\n    if 'dropout' in kwargs:\n        kwargs.pop('dropout')\n        warnings.warn('The `dropout` argument is no longer support in `Embedding`. '\n                      'You can apply a `keras.layers.SpatialDropout1D` layer '\n                      'right after the `Embedding` layer to get the same behavior.', stacklevel=3)\n    return args, kwargs, converted",
        "begin_line": 124,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.recurrent_args_preprocessor#156",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.recurrent_args_preprocessor(args, kwargs)",
        "snippet": "def recurrent_args_preprocessor(args, kwargs):\n    converted = []\n    if 'forget_bias_init' in kwargs:\n        if kwargs['forget_bias_init'] == 'one':\n            kwargs.pop('forget_bias_init')\n            kwargs['unit_forget_bias'] = True\n            converted.append(('forget_bias_init', 'unit_forget_bias'))\n        else:\n            kwargs.pop('forget_bias_init')\n            warnings.warn('The `forget_bias_init` argument '\n                          'has been ignored. Use `unit_forget_bias=True` '\n                          'instead to initialize with ones.', stacklevel=3)\n    if 'input_dim' in kwargs:\n        input_length = kwargs.pop('input_length', None)\n        input_dim = kwargs.pop('input_dim')\n        input_shape = (input_length, input_dim)\n        kwargs['input_shape'] = input_shape\n        converted.append(('input_dim', 'input_shape'))\n        warnings.warn('The `input_dim` and `input_length` arguments '\n                      'in recurrent layers are deprecated. '\n                      'Use `input_shape` instead.', stacklevel=3)\n    return args, kwargs, converted",
        "begin_line": 156,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.conv1d_args_preprocessor#241",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.conv1d_args_preprocessor(args, kwargs)",
        "snippet": "def conv1d_args_preprocessor(args, kwargs):\n    converted = []\n    if 'input_dim' in kwargs:\n        if 'input_length' in kwargs:\n            length = kwargs.pop('input_length')\n        else:\n            length = None\n        input_shape = (length, kwargs.pop('input_dim'))\n        kwargs['input_shape'] = input_shape\n        converted.append(('input_shape', 'input_dim'))\n    return args, kwargs, converted",
        "begin_line": 241,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.conv2d_args_preprocessor#268",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.conv2d_args_preprocessor(args, kwargs)",
        "snippet": "def conv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) > 4:\n        raise TypeError('Layer can receive at most 3 positional arguments.')\n    if len(args) == 4:\n        if isinstance(args[2], int) and isinstance(args[3], int):\n            new_keywords = ['padding', 'strides', 'data_format']\n            for kwd in new_keywords:\n                if kwd in kwargs:\n                    raise ValueError(\n                        'It seems that you are using the Keras 2 '\n                        'and you are passing both `kernel_size` and `strides` '\n                        'as integer positional arguments. For safety reasons, '\n                        'this is disallowed. Pass `strides` '\n                        'as a keyword argument instead.')\n            kernel_size = (args[2], args[3])\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    elif len(args) == 3 and isinstance(args[2], int):\n        if 'nb_col' in kwargs:\n            kernel_size = (args[2], kwargs.pop('nb_col'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    elif len(args) == 2:\n        if 'nb_row' in kwargs and 'nb_col' in kwargs:\n            kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    elif len(args) == 1:\n        if 'nb_row' in kwargs and 'nb_col' in kwargs:\n            kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n            kwargs['kernel_size'] = kernel_size\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    return args, kwargs, converted",
        "begin_line": 268,
        "end_line": 301,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014992503748125937,
            "pseudo_dstar_susp": 0.0005924170616113745,
            "pseudo_tarantula_susp": 0.001941747572815534,
            "pseudo_op2_susp": 0.0005924170616113745,
            "pseudo_barinel_susp": 0.001941747572815534
        }
    },
    {
        "name": "keras.legacy.interfaces.separable_conv2d_args_preprocessor#321",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.separable_conv2d_args_preprocessor(args, kwargs)",
        "snippet": "def separable_conv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if 'init' in kwargs:\n        init = kwargs.pop('init')\n        kwargs['depthwise_initializer'] = init\n        kwargs['pointwise_initializer'] = init\n        converted.append(('init', 'depthwise_initializer/pointwise_initializer'))\n    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n    return args, kwargs, converted + _converted",
        "begin_line": 321,
        "end_line": 329,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.deconv2d_args_preprocessor#346",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.deconv2d_args_preprocessor(args, kwargs)",
        "snippet": "def deconv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) == 5:\n        if isinstance(args[4], tuple):\n            args = args[:-1]\n            converted.append(('output_shape', None))\n    if 'output_shape' in kwargs:\n        kwargs.pop('output_shape')\n        converted.append(('output_shape', None))\n    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n    return args, kwargs, converted + _converted",
        "begin_line": 346,
        "end_line": 356,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.conv3d_args_preprocessor#376",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.conv3d_args_preprocessor(args, kwargs)",
        "snippet": "def conv3d_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) > 5:\n        raise TypeError('Layer can receive at most 4 positional arguments.')\n    if len(args) == 5:\n        if isinstance(args[2], int) and isinstance(args[3], int) and isinstance(args[4], int):\n            kernel_size = (args[2], args[3], args[4])\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'kernel_dim*'))\n    elif len(args) == 4 and isinstance(args[3], int):\n        if isinstance(args[2], int) and isinstance(args[3], int):\n            new_keywords = ['padding', 'strides', 'data_format']\n            for kwd in new_keywords:\n                if kwd in kwargs:\n                    raise ValueError(\n                        'It seems that you are using the Keras 2 '\n                        'and you are passing both `kernel_size` and `strides` '\n                        'as integer positional arguments. For safety reasons, '\n                        'this is disallowed. Pass `strides` '\n                        'as a keyword argument instead.')\n        if 'kernel_dim3' in kwargs:\n            kernel_size = (args[2], args[3], kwargs.pop('kernel_dim3'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'kernel_dim*'))\n    elif len(args) == 3:\n        if 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n            kernel_size = (args[2],\n                           kwargs.pop('kernel_dim2'),\n                           kwargs.pop('kernel_dim3'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'kernel_dim*'))\n    elif len(args) == 2:\n        if 'kernel_dim1' in kwargs and 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n            kernel_size = (kwargs.pop('kernel_dim1'),\n                           kwargs.pop('kernel_dim2'),\n                           kwargs.pop('kernel_dim3'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'kernel_dim*'))\n    elif len(args) == 1:\n        if 'kernel_dim1' in kwargs and 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n            kernel_size = (kwargs.pop('kernel_dim1'),\n                           kwargs.pop('kernel_dim2'),\n                           kwargs.pop('kernel_dim3'))\n            kwargs['kernel_size'] = kernel_size\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    return args, kwargs, converted",
        "begin_line": 376,
        "end_line": 421,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.batchnorm_args_preprocessor#441",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.batchnorm_args_preprocessor(args, kwargs)",
        "snippet": "def batchnorm_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) > 1:\n        raise TypeError('The `BatchNormalization` layer '\n                        'does not accept positional arguments. '\n                        'Use keyword arguments instead.')\n    if 'mode' in kwargs:\n        value = kwargs.pop('mode')\n        if value != 0:\n            raise TypeError('The `mode` argument of `BatchNormalization` '\n                            'no longer exists. `mode=1` and `mode=2` '\n                            'are no longer supported.')\n        converted.append(('mode', None))\n    return args, kwargs, converted",
        "begin_line": 441,
        "end_line": 454,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.convlstm2d_args_preprocessor#457",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.convlstm2d_args_preprocessor(args, kwargs)",
        "snippet": "def convlstm2d_args_preprocessor(args, kwargs):\n    converted = []\n    if 'forget_bias_init' in kwargs:\n        value = kwargs.pop('forget_bias_init')\n        if value == 'one':\n            kwargs['unit_forget_bias'] = True\n            converted.append(('forget_bias_init', 'unit_forget_bias'))\n        else:\n            warnings.warn('The `forget_bias_init` argument '\n                          'has been ignored. Use `unit_forget_bias=True` '\n                          'instead to initialize with ones.', stacklevel=3)\n    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n    return args, kwargs, converted + _converted",
        "begin_line": 457,
        "end_line": 469,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.zeropadding2d_args_preprocessor#498",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.zeropadding2d_args_preprocessor(args, kwargs)",
        "snippet": "def zeropadding2d_args_preprocessor(args, kwargs):\n    converted = []\n    if 'padding' in kwargs and isinstance(kwargs['padding'], dict):\n        if set(kwargs['padding'].keys()) <= {'top_pad', 'bottom_pad',\n                                             'left_pad', 'right_pad'}:\n            top_pad = kwargs['padding'].get('top_pad', 0)\n            bottom_pad = kwargs['padding'].get('bottom_pad', 0)\n            left_pad = kwargs['padding'].get('left_pad', 0)\n            right_pad = kwargs['padding'].get('right_pad', 0)\n            kwargs['padding'] = ((top_pad, bottom_pad), (left_pad, right_pad))\n            warnings.warn('The `padding` argument in the Keras 2 API no longer'\n                          'accepts dict types. You can now input argument as: '\n                          '`padding=(top_pad, bottom_pad, left_pad, right_pad)`.', stacklevel=3)\n    elif len(args) == 2 and isinstance(args[1], dict):\n        if set(args[1].keys()) <= {'top_pad', 'bottom_pad',\n                                   'left_pad', 'right_pad'}:\n            top_pad = args[1].get('top_pad', 0)\n            bottom_pad = args[1].get('bottom_pad', 0)\n            left_pad = args[1].get('left_pad', 0)\n            right_pad = args[1].get('right_pad', 0)\n            args = (args[0], ((top_pad, bottom_pad), (left_pad, right_pad)))\n            warnings.warn('The `padding` argument in the Keras 2 API no longer'\n                          'accepts dict types. You can now input argument as: '\n                          '`padding=((top_pad, bottom_pad), (left_pad, right_pad))`', stacklevel=3)\n    return args, kwargs, converted",
        "begin_line": 498,
        "end_line": 522,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.interfaces.generator_methods_args_preprocessor#571",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.generator_methods_args_preprocessor(args, kwargs)",
        "snippet": "def generator_methods_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) < 3:\n        if 'samples_per_epoch' in kwargs:\n            samples_per_epoch = kwargs.pop('samples_per_epoch')\n            if len(args) > 1:\n                generator = args[1]\n            else:\n                generator = kwargs['generator']\n            if hasattr(generator, 'batch_size'):\n                kwargs['steps_per_epoch'] = samples_per_epoch // generator.batch_size\n            else:\n                kwargs['steps_per_epoch'] = samples_per_epoch\n            converted.append(('samples_per_epoch', 'steps_per_epoch'))\n\n    keras1_args = {'samples_per_epoch', 'val_samples', 'nb_epoch', 'nb_val_samples', 'nb_worker'}\n    if keras1_args.intersection(kwargs.keys()):\n        warnings.warn('The semantics of the Keras 2 argument '\n                      '`steps_per_epoch` is not the same as the '\n                      'Keras 1 argument `samples_per_epoch`. '\n                      '`steps_per_epoch` is the number of batches '\n                      'to draw from the generator at each epoch. '\n                      'Basically steps_per_epoch = samples_per_epoch/batch_size. '\n                      'Similarly `nb_val_samples`->`validation_steps` and '\n                      '`val_samples`->`steps` arguments have changed. '\n                      'Update your method calls accordingly.', stacklevel=3)\n\n    return args, kwargs, converted",
        "begin_line": 571,
        "end_line": 598,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017574692442882249,
            "pseudo_dstar_susp": 0.0006222775357809583,
            "pseudo_tarantula_susp": 0.0023148148148148147,
            "pseudo_op2_susp": 0.0006222775357809583,
            "pseudo_barinel_susp": 0.0023148148148148147
        }
    },
    {
        "name": "keras.legacy.interfaces.add_weight_args_preprocessing#623",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.add_weight_args_preprocessing(args, kwargs)",
        "snippet": "def add_weight_args_preprocessing(args, kwargs):\n    if len(args) > 1:\n        if isinstance(args[1], (tuple, list)):\n            kwargs['shape'] = args[1]\n            args = (args[0],) + args[2:]\n            if len(args) > 1:\n                if isinstance(args[1], six.string_types):\n                    kwargs['name'] = args[1]\n                    args = (args[0],) + args[2:]\n    return args, kwargs, []",
        "begin_line": 623,
        "end_line": 632,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001177856301531213,
            "pseudo_dstar_susp": 0.0051813471502590676,
            "pseudo_tarantula_susp": 0.0006578947368421052,
            "pseudo_op2_susp": 0.0051813471502590676,
            "pseudo_barinel_susp": 0.0006578947368421052
        }
    },
    {
        "name": "keras.legacy.interfaces.get_updates_arg_preprocessing#640",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.get_updates_arg_preprocessing(args, kwargs)",
        "snippet": "def get_updates_arg_preprocessing(args, kwargs):\n    # Old interface: (params, constraints, loss)\n    # New interface: (loss, params)\n    if len(args) > 4:\n        raise TypeError('`get_update` call received more arguments '\n                        'than expected.')\n    elif len(args) == 4:\n        # Assuming old interface.\n        opt, params, _, loss = args\n        kwargs['loss'] = loss\n        kwargs['params'] = params\n        return [opt], kwargs, []\n    elif len(args) == 3:\n        if isinstance(args[1], (list, tuple)):\n            assert isinstance(args[2], dict)\n            assert 'loss' in kwargs\n            opt, params, _ = args\n            kwargs['params'] = params\n            return [opt], kwargs, []\n    return args, kwargs, []",
        "begin_line": 640,
        "end_line": 659,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003598416696653472,
            "pseudo_dstar_susp": 0.0003598416696653472,
            "pseudo_tarantula_susp": 0.00036088054853843375,
            "pseudo_op2_susp": 0.0003598416696653472,
            "pseudo_barinel_susp": 0.00036088054853843375
        }
    },
    {
        "name": "keras.applications.inception_resnet_v2.preprocess_input#46",
        "src_path": "keras/applications/inception_resnet_v2.py",
        "class_name": "keras.applications.inception_resnet_v2",
        "signature": "keras.applications.inception_resnet_v2.preprocess_input(x)",
        "snippet": "def preprocess_input(x):\n    \"\"\"Preprocesses a numpy array encoding a batch of images.\n\n    # Arguments\n        x: a 4D numpy array consists of RGB values within [0, 255].\n\n    # Returns\n        Preprocessed array.\n    \"\"\"\n    return imagenet_utils.preprocess_input(x, mode='tf')",
        "begin_line": 46,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.inception_resnet_v2.conv2d_bn#58",
        "src_path": "keras/applications/inception_resnet_v2.py",
        "class_name": "keras.applications.inception_resnet_v2",
        "signature": "keras.applications.inception_resnet_v2.conv2d_bn(x, filters, kernel_size, strides=1, padding='same', activation='relu', use_bias=False, name=None)",
        "snippet": "def conv2d_bn(x,\n              filters,\n              kernel_size,\n              strides=1,\n              padding='same',\n              activation='relu',\n              use_bias=False,\n              name=None):\n    \"\"\"Utility function to apply conv + BN.\n\n    # Arguments\n        x: input tensor.\n        filters: filters in `Conv2D`.\n        kernel_size: kernel size as in `Conv2D`.\n        strides: strides in `Conv2D`.\n        padding: padding mode in `Conv2D`.\n        activation: activation in `Conv2D`.\n        use_bias: whether to use a bias in `Conv2D`.\n        name: name of the ops; will become `name + '_ac'` for the activation\n            and `name + '_bn'` for the batch norm layer.\n\n    # Returns\n        Output tensor after applying `Conv2D` and `BatchNormalization`.\n    \"\"\"\n    x = Conv2D(filters,\n               kernel_size,\n               strides=strides,\n               padding=padding,\n               use_bias=use_bias,\n               name=name)(x)\n    if not use_bias:\n        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n        bn_name = None if name is None else name + '_bn'\n        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n    if activation is not None:\n        ac_name = None if name is None else name + '_ac'\n        x = Activation(activation, name=ac_name)(x)\n    return x",
        "begin_line": 58,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.inception_resnet_v2.inception_resnet_block#98",
        "src_path": "keras/applications/inception_resnet_v2.py",
        "class_name": "keras.applications.inception_resnet_v2",
        "signature": "keras.applications.inception_resnet_v2.inception_resnet_block(x, scale, block_type, block_idx, activation='relu')",
        "snippet": "def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n    \"\"\"Adds a Inception-ResNet block.\n\n    This function builds 3 types of Inception-ResNet blocks mentioned\n    in the paper, controlled by the `block_type` argument (which is the\n    block name used in the official TF-slim implementation):\n        - Inception-ResNet-A: `block_type='block35'`\n        - Inception-ResNet-B: `block_type='block17'`\n        - Inception-ResNet-C: `block_type='block8'`\n\n    # Arguments\n        x: input tensor.\n        scale: scaling factor to scale the residuals (i.e., the output of\n            passing `x` through an inception module) before adding them\n            to the shortcut branch. Let `r` be the output from the residual branch,\n            the output of this block will be `x + scale * r`.\n        block_type: `'block35'`, `'block17'` or `'block8'`, determines\n            the network structure in the residual branch.\n        block_idx: an `int` used for generating layer names. The Inception-ResNet blocks\n            are repeated many times in this network. We use `block_idx` to identify\n            each of the repetitions. For example, the first Inception-ResNet-A block\n            will have `block_type='block35', block_idx=0`, ane the layer names will have\n            a common prefix `'block35_0'`.\n        activation: activation function to use at the end of the block\n            (see [activations](../activations.md)).\n            When `activation=None`, no activation is applied\n            (i.e., \"linear\" activation: `a(x) = x`).\n\n    # Returns\n        Output tensor for the block.\n\n    # Raises\n        ValueError: if `block_type` is not one of `'block35'`,\n            `'block17'` or `'block8'`.\n    \"\"\"\n    if block_type == 'block35':\n        branch_0 = conv2d_bn(x, 32, 1)\n        branch_1 = conv2d_bn(x, 32, 1)\n        branch_1 = conv2d_bn(branch_1, 32, 3)\n        branch_2 = conv2d_bn(x, 32, 1)\n        branch_2 = conv2d_bn(branch_2, 48, 3)\n        branch_2 = conv2d_bn(branch_2, 64, 3)\n        branches = [branch_0, branch_1, branch_2]\n    elif block_type == 'block17':\n        branch_0 = conv2d_bn(x, 192, 1)\n        branch_1 = conv2d_bn(x, 128, 1)\n        branch_1 = conv2d_bn(branch_1, 160, [1, 7])\n        branch_1 = conv2d_bn(branch_1, 192, [7, 1])\n        branches = [branch_0, branch_1]\n    elif block_type == 'block8':\n        branch_0 = conv2d_bn(x, 192, 1)\n        branch_1 = conv2d_bn(x, 192, 1)\n        branch_1 = conv2d_bn(branch_1, 224, [1, 3])\n        branch_1 = conv2d_bn(branch_1, 256, [3, 1])\n        branches = [branch_0, branch_1]\n    else:\n        raise ValueError('Unknown Inception-ResNet block type. '\n                         'Expects \"block35\", \"block17\" or \"block8\", '\n                         'but got: ' + str(block_type))\n\n    block_name = block_type + '_' + str(block_idx)\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n    mixed = Concatenate(axis=channel_axis, name=block_name + '_mixed')(branches)\n    up = conv2d_bn(mixed,\n                   K.int_shape(x)[channel_axis],\n                   1,\n                   activation=None,\n                   use_bias=True,\n                   name=block_name + '_conv')\n\n    x = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n               output_shape=K.int_shape(x)[1:],\n               arguments={'scale': scale},\n               name=block_name)([x, up])\n    if activation is not None:\n        x = Activation(activation, name=block_name + '_ac')(x)\n    return x",
        "begin_line": 98,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.inception_resnet_v2.InceptionResNetV2#177",
        "src_path": "keras/applications/inception_resnet_v2.py",
        "class_name": "keras.applications.inception_resnet_v2",
        "signature": "keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def InceptionResNetV2(include_top=True,\n                      weights='imagenet',\n                      input_tensor=None,\n                      input_shape=None,\n                      pooling=None,\n                      classes=1000):\n    \"\"\"Instantiates the Inception-ResNet v2 architecture.\n\n    Optionally loads weights pre-trained on ImageNet.\n    Note that when using TensorFlow, for best performance you should\n    set `\"image_data_format\": \"channels_last\"` in your Keras config\n    at `~/.keras/keras.json`.\n\n    The model and the weights are compatible with TensorFlow, Theano and\n    CNTK backends. The data format convention used by the model is\n    the one specified in your Keras config file.\n\n    Note that the default input image size for this model is 299x299, instead\n    of 224x224 as in the VGG16 and ResNet models. Also, the input preprocessing\n    function is different (i.e., do not use `imagenet_utils.preprocess_input()`\n    with this model. Use `preprocess_input()` defined in this module instead).\n\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is `False` (otherwise the input shape\n            has to be `(299, 299, 3)` (with `'channels_last'` data format)\n            or `(3, 299, 299)` (with `'channels_first'` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 139.\n            E.g. `(150, 150, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the last convolutional layer.\n            - `'avg'` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `'max'` means that global max pooling will be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is `True`, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras `Model` instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(\n        input_shape,\n        default_size=299,\n        min_size=139,\n        data_format=K.image_data_format(),\n        require_flatten=False,\n        weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    # Stem block: 35 x 35 x 192\n    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid')\n    x = conv2d_bn(x, 32, 3, padding='valid')\n    x = conv2d_bn(x, 64, 3)\n    x = MaxPooling2D(3, strides=2)(x)\n    x = conv2d_bn(x, 80, 1, padding='valid')\n    x = conv2d_bn(x, 192, 3, padding='valid')\n    x = MaxPooling2D(3, strides=2)(x)\n\n    # Mixed 5b (Inception-A block): 35 x 35 x 320\n    branch_0 = conv2d_bn(x, 96, 1)\n    branch_1 = conv2d_bn(x, 48, 1)\n    branch_1 = conv2d_bn(branch_1, 64, 5)\n    branch_2 = conv2d_bn(x, 64, 1)\n    branch_2 = conv2d_bn(branch_2, 96, 3)\n    branch_2 = conv2d_bn(branch_2, 96, 3)\n    branch_pool = AveragePooling2D(3, strides=1, padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 64, 1)\n    branches = [branch_0, branch_1, branch_2, branch_pool]\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n    x = Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n\n    # 10x block35 (Inception-ResNet-A block): 35 x 35 x 320\n    for block_idx in range(1, 11):\n        x = inception_resnet_block(x,\n                                   scale=0.17,\n                                   block_type='block35',\n                                   block_idx=block_idx)\n\n    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid')\n    branch_1 = conv2d_bn(x, 256, 1)\n    branch_1 = conv2d_bn(branch_1, 256, 3)\n    branch_1 = conv2d_bn(branch_1, 384, 3, strides=2, padding='valid')\n    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n    branches = [branch_0, branch_1, branch_pool]\n    x = Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n\n    # 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\n    for block_idx in range(1, 21):\n        x = inception_resnet_block(x,\n                                   scale=0.1,\n                                   block_type='block17',\n                                   block_idx=block_idx)\n\n    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n    branch_0 = conv2d_bn(x, 256, 1)\n    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid')\n    branch_1 = conv2d_bn(x, 256, 1)\n    branch_1 = conv2d_bn(branch_1, 288, 3, strides=2, padding='valid')\n    branch_2 = conv2d_bn(x, 256, 1)\n    branch_2 = conv2d_bn(branch_2, 288, 3)\n    branch_2 = conv2d_bn(branch_2, 320, 3, strides=2, padding='valid')\n    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n    branches = [branch_0, branch_1, branch_2, branch_pool]\n    x = Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n\n    # 10x block8 (Inception-ResNet-C block): 8 x 8 x 2080\n    for block_idx in range(1, 10):\n        x = inception_resnet_block(x,\n                                   scale=0.2,\n                                   block_type='block8',\n                                   block_idx=block_idx)\n    x = inception_resnet_block(x,\n                               scale=1.,\n                               activation=None,\n                               block_type='block8',\n                               block_idx=10)\n\n    # Final convolution block: 8 x 8 x 1536\n    x = conv2d_bn(x, 1536, 1, name='conv_7b')\n\n    if include_top:\n        # Classification block\n        x = GlobalAveragePooling2D(name='avg_pool')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    # Create model\n    model = Model(inputs, x, name='inception_resnet_v2')\n\n    # Load weights\n    if weights == 'imagenet':\n        if K.image_data_format() == 'channels_first':\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n        if include_top:\n            fname = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'\n            weights_path = get_file(fname,\n                                    BASE_WEIGHT_URL + fname,\n                                    cache_subdir='models',\n                                    file_hash='e693bd0210a403b3192acc6073ad2e96')\n        else:\n            fname = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n            weights_path = get_file(fname,\n                                    BASE_WEIGHT_URL + fname,\n                                    cache_subdir='models',\n                                    file_hash='d19885ff4a710c122648d3b5c3b684e4')\n        model.load_weights(weights_path)\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model",
        "begin_line": 177,
        "end_line": 381,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils._extract_archive#76",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils._extract_archive(file_path, path='.', archive_format='auto')",
        "snippet": "def _extract_archive(file_path, path='.', archive_format='auto'):\n    \"\"\"Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n\n    # Arguments\n        file_path: path to the archive file\n        path: path to extract the archive file\n        archive_format: Archive format to try for extracting the file.\n            Options are 'auto', 'tar', 'zip', and None.\n            'tar' includes tar, tar.gz, and tar.bz files.\n            The default 'auto' is ['tar', 'zip'].\n            None or an empty list will return no matches found.\n\n    # Returns\n        True if a match was found and an archive extraction was completed,\n        False otherwise.\n    \"\"\"\n    if archive_format is None:\n        return False\n    if archive_format is 'auto':\n        archive_format = ['tar', 'zip']\n    if isinstance(archive_format, six.string_types):\n        archive_format = [archive_format]\n\n    for archive_type in archive_format:\n        if archive_type is 'tar':\n            open_fn = tarfile.open\n            is_match_fn = tarfile.is_tarfile\n        if archive_type is 'zip':\n            open_fn = zipfile.ZipFile\n            is_match_fn = zipfile.is_zipfile\n\n        if is_match_fn(file_path):\n            with open_fn(file_path) as archive:\n                try:\n                    archive.extractall(path)\n                except (tarfile.TarError, RuntimeError,\n                        KeyboardInterrupt):\n                    if os.path.exists(path):\n                        if os.path.isfile(path):\n                            os.remove(path)\n                        else:\n                            shutil.rmtree(path)\n                    raise\n            return True\n    return False",
        "begin_line": 76,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.get_file#123",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils.get_file(fname, origin, untar=False, md5_hash=None, file_hash=None, cache_subdir='datasets', hash_algorithm='auto', extract=False, archive_format='auto', cache_dir=None)",
        "snippet": "def get_file(fname,\n             origin,\n             untar=False,\n             md5_hash=None,\n             file_hash=None,\n             cache_subdir='datasets',\n             hash_algorithm='auto',\n             extract=False,\n             archive_format='auto',\n             cache_dir=None):\n    \"\"\"Downloads a file from a URL if it not already in the cache.\n\n    By default the file at the url `origin` is downloaded to the\n    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n    and given the filename `fname`. The final location of a file\n    `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n\n    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n    Passing a hash will verify the file after download. The command line\n    programs `shasum` and `sha256sum` can compute the hash.\n\n    # Arguments\n        fname: Name of the file. If an absolute path `/path/to/file.txt` is\n            specified the file will be saved at that location.\n        origin: Original URL of the file.\n        untar: Deprecated in favor of 'extract'.\n            boolean, whether the file should be decompressed\n        md5_hash: Deprecated in favor of 'file_hash'.\n            md5 hash of the file for verification\n        file_hash: The expected hash string of the file after download.\n            The sha256 and md5 hash algorithms are both supported.\n        cache_subdir: Subdirectory under the Keras cache dir where the file is\n            saved. If an absolute path `/path/to/folder` is\n            specified the file will be saved at that location.\n        hash_algorithm: Select the hash algorithm to verify the file.\n            options are 'md5', 'sha256', and 'auto'.\n            The default 'auto' detects the hash algorithm in use.\n        extract: True tries extracting the file as an Archive, like tar or zip.\n        archive_format: Archive format to try for extracting the file.\n            Options are 'auto', 'tar', 'zip', and None.\n            'tar' includes tar, tar.gz, and tar.bz files.\n            The default 'auto' is ['tar', 'zip'].\n            None or an empty list will return no matches found.\n        cache_dir: Location to store cached files, when None it\n            defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n\n    # Returns\n        Path to the downloaded file\n    \"\"\"\n    if cache_dir is None:\n        cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n    if md5_hash is not None and file_hash is None:\n        file_hash = md5_hash\n        hash_algorithm = 'md5'\n    datadir_base = os.path.expanduser(cache_dir)\n    if not os.access(datadir_base, os.W_OK):\n        datadir_base = os.path.join('/tmp', '.keras')\n    datadir = os.path.join(datadir_base, cache_subdir)\n    if not os.path.exists(datadir):\n        os.makedirs(datadir)\n\n    if untar:\n        untar_fpath = os.path.join(datadir, fname)\n        fpath = untar_fpath + '.tar.gz'\n    else:\n        fpath = os.path.join(datadir, fname)\n\n    download = False\n    if os.path.exists(fpath):\n        # File found; verify integrity if a hash was provided.\n        if file_hash is not None:\n            if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                print('A local file was found, but it seems to be '\n                      'incomplete or outdated because the ' + hash_algorithm +\n                      ' file hash does not match the original value of ' +\n                      file_hash + ' so we will re-download the data.')\n                download = True\n    else:\n        download = True\n\n    if download:\n        print('Downloading data from', origin)\n\n        class ProgressTracker(object):\n            # Maintain progbar for the lifetime of download.\n            # This design was chosen for Python 2.7 compatibility.\n            progbar = None\n\n        def dl_progress(count, block_size, total_size):\n            if ProgressTracker.progbar is None:\n                if total_size is -1:\n                    total_size = None\n                ProgressTracker.progbar = Progbar(total_size)\n            else:\n                ProgressTracker.progbar.update(count * block_size)\n\n        error_msg = 'URL fetch failure on {}: {} -- {}'\n        try:\n            try:\n                urlretrieve(origin, fpath, dl_progress)\n            except URLError as e:\n                raise Exception(error_msg.format(origin, e.errno, e.reason))\n            except HTTPError as e:\n                raise Exception(error_msg.format(origin, e.code, e.msg))\n        except (Exception, KeyboardInterrupt) as e:\n            if os.path.exists(fpath):\n                os.remove(fpath)\n            raise\n        ProgressTracker.progbar = None\n\n    if untar:\n        if not os.path.exists(untar_fpath):\n            _extract_archive(fpath, datadir, archive_format='tar')\n        return untar_fpath\n\n    if extract:\n        _extract_archive(fpath, datadir, archive_format)\n\n    return fpath",
        "begin_line": 123,
        "end_line": 241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.ProgressTracker.get_file#123",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.ProgressTracker",
        "signature": "keras.utils.data_utils.ProgressTracker.get_file(fname, origin, untar=False, md5_hash=None, file_hash=None, cache_subdir='datasets', hash_algorithm='auto', extract=False, archive_format='auto', cache_dir=None)",
        "snippet": "def get_file(fname,\n             origin,\n             untar=False,\n             md5_hash=None,\n             file_hash=None,\n             cache_subdir='datasets',\n             hash_algorithm='auto',\n             extract=False,\n             archive_format='auto',\n             cache_dir=None):\n    \"\"\"Downloads a file from a URL if it not already in the cache.\n\n    By default the file at the url `origin` is downloaded to the\n    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n    and given the filename `fname`. The final location of a file\n    `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n\n    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n    Passing a hash will verify the file after download. The command line\n    programs `shasum` and `sha256sum` can compute the hash.\n\n    # Arguments\n        fname: Name of the file. If an absolute path `/path/to/file.txt` is\n            specified the file will be saved at that location.\n        origin: Original URL of the file.\n        untar: Deprecated in favor of 'extract'.\n            boolean, whether the file should be decompressed\n        md5_hash: Deprecated in favor of 'file_hash'.\n            md5 hash of the file for verification\n        file_hash: The expected hash string of the file after download.\n            The sha256 and md5 hash algorithms are both supported.\n        cache_subdir: Subdirectory under the Keras cache dir where the file is\n            saved. If an absolute path `/path/to/folder` is\n            specified the file will be saved at that location.\n        hash_algorithm: Select the hash algorithm to verify the file.\n            options are 'md5', 'sha256', and 'auto'.\n            The default 'auto' detects the hash algorithm in use.\n        extract: True tries extracting the file as an Archive, like tar or zip.\n        archive_format: Archive format to try for extracting the file.\n            Options are 'auto', 'tar', 'zip', and None.\n            'tar' includes tar, tar.gz, and tar.bz files.\n            The default 'auto' is ['tar', 'zip'].\n            None or an empty list will return no matches found.\n        cache_dir: Location to store cached files, when None it\n            defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n\n    # Returns\n        Path to the downloaded file\n    \"\"\"\n    if cache_dir is None:\n        cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n    if md5_hash is not None and file_hash is None:\n        file_hash = md5_hash\n        hash_algorithm = 'md5'\n    datadir_base = os.path.expanduser(cache_dir)\n    if not os.access(datadir_base, os.W_OK):\n        datadir_base = os.path.join('/tmp', '.keras')\n    datadir = os.path.join(datadir_base, cache_subdir)\n    if not os.path.exists(datadir):\n        os.makedirs(datadir)\n\n    if untar:\n        untar_fpath = os.path.join(datadir, fname)\n        fpath = untar_fpath + '.tar.gz'\n    else:\n        fpath = os.path.join(datadir, fname)\n\n    download = False\n    if os.path.exists(fpath):\n        # File found; verify integrity if a hash was provided.\n        if file_hash is not None:\n            if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                print('A local file was found, but it seems to be '\n                      'incomplete or outdated because the ' + hash_algorithm +\n                      ' file hash does not match the original value of ' +\n                      file_hash + ' so we will re-download the data.')\n                download = True\n    else:\n        download = True\n\n    if download:\n        print('Downloading data from', origin)\n\n        class ProgressTracker(object):\n            # Maintain progbar for the lifetime of download.\n            # This design was chosen for Python 2.7 compatibility.\n            progbar = None\n\n        def dl_progress(count, block_size, total_size):\n            if ProgressTracker.progbar is None:\n                if total_size is -1:\n                    total_size = None\n                ProgressTracker.progbar = Progbar(total_size)\n            else:\n                ProgressTracker.progbar.update(count * block_size)\n\n        error_msg = 'URL fetch failure on {}: {} -- {}'\n        try:\n            try:\n                urlretrieve(origin, fpath, dl_progress)\n            except URLError as e:\n                raise Exception(error_msg.format(origin, e.errno, e.reason))\n            except HTTPError as e:\n                raise Exception(error_msg.format(origin, e.code, e.msg))\n        except (Exception, KeyboardInterrupt) as e:\n            if os.path.exists(fpath):\n                os.remove(fpath)\n            raise\n        ProgressTracker.progbar = None\n\n    if untar:\n        if not os.path.exists(untar_fpath):\n            _extract_archive(fpath, datadir, archive_format='tar')\n        return untar_fpath\n\n    if extract:\n        _extract_archive(fpath, datadir, archive_format)\n\n    return fpath",
        "begin_line": 123,
        "end_line": 241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.dl_progress#211",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils.dl_progress(count, block_size, total_size)",
        "snippet": "        def dl_progress(count, block_size, total_size):\n            if ProgressTracker.progbar is None:\n                if total_size is -1:\n                    total_size = None\n                ProgressTracker.progbar = Progbar(total_size)\n            else:\n                ProgressTracker.progbar.update(count * block_size)",
        "begin_line": 211,
        "end_line": 217,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils._hash_file#244",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils._hash_file(fpath, algorithm='sha256', chunk_size=65535)",
        "snippet": "def _hash_file(fpath, algorithm='sha256', chunk_size=65535):\n    \"\"\"Calculates a file sha256 or md5 hash.\n\n    # Example\n\n    ```python\n        >>> from keras.data_utils import _hash_file\n        >>> _hash_file('/path/to/file.zip')\n        'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'\n    ```\n\n    # Arguments\n        fpath: path to the file being validated\n        algorithm: hash algorithm, one of 'auto', 'sha256', or 'md5'.\n            The default 'auto' detects the hash algorithm in use.\n        chunk_size: Bytes to read at a time, important for large files.\n\n    # Returns\n        The file hash\n    \"\"\"\n    if (algorithm is 'sha256') or (algorithm is 'auto' and len(hash) is 64):\n        hasher = hashlib.sha256()\n    else:\n        hasher = hashlib.md5()\n\n    with open(fpath, 'rb') as fpath_file:\n        for chunk in iter(lambda: fpath_file.read(chunk_size), b''):\n            hasher.update(chunk)\n\n    return hasher.hexdigest()",
        "begin_line": 244,
        "end_line": 273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.validate_file#276",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils.validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535)",
        "snippet": "def validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535):\n    \"\"\"Validates a file against a sha256 or md5 hash.\n\n    # Arguments\n        fpath: path to the file being validated\n        file_hash:  The expected hash string of the file.\n            The sha256 and md5 hash algorithms are both supported.\n        algorithm: Hash algorithm, one of 'auto', 'sha256', or 'md5'.\n            The default 'auto' detects the hash algorithm in use.\n        chunk_size: Bytes to read at a time, important for large files.\n\n    # Returns\n        Whether the file is valid\n    \"\"\"\n    if ((algorithm is 'sha256') or\n            (algorithm is 'auto' and len(file_hash) is 64)):\n        hasher = 'sha256'\n    else:\n        hasher = 'md5'\n\n    if str(_hash_file(fpath, hasher, chunk_size)) == str(file_hash):\n        return True\n    else:\n        return False",
        "begin_line": 276,
        "end_line": 299,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.Sequence.on_epoch_end#364",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.Sequence",
        "signature": "keras.utils.data_utils.Sequence.on_epoch_end(self)",
        "snippet": "    def on_epoch_end(self):\n        \"\"\"Method called at the end of every epoch.\n        \"\"\"\n        pass",
        "begin_line": 364,
        "end_line": 367,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.init_pool#376",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils.init_pool(seqs)",
        "snippet": "def init_pool(seqs):\n    global _SHARED_SEQUENCES\n    _SHARED_SEQUENCES = seqs",
        "begin_line": 376,
        "end_line": 378,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.get_index#381",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils.get_index(uid, i)",
        "snippet": "def get_index(uid, i):\n    \"\"\"Get the value from the Sequence `uid` at index `i`.\n\n    To allow multiple Sequences to be used at the same time, we use `uid` to\n    get a specific one. A single Sequence would cause the validation to\n    overwrite the training Sequence.\n\n    # Arguments\n        uid: int, Sequence identifier\n        i: index\n\n    # Returns\n        The value at index `i`.\n    \"\"\"\n    return _SHARED_SEQUENCES[uid][i]",
        "begin_line": 381,
        "end_line": 395,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.SequenceEnqueuer.start#425",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.SequenceEnqueuer",
        "signature": "keras.utils.data_utils.SequenceEnqueuer.start(self, workers=1, max_queue_size=10)",
        "snippet": "    def start(self, workers=1, max_queue_size=10):\n        \"\"\"Starts the handler's workers.\n\n        # Arguments\n            workers: number of worker threads\n            max_queue_size: queue size\n                (when full, threads could block on `put()`).\n        \"\"\"\n        raise NotImplementedError",
        "begin_line": 425,
        "end_line": 433,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.SequenceEnqueuer.stop#436",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.SequenceEnqueuer",
        "signature": "keras.utils.data_utils.SequenceEnqueuer.stop(self, timeout=None)",
        "snippet": "    def stop(self, timeout=None):\n        \"\"\"Stop running threads and wait for them to exit, if necessary.\n\n        Should be called by the same thread which called start().\n\n        # Arguments\n            timeout: maximum time to wait on thread.join()\n        \"\"\"\n        raise NotImplementedError",
        "begin_line": 436,
        "end_line": 444,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer.__init__#470",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer.__init__(self, sequence, use_multiprocessing=False, shuffle=False)",
        "snippet": "    def __init__(self, sequence,\n                 use_multiprocessing=False,\n                 shuffle=False):\n        self.sequence = sequence\n        self.use_multiprocessing = use_multiprocessing\n\n        global _SEQUENCE_COUNTER\n        if _SEQUENCE_COUNTER is None:\n            try:\n                _SEQUENCE_COUNTER = multiprocessing.Value('i', 0)\n            except OSError:\n                # In this case the OS does not allow us to use\n                # multiprocessing. We resort to an int\n                # for enqueuer indexing.\n                _SEQUENCE_COUNTER = 0\n\n        if isinstance(_SEQUENCE_COUNTER, int):\n            self.uid = _SEQUENCE_COUNTER\n            _SEQUENCE_COUNTER += 1\n        else:\n            # Doing Multiprocessing.Value += x is not process-safe.\n            with _SEQUENCE_COUNTER.get_lock():\n                self.uid = _SEQUENCE_COUNTER.value\n                _SEQUENCE_COUNTER.value += 1\n\n        self.shuffle = shuffle\n        self.workers = 0\n        self.executor_fn = None\n        self.queue = None\n        self.run_thread = None\n        self.stop_signal = None",
        "begin_line": 470,
        "end_line": 500,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer.is_running#502",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer.is_running(self)",
        "snippet": "    def is_running(self):\n        return self.stop_signal is not None and not self.stop_signal.is_set()",
        "begin_line": 502,
        "end_line": 503,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer.start#505",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer.start(self, workers=1, max_queue_size=10)",
        "snippet": "    def start(self, workers=1, max_queue_size=10):\n        \"\"\"Start the handler's workers.\n\n        # Arguments\n            workers: number of worker threads\n            max_queue_size: queue size\n                (when full, workers could block on `put()`)\n        \"\"\"\n        if self.use_multiprocessing:\n            self.executor_fn = lambda seqs: multiprocessing.Pool(workers,\n                                                                 initializer=init_pool,\n                                                                 initargs=(seqs,))\n        else:\n            # We do not need the init since it's threads.\n            self.executor_fn = lambda _: ThreadPool(workers)\n        self.workers = workers\n        self.queue = queue.Queue(max_queue_size)\n        self.stop_signal = threading.Event()\n        self.run_thread = threading.Thread(target=self._run)\n        self.run_thread.daemon = True\n        self.run_thread.start()",
        "begin_line": 505,
        "end_line": 525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer._wait_queue#527",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer._wait_queue(self)",
        "snippet": "    def _wait_queue(self):\n        \"\"\"Wait for the queue to be empty.\"\"\"\n        while True:\n            time.sleep(0.1)\n            if self.queue.unfinished_tasks == 0 or self.stop_signal.is_set():\n                return",
        "begin_line": 527,
        "end_line": 532,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer._run#534",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer._run(self)",
        "snippet": "    def _run(self):\n        \"\"\"Submits request to the executor and queue the `Future` objects.\"\"\"\n        sequence = list(range(len(self.sequence)))\n        self._send_sequence()  # Share the initial sequence\n        while True:\n            if self.shuffle:\n                random.shuffle(sequence)\n\n            with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n                for i in sequence:\n                    if self.stop_signal.is_set():\n                        return\n                    self.queue.put(\n                        executor.apply_async(get_index, (self.uid, i)), block=True)\n\n                # Done with the current epoch, waiting for the final batches\n                self._wait_queue()\n\n                if self.stop_signal.is_set():\n                    # We're done\n                    return\n\n            # Call the internal on epoch end.\n            self.sequence.on_epoch_end()\n            self._send_sequence()  # Update the pool",
        "begin_line": 534,
        "end_line": 558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer.get#560",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer.get(self)",
        "snippet": "    def get(self):\n        \"\"\"Creates a generator to extract data from the queue.\n\n        Skip the data if it is `None`.\n\n        # Yields\n            The next element in the queue, i.e. a tuple\n            `(inputs, targets)` or\n            `(inputs, targets, sample_weights)`.\n        \"\"\"\n        try:\n            while self.is_running():\n                inputs = self.queue.get(block=True).get()\n                self.queue.task_done()\n                if inputs is not None:\n                    yield inputs\n        except Exception as e:\n            self.stop()\n            six.raise_from(StopIteration(e), e)",
        "begin_line": 560,
        "end_line": 578,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer._send_sequence#580",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer._send_sequence(self)",
        "snippet": "    def _send_sequence(self):\n        \"\"\"Send current Sequence to all workers.\"\"\"\n        # For new processes that may spawn\n        _SHARED_SEQUENCES[self.uid] = self.sequence",
        "begin_line": 580,
        "end_line": 583,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer.stop#585",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer.stop(self, timeout=None)",
        "snippet": "    def stop(self, timeout=None):\n        \"\"\"Stops running threads and wait for them to exit, if necessary.\n\n        Should be called by the same thread which called `start()`.\n\n        # Arguments\n            timeout: maximum time to wait on `thread.join()`\n        \"\"\"\n        self.stop_signal.set()\n        with self.queue.mutex:\n            self.queue.queue.clear()\n            self.queue.unfinished_tasks = 0\n            self.queue.not_full.notify()\n        self.run_thread.join(timeout)\n        _SHARED_SEQUENCES[self.uid] = None",
        "begin_line": 585,
        "end_line": 599,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.__init__#618",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.__init__(self, generator, use_multiprocessing=False, wait_time=0.05, seed=None)",
        "snippet": "    def __init__(self, generator,\n                 use_multiprocessing=False,\n                 wait_time=0.05,\n                 seed=None):\n        self.wait_time = wait_time\n        self._generator = generator\n        if os.name is 'nt' and use_multiprocessing is True:\n            # On Windows, avoid **SYSTEMATIC** error in `multiprocessing`:\n            # `TypeError: can't pickle generator objects`\n            # => Suggest multithreading instead of multiprocessing on Windows\n            raise ValueError('Using a generator with `use_multiprocessing=True`'\n                             ' is not supported on Windows (no marshalling of'\n                             ' generators across process boundaries). Instead,'\n                             ' use single thread/process or multithreading.')\n        else:\n            self._use_multiprocessing = use_multiprocessing\n        self._threads = []\n        self._stop_event = None\n        self._manager = None\n        self.queue = None\n        self.seed = seed",
        "begin_line": 618,
        "end_line": 638,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00066711140760507,
            "pseudo_dstar_susp": 0.0004943153732081067,
            "pseudo_tarantula_susp": 0.0011363636363636363,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0011363636363636363
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer._data_generator_task#640",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer._data_generator_task(self)",
        "snippet": "    def _data_generator_task(self):\n        if self._use_multiprocessing is False:\n            while not self._stop_event.is_set():\n                with self.genlock:\n                    try:\n                        if (self.queue is not None and\n                                self.queue.qsize() < self.max_queue_size):\n                            # On all OSes, avoid **SYSTEMATIC** error\n                            # in multithreading mode:\n                            # `ValueError: generator already executing`\n                            # => Serialize calls to\n                            # infinite iterator/generator's next() function\n                            generator_output = next(self._generator)\n                            self.queue.put((True, generator_output))\n                        else:\n                            time.sleep(self.wait_time)\n                    except StopIteration:\n                        break\n                    except Exception as e:\n                        # Can't pickle tracebacks.\n                        # As a compromise, print the traceback and pickle None instead.\n                        if not hasattr(e, '__traceback__'):\n                            setattr(e, '__traceback__', sys.exc_info()[2])\n                        self.queue.put((False, e))\n                        self._stop_event.set()\n                        break\n        else:\n            while not self._stop_event.is_set():\n                try:\n                    if (self.queue is not None and\n                            self.queue.qsize() < self.max_queue_size):\n                        generator_output = next(self._generator)\n                        self.queue.put((True, generator_output))\n                    else:\n                        time.sleep(self.wait_time)\n                except StopIteration:\n                    break\n                except Exception as e:\n                    # Can't pickle tracebacks.\n                    # As a compromise, print the traceback and pickle None instead.\n                    traceback.print_exc()\n                    setattr(e, '__traceback__', None)\n                    self.queue.put((False, e))\n                    self._stop_event.set()\n                    break",
        "begin_line": 640,
        "end_line": 684,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011173184357541898,
            "pseudo_dstar_susp": 0.0005455537370430987,
            "pseudo_tarantula_susp": 0.0014792899408284023,
            "pseudo_op2_susp": 0.0005455537370430987,
            "pseudo_barinel_susp": 0.0014792899408284023
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.start#686",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.start(self, workers=1, max_queue_size=10)",
        "snippet": "    def start(self, workers=1, max_queue_size=10):\n        \"\"\"Kicks off threads which add data from the generator into the queue.\n\n        # Arguments\n            workers: number of worker threads\n            max_queue_size: queue size\n                (when full, threads could block on `put()`)\n        \"\"\"\n        try:\n            self.max_queue_size = max_queue_size\n            if self._use_multiprocessing:\n                self._manager = multiprocessing.Manager()\n                self.queue = self._manager.Queue(maxsize=max_queue_size)\n                self._stop_event = multiprocessing.Event()\n            else:\n                # On all OSes, avoid **SYSTEMATIC** error in multithreading mode:\n                # `ValueError: generator already executing`\n                # => Serialize calls to infinite iterator/generator's next() function\n                self.genlock = threading.Lock()\n                self.queue = queue.Queue(maxsize=max_queue_size)\n                self._stop_event = threading.Event()\n\n            for _ in range(workers):\n                if self._use_multiprocessing:\n                    # Reset random seed else all children processes\n                    # share the same seed\n                    np.random.seed(self.seed)\n                    thread = multiprocessing.Process(target=self._data_generator_task)\n                    thread.daemon = True\n                    if self.seed is not None:\n                        self.seed += 1\n                else:\n                    thread = threading.Thread(target=self._data_generator_task)\n                self._threads.append(thread)\n                thread.start()\n        except:\n            self.stop()\n            raise",
        "begin_line": 686,
        "end_line": 723,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0016366612111292963,
            "pseudo_dstar_susp": 0.0006090133982947625,
            "pseudo_tarantula_susp": 0.002136752136752137,
            "pseudo_op2_susp": 0.0006090133982947625,
            "pseudo_barinel_susp": 0.002136752136752137
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.is_running#725",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.is_running(self)",
        "snippet": "    def is_running(self):\n        return self._stop_event is not None and not self._stop_event.is_set()",
        "begin_line": 725,
        "end_line": 726,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00066711140760507,
            "pseudo_dstar_susp": 0.0004943153732081067,
            "pseudo_tarantula_susp": 0.0011363636363636363,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0011363636363636363
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.stop#728",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.stop(self, timeout=None)",
        "snippet": "    def stop(self, timeout=None):\n        \"\"\"Stops running threads and wait for them to exit, if necessary.\n\n        Should be called by the same thread which called `start()`.\n\n        # Arguments\n            timeout: maximum time to wait on `thread.join()`.\n        \"\"\"\n        if self.is_running():\n            self._stop_event.set()\n\n        for thread in self._threads:\n            if self._use_multiprocessing:\n                if thread.is_alive():\n                    thread.terminate()\n            else:\n                # The thread.is_alive() test is subject to a race condition:\n                # the thread could terminate right after the test and before the\n                # join, rendering this test meaningless -> Call thread.join()\n                # always, which is ok no matter what the status of the thread.\n                thread.join(timeout)\n\n        if self._manager:\n            self._manager.shutdown()\n\n        self._threads = []\n        self._stop_event = None\n        self.queue = None",
        "begin_line": 728,
        "end_line": 755,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017574692442882249,
            "pseudo_dstar_susp": 0.0006222775357809583,
            "pseudo_tarantula_susp": 0.0023148148148148147,
            "pseudo_op2_susp": 0.0006222775357809583,
            "pseudo_barinel_susp": 0.0023148148148148147
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.get#757",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.get(self)",
        "snippet": "    def get(self):\n        \"\"\"Creates a generator to extract data from the queue.\n\n        Skip the data if it is `None`.\n\n        # Yields\n            The next element in the queue, i.e. a tuple\n            `(inputs, targets)` or\n            `(inputs, targets, sample_weights)`.\n        \"\"\"\n        while self.is_running():\n            if not self.queue.empty():\n                success, value = self.queue.get()\n                # Rethrow any exceptions found in the queue\n                if not success:\n                    six.reraise(value.__class__, value, value.__traceback__)\n                # Yield regular values\n                if value is not None:\n                    yield value\n            else:\n                all_finished = all([not thread.is_alive() for thread in self._threads])\n                if all_finished and self.queue.empty():\n                    raise StopIteration()\n                else:\n                    time.sleep(self.wait_time)\n\n        # Make sure to rethrow the first exception in the queue, if any\n        while not self.queue.empty():\n            success, value = self.queue.get()\n            if not success:\n                six.reraise(value.__class__, value, value.__traceback__)",
        "begin_line": 757,
        "end_line": 787,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002109704641350211,
            "pseudo_dstar_susp": 0.0011467889908256881,
            "pseudo_tarantula_susp": 0.0013774104683195593,
            "pseudo_op2_susp": 0.0011467889908256881,
            "pseudo_barinel_susp": 0.0013774104683195593
        }
    },
    {
        "name": "keras.backend.common.epsilon#13",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.epsilon()",
        "snippet": "def epsilon():\n    \"\"\"Returns the value of the fuzz factor used in numeric expressions.\n\n    # Returns\n        A float.\n\n    # Example\n    ```python\n        >>> keras.backend.epsilon()\n        1e-07\n    ```\n    \"\"\"\n    return _EPSILON",
        "begin_line": 13,
        "end_line": 25,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006765899864682003,
            "pseudo_dstar_susp": 0.0016,
            "pseudo_tarantula_susp": 0.0006293266205160479,
            "pseudo_op2_susp": 0.0016,
            "pseudo_barinel_susp": 0.0006293266205160479
        }
    },
    {
        "name": "keras.backend.common.set_epsilon#28",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.set_epsilon(e)",
        "snippet": "def set_epsilon(e):\n    \"\"\"Sets the value of the fuzz factor used in numeric expressions.\n\n    # Arguments\n        e: float. New value of epsilon.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.epsilon()\n        1e-07\n        >>> K.set_epsilon(1e-05)\n        >>> K.epsilon()\n        1e-05\n    ```\n    \"\"\"\n    global _EPSILON\n    _EPSILON = e",
        "begin_line": 28,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.common.floatx#48",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.floatx()",
        "snippet": "def floatx():\n    \"\"\"Returns the default float type, as a string.\n    (e.g. 'float16', 'float32', 'float64').\n\n    # Returns\n        String, the current default float type.\n\n    # Example\n    ```python\n        >>> keras.backend.floatx()\n        'float32'\n    ```\n    \"\"\"\n    return _FLOATX",
        "begin_line": 48,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003861003861003861,
            "pseudo_dstar_susp": 0.06666666666666667,
            "pseudo_tarantula_susp": 0.0008992805755395684,
            "pseudo_op2_susp": 0.06666666666666667,
            "pseudo_barinel_susp": 0.0008992805755395684
        }
    },
    {
        "name": "keras.backend.common.set_floatx#64",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.set_floatx(floatx)",
        "snippet": "def set_floatx(floatx):\n    \"\"\"Sets the default float type.\n\n    # Arguments\n        floatx: String, 'float16', 'float32', or 'float64'.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.floatx()\n        'float32'\n        >>> K.set_floatx('float16')\n        >>> K.floatx()\n        'float16'\n    ```\n    \"\"\"\n    global _FLOATX\n    if floatx not in {'float16', 'float32', 'float64'}:\n        raise ValueError('Unknown floatx type: ' + str(floatx))\n    _FLOATX = str(floatx)",
        "begin_line": 64,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.common.cast_to_floatx#86",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.cast_to_floatx(x)",
        "snippet": "def cast_to_floatx(x):\n    \"\"\"Cast a Numpy array to the default Keras float type.\n\n    # Arguments\n        x: Numpy array.\n\n    # Returns\n        The same Numpy array, cast to its new type.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.floatx()\n        'float32'\n        >>> arr = numpy.array([1.0, 2.0], dtype='float64')\n        >>> arr.dtype\n        dtype('float64')\n        >>> new_arr = K.cast_to_floatx(arr)\n        >>> new_arr\n        array([ 1.,  2.], dtype=float32)\n        >>> new_arr.dtype\n        dtype('float32')\n    ```\n    \"\"\"\n    return np.asarray(x, dtype=_FLOATX)",
        "begin_line": 86,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.476076555023923e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.common.image_data_format#113",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.image_data_format()",
        "snippet": "def image_data_format():\n    \"\"\"Returns the default image data format convention ('channels_first' or 'channels_last').\n\n    # Returns\n        A string, either `'channels_first'` or `'channels_last'`\n\n    # Example\n    ```python\n        >>> keras.backend.image_data_format()\n        'channels_first'\n    ```\n    \"\"\"\n    return _IMAGE_DATA_FORMAT",
        "begin_line": 113,
        "end_line": 125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017574692442882249,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.0008375209380234506,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.0008375209380234506
        }
    },
    {
        "name": "keras.backend.common.set_image_data_format#128",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.set_image_data_format(data_format)",
        "snippet": "def set_image_data_format(data_format):\n    \"\"\"Sets the value of the data format convention.\n\n    # Arguments\n        data_format: string. `'channels_first'` or `'channels_last'`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.image_data_format()\n        'channels_first'\n        >>> K.set_image_data_format('channels_last')\n        >>> K.image_data_format()\n        'channels_last'\n    ```\n    \"\"\"\n    global _IMAGE_DATA_FORMAT\n    if data_format not in {'channels_last', 'channels_first'}:\n        raise ValueError('Unknown data_format:', data_format)\n    _IMAGE_DATA_FORMAT = str(data_format)",
        "begin_line": 128,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.common.set_image_dim_ordering#152",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.set_image_dim_ordering(dim_ordering)",
        "snippet": "def set_image_dim_ordering(dim_ordering):\n    \"\"\"Legacy setter for `image_data_format`.\n\n    # Arguments\n        dim_ordering: string. `tf` or `th`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.image_data_format()\n        'channels_first'\n        >>> K.set_image_data_format('channels_last')\n        >>> K.image_data_format()\n        'channels_last'\n    ```\n\n    # Raises\n        ValueError: if `dim_ordering` is invalid.\n    \"\"\"\n    global _IMAGE_DATA_FORMAT\n    if dim_ordering not in {'tf', 'th'}:\n        raise ValueError('Unknown dim_ordering:', dim_ordering)\n    if dim_ordering == 'th':\n        data_format = 'channels_first'\n    else:\n        data_format = 'channels_last'\n    _IMAGE_DATA_FORMAT = data_format",
        "begin_line": 152,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.common.image_dim_ordering#181",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.image_dim_ordering()",
        "snippet": "def image_dim_ordering():\n    \"\"\"Legacy getter for `image_data_format`.\n\n    # Returns\n        string, one of `'th'`, `'tf'`\n    \"\"\"\n    if _IMAGE_DATA_FORMAT == 'channels_first':\n        return 'th'\n    else:\n        return 'tf'",
        "begin_line": 181,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.datasets.fashion_mnist.load_data#14",
        "src_path": "keras/datasets/fashion_mnist.py",
        "class_name": "keras.datasets.fashion_mnist",
        "signature": "keras.datasets.fashion_mnist.load_data()",
        "snippet": "def load_data():\n    \"\"\"Loads the Fashion-MNIST dataset.\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n    \"\"\"\n    dirname = os.path.join('datasets', 'fashion-mnist')\n    base = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/'\n    files = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n             't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n\n    paths = []\n    for fname in files:\n        paths.append(get_file(fname,\n                              origin=base + fname,\n                              cache_subdir=dirname))\n\n    with gzip.open(paths[0], 'rb') as lbpath:\n        y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n\n    with gzip.open(paths[1], 'rb') as imgpath:\n        x_train = np.frombuffer(imgpath.read(), np.uint8,\n                                offset=16).reshape(len(y_train), 28, 28)\n\n    with gzip.open(paths[2], 'rb') as lbpath:\n        y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n\n    with gzip.open(paths[3], 'rb') as imgpath:\n        x_test = np.frombuffer(imgpath.read(), np.uint8,\n                               offset=16).reshape(len(y_test), 28, 28)\n\n    return (x_train, y_train), (x_test, y_test)",
        "begin_line": 14,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling1D.__init__#19",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling1D",
        "signature": "keras.layers.pooling._Pooling1D.__init__(self, pool_size=2, strides=None, padding='valid', **kwargs)",
        "snippet": "    def __init__(self, pool_size=2, strides=None,\n                 padding='valid', **kwargs):\n        super(_Pooling1D, self).__init__(**kwargs)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = conv_utils.normalize_tuple(pool_size, 1, 'pool_size')\n        self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 19,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling1D.compute_output_shape#29",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling1D",
        "signature": "keras.layers.pooling._Pooling1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        length = conv_utils.conv_output_length(input_shape[1],\n                                               self.pool_size[0],\n                                               self.padding,\n                                               self.strides[0])\n        return (input_shape[0], length, input_shape[2])",
        "begin_line": 29,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling1D._pooling_function#36",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling1D",
        "signature": "keras.layers.pooling._Pooling1D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        raise NotImplementedError",
        "begin_line": 36,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling1D.call#40",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling1D",
        "signature": "keras.layers.pooling._Pooling1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        inputs = K.expand_dims(inputs, 2)   # add dummy last dimension\n        output = self._pooling_function(inputs=inputs,\n                                        pool_size=self.pool_size + (1,),\n                                        strides=self.strides + (1,),\n                                        padding=self.padding,\n                                        data_format='channels_last')\n        return K.squeeze(output, 2)  # remove dummy last dimension",
        "begin_line": 40,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling1D.get_config#49",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling1D",
        "signature": "keras.layers.pooling._Pooling1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'strides': self.strides,\n                  'pool_size': self.pool_size,\n                  'padding': self.padding}\n        base_config = super(_Pooling1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 49,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling1D.__init__#75",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling1D",
        "signature": "keras.layers.pooling.MaxPooling1D.__init__(self, pool_size=2, strides=None, padding='valid', **kwargs)",
        "snippet": "    def __init__(self, pool_size=2, strides=None,\n                 padding='valid', **kwargs):\n        super(MaxPooling1D, self).__init__(pool_size, strides,\n                                           padding, **kwargs)",
        "begin_line": 75,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling1D._pooling_function#80",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling1D",
        "signature": "keras.layers.pooling.MaxPooling1D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode='max')\n        return output",
        "begin_line": 80,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling1D.__init__#105",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling1D",
        "signature": "keras.layers.pooling.AveragePooling1D.__init__(self, pool_size=2, strides=None, padding='valid', **kwargs)",
        "snippet": "    def __init__(self, pool_size=2, strides=None,\n                 padding='valid', **kwargs):\n        super(AveragePooling1D, self).__init__(pool_size, strides,\n                                               padding, **kwargs)",
        "begin_line": 105,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling1D._pooling_function#110",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling1D",
        "signature": "keras.layers.pooling.AveragePooling1D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode='avg')\n        return output",
        "begin_line": 110,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling2D.__init__#121",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling2D",
        "signature": "keras.layers.pooling._Pooling2D.__init__(self, pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(_Pooling2D, self).__init__(**kwargs)\n        data_format = conv_utils.normalize_data_format(data_format)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size')\n        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 121,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling2D.compute_output_shape#133",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling2D",
        "signature": "keras.layers.pooling._Pooling2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        elif self.data_format == 'channels_last':\n            rows = input_shape[1]\n            cols = input_shape[2]\n        rows = conv_utils.conv_output_length(rows, self.pool_size[0],\n                                             self.padding, self.strides[0])\n        cols = conv_utils.conv_output_length(cols, self.pool_size[1],\n                                             self.padding, self.strides[1])\n        if self.data_format == 'channels_first':\n            return (input_shape[0], input_shape[1], rows, cols)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0], rows, cols, input_shape[3])",
        "begin_line": 133,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling2D._pooling_function#149",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling2D",
        "signature": "keras.layers.pooling._Pooling2D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        raise NotImplementedError",
        "begin_line": 149,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling2D.call#153",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling2D",
        "signature": "keras.layers.pooling._Pooling2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = self._pooling_function(inputs=inputs,\n                                        pool_size=self.pool_size,\n                                        strides=self.strides,\n                                        padding=self.padding,\n                                        data_format=self.data_format)\n        return output",
        "begin_line": 153,
        "end_line": 159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.350730688935282e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling2D.get_config#161",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling2D",
        "signature": "keras.layers.pooling._Pooling2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'pool_size': self.pool_size,\n                  'padding': self.padding,\n                  'strides': self.strides,\n                  'data_format': self.data_format}\n        base_config = super(_Pooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 161,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling2D.__init__#212",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling2D",
        "signature": "keras.layers.pooling.MaxPooling2D.__init__(self, pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(MaxPooling2D, self).__init__(pool_size, strides, padding,\n                                           data_format, **kwargs)",
        "begin_line": 212,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling2D._pooling_function#217",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling2D",
        "signature": "keras.layers.pooling.MaxPooling2D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format,\n                          pool_mode='max')\n        return output",
        "begin_line": 217,
        "end_line": 222,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling2D.__init__#267",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling2D",
        "signature": "keras.layers.pooling.AveragePooling2D.__init__(self, pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(AveragePooling2D, self).__init__(pool_size, strides, padding,\n                                               data_format, **kwargs)",
        "begin_line": 267,
        "end_line": 270,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling2D._pooling_function#272",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling2D",
        "signature": "keras.layers.pooling.AveragePooling2D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode='avg')\n        return output",
        "begin_line": 272,
        "end_line": 276,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling3D.__init__#283",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling3D",
        "signature": "keras.layers.pooling._Pooling3D.__init__(self, pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(_Pooling3D, self).__init__(**kwargs)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = conv_utils.normalize_tuple(pool_size, 3, 'pool_size')\n        self.strides = conv_utils.normalize_tuple(strides, 3, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 283,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling3D.compute_output_shape#294",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling3D",
        "signature": "keras.layers.pooling._Pooling3D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            len_dim1 = input_shape[2]\n            len_dim2 = input_shape[3]\n            len_dim3 = input_shape[4]\n        elif self.data_format == 'channels_last':\n            len_dim1 = input_shape[1]\n            len_dim2 = input_shape[2]\n            len_dim3 = input_shape[3]\n        len_dim1 = conv_utils.conv_output_length(len_dim1, self.pool_size[0],\n                                                 self.padding, self.strides[0])\n        len_dim2 = conv_utils.conv_output_length(len_dim2, self.pool_size[1],\n                                                 self.padding, self.strides[1])\n        len_dim3 = conv_utils.conv_output_length(len_dim3, self.pool_size[2],\n                                                 self.padding, self.strides[2])\n        if self.data_format == 'channels_first':\n            return (input_shape[0],\n                    input_shape[1],\n                    len_dim1, len_dim2, len_dim3)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0],\n                    len_dim1, len_dim2, len_dim3,\n                    input_shape[4])",
        "begin_line": 294,
        "end_line": 316,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling3D._pooling_function#318",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling3D",
        "signature": "keras.layers.pooling._Pooling3D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        raise NotImplementedError",
        "begin_line": 318,
        "end_line": 320,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling3D.call#322",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling3D",
        "signature": "keras.layers.pooling._Pooling3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = self._pooling_function(inputs=inputs,\n                                        pool_size=self.pool_size,\n                                        strides=self.strides,\n                                        padding=self.padding,\n                                        data_format=self.data_format)\n        return output",
        "begin_line": 322,
        "end_line": 328,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._Pooling3D.get_config#330",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling3D",
        "signature": "keras.layers.pooling._Pooling3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'pool_size': self.pool_size,\n                  'padding': self.padding,\n                  'strides': self.strides,\n                  'data_format': self.data_format}\n        base_config = super(_Pooling3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 330,
        "end_line": 336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling3D.__init__#377",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling3D",
        "signature": "keras.layers.pooling.MaxPooling3D.__init__(self, pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(MaxPooling3D, self).__init__(pool_size, strides, padding,\n                                           data_format, **kwargs)",
        "begin_line": 377,
        "end_line": 380,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling3D._pooling_function#382",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling3D",
        "signature": "keras.layers.pooling.MaxPooling3D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool3d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode='max')\n        return output",
        "begin_line": 382,
        "end_line": 386,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling3D.__init__#427",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling3D",
        "signature": "keras.layers.pooling.AveragePooling3D.__init__(self, pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(AveragePooling3D, self).__init__(pool_size, strides, padding,\n                                               data_format, **kwargs)",
        "begin_line": 427,
        "end_line": 430,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling3D._pooling_function#432",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling3D",
        "signature": "keras.layers.pooling.AveragePooling3D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool3d(inputs, pool_size, strides,\n                          padding, data_format,\n                          pool_mode='avg')\n        return output",
        "begin_line": 432,
        "end_line": 437,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling1D.__init__#444",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling1D",
        "signature": "keras.layers.pooling._GlobalPooling1D.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        super(_GlobalPooling1D, self).__init__(**kwargs)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 444,
        "end_line": 446,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling1D.compute_output_shape#448",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling1D",
        "signature": "keras.layers.pooling._GlobalPooling1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[2])",
        "begin_line": 448,
        "end_line": 449,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling1D.call#451",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling1D",
        "signature": "keras.layers.pooling._GlobalPooling1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        raise NotImplementedError",
        "begin_line": 451,
        "end_line": 452,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.GlobalAveragePooling1D.call#466",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalAveragePooling1D",
        "signature": "keras.layers.pooling.GlobalAveragePooling1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.mean(inputs, axis=1)",
        "begin_line": 466,
        "end_line": 467,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.GlobalMaxPooling1D.call#481",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalMaxPooling1D",
        "signature": "keras.layers.pooling.GlobalMaxPooling1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.max(inputs, axis=1)",
        "begin_line": 481,
        "end_line": 482,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling2D.__init__#490",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling2D",
        "signature": "keras.layers.pooling._GlobalPooling2D.__init__(self, data_format=None, **kwargs)",
        "snippet": "    def __init__(self, data_format=None, **kwargs):\n        super(_GlobalPooling2D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 490,
        "end_line": 493,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling2D.compute_output_shape#495",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling2D",
        "signature": "keras.layers.pooling._GlobalPooling2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_last':\n            return (input_shape[0], input_shape[3])\n        else:\n            return (input_shape[0], input_shape[1])",
        "begin_line": 495,
        "end_line": 499,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling2D.call#501",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling2D",
        "signature": "keras.layers.pooling._GlobalPooling2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        raise NotImplementedError",
        "begin_line": 501,
        "end_line": 502,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling2D.get_config#504",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling2D",
        "signature": "keras.layers.pooling._GlobalPooling2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'data_format': self.data_format}\n        base_config = super(_GlobalPooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 504,
        "end_line": 507,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.GlobalAveragePooling2D.call#538",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalAveragePooling2D",
        "signature": "keras.layers.pooling.GlobalAveragePooling2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_last':\n            return K.mean(inputs, axis=[1, 2])\n        else:\n            return K.mean(inputs, axis=[2, 3])",
        "begin_line": 538,
        "end_line": 542,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.GlobalMaxPooling2D.call#573",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalMaxPooling2D",
        "signature": "keras.layers.pooling.GlobalMaxPooling2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_last':\n            return K.max(inputs, axis=[1, 2])\n        else:\n            return K.max(inputs, axis=[2, 3])",
        "begin_line": 573,
        "end_line": 577,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling3D.__init__#585",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling3D",
        "signature": "keras.layers.pooling._GlobalPooling3D.__init__(self, data_format=None, **kwargs)",
        "snippet": "    def __init__(self, data_format=None, **kwargs):\n        super(_GlobalPooling3D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 585,
        "end_line": 588,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling3D.compute_output_shape#590",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling3D",
        "signature": "keras.layers.pooling._GlobalPooling3D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_last':\n            return (input_shape[0], input_shape[4])\n        else:\n            return (input_shape[0], input_shape[1])",
        "begin_line": 590,
        "end_line": 594,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling3D.call#596",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling3D",
        "signature": "keras.layers.pooling._GlobalPooling3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        raise NotImplementedError",
        "begin_line": 596,
        "end_line": 597,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling3D.get_config#599",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling3D",
        "signature": "keras.layers.pooling._GlobalPooling3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'data_format': self.data_format}\n        base_config = super(_GlobalPooling3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 599,
        "end_line": 602,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.GlobalAveragePooling3D.call#633",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalAveragePooling3D",
        "signature": "keras.layers.pooling.GlobalAveragePooling3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_last':\n            return K.mean(inputs, axis=[1, 2, 3])\n        else:\n            return K.mean(inputs, axis=[2, 3, 4])",
        "begin_line": 633,
        "end_line": 637,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.pooling.GlobalMaxPooling3D.call#668",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalMaxPooling3D",
        "signature": "keras.layers.pooling.GlobalMaxPooling3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_last':\n            return K.max(inputs, axis=[1, 2, 3])\n        else:\n            return K.max(inputs, axis=[2, 3, 4])",
        "begin_line": 668,
        "end_line": 672,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.datasets.cifar10.load_data#14",
        "src_path": "keras/datasets/cifar10.py",
        "class_name": "keras.datasets.cifar10",
        "signature": "keras.datasets.cifar10.load_data()",
        "snippet": "def load_data():\n    \"\"\"Loads CIFAR10 dataset.\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n    \"\"\"\n    dirname = 'cifar-10-batches-py'\n    origin = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n    path = get_file(dirname, origin=origin, untar=True)\n\n    num_train_samples = 50000\n\n    x_train = np.empty((num_train_samples, 3, 32, 32), dtype='uint8')\n    y_train = np.empty((num_train_samples,), dtype='uint8')\n\n    for i in range(1, 6):\n        fpath = os.path.join(path, 'data_batch_' + str(i))\n        (x_train[(i - 1) * 10000: i * 10000, :, :, :],\n         y_train[(i - 1) * 10000: i * 10000]) = load_batch(fpath)\n\n    fpath = os.path.join(path, 'test_batch')\n    x_test, y_test = load_batch(fpath)\n\n    y_train = np.reshape(y_train, (len(y_train), 1))\n    y_test = np.reshape(y_test, (len(y_test), 1))\n\n    if K.image_data_format() == 'channels_last':\n        x_train = x_train.transpose(0, 2, 3, 1)\n        x_test = x_test.transpose(0, 2, 3, 1)\n\n    return (x_train, y_train), (x_test, y_test)",
        "begin_line": 14,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.np_utils.to_categorical#9",
        "src_path": "keras/utils/np_utils.py",
        "class_name": "keras.utils.np_utils",
        "signature": "keras.utils.np_utils.to_categorical(y, num_classes=None)",
        "snippet": "def to_categorical(y, num_classes=None):\n    \"\"\"Converts a class vector (integers) to binary class matrix.\n\n    E.g. for use with categorical_crossentropy.\n\n    # Arguments\n        y: class vector to be converted into a matrix\n            (integers from 0 to num_classes).\n        num_classes: total number of classes.\n\n    # Returns\n        A binary matrix representation of the input.\n    \"\"\"\n    y = np.array(y, dtype='int')\n    input_shape = y.shape\n    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n        input_shape = tuple(input_shape[:-1])\n    y = y.ravel()\n    if not num_classes:\n        num_classes = np.max(y) + 1\n    n = y.shape[0]\n    categorical = np.zeros((n, num_classes))\n    categorical[np.arange(n), y] = 1\n    output_shape = input_shape + (num_classes,)\n    categorical = np.reshape(categorical, output_shape)\n    return categorical",
        "begin_line": 9,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005350454788657035,
            "pseudo_dstar_susp": 0.0004633920296570899,
            "pseudo_tarantula_susp": 0.0009140767824497258,
            "pseudo_op2_susp": 0.0004633920296570899,
            "pseudo_barinel_susp": 0.0009140767824497258
        }
    },
    {
        "name": "keras.utils.np_utils.normalize#37",
        "src_path": "keras/utils/np_utils.py",
        "class_name": "keras.utils.np_utils",
        "signature": "keras.utils.np_utils.normalize(x, axis=-1, order=2)",
        "snippet": "def normalize(x, axis=-1, order=2):\n    \"\"\"Normalizes a Numpy array.\n\n    # Arguments\n        x: Numpy array to normalize.\n        axis: axis along which to normalize.\n        order: Normalization order (e.g. 2 for L2 norm).\n\n    # Returns\n        A normalized copy of the array.\n    \"\"\"\n    l2 = np.atleast_1d(np.linalg.norm(x, order, axis))\n    l2[l2 == 0] = 1\n    return x / np.expand_dims(l2, axis)",
        "begin_line": 37,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.__init__.serialize#24",
        "src_path": "keras/layers/__init__.py",
        "class_name": "keras.layers.__init__",
        "signature": "keras.layers.__init__.serialize(layer)",
        "snippet": "def serialize(layer):\n    \"\"\"Serialize a layer.\n\n    # Arguments\n        layer: a Layer object.\n\n    # Returns\n        dictionary with config.\n    \"\"\"\n    return {'class_name': layer.__class__.__name__,\n            'config': layer.get_config()}",
        "begin_line": 24,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.__init__.deserialize#37",
        "src_path": "keras/layers/__init__.py",
        "class_name": "keras.layers.__init__",
        "signature": "keras.layers.__init__.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    \"\"\"Instantiate a layer from a config dictionary.\n\n    # Arguments\n        config: dict of the form {'class_name': str, 'config': dict}\n        custom_objects: dict mapping class names (or function names)\n            of custom (non-Keras) objects to class/functions\n\n    # Returns\n        Layer instance (may be Model, Sequential, Layer...)\n    \"\"\"\n    from .. import models\n    globs = globals()  # All layers.\n    globs['Model'] = models.Model\n    globs['Sequential'] = models.Sequential\n    return deserialize_keras_object(config,\n                                    module_objects=globs,\n                                    custom_objects=custom_objects,\n                                    printable_module_name='layer')",
        "begin_line": 37,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003790750568612585,
            "pseudo_dstar_susp": 0.0003779289493575208,
            "pseudo_tarantula_susp": 0.0004166666666666667,
            "pseudo_op2_susp": 0.0003779289493575208,
            "pseudo_barinel_susp": 0.0004166666666666667
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.__init__#87",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.__init__(self, rank, filters, kernel_size, strides=1, padding='valid', data_format=None, dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, rank,\n                 filters,\n                 kernel_size,\n                 strides=1,\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=1,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(_Conv, self).__init__(**kwargs)\n        self.rank = rank\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=self.rank + 2)",
        "begin_line": 87,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005586592178770949,
            "pseudo_dstar_susp": 0.0004786979415988511,
            "pseudo_tarantula_susp": 0.0010526315789473684,
            "pseudo_op2_susp": 0.0004786979415988511,
            "pseudo_barinel_susp": 0.0010526315789473684
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.build#123",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 123,
        "end_line": 150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011173184357541898,
            "pseudo_dstar_susp": 0.0005455537370430987,
            "pseudo_tarantula_susp": 0.0014792899408284023,
            "pseudo_op2_susp": 0.0005455537370430987,
            "pseudo_barinel_susp": 0.0014792899408284023
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.call#152",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.rank == 1:\n            outputs = K.conv1d(\n                inputs,\n                self.kernel,\n                strides=self.strides[0],\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate[0])\n        if self.rank == 2:\n            outputs = K.conv2d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n        if self.rank == 3:\n            outputs = K.conv3d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs",
        "begin_line": 152,
        "end_line": 186,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011173184357541898,
            "pseudo_dstar_susp": 0.0005455537370430987,
            "pseudo_tarantula_susp": 0.0014792899408284023,
            "pseudo_op2_susp": 0.0005455537370430987,
            "pseudo_barinel_susp": 0.0014792899408284023
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.compute_output_shape#188",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_last':\n            space = input_shape[1:-1]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n        if self.data_format == 'channels_first':\n            space = input_shape[2:]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            return (input_shape[0], self.filters) + tuple(new_space)",
        "begin_line": 188,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006765899864682003,
            "pseudo_dstar_susp": 0.000499001996007984,
            "pseudo_tarantula_susp": 0.0011614401858304297,
            "pseudo_op2_susp": 0.000499001996007984,
            "pseudo_barinel_susp": 0.0011614401858304297
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.get_config#214",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'rank': self.rank,\n            'filters': self.filters,\n            'kernel_size': self.kernel_size,\n            'strides': self.strides,\n            'padding': self.padding,\n            'data_format': self.data_format,\n            'dilation_rate': self.dilation_rate,\n            'activation': activations.serialize(self.activation),\n            'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(_Conv, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 214,
        "end_line": 234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.010894816951053e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv1D.__init__#305",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv1D",
        "signature": "keras.layers.convolutional.Conv1D.__init__(self, filters, kernel_size, strides=1, padding='valid', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=1,\n                 padding='valid',\n                 dilation_rate=1,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv1D, self).__init__(\n            rank=1,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format='channels_last',\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 305,
        "end_line": 338,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv1D.get_config#340",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv1D",
        "signature": "keras.layers.convolutional.Conv1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(Conv1D, self).get_config()\n        config.pop('rank')\n        config.pop('data_format')\n        return config",
        "begin_line": 340,
        "end_line": 344,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2D.__init__#429",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2D",
        "signature": "keras.layers.convolutional.Conv2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv2D, self).__init__(\n            rank=2,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 429,
        "end_line": 463,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007047216349541931,
            "pseudo_dstar_susp": 0.0005058168942842691,
            "pseudo_tarantula_susp": 0.001199040767386091,
            "pseudo_op2_susp": 0.0005058168942842691,
            "pseudo_barinel_susp": 0.001199040767386091
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2D.get_config#465",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2D",
        "signature": "keras.layers.convolutional.Conv2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(Conv2D, self).get_config()\n        config.pop('rank')\n        return config",
        "begin_line": 465,
        "end_line": 468,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3D.__init__#554",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3D",
        "signature": "keras.layers.convolutional.Conv3D.__init__(self, filters, kernel_size, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1, 1),\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=(1, 1, 1),\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv3D, self).__init__(\n            rank=3,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 554,
        "end_line": 588,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3D.get_config#590",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3D",
        "signature": "keras.layers.convolutional.Conv3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(Conv3D, self).get_config()\n        config.pop('rank')\n        return config",
        "begin_line": 590,
        "end_line": 593,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2DTranspose.__init__#683",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2DTranspose",
        "signature": "keras.layers.convolutional.Conv2DTranspose.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv2DTranspose, self).__init__(\n            filters,\n            kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 683,
        "end_line": 714,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2DTranspose.build#716",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2DTranspose",
        "signature": "keras.layers.convolutional.Conv2DTranspose.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if len(input_shape) != 4:\n            raise ValueError('Inputs should have rank ' +\n                             str(4) +\n                             '; Received input shape:', str(input_shape))\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 716,
        "end_line": 746,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2DTranspose.call#748",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2DTranspose",
        "signature": "keras.layers.convolutional.Conv2DTranspose.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n        if self.data_format == 'channels_first':\n            h_axis, w_axis = 2, 3\n        else:\n            h_axis, w_axis = 1, 2\n\n        height, width = input_shape[h_axis], input_shape[w_axis]\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.strides\n\n        # Infer the dynamic output shape:\n        out_height = conv_utils.deconv_length(height,\n                                              stride_h, kernel_h,\n                                              self.padding)\n        out_width = conv_utils.deconv_length(width,\n                                             stride_w, kernel_w,\n                                             self.padding)\n        if self.data_format == 'channels_first':\n            output_shape = (batch_size, self.filters, out_height, out_width)\n        else:\n            output_shape = (batch_size, out_height, out_width, self.filters)\n\n        outputs = K.conv2d_transpose(\n            inputs,\n            self.kernel,\n            output_shape,\n            self.strides,\n            padding=self.padding,\n            data_format=self.data_format)\n\n        if self.bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs",
        "begin_line": 748,
        "end_line": 788,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2DTranspose.compute_output_shape#790",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2DTranspose",
        "signature": "keras.layers.convolutional.Conv2DTranspose.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n        if self.data_format == 'channels_first':\n            c_axis, h_axis, w_axis = 1, 2, 3\n        else:\n            c_axis, h_axis, w_axis = 3, 1, 2\n\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.strides\n\n        output_shape[c_axis] = self.filters\n        output_shape[h_axis] = conv_utils.deconv_length(\n            output_shape[h_axis], stride_h, kernel_h, self.padding)\n        output_shape[w_axis] = conv_utils.deconv_length(\n            output_shape[w_axis], stride_w, kernel_w, self.padding)\n        return tuple(output_shape)",
        "begin_line": 790,
        "end_line": 805,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2DTranspose.get_config#807",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2DTranspose",
        "signature": "keras.layers.convolutional.Conv2DTranspose.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(Conv2DTranspose, self).get_config()\n        config.pop('dilation_rate')\n        return config",
        "begin_line": 807,
        "end_line": 810,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3DTranspose.__init__#899",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3DTranspose",
        "signature": "keras.layers.convolutional.Conv3DTranspose.__init__(self, filters, kernel_size, strides=(1, 1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1, 1),\n                 padding='valid',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv3DTranspose, self).__init__(\n            filters,\n            kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 899,
        "end_line": 930,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3DTranspose.build#932",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3DTranspose",
        "signature": "keras.layers.convolutional.Conv3DTranspose.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if len(input_shape) != 5:\n            raise ValueError('Inputs should have rank ' +\n                             str(5) +\n                             '; Received input shape:', str(input_shape))\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=5, axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 932,
        "end_line": 962,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3DTranspose.call#964",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3DTranspose",
        "signature": "keras.layers.convolutional.Conv3DTranspose.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n        if self.data_format == 'channels_first':\n            d_axis, h_axis, w_axis = 2, 3, 4\n        else:\n            d_axis, h_axis, w_axis = 1, 2, 3\n\n        depth = input_shape[d_axis]\n        height = input_shape[h_axis]\n        width = input_shape[w_axis]\n\n        kernel_d, kernel_h, kernel_w = self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n\n        # Infer the dynamic output shape:\n        out_depth = conv_utils.deconv_length(depth,\n                                             stride_d, kernel_d,\n                                             self.padding)\n        out_height = conv_utils.deconv_length(height,\n                                              stride_h, kernel_h,\n                                              self.padding)\n        out_width = conv_utils.deconv_length(width,\n                                             stride_w, kernel_w,\n                                             self.padding)\n\n        if self.data_format == 'channels_first':\n            output_shape = (batch_size, self.filters, out_depth, out_height, out_width)\n        else:\n            output_shape = (batch_size, out_depth, out_height, out_width, self.filters)\n\n        outputs = K.conv3d_transpose(inputs,\n                                     self.kernel,\n                                     output_shape,\n                                     self.strides,\n                                     padding=self.padding,\n                                     data_format=self.data_format)\n\n        if self.bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs",
        "begin_line": 964,
        "end_line": 1010,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3DTranspose.compute_output_shape#1012",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3DTranspose",
        "signature": "keras.layers.convolutional.Conv3DTranspose.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n        if self.data_format == 'channels_first':\n            c_axis, d_axis, h_axis, w_axis = 1, 2, 3, 4\n        else:\n            c_axis, d_axis, h_axis, w_axis = 4, 1, 2, 3\n\n        kernel_d, kernel_h, kernel_w = self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n\n        output_shape[c_axis] = self.filters\n        output_shape[d_axis] = conv_utils.deconv_length(output_shape[d_axis],\n                                                        stride_d,\n                                                        kernel_d,\n                                                        self.padding)\n        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n                                                        stride_h,\n                                                        kernel_h,\n                                                        self.padding)\n        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n                                                        stride_w,\n                                                        kernel_w,\n                                                        self.padding)\n\n        return tuple(output_shape)",
        "begin_line": 1012,
        "end_line": 1036,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3DTranspose.get_config#1038",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3DTranspose",
        "signature": "keras.layers.convolutional.Conv3DTranspose.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(Conv3DTranspose, self).get_config()\n        config.pop('dilation_rate')\n        return config",
        "begin_line": 1038,
        "end_line": 1041,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional._SeparableConv.__init__#1133",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._SeparableConv",
        "signature": "keras.layers.convolutional._SeparableConv.__init__(self, rank, filters, kernel_size, strides=1, padding='valid', data_format=None, depth_multiplier=1, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, pointwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, rank,\n                 filters,\n                 kernel_size,\n                 strides=1,\n                 padding='valid',\n                 data_format=None,\n                 depth_multiplier=1,\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer='glorot_uniform',\n                 pointwise_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 depthwise_regularizer=None,\n                 pointwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 pointwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(_SeparableConv, self).__init__(\n            rank=rank,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            activation=activation,\n            use_bias=use_bias,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.depth_multiplier = depth_multiplier\n        self.depthwise_initializer = initializers.get(depthwise_initializer)\n        self.pointwise_initializer = initializers.get(pointwise_initializer)\n        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n        self.pointwise_regularizer = regularizers.get(pointwise_regularizer)\n        self.depthwise_constraint = constraints.get(depthwise_constraint)\n        self.pointwise_constraint = constraints.get(pointwise_constraint)",
        "begin_line": 1133,
        "end_line": 1172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional._SeparableConv.build#1174",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._SeparableConv",
        "signature": "keras.layers.convolutional._SeparableConv.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if len(input_shape) < self.rank + 2:\n            raise ValueError('Inputs to `SeparableConv' + str(self.rank) + 'D` '\n                             'should have rank ' + str(self.rank + 2) + '. '\n                             'Received input shape:', str(input_shape))\n        channel_axis = 1 if self.data_format == 'channels_first' else -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = int(input_shape[channel_axis])\n        depthwise_kernel_shape = self.kernel_size + (input_dim, self.depth_multiplier)\n        pointwise_kernel_shape = (1,) * self.rank + (self.depth_multiplier * input_dim, self.filters)\n\n        self.depthwise_kernel = self.add_weight(\n            shape=depthwise_kernel_shape,\n            initializer=self.depthwise_initializer,\n            name='depthwise_kernel',\n            regularizer=self.depthwise_regularizer,\n            constraint=self.depthwise_constraint)\n        self.pointwise_kernel = self.add_weight(\n            shape=pointwise_kernel_shape,\n            initializer=self.pointwise_initializer,\n            name='pointwise_kernel',\n            regularizer=self.pointwise_regularizer,\n            constraint=self.pointwise_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 1174,
        "end_line": 1211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional._SeparableConv.call#1213",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._SeparableConv",
        "signature": "keras.layers.convolutional._SeparableConv.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.rank == 1:\n            outputs = K.separable_conv1d(\n                inputs,\n                self.depthwise_kernel,\n                self.pointwise_kernel,\n                data_format=self.data_format,\n                strides=self.strides,\n                padding=self.padding,\n                dilation_rate=self.dilation_rate)\n        if self.rank == 2:\n            outputs = K.separable_conv2d(\n                inputs,\n                self.depthwise_kernel,\n                self.pointwise_kernel,\n                data_format=self.data_format,\n                strides=self.strides,\n                padding=self.padding,\n                dilation_rate=self.dilation_rate)\n\n        if self.bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs",
        "begin_line": 1213,
        "end_line": 1241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional._SeparableConv.get_config#1243",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._SeparableConv",
        "signature": "keras.layers.convolutional._SeparableConv.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(_SeparableConv, self).get_config()\n        config.pop('rank')\n        config.pop('kernel_initializer')\n        config.pop('kernel_regularizer')\n        config.pop('kernel_constraint')\n        config['depth_multiplier'] = self.depth_multiplier\n        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n        config['pointwise_initializer'] = initializers.serialize(self.pointwise_initializer)\n        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n        config['pointwise_regularizer'] = regularizers.serialize(self.pointwise_regularizer)\n        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n        config['pointwise_constraint'] = constraints.serialize(self.pointwise_constraint)\n        return config",
        "begin_line": 1243,
        "end_line": 1256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.SeparableConv1D.__init__#1342",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.SeparableConv1D",
        "signature": "keras.layers.convolutional.SeparableConv1D.__init__(self, filters, kernel_size, strides=1, padding='valid', data_format=None, depth_multiplier=1, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, pointwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=1,\n                 padding='valid',\n                 data_format=None,\n                 depth_multiplier=1,\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer='glorot_uniform',\n                 pointwise_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 depthwise_regularizer=None,\n                 pointwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 pointwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(SeparableConv1D, self).__init__(\n            rank=1,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            depth_multiplier=depth_multiplier,\n            activation=activation,\n            use_bias=use_bias,\n            depthwise_initializer=depthwise_initializer,\n            pointwise_initializer=pointwise_initializer,\n            bias_initializer=bias_initializer,\n            depthwise_regularizer=depthwise_regularizer,\n            pointwise_regularizer=pointwise_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            depthwise_constraint=depthwise_constraint,\n            pointwise_constraint=pointwise_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)",
        "begin_line": 1342,
        "end_line": 1381,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.SeparableConv2D.__init__#1472",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.SeparableConv2D",
        "signature": "keras.layers.convolutional.SeparableConv2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, depth_multiplier=1, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, pointwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 depth_multiplier=1,\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer='glorot_uniform',\n                 pointwise_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 depthwise_regularizer=None,\n                 pointwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 pointwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(SeparableConv2D, self).__init__(\n            rank=2,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            depth_multiplier=depth_multiplier,\n            activation=activation,\n            use_bias=use_bias,\n            depthwise_initializer=depthwise_initializer,\n            pointwise_initializer=pointwise_initializer,\n            bias_initializer=bias_initializer,\n            depthwise_regularizer=depthwise_regularizer,\n            pointwise_regularizer=pointwise_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            depthwise_constraint=depthwise_constraint,\n            pointwise_constraint=pointwise_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)",
        "begin_line": 1472,
        "end_line": 1511,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.DepthwiseConv2D.__init__#1586",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.DepthwiseConv2D",
        "signature": "keras.layers.convolutional.DepthwiseConv2D.__init__(self, kernel_size, strides=(1, 1), padding='valid', depth_multiplier=1, data_format=None, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 depth_multiplier=1,\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 depthwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(DepthwiseConv2D, self).__init__(\n            filters=None,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            activation=activation,\n            use_bias=use_bias,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.depth_multiplier = depth_multiplier\n        self.depthwise_initializer = initializers.get(depthwise_initializer)\n        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n        self.depthwise_constraint = constraints.get(depthwise_constraint)\n        self.bias_initializer = initializers.get(bias_initializer)",
        "begin_line": 1586,
        "end_line": 1618,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.DepthwiseConv2D.build#1620",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.DepthwiseConv2D",
        "signature": "keras.layers.convolutional.DepthwiseConv2D.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if len(input_shape) < 4:\n            raise ValueError('Inputs to `DepthwiseConv2D` should have rank 4. '\n                             'Received input shape:', str(input_shape))\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = 3\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs to '\n                             '`DepthwiseConv2D` '\n                             'should be defined. Found `None`.')\n        input_dim = int(input_shape[channel_axis])\n        depthwise_kernel_shape = (self.kernel_size[0],\n                                  self.kernel_size[1],\n                                  input_dim,\n                                  self.depth_multiplier)\n\n        self.depthwise_kernel = self.add_weight(\n            shape=depthwise_kernel_shape,\n            initializer=self.depthwise_initializer,\n            name='depthwise_kernel',\n            regularizer=self.depthwise_regularizer,\n            constraint=self.depthwise_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 1620,
        "end_line": 1655,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.DepthwiseConv2D.call#1657",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.DepthwiseConv2D",
        "signature": "keras.layers.convolutional.DepthwiseConv2D.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        outputs = K.depthwise_conv2d(\n            inputs,\n            self.depthwise_kernel,\n            strides=self.strides,\n            padding=self.padding,\n            dilation_rate=self.dilation_rate,\n            data_format=self.data_format)\n\n        if self.bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n\n        return outputs",
        "begin_line": 1657,
        "end_line": 1675,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.DepthwiseConv2D.compute_output_shape#1677",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.DepthwiseConv2D",
        "signature": "keras.layers.convolutional.DepthwiseConv2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            rows = input_shape[2]\n            cols = input_shape[3]\n            out_filters = input_shape[1] * self.depth_multiplier\n        elif self.data_format == 'channels_last':\n            rows = input_shape[1]\n            cols = input_shape[2]\n            out_filters = input_shape[3] * self.depth_multiplier\n\n        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n                                             self.padding,\n                                             self.strides[0])\n        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n                                             self.padding,\n                                             self.strides[1])\n        if self.data_format == 'channels_first':\n            return (input_shape[0], out_filters, rows, cols)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0], rows, cols, out_filters)",
        "begin_line": 1677,
        "end_line": 1696,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.DepthwiseConv2D.get_config#1698",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.DepthwiseConv2D",
        "signature": "keras.layers.convolutional.DepthwiseConv2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(DepthwiseConv2D, self).get_config()\n        config.pop('filters')\n        config.pop('kernel_initializer')\n        config.pop('kernel_regularizer')\n        config.pop('kernel_constraint')\n        config['depth_multiplier'] = self.depth_multiplier\n        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n        return config",
        "begin_line": 1698,
        "end_line": 1708,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling1D.__init__#1727",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling1D",
        "signature": "keras.layers.convolutional.UpSampling1D.__init__(self, size=2, **kwargs)",
        "snippet": "    def __init__(self, size=2, **kwargs):\n        super(UpSampling1D, self).__init__(**kwargs)\n        self.size = int(size)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 1727,
        "end_line": 1730,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling1D.compute_output_shape#1732",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling1D",
        "signature": "keras.layers.convolutional.UpSampling1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        size = self.size * input_shape[1] if input_shape[1] is not None else None\n        return (input_shape[0], size, input_shape[2])",
        "begin_line": 1732,
        "end_line": 1734,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling1D.call#1736",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling1D",
        "signature": "keras.layers.convolutional.UpSampling1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = K.repeat_elements(inputs, self.size, axis=1)\n        return output",
        "begin_line": 1736,
        "end_line": 1738,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling1D.get_config#1740",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling1D",
        "signature": "keras.layers.convolutional.UpSampling1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'size': self.size}\n        base_config = super(UpSampling1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1740,
        "end_line": 1743,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling2D.__init__#1782",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling2D",
        "signature": "keras.layers.convolutional.UpSampling2D.__init__(self, size=(2, 2), data_format=None, **kwargs)",
        "snippet": "    def __init__(self, size=(2, 2), data_format=None, **kwargs):\n        super(UpSampling2D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.size = conv_utils.normalize_tuple(size, 2, 'size')\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 1782,
        "end_line": 1786,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling2D.compute_output_shape#1788",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling2D",
        "signature": "keras.layers.convolutional.UpSampling2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            height = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n            width = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n            return (input_shape[0],\n                    input_shape[1],\n                    height,\n                    width)\n        elif self.data_format == 'channels_last':\n            height = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n            width = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n            return (input_shape[0],\n                    height,\n                    width,\n                    input_shape[3])",
        "begin_line": 1788,
        "end_line": 1802,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling2D.call#1804",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling2D",
        "signature": "keras.layers.convolutional.UpSampling2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.resize_images(inputs, self.size[0], self.size[1],\n                               self.data_format)",
        "begin_line": 1804,
        "end_line": 1806,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling2D.get_config#1808",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling2D",
        "signature": "keras.layers.convolutional.UpSampling2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'size': self.size,\n                  'data_format': self.data_format}\n        base_config = super(UpSampling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1808,
        "end_line": 1812,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling3D.__init__#1851",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling3D",
        "signature": "keras.layers.convolutional.UpSampling3D.__init__(self, size=(2, 2, 2), data_format=None, **kwargs)",
        "snippet": "    def __init__(self, size=(2, 2, 2), data_format=None, **kwargs):\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.size = conv_utils.normalize_tuple(size, 3, 'size')\n        self.input_spec = InputSpec(ndim=5)\n        super(UpSampling3D, self).__init__(**kwargs)",
        "begin_line": 1851,
        "end_line": 1855,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling3D.compute_output_shape#1857",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling3D",
        "signature": "keras.layers.convolutional.UpSampling3D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            dim1 = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n            dim2 = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n            dim3 = self.size[2] * input_shape[4] if input_shape[4] is not None else None\n            return (input_shape[0],\n                    input_shape[1],\n                    dim1,\n                    dim2,\n                    dim3)\n        elif self.data_format == 'channels_last':\n            dim1 = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n            dim2 = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n            dim3 = self.size[2] * input_shape[3] if input_shape[3] is not None else None\n            return (input_shape[0],\n                    dim1,\n                    dim2,\n                    dim3,\n                    input_shape[4])",
        "begin_line": 1857,
        "end_line": 1875,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling3D.call#1877",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling3D",
        "signature": "keras.layers.convolutional.UpSampling3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.resize_volumes(inputs,\n                                self.size[0], self.size[1], self.size[2],\n                                self.data_format)",
        "begin_line": 1877,
        "end_line": 1880,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling3D.get_config#1882",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling3D",
        "signature": "keras.layers.convolutional.UpSampling3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'size': self.size,\n                  'data_format': self.data_format}\n        base_config = super(UpSampling3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1882,
        "end_line": 1886,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding1D.__init__#1908",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding1D",
        "signature": "keras.layers.convolutional.ZeroPadding1D.__init__(self, padding=1, **kwargs)",
        "snippet": "    def __init__(self, padding=1, **kwargs):\n        super(ZeroPadding1D, self).__init__(**kwargs)\n        self.padding = conv_utils.normalize_tuple(padding, 2, 'padding')\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 1908,
        "end_line": 1911,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding1D.compute_output_shape#1913",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding1D",
        "signature": "keras.layers.convolutional.ZeroPadding1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if input_shape[1] is not None:\n            length = input_shape[1] + self.padding[0] + self.padding[1]\n        else:\n            length = None\n        return (input_shape[0],\n                length,\n                input_shape[2])",
        "begin_line": 1913,
        "end_line": 1920,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding1D.call#1922",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding1D",
        "signature": "keras.layers.convolutional.ZeroPadding1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.temporal_padding(inputs, padding=self.padding)",
        "begin_line": 1922,
        "end_line": 1923,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding1D.get_config#1925",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding1D",
        "signature": "keras.layers.convolutional.ZeroPadding1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'padding': self.padding}\n        base_config = super(ZeroPadding1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1925,
        "end_line": 1928,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding2D.__init__#1975",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding2D",
        "signature": "keras.layers.convolutional.ZeroPadding2D.__init__(self, padding=(1, 1), data_format=None, **kwargs)",
        "snippet": "    def __init__(self,\n                 padding=(1, 1),\n                 data_format=None,\n                 **kwargs):\n        super(ZeroPadding2D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        if isinstance(padding, int):\n            self.padding = ((padding, padding), (padding, padding))\n        elif hasattr(padding, '__len__'):\n            if len(padding) != 2:\n                raise ValueError('`padding` should have two elements. '\n                                 'Found: ' + str(padding))\n            height_padding = conv_utils.normalize_tuple(padding[0], 2,\n                                                        '1st entry of padding')\n            width_padding = conv_utils.normalize_tuple(padding[1], 2,\n                                                       '2nd entry of padding')\n            self.padding = (height_padding, width_padding)\n        else:\n            raise ValueError('`padding` should be either an int, '\n                             'a tuple of 2 ints '\n                             '(symmetric_height_pad, symmetric_width_pad), '\n                             'or a tuple of 2 tuples of 2 ints '\n                             '((top_pad, bottom_pad), (left_pad, right_pad)). '\n                             'Found: ' + str(padding))\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 1975,
        "end_line": 1999,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding2D.compute_output_shape#2001",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding2D",
        "signature": "keras.layers.convolutional.ZeroPadding2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            if input_shape[2] is not None:\n                rows = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n            else:\n                rows = None\n            if input_shape[3] is not None:\n                cols = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n            else:\n                cols = None\n            return (input_shape[0],\n                    input_shape[1],\n                    rows,\n                    cols)\n        elif self.data_format == 'channels_last':\n            if input_shape[1] is not None:\n                rows = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n            else:\n                rows = None\n            if input_shape[2] is not None:\n                cols = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n            else:\n                cols = None\n            return (input_shape[0],\n                    rows,\n                    cols,\n                    input_shape[3])",
        "begin_line": 2001,
        "end_line": 2027,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding2D.call#2029",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding2D",
        "signature": "keras.layers.convolutional.ZeroPadding2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.spatial_2d_padding(inputs,\n                                    padding=self.padding,\n                                    data_format=self.data_format)",
        "begin_line": 2029,
        "end_line": 2032,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding2D.get_config#2034",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding2D",
        "signature": "keras.layers.convolutional.ZeroPadding2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'padding': self.padding,\n                  'data_format': self.data_format}\n        base_config = super(ZeroPadding2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 2034,
        "end_line": 2038,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding3D.__init__#2082",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding3D",
        "signature": "keras.layers.convolutional.ZeroPadding3D.__init__(self, padding=(1, 1, 1), data_format=None, **kwargs)",
        "snippet": "    def __init__(self, padding=(1, 1, 1), data_format=None, **kwargs):\n        super(ZeroPadding3D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        if isinstance(padding, int):\n            self.padding = ((padding, padding), (padding, padding), (padding, padding))\n        elif hasattr(padding, '__len__'):\n            if len(padding) != 3:\n                raise ValueError('`padding` should have 3 elements. '\n                                 'Found: ' + str(padding))\n            dim1_padding = conv_utils.normalize_tuple(padding[0], 2,\n                                                      '1st entry of padding')\n            dim2_padding = conv_utils.normalize_tuple(padding[1], 2,\n                                                      '2nd entry of padding')\n            dim3_padding = conv_utils.normalize_tuple(padding[2], 2,\n                                                      '3rd entry of padding')\n            self.padding = (dim1_padding, dim2_padding, dim3_padding)\n        else:\n            raise ValueError('`padding` should be either an int, '\n                             'a tuple of 3 ints '\n                             '(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad), '\n                             'or a tuple of 3 tuples of 2 ints '\n                             '((left_dim1_pad, right_dim1_pad),'\n                             ' (left_dim2_pad, right_dim2_pad),'\n                             ' (left_dim3_pad, right_dim2_pad)). '\n                             'Found: ' + str(padding))\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 2082,
        "end_line": 2107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding3D.compute_output_shape#2109",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding3D",
        "signature": "keras.layers.convolutional.ZeroPadding3D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            if input_shape[2] is not None:\n                dim1 = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n            else:\n                dim1 = None\n            if input_shape[3] is not None:\n                dim2 = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n            else:\n                dim2 = None\n            if input_shape[4] is not None:\n                dim3 = input_shape[4] + self.padding[2][0] + self.padding[2][1]\n            else:\n                dim3 = None\n            return (input_shape[0],\n                    input_shape[1],\n                    dim1,\n                    dim2,\n                    dim3)\n        elif self.data_format == 'channels_last':\n            if input_shape[1] is not None:\n                dim1 = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n            else:\n                dim1 = None\n            if input_shape[2] is not None:\n                dim2 = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n            else:\n                dim2 = None\n            if input_shape[3] is not None:\n                dim3 = input_shape[3] + self.padding[2][0] + self.padding[2][1]\n            else:\n                dim3 = None\n            return (input_shape[0],\n                    dim1,\n                    dim2,\n                    dim3,\n                    input_shape[4])",
        "begin_line": 2109,
        "end_line": 2145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding3D.call#2147",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding3D",
        "signature": "keras.layers.convolutional.ZeroPadding3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.spatial_3d_padding(inputs,\n                                    padding=self.padding,\n                                    data_format=self.data_format)",
        "begin_line": 2147,
        "end_line": 2150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding3D.get_config#2152",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding3D",
        "signature": "keras.layers.convolutional.ZeroPadding3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'padding': self.padding,\n                  'data_format': self.data_format}\n        base_config = super(ZeroPadding3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 2152,
        "end_line": 2156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping1D.__init__#2178",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping1D",
        "signature": "keras.layers.convolutional.Cropping1D.__init__(self, cropping=(1, 1), **kwargs)",
        "snippet": "    def __init__(self, cropping=(1, 1), **kwargs):\n        super(Cropping1D, self).__init__(**kwargs)\n        self.cropping = conv_utils.normalize_tuple(cropping, 2, 'cropping')\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 2178,
        "end_line": 2181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping1D.compute_output_shape#2183",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping1D",
        "signature": "keras.layers.convolutional.Cropping1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if input_shape[1] is not None:\n            length = input_shape[1] - self.cropping[0] - self.cropping[1]\n        else:\n            length = None\n        return (input_shape[0],\n                length,\n                input_shape[2])",
        "begin_line": 2183,
        "end_line": 2190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping1D.call#2192",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping1D",
        "signature": "keras.layers.convolutional.Cropping1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.cropping[1] == 0:\n            return inputs[:, self.cropping[0]:, :]\n        else:\n            return inputs[:, self.cropping[0]: -self.cropping[1], :]",
        "begin_line": 2192,
        "end_line": 2196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping1D.get_config#2198",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping1D",
        "signature": "keras.layers.convolutional.Cropping1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'cropping': self.cropping}\n        base_config = super(Cropping1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 2198,
        "end_line": 2201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping2D.__init__#2260",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping2D",
        "signature": "keras.layers.convolutional.Cropping2D.__init__(self, cropping=((0, 0), (0, 0)), data_format=None, **kwargs)",
        "snippet": "    def __init__(self, cropping=((0, 0), (0, 0)),\n                 data_format=None, **kwargs):\n        super(Cropping2D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        if isinstance(cropping, int):\n            self.cropping = ((cropping, cropping), (cropping, cropping))\n        elif hasattr(cropping, '__len__'):\n            if len(cropping) != 2:\n                raise ValueError('`cropping` should have two elements. '\n                                 'Found: ' + str(cropping))\n            height_cropping = conv_utils.normalize_tuple(\n                cropping[0], 2,\n                '1st entry of cropping')\n            width_cropping = conv_utils.normalize_tuple(\n                cropping[1], 2,\n                '2nd entry of cropping')\n            self.cropping = (height_cropping, width_cropping)\n        else:\n            raise ValueError('`cropping` should be either an int, '\n                             'a tuple of 2 ints '\n                             '(symmetric_height_crop, symmetric_width_crop), '\n                             'or a tuple of 2 tuples of 2 ints '\n                             '((top_crop, bottom_crop), (left_crop, right_crop)). '\n                             'Found: ' + str(cropping))\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 2260,
        "end_line": 2284,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping2D.compute_output_shape#2286",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping2D",
        "signature": "keras.layers.convolutional.Cropping2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            return (input_shape[0],\n                    input_shape[1],\n                    input_shape[2] - self.cropping[0][0] - self.cropping[0][1] if input_shape[2] else None,\n                    input_shape[3] - self.cropping[1][0] - self.cropping[1][1] if input_shape[3] else None)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0],\n                    input_shape[1] - self.cropping[0][0] - self.cropping[0][1] if input_shape[1] else None,\n                    input_shape[2] - self.cropping[1][0] - self.cropping[1][1] if input_shape[2] else None,\n                    input_shape[3])",
        "begin_line": 2286,
        "end_line": 2296,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping2D.call#2298",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping2D",
        "signature": "keras.layers.convolutional.Cropping2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_first':\n            if self.cropping[0][1] == self.cropping[1][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:]\n            elif self.cropping[0][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]: -self.cropping[1][1]]\n            elif self.cropping[1][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:]\n            return inputs[:,\n                          :,\n                          self.cropping[0][0]: -self.cropping[0][1],\n                          self.cropping[1][0]: -self.cropping[1][1]]\n        elif self.data_format == 'channels_last':\n            if self.cropping[0][1] == self.cropping[1][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:,\n                              :]\n            elif self.cropping[0][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              :]\n            elif self.cropping[1][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:,\n                              :]\n            return inputs[:,\n                          self.cropping[0][0]: -self.cropping[0][1],\n                          self.cropping[1][0]: -self.cropping[1][1],\n                          :]",
        "begin_line": 2298,
        "end_line": 2338,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping2D.get_config#2340",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping2D",
        "signature": "keras.layers.convolutional.Cropping2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'cropping': self.cropping,\n                  'data_format': self.data_format}\n        base_config = super(Cropping2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 2340,
        "end_line": 2344,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping3D.__init__#2388",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping3D",
        "signature": "keras.layers.convolutional.Cropping3D.__init__(self, cropping=((1, 1), (1, 1), (1, 1)), data_format=None, **kwargs)",
        "snippet": "    def __init__(self, cropping=((1, 1), (1, 1), (1, 1)),\n                 data_format=None, **kwargs):\n        super(Cropping3D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        if isinstance(cropping, int):\n            self.cropping = ((cropping, cropping),\n                             (cropping, cropping),\n                             (cropping, cropping))\n        elif hasattr(cropping, '__len__'):\n            if len(cropping) != 3:\n                raise ValueError('`cropping` should have 3 elements. '\n                                 'Found: ' + str(cropping))\n            dim1_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n                                                       '1st entry of cropping')\n            dim2_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n                                                       '2nd entry of cropping')\n            dim3_cropping = conv_utils.normalize_tuple(cropping[2], 2,\n                                                       '3rd entry of cropping')\n            self.cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n        else:\n            raise ValueError('`cropping` should be either an int, '\n                             'a tuple of 3 ints '\n                             '(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop), '\n                             'or a tuple of 3 tuples of 2 ints '\n                             '((left_dim1_crop, right_dim1_crop),'\n                             ' (left_dim2_crop, right_dim2_crop),'\n                             ' (left_dim3_crop, right_dim2_crop)). '\n                             'Found: ' + str(cropping))\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 2388,
        "end_line": 2416,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping3D.compute_output_shape#2418",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping3D",
        "signature": "keras.layers.convolutional.Cropping3D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            if input_shape[2] is not None:\n                dim1 = input_shape[2] - self.cropping[0][0] - self.cropping[0][1]\n            else:\n                dim1 = None\n            if input_shape[3] is not None:\n                dim2 = input_shape[3] - self.cropping[1][0] - self.cropping[1][1]\n            else:\n                dim2 = None\n            if input_shape[4] is not None:\n                dim3 = input_shape[4] - self.cropping[2][0] - self.cropping[2][1]\n            else:\n                dim3 = None\n            return (input_shape[0],\n                    input_shape[1],\n                    dim1,\n                    dim2,\n                    dim3)\n        elif self.data_format == 'channels_last':\n            if input_shape[1] is not None:\n                dim1 = input_shape[1] - self.cropping[0][0] - self.cropping[0][1]\n            else:\n                dim1 = None\n            if input_shape[2] is not None:\n                dim2 = input_shape[2] - self.cropping[1][0] - self.cropping[1][1]\n            else:\n                dim2 = None\n            if input_shape[3] is not None:\n                dim3 = input_shape[3] - self.cropping[2][0] - self.cropping[2][1]\n            else:\n                dim3 = None\n            return (input_shape[0],\n                    dim1,\n                    dim2,\n                    dim3,\n                    input_shape[4])",
        "begin_line": 2418,
        "end_line": 2454,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping3D.call#2456",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping3D",
        "signature": "keras.layers.convolutional.Cropping3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_first':\n            if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]:]\n            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]: -self.cropping[2][1]]\n            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]:]\n            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              self.cropping[2][0]:]\n            elif self.cropping[0][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              self.cropping[2][0]: -self.cropping[2][1]]\n            elif self.cropping[1][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]: -self.cropping[2][1]]\n            elif self.cropping[2][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              self.cropping[2][0]:]\n            return inputs[:,\n                          :,\n                          self.cropping[0][0]: -self.cropping[0][1],\n                          self.cropping[1][0]: -self.cropping[1][1],\n                          self.cropping[2][0]: -self.cropping[2][1]]\n\n        elif self.data_format == 'channels_last':\n            if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]:,\n                              :]\n            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]: -self.cropping[2][1],\n                              :]\n            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]:,\n                              :]\n            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:-self.cropping[1][1],\n                              self.cropping[2][0]:,\n                              :]\n            elif self.cropping[0][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              self.cropping[2][0]: -self.cropping[2][1],\n                              :]\n            elif self.cropping[1][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]: -self.cropping[2][1],\n                              :]\n            elif self.cropping[2][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              self.cropping[2][0]:,\n                              :]\n            return inputs[:,\n                          self.cropping[0][0]: -self.cropping[0][1],\n                          self.cropping[1][0]: -self.cropping[1][1],\n                          self.cropping[2][0]: -self.cropping[2][1],\n                          :]",
        "begin_line": 2456,
        "end_line": 2553,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping3D.get_config#2555",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping3D",
        "signature": "keras.layers.convolutional.Cropping3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'cropping': self.cropping,\n                  'data_format': self.data_format}\n        base_config = super(Cropping3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 2555,
        "end_line": 2559,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.BaseWrapper.__init__#58",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.BaseWrapper",
        "signature": "keras.wrappers.scikit_learn.BaseWrapper.__init__(self, build_fn=None, **sk_params)",
        "snippet": "    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n        self.check_params(sk_params)",
        "begin_line": 58,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.BaseWrapper.check_params#63",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.BaseWrapper",
        "signature": "keras.wrappers.scikit_learn.BaseWrapper.check_params(self, params)",
        "snippet": "    def check_params(self, params):\n        \"\"\"Checks for user typos in `params`.\n\n        # Arguments\n            params: dictionary; the parameters to be checked\n\n        # Raises\n            ValueError: if any member of `params` is not a valid argument.\n        \"\"\"\n        legal_params_fns = [Sequential.fit, Sequential.predict,\n                            Sequential.predict_classes, Sequential.evaluate]\n        if self.build_fn is None:\n            legal_params_fns.append(self.__call__)\n        elif (not isinstance(self.build_fn, types.FunctionType) and\n              not isinstance(self.build_fn, types.MethodType)):\n            legal_params_fns.append(self.build_fn.__call__)\n        else:\n            legal_params_fns.append(self.build_fn)\n\n        for params_name in params:\n            for fn in legal_params_fns:\n                if has_arg(fn, params_name):\n                    break\n            else:\n                if params_name != 'nb_epoch':\n                    raise ValueError(\n                        '{} is not a legal parameter'.format(params_name))",
        "begin_line": 63,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.BaseWrapper.fit#117",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.BaseWrapper",
        "signature": "keras.wrappers.scikit_learn.BaseWrapper.fit(self, x, y, **kwargs)",
        "snippet": "    def fit(self, x, y, **kwargs):\n        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n\n        # Arguments\n            x : array-like, shape `(n_samples, n_features)`\n                Training samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for `x`.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        \"\"\"\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif (not isinstance(self.build_fn, types.FunctionType) and\n              not isinstance(self.build_fn, types.MethodType)):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(x, y, **fit_args)\n\n        return history",
        "begin_line": 117,
        "end_line": 153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.BaseWrapper.filter_sk_params#155",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.BaseWrapper",
        "signature": "keras.wrappers.scikit_learn.BaseWrapper.filter_sk_params(self, fn, override=None)",
        "snippet": "    def filter_sk_params(self, fn, override=None):\n        \"\"\"Filters `sk_params` and returns those in `fn`'s arguments.\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to override `sk_params`\n\n        # Returns\n            res : dictionary containing variables\n                in both `sk_params` and `fn`'s arguments.\n        \"\"\"\n        override = override or {}\n        res = {}\n        for name, value in self.sk_params.items():\n            if has_arg(fn, name):\n                res.update({name: value})\n        res.update(override)\n        return res",
        "begin_line": 155,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasClassifier.fit#179",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasClassifier",
        "signature": "keras.wrappers.scikit_learn.KerasClassifier.fit(self, x, y, sample_weight=None, **kwargs)",
        "snippet": "    def fit(self, x, y, sample_weight=None, **kwargs):\n        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n\n        # Arguments\n            x : array-like, shape `(n_samples, n_features)`\n                Training samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for `x`.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n\n        # Raises\n            ValueError: In case of invalid shape for `y` argument.\n        \"\"\"\n        y = np.array(y)\n        if len(y.shape) == 2 and y.shape[1] > 1:\n            self.classes_ = np.arange(y.shape[1])\n        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n            self.classes_ = np.unique(y)\n            y = np.searchsorted(self.classes_, y)\n        else:\n            raise ValueError('Invalid shape for y: ' + str(y.shape))\n        self.n_classes_ = len(self.classes_)\n        if sample_weight is not None:\n            kwargs['sample_weight'] = sample_weight\n        return super(KerasClassifier, self).fit(x, y, **kwargs)",
        "begin_line": 179,
        "end_line": 209,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasClassifier.predict#211",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasClassifier",
        "signature": "keras.wrappers.scikit_learn.KerasClassifier.predict(self, x, **kwargs)",
        "snippet": "    def predict(self, x, **kwargs):\n        \"\"\"Returns the class predictions for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments\n                of `Sequential.predict_classes`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Class predictions.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n\n        proba = self.model.predict(x, **kwargs)\n        if proba.shape[-1] > 1:\n            classes = proba.argmax(axis=-1)\n        else:\n            classes = (proba > 0.5).astype('int32')\n        return self.classes_[classes]",
        "begin_line": 211,
        "end_line": 233,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasClassifier.predict_proba#235",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasClassifier",
        "signature": "keras.wrappers.scikit_learn.KerasClassifier.predict_proba(self, x, **kwargs)",
        "snippet": "    def predict_proba(self, x, **kwargs):\n        \"\"\"Returns class probability estimates for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments\n                of `Sequential.predict_classes`.\n\n        # Returns\n            proba: array-like, shape `(n_samples, n_outputs)`\n                Class probability estimates.\n                In the case of binary classification,\n                to match the scikit-learn API,\n                will return an array of shape `(n_samples, 2)`\n                (instead of `(n_sample, 1)` as in Keras).\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        probs = self.model.predict(x, **kwargs)\n\n        # check if binary classification\n        if probs.shape[1] == 1:\n            # first column is probability of class 0 and second is of class 1\n            probs = np.hstack([1 - probs, probs])\n        return probs",
        "begin_line": 235,
        "end_line": 261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasClassifier.score#263",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasClassifier",
        "signature": "keras.wrappers.scikit_learn.KerasClassifier.score(self, x, y, **kwargs)",
        "snippet": "    def score(self, x, y, **kwargs):\n        \"\"\"Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for `x`.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on `x` wrt. `y`.\n\n        # Raises\n            ValueError: If the underlying model isn't configured to\n                compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n                the `.compile()` method of the model.\n        \"\"\"\n        y = np.searchsorted(self.classes_, y)\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        outputs = self.model.evaluate(x, y, **kwargs)\n        if not isinstance(outputs, list):\n            outputs = [outputs]\n        for name, output in zip(self.model.metrics_names, outputs):\n            if name == 'acc':\n                return output\n        raise ValueError('The model is not configured to compute accuracy. '\n                         'You should pass `metrics=[\"accuracy\"]` to '\n                         'the `model.compile()` method.')",
        "begin_line": 263,
        "end_line": 301,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasRegressor.predict#308",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasRegressor",
        "signature": "keras.wrappers.scikit_learn.KerasRegressor.predict(self, x, **kwargs)",
        "snippet": "    def predict(self, x, **kwargs):\n        \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return np.squeeze(self.model.predict(x, **kwargs))",
        "begin_line": 308,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasRegressor.score#325",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasRegressor",
        "signature": "keras.wrappers.scikit_learn.KerasRegressor.score(self, x, y, **kwargs)",
        "snippet": "    def score(self, x, y, **kwargs):\n        \"\"\"Returns the mean loss on the given test data and labels.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where `n_samples` is the number of samples\n                and `n_features` is the number of features.\n            y: array-like, shape `(n_samples,)`\n                True labels for `x`.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on `x` wrt. `y`.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        loss = self.model.evaluate(x, y, **kwargs)\n        if isinstance(loss, list):\n            return -loss[0]\n        return -loss",
        "begin_line": 325,
        "end_line": 345,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.Constraint.__call__#15",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.Constraint",
        "signature": "keras.constraints.Constraint.__call__(self, w)",
        "snippet": "    def __call__(self, w):\n        return w",
        "begin_line": 15,
        "end_line": 16,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.Constraint.get_config#18",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.Constraint",
        "signature": "keras.constraints.Constraint.get_config(self)",
        "snippet": "    def get_config(self):\n        return {}",
        "begin_line": 18,
        "end_line": 19,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.MaxNorm.__init__#46",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MaxNorm",
        "signature": "keras.constraints.MaxNorm.__init__(self, max_value=2, axis=0)",
        "snippet": "    def __init__(self, max_value=2, axis=0):\n        self.max_value = max_value\n        self.axis = axis",
        "begin_line": 46,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.931472081218273e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.MaxNorm.__call__#50",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MaxNorm",
        "signature": "keras.constraints.MaxNorm.__call__(self, w)",
        "snippet": "    def __call__(self, w):\n        norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))\n        desired = K.clip(norms, 0, self.max_value)\n        w *= (desired / (K.epsilon() + norms))\n        return w",
        "begin_line": 50,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.MaxNorm.get_config#56",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MaxNorm",
        "signature": "keras.constraints.MaxNorm.get_config(self)",
        "snippet": "    def get_config(self):\n        return {'max_value': self.max_value,\n                'axis': self.axis}",
        "begin_line": 56,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.010894816951053e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.NonNeg.__call__#65",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.NonNeg",
        "signature": "keras.constraints.NonNeg.__call__(self, w)",
        "snippet": "    def __call__(self, w):\n        w *= K.cast(K.greater_equal(w, 0.), K.floatx())\n        return w",
        "begin_line": 65,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.UnitNorm.__init__#87",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.UnitNorm",
        "signature": "keras.constraints.UnitNorm.__init__(self, axis=0)",
        "snippet": "    def __init__(self, axis=0):\n        self.axis = axis",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.276090374906894e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.UnitNorm.__call__#90",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.UnitNorm",
        "signature": "keras.constraints.UnitNorm.__call__(self, w)",
        "snippet": "    def __call__(self, w):\n        return w / (K.epsilon() + K.sqrt(K.sum(K.square(w),\n                                               axis=self.axis,\n                                               keepdims=True)))",
        "begin_line": 90,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.UnitNorm.get_config#95",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.UnitNorm",
        "signature": "keras.constraints.UnitNorm.get_config(self)",
        "snippet": "    def get_config(self):\n        return {'axis': self.axis}",
        "begin_line": 95,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.350730688935282e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.MinMaxNorm.__init__#128",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MinMaxNorm",
        "signature": "keras.constraints.MinMaxNorm.__init__(self, min_value=0.0, max_value=1.0, rate=1.0, axis=0)",
        "snippet": "    def __init__(self, min_value=0.0, max_value=1.0, rate=1.0, axis=0):\n        self.min_value = min_value\n        self.max_value = max_value\n        self.rate = rate\n        self.axis = axis",
        "begin_line": 128,
        "end_line": 132,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.MinMaxNorm.__call__#134",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MinMaxNorm",
        "signature": "keras.constraints.MinMaxNorm.__call__(self, w)",
        "snippet": "    def __call__(self, w):\n        norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))\n        desired = (self.rate * K.clip(norms, self.min_value, self.max_value) +\n                   (1 - self.rate) * norms)\n        w *= (desired / (K.epsilon() + norms))\n        return w",
        "begin_line": 134,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.MinMaxNorm.get_config#141",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MinMaxNorm",
        "signature": "keras.constraints.MinMaxNorm.get_config(self)",
        "snippet": "    def get_config(self):\n        return {'min_value': self.min_value,\n                'max_value': self.max_value,\n                'rate': self.rate,\n                'axis': self.axis}",
        "begin_line": 141,
        "end_line": 145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.serialize#162",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints",
        "signature": "keras.constraints.serialize(constraint)",
        "snippet": "def serialize(constraint):\n    return serialize_keras_object(constraint)",
        "begin_line": 162,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.constraints.deserialize#166",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints",
        "signature": "keras.constraints.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='constraint')",
        "begin_line": 166,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.877737513786041e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.constraints.get#173",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints",
        "signature": "keras.constraints.get(identifier)",
        "snippet": "def get(identifier):\n    if identifier is None:\n        return None\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret constraint identifier: ' +\n                         str(identifier))",
        "begin_line": 173,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010504201680672268,
            "pseudo_dstar_susp": 0.004629629629629629,
            "pseudo_tarantula_susp": 0.000641025641025641,
            "pseudo_op2_susp": 0.004629629629629629,
            "pseudo_barinel_susp": 0.000641025641025641
        }
    },
    {
        "name": "keras.activations.softmax#14",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.softmax(x, axis=-1)",
        "snippet": "def softmax(x, axis=-1):\n    \"\"\"Softmax activation function.\n\n    # Arguments\n        x : Tensor.\n        axis: Integer, axis along which the softmax normalization is applied.\n\n    # Returns\n        Tensor, output of softmax transformation.\n\n    # Raises\n        ValueError: In case `dim(x) == 1`.\n    \"\"\"\n    ndim = K.ndim(x)\n    if ndim == 2:\n        return K.softmax(x)\n    elif ndim > 2:\n        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n        s = K.sum(e, axis=axis, keepdims=True)\n        return e / s\n    else:\n        raise ValueError('Cannot apply softmax to a tensor that is 1D')",
        "begin_line": 14,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004887585532746823,
            "pseudo_dstar_susp": 0.0004450378282153983,
            "pseudo_tarantula_susp": 0.0008038585209003215,
            "pseudo_op2_susp": 0.0004450378282153983,
            "pseudo_barinel_susp": 0.0008038585209003215
        }
    },
    {
        "name": "keras.activations.elu#38",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.elu(x, alpha=1.0)",
        "snippet": "def elu(x, alpha=1.0):\n    return K.elu(x, alpha)",
        "begin_line": 38,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.activations.selu#42",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.selu(x)",
        "snippet": "def selu(x):\n    \"\"\"Scaled Exponential Linear Unit. (Klambauer et al., 2017).\n\n    # Arguments\n        x: A tensor or variable to compute the activation function for.\n\n    # Returns\n        Tensor with the same shape and dtype as `x`.\n\n    # Note\n        - To be used together with the initialization \"lecun_normal\".\n        - To be used together with the dropout variant \"AlphaDropout\".\n\n    # References\n        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n    \"\"\"\n    alpha = 1.6732632423543772848170429916717\n    scale = 1.0507009873554804934193349852946\n    return scale * K.elu(x, alpha)",
        "begin_line": 42,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.activations.softplus#63",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.softplus(x)",
        "snippet": "def softplus(x):\n    return K.softplus(x)",
        "begin_line": 63,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.activations.softsign#67",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.softsign(x)",
        "snippet": "def softsign(x):\n    return K.softsign(x)",
        "begin_line": 67,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.activations.relu#71",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.relu(x, alpha=0.0, max_value=None)",
        "snippet": "def relu(x, alpha=0., max_value=None):\n    return K.relu(x, alpha=alpha, max_value=max_value)",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00043122035360068997,
            "pseudo_dstar_susp": 0.000423728813559322,
            "pseudo_tarantula_susp": 0.0007022471910112359,
            "pseudo_op2_susp": 0.000423728813559322,
            "pseudo_barinel_susp": 0.0007022471910112359
        }
    },
    {
        "name": "keras.activations.tanh#75",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.tanh(x)",
        "snippet": "def tanh(x):\n    return K.tanh(x)",
        "begin_line": 75,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.338910905621606e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.activations.sigmoid#79",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.sigmoid(x)",
        "snippet": "def sigmoid(x):\n    return K.sigmoid(x)",
        "begin_line": 79,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.activations.hard_sigmoid#83",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.hard_sigmoid(x)",
        "snippet": "def hard_sigmoid(x):\n    return K.hard_sigmoid(x)",
        "begin_line": 83,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.432181345224824e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.activations.linear#87",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.linear(x)",
        "snippet": "def linear(x):\n    return x",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013477088948787063,
            "pseudo_dstar_susp": 0.0018115942028985507,
            "pseudo_tarantula_susp": 0.0008873114463176575,
            "pseudo_op2_susp": 0.0018115942028985507,
            "pseudo_barinel_susp": 0.0008873114463176575
        }
    },
    {
        "name": "keras.activations.serialize#91",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.serialize(activation)",
        "snippet": "def serialize(activation):\n    return activation.__name__",
        "begin_line": 91,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003940110323089047,
            "pseudo_dstar_susp": 0.00039277297721916735,
            "pseudo_tarantula_susp": 0.00047961630695443646,
            "pseudo_op2_susp": 0.00039277297721916735,
            "pseudo_barinel_susp": 0.00047961630695443646
        }
    },
    {
        "name": "keras.activations.deserialize#95",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.deserialize(name, custom_objects=None)",
        "snippet": "def deserialize(name, custom_objects=None):\n    return deserialize_keras_object(name,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='activation function')",
        "begin_line": 95,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005159958720330237,
            "pseudo_dstar_susp": 0.001053740779768177,
            "pseudo_tarantula_susp": 0.0004222972972972973,
            "pseudo_op2_susp": 0.001053740779768177,
            "pseudo_barinel_susp": 0.0004222972972972973
        }
    },
    {
        "name": "keras.activations.get#102",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.get(identifier)",
        "snippet": "def get(identifier):\n    if identifier is None:\n        return linear\n    if isinstance(identifier, six.string_types):\n        identifier = str(identifier)\n        return deserialize(identifier)\n    elif callable(identifier):\n        if isinstance(identifier, Layer):\n            warnings.warn(\n                'Do not pass a layer instance (such as {identifier}) as the '\n                'activation argument of another layer. Instead, advanced '\n                'activation layers should be used just like any other '\n                'layer in a model.'.format(\n                    identifier=identifier.__class__.__name__))\n        return identifier\n    else:\n        raise ValueError('Could not interpret '\n                         'activation function identifier:', identifier)",
        "begin_line": 102,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0012453300124533001,
            "pseudo_dstar_susp": 0.005376344086021506,
            "pseudo_tarantula_susp": 0.0008818342151675485,
            "pseudo_op2_susp": 0.005376344086021506,
            "pseudo_barinel_susp": 0.0008818342151675485
        }
    },
    {
        "name": "keras.engine.topology.InputSpec.__init__#53",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.InputSpec",
        "signature": "keras.engine.topology.InputSpec.__init__(self, dtype=None, shape=None, ndim=None, max_ndim=None, min_ndim=None, axes=None)",
        "snippet": "    def __init__(self, dtype=None,\n                 shape=None,\n                 ndim=None,\n                 max_ndim=None,\n                 min_ndim=None,\n                 axes=None):\n        self.dtype = dtype\n        self.shape = shape\n        if shape is not None:\n            self.ndim = len(shape)\n        else:\n            self.ndim = ndim\n        self.max_ndim = max_ndim\n        self.min_ndim = min_ndim\n        self.axes = axes or {}",
        "begin_line": 53,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008326394671107411,
            "pseudo_dstar_susp": 0.002347417840375587,
            "pseudo_tarantula_susp": 0.0005555555555555556,
            "pseudo_op2_susp": 0.002347417840375587,
            "pseudo_barinel_susp": 0.0005561735261401557
        }
    },
    {
        "name": "keras.engine.topology.InputSpec.__repr__#69",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.InputSpec",
        "signature": "keras.engine.topology.InputSpec.__repr__(self)",
        "snippet": "    def __repr__(self):\n        spec = [('dtype=' + str(self.dtype)) if self.dtype else '',\n                ('shape=' + str(self.shape)) if self.shape else '',\n                ('ndim=' + str(self.ndim)) if self.ndim else '',\n                ('max_ndim=' + str(self.max_ndim)) if self.max_ndim else '',\n                ('min_ndim=' + str(self.min_ndim)) if self.min_ndim else '',\n                ('axes=' + str(self.axes)) if self.axes else '']\n        return 'InputSpec(%s)' % ', '.join(x for x in spec if x)",
        "begin_line": 69,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Node.__init__#124",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Node",
        "signature": "keras.engine.topology.Node.__init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, input_masks, output_masks, input_shapes, output_shapes, arguments=None)",
        "snippet": "    def __init__(self, outbound_layer,\n                 inbound_layers, node_indices, tensor_indices,\n                 input_tensors, output_tensors,\n                 input_masks, output_masks,\n                 input_shapes, output_shapes,\n                 arguments=None):\n        # Layer instance (NOT a list).\n        # this is the layer that takes a list of input tensors\n        # and turns them into a list of output tensors.\n        # the current node will be added to\n        # the inbound_nodes of outbound_layer.\n        self.outbound_layer = outbound_layer\n\n        # The following 3 properties describe where\n        # the input tensors come from: which layers,\n        # and for each layer, which node and which\n        # tensor output of each node.\n\n        # List of layer instances.\n        self.inbound_layers = inbound_layers\n        # List of integers, 1:1 mapping with inbound_layers.\n        self.node_indices = node_indices\n        # List of integers, 1:1 mapping with inbound_layers.\n        self.tensor_indices = tensor_indices\n\n        # Following 2 properties:\n        # tensor inputs and outputs of outbound_layer.\n\n        # List of tensors. 1:1 mapping with inbound_layers.\n        self.input_tensors = input_tensors\n        # List of tensors, created by outbound_layer.call().\n        self.output_tensors = output_tensors\n\n        # Following 2 properties: input and output masks.\n        # List of tensors, 1:1 mapping with input_tensor.\n        self.input_masks = input_masks\n        # List of tensors, created by outbound_layer.compute_mask().\n        self.output_masks = output_masks\n\n        # Following 2 properties: input and output shapes.\n\n        # List of shape tuples, shapes of input_tensors.\n        self.input_shapes = input_shapes\n        # List of shape tuples, shapes of output_tensors.\n        self.output_shapes = output_shapes\n\n        # Optional keyword arguments to layer's `call`.\n        self.arguments = arguments\n\n        # Add nodes to all layers involved.\n        for layer in inbound_layers:\n            if layer is not None:\n                layer._outbound_nodes.append(self)\n        outbound_layer._inbound_nodes.append(self)",
        "begin_line": 124,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009765625,
            "pseudo_dstar_susp": 0.003875968992248062,
            "pseudo_tarantula_susp": 0.0006203473945409429,
            "pseudo_op2_susp": 0.003875968992248062,
            "pseudo_barinel_susp": 0.0006203473945409429
        }
    },
    {
        "name": "keras.engine.topology.Node.get_config#179",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Node",
        "signature": "keras.engine.topology.Node.get_config(self)",
        "snippet": "    def get_config(self):\n        inbound_names = []\n        for layer in self.inbound_layers:\n            if layer:\n                inbound_names.append(layer.name)\n            else:\n                inbound_names.append(None)\n        return {'outbound_layer': self.outbound_layer.name if self.outbound_layer else None,\n                'inbound_layers': inbound_names,\n                'node_indices': self.node_indices,\n                'tensor_indices': self.tensor_indices}",
        "begin_line": 179,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.__init__#259",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        self.input_spec = None\n        self.supports_masking = False\n        self.stateful = False\n\n        # These properties will be set upon call of self.build()\n        self._trainable_weights = []\n        self._non_trainable_weights = []\n        self._losses = []\n        self._updates = []\n        self._per_input_losses = {}\n        self._per_input_updates = {}\n        self._built = False\n\n        # These lists will be filled via successive calls\n        # to self._add_inbound_node().\n        self._inbound_nodes = []\n        self._outbound_nodes = []\n\n        # These properties should be set by the user via keyword arguments.\n        # note that 'dtype', 'input_shape' and 'batch_input_shape'\n        # are only applicable to input layers: do not pass these keywords\n        # to non-input layers.\n        allowed_kwargs = {'input_shape',\n                          'batch_input_shape',\n                          'batch_size',\n                          'dtype',\n                          'name',\n                          'trainable',\n                          'weights',\n                          'input_dtype',  # legacy\n                          }\n        for kwarg in kwargs:\n            if kwarg not in allowed_kwargs:\n                raise TypeError('Keyword argument not understood:', kwarg)\n        name = kwargs.get('name')\n        if not name:\n            prefix = self.__class__.__name__\n            name = _to_snake_case(prefix) + '_' + str(K.get_uid(prefix))\n        self.name = name\n\n        self.trainable = kwargs.get('trainable', True)\n        if 'input_shape' in kwargs or 'batch_input_shape' in kwargs:\n            # In this case we will later create an input layer\n            # to insert before the current layer\n            if 'batch_input_shape' in kwargs:\n                batch_input_shape = tuple(kwargs['batch_input_shape'])\n            elif 'input_shape' in kwargs:\n                if 'batch_size' in kwargs:\n                    batch_size = kwargs['batch_size']\n                else:\n                    batch_size = None\n                batch_input_shape = (batch_size,) + tuple(kwargs['input_shape'])\n            self.batch_input_shape = batch_input_shape\n\n            # Set dtype.\n            dtype = kwargs.get('dtype')\n            if dtype is None:\n                dtype = kwargs.get('input_dtype')\n            if dtype is None:\n                dtype = K.floatx()\n            self.dtype = dtype\n\n        if 'weights' in kwargs:\n            self._initial_weights = kwargs['weights']\n        else:\n            self._initial_weights = None",
        "begin_line": 259,
        "end_line": 325,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013812154696132596,
            "pseudo_dstar_susp": 0.0021008403361344537,
            "pseudo_tarantula_susp": 0.0009066183136899365,
            "pseudo_op2_susp": 0.0021008403361344537,
            "pseudo_barinel_susp": 0.0009049773755656109
        }
    },
    {
        "name": "keras.engine.topology.Layer._node_key#328",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer._node_key(layer, node_index)",
        "snippet": "    def _node_key(layer, node_index):\n        \"\"\"Converts a layer and its index to a unique (immutable type) name.\n\n        This function is used internally with `self._container_nodes`.\n\n        # Arguments\n            layer: The layer.\n            node_index: The layer's position (e.g. via enumerate) in a list of\n                nodes.\n\n        # Returns\n            The unique name.\n        \"\"\"\n        return layer.name + '_ib-' + str(node_index)",
        "begin_line": 328,
        "end_line": 341,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005966587112171838,
            "pseudo_dstar_susp": 0.001358695652173913,
            "pseudo_tarantula_susp": 0.0004572473708276177,
            "pseudo_op2_susp": 0.001358695652173913,
            "pseudo_barinel_susp": 0.0004572473708276177
        }
    },
    {
        "name": "keras.engine.topology.Layer.losses#344",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.losses(self)",
        "snippet": "    def losses(self):\n        return self._losses",
        "begin_line": 344,
        "end_line": 345,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004520795660036166,
            "pseudo_dstar_susp": 0.0008787346221441124,
            "pseudo_tarantula_susp": 0.0003819709702062643,
            "pseudo_op2_susp": 0.0008787346221441124,
            "pseudo_barinel_susp": 0.0003819709702062643
        }
    },
    {
        "name": "keras.engine.topology.Layer.updates#348",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.updates(self)",
        "snippet": "    def updates(self):\n        if not self.trainable and not self.stateful:\n            return []\n        return self._updates",
        "begin_line": 348,
        "end_line": 351,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003598416696653472,
            "pseudo_dstar_susp": 0.0003598416696653472,
            "pseudo_tarantula_susp": 0.00036088054853843375,
            "pseudo_op2_susp": 0.0003598416696653472,
            "pseudo_barinel_susp": 0.00036088054853843375
        }
    },
    {
        "name": "keras.engine.topology.Layer.built#354",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.built(self)",
        "snippet": "    def built(self):\n        return self._built",
        "begin_line": 354,
        "end_line": 355,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009337068160597573,
            "pseudo_dstar_susp": 0.003278688524590164,
            "pseudo_tarantula_susp": 0.0006024096385542169,
            "pseudo_op2_susp": 0.003278688524590164,
            "pseudo_barinel_susp": 0.0006024096385542169
        }
    },
    {
        "name": "keras.engine.topology.Layer.built#358",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.built(self, value)",
        "snippet": "    def built(self, value):\n        self._built = value",
        "begin_line": 358,
        "end_line": 359,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008375209380234506,
            "pseudo_dstar_susp": 0.002386634844868735,
            "pseudo_tarantula_susp": 0.0005589714924538849,
            "pseudo_op2_susp": 0.002386634844868735,
            "pseudo_barinel_susp": 0.0005589714924538849
        }
    },
    {
        "name": "keras.engine.topology.Layer.trainable_weights#362",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        trainable = getattr(self, 'trainable', True)\n        if trainable:\n            return self._trainable_weights\n        else:\n            return []",
        "begin_line": 362,
        "end_line": 367,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006472491909385113,
            "pseudo_dstar_susp": 0.0015527950310559005,
            "pseudo_tarantula_susp": 0.0005422993492407809,
            "pseudo_op2_susp": 0.0015527950310559005,
            "pseudo_barinel_susp": 0.0005422993492407809
        }
    },
    {
        "name": "keras.engine.topology.Layer.non_trainable_weights#374",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        trainable = getattr(self, 'trainable', True)\n        if not trainable:\n            return self._trainable_weights + self._non_trainable_weights\n        else:\n            return self._non_trainable_weights",
        "begin_line": 374,
        "end_line": 379,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003933910306845004,
            "pseudo_dstar_susp": 0.000392156862745098,
            "pseudo_tarantula_susp": 0.0004757373929590866,
            "pseudo_op2_susp": 0.000392156862745098,
            "pseudo_barinel_susp": 0.0004757373929590866
        }
    },
    {
        "name": "keras.engine.topology.Layer.add_weight#386",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)",
        "snippet": "    def add_weight(self,\n                   name,\n                   shape,\n                   dtype=None,\n                   initializer=None,\n                   regularizer=None,\n                   trainable=True,\n                   constraint=None):\n        \"\"\"Adds a weight variable to the layer.\n\n        # Arguments\n            name: String, the name for the weight variable.\n            shape: The shape tuple of the weight.\n            dtype: The dtype of the weight.\n            initializer: An Initializer instance (callable).\n            regularizer: An optional Regularizer instance.\n            trainable: A boolean, whether the weight should\n                be trained via backprop or not (assuming\n                that the layer itself is also trainable).\n            constraint: An optional Constraint instance.\n\n        # Returns\n            The created weight variable.\n        \"\"\"\n        initializer = initializers.get(initializer)\n        if dtype is None:\n            dtype = K.floatx()\n        weight = K.variable(initializer(shape),\n                            dtype=dtype,\n                            name=name,\n                            constraint=constraint)\n        if regularizer is not None:\n            self.add_loss(regularizer(weight))\n        if trainable:\n            self._trainable_weights.append(weight)\n        else:\n            self._non_trainable_weights.append(weight)\n        return weight",
        "begin_line": 386,
        "end_line": 423,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011976047904191617,
            "pseudo_dstar_susp": 0.00558659217877095,
            "pseudo_tarantula_susp": 0.0006706908115358819,
            "pseudo_op2_susp": 0.00558659217877095,
            "pseudo_barinel_susp": 0.0006706908115358819
        }
    },
    {
        "name": "keras.engine.topology.Layer.assert_input_compatibility#425",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.assert_input_compatibility(self, inputs)",
        "snippet": "    def assert_input_compatibility(self, inputs):\n        \"\"\"Checks compatibility between the layer and provided inputs.\n\n        This checks that the tensor(s) `input`\n        verify the input assumptions of the layer\n        (if any). If not, exceptions are raised.\n\n        # Arguments\n            inputs: input tensor or list of input tensors.\n\n        # Raises\n            ValueError: in case of mismatch between\n                the provided inputs and the expectations of the layer.\n        \"\"\"\n        inputs = _to_list(inputs)\n        for x in inputs:\n            try:\n                K.is_keras_tensor(x)\n            except ValueError:\n                raise ValueError('Layer ' + self.name + ' was called with '\n                                 'an input that isn\\'t a symbolic tensor. '\n                                 'Received type: ' +\n                                 str(type(x)) + '. Full input: ' +\n                                 str(inputs) + '. All inputs to the layer '\n                                 'should be tensors.')\n\n        if not self.input_spec:\n            return\n        if not isinstance(self.input_spec, (list, tuple)):\n            input_spec = _to_list(self.input_spec)\n        else:\n            input_spec = self.input_spec\n        if len(inputs) != len(input_spec):\n            raise ValueError('Layer ' + self.name + ' expects ' +\n                             str(len(input_spec)) + ' inputs, '\n                             'but it received ' + str(len(inputs)) +\n                             ' input tensors. Input received: ' +\n                             str(inputs))\n        for input_index, (x, spec) in enumerate(zip(inputs, input_spec)):\n            if spec is None:\n                continue\n\n            # Check ndim.\n            if spec.ndim is not None:\n                if K.ndim(x) != spec.ndim:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected ndim=' +\n                                     str(spec.ndim) + ', found ndim=' +\n                                     str(K.ndim(x)))\n            if spec.max_ndim is not None:\n                ndim = K.ndim(x)\n                if ndim is not None and ndim > spec.max_ndim:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected max_ndim=' +\n                                     str(spec.max_ndim) + ', found ndim=' +\n                                     str(K.ndim(x)))\n            if spec.min_ndim is not None:\n                ndim = K.ndim(x)\n                if ndim is not None and ndim < spec.min_ndim:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected min_ndim=' +\n                                     str(spec.min_ndim) + ', found ndim=' +\n                                     str(K.ndim(x)))\n            # Check dtype.\n            if spec.dtype is not None:\n                if K.dtype(x) != spec.dtype:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected dtype=' +\n                                     str(spec.dtype) + ', found dtype=' +\n                                     str(K.dtype(x)))\n            # Check specific shape axes.\n            if spec.axes:\n                try:\n                    x_shape = K.int_shape(x)\n                except TypeError:\n                    x_shape = None\n                if x_shape is not None:\n                    for axis, value in spec.axes.items():\n                        if value is not None and x_shape[int(axis)] not in {value, None}:\n                            raise ValueError('Input ' + str(input_index) +\n                                             ' is incompatible with layer ' +\n                                             self.name + ': expected axis ' +\n                                             str(axis) + ' of input shape to have '\n                                             'value ' + str(value) +\n                                             ' but got shape ' + str(x_shape))\n            # Check shape.\n            if spec.shape is not None:\n                try:\n                    x_shape = K.int_shape(x)\n                except TypeError:\n                    x_shape = None\n                if x_shape is not None:\n                    for spec_dim, dim in zip(spec.shape, x_shape):\n                        if spec_dim is not None and dim is not None:\n                            if spec_dim != dim:\n                                raise ValueError(\n                                    'Input ' + str(input_index) +\n                                    ' is incompatible with layer ' +\n                                    self.name + ': expected shape=' +\n                                    str(spec.shape) + ', found shape=' +\n                                    str(x_shape))",
        "begin_line": 425,
        "end_line": 529,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006329113924050633,
            "pseudo_dstar_susp": 0.011764705882352941,
            "pseudo_tarantula_susp": 0.006666666666666667,
            "pseudo_op2_susp": 0.011764705882352941,
            "pseudo_barinel_susp": 0.006666666666666667
        }
    },
    {
        "name": "keras.engine.topology.Layer.call#531",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.call(self, inputs, **kwargs)",
        "snippet": "    def call(self, inputs, **kwargs):\n        \"\"\"This is where the layer's logic lives.\n\n        # Arguments\n            inputs: Input tensor, or list/tuple of input tensors.\n            **kwargs: Additional keyword arguments.\n\n        # Returns\n            A tensor or list/tuple of tensors.\n        \"\"\"\n        return inputs",
        "begin_line": 531,
        "end_line": 541,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000992063492063492,
            "pseudo_dstar_susp": 0.0005296610169491525,
            "pseudo_tarantula_susp": 0.0013513513513513514,
            "pseudo_op2_susp": 0.0005296610169491525,
            "pseudo_barinel_susp": 0.0013513513513513514
        }
    },
    {
        "name": "keras.engine.topology.Layer.__call__#543",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.__call__(self, inputs, **kwargs)",
        "snippet": "    def __call__(self, inputs, **kwargs):\n        \"\"\"Wrapper around self.call(), for handling internal references.\n\n        If a Keras tensor is passed:\n            - We call self._add_inbound_node().\n            - If necessary, we `build` the layer to match\n                the _keras_shape of the input(s).\n            - We update the _keras_shape of every input tensor with\n                its new shape (obtained via self.compute_output_shape).\n                This is done as part of _add_inbound_node().\n            - We update the _keras_history of the output tensor(s)\n                with the current layer.\n                This is done as part of _add_inbound_node().\n\n        # Arguments\n            inputs: Can be a tensor or list/tuple of tensors.\n            **kwargs: Additional keyword arguments to be passed to `call()`.\n\n        # Returns\n            Output of the layer's `call` method.\n\n        # Raises\n            ValueError: in case the layer is missing shape information\n                for its `build` call.\n        \"\"\"\n        if isinstance(inputs, list):\n            inputs = inputs[:]\n        with K.name_scope(self.name):\n            # Handle laying building (weight creating, input spec locking).\n            if not self.built:\n                # Raise exceptions in case the input is not compatible\n                # with the input_spec specified in the layer constructor.\n                self.assert_input_compatibility(inputs)\n\n                # Collect input shapes to build layer.\n                input_shapes = []\n                for x_elem in _to_list(inputs):\n                    if hasattr(x_elem, '_keras_shape'):\n                        input_shapes.append(x_elem._keras_shape)\n                    elif hasattr(K, 'int_shape'):\n                        input_shapes.append(K.int_shape(x_elem))\n                    else:\n                        raise ValueError('You tried to call layer \"' + self.name +\n                                         '\". This layer has no information'\n                                         ' about its expected input shape, '\n                                         'and thus cannot be built. '\n                                         'You can build it manually via: '\n                                         '`layer.build(batch_input_shape)`')\n                if len(input_shapes) == 1:\n                    self.build(input_shapes[0])\n                else:\n                    self.build(input_shapes)\n                self.built = True\n\n                # Load weights that were specified at layer instantiation.\n                if self._initial_weights is not None:\n                    self.set_weights(self._initial_weights)\n\n            # Raise exceptions in case the input is not compatible\n            # with the input_spec set at build time.\n            self.assert_input_compatibility(inputs)\n\n            # Handle mask propagation.\n            previous_mask = _collect_previous_mask(inputs)\n            user_kwargs = copy.copy(kwargs)\n            if not _is_all_none(previous_mask):\n                # The previous layer generated a mask.\n                if has_arg(self.call, 'mask'):\n                    if 'mask' not in kwargs:\n                        # If mask is explicitly passed to __call__,\n                        # we should override the default mask.\n                        kwargs['mask'] = previous_mask\n            # Handle automatic shape inference (only useful for Theano).\n            input_shape = _collect_input_shape(inputs)\n\n            # Actually call the layer, collecting output(s), mask(s), and shape(s).\n            output = self.call(inputs, **kwargs)\n            output_mask = self.compute_mask(inputs, previous_mask)\n\n            # If the layer returns tensors from its inputs, unmodified,\n            # we copy them to avoid loss of tensor metadata.\n            output_ls = _to_list(output)\n            inputs_ls = _to_list(inputs)\n            output_ls_copy = []\n            for x in output_ls:\n                if x in inputs_ls:\n                    x = K.identity(x)\n                output_ls_copy.append(x)\n            if len(output_ls_copy) == 1:\n                output = output_ls_copy[0]\n            else:\n                output = output_ls_copy\n\n            # Inferring the output shape is only relevant for Theano.\n            if all([s is not None for s in _to_list(input_shape)]):\n                output_shape = self.compute_output_shape(input_shape)\n            else:\n                if isinstance(input_shape, list):\n                    output_shape = [None for _ in input_shape]\n                else:\n                    output_shape = None\n\n            if not isinstance(output_mask, (list, tuple)) and len(output_ls) > 1:\n                # Augment the mask to match the length of the output.\n                output_mask = [output_mask] * len(output_ls)\n\n            # Add an inbound node to the layer, so that it keeps track\n            # of the call and of all new variables created during the call.\n            # This also updates the layer history of the output tensor(s).\n            # If the input tensor(s) had not previous Keras history,\n            # this does nothing.\n            self._add_inbound_node(input_tensors=inputs, output_tensors=output,\n                                   input_masks=previous_mask, output_masks=output_mask,\n                                   input_shapes=input_shape, output_shapes=output_shape,\n                                   arguments=user_kwargs)\n\n            # Apply activity regularizer if any:\n            if hasattr(self, 'activity_regularizer') and self.activity_regularizer is not None:\n                regularization_losses = [self.activity_regularizer(x) for x in _to_list(output)]\n                self.add_loss(regularization_losses, _to_list(inputs))\n        return output",
        "begin_line": 543,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 1.0,
            "pseudo_dstar_susp": 0.023255813953488372,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.023255813953488372,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.engine.topology.Layer._add_inbound_node#665",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer._add_inbound_node(self, input_tensors, output_tensors, input_masks, output_masks, input_shapes, output_shapes, arguments=None)",
        "snippet": "    def _add_inbound_node(self, input_tensors, output_tensors,\n                          input_masks, output_masks,\n                          input_shapes, output_shapes, arguments=None):\n        \"\"\"Internal method to create an inbound node for the layer.\n\n        # Arguments\n            input_tensors: list of input tensors.\n            output_tensors: list of output tensors.\n            input_masks: list of input masks (a mask can be a tensor, or None).\n            output_masks: list of output masks (a mask can be a tensor, or None).\n            input_shapes: list of input shape tuples.\n            output_shapes: list of output shape tuples.\n            arguments: dictionary of keyword arguments that were passed to the\n                `call` method of the layer at the call that created the node.\n        \"\"\"\n        input_tensors = _to_list(input_tensors)\n        output_tensors = _to_list(output_tensors)\n        input_masks = _to_list(input_masks)\n        output_masks = _to_list(output_masks)\n        input_shapes = _to_list(input_shapes)\n        output_shapes = _to_list(output_shapes)\n\n        # Collect input tensor(s) coordinates.\n        inbound_layers = []\n        node_indices = []\n        tensor_indices = []\n        for x in input_tensors:\n            if hasattr(x, '_keras_history'):\n                inbound_layer, node_index, tensor_index = x._keras_history\n                inbound_layers.append(inbound_layer)\n                node_indices.append(node_index)\n                tensor_indices.append(tensor_index)\n            else:\n                inbound_layers.append(None)\n                node_indices.append(None)\n                tensor_indices.append(None)\n\n        # Create node, add it to inbound nodes.\n        Node(\n            self,\n            inbound_layers=inbound_layers,\n            node_indices=node_indices,\n            tensor_indices=tensor_indices,\n            input_tensors=input_tensors,\n            output_tensors=output_tensors,\n            input_masks=input_masks,\n            output_masks=output_masks,\n            input_shapes=input_shapes,\n            output_shapes=output_shapes,\n            arguments=arguments\n        )\n\n        # Update tensor history, _keras_shape and _uses_learning_phase.\n        for i in range(len(output_tensors)):\n            output_tensors[i]._keras_shape = output_shapes[i]\n            uses_lp = any([getattr(x, '_uses_learning_phase', False) for x in input_tensors])\n            uses_lp = getattr(self, 'uses_learning_phase', False) or uses_lp\n            output_tensors[i]._uses_learning_phase = getattr(output_tensors[i], '_uses_learning_phase', False) or uses_lp\n            output_tensors[i]._keras_history = (self,\n                                                len(self._inbound_nodes) - 1,\n                                                i)",
        "begin_line": 665,
        "end_line": 725,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001841620626151013,
            "pseudo_dstar_susp": 0.023255813953488372,
            "pseudo_tarantula_susp": 0.001658374792703151,
            "pseudo_op2_susp": 0.023255813953488372,
            "pseudo_barinel_susp": 0.001658374792703151
        }
    },
    {
        "name": "keras.engine.topology.Layer.compute_output_shape#727",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        \"\"\"Computes the output shape of the layer.\n\n        Assumes that the layer will be built\n        to match that input shape provided.\n\n        # Arguments\n            input_shape: Shape tuple (tuple of integers)\n                or list of shape tuples (one per output tensor of the layer).\n                Shape tuples can include None for free dimensions,\n                instead of an integer.\n\n        # Returns\n            An input shape tuple.\n        \"\"\"\n        if hasattr(self, 'get_output_shape_for'):\n            msg = \"Class `{}.{}` defines `get_output_shape_for` but does not override `compute_output_shape`. \" + \\\n                  \"If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.\"\n            warnings.warn(msg.format(type(self).__module__, type(self).__name__), stacklevel=2)\n        return input_shape",
        "begin_line": 727,
        "end_line": 746,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000992063492063492,
            "pseudo_dstar_susp": 0.0005296610169491525,
            "pseudo_tarantula_susp": 0.0013513513513513514,
            "pseudo_op2_susp": 0.0005296610169491525,
            "pseudo_barinel_susp": 0.0013513513513513514
        }
    },
    {
        "name": "keras.engine.topology.Layer.compute_mask#748",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        \"\"\"Computes an output mask tensor.\n\n        # Arguments\n            inputs: Tensor or list of tensors.\n            mask: Tensor or list of tensors.\n\n        # Returns\n            None or a tensor (or list of tensors,\n                one per output tensor of the layer).\n        \"\"\"\n        if not self.supports_masking:\n            if mask is not None:\n                if isinstance(mask, list):\n                    if any(m is not None for m in mask):\n                        raise TypeError('Layer ' + self.name +\n                                        ' does not support masking, '\n                                        'but was passed an input_mask: ' +\n                                        str(mask))\n                else:\n                    raise TypeError('Layer ' + self.name +\n                                    ' does not support masking, '\n                                    'but was passed an input_mask: ' +\n                                    str(mask))\n            # masking not explicitly supported: return None as mask\n            return None\n        # if masking is explicitly supported, by default\n        # carry over the input mask\n        return mask",
        "begin_line": 748,
        "end_line": 776,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001692047377326565,
            "pseudo_dstar_susp": 0.007352941176470588,
            "pseudo_tarantula_susp": 0.0009615384615384616,
            "pseudo_op2_susp": 0.007352941176470588,
            "pseudo_barinel_susp": 0.0009615384615384616
        }
    },
    {
        "name": "keras.engine.topology.Layer.build#778",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        \"\"\"Creates the layer weights.\n\n        Must be implemented on all layers that have weights.\n\n        # Arguments\n            input_shape: Keras tensor (future input to layer)\n                or list/tuple of Keras tensors to reference\n                for weight shape computations.\n        \"\"\"\n        self.built = True",
        "begin_line": 778,
        "end_line": 788,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003749531308586427,
            "pseudo_dstar_susp": 0.0003746721618583739,
            "pseudo_tarantula_susp": 0.00038299502106472615,
            "pseudo_op2_susp": 0.0003746721618583739,
            "pseudo_barinel_susp": 0.00038299502106472615
        }
    },
    {
        "name": "keras.engine.topology.Layer._get_node_attribute_at_index#790",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer._get_node_attribute_at_index(self, node_index, attr, attr_name)",
        "snippet": "    def _get_node_attribute_at_index(self, node_index, attr, attr_name):\n        \"\"\"Retrieves an attribute (e.g. input_tensors) from a node.\n\n        This is used to implement the methods:\n            - get_input_shape_at\n            - get_output_shape_at\n            - get_input_at\n            etc...\n\n        # Arguments\n            node_index: Integer index of the node from which\n                to retrieve the attribute.\n            attr: Exact node attribute name.\n            attr_name: Human-readable attribute name, for error messages.\n\n        # Returns\n            The layer's attribute `attr` at the node of index `node_index`.\n\n        # Raises\n            RuntimeError: If the layer has no inbound nodes.\n            ValueError: If the index is does not match any node.\n        \"\"\"\n        if not self._inbound_nodes:\n            raise RuntimeError('The layer has never been called '\n                               'and thus has no defined ' + attr_name + '.')\n        if not len(self._inbound_nodes) > node_index:\n            raise ValueError('Asked to get ' + attr_name +\n                             ' at node ' + str(node_index) +\n                             ', but the layer has only ' +\n                             str(len(self._inbound_nodes)) + ' inbound nodes.')\n        values = getattr(self._inbound_nodes[node_index], attr)\n        if len(values) == 1:\n            return values[0]\n        else:\n            return values",
        "begin_line": 790,
        "end_line": 824,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000564652738565782,
            "pseudo_dstar_susp": 0.0012121212121212121,
            "pseudo_tarantula_susp": 0.00043821209465381246,
            "pseudo_op2_susp": 0.0012121212121212121,
            "pseudo_barinel_susp": 0.00043821209465381246
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_input_shape_at#826",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_input_shape_at(self, node_index)",
        "snippet": "    def get_input_shape_at(self, node_index):\n        \"\"\"Retrieves the input shape(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A shape tuple\n            (or list of shape tuples if the layer has multiple inputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'input_shapes',\n                                                 'input shape')",
        "begin_line": 826,
        "end_line": 841,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_output_shape_at#843",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_output_shape_at(self, node_index)",
        "snippet": "    def get_output_shape_at(self, node_index):\n        \"\"\"Retrieves the output shape(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A shape tuple\n            (or list of shape tuples if the layer has multiple outputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'output_shapes',\n                                                 'output shape')",
        "begin_line": 843,
        "end_line": 858,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_input_at#860",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_input_at(self, node_index)",
        "snippet": "    def get_input_at(self, node_index):\n        \"\"\"Retrieves the input tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A tensor (or list of tensors if the layer has multiple inputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'input_tensors',\n                                                 'input')",
        "begin_line": 860,
        "end_line": 874,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_output_at#876",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_output_at(self, node_index)",
        "snippet": "    def get_output_at(self, node_index):\n        \"\"\"Retrieves the output tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A tensor (or list of tensors if the layer has multiple outputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'output_tensors',\n                                                 'output')",
        "begin_line": 876,
        "end_line": 890,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_input_mask_at#892",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_input_mask_at(self, node_index)",
        "snippet": "    def get_input_mask_at(self, node_index):\n        \"\"\"Retrieves the input mask tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A mask tensor\n            (or list of tensors if the layer has multiple inputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'input_masks',\n                                                 'input mask')",
        "begin_line": 892,
        "end_line": 907,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_output_mask_at#909",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_output_mask_at(self, node_index)",
        "snippet": "    def get_output_mask_at(self, node_index):\n        \"\"\"Retrieves the output mask tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A mask tensor\n            (or list of tensors if the layer has multiple outputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'output_masks',\n                                                 'output mask')",
        "begin_line": 909,
        "end_line": 924,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.input#927",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.input(self)",
        "snippet": "    def input(self):\n        \"\"\"Retrieves the input tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Input tensor or list of input tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if len(self._inbound_nodes) > 1:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has multiple inbound nodes, '\n                                 'hence the notion of \"layer input\" '\n                                 'is ill-defined. '\n                                 'Use `get_input_at(node_index)` instead.')\n        elif not self._inbound_nodes:\n            raise AttributeError('Layer ' + self.name +\n                                 ' is not connected, no input to return.')\n        return self._get_node_attribute_at_index(0, 'input_tensors',\n                                                 'input')",
        "begin_line": 927,
        "end_line": 950,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000564652738565782,
            "pseudo_dstar_susp": 0.0012121212121212121,
            "pseudo_tarantula_susp": 0.00043821209465381246,
            "pseudo_op2_susp": 0.0012121212121212121,
            "pseudo_barinel_susp": 0.00043821209465381246
        }
    },
    {
        "name": "keras.engine.topology.Layer.output#953",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.output(self)",
        "snippet": "    def output(self):\n        \"\"\"Retrieves the output tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Output tensor or list of output tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if not self._inbound_nodes:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has no inbound nodes.')\n        if len(self._inbound_nodes) > 1:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has multiple inbound nodes, '\n                                 'hence the notion of \"layer output\" '\n                                 'is ill-defined. '\n                                 'Use `get_output_at(node_index)` instead.')\n        return self._get_node_attribute_at_index(0, 'output_tensors',\n                                                 'output')",
        "begin_line": 953,
        "end_line": 976,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.input_mask#979",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.input_mask(self)",
        "snippet": "    def input_mask(self):\n        \"\"\"Retrieves the input mask tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Input mask tensor (potentially None) or list of input\n            mask tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if len(self._inbound_nodes) != 1:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has multiple inbound nodes, ' +\n                                 'hence the notion of \"layer input mask\" '\n                                 'is ill-defined. '\n                                 'Use `get_input_mask_at(node_index)` '\n                                 'instead.')\n        return self._get_node_attribute_at_index(0, 'input_masks',\n                                                 'input mask')",
        "begin_line": 979,
        "end_line": 1001,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.output_mask#1004",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.output_mask(self)",
        "snippet": "    def output_mask(self):\n        \"\"\"Retrieves the output mask tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Output mask tensor (potentially None) or list of output\n            mask tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if len(self._inbound_nodes) != 1:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has multiple inbound nodes, '\n                                 'hence the notion of \"layer output mask\" '\n                                 'is ill-defined. '\n                                 'Use `get_output_mask_at(node_index)` '\n                                 'instead.')\n        return self._get_node_attribute_at_index(0, 'output_masks',\n                                                 'output mask')",
        "begin_line": 1004,
        "end_line": 1026,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.input_shape#1029",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.input_shape(self)",
        "snippet": "    def input_shape(self):\n        \"\"\"Retrieves the input shape tuple(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Input shape tuple\n            (or list of input shape tuples, one tuple per input tensor).\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if not self._inbound_nodes:\n            raise AttributeError('The layer has never been called '\n                                 'and thus has no defined input shape.')\n        all_input_shapes = set([str(node.input_shapes) for node in self._inbound_nodes])\n        if len(all_input_shapes) == 1:\n            input_shapes = self._inbound_nodes[0].input_shapes\n            if len(input_shapes) == 1:\n                return input_shapes[0]\n            else:\n                return input_shapes\n        else:\n            raise AttributeError('The layer \"' + str(self.name) +\n                                 ' has multiple inbound nodes, '\n                                 'with different input shapes. Hence '\n                                 'the notion of \"input shape\" is '\n                                 'ill-defined for the layer. '\n                                 'Use `get_input_shape_at(node_index)` '\n                                 'instead.')",
        "begin_line": 1029,
        "end_line": 1060,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.output_shape#1063",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.output_shape(self)",
        "snippet": "    def output_shape(self):\n        \"\"\"Retrieves the output shape tuple(s) of a layer.\n\n        Only applicable if the layer has one inbound node,\n        or if all inbound nodes have the same output shape.\n\n        # Returns\n            Output shape tuple\n            (or list of input shape tuples, one tuple per output tensor).\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if not self._inbound_nodes:\n            raise AttributeError('The layer has never been called '\n                                 'and thus has no defined output shape.')\n        all_output_shapes = set([str(node.output_shapes) for node in self._inbound_nodes])\n        if len(all_output_shapes) == 1:\n            output_shapes = self._inbound_nodes[0].output_shapes\n            if len(output_shapes) == 1:\n                return output_shapes[0]\n            else:\n                return output_shapes\n        else:\n            raise AttributeError('The layer \"' + str(self.name) +\n                                 ' has multiple inbound nodes, '\n                                 'with different output shapes. Hence '\n                                 'the notion of \"output shape\" is '\n                                 'ill-defined for the layer. '\n                                 'Use `get_output_shape_at(node_index)` '\n                                 'instead.')",
        "begin_line": 1063,
        "end_line": 1094,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001026694045174538,
            "pseudo_dstar_susp": 0.0011337868480725624,
            "pseudo_tarantula_susp": 0.0009852216748768472,
            "pseudo_op2_susp": 0.0011337868480725624,
            "pseudo_barinel_susp": 0.0009852216748768472
        }
    },
    {
        "name": "keras.engine.topology.Layer.add_loss#1096",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.add_loss(self, losses, inputs=None)",
        "snippet": "    def add_loss(self, losses, inputs=None):\n        \"\"\"Adds losses to the layer.\n\n        The loss may potentially be conditional on some inputs tensors,\n        for instance activity losses are conditional on the layer's inputs.\n\n        # Arguments\n            losses: loss tensor or list of loss tensors\n                to add to the layer.\n            inputs: input tensor or list of inputs tensors to mark\n                the losses as conditional on these inputs.\n                If None is passed, the loss is assumed unconditional\n                (e.g. L2 weight regularization, which only depends\n                on the layer's weights variables, not on any inputs tensors).\n        \"\"\"\n        if losses is None or losses == []:\n            return\n        # Update self.losses\n        losses = _to_list(losses)\n        if hasattr(self, '_losses'):\n            self._losses += losses\n        # Update self._per_input_updates\n        if isinstance(inputs, list) and inputs == []:\n            inputs = None\n        if inputs is not None:\n            inputs_hash = _object_list_uid(inputs)\n        else:\n            # Updates indexed by None are unconditional\n            # rather than input-dependent\n            inputs_hash = None\n        if inputs_hash not in self._per_input_losses:\n            self._per_input_losses[inputs_hash] = []\n        self._per_input_losses[inputs_hash] += losses",
        "begin_line": 1096,
        "end_line": 1128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011173184357541898,
            "pseudo_dstar_susp": 0.0005455537370430987,
            "pseudo_tarantula_susp": 0.0014792899408284023,
            "pseudo_op2_susp": 0.0005455537370430987,
            "pseudo_barinel_susp": 0.0014792899408284023
        }
    },
    {
        "name": "keras.engine.topology.Layer.add_update#1130",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.add_update(self, updates, inputs=None)",
        "snippet": "    def add_update(self, updates, inputs=None):\n        \"\"\"Adds updates to the layer.\n\n        The updates may potentially be conditional on some inputs tensors,\n        for instance batch norm updates are conditional on the layer's inputs.\n\n        # Arguments\n            updates: update op or list of update ops\n                to add to the layer.\n            inputs: input tensor or list of inputs tensors to mark\n                the updates as conditional on these inputs.\n                If None is passed, the updates are assumed unconditional.\n        \"\"\"\n        if updates is None or updates == []:\n            return\n        # Update self.updates\n        updates = _to_list(updates)\n        if hasattr(self, '_updates'):\n            self._updates += updates\n        # Update self._per_input_updates\n        if isinstance(inputs, list) and inputs == []:\n            inputs = None\n        if inputs is not None:\n            inputs_hash = _object_list_uid(inputs)\n        else:\n            # Updates indexed by None are unconditional\n            # rather than input-dependent\n            inputs_hash = None\n        if inputs_hash not in self._per_input_updates:\n            self._per_input_updates[inputs_hash] = []\n        self._per_input_updates[inputs_hash] += updates",
        "begin_line": 1130,
        "end_line": 1160,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011173184357541898,
            "pseudo_dstar_susp": 0.0005455537370430987,
            "pseudo_tarantula_susp": 0.0014792899408284023,
            "pseudo_op2_susp": 0.0005455537370430987,
            "pseudo_barinel_susp": 0.0014792899408284023
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_updates_for#1162",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_updates_for(self, inputs)",
        "snippet": "    def get_updates_for(self, inputs):\n        if not self.trainable and not self.stateful:\n            return []\n        if inputs is not None:\n            inputs_hash = _object_list_uid(inputs)\n        else:\n            inputs_hash = None\n        if inputs_hash in self._per_input_updates:\n            return self._per_input_updates[inputs_hash]\n        return []",
        "begin_line": 1162,
        "end_line": 1171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004992511233150275,
            "pseudo_dstar_susp": 0.0010427528675703858,
            "pseudo_tarantula_susp": 0.00041322314049586776,
            "pseudo_op2_susp": 0.0010427528675703858,
            "pseudo_barinel_susp": 0.00041322314049586776
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_losses_for#1173",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_losses_for(self, inputs)",
        "snippet": "    def get_losses_for(self, inputs):\n        if inputs is not None:\n            inputs_hash = _object_list_uid(inputs)\n        else:\n            inputs_hash = None\n        if inputs_hash in self._per_input_losses:\n            return self._per_input_losses[inputs_hash]\n        return []",
        "begin_line": 1173,
        "end_line": 1180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006527415143603133,
            "pseudo_dstar_susp": 0.0015698587127158557,
            "pseudo_tarantula_susp": 0.0005592841163310962,
            "pseudo_op2_susp": 0.0015698587127158557,
            "pseudo_barinel_susp": 0.0005592841163310962
        }
    },
    {
        "name": "keras.engine.topology.Layer.weights#1183",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.weights(self)",
        "snippet": "    def weights(self):\n        return self.trainable_weights + self.non_trainable_weights",
        "begin_line": 1183,
        "end_line": 1184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003718854592785422,
            "pseudo_dstar_susp": 0.0003718854592785422,
            "pseudo_tarantula_susp": 0.0003732736095558044,
            "pseudo_op2_susp": 0.0003718854592785422,
            "pseudo_barinel_susp": 0.0003732736095558044
        }
    },
    {
        "name": "keras.engine.topology.Layer.set_weights#1186",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the layer, from Numpy arrays.\n\n        # Arguments\n            weights: a list of Numpy arrays. The number\n                of arrays and their shape must match\n                number of the dimensions of the weights\n                of the layer (i.e. it should match the\n                output of `get_weights`).\n\n        # Raises\n            ValueError: If the provided weights list does not match the\n                layer's specifications.\n        \"\"\"\n        params = self.weights\n        if len(params) != len(weights):\n            raise ValueError('You called `set_weights(weights)` on layer \"' +\n                             self.name +\n                             '\" with a  weight list of length ' +\n                             str(len(weights)) +\n                             ', but the layer was expecting ' +\n                             str(len(params)) +\n                             ' weights. Provided weights: ' +\n                             str(weights)[:50] + '...')\n        if not params:\n            return\n        weight_value_tuples = []\n        param_values = K.batch_get_value(params)\n        for pv, p, w in zip(param_values, params, weights):\n            if pv.shape != w.shape:\n                raise ValueError('Layer weight shape ' +\n                                 str(pv.shape) +\n                                 ' not compatible with '\n                                 'provided weight shape ' + str(w.shape))\n            weight_value_tuples.append((p, w))\n        K.batch_set_value(weight_value_tuples)",
        "begin_line": 1186,
        "end_line": 1221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_weights#1223",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_weights(self)",
        "snippet": "    def get_weights(self):\n        \"\"\"Returns the current weights of the layer.\n\n        # Returns\n            Weights values as a list of numpy arrays.\n        \"\"\"\n        params = self.weights\n        return K.batch_get_value(params)",
        "begin_line": 1223,
        "end_line": 1230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.355104442483083e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_config#1232",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_config(self)",
        "snippet": "    def get_config(self):\n        \"\"\"Returns the config of the layer.\n\n        A layer config is a Python dictionary (serializable)\n        containing the configuration of a layer.\n        The same layer can be reinstantiated later\n        (without its trained weights) from this configuration.\n\n        The config of a layer does not include connectivity\n        information, nor the layer class name. These are handled\n        by `Container` (one layer of abstraction above).\n\n        # Returns\n            Python dictionary.\n        \"\"\"\n        config = {'name': self.name,\n                  'trainable': self.trainable}\n        if hasattr(self, 'batch_input_shape'):\n            config['batch_input_shape'] = self.batch_input_shape\n        if hasattr(self, 'dtype'):\n            config['dtype'] = self.dtype\n        return config",
        "begin_line": 1232,
        "end_line": 1253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036900369003690036,
            "pseudo_dstar_susp": 0.00036900369003690036,
            "pseudo_tarantula_susp": 0.0003700962250185048,
            "pseudo_op2_susp": 0.00036900369003690036,
            "pseudo_barinel_susp": 0.0003700962250185048
        }
    },
    {
        "name": "keras.engine.topology.Layer.from_config#1256",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        \"\"\"Creates a layer from its config.\n\n        This method is the reverse of `get_config`,\n        capable of instantiating the same layer from the config\n        dictionary. It does not handle layer connectivity\n        (handled by Container), nor weights (handled by `set_weights`).\n\n        # Arguments\n            config: A Python dictionary, typically the\n                output of get_config.\n\n        # Returns\n            A layer instance.\n        \"\"\"\n        return cls(**config)",
        "begin_line": 1256,
        "end_line": 1271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003769317753486619,
            "pseudo_dstar_susp": 0.0003757985719654265,
            "pseudo_tarantula_susp": 0.00041356492969396195,
            "pseudo_op2_susp": 0.0003757985719654265,
            "pseudo_barinel_susp": 0.00041356492969396195
        }
    },
    {
        "name": "keras.engine.topology.Layer.count_params#1273",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.count_params(self)",
        "snippet": "    def count_params(self):\n        \"\"\"Counts the total number of scalars composing the weights.\n\n        # Returns\n            An integer count.\n\n        # Raises\n            RuntimeError: if the layer isn't yet built\n                (in which case its weights aren't yet defined).\n        \"\"\"\n        if not self.built:\n            if self.__class__.__name__ == 'Sequential':\n                self.build()\n            else:\n                raise RuntimeError('You tried to call `count_params` on ' +\n                                   self.name + ', but the layer isn\\'t built. '\n                                   'You can build it manually via: `' +\n                                   self.name + '.build(batch_input_shape)`.')\n        return count_params(self.weights)",
        "begin_line": 1273,
        "end_line": 1291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011173184357541898,
            "pseudo_dstar_susp": 0.0005455537370430987,
            "pseudo_tarantula_susp": 0.0014792899408284023,
            "pseudo_op2_susp": 0.0005455537370430987,
            "pseudo_barinel_susp": 0.0014792899408284023
        }
    },
    {
        "name": "keras.engine.topology.InputLayer.__init__#1314",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.InputLayer",
        "signature": "keras.engine.topology.InputLayer.__init__(self, input_shape=None, batch_size=None, batch_input_shape=None, dtype=None, input_tensor=None, sparse=False, name=None)",
        "snippet": "    def __init__(self, input_shape=None, batch_size=None,\n                 batch_input_shape=None,\n                 dtype=None, input_tensor=None, sparse=False, name=None):\n        if not name:\n            prefix = 'input'\n            name = prefix + '_' + str(K.get_uid(prefix))\n        super(InputLayer, self).__init__(dtype=dtype, name=name)\n\n        self.trainable = False\n        self.built = True\n        self.sparse = sparse\n\n        if input_shape and batch_input_shape:\n            raise ValueError('Only provide the input_shape OR '\n                             'batch_input_shape argument to '\n                             'InputLayer, not both at the same time.')\n        if input_tensor is not None and batch_input_shape is None:\n            # If input_tensor is set, and batch_input_shape is not set:\n            # Attempt automatic input shape inference.\n            try:\n                batch_input_shape = K.int_shape(input_tensor)\n            except TypeError:\n                if not input_shape and not batch_input_shape:\n                    raise ValueError('InputLayer was provided '\n                                     'an input_tensor argument, '\n                                     'but its input shape cannot be '\n                                     'automatically inferred. '\n                                     'You should pass an input_shape or '\n                                     'batch_input_shape argument.')\n        if not batch_input_shape:\n            if not input_shape:\n                raise ValueError('An Input layer should be passed either '\n                                 'a `batch_input_shape` or an `input_shape`.')\n            else:\n                batch_input_shape = (batch_size,) + tuple(input_shape)\n        else:\n            batch_input_shape = tuple(batch_input_shape)\n\n        if not dtype:\n            if input_tensor is None:\n                dtype = K.floatx()\n            else:\n                dtype = K.dtype(input_tensor)\n\n        self.batch_input_shape = batch_input_shape\n        self.dtype = dtype\n\n        if input_tensor is None:\n            self.is_placeholder = True\n            input_tensor = K.placeholder(shape=batch_input_shape,\n                                         dtype=dtype,\n                                         sparse=self.sparse,\n                                         name=self.name)\n        else:\n            self.is_placeholder = False\n            input_tensor._keras_shape = batch_input_shape\n        # Create an input node to add to self.outbound_node\n        # and set output_tensors' _keras_history.\n        input_tensor._uses_learning_phase = False\n        input_tensor._keras_history = (self, 0, 0)\n        Node(self,\n             inbound_layers=[],\n             node_indices=[],\n             tensor_indices=[],\n             input_tensors=[input_tensor],\n             output_tensors=[input_tensor],\n             input_masks=[None],\n             output_masks=[None],\n             input_shapes=[batch_input_shape],\n             output_shapes=[batch_input_shape])",
        "begin_line": 1314,
        "end_line": 1383,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008795074758135445,
            "pseudo_dstar_susp": 0.0026954177897574125,
            "pseudo_tarantula_susp": 0.0005790387955993051,
            "pseudo_op2_susp": 0.0026954177897574125,
            "pseudo_barinel_susp": 0.0005790387955993051
        }
    },
    {
        "name": "keras.engine.topology.InputLayer.get_config#1385",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.InputLayer",
        "signature": "keras.engine.topology.InputLayer.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'batch_input_shape': self.batch_input_shape,\n                  'dtype': self.dtype,\n                  'sparse': self.sparse,\n                  'name': self.name}\n        return config",
        "begin_line": 1385,
        "end_line": 1390,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00039603960396039607,
            "pseudo_dstar_susp": 0.00039478878799842083,
            "pseudo_tarantula_susp": 0.0005055611729019212,
            "pseudo_op2_susp": 0.00039478878799842083,
            "pseudo_barinel_susp": 0.0005055611729019212
        }
    },
    {
        "name": "keras.engine.topology.Input#1393",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.Input(shape=None, batch_shape=None, name=None, dtype=None, sparse=False, tensor=None)",
        "snippet": "def Input(shape=None, batch_shape=None,\n          name=None, dtype=None, sparse=False,\n          tensor=None):\n    \"\"\"`Input()` is used to instantiate a Keras tensor.\n\n    A Keras tensor is a tensor object from the underlying backend\n    (Theano, TensorFlow or CNTK), which we augment with certain\n    attributes that allow us to build a Keras model\n    just by knowing the inputs and outputs of the model.\n\n    For instance, if a, b and c are Keras tensors,\n    it becomes possible to do:\n    `model = Model(input=[a, b], output=c)`\n\n    The added Keras attributes are:\n        `_keras_shape`: Integer shape tuple propagated\n            via Keras-side shape inference.\n        `_keras_history`: Last layer applied to the tensor.\n            the entire layer graph is retrievable from that layer,\n            recursively.\n\n    # Arguments\n        shape: A shape tuple (integer), not including the batch size.\n            For instance, `shape=(32,)` indicates that the expected input\n            will be batches of 32-dimensional vectors.\n        batch_shape: A shape tuple (integer), including the batch size.\n            For instance, `batch_shape=(10, 32)` indicates that\n            the expected input will be batches of 10 32-dimensional vectors.\n            `batch_shape=(None, 32)` indicates batches of an arbitrary number\n            of 32-dimensional vectors.\n        name: An optional name string for the layer.\n            Should be unique in a model (do not reuse the same name twice).\n            It will be autogenerated if it isn't provided.\n        dtype: The data type expected by the input, as a string\n            (`float32`, `float64`, `int32`...)\n        sparse: A boolean specifying whether the placeholder\n            to be created is sparse.\n        tensor: Optional existing tensor to wrap into the `Input` layer.\n            If set, the layer will not create a placeholder tensor.\n\n    # Returns\n        A tensor.\n\n    # Example\n\n        ```python\n        # this is a logistic regression in Keras\n        x = Input(shape=(32,))\n        y = Dense(16, activation='softmax')(x)\n        model = Model(x, y)\n        ```\n    \"\"\"\n    if not batch_shape and tensor is None:\n        assert shape is not None, ('Please provide to Input either a `shape`'\n                                   ' or a `batch_shape` argument. Note that '\n                                   '`shape` does not include the batch '\n                                   'dimension.')\n    if shape is not None and not batch_shape:\n        batch_shape = (None,) + tuple(shape)\n    if not dtype:\n        dtype = K.floatx()\n    input_layer = InputLayer(batch_input_shape=batch_shape,\n                             name=name, dtype=dtype,\n                             sparse=sparse,\n                             input_tensor=tensor)\n    # Return tensor including _keras_shape and _keras_history.\n    # Note that in this case train_output and test_output are the same pointer.\n    outputs = input_layer._inbound_nodes[0].output_tensors\n    if len(outputs) == 1:\n        return outputs[0]\n    else:\n        return outputs",
        "begin_line": 1393,
        "end_line": 1464,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008795074758135445,
            "pseudo_dstar_susp": 0.0026954177897574125,
            "pseudo_tarantula_susp": 0.0005790387955993051,
            "pseudo_op2_susp": 0.0026954177897574125,
            "pseudo_barinel_susp": 0.0005790387955993051
        }
    },
    {
        "name": "keras.engine.topology.Container.__init__#1507",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.__init__(self, inputs, outputs, name=None)",
        "snippet": "    def __init__(self, inputs, outputs, name=None):\n        # Handle `name` argument.\n        if not name:\n            prefix = self.__class__.__name__.lower()\n            name = prefix + '_' + str(K.get_uid(prefix))\n        self.name = name\n\n        self.supports_masking = False\n        self.trainable = True\n        self._per_input_losses = {}\n        self._per_input_updates = {}\n\n        # Container-specific properties.\n        if isinstance(inputs, (list, tuple)):\n            self.inputs = list(inputs)  # Tensor or list of tensors.\n        else:\n            self.inputs = [inputs]\n        if isinstance(outputs, (list, tuple)):\n            self.outputs = list(outputs)\n        else:\n            self.outputs = [outputs]\n\n        # Check for redundancy in inputs.\n        if len(set(self.inputs)) != len(self.inputs):\n            raise ValueError('The list of inputs passed to the model '\n                             'is redundant. '\n                             'All inputs should only appear once.'\n                             ' Found: ' + str(self.inputs))\n\n        # Check for redundancy in outputs.\n        if len(set(self.outputs)) != len(self.outputs):\n            warnings.warn('The list of outputs passed to the model '\n                          'is redundant. '\n                          'All outputs should only appear once.'\n                          ' Found: ' + str(self.outputs))\n\n        # List of initial layers (1 to 1 mapping with self.inputs,\n        # hence the same layer might appear twice)\n        self.input_layers = []\n        self.input_layers_node_indices = []\n        self.input_layers_tensor_indices = []\n        # list of layers (1 to 1 mapping with self.inputs,\n        # hence the same layer might appear twice)\n        self.output_layers = []\n        self.output_layers_node_indices = []\n        self.output_layers_tensor_indices = []\n        # all layers in order of horizontal graph traversal.\n        # Entries are unique. Includes input and output layers.\n        self.layers = []\n\n        # This is for performance optimization\n        # when calling the Container on new inputs.\n        # every time the Container is called on a set on input tensors,\n        # we compute the output tensors,\n        # output masks and output shapes in one pass,\n        # then cache them here. When one of these output is queried later,\n        # we retrieve it from there instead of recomputing it.\n        self._output_mask_cache = {}\n        self._output_tensor_cache = {}\n        self._output_shape_cache = {}\n\n        # User-provided arguments validation.\n        for x in self.inputs:\n            # Check that x is a Keras tensor.\n            if not hasattr(x, '_keras_history'):\n                cls_name = self.__class__.__name__\n                raise TypeError('Input tensors to a ' + cls_name + ' ' +\n                                'must be Keras tensors. Found: ' + str(x) +\n                                ' (missing Keras metadata).')\n            # Check that x is an input tensor.\n            layer, node_index, tensor_index = x._keras_history\n            if len(layer._inbound_nodes) > 1 or (layer._inbound_nodes and layer._inbound_nodes[0].inbound_layers):\n                cls_name = self.__class__.__name__\n                warnings.warn(cls_name + ' inputs must come from '\n                              'a Keras Input layer, '\n                              'they cannot be the output of '\n                              'a previous non-Input layer. '\n                              'Here, a tensor specified as '\n                              'input to \"' + self.name +\n                              '\" was not an Input tensor, '\n                              'it was generated by layer ' +\n                              layer.name + '.\\n'\n                              'Note that input tensors are '\n                              'instantiated via `tensor = Input(shape)`.\\n'\n                              'The tensor that caused the issue was: ' +\n                              str(x.name))\n        for x in self.outputs:\n            if not hasattr(x, '_keras_history'):\n                cls_name = self.__class__.__name__\n                raise TypeError('Output tensors to a ' + cls_name + ' must be '\n                                'Keras tensors. Found: ' + str(x))\n        # Build self.output_layers:\n        for x in self.outputs:\n            layer, node_index, tensor_index = x._keras_history\n            self.output_layers.append(layer)\n            self.output_layers_node_indices.append(node_index)\n            self.output_layers_tensor_indices.append(tensor_index)\n\n        # Fill in the output mask cache.\n        masks = []\n        for x in self.inputs:\n            layer, node_index, tensor_index = x._keras_history\n            node = layer._inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        mask_cache_key = ','.join([str(id(x)) for x in self.inputs])\n        mask_cache_key += '_' + ','.join([str(id(x)) for x in masks])\n        masks = []\n        for x in self.outputs:\n            layer, node_index, tensor_index = x._keras_history\n            node = layer._inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        if len(masks) == 1:\n            mask = masks[0]\n        else:\n            mask = masks\n        self._output_mask_cache[mask_cache_key] = mask\n\n        # Build self.input_layers:\n        for x in self.inputs:\n            layer, node_index, tensor_index = x._keras_history\n            # It's supposed to be an input layer, so only one node\n            # and one tensor output.\n            assert node_index == 0\n            assert tensor_index == 0\n            self.input_layers.append(layer)\n            self.input_layers_node_indices.append(node_index)\n            self.input_layers_tensor_indices.append(tensor_index)\n\n        # Build self.input_names and self.output_names.\n        self.input_names = []\n        self.output_names = []\n        self._feed_input_names = []\n        self._feed_inputs = []\n        self._feed_input_shapes = []\n        for i, layer in enumerate(self.input_layers):\n            # Check that layer is an InputLayer.\n            if not isinstance(layer, InputLayer):\n                raise TypeError(\n                    'Input layers to a `Model` must be `InputLayer` objects. '\n                    'Received inputs: {}. '\n                    'Input {} (0-based) originates '\n                    'from layer type `{}`.'.format(inputs,\n                                                   i,\n                                                   layer.__class__.__name__))\n            self.input_names.append(layer.name)\n            if layer.is_placeholder:\n                self._feed_input_names.append(layer.name)\n                self._feed_inputs.append(layer.input)\n                self._feed_input_shapes.append(self.inputs[i]._keras_shape)\n        for layer in self.output_layers:\n            self.output_names.append(layer.name)\n\n        self._internal_input_shapes = [x._keras_shape for x in self.inputs]\n        self._internal_output_shapes = [x._keras_shape for x in self.outputs]\n\n        # Container_nodes: set of nodes included in the graph\n        # (not all nodes included in the layers\n        # are relevant to the current graph).\n        container_nodes = set()  # ids of all nodes relevant to the Container\n        nodes_depths = {}  # dict {node: depth value}\n        layers_depths = {}  # dict {layer: depth value}\n        layer_indices = {}  # dict {layer: index in traversal}\n        nodes_in_decreasing_depth = []\n\n        def build_map_of_graph(tensor, finished_nodes, nodes_in_progress,\n                               layer=None, node_index=None, tensor_index=None):\n            \"\"\"Builds a map of the graph of layers.\n\n            This recursively updates the map `layer_indices`,\n            the list `nodes_in_decreasing_depth` and the set `container_nodes`.\n\n            # Arguments\n                tensor: Some tensor in a graph.\n                finished_nodes: Set of nodes whose subgraphs have been traversed\n                    completely. Useful to prevent duplicated work.\n                nodes_in_progress: Set of nodes that are currently active on the\n                    recursion stack. Useful to detect cycles.\n                layer: Layer from which `tensor` comes from. If not provided,\n                    will be obtained from `tensor._keras_history`.\n                node_index: Node index from which `tensor` comes from.\n                tensor_index: Tensor_index from which `tensor` comes from.\n\n            # Raises\n                RuntimeError: if a cycle is detected.\n            \"\"\"\n            if not layer or node_index is None or tensor_index is None:\n                layer, node_index, tensor_index = tensor._keras_history\n            node = layer._inbound_nodes[node_index]\n\n            # Prevent cycles.\n            if node in nodes_in_progress:\n                raise RuntimeError(\n                    'The tensor ' + str(tensor) + ' at layer \"' +\n                    layer.name + '\" is part of a cycle.')\n\n            # Don't repeat work for shared subgraphs\n            if node in finished_nodes:\n                return\n\n            # Update container_nodes.\n            container_nodes.add(self._node_key(layer, node_index))\n\n            # Store the traversal order for layer sorting.\n            if layer not in layer_indices:\n                layer_indices[layer] = len(layer_indices)\n\n            nodes_in_progress.add(node)\n\n            # Propagate to all previous tensors connected to this node.\n            for i in range(len(node.inbound_layers)):\n                x = node.input_tensors[i]\n                layer = node.inbound_layers[i]\n                node_index = node.node_indices[i]\n                tensor_index = node.tensor_indices[i]\n                build_map_of_graph(x, finished_nodes, nodes_in_progress,\n                                   layer, node_index, tensor_index)\n\n            finished_nodes.add(node)\n            nodes_in_progress.remove(node)\n\n            nodes_in_decreasing_depth.append(node)\n\n        finished_nodes = set()\n        nodes_in_progress = set()\n        for x in self.outputs:\n            build_map_of_graph(x, finished_nodes, nodes_in_progress)\n\n        for node in reversed(nodes_in_decreasing_depth):\n            # If the depth is not set, the node has no outbound nodes (depth 0).\n            depth = nodes_depths.setdefault(node, 0)\n\n            # Update the depth of the corresponding layer\n            previous_depth = layers_depths.get(node.outbound_layer, 0)\n            # If we've seen this layer before at a higher depth, we should use that depth instead\n            # of the node depth.  This is necessary for shared layers that have inputs at different\n            # depth levels in the graph.\n            depth = max(depth, previous_depth)\n            layers_depths[node.outbound_layer] = depth\n            nodes_depths[node] = depth\n\n            # Update the depth of inbound nodes.\n            for i in range(len(node.inbound_layers)):\n                inbound_layer = node.inbound_layers[i]\n                node_index = node.node_indices[i]\n                inbound_node = inbound_layer._inbound_nodes[node_index]\n                previous_depth = nodes_depths.get(inbound_node, 0)\n                nodes_depths[inbound_node] = max(depth + 1, previous_depth)\n\n        # Build a dict {depth: list of nodes with this depth}\n        nodes_by_depth = {}\n        for node, depth in nodes_depths.items():\n            if depth not in nodes_by_depth:\n                nodes_by_depth[depth] = []\n            nodes_by_depth[depth].append(node)\n\n        # Build a dict {depth: list of layers with this depth}\n        layers_by_depth = {}\n        for layer, depth in layers_depths.items():\n            if depth not in layers_by_depth:\n                layers_by_depth[depth] = []\n            layers_by_depth[depth].append(layer)\n\n        # Get sorted list of layer depths.\n        depth_keys = list(layers_by_depth.keys())\n        depth_keys.sort(reverse=True)\n\n        # Set self.layers and self.layers_by_depth.\n        layers = []\n        for depth in depth_keys:\n            layers_for_depth = layers_by_depth[depth]\n            # Container.layers needs to have a deterministic order:\n            # here we order them by traversal order.\n            layers_for_depth.sort(key=lambda x: layer_indices[x])\n            for layer in layers_for_depth:\n                layers.append(layer)\n        self.layers = layers\n        self.layers_by_depth = layers_by_depth\n\n        # Get sorted list of node depths.\n        depth_keys = list(nodes_by_depth.keys())\n        depth_keys.sort(reverse=True)\n\n        # Check that all tensors required are computable.\n        # computable_tensors: all tensors in the graph\n        # that can be computed from the inputs provided.\n        computable_tensors = []\n        for x in self.inputs:\n            computable_tensors.append(x)\n\n        layers_with_complete_input = []  # To provide a better error msg.\n        for depth in depth_keys:\n            for node in nodes_by_depth[depth]:\n                layer = node.outbound_layer\n                if layer:\n                    for x in node.input_tensors:\n                        if x not in computable_tensors:\n                            raise RuntimeError(\n                                'Graph disconnected: '\n                                'cannot obtain value for tensor ' +\n                                str(x) + ' at layer \"' + layer.name + '\". '\n                                'The following previous layers '\n                                'were accessed without issue: ' +\n                                str(layers_with_complete_input))\n                    for x in node.output_tensors:\n                        computable_tensors.append(x)\n                    layers_with_complete_input.append(layer.name)\n\n        # Set self._container_nodes and self._nodes_by_depth.\n        self._container_nodes = container_nodes\n        self._nodes_by_depth = nodes_by_depth\n\n        # Ensure name unicity, which will be crucial for serialization\n        # (since serialized nodes refer to layers by their name).\n        all_names = [layer.name for layer in self.layers]\n        for name in all_names:\n            if all_names.count(name) != 1:\n                raise RuntimeError('The name \"' + name + '\" is used ' +\n                                   str(all_names.count(name)) +\n                                   ' times in the model. '\n                                   'All layer names should be unique. '\n                                   'Layer names: ', all_names)\n\n        # Layer parameters.\n        # The new container starts with a single inbound node\n        # for its inputs, and no outbound nodes.\n        self._outbound_nodes = []  # Will be appended to by future calls to __call__\n        self._inbound_nodes = []  # Will be appended to below, and by future calls to __call__\n        # Create the node linking internal inputs to internal outputs.\n        Node(outbound_layer=self,\n             inbound_layers=[],\n             node_indices=[],\n             tensor_indices=[],\n             input_tensors=self.inputs,\n             output_tensors=self.outputs,\n             # No container-level masking for now.\n             input_masks=[None for _ in self.inputs],\n             output_masks=[None for _ in self.outputs],\n             input_shapes=[x._keras_shape for x in self.inputs],\n             output_shapes=[x._keras_shape for x in self.outputs])\n        self.built = True",
        "begin_line": 1507,
        "end_line": 1848,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.015873015873015872,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.015873015873015872,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.engine.topology.Container.build_map_of_graph#1673",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.build_map_of_graph(tensor, finished_nodes, nodes_in_progress, layer=None, node_index=None, tensor_index=None)",
        "snippet": "        def build_map_of_graph(tensor, finished_nodes, nodes_in_progress,\n                               layer=None, node_index=None, tensor_index=None):\n            \"\"\"Builds a map of the graph of layers.\n\n            This recursively updates the map `layer_indices`,\n            the list `nodes_in_decreasing_depth` and the set `container_nodes`.\n\n            # Arguments\n                tensor: Some tensor in a graph.\n                finished_nodes: Set of nodes whose subgraphs have been traversed\n                    completely. Useful to prevent duplicated work.\n                nodes_in_progress: Set of nodes that are currently active on the\n                    recursion stack. Useful to detect cycles.\n                layer: Layer from which `tensor` comes from. If not provided,\n                    will be obtained from `tensor._keras_history`.\n                node_index: Node index from which `tensor` comes from.\n                tensor_index: Tensor_index from which `tensor` comes from.\n\n            # Raises\n                RuntimeError: if a cycle is detected.\n            \"\"\"\n            if not layer or node_index is None or tensor_index is None:\n                layer, node_index, tensor_index = tensor._keras_history\n            node = layer._inbound_nodes[node_index]\n\n            # Prevent cycles.\n            if node in nodes_in_progress:\n                raise RuntimeError(\n                    'The tensor ' + str(tensor) + ' at layer \"' +\n                    layer.name + '\" is part of a cycle.')\n\n            # Don't repeat work for shared subgraphs\n            if node in finished_nodes:\n                return\n\n            # Update container_nodes.\n            container_nodes.add(self._node_key(layer, node_index))\n\n            # Store the traversal order for layer sorting.\n            if layer not in layer_indices:\n                layer_indices[layer] = len(layer_indices)\n\n            nodes_in_progress.add(node)\n\n            # Propagate to all previous tensors connected to this node.\n            for i in range(len(node.inbound_layers)):\n                x = node.input_tensors[i]\n                layer = node.inbound_layers[i]\n                node_index = node.node_indices[i]\n                tensor_index = node.tensor_indices[i]\n                build_map_of_graph(x, finished_nodes, nodes_in_progress,\n                                   layer, node_index, tensor_index)\n\n            finished_nodes.add(node)\n            nodes_in_progress.remove(node)\n\n            nodes_in_decreasing_depth.append(node)",
        "begin_line": 1673,
        "end_line": 1729,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006397952655150352,
            "pseudo_dstar_susp": 0.001358695652173913,
            "pseudo_tarantula_susp": 0.0010976948408342481,
            "pseudo_op2_susp": 0.001358695652173913,
            "pseudo_barinel_susp": 0.0010976948408342481
        }
    },
    {
        "name": "keras.engine.topology.Container.get_layer#1855",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.get_layer(self, name=None, index=None)",
        "snippet": "    def get_layer(self, name=None, index=None):\n        \"\"\"Retrieves a layer based on either its name (unique) or index.\n\n        Indices are based on order of horizontal graph traversal (bottom-up).\n\n        # Arguments\n            name: String, name of layer.\n            index: Integer, index of layer.\n\n        # Returns\n            A layer instance.\n\n        # Raises\n            ValueError: In case of invalid layer name or index.\n        \"\"\"\n        # It would be unreliable to build a dictionary\n        # based on layer names, because names can potentially\n        # be changed at any point by the user\n        # without the container being notified of it.\n        if index is not None:\n            if len(self.layers) <= index:\n                raise ValueError('Was asked to retrieve layer at index ' +\n                                 str(index) + ' but model only has ' +\n                                 str(len(self.layers)) + ' layers.')\n            else:\n                return self.layers[index]\n        else:\n            if not name:\n                raise ValueError('Provide either a layer name or layer index.')\n\n        for layer in self.layers:\n            if layer.name == name:\n                return layer\n\n        raise ValueError('No such layer: ' + name)",
        "begin_line": 1855,
        "end_line": 1889,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Container.updates#1892",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.updates(self)",
        "snippet": "    def updates(self):\n        \"\"\"Retrieves the model's updates.\n\n        Will only include updates that are either\n        inconditional, or conditional on inputs to this model\n        (e.g. will not include updates that depend on tensors\n        that aren't inputs to this model).\n\n        # Returns\n            A list of update ops.\n        \"\"\"\n        if not self.trainable and not self.stateful:\n            return []\n        updates = []\n        for layer in self.layers:\n            if hasattr(layer, 'updates'):\n                # Collect updates that are dependent on inputs\n                # that are part of the model.\n                for node_index, node in enumerate(layer._inbound_nodes):\n                    node_key = self._node_key(layer, node_index)\n                    if node_key in self._container_nodes:\n                        # The model owns this layer node.\n                        inputs = node.input_tensors\n                        updates += layer.get_updates_for(inputs)\n                # Collect unconditional updates.\n                updates += layer.get_updates_for(None)\n        return updates",
        "begin_line": 1892,
        "end_line": 1918,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003629764065335753,
            "pseudo_dstar_susp": 0.0003629764065335753,
            "pseudo_tarantula_susp": 0.00036403349108117945,
            "pseudo_op2_susp": 0.0003629764065335753,
            "pseudo_barinel_susp": 0.00036403349108117945
        }
    },
    {
        "name": "keras.engine.topology.Container.losses#1921",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.losses(self)",
        "snippet": "    def losses(self):\n        \"\"\"Retrieves the model's losses.\n\n        Will only include losses that are either\n        inconditional, or conditional on inputs to this model\n        (e.g. will not include losses that depend on tensors\n        that aren't inputs to this model).\n\n        # Returns\n            A list of loss tensors.\n        \"\"\"\n        losses = []\n        # Retrieve losses for all internal layers.\n        for layer in self.layers:\n            if hasattr(layer, 'losses'):\n                # Collect losses that are dependent on inputs\n                # that are part of the model.\n                for node_index, node in enumerate(layer._inbound_nodes):\n                    node_key = self._node_key(layer, node_index)\n                    if node_key in self._container_nodes:\n                        # The model owns this layer node.\n                        inputs = node.input_tensors\n                        losses += layer.get_losses_for(inputs)\n                # Collect unconditional losses.\n                losses += layer.get_losses_for(None)\n        # Add any potential unconditional model-level loss.\n        losses += self.get_losses_for(None)\n\n        unique_tensors = list(set(x for x in losses if not isinstance(x, (float, int))))\n        non_tensors = [x for x in losses if isinstance(x, (float, int))]\n        return unique_tensors + non_tensors",
        "begin_line": 1921,
        "end_line": 1951,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006365372374283895,
            "pseudo_dstar_susp": 0.00186219739292365,
            "pseudo_tarantula_susp": 0.00039032006245121,
            "pseudo_op2_susp": 0.00186219739292365,
            "pseudo_barinel_susp": 0.00039032006245121
        }
    },
    {
        "name": "keras.engine.topology.Container.uses_learning_phase#1954",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.uses_learning_phase(self)",
        "snippet": "    def uses_learning_phase(self):\n        return any([x._uses_learning_phase for x in self.outputs])",
        "begin_line": 1954,
        "end_line": 1955,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006261740763932373,
            "pseudo_dstar_susp": 0.0018450184501845018,
            "pseudo_tarantula_susp": 0.0003795066413662239,
            "pseudo_op2_susp": 0.0018450184501845018,
            "pseudo_barinel_susp": 0.0003795066413662239
        }
    },
    {
        "name": "keras.engine.topology.Container.stateful#1958",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.stateful(self)",
        "snippet": "    def stateful(self):\n        return any([(hasattr(layer, 'stateful') and layer.stateful) for layer in self.layers])",
        "begin_line": 1958,
        "end_line": 1959,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003745318352059925,
            "pseudo_dstar_susp": 0.0008424599831508003,
            "pseudo_tarantula_susp": 0.0003487966515521451,
            "pseudo_op2_susp": 0.0008424599831508003,
            "pseudo_barinel_susp": 0.0003487966515521451
        }
    },
    {
        "name": "keras.engine.topology.Container.reset_states#1961",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.reset_states(self)",
        "snippet": "    def reset_states(self):\n        for layer in self.layers:\n            if hasattr(layer, 'reset_states') and getattr(layer, 'stateful', False):\n                layer.reset_states()",
        "begin_line": 1961,
        "end_line": 1964,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Container.state_updates#1967",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.state_updates(self)",
        "snippet": "    def state_updates(self):\n        \"\"\"Returns the `updates` from all layers that are stateful.\n\n        This is useful for separating training updates and\n        state updates, e.g. when we need to update a layer's internal state\n        during prediction.\n\n        # Returns\n            A list of update ops.\n        \"\"\"\n        state_updates = []\n        for layer in self.layers:\n            if layer.stateful:\n                state_updates += layer.updates\n        return state_updates",
        "begin_line": 1967,
        "end_line": 1981,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036643459142543056,
            "pseudo_dstar_susp": 0.00036643459142543056,
            "pseudo_tarantula_susp": 0.0003675119441381845,
            "pseudo_op2_susp": 0.00036643459142543056,
            "pseudo_barinel_susp": 0.0003675119441381845
        }
    },
    {
        "name": "keras.engine.topology.Container.trainable_weights#1984",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        weights = []\n        for layer in self.layers:\n            weights += layer.trainable_weights\n        return weights",
        "begin_line": 1984,
        "end_line": 1990,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006565988181221273,
            "pseudo_dstar_susp": 0.001589825119236884,
            "pseudo_tarantula_susp": 0.0005627462014631402,
            "pseudo_op2_susp": 0.001589825119236884,
            "pseudo_barinel_susp": 0.0005627462014631402
        }
    },
    {
        "name": "keras.engine.topology.Container.non_trainable_weights#1993",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        weights = []\n        for layer in self.layers:\n            weights += layer.non_trainable_weights\n        if not self.trainable:\n            trainable_weights = []\n            for layer in self.layers:\n                trainable_weights += layer.trainable_weights\n            return trainable_weights + weights\n        return weights",
        "begin_line": 1993,
        "end_line": 2002,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004177109440267335,
            "pseudo_dstar_susp": 0.00041597337770382697,
            "pseudo_tarantula_susp": 0.000643915003219575,
            "pseudo_op2_susp": 0.00041597337770382697,
            "pseudo_barinel_susp": 0.000643915003219575
        }
    },
    {
        "name": "keras.engine.topology.Container.get_weights#2004",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.get_weights(self)",
        "snippet": "    def get_weights(self):\n        \"\"\"Retrieves the weights of the model.\n\n        # Returns\n            A flat list of Numpy arrays.\n        \"\"\"\n        weights = []\n        for layer in self.layers:\n            weights += layer.weights\n        return K.batch_get_value(weights)",
        "begin_line": 2004,
        "end_line": 2013,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.49288176232579e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Container.set_weights#2015",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the model.\n\n        # Arguments\n            weights: A list of Numpy arrays with shapes and types matching\n                the output of `model.get_weights()`.\n        \"\"\"\n        tuples = []\n        for layer in self.layers:\n            num_param = len(layer.weights)\n            layer_weights = weights[:num_param]\n            for sw, w in zip(layer.weights, layer_weights):\n                tuples.append((sw, w))\n            weights = weights[num_param:]\n        K.batch_set_value(tuples)",
        "begin_line": 2015,
        "end_line": 2029,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.525586995785671e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Container.input_spec#2032",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.input_spec(self)",
        "snippet": "    def input_spec(self):\n        \"\"\"Gets the model's input specs.\n\n        # Returns\n            A list of `InputSpec` instances (one per input to the model)\n                or a single instance if the model has only one input.\n        \"\"\"\n        specs = []\n        for layer in getattr(self, 'input_layers', []):\n            if layer.input_spec is None:\n                specs.append(None)\n            else:\n                if not isinstance(layer.input_spec, list):\n                    raise TypeError('Layer ' + layer.name +\n                                    ' has an input_spec attribute that '\n                                    'is not a list. We expect a list. '\n                                    'Found input_spec = ' +\n                                    str(layer.input_spec))\n                specs += layer.input_spec\n        if len(specs) == 1:\n            return specs[0]\n        return specs",
        "begin_line": 2032,
        "end_line": 2053,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002506265664160401,
            "pseudo_dstar_susp": 0.0006596306068601583,
            "pseudo_tarantula_susp": 0.0029585798816568047,
            "pseudo_op2_susp": 0.0006596306068601583,
            "pseudo_barinel_susp": 0.0029585798816568047
        }
    },
    {
        "name": "keras.engine.topology.Container.call#2055",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        \"\"\"Calls the model on new inputs.\n\n        In this case `call` just reapplies\n        all ops in the graph to the new inputs\n        (e.g. build a new computational graph from the provided inputs).\n\n        A model is callable on non-Keras tensors.\n\n        # Arguments\n            inputs: A tensor or list of tensors.\n            mask: A mask or list of masks. A mask can be\n                either a tensor or None (no mask).\n\n        # Returns\n            A tensor if there is a single output, or\n            a list of tensors if there are more than one outputs.\n        \"\"\"\n        inputs = _to_list(inputs)\n        if mask is None:\n            masks = [None for _ in range(len(inputs))]\n        else:\n            masks = _to_list(mask)\n        cache_key = ','.join([str(id(x)) for x in inputs])\n        cache_key += '_' + ','.join([str(id(x)) for x in masks])\n        if cache_key in self._output_tensor_cache:\n            return self._output_tensor_cache[cache_key]\n        else:\n            output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n            return output_tensors",
        "begin_line": 2055,
        "end_line": 2084,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0011574074074074073,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0011574074074074073,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.engine.topology.Container.compute_mask#2086",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.compute_mask(self, inputs, mask)",
        "snippet": "    def compute_mask(self, inputs, mask):\n        inputs = _to_list(inputs)\n        if mask is None:\n            masks = [None for _ in range(len(inputs))]\n        else:\n            masks = _to_list(mask)\n        cache_key = ','.join([str(id(x)) for x in inputs])\n        cache_key += '_' + ','.join([str(id(x)) for x in masks])\n        if cache_key in self._output_mask_cache:\n            return self._output_mask_cache[cache_key]\n        else:\n            _, output_masks, _ = self.run_internal_graph(inputs, masks)\n            return output_masks",
        "begin_line": 2086,
        "end_line": 2098,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0045662100456621,
            "pseudo_dstar_susp": 0.017857142857142856,
            "pseudo_tarantula_susp": 0.005050505050505051,
            "pseudo_op2_susp": 0.017857142857142856,
            "pseudo_barinel_susp": 0.005050505050505051
        }
    },
    {
        "name": "keras.engine.topology.Container.compute_output_shape#2100",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        input_shapes = _to_list(input_shape)\n        if len(input_shapes) != len(self.input_layers):\n            raise ValueError('Invalid input_shape argument ' +\n                             str(input_shape) + ': model has ' +\n                             str(len(self.input_layers)) + ' tensor inputs.')\n\n        cache_key = ','.join([str(x) for x in input_shapes])\n        if cache_key in self._output_shape_cache:\n            output_shapes = self._output_shape_cache[cache_key]\n            if isinstance(output_shapes, list) and len(output_shapes) == 1:\n                return output_shapes[0]\n            return output_shapes\n        else:\n            # Bad luck, we have to run the graph manually.\n            layers_to_output_shapes = {}\n            for i in range(len(input_shapes)):\n                layer = self.input_layers[i]\n                input_shape = input_shapes[i]\n                # It's an input layer: compute_output_shape is identity,\n                # and there is only one node and one tensor output.\n                shape_key = layer.name + '_0_0'\n                layers_to_output_shapes[shape_key] = input_shape\n\n            depth_keys = list(self._nodes_by_depth.keys())\n            depth_keys.sort(reverse=True)\n            # Iterate over nodes, by depth level.\n            if len(depth_keys) > 1:\n                for depth in depth_keys:\n                    nodes = self._nodes_by_depth[depth]\n                    for node in nodes:\n                        # This is always a single layer, never a list.\n                        layer = node.outbound_layer\n                        if layer in self.input_layers:\n                            # We've already covered the input layers\n                            # a few lines above.\n                            continue\n                        # Potentially redundant list,\n                        # same size of node.input_tensors.\n                        input_shapes = []\n                        for j in range(len(node.inbound_layers)):\n                            inbound_layer = node.inbound_layers[j]\n                            node_index = node.node_indices[j]\n                            tensor_index = node.tensor_indices[j]\n                            shape_key = inbound_layer.name + '_%s_%s' % (node_index, tensor_index)\n                            input_shape = layers_to_output_shapes[shape_key]\n                            input_shapes.append(input_shape)\n\n                        if len(input_shapes) == 1:\n                            output_shape = layer.compute_output_shape(input_shapes[0])\n                        else:\n                            output_shape = layer.compute_output_shape(input_shapes)\n\n                        output_shapes = _to_list(output_shape)\n                        node_index = layer._inbound_nodes.index(node)\n                        for j in range(len(output_shapes)):\n                            shape_key = layer.name + '_%s_%s' % (node_index, j)\n                            layers_to_output_shapes[shape_key] = output_shapes[j]\n\n            # Read final output shapes from layers_to_output_shapes.\n            output_shapes = []\n            output_shape_keys = []\n            for i in range(len(self.output_layers)):\n                layer = self.output_layers[i]\n                node_index = self.output_layers_node_indices[i]\n                tensor_index = self.output_layers_tensor_indices[i]\n                shape_key = layer.name + '_%s_%s' % (node_index, tensor_index)\n                output_shape_keys.append(shape_key)\n\n            for i, key in enumerate(output_shape_keys):\n                assert key in layers_to_output_shapes\n                output_shapes.append(layers_to_output_shapes[key])\n            # Store in cache.\n            self._output_shape_cache[cache_key] = output_shapes\n            if isinstance(output_shapes, list) and len(output_shapes) == 1:\n                return output_shapes[0]\n            return output_shapes",
        "begin_line": 2100,
        "end_line": 2176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.009009009009009009,
            "pseudo_dstar_susp": 0.0011441647597254005,
            "pseudo_tarantula_susp": 0.009259259259259259,
            "pseudo_op2_susp": 0.0011441647597254005,
            "pseudo_barinel_susp": 0.009259259259259259
        }
    },
    {
        "name": "keras.engine.topology.Container.run_internal_graph#2178",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.run_internal_graph(self, inputs, masks=None)",
        "snippet": "    def run_internal_graph(self, inputs, masks=None):\n        \"\"\"Computes output tensors for new inputs.\n\n        # Note:\n            - Expects `inputs` to be a list (potentially with 1 element).\n            - Can be run on non-Keras tensors.\n\n        # Arguments\n            inputs: List of tensors\n            masks: List of masks (tensors or None).\n\n        # Returns\n            Three lists: output_tensors, output_masks, output_shapes\n        \"\"\"\n        if masks is None:\n            masks = [None for _ in range(len(inputs))]\n\n        # Dictionary mapping reference tensors to tuples\n        # (computed tensor, compute mask)\n        # we assume a 1:1 mapping from tensor to mask\n        # TODO: raise exception when a `.compute_mask()` call\n        # does not return a list the same size as `call`\n        tensor_map = {}\n        for x, y, mask in zip(self.inputs, inputs, masks):\n            tensor_map[str(id(x))] = (y, mask)\n\n        depth_keys = list(self._nodes_by_depth.keys())\n        depth_keys.sort(reverse=True)\n        for depth in depth_keys:\n            nodes = self._nodes_by_depth[depth]\n            for node in nodes:\n                # This is always a single layer, never a list.\n                layer = node.outbound_layer\n\n                reference_input_tensors = node.input_tensors\n                reference_output_tensors = node.output_tensors\n\n                # If all previous input tensors are available in tensor_map,\n                # then call node.inbound_layer on them.\n                computed_data = []  # List of tuples (input, mask).\n                for x in reference_input_tensors:\n                    if str(id(x)) in tensor_map:\n                        computed_data.append(tensor_map[str(id(x))])\n\n                if len(computed_data) == len(reference_input_tensors):\n                    # call layer\n                    with K.name_scope(layer.name):\n                        if node.arguments:\n                            kwargs = node.arguments\n                        else:\n                            kwargs = {}\n                        if len(computed_data) == 1:\n                            computed_tensor, computed_mask = computed_data[0]\n                            if has_arg(layer.call, 'mask'):\n                                if 'mask' not in kwargs:\n                                    kwargs['mask'] = computed_mask\n                            output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n                            output_masks = _to_list(layer.compute_mask(computed_tensor,\n                                                                       computed_mask))\n                            computed_tensors = [computed_tensor]\n                            computed_masks = [computed_mask]\n                        else:\n                            computed_tensors = [x[0] for x in computed_data]\n                            computed_masks = [x[1] for x in computed_data]\n                            if has_arg(layer.call, 'mask'):\n                                if 'mask' not in kwargs:\n                                    kwargs['mask'] = computed_masks\n                            output_tensors = _to_list(layer.call(computed_tensors, **kwargs))\n                            output_masks = _to_list(layer.compute_mask(computed_tensors,\n                                                                       computed_masks))\n\n                        # Apply activity regularizer if any:\n                        if hasattr(layer, 'activity_regularizer') and layer.activity_regularizer is not None:\n                            regularization_losses = [layer.activity_regularizer(x) for x in output_tensors]\n                            layer.add_loss(regularization_losses, computed_tensors)\n\n                    # Update model updates and losses:\n                    # Keep track of updates that depend on the inputs\n                    # (e.g. BN updates).\n                    self.add_update(layer.get_updates_for(computed_tensors), inputs)\n                    # Keep track of unconditional updates (e.g. a counter).\n                    self.add_update(layer.get_updates_for(None), None)\n                    # Keep track of losses that depend on the inputs\n                    # (e.g. activity regularizers).\n                    self.add_loss(layer.get_losses_for(computed_tensors), inputs)\n                    # Keep track of unconditional losses\n                    # (e.g. weight regularizers).\n                    self.add_loss(layer.get_losses_for(None), None)\n\n                    # Update _keras_shape.\n                    if all([hasattr(x, '_keras_shape') for x in computed_tensors]):\n                        if len(computed_tensors) == 1:\n                            shapes = _to_list(layer.compute_output_shape(computed_tensors[0]._keras_shape))\n                            uses_learning_phase = computed_tensors[0]._uses_learning_phase\n                        else:\n                            shapes = _to_list(layer.compute_output_shape([x._keras_shape for x in computed_tensors]))\n                            uses_learning_phase = any([x._uses_learning_phase for x in computed_tensors])\n                        for x, s in zip(output_tensors, shapes):\n                            x._keras_shape = s\n                            x._uses_learning_phase = getattr(x, '_uses_learning_phase', False) or uses_learning_phase\n\n                    # Update tensor_map.\n                    for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):\n                        tensor_map[str(id(x))] = (y, mask)\n\n        output_tensors = []\n        output_masks = []\n        output_shapes = []\n        for x in self.outputs:\n            assert str(id(x)) in tensor_map, 'Could not compute output ' + str(x)\n            tensor, mask = tensor_map[str(id(x))]\n            if hasattr(tensor, '_keras_shape') and output_shapes is not None:\n                shape = tensor._keras_shape\n                output_shapes.append(shape)\n            else:\n                output_shapes = None\n            output_tensors.append(tensor)\n            output_masks.append(mask)\n\n        # Update cache;\n        # keys are based on ids on input tensors and inputs masks.\n        cache_key = ','.join([str(id(x)) for x in inputs])\n        cache_key += '_' + ','.join([str(id(x)) for x in masks])\n\n        if len(output_tensors) == 1:\n            output_tensors = output_tensors[0]\n            self._output_tensor_cache[cache_key] = output_tensors\n        else:\n            self._output_tensor_cache[cache_key] = output_tensors\n\n        if len(output_masks) == 1:\n            output_masks = output_masks[0]\n            self._output_mask_cache[cache_key] = output_masks\n        else:\n            self._output_mask_cache[cache_key] = output_masks\n\n        if output_shapes is not None:\n            input_shapes = [x._keras_shape for x in inputs]\n            cache_key = ','.join([str(x) for x in input_shapes])\n            if len(output_shapes) == 1:\n                output_shapes = output_shapes[0]\n                self._output_shape_cache[cache_key] = output_shapes\n            else:\n                self._output_shape_cache[cache_key] = output_shapes\n        return output_tensors, output_masks, output_shapes",
        "begin_line": 2178,
        "end_line": 2322,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.001184834123222749,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.001184834123222749,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.engine.topology.Container.get_config#2324",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'name': self.name,\n        }\n\n        # Build a map from a layer unique name (self._node_key)\n        # to the index of the nodes that are saved in the config.\n        # Only nodes in container_nodes are saved.\n        node_conversion_map = {}\n        for layer in self.layers:\n            if issubclass(layer.__class__, Container):\n                # Containers start with a pre-existing node\n                # linking their input to output.\n                kept_nodes = 1\n            else:\n                kept_nodes = 0\n            for original_node_index, node in enumerate(layer._inbound_nodes):\n                node_key = self._node_key(layer, original_node_index)\n                if node_key in self._container_nodes:\n                    # i.e. we mark it to be saved\n                    node_conversion_map[node_key] = kept_nodes\n                    kept_nodes += 1\n\n        # serialize and save the layers in layer_configs\n        layer_configs = []\n        for layer in self.layers:  # From the earliest layers on.\n            layer_class_name = layer.__class__.__name__\n            layer_config = layer.get_config()\n            filtered_inbound_nodes = []\n            for original_node_index, node in enumerate(layer._inbound_nodes):\n                node_key = self._node_key(layer, original_node_index)\n                if node_key in self._container_nodes:\n                    # The node is relevant to the model:\n                    # add to filtered_inbound_nodes.\n                    if node.arguments:\n                        try:\n                            json.dumps(node.arguments)\n                            kwargs = node.arguments\n                        except TypeError:\n                            warnings.warn(\n                                'Layer ' + layer.name +\n                                ' was passed non-serializable keyword arguments: ' +\n                                str(node.arguments) + '. They will not be included '\n                                'in the serialized model (and thus will be missing '\n                                'at deserialization time).')\n                            kwargs = {}\n                    else:\n                        kwargs = {}\n                    if node.inbound_layers:\n                        node_data = []\n                        for i in range(len(node.inbound_layers)):\n                            inbound_layer = node.inbound_layers[i]\n                            node_index = node.node_indices[i]\n                            tensor_index = node.tensor_indices[i]\n\n                            new_node_index = node_conversion_map.get(\n                                self._node_key(inbound_layer, node_index), 0)\n                            node_data.append([inbound_layer.name,\n                                              new_node_index,\n                                              tensor_index,\n                                              kwargs])\n                        filtered_inbound_nodes.append(node_data)\n            layer_configs.append({\n                'name': layer.name,\n                'class_name': layer_class_name,\n                'config': layer_config,\n                'inbound_nodes': filtered_inbound_nodes,\n            })\n        config['layers'] = layer_configs\n\n        # Gather info about inputs and outputs.\n        model_inputs = []\n        for i in range(len(self.input_layers)):\n            layer = self.input_layers[i]\n            node_index = self.input_layers_node_indices[i]\n\n            node_key = self._node_key(layer, node_index)\n            if node_key not in self._container_nodes:\n                continue\n            new_node_index = node_conversion_map[node_key]\n            tensor_index = self.input_layers_tensor_indices[i]\n            model_inputs.append([layer.name, new_node_index, tensor_index])\n        config['input_layers'] = model_inputs\n        model_outputs = []\n        for i in range(len(self.output_layers)):\n            layer = self.output_layers[i]\n            node_index = self.output_layers_node_indices[i]\n\n            node_key = self._node_key(layer, node_index)\n            if node_key not in self._container_nodes:\n                continue\n            new_node_index = node_conversion_map[node_key]\n            tensor_index = self.output_layers_tensor_indices[i]\n            model_outputs.append([layer.name, new_node_index, tensor_index])\n        config['output_layers'] = model_outputs\n        return copy.deepcopy(config)",
        "begin_line": 2324,
        "end_line": 2419,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006329113924050633,
            "pseudo_dstar_susp": 0.0007513148009015778,
            "pseudo_tarantula_susp": 0.006666666666666667,
            "pseudo_op2_susp": 0.0007513148009015778,
            "pseudo_barinel_susp": 0.006666666666666667
        }
    },
    {
        "name": "keras.engine.topology.Container.from_config#2422",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        \"\"\"Instantiates a Model from its config (output of `get_config()`).\n\n        # Arguments\n            config: Model config dictionary.\n            custom_objects: Optional dictionary mapping names\n                (strings) to custom classes or functions to be\n                considered during deserialization.\n\n        # Returns\n            A model instance.\n\n        # Raises\n            ValueError: In case of improperly formatted config dict.\n        \"\"\"\n        # Layer instances created during\n        # the graph reconstruction process\n        created_layers = {}\n\n        # Dictionary mapping layer instances to\n        # node data that specifies a layer call.\n        # It acts as a queue that maintains any unprocessed\n        # layer call until it becomes possible to process it\n        # (i.e. until the input tensors to the call all exist).\n        unprocessed_nodes = {}\n\n        def add_unprocessed_node(layer, node_data):\n            if layer not in unprocessed_nodes:\n                unprocessed_nodes[layer] = [node_data]\n            else:\n                unprocessed_nodes[layer].append(node_data)\n\n        def process_node(layer, node_data):\n            input_tensors = []\n            for input_data in node_data:\n                inbound_layer_name = input_data[0]\n                inbound_node_index = input_data[1]\n                inbound_tensor_index = input_data[2]\n                if len(input_data) == 3:\n                    kwargs = {}\n                elif len(input_data) == 4:\n                    kwargs = input_data[3]\n                else:\n                    raise ValueError('Improperly formatted model config.')\n                if inbound_layer_name not in created_layers:\n                    add_unprocessed_node(layer, node_data)\n                    return\n                inbound_layer = created_layers[inbound_layer_name]\n                if len(inbound_layer._inbound_nodes) <= inbound_node_index:\n                    add_unprocessed_node(layer, node_data)\n                    return\n                inbound_node = inbound_layer._inbound_nodes[inbound_node_index]\n                input_tensors.append(inbound_node.output_tensors[inbound_tensor_index])\n            # Call layer on its inputs, thus creating the node\n            # and building the layer if needed.\n            if input_tensors:\n                if len(input_tensors) == 1:\n                    layer(input_tensors[0], **kwargs)\n                else:\n                    layer(input_tensors, **kwargs)\n\n        def process_layer(layer_data):\n            \"\"\"Deserializes a layer, then call it on appropriate inputs.\n\n            # Arguments\n                layer_data: layer config dict.\n\n            # Raises\n                ValueError: In case of improperly formatted `layer_data` dict.\n            \"\"\"\n            layer_name = layer_data['name']\n\n            # Instantiate layer.\n            from ..layers import deserialize as deserialize_layer\n\n            layer = deserialize_layer(layer_data,\n                                      custom_objects=custom_objects)\n            created_layers[layer_name] = layer\n\n            # Gather layer inputs.\n            inbound_nodes_data = layer_data['inbound_nodes']\n            for node_data in inbound_nodes_data:\n                # We don't process nodes (i.e. make layer calls)\n                # on the fly because the inbound node may not yet exist,\n                # in case of layer shared at different topological depths\n                # (e.g. a model such as A(B(A(B(x)))))\n                add_unprocessed_node(layer, node_data)\n\n        # First, we create all layers and enqueue nodes to be processed\n        for layer_data in config['layers']:\n            process_layer(layer_data)\n        # Then we process nodes in order of layer depth.\n        # Nodes that cannot yet be processed (if the inbound node\n        # does not yet exist) are re-enqueued, and the process\n        # is repeated until all nodes are processed.\n        while unprocessed_nodes:\n            for layer_data in config['layers']:\n                layer = created_layers[layer_data['name']]\n                if layer in unprocessed_nodes:\n                    for node_data in unprocessed_nodes.pop(layer):\n                        process_node(layer, node_data)\n\n        name = config.get('name')\n        input_tensors = []\n        output_tensors = []\n        for layer_data in config['input_layers']:\n            layer_name, node_index, tensor_index = layer_data\n            assert layer_name in created_layers\n            layer = created_layers[layer_name]\n            layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n            input_tensors.append(layer_output_tensors[tensor_index])\n        for layer_data in config['output_layers']:\n            layer_name, node_index, tensor_index = layer_data\n            assert layer_name in created_layers\n            layer = created_layers[layer_name]\n            layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n            output_tensors.append(layer_output_tensors[tensor_index])\n        return cls(inputs=input_tensors, outputs=output_tensors, name=name)",
        "begin_line": 2422,
        "end_line": 2539,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00040535062829347385,
            "pseudo_dstar_susp": 0.00040404040404040404,
            "pseudo_tarantula_susp": 0.0005243838489774515,
            "pseudo_op2_susp": 0.00040404040404040404,
            "pseudo_barinel_susp": 0.0005243838489774515
        }
    },
    {
        "name": "keras.engine.topology.Container.add_unprocessed_node#2448",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.add_unprocessed_node(layer, node_data)",
        "snippet": "        def add_unprocessed_node(layer, node_data):\n            if layer not in unprocessed_nodes:\n                unprocessed_nodes[layer] = [node_data]\n            else:\n                unprocessed_nodes[layer].append(node_data)",
        "begin_line": 2448,
        "end_line": 2452,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0045662100456621,
            "pseudo_dstar_susp": 0.0011111111111111111,
            "pseudo_tarantula_susp": 0.005050505050505051,
            "pseudo_op2_susp": 0.0011111111111111111,
            "pseudo_barinel_susp": 0.005050505050505051
        }
    },
    {
        "name": "keras.engine.topology.Container.process_node#2454",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.process_node(layer, node_data)",
        "snippet": "        def process_node(layer, node_data):\n            input_tensors = []\n            for input_data in node_data:\n                inbound_layer_name = input_data[0]\n                inbound_node_index = input_data[1]\n                inbound_tensor_index = input_data[2]\n                if len(input_data) == 3:\n                    kwargs = {}\n                elif len(input_data) == 4:\n                    kwargs = input_data[3]\n                else:\n                    raise ValueError('Improperly formatted model config.')\n                if inbound_layer_name not in created_layers:\n                    add_unprocessed_node(layer, node_data)\n                    return\n                inbound_layer = created_layers[inbound_layer_name]\n                if len(inbound_layer._inbound_nodes) <= inbound_node_index:\n                    add_unprocessed_node(layer, node_data)\n                    return\n                inbound_node = inbound_layer._inbound_nodes[inbound_node_index]\n                input_tensors.append(inbound_node.output_tensors[inbound_tensor_index])\n            # Call layer on its inputs, thus creating the node\n            # and building the layer if needed.\n            if input_tensors:\n                if len(input_tensors) == 1:\n                    layer(input_tensors[0], **kwargs)\n                else:\n                    layer(input_tensors, **kwargs)",
        "begin_line": 2454,
        "end_line": 2481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027397260273972603,
            "pseudo_dstar_susp": 0.0011111111111111111,
            "pseudo_tarantula_susp": 0.003257328990228013,
            "pseudo_op2_susp": 0.0011111111111111111,
            "pseudo_barinel_susp": 0.003257328990228013
        }
    },
    {
        "name": "keras.engine.topology.Container.process_layer#2483",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.process_layer(layer_data)",
        "snippet": "        def process_layer(layer_data):\n            \"\"\"Deserializes a layer, then call it on appropriate inputs.\n\n            # Arguments\n                layer_data: layer config dict.\n\n            # Raises\n                ValueError: In case of improperly formatted `layer_data` dict.\n            \"\"\"\n            layer_name = layer_data['name']\n\n            # Instantiate layer.\n            from ..layers import deserialize as deserialize_layer\n\n            layer = deserialize_layer(layer_data,\n                                      custom_objects=custom_objects)\n            created_layers[layer_name] = layer\n\n            # Gather layer inputs.\n            inbound_nodes_data = layer_data['inbound_nodes']\n            for node_data in inbound_nodes_data:\n                # We don't process nodes (i.e. make layer calls)\n                # on the fly because the inbound node may not yet exist,\n                # in case of layer shared at different topological depths\n                # (e.g. a model such as A(B(A(B(x)))))\n                add_unprocessed_node(layer, node_data)",
        "begin_line": 2483,
        "end_line": 2508,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005350454788657035,
            "pseudo_dstar_susp": 0.0011111111111111111,
            "pseudo_tarantula_susp": 0.0005243838489774515,
            "pseudo_op2_susp": 0.0011111111111111111,
            "pseudo_barinel_susp": 0.0005243838489774515
        }
    },
    {
        "name": "keras.engine.topology.Container.save#2541",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.save(self, filepath, overwrite=True, include_optimizer=True)",
        "snippet": "    def save(self, filepath, overwrite=True, include_optimizer=True):\n        \"\"\"Saves the model to a single HDF5 file.\n\n        The savefile includes:\n            - The model architecture, allowing to re-instantiate the model.\n            - The model weights.\n            - The state of the optimizer, allowing to resume training\n                exactly where you left off.\n\n        This allows you to save the entirety of the state of a model\n        in a single file.\n\n        Saved models can be reinstantiated via `keras.models.load_model`.\n        The model returned by `load_model`\n        is a compiled model ready to be used (unless the saved model\n        was never compiled in the first place).\n\n        # Arguments\n            filepath: String, path to the file to save the weights to.\n            overwrite: Whether to silently overwrite any existing file at the\n                target location, or provide the user with a manual prompt.\n            include_optimizer: If True, save optimizer's state together.\n\n        # Example\n\n        ```python\n        from keras.models import load_model\n\n        model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n        del model  # deletes the existing model\n\n        # returns a compiled model\n        # identical to the previous one\n        model = load_model('my_model.h5')\n        ```\n        \"\"\"\n        from ..models import save_model\n        save_model(self, filepath, overwrite, include_optimizer)",
        "begin_line": 2541,
        "end_line": 2578,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Container.save_weights#2580",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.save_weights(self, filepath, overwrite=True)",
        "snippet": "    def save_weights(self, filepath, overwrite=True):\n        \"\"\"Dumps all layer weights to a HDF5 file.\n\n        The weight file has:\n            - `layer_names` (attribute), a list of strings\n                (ordered names of model layers).\n            - For every layer, a `group` named `layer.name`\n                - For every such layer group, a group attribute `weight_names`,\n                    a list of strings\n                    (ordered names of weights tensor of the layer).\n                - For every weight in the layer, a dataset\n                    storing the weight value, named after the weight tensor.\n\n        # Arguments\n            filepath: String, path to the file to save the weights to.\n            overwrite: Whether to silently overwrite any existing file at the\n                target location, or provide the user with a manual prompt.\n\n        # Raises\n            ImportError: If h5py is not available.\n        \"\"\"\n        if h5py is None:\n            raise ImportError('`save_weights` requires h5py.')\n        # If file exists and should not be overwritten:\n        if not overwrite and os.path.isfile(filepath):\n            proceed = ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n        with h5py.File(filepath, 'w') as f:\n            save_weights_to_hdf5_group(f, self.layers)\n            f.flush()",
        "begin_line": 2580,
        "end_line": 2610,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Container.load_weights#2612",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False)",
        "snippet": "    def load_weights(self, filepath, by_name=False,\n                     skip_mismatch=False, reshape=False):\n        \"\"\"Loads all layer weights from a HDF5 save file.\n\n        If `by_name` is False (default) weights are loaded\n        based on the network's topology, meaning the architecture\n        should be the same as when the weights were saved.\n        Note that layers that don't have weights are not taken\n        into account in the topological ordering, so adding or\n        removing layers is fine as long as they don't have weights.\n\n        If `by_name` is True, weights are loaded into layers\n        only if they share the same name. This is useful\n        for fine-tuning or transfer-learning models where\n        some of the layers have changed.\n\n        # Arguments\n            filepath: String, path to the weights file to load.\n            by_name: Boolean, whether to load weights by name\n                or by topological order.\n            skip_mismatch: Boolean, whether to skip loading of layers\n                where there is a mismatch in the number of weights,\n                or a mismatch in the shape of the weight\n                (only valid when `by_name`=True).\n            reshape: Reshape weights to fit the layer when the correct number\n                of weight arrays is present but their shape does not match.\n\n\n        # Raises\n            ImportError: If h5py is not available.\n        \"\"\"\n        if h5py is None:\n            raise ImportError('`load_weights` requires h5py.')\n        with h5py.File(filepath, mode='r') as f:\n            if 'layer_names' not in f.attrs and 'model_weights' in f:\n                f = f['model_weights']\n            if by_name:\n                load_weights_from_hdf5_group_by_name(\n                    f, self.layers, skip_mismatch=skip_mismatch,\n                    reshape=reshape)\n            else:\n                load_weights_from_hdf5_group(\n                    f, self.layers, reshape=reshape)",
        "begin_line": 2612,
        "end_line": 2654,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.Container._updated_config#2656",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container._updated_config(self)",
        "snippet": "    def _updated_config(self):\n        \"\"\"Util hared between different serialization methods.\n\n        # Returns\n            Model config with Keras version information added.\n        \"\"\"\n        from .. import __version__ as keras_version\n\n        config = self.get_config()\n        model_config = {\n            'class_name': self.__class__.__name__,\n            'config': config,\n            'keras_version': keras_version,\n            'backend': K.backend()\n        }\n        return model_config",
        "begin_line": 2656,
        "end_line": 2671,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0019083969465648854,
            "pseudo_dstar_susp": 0.0006361323155216285,
            "pseudo_tarantula_susp": 0.002531645569620253,
            "pseudo_op2_susp": 0.0006361323155216285,
            "pseudo_barinel_susp": 0.002531645569620253
        }
    },
    {
        "name": "keras.engine.topology.Container.to_json#2673",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.to_json(self, **kwargs)",
        "snippet": "    def to_json(self, **kwargs):\n        \"\"\"Returns a JSON string containing the network configuration.\n\n        To load a network from a JSON save file, use\n        `keras.models.model_from_json(json_string, custom_objects={})`.\n\n        # Arguments\n            **kwargs: Additional keyword arguments\n                to be passed to `json.dumps()`.\n\n        # Returns\n            A JSON string.\n        \"\"\"\n        def get_json_type(obj):\n            # If obj is any numpy type\n            if type(obj).__module__ == np.__name__:\n                return obj.item()\n\n            # If obj is a python 'type'\n            if type(obj).__name__ == type.__name__:\n                return obj.__name__\n\n            raise TypeError('Not JSON Serializable:', obj)\n\n        model_config = self._updated_config()\n        return json.dumps(model_config, default=get_json_type, **kwargs)",
        "begin_line": 2673,
        "end_line": 2698,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0019083969465648854,
            "pseudo_dstar_susp": 0.0006361323155216285,
            "pseudo_tarantula_susp": 0.002531645569620253,
            "pseudo_op2_susp": 0.0006361323155216285,
            "pseudo_barinel_susp": 0.002531645569620253
        }
    },
    {
        "name": "keras.engine.topology.Container.get_json_type#2686",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.get_json_type(obj)",
        "snippet": "        def get_json_type(obj):\n            # If obj is any numpy type\n            if type(obj).__module__ == np.__name__:\n                return obj.item()\n\n            # If obj is a python 'type'\n            if type(obj).__name__ == type.__name__:\n                return obj.__name__\n\n            raise TypeError('Not JSON Serializable:', obj)",
        "begin_line": 2686,
        "end_line": 2695,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0019083969465648854,
            "pseudo_dstar_susp": 0.0006361323155216285,
            "pseudo_tarantula_susp": 0.002531645569620253,
            "pseudo_op2_susp": 0.0006361323155216285,
            "pseudo_barinel_susp": 0.002531645569620253
        }
    },
    {
        "name": "keras.engine.topology.Container.to_yaml#2700",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.to_yaml(self, **kwargs)",
        "snippet": "    def to_yaml(self, **kwargs):\n        \"\"\"Returns a yaml string containing the network configuration.\n\n        To load a network from a yaml save file, use\n        `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n\n        `custom_objects` should be a dictionary mapping\n        the names of custom losses / layers / etc to the corresponding\n        functions / classes.\n\n        # Arguments\n            **kwargs: Additional keyword arguments\n                to be passed to `yaml.dump()`.\n\n        # Returns\n            A YAML string.\n        \"\"\"\n        return yaml.dump(self._updated_config(), **kwargs)",
        "begin_line": 2700,
        "end_line": 2717,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027397260273972603,
            "pseudo_dstar_susp": 0.0006734006734006734,
            "pseudo_tarantula_susp": 0.003257328990228013,
            "pseudo_op2_susp": 0.0006734006734006734,
            "pseudo_barinel_susp": 0.003257328990228013
        }
    },
    {
        "name": "keras.engine.topology.Container.summary#2719",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.summary(self, line_length=None, positions=None, print_fn=None)",
        "snippet": "    def summary(self, line_length=None, positions=None, print_fn=None):\n        \"\"\"Prints a string summary of the network.\n\n        # Arguments\n            line_length: Total length of printed lines\n                (e.g. set this to adapt the display to different\n                terminal window sizes).\n            positions: Relative or absolute positions of log elements\n                in each line. If not provided,\n                defaults to `[.33, .55, .67, 1.]`.\n            print_fn: Print function to use.\n                It will be called on each line of the summary.\n                You can set it to a custom function\n                in order to capture the string summary.\n                It defaults to `print` (prints to stdout).\n        \"\"\"\n        return print_layer_summary(self,\n                                   line_length=line_length,\n                                   positions=positions,\n                                   print_fn=print_fn)",
        "begin_line": 2719,
        "end_line": 2738,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00129366106080207,
            "pseudo_dstar_susp": 0.0005656108597285068,
            "pseudo_tarantula_susp": 0.001658374792703151,
            "pseudo_op2_susp": 0.0005656108597285068,
            "pseudo_barinel_susp": 0.001658374792703151
        }
    },
    {
        "name": "keras.engine.topology.get_source_inputs#2741",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.get_source_inputs(tensor, layer=None, node_index=None)",
        "snippet": "def get_source_inputs(tensor, layer=None, node_index=None):\n    \"\"\"Returns the list of input tensors necessary to compute `tensor`.\n\n    Output will always be a list of tensors\n    (potentially with 1 element).\n\n    # Arguments\n        tensor: The tensor to start from.\n        layer: Origin layer of the tensor. Will be\n            determined via tensor._keras_history if not provided.\n        node_index: Origin node index of the tensor.\n\n    # Returns\n        List of input tensors.\n    \"\"\"\n    if not hasattr(tensor, '_keras_history'):\n        return tensor\n\n    if layer is None or node_index:\n        layer, node_index, _ = tensor._keras_history\n    if not layer._inbound_nodes:\n        return [tensor]\n    else:\n        node = layer._inbound_nodes[node_index]\n        if not node.inbound_layers:\n            # Reached an Input layer, stop recursion.\n            return node.input_tensors\n        else:\n            source_tensors = []\n            for i in range(len(node.inbound_layers)):\n                x = node.input_tensors[i]\n                layer = node.inbound_layers[i]\n                node_index = node.node_indices[i]\n                previous_sources = get_source_inputs(x,\n                                                     layer,\n                                                     node_index)\n                # Avoid input redundancy.\n                for x in previous_sources:\n                    if x not in source_tensors:\n                        source_tensors.append(x)\n            return source_tensors",
        "begin_line": 2741,
        "end_line": 2781,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007604562737642585,
            "pseudo_dstar_susp": 0.0016611295681063123,
            "pseudo_tarantula_susp": 0.0007022471910112359,
            "pseudo_op2_susp": 0.0016611295681063123,
            "pseudo_barinel_susp": 0.0007022471910112359
        }
    },
    {
        "name": "keras.engine.topology._to_list#2784",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._to_list(x)",
        "snippet": "def _to_list(x):\n    \"\"\"Normalizes a list/tensor into a list.\n\n    If a tensor is passed, we return\n    a list of size 1 containing the tensor.\n\n    # Arguments\n        x: target object to be normalized.\n\n    # Returns\n        A list.\n    \"\"\"\n    if isinstance(x, list):\n        return x\n    return [x]",
        "begin_line": 2784,
        "end_line": 2798,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008620689655172414,
            "pseudo_dstar_susp": 0.0025380710659898475,
            "pseudo_tarantula_susp": 0.0005711022272986865,
            "pseudo_op2_susp": 0.0025380710659898475,
            "pseudo_barinel_susp": 0.0005711022272986865
        }
    },
    {
        "name": "keras.engine.topology._object_list_uid#2801",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._object_list_uid(object_list)",
        "snippet": "def _object_list_uid(object_list):\n    object_list = _to_list(object_list)\n    return ', '.join([str(abs(id(x))) for x in object_list])",
        "begin_line": 2801,
        "end_line": 2803,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014044943820224719,
            "pseudo_dstar_susp": 0.017241379310344827,
            "pseudo_tarantula_susp": 0.000500751126690035,
            "pseudo_op2_susp": 0.017241379310344827,
            "pseudo_barinel_susp": 0.000500751126690035
        }
    },
    {
        "name": "keras.engine.topology._is_all_none#2806",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._is_all_none(iterable_or_element)",
        "snippet": "def _is_all_none(iterable_or_element):\n    if not isinstance(iterable_or_element, (list, tuple)):\n        iterable = [iterable_or_element]\n    else:\n        iterable = iterable_or_element\n    for element in iterable:\n        if element is not None:\n            return False\n    return True",
        "begin_line": 2806,
        "end_line": 2814,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010070493454179255,
            "pseudo_dstar_susp": 0.004048582995951417,
            "pseudo_tarantula_susp": 0.0008097165991902834,
            "pseudo_op2_susp": 0.004048582995951417,
            "pseudo_barinel_susp": 0.0008097165991902834
        }
    },
    {
        "name": "keras.engine.topology._collect_previous_mask#2817",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._collect_previous_mask(input_tensors)",
        "snippet": "def _collect_previous_mask(input_tensors):\n    \"\"\"Retrieves the output mask(s) of the previous node.\n\n    # Arguments\n        input_tensors: A tensor or list of tensors.\n\n    # Returns\n        A mask tensor or list of mask tensors.\n    \"\"\"\n    input_tensors = _to_list(input_tensors)\n    masks = []\n    for x in input_tensors:\n        if hasattr(x, '_keras_history'):\n            inbound_layer, node_index, tensor_index = x._keras_history\n            node = inbound_layer._inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        else:\n            masks.append(None)\n    if len(masks) == 1:\n        return masks[0]\n    return masks",
        "begin_line": 2817,
        "end_line": 2838,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00129366106080207,
            "pseudo_dstar_susp": 0.004048582995951417,
            "pseudo_tarantula_susp": 0.001658374792703151,
            "pseudo_op2_susp": 0.004048582995951417,
            "pseudo_barinel_susp": 0.001658374792703151
        }
    },
    {
        "name": "keras.engine.topology._to_snake_case#2841",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._to_snake_case(name)",
        "snippet": "def _to_snake_case(name):\n    intermediate = re.sub('(.)([A-Z][a-z0-9]+)', r'\\1_\\2', name)\n    insecure = re.sub('([a-z])([A-Z])', r'\\1_\\2', intermediate).lower()\n    # If the class is private the name starts with \"_\" which is not secure\n    # for creating scopes. We prefix the name with \"private\" in this case.\n    if insecure[0] != '_':\n        return insecure\n    return 'private' + insecure",
        "begin_line": 2841,
        "end_line": 2848,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005543237250554324,
            "pseudo_dstar_susp": 0.0011961722488038277,
            "pseudo_tarantula_susp": 0.0004210526315789474,
            "pseudo_op2_susp": 0.0011961722488038277,
            "pseudo_barinel_susp": 0.0004210526315789474
        }
    },
    {
        "name": "keras.engine.topology._collect_input_shape#2851",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._collect_input_shape(input_tensors)",
        "snippet": "def _collect_input_shape(input_tensors):\n    \"\"\"Collects the output shape(s) of a list of Keras tensors.\n\n    # Arguments\n        input_tensors: list of input tensors (or single input tensor).\n\n    # Returns\n        List of shape tuples (or single tuple), one tuple per input.\n    \"\"\"\n    input_tensors = _to_list(input_tensors)\n    shapes = []\n    for x in input_tensors:\n        try:\n            shapes.append(K.int_shape(x))\n        except TypeError:\n            shapes.append(None)\n    if len(shapes) == 1:\n        return shapes[0]\n    return shapes",
        "begin_line": 2851,
        "end_line": 2869,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010070493454179255,
            "pseudo_dstar_susp": 0.004048582995951417,
            "pseudo_tarantula_susp": 0.0008097165991902834,
            "pseudo_op2_susp": 0.004048582995951417,
            "pseudo_barinel_susp": 0.0008097165991902834
        }
    },
    {
        "name": "keras.engine.topology._save_attributes_to_hdf5_group#2872",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._save_attributes_to_hdf5_group(group, name, data)",
        "snippet": "def _save_attributes_to_hdf5_group(group, name, data):\n    \"\"\"Saves attributes (data) of the specified name into the HDF5 group.\n\n    This method deals with an inherent problem of HDF5 file which is not\n    able to store data larger than HDF5_OBJECT_HEADER_LIMIT bytes.\n\n    # Arguments\n        group: A pointer to a HDF5 group.\n        name: A name of the attributes to save.\n        data: Attributes data to store.\n    \"\"\"\n    # Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`\n    # because in that case even chunking the array would not make the saving\n    # possible.\n    bad_attributes = [x for x in data if len(x) > HDF5_OBJECT_HEADER_LIMIT]\n\n    # Expecting this to never be true.\n    if len(bad_attributes) > 0:\n        raise RuntimeError('The following attributes cannot be saved to HDF5 '\n                           'file because they are larger than %d bytes: %s'\n                           % (HDF5_OBJECT_HEADER_LIMIT,\n                              ', '.join([x for x in bad_attributes])))\n\n    data_npy = np.asarray(data)\n\n    num_chunks = 1\n    chunked_data = np.array_split(data_npy, num_chunks)\n\n    # This will never loop forever thanks to the test above.\n    while any(map(lambda x: x.nbytes > HDF5_OBJECT_HEADER_LIMIT, chunked_data)):\n        num_chunks += 1\n        chunked_data = np.array_split(data_npy, num_chunks)\n\n    if num_chunks > 1:\n        for chunk_id, chunk_data in enumerate(chunked_data):\n            group.attrs['%s%d' % (name, chunk_id)] = chunk_data\n    else:\n        group.attrs[name] = data",
        "begin_line": 2872,
        "end_line": 2909,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology._load_attributes_from_hdf5_group#2912",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._load_attributes_from_hdf5_group(group, name)",
        "snippet": "def _load_attributes_from_hdf5_group(group, name):\n    \"\"\"Loads attributes of the specified name from the HDF5 group.\n\n    This method deals with an inherent problem\n    of HDF5 file which is not able to store\n    data larger than HDF5_OBJECT_HEADER_LIMIT bytes.\n\n    # Arguments\n        group: A pointer to a HDF5 group.\n        name: A name of the attributes to load.\n\n    # Returns\n        data: Attributes data.\n    \"\"\"\n    if name in group.attrs:\n        data = [n.decode('utf8') for n in group.attrs[name]]\n    else:\n        data = []\n        chunk_id = 0\n        while ('%s%d' % (name, chunk_id)) in group.attrs:\n            data.extend([n.decode('utf8')\n                        for n in group.attrs['%s%d' % (name, chunk_id)]])\n            chunk_id += 1\n    return data",
        "begin_line": 2912,
        "end_line": 2935,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.save_weights_to_hdf5_group#2938",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.save_weights_to_hdf5_group(f, layers)",
        "snippet": "def save_weights_to_hdf5_group(f, layers):\n    from .. import __version__ as keras_version\n\n    _save_attributes_to_hdf5_group(\n        f, 'layer_names', [layer.name.encode('utf8') for layer in layers])\n    f.attrs['backend'] = K.backend().encode('utf8')\n    f.attrs['keras_version'] = str(keras_version).encode('utf8')\n\n    for layer in layers:\n        g = f.create_group(layer.name)\n        symbolic_weights = layer.weights\n        weight_values = K.batch_get_value(symbolic_weights)\n        weight_names = []\n        for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n            if hasattr(w, 'name') and w.name:\n                name = str(w.name)\n            else:\n                name = 'param_' + str(i)\n            weight_names.append(name.encode('utf8'))\n        _save_attributes_to_hdf5_group(g, 'weight_names', weight_names)\n        for name, val in zip(weight_names, weight_values):\n            param_dset = g.create_dataset(name, val.shape,\n                                          dtype=val.dtype)\n            if not val.shape:\n                # scalar\n                param_dset[()] = val\n            else:\n                param_dset[:] = val",
        "begin_line": 2938,
        "end_line": 2965,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.8125e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.preprocess_weights_for_loading#2968",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.preprocess_weights_for_loading(layer, weights, original_keras_version=None, original_backend=None, reshape=False)",
        "snippet": "def preprocess_weights_for_loading(layer, weights,\n                                   original_keras_version=None,\n                                   original_backend=None,\n                                   reshape=False):\n    \"\"\"Converts layers weights from Keras 1 format to Keras 2.\n\n    # Arguments\n        layer: Layer instance.\n        weights: List of weights values (Numpy arrays).\n        original_keras_version: Keras version for the weights, as a string.\n        original_backend: Keras backend the weights were trained with,\n            as a string.\n        reshape: Reshape weights to fit the layer when the correct number\n            of values are present but the shape does not match.\n\n    # Returns\n        A list of weights values (Numpy arrays).\n    \"\"\"\n    if layer.__class__.__name__ == 'Bidirectional':\n        num_weights_per_layer = len(weights) // 2\n        forward_weights = preprocess_weights_for_loading(layer.forward_layer,\n                                                         weights[:num_weights_per_layer],\n                                                         original_keras_version,\n                                                         original_backend)\n        backward_weights = preprocess_weights_for_loading(layer.backward_layer,\n                                                          weights[num_weights_per_layer:],\n                                                          original_keras_version,\n                                                          original_backend)\n        weights = forward_weights + backward_weights\n\n    if original_keras_version == '1':\n        if layer.__class__.__name__ == 'TimeDistributed':\n            weights = preprocess_weights_for_loading(layer.layer,\n                                                     weights,\n                                                     original_keras_version,\n                                                     original_backend)\n\n        if layer.__class__.__name__ == 'Conv1D':\n            shape = weights[0].shape\n            # Handle Keras 1.1 format\n            if shape[:2] != (layer.kernel_size[0], 1) or shape[3] != layer.filters:\n                # Legacy shape:\n                # (filters, input_dim, filter_length, 1)\n                assert shape[0] == layer.filters and shape[2:] == (layer.kernel_size[0], 1)\n                weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n            weights[0] = weights[0][:, 0, :, :]\n\n        if layer.__class__.__name__ == 'Conv2D':\n            if layer.data_format == 'channels_first':\n                # old: (filters, stack_size, kernel_rows, kernel_cols)\n                # new: (kernel_rows, kernel_cols, stack_size, filters)\n                weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n\n        if layer.__class__.__name__ == 'Conv2DTranspose':\n            if layer.data_format == 'channels_last':\n                # old: (kernel_rows, kernel_cols, stack_size, filters)\n                # new: (kernel_rows, kernel_cols, filters, stack_size)\n                weights[0] = np.transpose(weights[0], (0, 1, 3, 2))\n            if layer.data_format == 'channels_first':\n                # old: (filters, stack_size, kernel_rows, kernel_cols)\n                # new: (kernel_rows, kernel_cols, filters, stack_size)\n                weights[0] = np.transpose(weights[0], (2, 3, 0, 1))\n\n        if layer.__class__.__name__ == 'Conv3D':\n            if layer.data_format == 'channels_first':\n                # old: (filters, stack_size, ...)\n                # new: (..., stack_size, filters)\n                weights[0] = np.transpose(weights[0], (2, 3, 4, 1, 0))\n\n        if layer.__class__.__name__ == 'GRU':\n            if len(weights) == 9:\n                kernel = np.concatenate([weights[0],\n                                         weights[3],\n                                         weights[6]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[4],\n                                                   weights[7]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[5],\n                                       weights[8]], axis=-1)\n                weights = [kernel, recurrent_kernel, bias]\n\n        if layer.__class__.__name__ == 'LSTM':\n            if len(weights) == 12:\n                # old: i, c, f, o\n                # new: i, f, c, o\n                kernel = np.concatenate([weights[0],\n                                         weights[6],\n                                         weights[3],\n                                         weights[9]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[7],\n                                                   weights[4],\n                                                   weights[10]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[8],\n                                       weights[5],\n                                       weights[11]], axis=-1)\n                weights = [kernel, recurrent_kernel, bias]\n\n        if layer.__class__.__name__ == 'ConvLSTM2D':\n            if len(weights) == 12:\n                kernel = np.concatenate([weights[0],\n                                         weights[6],\n                                         weights[3],\n                                         weights[9]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[7],\n                                                   weights[4],\n                                                   weights[10]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[8],\n                                       weights[5],\n                                       weights[11]], axis=-1)\n                if layer.data_format == 'channels_first':\n                    # old: (filters, stack_size, kernel_rows, kernel_cols)\n                    # new: (kernel_rows, kernel_cols, stack_size, filters)\n                    kernel = np.transpose(kernel, (2, 3, 1, 0))\n                    recurrent_kernel = np.transpose(recurrent_kernel,\n                                                    (2, 3, 1, 0))\n                weights = [kernel, recurrent_kernel, bias]\n\n        if layer.__class__.__name__ in ['Model', 'Sequential']:\n            new_weights = []\n            # trainable weights\n            for sublayer in layer.layers:\n                num_weights = len(sublayer.trainable_weights)\n                if num_weights > 0:\n                    new_weights.extend(preprocess_weights_for_loading(\n                        layer=sublayer,\n                        weights=weights[:num_weights],\n                        original_keras_version=original_keras_version,\n                        original_backend=original_backend))\n                    weights = weights[num_weights:]\n\n            # non-trainable weights\n            for sublayer in layer.layers:\n                num_weights = len([l for l in sublayer.weights if l not in sublayer.trainable_weights])\n                if num_weights > 0:\n                    new_weights.extend(preprocess_weights_for_loading(\n                        layer=sublayer,\n                        weights=weights[:num_weights],\n                        original_keras_version=original_keras_version,\n                        original_backend=original_backend))\n                    weights = weights[num_weights:]\n            weights = new_weights\n\n    conv_layers = ['Conv1D',\n                   'Conv2D',\n                   'Conv3D',\n                   'Conv2DTranspose',\n                   'ConvLSTM2D']\n    if layer.__class__.__name__ in conv_layers:\n        layer_weights_shape = K.int_shape(layer.weights[0])\n        if _need_convert_kernel(original_backend):\n            weights[0] = conv_utils.convert_kernel(weights[0])\n            if layer.__class__.__name__ == 'ConvLSTM2D':\n                weights[1] = conv_utils.convert_kernel(weights[1])\n        if reshape and layer_weights_shape != weights[0].shape:\n            if weights[0].size != np.prod(layer_weights_shape):\n                raise ValueError('Weights must be of equal size to ' +\n                                 'apply a reshape operation. ' +\n                                 'Layer ' + layer.name +\n                                 '\\'s weights have shape ' +\n                                 str(layer_weights_shape) + ' and size ' +\n                                 str(np.prod(layer_weights_shape)) + '. ' +\n                                 'The weights for loading have shape ' +\n                                 str(weights[0].shape) + ' and size ' +\n                                 str(weights[0].size) + '. ')\n            weights[0] = np.reshape(weights[0], layer_weights_shape)\n        elif layer_weights_shape != weights[0].shape:\n            weights[0] = np.transpose(weights[0], (3, 2, 0, 1))\n            if layer.__class__.__name__ == 'ConvLSTM2D':\n                weights[1] = np.transpose(weights[1], (3, 2, 0, 1))\n\n    weights = _convert_rnn_weights(layer, weights)\n\n    return weights",
        "begin_line": 2968,
        "end_line": 3145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology._convert_rnn_weights#3148",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._convert_rnn_weights(layer, weights)",
        "snippet": "def _convert_rnn_weights(layer, weights):\n    \"\"\"Converts weights for RNN layers between native and CuDNN format.\n\n    Input kernels for each gate are transposed and converted between Fortran\n    and C layout, recurrent kernels are transposed. For LSTM biases are summed/\n    split in half, for GRU biases are reshaped.\n\n    Weights can be converted in both directions between `LSTM` and`CuDNNSLTM`\n    and between `CuDNNGRU` and `GRU(reset_after=True)`. Default `GRU` is not\n    compatible with `CuDNNGRU`.\n\n    For missing biases in `LSTM`/`GRU` (`use_bias=False`) no conversion is made.\n\n    # Arguments\n        layer: Target layer instance.\n        weights: List of source weights values (input kernels, recurrent\n            kernels, [biases]) (Numpy arrays).\n\n    # Returns\n        A list of converted weights values (Numpy arrays).\n\n    # Raises\n        ValueError: for incompatible GRU layer/weights or incompatible biases\n    \"\"\"\n\n    def transform_kernels(kernels, func, n_gates):\n        \"\"\"Transforms kernel for each gate separately using given function.\n\n        # Arguments\n            kernels: Stacked array of kernels for individual gates.\n            func: Function applied to kernel of each gate.\n            n_gates: Number of gates (4 for LSTM, 3 for GRU).\n        # Returns\n            Stacked array of transformed kernels.\n        \"\"\"\n        return np.hstack([func(k) for k in np.hsplit(kernels, n_gates)])\n\n    def transpose_input(from_cudnn):\n        \"\"\"Makes a function that transforms input kernels from/to CuDNN format.\n\n        It keeps the shape, but changes between the layout (Fortran/C). Eg.:\n\n        ```\n        Keras                 CuDNN\n        [[0, 1, 2],  <--->  [[0, 2, 4],\n         [3, 4, 5]]          [1, 3, 5]]\n        ```\n\n        It can be passed to `transform_kernels()`.\n\n        # Arguments\n            from_cudnn: `True` if source weights are in CuDNN format, `False`\n                if they're in plain Keras format.\n        # Returns\n            Function that converts input kernel to the other format.\n        \"\"\"\n        order = 'F' if from_cudnn else 'C'\n\n        def transform(kernel):\n            return kernel.T.reshape(kernel.shape, order=order)\n\n        return transform\n\n    target_class = layer.__class__.__name__\n\n    # convert the weights between CuDNNLSTM and LSTM\n    if target_class in ['LSTM', 'CuDNNLSTM'] and len(weights) == 3:\n        # determine if we're loading a CuDNNLSTM layer from the number of bias weights:\n        # CuDNNLSTM has (units * 8) weights; while LSTM has (units * 4)\n        # if there's no bias weight in the file, skip this conversion\n        units = weights[1].shape[0]\n        bias_shape = weights[2].shape\n        n_gates = 4\n\n        if bias_shape == (2 * units * n_gates,):\n            source = 'CuDNNLSTM'\n        elif bias_shape == (units * n_gates,):\n            source = 'LSTM'\n        else:\n            raise ValueError('Invalid bias shape: ' + str(bias_shape))\n\n        def convert_weights(weights, from_cudnn=True):\n            # transpose (and reshape) input and recurrent kernels\n            kernels = transform_kernels(weights[0], transpose_input(from_cudnn), n_gates)\n            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n            if from_cudnn:\n                # merge input and recurrent biases into a single set\n                biases = np.sum(np.split(weights[2], 2, axis=0), axis=0)\n            else:\n                # Split single set of biases evenly to two sets. The way of\n                # splitting doesn't matter as long as the two sets sum is kept.\n                biases = np.tile(0.5 * weights[2], 2)\n            return [kernels, recurrent_kernels, biases]\n\n        if source != target_class:\n            weights = convert_weights(weights, from_cudnn=source == 'CuDNNLSTM')\n\n    # convert the weights between CuDNNGRU and GRU(reset_after=True)\n    if target_class in ['GRU', 'CuDNNGRU'] and len(weights) == 3:\n        # We can determine the source of the weights from the shape of the bias.\n        # If there is no bias we skip the conversion since CuDNNGRU always has biases.\n\n        units = weights[1].shape[0]\n        bias_shape = weights[2].shape\n        n_gates = 3\n\n        def convert_weights(weights, from_cudnn=True):\n            kernels = transform_kernels(weights[0], transpose_input(from_cudnn), n_gates)\n            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n            biases = weights[2].reshape((2, -1) if from_cudnn else -1)\n            return [kernels, recurrent_kernels, biases]\n\n        if bias_shape == (2 * units * n_gates,):\n            source = 'CuDNNGRU'\n        elif bias_shape == (2, units * n_gates):\n            source = 'GRU(reset_after=True)'\n        elif bias_shape == (units * n_gates,):\n            source = 'GRU(reset_after=False)'\n        else:\n            raise ValueError('Invalid bias shape: ' + str(bias_shape))\n\n        if target_class == 'CuDNNGRU':\n            target = 'CuDNNGRU'\n        elif layer.reset_after:\n            target = 'GRU(reset_after=True)'\n        else:\n            target = 'GRU(reset_after=False)'\n\n        # only convert between different types\n        if source != target:\n            types = (source, target)\n            if 'GRU(reset_after=False)' in types:\n                raise ValueError('%s is not compatible with %s' % types)\n            if source == 'CuDNNGRU':\n                weights = convert_weights(weights, from_cudnn=True)\n            elif source == 'GRU(reset_after=True)':\n                weights = convert_weights(weights, from_cudnn=False)\n\n    return weights",
        "begin_line": 3148,
        "end_line": 3286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.transform_kernels#3173",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.transform_kernels(kernels, func, n_gates)",
        "snippet": "    def transform_kernels(kernels, func, n_gates):\n        \"\"\"Transforms kernel for each gate separately using given function.\n\n        # Arguments\n            kernels: Stacked array of kernels for individual gates.\n            func: Function applied to kernel of each gate.\n            n_gates: Number of gates (4 for LSTM, 3 for GRU).\n        # Returns\n            Stacked array of transformed kernels.\n        \"\"\"\n        return np.hstack([func(k) for k in np.hsplit(kernels, n_gates)])",
        "begin_line": 3173,
        "end_line": 3183,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.628928898382667e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.transpose_input#3185",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.transpose_input(from_cudnn)",
        "snippet": "    def transpose_input(from_cudnn):\n        \"\"\"Makes a function that transforms input kernels from/to CuDNN format.\n\n        It keeps the shape, but changes between the layout (Fortran/C). Eg.:\n\n        ```\n        Keras                 CuDNN\n        [[0, 1, 2],  <--->  [[0, 2, 4],\n         [3, 4, 5]]          [1, 3, 5]]\n        ```\n\n        It can be passed to `transform_kernels()`.\n\n        # Arguments\n            from_cudnn: `True` if source weights are in CuDNN format, `False`\n                if they're in plain Keras format.\n        # Returns\n            Function that converts input kernel to the other format.\n        \"\"\"\n        order = 'F' if from_cudnn else 'C'\n\n        def transform(kernel):\n            return kernel.T.reshape(kernel.shape, order=order)\n\n        return transform",
        "begin_line": 3185,
        "end_line": 3209,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.628928898382667e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.convert_weights#3229",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.convert_weights(weights, from_cudnn=True)",
        "snippet": "        def convert_weights(weights, from_cudnn=True):\n            # transpose (and reshape) input and recurrent kernels\n            kernels = transform_kernels(weights[0], transpose_input(from_cudnn), n_gates)\n            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n            if from_cudnn:\n                # merge input and recurrent biases into a single set\n                biases = np.sum(np.split(weights[2], 2, axis=0), axis=0)\n            else:\n                # Split single set of biases evenly to two sets. The way of\n                # splitting doesn't matter as long as the two sets sum is kept.\n                biases = np.tile(0.5 * weights[2], 2)\n            return [kernels, recurrent_kernels, biases]",
        "begin_line": 3229,
        "end_line": 3240,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.convert_weights#3254",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.convert_weights(weights, from_cudnn=True)",
        "snippet": "        def convert_weights(weights, from_cudnn=True):\n            kernels = transform_kernels(weights[0], transpose_input(from_cudnn), n_gates)\n            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n            biases = weights[2].reshape((2, -1) if from_cudnn else -1)\n            return [kernels, recurrent_kernels, biases]",
        "begin_line": 3254,
        "end_line": 3258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology._need_convert_kernel#3289",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._need_convert_kernel(original_backend)",
        "snippet": "def _need_convert_kernel(original_backend):\n    \"\"\"Checks if conversion on kernel matrices is required during weight loading.\n\n    The convolution operation is implemented differently in different backends.\n    While TH implements convolution, TF and CNTK implement the correlation operation.\n    So the channel axis needs to be flipped when we're loading TF weights onto a TH model,\n    or vice verca. However, there's no conversion required between TF and CNTK.\n\n    # Arguments\n        original_backend: Keras backend the weights were trained with, as a string.\n\n    # Returns\n        `True` if conversion on kernel matrices is required, otherwise `False`.\n    \"\"\"\n    if original_backend is None:\n        # backend information not available\n        return False\n    uses_correlation = {'tensorflow': True,\n                        'theano': False,\n                        'cntk': True}\n    return uses_correlation[original_backend] != uses_correlation[K.backend()]",
        "begin_line": 3289,
        "end_line": 3309,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.load_weights_from_hdf5_group#3312",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.load_weights_from_hdf5_group(f, layers, reshape=False)",
        "snippet": "def load_weights_from_hdf5_group(f, layers, reshape=False):\n    \"\"\"Implements topological (order-based) weight loading.\n\n    # Arguments\n        f: A pointer to a HDF5 group.\n        layers: a list of target layers.\n        reshape: Reshape weights to fit the layer when the correct number\n            of values are present but the shape does not match.\n\n    # Raises\n        ValueError: in case of mismatch between provided layers\n            and weights file.\n    \"\"\"\n    if 'keras_version' in f.attrs:\n        original_keras_version = f.attrs['keras_version'].decode('utf8')\n    else:\n        original_keras_version = '1'\n    if 'backend' in f.attrs:\n        original_backend = f.attrs['backend'].decode('utf8')\n    else:\n        original_backend = None\n\n    filtered_layers = []\n    for layer in layers:\n        weights = layer.weights\n        if weights:\n            filtered_layers.append(layer)\n\n    layer_names = _load_attributes_from_hdf5_group(f, 'layer_names')\n    filtered_layer_names = []\n    for name in layer_names:\n        g = f[name]\n        weight_names = _load_attributes_from_hdf5_group(g, 'weight_names')\n        if weight_names:\n            filtered_layer_names.append(name)\n    layer_names = filtered_layer_names\n    if len(layer_names) != len(filtered_layers):\n        raise ValueError('You are trying to load a weight file '\n                         'containing ' + str(len(layer_names)) +\n                         ' layers into a model with ' +\n                         str(len(filtered_layers)) + ' layers.')\n\n    # We batch weight value assignments in a single backend call\n    # which provides a speedup in TensorFlow.\n    weight_value_tuples = []\n    for k, name in enumerate(layer_names):\n        g = f[name]\n        weight_names = _load_attributes_from_hdf5_group(g, 'weight_names')\n        weight_values = [g[weight_name] for weight_name in weight_names]\n        layer = filtered_layers[k]\n        symbolic_weights = layer.weights\n        weight_values = preprocess_weights_for_loading(layer,\n                                                       weight_values,\n                                                       original_keras_version,\n                                                       original_backend,\n                                                       reshape=reshape)\n        if len(weight_values) != len(symbolic_weights):\n            raise ValueError('Layer #' + str(k) +\n                             ' (named \"' + layer.name +\n                             '\" in the current model) was found to '\n                             'correspond to layer ' + name +\n                             ' in the save file. '\n                             'However the new layer ' + layer.name +\n                             ' expects ' + str(len(symbolic_weights)) +\n                             ' weights, but the saved weights have ' +\n                             str(len(weight_values)) +\n                             ' elements.')\n        weight_value_tuples += zip(symbolic_weights, weight_values)\n    K.batch_set_value(weight_value_tuples)",
        "begin_line": 3312,
        "end_line": 3380,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.95291872117067e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.topology.load_weights_from_hdf5_group_by_name#3383",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False, reshape=False)",
        "snippet": "def load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False,\n                                         reshape=False):\n    \"\"\"Implements name-based weight loading.\n\n    (instead of topological weight loading).\n\n    Layers that have no matching name are skipped.\n\n    # Arguments\n        f: A pointer to a HDF5 group.\n        layers: A list of target layers.\n        skip_mismatch: Boolean, whether to skip loading of layers\n            where there is a mismatch in the number of weights,\n            or a mismatch in the shape of the weights.\n        reshape: Reshape weights to fit the layer when the correct number\n            of values are present but the shape does not match.\n\n    # Raises\n        ValueError: in case of mismatch between provided layers\n            and weights file and skip_mismatch=False.\n    \"\"\"\n    if 'keras_version' in f.attrs:\n        original_keras_version = f.attrs['keras_version'].decode('utf8')\n    else:\n        original_keras_version = '1'\n    if 'backend' in f.attrs:\n        original_backend = f.attrs['backend'].decode('utf8')\n    else:\n        original_backend = None\n\n    # New file format.\n    layer_names = _load_attributes_from_hdf5_group(f, 'layer_names')\n\n    # Reverse index of layer name to list of layers with name.\n    index = {}\n    for layer in layers:\n        if layer.name:\n            index.setdefault(layer.name, []).append(layer)\n\n    # We batch weight value assignments in a single backend call\n    # which provides a speedup in TensorFlow.\n    weight_value_tuples = []\n    for k, name in enumerate(layer_names):\n        g = f[name]\n        weight_names = _load_attributes_from_hdf5_group(g, 'weight_names')\n        weight_values = [g[weight_name] for weight_name in weight_names]\n\n        for layer in index.get(name, []):\n            symbolic_weights = layer.weights\n            weight_values = preprocess_weights_for_loading(\n                layer,\n                weight_values,\n                original_keras_version,\n                original_backend,\n                reshape=reshape)\n            if len(weight_values) != len(symbolic_weights):\n                if skip_mismatch:\n                    warnings.warn('Skipping loading of weights for layer {}'.format(layer.name) +\n                                  ' due to mismatch in number of weights' +\n                                  ' ({} vs {}).'.format(len(symbolic_weights), len(weight_values)))\n                    continue\n                else:\n                    raise ValueError('Layer #' + str(k) +\n                                     ' (named \"' + layer.name +\n                                     '\") expects ' +\n                                     str(len(symbolic_weights)) +\n                                     ' weight(s), but the saved weights' +\n                                     ' have ' + str(len(weight_values)) +\n                                     ' element(s).')\n            # Set values.\n            for i in range(len(weight_values)):\n                if skip_mismatch:\n                    if K.int_shape(symbolic_weights[i]) != weight_values[i].shape:\n                        warnings.warn('Skipping loading of weights for layer {}'.format(layer.name) +\n                                      ' due to mismatch in shape' +\n                                      ' ({} vs {}).'.format(\n                                          symbolic_weights[i].shape,\n                                          weight_values[i].shape))\n                        continue\n\n                weight_value_tuples.append((symbolic_weights[i],\n                                            weight_values[i]))\n\n    K.batch_set_value(weight_value_tuples)",
        "begin_line": 3383,
        "end_line": 3466,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.vgg16.VGG16#37",
        "src_path": "keras/applications/vgg16.py",
        "class_name": "keras.applications.vgg16",
        "signature": "keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def VGG16(include_top=True, weights='imagenet',\n          input_tensor=None, input_shape=None,\n          pooling=None,\n          classes=1000):\n    \"\"\"Instantiates the VGG16 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format='channels_last'` in your Keras config\n    at ~/.keras/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 224)` (with `channels_first` data format).\n            It should have exactly 3 input channels,\n            and width and height should be no smaller than 48.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=48,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    # Block 1\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n    # Block 2\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n\n    # Block 4\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n\n    # Block 5\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n\n    if include_top:\n        # Classification block\n        x = Flatten(name='flatten')(x)\n        x = Dense(4096, activation='relu', name='fc1')(x)\n        x = Dense(4096, activation='relu', name='fc2')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='vgg16')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n                                    WEIGHTS_PATH,\n                                    cache_subdir='models',\n                                    file_hash='64373286793e3c8b2b4e3219cbf3544b')\n        else:\n            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                    WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models',\n                                    file_hash='6d6bbae143d832006294945121d1f1fc')\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n            if include_top:\n                maxpool = model.get_layer(name='block5_pool')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name='fc1')\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model",
        "begin_line": 37,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.imagenet_utils._preprocess_numpy_input#21",
        "src_path": "keras/applications/imagenet_utils.py",
        "class_name": "keras.applications.imagenet_utils",
        "signature": "keras.applications.imagenet_utils._preprocess_numpy_input(x, data_format, mode)",
        "snippet": "def _preprocess_numpy_input(x, data_format, mode):\n    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n\n    # Arguments\n        x: Input array, 3D or 4D.\n        data_format: Data format of the image array.\n        mode: One of \"caffe\", \"tf\" or \"torch\".\n            - caffe: will convert the images from RGB to BGR,\n                then will zero-center each color channel with\n                respect to the ImageNet dataset,\n                without scaling.\n            - tf: will scale pixels between -1 and 1,\n                sample-wise.\n            - torch: will scale pixels between 0 and 1 and then\n                will normalize each channel with respect to the\n                ImageNet dataset.\n\n    # Returns\n        Preprocessed Numpy array.\n    \"\"\"\n    if mode == 'tf':\n        x /= 127.5\n        x -= 1.\n        return x\n\n    if mode == 'torch':\n        x /= 255.\n        mean = [0.485, 0.456, 0.406]\n        std = [0.229, 0.224, 0.225]\n    else:\n        if data_format == 'channels_first':\n            # 'RGB'->'BGR'\n            if x.ndim == 3:\n                x = x[::-1, ...]\n            else:\n                x = x[:, ::-1, ...]\n        else:\n            # 'RGB'->'BGR'\n            x = x[..., ::-1]\n        mean = [103.939, 116.779, 123.68]\n        std = None\n\n    # Zero-center by mean pixel\n    if data_format == 'channels_first':\n        if x.ndim == 3:\n            x[0, :, :] -= mean[0]\n            x[1, :, :] -= mean[1]\n            x[2, :, :] -= mean[2]\n            if std is not None:\n                x[0, :, :] /= std[0]\n                x[1, :, :] /= std[1]\n                x[2, :, :] /= std[2]\n        else:\n            x[:, 0, :, :] -= mean[0]\n            x[:, 1, :, :] -= mean[1]\n            x[:, 2, :, :] -= mean[2]\n            if std is not None:\n                x[:, 0, :, :] /= std[0]\n                x[:, 1, :, :] /= std[1]\n                x[:, 2, :, :] /= std[2]\n    else:\n        x[..., 0] -= mean[0]\n        x[..., 1] -= mean[1]\n        x[..., 2] -= mean[2]\n        if std is not None:\n            x[..., 0] /= std[0]\n            x[..., 1] /= std[1]\n            x[..., 2] /= std[2]\n    return x",
        "begin_line": 21,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.imagenet_utils._preprocess_symbolic_input#92",
        "src_path": "keras/applications/imagenet_utils.py",
        "class_name": "keras.applications.imagenet_utils",
        "signature": "keras.applications.imagenet_utils._preprocess_symbolic_input(x, data_format, mode)",
        "snippet": "def _preprocess_symbolic_input(x, data_format, mode):\n    \"\"\"Preprocesses a tensor encoding a batch of images.\n\n    # Arguments\n        x: Input tensor, 3D or 4D.\n        data_format: Data format of the image tensor.\n        mode: One of \"caffe\", \"tf\" or \"torch\".\n            - caffe: will convert the images from RGB to BGR,\n                then will zero-center each color channel with\n                respect to the ImageNet dataset,\n                without scaling.\n            - tf: will scale pixels between -1 and 1,\n                sample-wise.\n            - torch: will scale pixels between 0 and 1 and then\n                will normalize each channel with respect to the\n                ImageNet dataset.\n\n    # Returns\n        Preprocessed tensor.\n    \"\"\"\n    global _IMAGENET_MEAN\n\n    if mode == 'tf':\n        x /= 127.5\n        x -= 1.\n        return x\n\n    if mode == 'torch':\n        x /= 255.\n        mean = [0.485, 0.456, 0.406]\n        std = [0.229, 0.224, 0.225]\n    else:\n        if data_format == 'channels_first':\n            # 'RGB'->'BGR'\n            if K.ndim(x) == 3:\n                x = x[::-1, ...]\n            else:\n                x = x[:, ::-1, ...]\n        else:\n            # 'RGB'->'BGR'\n            x = x[..., ::-1]\n        mean = [103.939, 116.779, 123.68]\n        std = None\n\n    if _IMAGENET_MEAN is None:\n        _IMAGENET_MEAN = K.constant(-np.array(mean))\n\n    # Zero-center by mean pixel\n    if K.dtype(x) != K.dtype(_IMAGENET_MEAN):\n        x = K.bias_add(x, K.cast(_IMAGENET_MEAN, K.dtype(x)), data_format)\n    else:\n        x = K.bias_add(x, _IMAGENET_MEAN, data_format)\n    if std is not None:\n        x /= std\n    return x",
        "begin_line": 92,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.imagenet_utils.preprocess_input#149",
        "src_path": "keras/applications/imagenet_utils.py",
        "class_name": "keras.applications.imagenet_utils",
        "signature": "keras.applications.imagenet_utils.preprocess_input(x, data_format=None, mode='caffe')",
        "snippet": "def preprocess_input(x, data_format=None, mode='caffe'):\n    \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\n\n    # Arguments\n        x: Input Numpy or symbolic tensor, 3D or 4D.\n        data_format: Data format of the image tensor/array.\n        mode: One of \"caffe\", \"tf\".\n            - caffe: will convert the images from RGB to BGR,\n                then will zero-center each color channel with\n                respect to the ImageNet dataset,\n                without scaling.\n            - tf: will scale pixels between -1 and 1,\n                sample-wise.\n\n    # Returns\n        Preprocessed tensor or Numpy array.\n\n    # Raises\n        ValueError: In case of unknown `data_format` argument.\n    \"\"\"\n    if data_format is None:\n        data_format = K.image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    if isinstance(x, np.ndarray):\n        return _preprocess_numpy_input(x, data_format=data_format, mode=mode)\n    else:\n        return _preprocess_symbolic_input(x, data_format=data_format,\n                                          mode=mode)",
        "begin_line": 149,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.imagenet_utils.decode_predictions#181",
        "src_path": "keras/applications/imagenet_utils.py",
        "class_name": "keras.applications.imagenet_utils",
        "signature": "keras.applications.imagenet_utils.decode_predictions(preds, top=5)",
        "snippet": "def decode_predictions(preds, top=5):\n    \"\"\"Decodes the prediction of an ImageNet model.\n\n    # Arguments\n        preds: Numpy tensor encoding a batch of predictions.\n        top: Integer, how many top-guesses to return.\n\n    # Returns\n        A list of lists of top class prediction tuples\n        `(class_name, class_description, score)`.\n        One list of tuples per sample in batch input.\n\n    # Raises\n        ValueError: In case of invalid shape of the `pred` array\n            (must be 2D).\n    \"\"\"\n    global CLASS_INDEX\n    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n        raise ValueError('`decode_predictions` expects '\n                         'a batch of predictions '\n                         '(i.e. a 2D array of shape (samples, 1000)). '\n                         'Found array with shape: ' + str(preds.shape))\n    if CLASS_INDEX is None:\n        fpath = get_file('imagenet_class_index.json',\n                         CLASS_INDEX_PATH,\n                         cache_subdir='models',\n                         file_hash='c2c37ea517e94d9795004a39431a14cb')\n        with open(fpath) as f:\n            CLASS_INDEX = json.load(f)\n    results = []\n    for pred in preds:\n        top_indices = pred.argsort()[-top:][::-1]\n        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n        result.sort(key=lambda x: x[2], reverse=True)\n        results.append(result)\n    return results",
        "begin_line": 181,
        "end_line": 216,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.imagenet_utils._obtain_input_shape#219",
        "src_path": "keras/applications/imagenet_utils.py",
        "class_name": "keras.applications.imagenet_utils",
        "signature": "keras.applications.imagenet_utils._obtain_input_shape(input_shape, default_size, min_size, data_format, require_flatten, weights=None)",
        "snippet": "def _obtain_input_shape(input_shape,\n                        default_size,\n                        min_size,\n                        data_format,\n                        require_flatten,\n                        weights=None):\n    \"\"\"Internal utility to compute/validate a model's input shape.\n\n    # Arguments\n        input_shape: Either None (will return the default network input shape),\n            or a user-provided shape to be validated.\n        default_size: Default input width/height for the model.\n        min_size: Minimum input width/height accepted by the model.\n        data_format: Image data format to use.\n        require_flatten: Whether the model is expected to\n            be linked to a classifier via a Flatten layer.\n        weights: One of `None` (random initialization)\n            or 'imagenet' (pre-training on ImageNet).\n            If weights='imagenet' input channels must be equal to 3.\n\n    # Returns\n        An integer shape tuple (may include None entries).\n\n    # Raises\n        ValueError: In case of invalid argument values.\n    \"\"\"\n    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n        if data_format == 'channels_first':\n            if input_shape[0] not in {1, 3}:\n                warnings.warn(\n                    'This model usually expects 1 or 3 input channels. '\n                    'However, it was passed an input_shape with ' +\n                    str(input_shape[0]) + ' input channels.')\n            default_shape = (input_shape[0], default_size, default_size)\n        else:\n            if input_shape[-1] not in {1, 3}:\n                warnings.warn(\n                    'This model usually expects 1 or 3 input channels. '\n                    'However, it was passed an input_shape with ' +\n                    str(input_shape[-1]) + ' input channels.')\n            default_shape = (default_size, default_size, input_shape[-1])\n    else:\n        if data_format == 'channels_first':\n            default_shape = (3, default_size, default_size)\n        else:\n            default_shape = (default_size, default_size, 3)\n    if weights == 'imagenet' and require_flatten:\n        if input_shape is not None:\n            if input_shape != default_shape:\n                raise ValueError('When setting`include_top=True` '\n                                 'and loading `imagenet` weights, '\n                                 '`input_shape` should be ' +\n                                 str(default_shape) + '.')\n        return default_shape\n    if input_shape:\n        if data_format == 'channels_first':\n            if input_shape is not None:\n                if len(input_shape) != 3:\n                    raise ValueError(\n                        '`input_shape` must be a tuple of three integers.')\n                if input_shape[0] != 3 and weights == 'imagenet':\n                    raise ValueError('The input must have 3 channels; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n                   (input_shape[2] is not None and input_shape[2] < min_size)):\n                    raise ValueError('Input size must be at least ' +\n                                     str(min_size) + 'x' + str(min_size) + '; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n        else:\n            if input_shape is not None:\n                if len(input_shape) != 3:\n                    raise ValueError(\n                        '`input_shape` must be a tuple of three integers.')\n                if input_shape[-1] != 3 and weights == 'imagenet':\n                    raise ValueError('The input must have 3 channels; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n                   (input_shape[1] is not None and input_shape[1] < min_size)):\n                    raise ValueError('Input size must be at least ' +\n                                     str(min_size) + 'x' + str(min_size) + '; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n    else:\n        if require_flatten:\n            input_shape = default_shape\n        else:\n            if data_format == 'channels_first':\n                input_shape = (3, None, None)\n            else:\n                input_shape = (None, None, 3)\n    if require_flatten:\n        if None in input_shape:\n            raise ValueError('If `include_top` is True, '\n                             'you should specify a static `input_shape`. '\n                             'Got `input_shape=' + str(input_shape) + '`')\n    return input_shape",
        "begin_line": 219,
        "end_line": 313,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected1D.__init__#81",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected1D",
        "signature": "keras.layers.local.LocallyConnected1D.__init__(self, filters, kernel_size, strides=1, padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=1,\n                 padding='valid',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(LocallyConnected1D, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        if self.padding != 'valid':\n            raise ValueError('Invalid border mode for LocallyConnected1D '\n                             '(only \"valid\" is supported): ' + padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 81,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected1D.build#116",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected1D",
        "signature": "keras.layers.local.LocallyConnected1D.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[2]\n        if input_dim is None:\n            raise ValueError('Axis 2 of input should be fully-defined. '\n                             'Found shape:', input_shape)\n        output_length = conv_utils.conv_output_length(input_shape[1],\n                                                      self.kernel_size[0],\n                                                      self.padding,\n                                                      self.strides[0])\n        self.kernel_shape = (output_length,\n                             self.kernel_size[0] * input_dim,\n                             self.filters)\n        self.kernel = self.add_weight(\n            shape=self.kernel_shape,\n            initializer=self.kernel_initializer,\n            name='kernel',\n            regularizer=self.kernel_regularizer,\n            constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(\n                shape=(output_length, self.filters),\n                initializer=self.bias_initializer,\n                name='bias',\n                regularizer=self.bias_regularizer,\n                constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.input_spec = InputSpec(ndim=3, axes={2: input_dim})\n        self.built = True",
        "begin_line": 116,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected1D.compute_output_shape#146",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected1D",
        "signature": "keras.layers.local.LocallyConnected1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        length = conv_utils.conv_output_length(input_shape[1],\n                                               self.kernel_size[0],\n                                               self.padding,\n                                               self.strides[0])\n        return (input_shape[0], length, self.filters)",
        "begin_line": 146,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected1D.call#153",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected1D",
        "signature": "keras.layers.local.LocallyConnected1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = K.local_conv1d(inputs, self.kernel, self.kernel_size, self.strides)\n        if self.use_bias:\n            output = K.bias_add(output, self.bias)\n        if self.activation is not None:\n            output = self.activation(output)\n        return output",
        "begin_line": 153,
        "end_line": 159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected1D.get_config#161",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected1D",
        "signature": "keras.layers.local.LocallyConnected1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'filters': self.filters,\n            'kernel_size': self.kernel_size,\n            'strides': self.strides,\n            'padding': self.padding,\n            'activation': activations.serialize(self.activation),\n            'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(LocallyConnected1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 161,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected2D.__init__#263",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected2D",
        "signature": "keras.layers.local.LocallyConnected2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(LocallyConnected2D, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        if self.padding != 'valid':\n            raise ValueError('Invalid border mode for LocallyConnected2D '\n                             '(only \"valid\" is supported): ' + padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 263,
        "end_line": 296,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected2D.build#298",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected2D",
        "signature": "keras.layers.local.LocallyConnected2D.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if self.data_format == 'channels_last':\n            input_row, input_col = input_shape[1:-1]\n            input_filter = input_shape[3]\n        else:\n            input_row, input_col = input_shape[2:]\n            input_filter = input_shape[1]\n        if input_row is None or input_col is None:\n            raise ValueError('The spatial dimensions of the inputs to '\n                             ' a LocallyConnected2D layer '\n                             'should be fully-defined, but layer received '\n                             'the inputs shape ' + str(input_shape))\n        output_row = conv_utils.conv_output_length(input_row, self.kernel_size[0],\n                                                   self.padding, self.strides[0])\n        output_col = conv_utils.conv_output_length(input_col, self.kernel_size[1],\n                                                   self.padding, self.strides[1])\n        self.output_row = output_row\n        self.output_col = output_col\n        self.kernel_shape = (output_row * output_col,\n                             self.kernel_size[0] * self.kernel_size[1] * input_filter,\n                             self.filters)\n        self.kernel = self.add_weight(shape=self.kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(output_row, output_col, self.filters),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        if self.data_format == 'channels_first':\n            self.input_spec = InputSpec(ndim=4, axes={1: input_filter})\n        else:\n            self.input_spec = InputSpec(ndim=4, axes={-1: input_filter})\n        self.built = True",
        "begin_line": 298,
        "end_line": 336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected2D.compute_output_shape#338",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected2D",
        "signature": "keras.layers.local.LocallyConnected2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        elif self.data_format == 'channels_last':\n            rows = input_shape[1]\n            cols = input_shape[2]\n\n        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n                                             self.padding, self.strides[0])\n        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n                                             self.padding, self.strides[1])\n\n        if self.data_format == 'channels_first':\n            return (input_shape[0], self.filters, rows, cols)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0], rows, cols, self.filters)",
        "begin_line": 338,
        "end_line": 354,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected2D.call#356",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected2D",
        "signature": "keras.layers.local.LocallyConnected2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = K.local_conv2d(inputs,\n                                self.kernel,\n                                self.kernel_size,\n                                self.strides,\n                                (self.output_row, self.output_col),\n                                self.data_format)\n\n        if self.use_bias:\n            output = K.bias_add(output, self.bias, data_format=self.data_format)\n\n        output = self.activation(output)\n        return output",
        "begin_line": 356,
        "end_line": 368,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected2D.get_config#370",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected2D",
        "signature": "keras.layers.local.LocallyConnected2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'filters': self.filters,\n            'kernel_size': self.kernel_size,\n            'strides': self.strides,\n            'padding': self.padding,\n            'data_format': self.data_format,\n            'activation': activations.serialize(self.activation),\n            'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(LocallyConnected2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 370,
        "end_line": 388,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.nasnet.NASNet#69",
        "src_path": "keras/applications/nasnet.py",
        "class_name": "keras.applications.nasnet",
        "signature": "keras.applications.nasnet.NASNet(input_shape=None, penultimate_filters=4032, num_blocks=6, stem_block_filters=96, skip_reduction=True, filter_multiplier=2, include_top=True, weights=None, input_tensor=None, pooling=None, classes=1000, default_size=None)",
        "snippet": "def NASNet(input_shape=None,\n           penultimate_filters=4032,\n           num_blocks=6,\n           stem_block_filters=96,\n           skip_reduction=True,\n           filter_multiplier=2,\n           include_top=True,\n           weights=None,\n           input_tensor=None,\n           pooling=None,\n           classes=1000,\n           default_size=None):\n    '''Instantiates a NASNet model.\n\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format='channels_last'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: Optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(331, 331, 3)` for NASNetLarge or\n            `(224, 224, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        penultimate_filters: Number of filters in the penultimate layer.\n            NASNet models use the notation `NASNet (N @ P)`, where:\n                -   N is the number of blocks\n                -   P is the number of penultimate filters\n        num_blocks: Number of repeated blocks of the NASNet model.\n            NASNet models use the notation `NASNet (N @ P)`, where:\n                -   N is the number of blocks\n                -   P is the number of penultimate filters\n        stem_block_filters: Number of filters in the initial stem block\n        skip_reduction: Whether to skip the reduction step at the tail\n            end of the network. Set to `False` for CIFAR models.\n        filter_multiplier: Controls the width of the network.\n            - If `filter_multiplier` < 1.0, proportionally decreases the number\n                of filters in each layer.\n            - If `filter_multiplier` > 1.0, proportionally increases the number\n                of filters in each layer.\n            - If `filter_multiplier` = 1, default number of filters from the\n                 paper are used at each layer.\n        include_top: Whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: Optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: Optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: Specifies the default image size of the model\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: In case of invalid argument for `weights`,\n            invalid input shape or invalid `penultimate_filters` value.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    '''\n    if K.backend() != 'tensorflow':\n        raise RuntimeError('Only TensorFlow backend is currently supported, '\n                           'as other backends do not support '\n                           'separable convolution.')\n\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as ImageNet with `include_top` '\n                         'as true, `classes` should be 1000')\n\n    if default_size is None:\n        default_size = 331\n\n    # Determine proper input shape and default size.\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=default_size,\n                                      min_size=32,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top or weights,\n                                      weights=weights)\n\n    if K.image_data_format() != 'channels_last':\n        warnings.warn('The NASNet family of models is only available '\n                      'for the input data format \"channels_last\" '\n                      '(width, height, channels). '\n                      'However your settings specify the default '\n                      'data format \"channels_first\" (channels, width, height).'\n                      ' You should set `image_data_format=\"channels_last\"` '\n                      'in your Keras config located at ~/.keras/keras.json. '\n                      'The model being returned right now will expect inputs '\n                      'to follow the \"channels_last\" data format.')\n        K.set_image_data_format('channels_last')\n        old_data_format = 'channels_first'\n    else:\n        old_data_format = None\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    if penultimate_filters % 24 != 0:\n        raise ValueError(\n            'For NASNet-A models, the value of `penultimate_filters` '\n            'needs to be divisible by 24. Current value: %d' %\n            penultimate_filters)\n\n    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n    filters = penultimate_filters // 24\n\n    if not skip_reduction:\n        x = Conv2D(stem_block_filters, (3, 3), strides=(2, 2), padding='valid',\n                   use_bias=False, name='stem_conv1',\n                   kernel_initializer='he_normal')(img_input)\n    else:\n        x = Conv2D(stem_block_filters, (3, 3), strides=(1, 1), padding='same',\n                   use_bias=False, name='stem_conv1',\n                   kernel_initializer='he_normal')(img_input)\n\n    x = BatchNormalization(axis=channel_dim, momentum=0.9997,\n                           epsilon=1e-3, name='stem_bn1')(x)\n\n    p = None\n    if not skip_reduction:  # imagenet / mobile mode\n        x, p = _reduction_a_cell(x, p, filters // (filter_multiplier ** 2),\n                                 block_id='stem_1')\n        x, p = _reduction_a_cell(x, p, filters // filter_multiplier,\n                                 block_id='stem_2')\n\n    for i in range(num_blocks):\n        x, p = _normal_a_cell(x, p, filters, block_id='%d' % (i))\n\n    x, p0 = _reduction_a_cell(x, p, filters * filter_multiplier,\n                              block_id='reduce_%d' % (num_blocks))\n\n    p = p0 if not skip_reduction else p\n\n    for i in range(num_blocks):\n        x, p = _normal_a_cell(x, p, filters * filter_multiplier,\n                              block_id='%d' % (num_blocks + i + 1))\n\n    x, p0 = _reduction_a_cell(x, p, filters * filter_multiplier ** 2,\n                              block_id='reduce_%d' % (2 * num_blocks))\n\n    p = p0 if not skip_reduction else p\n\n    for i in range(num_blocks):\n        x, p = _normal_a_cell(x, p, filters * filter_multiplier ** 2,\n                              block_id='%d' % (2 * num_blocks + i + 1))\n\n    x = Activation('relu')(x)\n\n    if include_top:\n        x = GlobalAveragePooling2D()(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    model = Model(inputs, x, name='NASNet')\n\n    # load weights\n    if weights == 'imagenet':\n        if default_size == 224:  # mobile version\n            if include_top:\n                weight_path = NASNET_MOBILE_WEIGHT_PATH\n                model_name = 'nasnet_mobile.h5'\n            else:\n                weight_path = NASNET_MOBILE_WEIGHT_PATH_NO_TOP\n                model_name = 'nasnet_mobile_no_top.h5'\n\n            weights_file = get_file(model_name, weight_path,\n                                    cache_subdir='models')\n            model.load_weights(weights_file)\n\n        elif default_size == 331:  # large version\n            if include_top:\n                weight_path = NASNET_LARGE_WEIGHT_PATH\n                model_name = 'nasnet_large.h5'\n            else:\n                weight_path = NASNET_LARGE_WEIGHT_PATH_NO_TOP\n                model_name = 'nasnet_large_no_top.h5'\n\n            weights_file = get_file(model_name, weight_path,\n                                    cache_subdir='models')\n            model.load_weights(weights_file)\n        else:\n            raise ValueError(\n                'ImageNet weights can only be loaded with NASNetLarge'\n                ' or NASNetMobile')\n    elif weights is not None:\n        model.load_weights(weights)\n\n    if old_data_format:\n        K.set_image_data_format(old_data_format)\n\n    return model",
        "begin_line": 69,
        "end_line": 300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.nasnet.NASNetLarge#303",
        "src_path": "keras/applications/nasnet.py",
        "class_name": "keras.applications.nasnet",
        "signature": "keras.applications.nasnet.NASNetLarge(input_shape=None, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)",
        "snippet": "def NASNetLarge(input_shape=None,\n                include_top=True,\n                weights='imagenet',\n                input_tensor=None,\n                pooling=None,\n                classes=1000):\n    '''Instantiates a NASNet model in ImageNet mode.\n\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format='channels_last'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: Optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(331, 331, 3)` for NASNetLarge.\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        include_top: Whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: Optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: Optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    '''\n    return NASNet(input_shape,\n                  penultimate_filters=4032,\n                  num_blocks=6,\n                  stem_block_filters=96,\n                  skip_reduction=False,\n                  filter_multiplier=2,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=331)",
        "begin_line": 303,
        "end_line": 366,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.nasnet.NASNetMobile#369",
        "src_path": "keras/applications/nasnet.py",
        "class_name": "keras.applications.nasnet",
        "signature": "keras.applications.nasnet.NASNetMobile(input_shape=None, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)",
        "snippet": "def NASNetMobile(input_shape=None,\n                 include_top=True,\n                 weights='imagenet',\n                 input_tensor=None,\n                 pooling=None,\n                 classes=1000):\n    '''Instantiates a Mobile NASNet model in ImageNet mode.\n\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format='channels_last'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: Optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        include_top: Whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: Optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: Optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: In case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    '''\n    return NASNet(input_shape,\n                  penultimate_filters=1056,\n                  num_blocks=4,\n                  stem_block_filters=32,\n                  skip_reduction=False,\n                  filter_multiplier=2,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=224)",
        "begin_line": 369,
        "end_line": 432,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.nasnet._separable_conv_block#435",
        "src_path": "keras/applications/nasnet.py",
        "class_name": "keras.applications.nasnet",
        "signature": "keras.applications.nasnet._separable_conv_block(ip, filters, kernel_size=(3, 3), strides=(1, 1), block_id=None)",
        "snippet": "def _separable_conv_block(ip, filters,\n                          kernel_size=(3, 3),\n                          strides=(1, 1),\n                          block_id=None):\n    '''Adds 2 blocks of [relu-separable conv-batchnorm].\n\n    # Arguments\n        ip: Input tensor\n        filters: Number of output filters per layer\n        kernel_size: Kernel size of separable convolutions\n        strides: Strided convolution for downsampling\n        block_id: String block_id\n\n    # Returns\n        A Keras tensor\n    '''\n    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n\n    with K.name_scope('separable_conv_block_%s' % block_id):\n        x = Activation('relu')(ip)\n        x = SeparableConv2D(filters, kernel_size, strides=strides,\n                            name='separable_conv_1_%s' % block_id,\n                            padding='same', use_bias=False,\n                            kernel_initializer='he_normal')(x)\n        x = BatchNormalization(axis=channel_dim, momentum=0.9997,\n                               epsilon=1e-3,\n                               name='separable_conv_1_bn_%s' % (block_id))(x)\n        x = Activation('relu')(x)\n        x = SeparableConv2D(filters, kernel_size,\n                            name='separable_conv_2_%s' % block_id,\n                            padding='same', use_bias=False,\n                            kernel_initializer='he_normal')(x)\n        x = BatchNormalization(axis=channel_dim, momentum=0.9997,\n                               epsilon=1e-3,\n                               name='separable_conv_2_bn_%s' % (block_id))(x)\n    return x",
        "begin_line": 435,
        "end_line": 470,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.nasnet._adjust_block#473",
        "src_path": "keras/applications/nasnet.py",
        "class_name": "keras.applications.nasnet",
        "signature": "keras.applications.nasnet._adjust_block(p, ip, filters, block_id=None)",
        "snippet": "def _adjust_block(p, ip, filters, block_id=None):\n    '''Adjusts the input `previous path` to match the shape of the `input`.\n\n    Used in situations where the output number of filters needs to be changed.\n\n    # Arguments\n        p: Input tensor which needs to be modified\n        ip: Input tensor whose shape needs to be matched\n        filters: Number of output filters to be matched\n        block_id: String block_id\n\n    # Returns\n        Adjusted Keras tensor\n    '''\n    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n    img_dim = 2 if K.image_data_format() == 'channels_first' else -2\n\n    ip_shape = K.int_shape(ip)\n\n    if p is not None:\n        p_shape = K.int_shape(p)\n\n    with K.name_scope('adjust_block'):\n        if p is None:\n            p = ip\n\n        elif p_shape[img_dim] != ip_shape[img_dim]:\n            with K.name_scope('adjust_reduction_block_%s' % block_id):\n                p = Activation('relu', name='adjust_relu_1_%s' % block_id)(p)\n\n                p1 = AveragePooling2D((1, 1), strides=(2, 2), padding='valid',\n                                      name='adjust_avg_pool_1_%s' % block_id)(p)\n                p1 = Conv2D(filters // 2, (1, 1), padding='same',\n                            use_bias=False, name='adjust_conv_1_%s' % block_id,\n                            kernel_initializer='he_normal')(p1)\n\n                p2 = ZeroPadding2D(padding=((0, 1), (0, 1)))(p)\n                p2 = Cropping2D(cropping=((1, 0), (1, 0)))(p2)\n                p2 = AveragePooling2D((1, 1), strides=(2, 2), padding='valid',\n                                      name='adjust_avg_pool_2_%s' % block_id)(\n                    p2)\n                p2 = Conv2D(filters // 2, (1, 1), padding='same',\n                            use_bias=False, name='adjust_conv_2_%s' % block_id,\n                            kernel_initializer='he_normal')(p2)\n\n                p = concatenate([p1, p2], axis=channel_dim)\n                p = BatchNormalization(axis=channel_dim, momentum=0.9997,\n                                       epsilon=1e-3,\n                                       name='adjust_bn_%s' % block_id)(p)\n\n        elif p_shape[channel_dim] != filters:\n            with K.name_scope('adjust_projection_block_%s' % block_id):\n                p = Activation('relu')(p)\n                p = Conv2D(filters, (1, 1), strides=(1, 1), padding='same',\n                           name='adjust_conv_projection_%s' % block_id,\n                           use_bias=False, kernel_initializer='he_normal')(p)\n                p = BatchNormalization(axis=channel_dim, momentum=0.9997,\n                                       epsilon=1e-3,\n                                       name='adjust_bn_%s' % block_id)(p)\n    return p",
        "begin_line": 473,
        "end_line": 532,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.nasnet._normal_a_cell#535",
        "src_path": "keras/applications/nasnet.py",
        "class_name": "keras.applications.nasnet",
        "signature": "keras.applications.nasnet._normal_a_cell(ip, p, filters, block_id=None)",
        "snippet": "def _normal_a_cell(ip, p, filters, block_id=None):\n    '''Adds a Normal cell for NASNet-A (Fig. 4 in the paper).\n\n    # Arguments\n        ip: Input tensor `x`\n        p: Input tensor `p`\n        filters: Number of output filters\n        block_id: String block_id\n\n    # Returns\n        A Keras tensor\n    '''\n    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n\n    with K.name_scope('normal_A_block_%s' % block_id):\n        p = _adjust_block(p, ip, filters, block_id)\n\n        h = Activation('relu')(ip)\n        h = Conv2D(filters, (1, 1), strides=(1, 1), padding='same',\n                   name='normal_conv_1_%s' % block_id,\n                   use_bias=False, kernel_initializer='he_normal')(h)\n        h = BatchNormalization(axis=channel_dim, momentum=0.9997,\n                               epsilon=1e-3,\n                               name='normal_bn_1_%s' % block_id)(h)\n\n        with K.name_scope('block_1'):\n            x1_1 = _separable_conv_block(h, filters, kernel_size=(5, 5),\n                                         block_id='normal_left1_%s' % block_id)\n            x1_2 = _separable_conv_block(p, filters,\n                                         block_id='normal_right1_%s' % block_id)\n            x1 = add([x1_1, x1_2], name='normal_add_1_%s' % block_id)\n\n        with K.name_scope('block_2'):\n            x2_1 = _separable_conv_block(p, filters, (5, 5),\n                                         block_id='normal_left2_%s' % block_id)\n            x2_2 = _separable_conv_block(p, filters, (3, 3),\n                                         block_id='normal_right2_%s' % block_id)\n            x2 = add([x2_1, x2_2], name='normal_add_2_%s' % block_id)\n\n        with K.name_scope('block_3'):\n            x3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same',\n                                  name='normal_left3_%s' % (block_id))(h)\n            x3 = add([x3, p], name='normal_add_3_%s' % block_id)\n\n        with K.name_scope('block_4'):\n            x4_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same',\n                                    name='normal_left4_%s' % (block_id))(p)\n            x4_2 = AveragePooling2D((3, 3), strides=(1, 1), padding='same',\n                                    name='normal_right4_%s' % (block_id))(p)\n            x4 = add([x4_1, x4_2], name='normal_add_4_%s' % block_id)\n\n        with K.name_scope('block_5'):\n            x5 = _separable_conv_block(h, filters,\n                                       block_id='normal_left5_%s' % block_id)\n            x5 = add([x5, h], name='normal_add_5_%s' % block_id)\n\n        x = concatenate([p, x1, x2, x3, x4, x5], axis=channel_dim,\n                        name='normal_concat_%s' % block_id)\n    return x, ip",
        "begin_line": 535,
        "end_line": 593,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.nasnet._reduction_a_cell#596",
        "src_path": "keras/applications/nasnet.py",
        "class_name": "keras.applications.nasnet",
        "signature": "keras.applications.nasnet._reduction_a_cell(ip, p, filters, block_id=None)",
        "snippet": "def _reduction_a_cell(ip, p, filters, block_id=None):\n    '''Adds a Reduction cell for NASNet-A (Fig. 4 in the paper).\n\n    # Arguments\n        ip: Input tensor `x`\n        p: Input tensor `p`\n        filters: Number of output filters\n        block_id: String block_id\n\n    # Returns\n        A Keras tensor\n    '''\n    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n\n    with K.name_scope('reduction_A_block_%s' % block_id):\n        p = _adjust_block(p, ip, filters, block_id)\n\n        h = Activation('relu')(ip)\n        h = Conv2D(filters, (1, 1), strides=(1, 1), padding='same',\n                   name='reduction_conv_1_%s' % block_id,\n                   use_bias=False, kernel_initializer='he_normal')(h)\n        h = BatchNormalization(axis=channel_dim, momentum=0.9997,\n                               epsilon=1e-3,\n                               name='reduction_bn_1_%s' % block_id)(h)\n\n        with K.name_scope('block_1'):\n            x1_1 = _separable_conv_block(h, filters, (5, 5), strides=(2, 2),\n                                         block_id='reduction_left1_%s' % block_id)\n            x1_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2),\n                                         block_id='reduction_1_%s' % block_id)\n            x1 = add([x1_1, x1_2], name='reduction_add_1_%s' % block_id)\n\n        with K.name_scope('block_2'):\n            x2_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='same',\n                                name='reduction_left2_%s' % block_id)(h)\n            x2_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2),\n                                         block_id='reduction_right2_%s' % block_id)\n            x2 = add([x2_1, x2_2], name='reduction_add_2_%s' % block_id)\n\n        with K.name_scope('block_3'):\n            x3_1 = AveragePooling2D((3, 3), strides=(2, 2), padding='same',\n                                    name='reduction_left3_%s' % block_id)(h)\n            x3_2 = _separable_conv_block(p, filters, (5, 5), strides=(2, 2),\n                                         block_id='reduction_right3_%s' % block_id)\n            x3 = add([x3_1, x3_2], name='reduction_add3_%s' % block_id)\n\n        with K.name_scope('block_4'):\n            x4 = AveragePooling2D((3, 3), strides=(1, 1), padding='same',\n                                  name='reduction_left4_%s' % block_id)(x1)\n            x4 = add([x2, x4])\n\n        with K.name_scope('block_5'):\n            x5_1 = _separable_conv_block(x1, filters, (3, 3),\n                                         block_id='reduction_left4_%s' % block_id)\n            x5_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='same',\n                                name='reduction_right5_%s' % block_id)(h)\n            x5 = add([x5_1, x5_2], name='reduction_add4_%s' % block_id)\n\n        x = concatenate([x2, x3, x4, x5], axis=channel_dim,\n                        name='reduction_concat_%s' % block_id)\n        return x, ip",
        "begin_line": 596,
        "end_line": 656,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.__init__#74",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.__init__(self, input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)",
        "snippet": "    def __init__(self, input_dim, output_dim,\n                 embeddings_initializer='uniform',\n                 embeddings_regularizer=None,\n                 activity_regularizer=None,\n                 embeddings_constraint=None,\n                 mask_zero=False,\n                 input_length=None,\n                 **kwargs):\n        if 'input_shape' not in kwargs:\n            if input_length:\n                kwargs['input_shape'] = (input_length,)\n            else:\n                kwargs['input_shape'] = (None,)\n        super(Embedding, self).__init__(**kwargs)\n\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.embeddings_initializer = initializers.get(embeddings_initializer)\n        self.embeddings_regularizer = regularizers.get(embeddings_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.embeddings_constraint = constraints.get(embeddings_constraint)\n        self.mask_zero = mask_zero\n        self.input_length = input_length",
        "begin_line": 74,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.build#98",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        self.embeddings = self.add_weight(\n            shape=(self.input_dim, self.output_dim),\n            initializer=self.embeddings_initializer,\n            name='embeddings',\n            regularizer=self.embeddings_regularizer,\n            constraint=self.embeddings_constraint,\n            dtype=self.dtype)\n        self.built = True",
        "begin_line": 98,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.21422704123542e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.compute_mask#108",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if not self.mask_zero:\n            return None\n        else:\n            return K.not_equal(inputs, 0)",
        "begin_line": 108,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.compute_output_shape#114",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.input_length is None:\n            return input_shape + (self.output_dim,)\n        else:\n            # input_length can be tuple if input is 3D or higher\n            if isinstance(self.input_length, (list, tuple)):\n                in_lens = list(self.input_length)\n            else:\n                in_lens = [self.input_length]\n            if len(in_lens) != len(input_shape) - 1:\n                ValueError('\"input_length\" is %s, but received input has shape %s' %\n                           (str(self.input_length), str(input_shape)))\n            else:\n                for i, (s1, s2) in enumerate(zip(in_lens, input_shape[1:])):\n                    if s1 is not None and s2 is not None and s1 != s2:\n                        ValueError('\"input_length\" is %s, but received input has shape %s' %\n                                   (str(self.input_length), str(input_shape)))\n                    elif s1 is None:\n                        in_lens[i] = s2\n            return (input_shape[0],) + tuple(in_lens) + (self.output_dim,)",
        "begin_line": 114,
        "end_line": 133,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.call#135",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if K.dtype(inputs) != 'int32':\n            inputs = K.cast(inputs, 'int32')\n        out = K.gather(self.embeddings, inputs)\n        return out",
        "begin_line": 135,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.350730688935282e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.get_config#141",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'input_dim': self.input_dim,\n                  'output_dim': self.output_dim,\n                  'embeddings_initializer': initializers.serialize(self.embeddings_initializer),\n                  'embeddings_regularizer': regularizers.serialize(self.embeddings_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'embeddings_constraint': constraints.serialize(self.embeddings_constraint),\n                  'mask_zero': self.mask_zero,\n                  'input_length': self.input_length}\n        base_config = super(Embedding, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 141,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.datasets.mnist.load_data#11",
        "src_path": "keras/datasets/mnist.py",
        "class_name": "keras.datasets.mnist",
        "signature": "keras.datasets.mnist.load_data(path='mnist.npz')",
        "snippet": "def load_data(path='mnist.npz'):\n    \"\"\"Loads the MNIST dataset.\n\n    # Arguments\n        path: path where to cache the dataset locally\n            (relative to ~/.keras/datasets).\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n    \"\"\"\n    path = get_file(path,\n                    origin='https://s3.amazonaws.com/img-datasets/mnist.npz',\n                    file_hash='8a61469f7ea1b51cbae51d4f78837e45')\n    f = np.load(path)\n    x_train, y_train = f['x_train'], f['y_train']\n    x_test, y_test = f['x_test'], f['y_test']\n    f.close()\n    return (x_train, y_train), (x_test, y_test)",
        "begin_line": 11,
        "end_line": 28,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.CallbackList.__init__#38",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.__init__(self, callbacks=None, queue_length=10)",
        "snippet": "    def __init__(self, callbacks=None, queue_length=10):\n        callbacks = callbacks or []\n        self.callbacks = [c for c in callbacks]\n        self.queue_length = queue_length",
        "begin_line": 38,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005178663904712584,
            "pseudo_dstar_susp": 0.0010570824524312897,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0010570824524312897,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.CallbackList.append#43",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.append(self, callback)",
        "snippet": "    def append(self, callback):\n        self.callbacks.append(callback)",
        "begin_line": 43,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.CallbackList.set_params#46",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.set_params(self, params)",
        "snippet": "    def set_params(self, params):\n        for callback in self.callbacks:\n            callback.set_params(params)",
        "begin_line": 46,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.CallbackList.set_model#50",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.set_model(self, model)",
        "snippet": "    def set_model(self, model):\n        for callback in self.callbacks:\n            callback.set_model(model)",
        "begin_line": 50,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_epoch_begin#54",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        \"\"\"Called at the start of an epoch.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_begin(epoch, logs)\n        self._delta_t_batch = 0.\n        self._delta_ts_batch_begin = deque([], maxlen=self.queue_length)\n        self._delta_ts_batch_end = deque([], maxlen=self.queue_length)",
        "begin_line": 54,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_epoch_end#68",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        \"\"\"Called at the end of an epoch.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_end(epoch, logs)",
        "begin_line": 68,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00039077764751856197,
            "pseudo_dstar_susp": 0.00038955979742890534,
            "pseudo_tarantula_susp": 0.0004338394793926247,
            "pseudo_op2_susp": 0.00038955979742890534,
            "pseudo_barinel_susp": 0.00043402777777777775
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_batch_begin#79",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_batch_begin(self, batch, logs=None)",
        "snippet": "    def on_batch_begin(self, batch, logs=None):\n        \"\"\"Called right before processing a batch.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        t_before_callbacks = time.time()\n        for callback in self.callbacks:\n            callback.on_batch_begin(batch, logs)\n        self._delta_ts_batch_begin.append(time.time() - t_before_callbacks)\n        delta_t_median = np.median(self._delta_ts_batch_begin)\n        if (self._delta_t_batch > 0. and\n           delta_t_median > 0.95 * self._delta_t_batch and\n           delta_t_median > 0.1):\n            warnings.warn('Method on_batch_begin() is slow compared '\n                          'to the batch update (%f). Check your callbacks.'\n                          % delta_t_median)\n        self._t_enter_batch = time.time()",
        "begin_line": 79,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00041562759767248546,
            "pseudo_dstar_susp": 0.00041425020712510354,
            "pseudo_tarantula_susp": 0.0006269592476489029,
            "pseudo_op2_susp": 0.00041425020712510354,
            "pseudo_barinel_susp": 0.0006269592476489029
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_batch_end#100",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        \"\"\"Called at the end of a batch.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        if not hasattr(self, '_t_enter_batch'):\n            self._t_enter_batch = time.time()\n        self._delta_t_batch = time.time() - self._t_enter_batch\n        t_before_callbacks = time.time()\n        for callback in self.callbacks:\n            callback.on_batch_end(batch, logs)\n        self._delta_ts_batch_end.append(time.time() - t_before_callbacks)\n        delta_t_median = np.median(self._delta_ts_batch_end)\n        if (self._delta_t_batch > 0. and\n           (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n            warnings.warn('Method on_batch_end() is slow compared '\n                          'to the batch update (%f). Check your callbacks.'\n                          % delta_t_median)",
        "begin_line": 100,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_train_begin#122",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        \"\"\"Called at the beginning of training.\n\n        # Arguments\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_train_begin(logs)",
        "begin_line": 122,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_train_end#132",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_train_end(self, logs=None)",
        "snippet": "    def on_train_end(self, logs=None):\n        \"\"\"Called at the end of training.\n\n        # Arguments\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_train_end(logs)",
        "begin_line": 132,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003924646781789639,
            "pseudo_dstar_susp": 0.0003912363067292645,
            "pseudo_tarantula_susp": 0.0004366812227074236,
            "pseudo_op2_susp": 0.0003912363067292645,
            "pseudo_barinel_susp": 0.00043649061545176777
        }
    },
    {
        "name": "keras.callbacks.CallbackList.__iter__#142",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return iter(self.callbacks)",
        "begin_line": 142,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003933910306845004,
            "pseudo_dstar_susp": 0.000392156862745098,
            "pseudo_tarantula_susp": 0.0004757373929590866,
            "pseudo_op2_susp": 0.000392156862745098,
            "pseudo_barinel_susp": 0.0004757373929590866
        }
    },
    {
        "name": "keras.callbacks.Callback.__init__#173",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.__init__(self)",
        "snippet": "    def __init__(self):\n        self.validation_data = None\n        self.model = None",
        "begin_line": 173,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006618133686300463,
            "pseudo_dstar_susp": 0.0011210762331838565,
            "pseudo_tarantula_susp": 0.000859106529209622,
            "pseudo_op2_susp": 0.0011210762331838565,
            "pseudo_barinel_susp": 0.000859106529209622
        }
    },
    {
        "name": "keras.callbacks.Callback.set_params#177",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.set_params(self, params)",
        "snippet": "    def set_params(self, params):\n        self.params = params",
        "begin_line": 177,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.Callback.set_model#180",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.set_model(self, model)",
        "snippet": "    def set_model(self, model):\n        self.model = model",
        "begin_line": 180,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.Callback.on_epoch_begin#183",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        pass",
        "begin_line": 183,
        "end_line": 184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.Callback.on_epoch_end#186",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        pass",
        "begin_line": 186,
        "end_line": 187,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.Callback.on_batch_begin#189",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_batch_begin(self, batch, logs=None)",
        "snippet": "    def on_batch_begin(self, batch, logs=None):\n        pass",
        "begin_line": 189,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.Callback.on_batch_end#192",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        pass",
        "begin_line": 192,
        "end_line": 193,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.Callback.on_train_begin#195",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        pass",
        "begin_line": 195,
        "end_line": 196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.Callback.on_train_end#198",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_train_end(self, logs=None)",
        "snippet": "    def on_train_end(self, logs=None):\n        pass",
        "begin_line": 198,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003924646781789639,
            "pseudo_dstar_susp": 0.0003912363067292645,
            "pseudo_tarantula_susp": 0.0004366812227074236,
            "pseudo_op2_susp": 0.0003912363067292645,
            "pseudo_barinel_susp": 0.00043649061545176777
        }
    },
    {
        "name": "keras.callbacks.BaseLogger.__init__#214",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.BaseLogger",
        "signature": "keras.callbacks.BaseLogger.__init__(self, stateful_metrics=None)",
        "snippet": "    def __init__(self, stateful_metrics=None):\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()",
        "begin_line": 214,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00039077764751856197,
            "pseudo_dstar_susp": 0.00038955979742890534,
            "pseudo_tarantula_susp": 0.0004338394793926247,
            "pseudo_op2_susp": 0.00038955979742890534,
            "pseudo_barinel_susp": 0.00043402777777777775
        }
    },
    {
        "name": "keras.callbacks.BaseLogger.on_epoch_begin#220",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.BaseLogger",
        "signature": "keras.callbacks.BaseLogger.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        self.seen = 0\n        self.totals = {}",
        "begin_line": 220,
        "end_line": 222,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.BaseLogger.on_batch_end#224",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.BaseLogger",
        "signature": "keras.callbacks.BaseLogger.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        batch_size = logs.get('size', 0)\n        self.seen += batch_size\n\n        for k, v in logs.items():\n            if k in self.stateful_metrics:\n                self.totals[k] = v\n            else:\n                if k in self.totals:\n                    self.totals[k] += v * batch_size\n                else:\n                    self.totals[k] = v * batch_size",
        "begin_line": 224,
        "end_line": 236,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00041562759767248546,
            "pseudo_dstar_susp": 0.00041425020712510354,
            "pseudo_tarantula_susp": 0.0006269592476489029,
            "pseudo_op2_susp": 0.00041425020712510354,
            "pseudo_barinel_susp": 0.0006269592476489029
        }
    },
    {
        "name": "keras.callbacks.BaseLogger.on_epoch_end#238",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.BaseLogger",
        "signature": "keras.callbacks.BaseLogger.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        if logs is not None:\n            for k in self.params['metrics']:\n                if k in self.totals:\n                    # Make value available to next callbacks.\n                    if k in self.stateful_metrics:\n                        logs[k] = self.totals[k]\n                    else:\n                        logs[k] = self.totals[k] / self.seen",
        "begin_line": 238,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00039077764751856197,
            "pseudo_dstar_susp": 0.00038955979742890534,
            "pseudo_tarantula_susp": 0.0004338394793926247,
            "pseudo_op2_susp": 0.00038955979742890534,
            "pseudo_barinel_susp": 0.00043402777777777775
        }
    },
    {
        "name": "keras.callbacks.TerminateOnNaN.__init__#253",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TerminateOnNaN",
        "signature": "keras.callbacks.TerminateOnNaN.__init__(self)",
        "snippet": "    def __init__(self):\n        super(TerminateOnNaN, self).__init__()",
        "begin_line": 253,
        "end_line": 254,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.TerminateOnNaN.on_batch_end#256",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TerminateOnNaN",
        "signature": "keras.callbacks.TerminateOnNaN.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        loss = logs.get('loss')\n        if loss is not None:\n            if np.isnan(loss) or np.isinf(loss):\n                print('Batch %d: Invalid loss, terminating training' % (batch))\n                self.model.stop_training = True",
        "begin_line": 256,
        "end_line": 262,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.__init__#281",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.__init__(self, count_mode='samples', stateful_metrics=None)",
        "snippet": "    def __init__(self, count_mode='samples',\n                 stateful_metrics=None):\n        super(ProgbarLogger, self).__init__()\n        if count_mode == 'samples':\n            self.use_steps = False\n        elif count_mode == 'steps':\n            self.use_steps = True\n        else:\n            raise ValueError('Unknown `count_mode`: ' + str(count_mode))\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()",
        "begin_line": 281,
        "end_line": 293,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013812154696132596,
            "pseudo_dstar_susp": 0.0005763688760806917,
            "pseudo_tarantula_susp": 0.0017761989342806395,
            "pseudo_op2_susp": 0.0005763688760806917,
            "pseudo_barinel_susp": 0.0017761989342806395
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.on_train_begin#295",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        self.verbose = self.params['verbose']\n        self.epochs = self.params['epochs']",
        "begin_line": 295,
        "end_line": 297,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004462293618920125,
            "pseudo_dstar_susp": 0.00043725404459991256,
            "pseudo_tarantula_susp": 0.0007722007722007722,
            "pseudo_op2_susp": 0.00043725404459991256,
            "pseudo_barinel_susp": 0.0007722007722007722
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.on_epoch_begin#299",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        if self.verbose:\n            print('Epoch %d/%d' % (epoch + 1, self.epochs))\n            if self.use_steps:\n                target = self.params['steps']\n            else:\n                target = self.params['samples']\n            self.target = target\n            self.progbar = Progbar(target=self.target,\n                                   verbose=self.verbose,\n                                   stateful_metrics=self.stateful_metrics)\n        self.seen = 0",
        "begin_line": 299,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013812154696132596,
            "pseudo_dstar_susp": 0.0005763688760806917,
            "pseudo_tarantula_susp": 0.0017761989342806395,
            "pseudo_op2_susp": 0.0005763688760806917,
            "pseudo_barinel_susp": 0.0017761989342806395
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.on_batch_begin#312",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.on_batch_begin(self, batch, logs=None)",
        "snippet": "    def on_batch_begin(self, batch, logs=None):\n        if self.seen < self.target:\n            self.log_values = []",
        "begin_line": 312,
        "end_line": 314,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004462293618920125,
            "pseudo_dstar_susp": 0.00043725404459991256,
            "pseudo_tarantula_susp": 0.0007722007722007722,
            "pseudo_op2_susp": 0.00043725404459991256,
            "pseudo_barinel_susp": 0.0007722007722007722
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.on_batch_end#316",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        batch_size = logs.get('size', 0)\n        if self.use_steps:\n            self.seen += 1\n        else:\n            self.seen += batch_size\n\n        for k in self.params['metrics']:\n            if k in logs:\n                self.log_values.append((k, logs[k]))\n\n        # Skip progbar update for the last batch;\n        # will be handled by on_epoch_end.\n        if self.verbose and self.seen < self.target:\n            self.progbar.update(self.seen, self.log_values)",
        "begin_line": 316,
        "end_line": 331,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013812154696132596,
            "pseudo_dstar_susp": 0.0005763688760806917,
            "pseudo_tarantula_susp": 0.0017761989342806395,
            "pseudo_op2_susp": 0.0005763688760806917,
            "pseudo_barinel_susp": 0.0017761989342806395
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.on_epoch_end#333",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        for k in self.params['metrics']:\n            if k in logs:\n                self.log_values.append((k, logs[k]))\n        if self.verbose:\n            self.progbar.update(self.seen, self.log_values)",
        "begin_line": 333,
        "end_line": 339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00045351473922902497,
            "pseudo_dstar_susp": 0.0004428697962798937,
            "pseudo_tarantula_susp": 0.0007905138339920949,
            "pseudo_op2_susp": 0.0004428697962798937,
            "pseudo_barinel_susp": 0.0007905138339920949
        }
    },
    {
        "name": "keras.callbacks.History.on_train_begin#350",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.History",
        "signature": "keras.callbacks.History.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        self.epoch = []\n        self.history = {}",
        "begin_line": 350,
        "end_line": 352,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00038580246913580245,
            "pseudo_dstar_susp": 0.0003846153846153846,
            "pseudo_tarantula_susp": 0.000427715996578272,
            "pseudo_op2_susp": 0.0003846153846153846,
            "pseudo_barinel_susp": 0.000427715996578272
        }
    },
    {
        "name": "keras.callbacks.History.on_epoch_end#354",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.History",
        "signature": "keras.callbacks.History.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        self.epoch.append(epoch)\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)",
        "begin_line": 354,
        "end_line": 358,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003924646781789639,
            "pseudo_dstar_susp": 0.0003912363067292645,
            "pseudo_tarantula_susp": 0.0004366812227074236,
            "pseudo_op2_susp": 0.0003912363067292645,
            "pseudo_barinel_susp": 0.00043649061545176777
        }
    },
    {
        "name": "keras.callbacks.ModelCheckpoint.__init__#393",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ModelCheckpoint",
        "signature": "keras.callbacks.ModelCheckpoint.__init__(self, filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)",
        "snippet": "    def __init__(self, filepath, monitor='val_loss', verbose=0,\n                 save_best_only=False, save_weights_only=False,\n                 mode='auto', period=1):\n        super(ModelCheckpoint, self).__init__()\n        self.monitor = monitor\n        self.verbose = verbose\n        self.filepath = filepath\n        self.save_best_only = save_best_only\n        self.save_weights_only = save_weights_only\n        self.period = period\n        self.epochs_since_last_save = 0\n\n        if mode not in ['auto', 'min', 'max']:\n            warnings.warn('ModelCheckpoint mode %s is unknown, '\n                          'fallback to auto mode.' % (mode),\n                          RuntimeWarning)\n            mode = 'auto'\n\n        if mode == 'min':\n            self.monitor_op = np.less\n            self.best = np.Inf\n        elif mode == 'max':\n            self.monitor_op = np.greater\n            self.best = -np.Inf\n        else:\n            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n                self.monitor_op = np.greater\n                self.best = -np.Inf\n            else:\n                self.monitor_op = np.less\n                self.best = np.Inf",
        "begin_line": 393,
        "end_line": 423,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.ModelCheckpoint.on_epoch_end#425",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ModelCheckpoint",
        "signature": "keras.callbacks.ModelCheckpoint.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        self.epochs_since_last_save += 1\n        if self.epochs_since_last_save >= self.period:\n            self.epochs_since_last_save = 0\n            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n            if self.save_best_only:\n                current = logs.get(self.monitor)\n                if current is None:\n                    warnings.warn('Can save best model only with %s available, '\n                                  'skipping.' % (self.monitor), RuntimeWarning)\n                else:\n                    if self.monitor_op(current, self.best):\n                        if self.verbose > 0:\n                            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n                                  ' saving model to %s'\n                                  % (epoch + 1, self.monitor, self.best,\n                                     current, filepath))\n                        self.best = current\n                        if self.save_weights_only:\n                            self.model.save_weights(filepath, overwrite=True)\n                        else:\n                            self.model.save(filepath, overwrite=True)\n                    else:\n                        if self.verbose > 0:\n                            print('\\nEpoch %05d: %s did not improve' %\n                                  (epoch + 1, self.monitor))\n            else:\n                if self.verbose > 0:\n                    print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n                if self.save_weights_only:\n                    self.model.save_weights(filepath, overwrite=True)\n                else:\n                    self.model.save(filepath, overwrite=True)",
        "begin_line": 425,
        "end_line": 458,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.EarlyStopping.__init__#482",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.EarlyStopping",
        "signature": "keras.callbacks.EarlyStopping.__init__(self, monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')",
        "snippet": "    def __init__(self, monitor='val_loss',\n                 min_delta=0, patience=0, verbose=0, mode='auto'):\n        super(EarlyStopping, self).__init__()\n\n        self.monitor = monitor\n        self.patience = patience\n        self.verbose = verbose\n        self.min_delta = min_delta\n        self.wait = 0\n        self.stopped_epoch = 0\n\n        if mode not in ['auto', 'min', 'max']:\n            warnings.warn('EarlyStopping mode %s is unknown, '\n                          'fallback to auto mode.' % mode,\n                          RuntimeWarning)\n            mode = 'auto'\n\n        if mode == 'min':\n            self.monitor_op = np.less\n        elif mode == 'max':\n            self.monitor_op = np.greater\n        else:\n            if 'acc' in self.monitor:\n                self.monitor_op = np.greater\n            else:\n                self.monitor_op = np.less\n\n        if self.monitor_op == np.greater:\n            self.min_delta *= 1\n        else:\n            self.min_delta *= -1",
        "begin_line": 482,
        "end_line": 512,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.EarlyStopping.on_train_begin#514",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.EarlyStopping",
        "signature": "keras.callbacks.EarlyStopping.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        # Allow instances to be re-used\n        self.wait = 0\n        self.stopped_epoch = 0\n        self.best = np.Inf if self.monitor_op == np.less else -np.Inf",
        "begin_line": 514,
        "end_line": 518,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.EarlyStopping.on_epoch_end#520",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.EarlyStopping",
        "signature": "keras.callbacks.EarlyStopping.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        current = logs.get(self.monitor)\n        if current is None:\n            warnings.warn(\n                'Early stopping conditioned on metric `%s` '\n                'which is not available. Available metrics are: %s' %\n                (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n            )\n            return\n        if self.monitor_op(current - self.min_delta, self.best):\n            self.best = current\n            self.wait = 0\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                self.stopped_epoch = epoch\n                self.model.stop_training = True",
        "begin_line": 520,
        "end_line": 536,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.EarlyStopping.on_train_end#538",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.EarlyStopping",
        "signature": "keras.callbacks.EarlyStopping.on_train_end(self, logs=None)",
        "snippet": "    def on_train_end(self, logs=None):\n        if self.stopped_epoch > 0 and self.verbose > 0:\n            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))",
        "begin_line": 538,
        "end_line": 540,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.RemoteMonitor.__init__#558",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.RemoteMonitor",
        "signature": "keras.callbacks.RemoteMonitor.__init__(self, root='http://localhost:9000', path='/publish/epoch/end/', field='data', headers=None)",
        "snippet": "    def __init__(self,\n                 root='http://localhost:9000',\n                 path='/publish/epoch/end/',\n                 field='data',\n                 headers=None):\n        super(RemoteMonitor, self).__init__()\n\n        self.root = root\n        self.path = path\n        self.field = field\n        self.headers = headers",
        "begin_line": 558,
        "end_line": 568,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.callbacks.RemoteMonitor.on_epoch_end#570",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.RemoteMonitor",
        "signature": "keras.callbacks.RemoteMonitor.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        if requests is None:\n            raise ImportError('RemoteMonitor requires '\n                              'the `requests` library.')\n        logs = logs or {}\n        send = {}\n        send['epoch'] = epoch\n        for k, v in logs.items():\n            if isinstance(v, (np.ndarray, np.generic)):\n                send[k] = v.item()\n            else:\n                send[k] = v\n        try:\n            requests.post(self.root + self.path,\n                          {self.field: json.dumps(send)},\n                          headers=self.headers)\n        except requests.exceptions.RequestException:\n            warnings.warn('Warning: could not reach RemoteMonitor '\n                          'root server at ' + str(self.root))",
        "begin_line": 570,
        "end_line": 588,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.LearningRateScheduler.__init__#601",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.LearningRateScheduler",
        "signature": "keras.callbacks.LearningRateScheduler.__init__(self, schedule, verbose=0)",
        "snippet": "    def __init__(self, schedule, verbose=0):\n        super(LearningRateScheduler, self).__init__()\n        self.schedule = schedule\n        self.verbose = verbose",
        "begin_line": 601,
        "end_line": 604,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.LearningRateScheduler.on_epoch_begin#606",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.LearningRateScheduler",
        "signature": "keras.callbacks.LearningRateScheduler.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        if not hasattr(self.model.optimizer, 'lr'):\n            raise ValueError('Optimizer must have a \"lr\" attribute.')\n        lr = float(K.get_value(self.model.optimizer.lr))\n        try:  # new API\n            lr = self.schedule(epoch, lr=lr)\n        except TypeError:  # old API for backward compatibility\n            lr = self.schedule(epoch)\n        if not isinstance(lr, (float, np.float32, np.float64)):\n            raise ValueError('The output of the \"schedule\" function '\n                             'should be float.')\n        K.set_value(self.model.optimizer.lr, lr)\n        if self.verbose > 0:\n            print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n                  'rate to %s.' % (epoch + 1, lr))",
        "begin_line": 606,
        "end_line": 620,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.TensorBoard.__init__#671",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TensorBoard",
        "signature": "keras.callbacks.TensorBoard.__init__(self, log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)",
        "snippet": "    def __init__(self, log_dir='./logs',\n                 histogram_freq=0,\n                 batch_size=32,\n                 write_graph=True,\n                 write_grads=False,\n                 write_images=False,\n                 embeddings_freq=0,\n                 embeddings_layer_names=None,\n                 embeddings_metadata=None):\n        super(TensorBoard, self).__init__()\n        global tf, projector\n        try:\n            import tensorflow as tf\n            from tensorflow.contrib.tensorboard.plugins import projector\n        except ImportError:\n            raise ImportError('You need the TensorFlow module installed to use TensorBoard.')\n\n        if K.backend() != 'tensorflow':\n            if histogram_freq != 0:\n                warnings.warn('You are not using the TensorFlow backend. '\n                              'histogram_freq was set to 0')\n                histogram_freq = 0\n            if write_graph:\n                warnings.warn('You are not using the TensorFlow backend. '\n                              'write_graph was set to False')\n                write_graph = False\n            if write_images:\n                warnings.warn('You are not using the TensorFlow backend. '\n                              'write_images was set to False')\n                write_images = False\n            if embeddings_freq != 0:\n                warnings.warn('You are not using the TensorFlow backend. '\n                              'embeddings_freq was set to 0')\n                embeddings_freq = 0\n\n        self.log_dir = log_dir\n        self.histogram_freq = histogram_freq\n        self.merged = None\n        self.write_graph = write_graph\n        self.write_grads = write_grads\n        self.write_images = write_images\n        self.embeddings_freq = embeddings_freq\n        self.embeddings_layer_names = embeddings_layer_names\n        self.embeddings_metadata = embeddings_metadata or {}\n        self.batch_size = batch_size",
        "begin_line": 671,
        "end_line": 715,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.TensorBoard.set_model#717",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TensorBoard",
        "signature": "keras.callbacks.TensorBoard.set_model(self, model)",
        "snippet": "    def set_model(self, model):\n        self.model = model\n        if K.backend() == 'tensorflow':\n            self.sess = K.get_session()\n        if self.histogram_freq and self.merged is None:\n            for layer in self.model.layers:\n\n                for weight in layer.weights:\n                    mapped_weight_name = weight.name.replace(':', '_')\n                    tf.summary.histogram(mapped_weight_name, weight)\n                    if self.write_grads:\n                        grads = model.optimizer.get_gradients(model.total_loss,\n                                                              weight)\n\n                        def is_indexed_slices(grad):\n                            return type(grad).__name__ == 'IndexedSlices'\n                        grads = [\n                            grad.values if is_indexed_slices(grad) else grad\n                            for grad in grads]\n                        tf.summary.histogram('{}_grad'.format(mapped_weight_name), grads)\n                    if self.write_images:\n                        w_img = tf.squeeze(weight)\n                        shape = K.int_shape(w_img)\n                        if len(shape) == 2:  # dense layer kernel case\n                            if shape[0] > shape[1]:\n                                w_img = tf.transpose(w_img)\n                                shape = K.int_shape(w_img)\n                            w_img = tf.reshape(w_img, [1,\n                                                       shape[0],\n                                                       shape[1],\n                                                       1])\n                        elif len(shape) == 3:  # convnet case\n                            if K.image_data_format() == 'channels_last':\n                                # switch to channels_first to display\n                                # every kernel as a separate image\n                                w_img = tf.transpose(w_img, perm=[2, 0, 1])\n                                shape = K.int_shape(w_img)\n                            w_img = tf.reshape(w_img, [shape[0],\n                                                       shape[1],\n                                                       shape[2],\n                                                       1])\n                        elif len(shape) == 1:  # bias case\n                            w_img = tf.reshape(w_img, [1,\n                                                       shape[0],\n                                                       1,\n                                                       1])\n                        else:\n                            # not possible to handle 3D convnets etc.\n                            continue\n\n                        shape = K.int_shape(w_img)\n                        assert len(shape) == 4 and shape[-1] in [1, 3, 4]\n                        tf.summary.image(mapped_weight_name, w_img)\n\n                if hasattr(layer, 'output'):\n                    tf.summary.histogram('{}_out'.format(layer.name),\n                                         layer.output)\n        self.merged = tf.summary.merge_all()\n\n        if self.write_graph:\n            self.writer = tf.summary.FileWriter(self.log_dir,\n                                                self.sess.graph)\n        else:\n            self.writer = tf.summary.FileWriter(self.log_dir)\n\n        if self.embeddings_freq:\n            embeddings_layer_names = self.embeddings_layer_names\n\n            if not embeddings_layer_names:\n                embeddings_layer_names = [layer.name for layer in self.model.layers\n                                          if type(layer).__name__ == 'Embedding']\n\n            embeddings = {layer.name: layer.weights[0]\n                          for layer in self.model.layers\n                          if layer.name in embeddings_layer_names}\n\n            self.saver = tf.train.Saver(list(embeddings.values()))\n\n            embeddings_metadata = {}\n\n            if not isinstance(self.embeddings_metadata, str):\n                embeddings_metadata = self.embeddings_metadata\n            else:\n                embeddings_metadata = {layer_name: self.embeddings_metadata\n                                       for layer_name in embeddings.keys()}\n\n            config = projector.ProjectorConfig()\n            self.embeddings_ckpt_path = os.path.join(self.log_dir,\n                                                     'keras_embedding.ckpt')\n\n            for layer_name, tensor in embeddings.items():\n                embedding = config.embeddings.add()\n                embedding.tensor_name = tensor.name\n\n                if layer_name in embeddings_metadata:\n                    embedding.metadata_path = embeddings_metadata[layer_name]\n\n            projector.visualize_embeddings(self.writer, config)",
        "begin_line": 717,
        "end_line": 814,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.TensorBoard.is_indexed_slices#731",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TensorBoard",
        "signature": "keras.callbacks.TensorBoard.is_indexed_slices(grad)",
        "snippet": "                        def is_indexed_slices(grad):\n                            return type(grad).__name__ == 'IndexedSlices'",
        "begin_line": 731,
        "end_line": 732,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.TensorBoard.on_epoch_end#816",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TensorBoard",
        "signature": "keras.callbacks.TensorBoard.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        if not self.validation_data and self.histogram_freq:\n            raise ValueError('If printing histograms, validation_data must be '\n                             'provided, and cannot be a generator.')\n        if self.validation_data and self.histogram_freq:\n            if epoch % self.histogram_freq == 0:\n\n                val_data = self.validation_data\n                tensors = (self.model.inputs +\n                           self.model.targets +\n                           self.model.sample_weights)\n\n                if self.model.uses_learning_phase:\n                    tensors += [K.learning_phase()]\n\n                assert len(val_data) == len(tensors)\n                val_size = val_data[0].shape[0]\n                i = 0\n                while i < val_size:\n                    step = min(self.batch_size, val_size - i)\n                    if self.model.uses_learning_phase:\n                        # do not slice the learning phase\n                        batch_val = [x[i:i + step] for x in val_data[:-1]]\n                        batch_val.append(val_data[-1])\n                    else:\n                        batch_val = [x[i:i + step] for x in val_data]\n                    assert len(batch_val) == len(tensors)\n                    feed_dict = dict(zip(tensors, batch_val))\n                    result = self.sess.run([self.merged], feed_dict=feed_dict)\n                    summary_str = result[0]\n                    self.writer.add_summary(summary_str, epoch)\n                    i += self.batch_size\n\n        if self.embeddings_freq and self.embeddings_ckpt_path:\n            if epoch % self.embeddings_freq == 0:\n                self.saver.save(self.sess,\n                                self.embeddings_ckpt_path,\n                                epoch)\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, epoch)\n        self.writer.flush()",
        "begin_line": 816,
        "end_line": 865,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.TensorBoard.on_train_end#867",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TensorBoard",
        "signature": "keras.callbacks.TensorBoard.on_train_end(self, _)",
        "snippet": "    def on_train_end(self, _):\n        self.writer.close()",
        "begin_line": 867,
        "end_line": 868,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.ReduceLROnPlateau.__init__#908",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ReduceLROnPlateau",
        "signature": "keras.callbacks.ReduceLROnPlateau.__init__(self, monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)",
        "snippet": "    def __init__(self, monitor='val_loss', factor=0.1, patience=10,\n                 verbose=0, mode='auto', epsilon=1e-4, cooldown=0, min_lr=0):\n        super(ReduceLROnPlateau, self).__init__()\n\n        self.monitor = monitor\n        if factor >= 1.0:\n            raise ValueError('ReduceLROnPlateau '\n                             'does not support a factor >= 1.0.')\n        self.factor = factor\n        self.min_lr = min_lr\n        self.epsilon = epsilon\n        self.patience = patience\n        self.verbose = verbose\n        self.cooldown = cooldown\n        self.cooldown_counter = 0  # Cooldown counter.\n        self.wait = 0\n        self.best = 0\n        self.mode = mode\n        self.monitor_op = None\n        self._reset()",
        "begin_line": 908,
        "end_line": 927,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.ReduceLROnPlateau._reset#929",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ReduceLROnPlateau",
        "signature": "keras.callbacks.ReduceLROnPlateau._reset(self)",
        "snippet": "    def _reset(self):\n        \"\"\"Resets wait counter and cooldown counter.\n        \"\"\"\n        if self.mode not in ['auto', 'min', 'max']:\n            warnings.warn('Learning Rate Plateau Reducing mode %s is unknown, '\n                          'fallback to auto mode.' % (self.mode),\n                          RuntimeWarning)\n            self.mode = 'auto'\n        if (self.mode == 'min' or\n           (self.mode == 'auto' and 'acc' not in self.monitor)):\n            self.monitor_op = lambda a, b: np.less(a, b - self.epsilon)\n            self.best = np.Inf\n        else:\n            self.monitor_op = lambda a, b: np.greater(a, b + self.epsilon)\n            self.best = -np.Inf\n        self.cooldown_counter = 0\n        self.wait = 0",
        "begin_line": 929,
        "end_line": 945,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.ReduceLROnPlateau.on_train_begin#947",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ReduceLROnPlateau",
        "signature": "keras.callbacks.ReduceLROnPlateau.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        self._reset()",
        "begin_line": 947,
        "end_line": 948,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.ReduceLROnPlateau.on_epoch_end#950",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ReduceLROnPlateau",
        "signature": "keras.callbacks.ReduceLROnPlateau.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)\n        current = logs.get(self.monitor)\n        if current is None:\n            warnings.warn(\n                'Reduce LR on plateau conditioned on metric `%s` '\n                'which is not available. Available metrics are: %s' %\n                (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n            )\n\n        else:\n            if self.in_cooldown():\n                self.cooldown_counter -= 1\n                self.wait = 0\n\n            if self.monitor_op(current, self.best):\n                self.best = current\n                self.wait = 0\n            elif not self.in_cooldown():\n                if self.wait >= self.patience:\n                    old_lr = float(K.get_value(self.model.optimizer.lr))\n                    if old_lr > self.min_lr:\n                        new_lr = old_lr * self.factor\n                        new_lr = max(new_lr, self.min_lr)\n                        K.set_value(self.model.optimizer.lr, new_lr)\n                        if self.verbose > 0:\n                            print('\\nEpoch %05d: ReduceLROnPlateau reducing learning '\n                                  'rate to %s.' % (epoch + 1, new_lr))\n                        self.cooldown_counter = self.cooldown\n                        self.wait = 0\n                self.wait += 1",
        "begin_line": 950,
        "end_line": 981,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.ReduceLROnPlateau.in_cooldown#983",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ReduceLROnPlateau",
        "signature": "keras.callbacks.ReduceLROnPlateau.in_cooldown(self)",
        "snippet": "    def in_cooldown(self):\n        return self.cooldown_counter > 0",
        "begin_line": 983,
        "end_line": 984,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.CSVLogger.__init__#1007",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CSVLogger",
        "signature": "keras.callbacks.CSVLogger.__init__(self, filename, separator=',', append=False)",
        "snippet": "    def __init__(self, filename, separator=',', append=False):\n        self.sep = separator\n        self.filename = filename\n        self.append = append\n        self.writer = None\n        self.keys = None\n        self.append_header = True\n        self.file_flags = 'b' if six.PY2 and os.name == 'nt' else ''\n        super(CSVLogger, self).__init__()",
        "begin_line": 1007,
        "end_line": 1015,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.CSVLogger.on_train_begin#1017",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CSVLogger",
        "signature": "keras.callbacks.CSVLogger.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        if self.append:\n            if os.path.exists(self.filename):\n                with open(self.filename, 'r' + self.file_flags) as f:\n                    self.append_header = not bool(len(f.readline()))\n            self.csv_file = open(self.filename, 'a' + self.file_flags)\n        else:\n            self.csv_file = open(self.filename, 'w' + self.file_flags)",
        "begin_line": 1017,
        "end_line": 1024,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.CSVLogger.on_epoch_end#1026",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CSVLogger",
        "signature": "keras.callbacks.CSVLogger.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        def handle_value(k):\n            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n            if isinstance(k, six.string_types):\n                return k\n            elif isinstance(k, Iterable) and not is_zero_dim_ndarray:\n                return '\"[%s]\"' % (', '.join(map(str, k)))\n            else:\n                return k\n\n        if self.keys is None:\n            self.keys = sorted(logs.keys())\n\n        if self.model.stop_training:\n            # We set NA so that csv parsers do not fail for this last epoch.\n            logs = dict([(k, logs[k]) if k in logs else (k, 'NA') for k in self.keys])\n\n        if not self.writer:\n            class CustomDialect(csv.excel):\n                delimiter = self.sep\n\n            self.writer = csv.DictWriter(self.csv_file,\n                                         fieldnames=['epoch'] + self.keys, dialect=CustomDialect)\n            if self.append_header:\n                self.writer.writeheader()\n\n        row_dict = OrderedDict({'epoch': epoch})\n        row_dict.update((key, handle_value(logs[key])) for key in self.keys)\n        self.writer.writerow(row_dict)\n        self.csv_file.flush()",
        "begin_line": 1026,
        "end_line": 1057,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.CSVLogger.handle_value#1029",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CSVLogger",
        "signature": "keras.callbacks.CSVLogger.handle_value(k)",
        "snippet": "        def handle_value(k):\n            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n            if isinstance(k, six.string_types):\n                return k\n            elif isinstance(k, Iterable) and not is_zero_dim_ndarray:\n                return '\"[%s]\"' % (', '.join(map(str, k)))\n            else:\n                return k",
        "begin_line": 1029,
        "end_line": 1036,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.CustomDialect.on_epoch_end#1026",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CustomDialect",
        "signature": "keras.callbacks.CustomDialect.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        def handle_value(k):\n            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n            if isinstance(k, six.string_types):\n                return k\n            elif isinstance(k, Iterable) and not is_zero_dim_ndarray:\n                return '\"[%s]\"' % (', '.join(map(str, k)))\n            else:\n                return k\n\n        if self.keys is None:\n            self.keys = sorted(logs.keys())\n\n        if self.model.stop_training:\n            # We set NA so that csv parsers do not fail for this last epoch.\n            logs = dict([(k, logs[k]) if k in logs else (k, 'NA') for k in self.keys])\n\n        if not self.writer:\n            class CustomDialect(csv.excel):\n                delimiter = self.sep\n\n            self.writer = csv.DictWriter(self.csv_file,\n                                         fieldnames=['epoch'] + self.keys, dialect=CustomDialect)\n            if self.append_header:\n                self.writer.writeheader()\n\n        row_dict = OrderedDict({'epoch': epoch})\n        row_dict.update((key, handle_value(logs[key])) for key in self.keys)\n        self.writer.writerow(row_dict)\n        self.csv_file.flush()",
        "begin_line": 1026,
        "end_line": 1057,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.CSVLogger.on_train_end#1059",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CSVLogger",
        "signature": "keras.callbacks.CSVLogger.on_train_end(self, logs=None)",
        "snippet": "    def on_train_end(self, logs=None):\n        self.csv_file.close()\n        self.writer = None",
        "begin_line": 1059,
        "end_line": 1061,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.callbacks.LambdaCallback.__init__#1116",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.LambdaCallback",
        "signature": "keras.callbacks.LambdaCallback.__init__(self, on_epoch_begin=None, on_epoch_end=None, on_batch_begin=None, on_batch_end=None, on_train_begin=None, on_train_end=None, **kwargs)",
        "snippet": "    def __init__(self,\n                 on_epoch_begin=None,\n                 on_epoch_end=None,\n                 on_batch_begin=None,\n                 on_batch_end=None,\n                 on_train_begin=None,\n                 on_train_end=None,\n                 **kwargs):\n        super(LambdaCallback, self).__init__()\n        self.__dict__.update(kwargs)\n        if on_epoch_begin is not None:\n            self.on_epoch_begin = on_epoch_begin\n        else:\n            self.on_epoch_begin = lambda epoch, logs: None\n        if on_epoch_end is not None:\n            self.on_epoch_end = on_epoch_end\n        else:\n            self.on_epoch_end = lambda epoch, logs: None\n        if on_batch_begin is not None:\n            self.on_batch_begin = on_batch_begin\n        else:\n            self.on_batch_begin = lambda batch, logs: None\n        if on_batch_end is not None:\n            self.on_batch_end = on_batch_end\n        else:\n            self.on_batch_end = lambda batch, logs: None\n        if on_train_begin is not None:\n            self.on_train_begin = on_train_begin\n        else:\n            self.on_train_begin = lambda logs: None\n        if on_train_end is not None:\n            self.on_train_end = on_train_end\n        else:\n            self.on_train_end = lambda logs: None",
        "begin_line": 1116,
        "end_line": 1149,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.mobilenet.relu6#86",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet",
        "signature": "keras.applications.mobilenet.relu6(x)",
        "snippet": "def relu6(x):\n    return K.relu(x, max_value=6)",
        "begin_line": 86,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.mobilenet.preprocess_input#90",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet",
        "signature": "keras.applications.mobilenet.preprocess_input(x)",
        "snippet": "def preprocess_input(x):\n    \"\"\"Preprocesses a numpy array encoding a batch of images.\n\n    # Arguments\n        x: a 4D numpy array consists of RGB values within [0, 255].\n\n    # Returns\n        Preprocessed array.\n    \"\"\"\n    return imagenet_utils.preprocess_input(x, mode='tf')",
        "begin_line": 90,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.mobilenet.MobileNet#102",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet",
        "signature": "keras.applications.mobilenet.MobileNet(input_shape=None, alpha=1.0, depth_multiplier=1, dropout=0.001, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)",
        "snippet": "def MobileNet(input_shape=None,\n              alpha=1.0,\n              depth_multiplier=1,\n              dropout=1e-3,\n              include_top=True,\n              weights='imagenet',\n              input_tensor=None,\n              pooling=None,\n              classes=1000):\n    \"\"\"Instantiates the MobileNet architecture.\n\n    To load a MobileNet model via `load_model`, import the custom\n    objects `relu6` and pass them to the `custom_objects` parameter.\n    E.g.\n    model = load_model('mobilenet.h5', custom_objects={\n                       'relu6': mobilenet.relu6})\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or (3, 224, 224) (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(200, 200, 3)` would be one valid value.\n        alpha: controls the width of the network.\n            - If `alpha` < 1.0, proportionally decreases the number\n                of filters in each layer.\n            - If `alpha` > 1.0, proportionally increases the number\n                of filters in each layer.\n            - If `alpha` = 1, default number of filters from the paper\n                 are used at each layer.\n        depth_multiplier: depth multiplier for depthwise convolution\n            (also called the resolution multiplier)\n        dropout: dropout rate\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    \"\"\"\n\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as ImageNet with `include_top` '\n                         'as true, `classes` should be 1000')\n\n    # Determine proper input shape and default size.\n    if input_shape is None:\n        default_size = 224\n    else:\n        if K.image_data_format() == 'channels_first':\n            rows = input_shape[1]\n            cols = input_shape[2]\n        else:\n            rows = input_shape[0]\n            cols = input_shape[1]\n\n        if rows == cols and rows in [128, 160, 192, 224]:\n            default_size = rows\n        else:\n            default_size = 224\n\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=default_size,\n                                      min_size=32,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if K.image_data_format() == 'channels_last':\n        row_axis, col_axis = (0, 1)\n    else:\n        row_axis, col_axis = (1, 2)\n    rows = input_shape[row_axis]\n    cols = input_shape[col_axis]\n\n    if weights == 'imagenet':\n        if depth_multiplier != 1:\n            raise ValueError('If imagenet weights are being loaded, '\n                             'depth multiplier must be 1')\n\n        if alpha not in [0.25, 0.50, 0.75, 1.0]:\n            raise ValueError('If imagenet weights are being loaded, '\n                             'alpha can be one of'\n                             '`0.25`, `0.50`, `0.75` or `1.0` only.')\n\n        if rows != cols or rows not in [128, 160, 192, 224]:\n            raise ValueError('If imagenet weights are being loaded, '\n                             'input must have a static square shape (one of '\n                             '(128,128), (160,160), (192,192), or (224, 224)).'\n                             ' Input shape provided = %s' % (input_shape,))\n\n    if K.image_data_format() != 'channels_last':\n        warnings.warn('The MobileNet family of models is only available '\n                      'for the input data format \"channels_last\" '\n                      '(width, height, channels). '\n                      'However your settings specify the default '\n                      'data format \"channels_first\" (channels, width, height).'\n                      ' You should set `image_data_format=\"channels_last\"` '\n                      'in your Keras config located at ~/.keras/keras.json. '\n                      'The model being returned right now will expect inputs '\n                      'to follow the \"channels_last\" data format.')\n        K.set_image_data_format('channels_last')\n        old_data_format = 'channels_first'\n    else:\n        old_data_format = None\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    x = _conv_block(img_input, 32, alpha, strides=(2, 2))\n    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)\n\n    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier,\n                              strides=(2, 2), block_id=2)\n    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n\n    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier,\n                              strides=(2, 2), block_id=4)\n    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier,\n                              strides=(2, 2), block_id=6)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)\n\n    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier,\n                              strides=(2, 2), block_id=12)\n    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)\n\n    if include_top:\n        if K.image_data_format() == 'channels_first':\n            shape = (int(1024 * alpha), 1, 1)\n        else:\n            shape = (1, 1, int(1024 * alpha))\n\n        x = GlobalAveragePooling2D()(x)\n        x = Reshape(shape, name='reshape_1')(x)\n        x = Dropout(dropout, name='dropout')(x)\n        x = Conv2D(classes, (1, 1),\n                   padding='same', name='conv_preds')(x)\n        x = Activation('softmax', name='act_softmax')(x)\n        x = Reshape((classes,), name='reshape_2')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    # Create model.\n    model = Model(inputs, x, name='mobilenet_%0.2f_%s' % (alpha, rows))\n\n    # load weights\n    if weights == 'imagenet':\n        if K.image_data_format() == 'channels_first':\n            raise ValueError('Weights for \"channels_first\" format '\n                             'are not available.')\n        if alpha == 1.0:\n            alpha_text = '1_0'\n        elif alpha == 0.75:\n            alpha_text = '7_5'\n        elif alpha == 0.50:\n            alpha_text = '5_0'\n        else:\n            alpha_text = '2_5'\n\n        if include_top:\n            model_name = 'mobilenet_%s_%d_tf.h5' % (alpha_text, rows)\n            weigh_path = BASE_WEIGHT_PATH + model_name\n            weights_path = get_file(model_name,\n                                    weigh_path,\n                                    cache_subdir='models')\n        else:\n            model_name = 'mobilenet_%s_%d_tf_no_top.h5' % (alpha_text, rows)\n            weigh_path = BASE_WEIGHT_PATH + model_name\n            weights_path = get_file(model_name,\n                                    weigh_path,\n                                    cache_subdir='models')\n        model.load_weights(weights_path)\n    elif weights is not None:\n        model.load_weights(weights)\n\n    if old_data_format:\n        K.set_image_data_format(old_data_format)\n    return model",
        "begin_line": 102,
        "end_line": 334,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.mobilenet._conv_block#337",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet",
        "signature": "keras.applications.mobilenet._conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1))",
        "snippet": "def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):\n    \"\"\"Adds an initial convolution layer (with batch normalization and relu6).\n\n    # Arguments\n        inputs: Input tensor of shape `(rows, cols, 3)`\n            (with `channels_last` data format) or\n            (3, rows, cols) (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        alpha: controls the width of the network.\n            - If `alpha` < 1.0, proportionally decreases the number\n                of filters in each layer.\n            - If `alpha` > 1.0, proportionally increases the number\n                of filters in each layer.\n            - If `alpha` = 1, default number of filters from the paper\n                 are used at each layer.\n        kernel: An integer or tuple/list of 2 integers, specifying the\n            width and height of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution along the width and height.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n\n    # Input shape\n        4D tensor with shape:\n        `(samples, channels, rows, cols)` if data_format='channels_first'\n        or 4D tensor with shape:\n        `(samples, rows, cols, channels)` if data_format='channels_last'.\n\n    # Output shape\n        4D tensor with shape:\n        `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n        or 4D tensor with shape:\n        `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n        `rows` and `cols` values might have changed due to stride.\n\n    # Returns\n        Output tensor of block.\n    \"\"\"\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    filters = int(filters * alpha)\n    x = ZeroPadding2D(padding=(1, 1), name='conv1_pad')(inputs)\n    x = Conv2D(filters, kernel,\n               padding='valid',\n               use_bias=False,\n               strides=strides,\n               name='conv1')(x)\n    x = BatchNormalization(axis=channel_axis, name='conv1_bn')(x)\n    return Activation(relu6, name='conv1_relu')(x)",
        "begin_line": 337,
        "end_line": 392,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.mobilenet._depthwise_conv_block#395",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet",
        "signature": "keras.applications.mobilenet._depthwise_conv_block(inputs, pointwise_conv_filters, alpha, depth_multiplier=1, strides=(1, 1), block_id=1)",
        "snippet": "def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n                          depth_multiplier=1, strides=(1, 1), block_id=1):\n    \"\"\"Adds a depthwise convolution block.\n\n    A depthwise convolution block consists of a depthwise conv,\n    batch normalization, relu6, pointwise convolution,\n    batch normalization and relu6 activation.\n\n    # Arguments\n        inputs: Input tensor of shape `(rows, cols, channels)`\n            (with `channels_last` data format) or\n            (channels, rows, cols) (with `channels_first` data format).\n        pointwise_conv_filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the pointwise convolution).\n        alpha: controls the width of the network.\n            - If `alpha` < 1.0, proportionally decreases the number\n                of filters in each layer.\n            - If `alpha` > 1.0, proportionally increases the number\n                of filters in each layer.\n            - If `alpha` = 1, default number of filters from the paper\n                 are used at each layer.\n        depth_multiplier: The number of depthwise convolution output channels\n            for each input channel.\n            The total number of depthwise convolution output\n            channels will be equal to `filters_in * depth_multiplier`.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution along the width and height.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        block_id: Integer, a unique identification designating the block number.\n\n    # Input shape\n        4D tensor with shape:\n        `(batch, channels, rows, cols)` if data_format='channels_first'\n        or 4D tensor with shape:\n        `(batch, rows, cols, channels)` if data_format='channels_last'.\n\n    # Output shape\n        4D tensor with shape:\n        `(batch, filters, new_rows, new_cols)` if data_format='channels_first'\n        or 4D tensor with shape:\n        `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.\n        `rows` and `cols` values might have changed due to stride.\n\n    # Returns\n        Output tensor of block.\n    \"\"\"\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n\n    x = ZeroPadding2D(padding=(1, 1), name='conv_pad_%d' % block_id)(inputs)\n    x = DepthwiseConv2D((3, 3),\n                        padding='valid',\n                        depth_multiplier=depth_multiplier,\n                        strides=strides,\n                        use_bias=False,\n                        name='conv_dw_%d' % block_id)(x)\n    x = BatchNormalization(axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n    x = Activation(relu6, name='conv_dw_%d_relu' % block_id)(x)\n\n    x = Conv2D(pointwise_conv_filters, (1, 1),\n               padding='same',\n               use_bias=False,\n               strides=(1, 1),\n               name='conv_pw_%d' % block_id)(x)\n    x = BatchNormalization(axis=channel_axis, name='conv_pw_%d_bn' % block_id)(x)\n    return Activation(relu6, name='conv_pw_%d_relu' % block_id)(x)",
        "begin_line": 395,
        "end_line": 463,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.resnet50.identity_block#43",
        "src_path": "keras/applications/resnet50.py",
        "class_name": "keras.applications.resnet50",
        "signature": "keras.applications.resnet50.identity_block(input_tensor, kernel_size, filters, stage, block)",
        "snippet": "def identity_block(input_tensor, kernel_size, filters, stage, block):\n    \"\"\"The identity block is the block that has no conv layer at shortcut.\n\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: default 3, the kernel size of middle conv layer at main path\n        filters: list of integers, the filters of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: 'a','b'..., current block label, used for generating layer names\n\n    # Returns\n        Output tensor for the block.\n    \"\"\"\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters2, kernel_size,\n               padding='same', name=conv_name_base + '2b')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    x = layers.add([x, input_tensor])\n    x = Activation('relu')(x)\n    return x",
        "begin_line": 43,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.resnet50.conv_block#81",
        "src_path": "keras/applications/resnet50.py",
        "class_name": "keras.applications.resnet50",
        "signature": "keras.applications.resnet50.conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2))",
        "snippet": "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n    \"\"\"A block that has a conv layer at shortcut.\n\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: default 3, the kernel size of middle conv layer at main path\n        filters: list of integers, the filters of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: 'a','b'..., current block label, used for generating layer names\n        strides: Strides for the first conv layer in the block.\n\n    # Returns\n        Output tensor for the block.\n\n    Note that from stage 3,\n    the first conv layer at main path is with strides=(2, 2)\n    And the shortcut should have strides=(2, 2) as well\n    \"\"\"\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = Conv2D(filters1, (1, 1), strides=strides,\n               name=conv_name_base + '2a')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters2, kernel_size, padding='same',\n               name=conv_name_base + '2b')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n                      name=conv_name_base + '1')(input_tensor)\n    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n\n    x = layers.add([x, shortcut])\n    x = Activation('relu')(x)\n    return x",
        "begin_line": 81,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.resnet50.ResNet50#129",
        "src_path": "keras/applications/resnet50.py",
        "class_name": "keras.applications.resnet50",
        "signature": "keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def ResNet50(include_top=True, weights='imagenet',\n             input_tensor=None, input_shape=None,\n             pooling=None,\n             classes=1000):\n    \"\"\"Instantiates the ResNet50 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format='channels_last'` in your Keras config\n    at ~/.keras/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 224)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 197.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=197,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n\n    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n    x = Conv2D(64, (7, 7), strides=(2, 2), padding='valid', name='conv1')(x)\n    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n\n    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n\n    if include_top:\n        x = Flatten()(x)\n        x = Dense(classes, activation='softmax', name='fc1000')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='resnet50')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n                                    WEIGHTS_PATH,\n                                    cache_subdir='models',\n                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n        else:\n            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                    WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models',\n                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n            if include_top:\n                maxpool = model.get_layer(name='avg_pool')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name='fc1000')\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n\n        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n            warnings.warn('You are using the TensorFlow backend, yet you '\n                          'are using the Theano '\n                          'image data format convention '\n                          '(`image_data_format=\"channels_first\"`). '\n                          'For best performance, set '\n                          '`image_data_format=\"channels_last\"` in '\n                          'your Keras config '\n                          'at ~/.keras/keras.json.')\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model",
        "begin_line": 129,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRNN2D.__init__#126",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRNN2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRNN2D.__init__(self, cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)",
        "snippet": "    def __init__(self, cell,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if unroll:\n            raise TypeError('Unrolling isn\\'t possible with '\n                            'convolutional RNNs.')\n        if isinstance(cell, (list, tuple)):\n            # The StackedConvRNN2DCells isn't implemented yet.\n            raise TypeError('It is not possible at the moment to'\n                            'stack convolutional cells.')\n        super(ConvRNN2D, self).__init__(cell,\n                                        return_sequences,\n                                        return_state,\n                                        go_backwards,\n                                        stateful,\n                                        unroll,\n                                        **kwargs)\n        self.input_spec = [InputSpec(ndim=5)]",
        "begin_line": 126,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRNN2D.compute_output_shape#149",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRNN2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRNN2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        cell = self.cell\n        if cell.data_format == 'channels_first':\n            rows = input_shape[3]\n            cols = input_shape[4]\n        elif cell.data_format == 'channels_last':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        rows = conv_utils.conv_output_length(rows,\n                                             cell.kernel_size[0],\n                                             padding=cell.padding,\n                                             stride=cell.strides[0],\n                                             dilation=cell.dilation_rate[0])\n        cols = conv_utils.conv_output_length(cols,\n                                             cell.kernel_size[1],\n                                             padding=cell.padding,\n                                             stride=cell.strides[1],\n                                             dilation=cell.dilation_rate[1])\n\n        if cell.data_format == 'channels_first':\n            output_shape = input_shape[:2] + (cell.filters, rows, cols)\n        elif cell.data_format == 'channels_last':\n            output_shape = input_shape[:2] + (rows, cols, cell.filters)\n\n        if not self.return_sequences:\n            output_shape = output_shape[:1] + output_shape[2:]\n\n        if self.return_state:\n            output_shape = [output_shape]\n            if cell.data_format == 'channels_first':\n                output_shape += [(input_shape[0], cell.filters, rows, cols)\n                                 for _ in range(2)]\n            elif cell.data_format == 'channels_last':\n                output_shape += [(input_shape[0], rows, cols, cell.filters)\n                                 for _ in range(2)]\n        return output_shape",
        "begin_line": 149,
        "end_line": 187,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRNN2D.build#189",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRNN2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRNN2D.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        # Note input_shape will be list of shapes of initial states and\n        # constants if these are passed in __call__.\n        if self._num_constants is not None:\n            constants_shape = input_shape[-self._num_constants:]\n        else:\n            constants_shape = None\n\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        self.input_spec[0] = InputSpec(shape=(batch_size, None) + input_shape[2:5])\n\n        # allow cell (if layer) to build before we set or validate state_spec\n        if isinstance(self.cell, Layer):\n            step_input_shape = (input_shape[0],) + input_shape[2:]\n            if constants_shape is not None:\n                self.cell.build([step_input_shape] + constants_shape)\n            else:\n                self.cell.build(step_input_shape)\n\n        # set or validate state_spec\n        if hasattr(self.cell.state_size, '__len__'):\n            state_size = list(self.cell.state_size)\n        else:\n            state_size = [self.cell.state_size]\n\n        if self.state_spec is not None:\n            # initial_state was passed in call, check compatibility\n            if self.cell.data_format == 'channels_first':\n                ch_dim = 1\n            elif self.cell.data_format == 'channels_last':\n                ch_dim = 3\n            if not [spec.shape[ch_dim] for spec in self.state_spec] == state_size:\n                raise ValueError(\n                    'An initial_state was passed that is not compatible with '\n                    '`cell.state_size`. Received `state_spec`={}; '\n                    'However `cell.state_size` is '\n                    '{}'.format([spec.shape for spec in self.state_spec], self.cell.state_size))\n        else:\n            if self.cell.data_format == 'channels_first':\n                self.state_spec = [InputSpec(shape=(None, dim, None, None))\n                                   for dim in state_size]\n            elif self.cell.data_format == 'channels_last':\n                self.state_spec = [InputSpec(shape=(None, None, None, dim))\n                                   for dim in state_size]\n        if self.stateful:\n            self.reset_states()\n        self.built = True",
        "begin_line": 189,
        "end_line": 238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRNN2D.get_initial_state#240",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRNN2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRNN2D.get_initial_state(self, inputs)",
        "snippet": "    def get_initial_state(self, inputs):\n        # (samples, timesteps, rows, cols, filters)\n        initial_state = K.zeros_like(inputs)\n        # (samples, rows, cols, filters)\n        initial_state = K.sum(initial_state, axis=1)\n        shape = list(self.cell.kernel_shape)\n        shape[-1] = self.cell.filters\n        initial_state = self.cell.input_conv(initial_state,\n                                             K.zeros(tuple(shape)),\n                                             padding=self.cell.padding)\n        # Fix for Theano because it needs\n        # K.int_shape to work in call() with initial_state.\n        keras_shape = list(K.int_shape(inputs))\n        keras_shape.pop(1)\n        if K.image_data_format() == 'channels_first':\n            indices = 2, 3\n        else:\n            indices = 1, 2\n        for i, j in enumerate(indices):\n            keras_shape[j] = conv_utils.conv_output_length(\n                keras_shape[j],\n                shape[i],\n                padding=self.cell.padding,\n                stride=self.cell.strides[i],\n                dilation=self.cell.dilation_rate[i])\n        initial_state._keras_shape = keras_shape\n\n        if hasattr(self.cell.state_size, '__len__'):\n            return [initial_state for _ in self.cell.state_size]\n        else:\n            return [initial_state]",
        "begin_line": 240,
        "end_line": 270,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRNN2D.__call__#272",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRNN2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRNN2D.__call__(self, inputs, initial_state=None, constants=None, **kwargs)",
        "snippet": "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n        inputs, initial_state, constants = self._standardize_args(\n            inputs, initial_state, constants)\n\n        if initial_state is None and constants is None:\n            return super(ConvRNN2D, self).__call__(inputs, **kwargs)\n\n        # If any of `initial_state` or `constants` are specified and are Keras\n        # tensors, then add them to the inputs and temporarily modify the\n        # input_spec to include them.\n\n        additional_inputs = []\n        additional_specs = []\n        if initial_state is not None:\n            kwargs['initial_state'] = initial_state\n            additional_inputs += initial_state\n            self.state_spec = []\n            for state in initial_state:\n                try:\n                    shape = K.int_shape(state)\n                # Fix for Theano\n                except TypeError:\n                    shape = tuple(None for _ in range(K.ndim(state)))\n                self.state_spec.append(InputSpec(shape=shape))\n\n            additional_specs += self.state_spec\n        if constants is not None:\n            kwargs['constants'] = constants\n            additional_inputs += constants\n            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n                                   for constant in constants]\n            self._num_constants = len(constants)\n            additional_specs += self.constants_spec\n        # at this point additional_inputs cannot be empty\n        for tensor in additional_inputs:\n            if K.is_keras_tensor(tensor) != K.is_keras_tensor(additional_inputs[0]):\n                raise ValueError('The initial state or constants of an RNN'\n                                 ' layer cannot be specified with a mix of'\n                                 ' Keras tensors and non-Keras tensors')\n\n        if K.is_keras_tensor(additional_inputs[0]):\n            # Compute the full input spec, including state and constants\n            full_input = [inputs] + additional_inputs\n            full_input_spec = self.input_spec + additional_specs\n            # Perform the call with temporarily replaced input_spec\n            original_input_spec = self.input_spec\n            self.input_spec = full_input_spec\n            output = super(ConvRNN2D, self).__call__(full_input, **kwargs)\n            self.input_spec = original_input_spec\n            return output\n        else:\n            return super(ConvRNN2D, self).__call__(inputs, **kwargs)",
        "begin_line": 272,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRNN2D.call#325",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRNN2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRNN2D.call(self, inputs, mask=None, training=None, initial_state=None, constants=None)",
        "snippet": "    def call(self,\n             inputs,\n             mask=None,\n             training=None,\n             initial_state=None,\n             constants=None):\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            inputs = inputs[0]\n        if initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if isinstance(mask, list):\n            mask = mask[0]\n\n        if len(initial_state) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_state)) +\n                             ' initial states.')\n        timesteps = K.int_shape(inputs)[1]\n\n        kwargs = {}\n        if has_arg(self.cell.call, 'training'):\n            kwargs['training'] = training\n\n        if constants:\n            if not has_arg(self.cell.call, 'constants'):\n                raise ValueError('RNN cell does not support constants')\n\n            def step(inputs, states):\n                constants = states[-self._num_constants:]\n                states = states[:-self._num_constants]\n                return self.cell.call(inputs, states, constants=constants,\n                                      **kwargs)\n        else:\n            def step(inputs, states):\n                return self.cell.call(inputs, states, **kwargs)\n\n        last_output, outputs, states = K.rnn(step,\n                                             inputs,\n                                             initial_state,\n                                             constants=constants,\n                                             go_backwards=self.go_backwards,\n                                             mask=mask,\n                                             input_length=timesteps)\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        if self.return_sequences:\n            output = outputs\n        else:\n            output = last_output\n\n        # Properly set learning phase\n        if getattr(last_output, '_uses_learning_phase', False):\n            output._uses_learning_phase = True\n\n        if self.return_state:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            else:\n                states = list(states)\n            return [output] + states\n        else:\n            return output",
        "begin_line": 325,
        "end_line": 398,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRNN2D.step#366",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRNN2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRNN2D.step(inputs, states)",
        "snippet": "            def step(inputs, states):\n                return self.cell.call(inputs, states, **kwargs)",
        "begin_line": 366,
        "end_line": 367,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRNN2D.reset_states#400",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRNN2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRNN2D.reset_states(self, states=None)",
        "snippet": "    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError('Layer must be stateful.')\n        input_shape = self.input_spec[0].shape\n        state_shape = self.compute_output_shape(input_shape)\n        if self.return_state:\n            state_shape = state_shape[0]\n        if self.return_sequences:\n            state_shape = state_shape[:1] + state_shape[2:]\n        if None in state_shape:\n            raise ValueError('If a RNN is stateful, it needs to know '\n                             'its batch size. Specify the batch size '\n                             'of your input tensors: \\n'\n                             '- If using a Sequential model, '\n                             'specify the batch size by passing '\n                             'a `batch_input_shape` '\n                             'argument to your first layer.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a '\n                             '`batch_shape` argument to your Input layer.\\n'\n                             'The same thing goes for the number of rows and columns.')\n\n        # helper function\n        def get_tuple_shape(nb_channels):\n            result = list(state_shape)\n            if self.cell.data_format == 'channels_first':\n                result[1] = nb_channels\n            elif self.cell.data_format == 'channels_last':\n                result[3] = nb_channels\n            else:\n                raise KeyError\n            return tuple(result)\n\n        # initialize state if None\n        if self.states[0] is None:\n            if hasattr(self.cell.state_size, '__len__'):\n                self.states = [K.zeros(get_tuple_shape(dim))\n                               for dim in self.cell.state_size]\n            else:\n                self.states = [K.zeros(get_tuple_shape(self.cell.state_size))]\n        elif states is None:\n            if hasattr(self.cell.state_size, '__len__'):\n                for state, dim in zip(self.states, self.cell.state_size):\n                    K.set_value(state, np.zeros(get_tuple_shape(dim)))\n            else:\n                K.set_value(self.states[0],\n                            np.zeros(get_tuple_shape(self.cell.state_size)))\n        else:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            if len(states) != len(self.states):\n                raise ValueError('Layer ' + self.name + ' expects ' +\n                                 str(len(self.states)) + ' states, '\n                                                         'but it received ' + str(len(states)) +\n                                 ' state values. Input received: ' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if hasattr(self.cell.state_size, '__len__'):\n                    dim = self.cell.state_size[index]\n                else:\n                    dim = self.cell.state_size\n                if value.shape != get_tuple_shape(dim):\n                    raise ValueError('State ' + str(index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected shape=' +\n                                     str(get_tuple_shape(dim)) +\n                                     ', found shape=' + str(value.shape))\n                # TODO: consider batch calls to `set_value`.\n                K.set_value(state, value)",
        "begin_line": 400,
        "end_line": 468,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRNN2D.get_tuple_shape#423",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRNN2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRNN2D.get_tuple_shape(nb_channels)",
        "snippet": "        def get_tuple_shape(nb_channels):\n            result = list(state_shape)\n            if self.cell.data_format == 'channels_first':\n                result[1] = nb_channels\n            elif self.cell.data_format == 'channels_last':\n                result[3] = nb_channels\n            else:\n                raise KeyError\n            return tuple(result)",
        "begin_line": 423,
        "end_line": 431,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.__init__#538",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 **kwargs):\n        super(ConvLSTM2DCell, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, 2, 'dilation_rate')\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n            warnings.warn(\n                'RNN dropout is no longer supported with the Theano backend '\n                'due to technical limitations. '\n                'You can either set `dropout` and `recurrent_dropout` to 0, '\n                'or use the TensorFlow backend.')\n            dropout = 0.\n            recurrent_dropout = 0.\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.state_size = (self.filters, self.filters)\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None",
        "begin_line": 538,
        "end_line": 596,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.build#598",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.filters * 4)\n        self.kernel_shape = kernel_shape\n        recurrent_kernel_shape = self.kernel_size + (self.filters, self.filters * 4)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=recurrent_kernel_shape,\n            initializer=self.recurrent_initializer,\n            name='recurrent_kernel',\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters * 4,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n            if self.unit_forget_bias:\n                bias_value = np.zeros((self.filters * 4,))\n                bias_value[self.filters: self.filters * 2] = 1.\n                K.set_value(self.bias, bias_value)\n        else:\n            self.bias = None\n\n        self.kernel_i = self.kernel[:, :, :, :self.filters]\n        self.recurrent_kernel_i = self.recurrent_kernel[:, :, :, :self.filters]\n        self.kernel_f = self.kernel[:, :, :, self.filters: self.filters * 2]\n        self.recurrent_kernel_f = self.recurrent_kernel[:, :, :, self.filters: self.filters * 2]\n        self.kernel_c = self.kernel[:, :, :, self.filters * 2: self.filters * 3]\n        self.recurrent_kernel_c = self.recurrent_kernel[:, :, :, self.filters * 2: self.filters * 3]\n        self.kernel_o = self.kernel[:, :, :, self.filters * 3:]\n        self.recurrent_kernel_o = self.recurrent_kernel[:, :, :, self.filters * 3:]\n\n        if self.use_bias:\n            self.bias_i = self.bias[:self.filters]\n            self.bias_f = self.bias[self.filters: self.filters * 2]\n            self.bias_c = self.bias[self.filters * 2: self.filters * 3]\n            self.bias_o = self.bias[self.filters * 3:]\n        else:\n            self.bias_i = None\n            self.bias_f = None\n            self.bias_c = None\n            self.bias_o = None\n        self.built = True",
        "begin_line": 598,
        "end_line": 655,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.call#657",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.call(self, inputs, states, training=None)",
        "snippet": "    def call(self, inputs, states, training=None):\n        if 0 < self.dropout < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n                K.ones_like(inputs),\n                self.dropout,\n                training=training,\n                count=4)\n        if (0 < self.recurrent_dropout < 1 and\n                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask = _generate_dropout_mask(\n                K.ones_like(states[1]),\n                self.recurrent_dropout,\n                training=training,\n                count=4)\n\n        # dropout matrices for input units\n        dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        h_tm1 = states[0]  # previous memory state\n        c_tm1 = states[1]  # previous carry state\n\n        if 0 < self.dropout < 1.:\n            inputs_i = inputs * dp_mask[0]\n            inputs_f = inputs * dp_mask[1]\n            inputs_c = inputs * dp_mask[2]\n            inputs_o = inputs * dp_mask[3]\n        else:\n            inputs_i = inputs\n            inputs_f = inputs\n            inputs_c = inputs\n            inputs_o = inputs\n\n        if 0 < self.recurrent_dropout < 1.:\n            h_tm1_i = h_tm1 * rec_dp_mask[0]\n            h_tm1_f = h_tm1 * rec_dp_mask[1]\n            h_tm1_c = h_tm1 * rec_dp_mask[2]\n            h_tm1_o = h_tm1 * rec_dp_mask[3]\n        else:\n            h_tm1_i = h_tm1\n            h_tm1_f = h_tm1\n            h_tm1_c = h_tm1\n            h_tm1_o = h_tm1\n\n        x_i = self.input_conv(inputs_i, self.kernel_i, self.bias_i,\n                              padding=self.padding)\n        x_f = self.input_conv(inputs_f, self.kernel_f, self.bias_f,\n                              padding=self.padding)\n        x_c = self.input_conv(inputs_c, self.kernel_c, self.bias_c,\n                              padding=self.padding)\n        x_o = self.input_conv(inputs_o, self.kernel_o, self.bias_o,\n                              padding=self.padding)\n        h_i = self.recurrent_conv(h_tm1_i,\n                                  self.recurrent_kernel_i)\n        h_f = self.recurrent_conv(h_tm1_f,\n                                  self.recurrent_kernel_f)\n        h_c = self.recurrent_conv(h_tm1_c,\n                                  self.recurrent_kernel_c)\n        h_o = self.recurrent_conv(h_tm1_o,\n                                  self.recurrent_kernel_o)\n\n        i = self.recurrent_activation(x_i + h_i)\n        f = self.recurrent_activation(x_f + h_f)\n        c = f * c_tm1 + i * self.activation(x_c + h_c)\n        o = self.recurrent_activation(x_o + h_o)\n        h = o * self.activation(c)\n\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase = True\n\n        return h, [h, c]",
        "begin_line": 657,
        "end_line": 729,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.input_conv#731",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.input_conv(self, x, w, b=None, padding='valid')",
        "snippet": "    def input_conv(self, x, w, b=None, padding='valid'):\n        conv_out = K.conv2d(x, w, strides=self.strides,\n                            padding=padding,\n                            data_format=self.data_format,\n                            dilation_rate=self.dilation_rate)\n        if b is not None:\n            conv_out = K.bias_add(conv_out, b,\n                                  data_format=self.data_format)\n        return conv_out",
        "begin_line": 731,
        "end_line": 739,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.recurrent_conv#741",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.recurrent_conv(self, x, w)",
        "snippet": "    def recurrent_conv(self, x, w):\n        conv_out = K.conv2d(x, w, strides=(1, 1),\n                            padding='same',\n                            data_format=self.data_format)\n        return conv_out",
        "begin_line": 741,
        "end_line": 745,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.get_config#747",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2DCell",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2DCell.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'filters': self.filters,\n                  'kernel_size': self.kernel_size,\n                  'strides': self.strides,\n                  'padding': self.padding,\n                  'data_format': self.data_format,\n                  'dilation_rate': self.dilation_rate,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation': activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'unit_forget_bias': self.unit_forget_bias,\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout}\n        base_config = super(ConvLSTM2DCell, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 747,
        "end_line": 770,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.__init__#894",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, go_backwards=False, stateful=False, dropout=0.0, recurrent_dropout=0.0, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 return_sequences=False,\n                 go_backwards=False,\n                 stateful=False,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 **kwargs):\n        cell = ConvLSTM2DCell(filters=filters,\n                              kernel_size=kernel_size,\n                              strides=strides,\n                              padding=padding,\n                              data_format=data_format,\n                              dilation_rate=dilation_rate,\n                              activation=activation,\n                              recurrent_activation=recurrent_activation,\n                              use_bias=use_bias,\n                              kernel_initializer=kernel_initializer,\n                              recurrent_initializer=recurrent_initializer,\n                              bias_initializer=bias_initializer,\n                              unit_forget_bias=unit_forget_bias,\n                              kernel_regularizer=kernel_regularizer,\n                              recurrent_regularizer=recurrent_regularizer,\n                              bias_regularizer=bias_regularizer,\n                              kernel_constraint=kernel_constraint,\n                              recurrent_constraint=recurrent_constraint,\n                              bias_constraint=bias_constraint,\n                              dropout=dropout,\n                              recurrent_dropout=recurrent_dropout)\n        super(ConvLSTM2D, self).__init__(cell,\n                                         return_sequences=return_sequences,\n                                         go_backwards=go_backwards,\n                                         stateful=stateful,\n                                         **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)",
        "begin_line": 894,
        "end_line": 946,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.call#948",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        return super(ConvLSTM2D, self).call(inputs,\n                                            mask=mask,\n                                            training=training,\n                                            initial_state=initial_state)",
        "begin_line": 948,
        "end_line": 952,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.filters#955",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.filters(self)",
        "snippet": "    def filters(self):\n        return self.cell.filters",
        "begin_line": 955,
        "end_line": 956,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.kernel_size#959",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.kernel_size(self)",
        "snippet": "    def kernel_size(self):\n        return self.cell.kernel_size",
        "begin_line": 959,
        "end_line": 960,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.strides#963",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.strides(self)",
        "snippet": "    def strides(self):\n        return self.cell.strides",
        "begin_line": 963,
        "end_line": 964,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.padding#967",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.padding(self)",
        "snippet": "    def padding(self):\n        return self.cell.padding",
        "begin_line": 967,
        "end_line": 968,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.data_format#971",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.data_format(self)",
        "snippet": "    def data_format(self):\n        return self.cell.data_format",
        "begin_line": 971,
        "end_line": 972,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.dilation_rate#975",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.dilation_rate(self)",
        "snippet": "    def dilation_rate(self):\n        return self.cell.dilation_rate",
        "begin_line": 975,
        "end_line": 976,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.activation#979",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.activation(self)",
        "snippet": "    def activation(self):\n        return self.cell.activation",
        "begin_line": 979,
        "end_line": 980,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_activation#983",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_activation(self)",
        "snippet": "    def recurrent_activation(self):\n        return self.cell.recurrent_activation",
        "begin_line": 983,
        "end_line": 984,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.use_bias#987",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.use_bias(self)",
        "snippet": "    def use_bias(self):\n        return self.cell.use_bias",
        "begin_line": 987,
        "end_line": 988,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.kernel_initializer#991",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.kernel_initializer(self)",
        "snippet": "    def kernel_initializer(self):\n        return self.cell.kernel_initializer",
        "begin_line": 991,
        "end_line": 992,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_initializer#995",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_initializer(self)",
        "snippet": "    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer",
        "begin_line": 995,
        "end_line": 996,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.bias_initializer#999",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.bias_initializer(self)",
        "snippet": "    def bias_initializer(self):\n        return self.cell.bias_initializer",
        "begin_line": 999,
        "end_line": 1000,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.unit_forget_bias#1003",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.unit_forget_bias(self)",
        "snippet": "    def unit_forget_bias(self):\n        return self.cell.unit_forget_bias",
        "begin_line": 1003,
        "end_line": 1004,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.kernel_regularizer#1007",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.kernel_regularizer(self)",
        "snippet": "    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer",
        "begin_line": 1007,
        "end_line": 1008,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_regularizer#1011",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_regularizer(self)",
        "snippet": "    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer",
        "begin_line": 1011,
        "end_line": 1012,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.bias_regularizer#1015",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.bias_regularizer(self)",
        "snippet": "    def bias_regularizer(self):\n        return self.cell.bias_regularizer",
        "begin_line": 1015,
        "end_line": 1016,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.kernel_constraint#1019",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.kernel_constraint(self)",
        "snippet": "    def kernel_constraint(self):\n        return self.cell.kernel_constraint",
        "begin_line": 1019,
        "end_line": 1020,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_constraint#1023",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_constraint(self)",
        "snippet": "    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint",
        "begin_line": 1023,
        "end_line": 1024,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.bias_constraint#1027",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.bias_constraint(self)",
        "snippet": "    def bias_constraint(self):\n        return self.cell.bias_constraint",
        "begin_line": 1027,
        "end_line": 1028,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.dropout#1031",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.dropout(self)",
        "snippet": "    def dropout(self):\n        return self.cell.dropout",
        "begin_line": 1031,
        "end_line": 1032,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_dropout#1035",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_dropout(self)",
        "snippet": "    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout",
        "begin_line": 1035,
        "end_line": 1036,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.get_config#1038",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'filters': self.filters,\n                  'kernel_size': self.kernel_size,\n                  'strides': self.strides,\n                  'padding': self.padding,\n                  'data_format': self.data_format,\n                  'dilation_rate': self.dilation_rate,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation': activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'unit_forget_bias': self.unit_forget_bias,\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout}\n        base_config = super(ConvLSTM2D, self).get_config()\n        del base_config['cell']\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1038,
        "end_line": 1063,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.from_config#1066",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        return cls(**config)",
        "begin_line": 1066,
        "end_line": 1067,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.inception_v3.conv2d_bn#43",
        "src_path": "keras/applications/inception_v3.py",
        "class_name": "keras.applications.inception_v3",
        "signature": "keras.applications.inception_v3.conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), name=None)",
        "snippet": "def conv2d_bn(x,\n              filters,\n              num_row,\n              num_col,\n              padding='same',\n              strides=(1, 1),\n              name=None):\n    \"\"\"Utility function to apply conv + BN.\n\n    # Arguments\n        x: input tensor.\n        filters: filters in `Conv2D`.\n        num_row: height of the convolution kernel.\n        num_col: width of the convolution kernel.\n        padding: padding mode in `Conv2D`.\n        strides: strides in `Conv2D`.\n        name: name of the ops; will become `name + '_conv'`\n            for the convolution and `name + '_bn'` for the\n            batch norm layer.\n\n    # Returns\n        Output tensor after applying `Conv2D` and `BatchNormalization`.\n    \"\"\"\n    if name is not None:\n        bn_name = name + '_bn'\n        conv_name = name + '_conv'\n    else:\n        bn_name = None\n        conv_name = None\n    if K.image_data_format() == 'channels_first':\n        bn_axis = 1\n    else:\n        bn_axis = 3\n    x = Conv2D(\n        filters, (num_row, num_col),\n        strides=strides,\n        padding=padding,\n        use_bias=False,\n        name=conv_name)(x)\n    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n    x = Activation('relu', name=name)(x)\n    return x",
        "begin_line": 43,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.inception_v3.InceptionV3#87",
        "src_path": "keras/applications/inception_v3.py",
        "class_name": "keras.applications.inception_v3",
        "signature": "keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def InceptionV3(include_top=True,\n                weights='imagenet',\n                input_tensor=None,\n                input_shape=None,\n                pooling=None,\n                classes=1000):\n    \"\"\"Instantiates the Inception v3 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format='channels_last'` in your Keras config\n    at ~/.keras/keras.json.\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n    Note that the default input image size for this model is 299x299.\n\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(299, 299, 3)` (with `channels_last` data format)\n            or `(3, 299, 299)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 139.\n            E.g. `(150, 150, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(\n        input_shape,\n        default_size=299,\n        min_size=139,\n        data_format=K.image_data_format(),\n        require_flatten=False,\n        weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    if K.image_data_format() == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = 3\n\n    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n    x = conv2d_bn(x, 64, 3, 3)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv2d_bn(x, 80, 1, 1, padding='valid')\n    x = conv2d_bn(x, 192, 3, 3, padding='valid')\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    # mixed 0, 1, 2: 35 x 35 x 256\n    branch1x1 = conv2d_bn(x, 64, 1, 1)\n\n    branch5x5 = conv2d_bn(x, 48, 1, 1)\n    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed0')\n\n    # mixed 1: 35 x 35 x 256\n    branch1x1 = conv2d_bn(x, 64, 1, 1)\n\n    branch5x5 = conv2d_bn(x, 48, 1, 1)\n    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed1')\n\n    # mixed 2: 35 x 35 x 256\n    branch1x1 = conv2d_bn(x, 64, 1, 1)\n\n    branch5x5 = conv2d_bn(x, 48, 1, 1)\n    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed2')\n\n    # mixed 3: 17 x 17 x 768\n    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(\n        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n\n    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n    x = layers.concatenate(\n        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n\n    # mixed 4: 17 x 17 x 768\n    branch1x1 = conv2d_bn(x, 192, 1, 1)\n\n    branch7x7 = conv2d_bn(x, 128, 1, 1)\n    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n\n    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed4')\n\n    # mixed 5, 6: 17 x 17 x 768\n    for i in range(2):\n        branch1x1 = conv2d_bn(x, 192, 1, 1)\n\n        branch7x7 = conv2d_bn(x, 160, 1, 1)\n        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n\n        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n\n        branch_pool = AveragePooling2D(\n            (3, 3), strides=(1, 1), padding='same')(x)\n        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n        x = layers.concatenate(\n            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n            axis=channel_axis,\n            name='mixed' + str(5 + i))\n\n    # mixed 7: 17 x 17 x 768\n    branch1x1 = conv2d_bn(x, 192, 1, 1)\n\n    branch7x7 = conv2d_bn(x, 192, 1, 1)\n    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n\n    branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed7')\n\n    # mixed 8: 8 x 8 x 1280\n    branch3x3 = conv2d_bn(x, 192, 1, 1)\n    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n                          strides=(2, 2), padding='valid')\n\n    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n    branch7x7x3 = conv2d_bn(\n        branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n\n    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n    x = layers.concatenate(\n        [branch3x3, branch7x7x3, branch_pool], axis=channel_axis, name='mixed8')\n\n    # mixed 9: 8 x 8 x 2048\n    for i in range(2):\n        branch1x1 = conv2d_bn(x, 320, 1, 1)\n\n        branch3x3 = conv2d_bn(x, 384, 1, 1)\n        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n        branch3x3 = layers.concatenate(\n            [branch3x3_1, branch3x3_2], axis=channel_axis, name='mixed9_' + str(i))\n\n        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n        branch3x3dbl = layers.concatenate(\n            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n\n        branch_pool = AveragePooling2D(\n            (3, 3), strides=(1, 1), padding='same')(x)\n        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n        x = layers.concatenate(\n            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n            axis=channel_axis,\n            name='mixed' + str(9 + i))\n    if include_top:\n        # Classification block\n        x = GlobalAveragePooling2D(name='avg_pool')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='inception_v3')\n\n    # load weights\n    if weights == 'imagenet':\n        if K.image_data_format() == 'channels_first':\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n        if include_top:\n            weights_path = get_file(\n                'inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n                WEIGHTS_PATH,\n                cache_subdir='models',\n                file_hash='9a0d58056eeedaa3f26cb7ebd46da564')\n        else:\n            weights_path = get_file(\n                'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                WEIGHTS_PATH_NO_TOP,\n                cache_subdir='models',\n                file_hash='bcbd6486424b2319ff4ef7d526e38f63')\n        model.load_weights(weights_path)\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model",
        "begin_line": 87,
        "end_line": 395,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.inception_v3.preprocess_input#398",
        "src_path": "keras/applications/inception_v3.py",
        "class_name": "keras.applications.inception_v3",
        "signature": "keras.applications.inception_v3.preprocess_input(x)",
        "snippet": "def preprocess_input(x):\n    \"\"\"Preprocesses a numpy array encoding a batch of images.\n\n    # Arguments\n        x: a 4D numpy array consists of RGB values within [0, 255].\n\n    # Returns\n        Preprocessed array.\n    \"\"\"\n    return imagenet_utils.preprocess_input(x, mode='tf')",
        "begin_line": 398,
        "end_line": 407,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Merge.__init__#67",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.__init__(self, layers=None, mode='sum', concat_axis=-1, dot_axes=-1, output_shape=None, output_mask=None, arguments=None, node_indices=None, tensor_indices=None, name=None)",
        "snippet": "    def __init__(self, layers=None, mode='sum', concat_axis=-1,\n                 dot_axes=-1, output_shape=None, output_mask=None,\n                 arguments=None, node_indices=None, tensor_indices=None,\n                 name=None):\n        warnings.warn('The `Merge` layer is deprecated '\n                      'and will be removed after 08/2017. '\n                      'Use instead layers from `keras.layers.merge`, '\n                      'e.g. `add`, `concatenate`, etc.', stacklevel=2)\n        self.layers = layers\n        self.mode = mode\n        self.concat_axis = concat_axis\n        self.dot_axes = dot_axes\n        self._output_shape = output_shape\n        self.node_indices = node_indices\n        self._output_mask = output_mask\n        self.arguments = arguments if arguments else {}\n        self._initial_weights = None\n        self._updates = []\n        self._losses = []\n        self._per_input_updates = {}\n        self._per_input_losses = {}\n\n        # Layer parameters.\n        self._inbound_nodes = []\n        self._outbound_nodes = []\n        self.constraints = {}\n        self._trainable_weights = []\n        self._non_trainable_weights = []\n        self.supports_masking = True\n        self.uses_learning_phase = False\n        self.input_spec = None  # Compatible with anything.\n        self.stateful = False\n        self.trainable = True\n        if not name:\n            prefix = self.__class__.__name__.lower()\n            name = prefix + '_' + str(K.get_uid(prefix))\n        self.name = name\n\n        if layers:\n            # This exists for backwards compatibility.\n            # equivalent to:\n            # merge = Merge(layers=None)\n            # output = merge([input_tensor_1, input_tensor_2])\n            if not node_indices:\n                # By default we connect to\n                # the 1st output stream in the input layer.\n                node_indices = [0 for _ in range(len(layers))]\n            if not tensor_indices:\n                tensor_indices = [0 for _ in range(len(layers))]\n            self._arguments_validation(layers, mode,\n                                       concat_axis, dot_axes,\n                                       node_indices, tensor_indices)\n            self.built = True\n            input_tensors = []\n            input_masks = []\n            for i, layer in enumerate(layers):\n                node_index = node_indices[i]\n                tensor_index = tensor_indices[i]\n                inbound_node = layer._inbound_nodes[node_index]\n                input_tensors.append(inbound_node.output_tensors[tensor_index])\n                input_masks.append(inbound_node.output_masks[tensor_index])\n            self(input_tensors, mask=input_masks)\n        else:\n            self.built = False",
        "begin_line": 67,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Merge._arguments_validation#132",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge._arguments_validation(self, layers, mode, concat_axis, dot_axes, node_indices, tensor_indices)",
        "snippet": "    def _arguments_validation(self, layers, mode, concat_axis, dot_axes,\n                              node_indices, tensor_indices):\n        \"\"\"Validates user-passed arguments and raises exceptions\n        as appropriate.\n        \"\"\"\n        if not callable(mode):\n            if mode not in {'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'}:\n                raise ValueError('Invalid merge mode: ' + str(mode))\n        if not isinstance(layers, (list, tuple)) or len(layers) < 2:\n            raise TypeError('A Merge should only be applied to a list of '\n                            'layers with at least 2 elements. Found: ' +\n                            str(layers))\n\n        if tensor_indices is None:\n            tensor_indices = [None for _ in range(len(layers))]\n\n        input_shapes = []\n        for i, layer in enumerate(layers):\n            layer_output_shape = layer.get_output_shape_at(node_indices[i])\n            if isinstance(layer_output_shape, list):\n                # Case: the layer has multiple output tensors\n                # and we only need a specific one.\n                layer_output_shape = layer_output_shape[tensor_indices[i]]\n            input_shapes.append(layer_output_shape)\n\n        if mode in {'sum', 'mul', 'ave', 'cos', 'max'}:\n            input_shapes_set = set(input_shapes)\n            if len(input_shapes_set) > 1:\n                raise ValueError('Only layers of same output shape can '\n                                 'be merged using ' + mode + ' mode. ' +\n                                 'Layer shapes: %s' % input_shapes)\n        if mode in {'cos', 'dot'}:\n            if len(layers) > 2:\n                raise ValueError(mode + ' merge takes exactly 2 layers')\n            shape1 = input_shapes[0]\n            shape2 = input_shapes[1]\n            n1 = len(shape1)\n            n2 = len(shape2)\n            if isinstance(dot_axes, int):\n                if dot_axes < 0:\n                    self.dot_axes = [dot_axes % n1, dot_axes % n2]\n                else:\n                    self.dot_axes = [dot_axes, ] * 2\n            if not isinstance(self.dot_axes, (list, tuple)):\n                raise TypeError('Invalid type for dot_axes - '\n                                'should be a list.')\n            if len(self.dot_axes) != 2:\n                raise ValueError('Invalid format for dot_axes - '\n                                 'should contain two elements.')\n            if not isinstance(self.dot_axes[0], int) or not isinstance(self.dot_axes[1], int):\n                raise ValueError('Invalid format for dot_axes - '\n                                 'list elements should be \"int\".')\n            if shape1[self.dot_axes[0]] != shape2[self.dot_axes[1]]:\n                raise ValueError('Dimension incompatibility using dot mode: '\n                                 '%s != %s. ' % (shape1[self.dot_axes[0]], shape2[self.dot_axes[1]]) +\n                                 'Layer shapes: %s, %s' % (shape1, shape2))\n        elif mode == 'concat':\n            reduced_inputs_shapes = [list(shape) for shape in input_shapes]\n            shape_set = set()\n            for i in range(len(reduced_inputs_shapes)):\n                del reduced_inputs_shapes[i][self.concat_axis]\n                shape_set.add(tuple(reduced_inputs_shapes[i]))\n            if len(shape_set) > 1:\n                raise ValueError('\"concat\" mode can only merge '\n                                 'layers with matching '\n                                 'output shapes except for the concat axis. '\n                                 'Layer shapes: %s' % (input_shapes))",
        "begin_line": 132,
        "end_line": 198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Merge.call#200",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        if not isinstance(inputs, list) or len(inputs) <= 1:\n            raise TypeError('Merge must be called on a list of tensors '\n                            '(at least 2). Got: ' + str(inputs))\n        # Case: \"mode\" is a lambda or function.\n        if callable(self.mode):\n            arguments = self.arguments\n            if has_arg(self.mode, 'mask'):\n                arguments['mask'] = mask\n            return self.mode(inputs, **arguments)\n\n        if self.mode == 'sum' or self.mode == 'ave':\n            s = inputs[0]\n            for i in range(1, len(inputs)):\n                s += inputs[i]\n            if self.mode == 'ave':\n                s /= len(inputs)\n            return s\n\n        elif self.mode == 'concat':\n            return K.concatenate(inputs, axis=self.concat_axis)\n\n        elif self.mode == 'mul':\n            s = inputs[0]\n            for i in range(1, len(inputs)):\n                s *= inputs[i]\n            return s\n        elif self.mode == 'max':\n            s = inputs[0]\n            for i in range(1, len(inputs)):\n                s = K.maximum(s, inputs[i])\n            return s\n        elif self.mode == 'dot':\n            l1 = inputs[0]\n            l2 = inputs[1]\n            output = K.batch_dot(l1, l2, self.dot_axes)\n            return output\n\n        elif self.mode == 'cos':\n            l1 = inputs[0]\n            l2 = inputs[1]\n            denominator = K.sqrt(K.batch_dot(l1, l1, self.dot_axes) *\n                                 K.batch_dot(l2, l2, self.dot_axes))\n            denominator = K.maximum(denominator, K.epsilon())\n            output = K.batch_dot(l1, l2, self.dot_axes) / denominator\n            output = K.expand_dims(output, 1)\n            return output\n        else:\n            raise ValueError('Unknown merge mode.')",
        "begin_line": 200,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Merge.compute_output_shape#250",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        # Must have multiple input shape tuples.\n        assert isinstance(input_shape, list)\n        # Case: callable self._output_shape.\n        if callable(self.mode):\n            if callable(self._output_shape):\n                output_shape = self._output_shape(input_shape)\n                return output_shape\n            elif self._output_shape is not None:\n                return (input_shape[0][0],) + tuple(self._output_shape)\n            else:\n                raise ValueError('The Merge layer ' + self.name +\n                                 ' has a callable `mode` argument, '\n                                 'and we cannot infer its output shape '\n                                 'because no `output_shape` '\n                                 'argument was provided. '\n                                 'Make sure to pass a shape tuple '\n                                 '(or callable) '\n                                 '`output_shape` to Merge.')\n        # Pre-defined merge modes.\n        input_shapes = input_shape\n        if self.mode in ['sum', 'mul', 'ave', 'max']:\n            # All tuples in input_shapes should be the same.\n            return input_shapes[0]\n        elif self.mode == 'concat':\n            output_shape = list(input_shapes[0])\n            for shape in input_shapes[1:]:\n                if output_shape[self.concat_axis] is None or shape[self.concat_axis] is None:\n                    output_shape[self.concat_axis] = None\n                    break\n                output_shape[self.concat_axis] += shape[self.concat_axis]\n            return tuple(output_shape)\n        elif self.mode in ['dot', 'cos']:\n            shape1 = list(input_shapes[0])\n            shape2 = list(input_shapes[1])\n            shape1.pop(self.dot_axes[0])\n            shape2.pop(self.dot_axes[1])\n            shape2.pop(0)\n            output_shape = shape1 + shape2\n            if len(output_shape) == 1:\n                output_shape += [1]\n            return tuple(output_shape)",
        "begin_line": 250,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Merge.compute_mask#293",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if mask is None or all([m is None for m in mask]):\n            return None\n\n        assert hasattr(mask, '__len__') and len(mask) == len(inputs)\n\n        if self.mode in ['sum', 'mul', 'ave', 'max']:\n            masks = [K.expand_dims(m, 0) for m in mask if m is not None]\n            return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)\n        elif self.mode == 'concat':\n            # Make a list of masks while making sure\n            # the dimensionality of each mask\n            # is the same as the corresponding input.\n            masks = []\n            for input_i, mask_i in zip(inputs, mask):\n                if mask_i is None:\n                    # Input is unmasked. Append all 1s to masks,\n                    masks.append(K.ones_like(input_i, dtype='bool'))\n                elif K.ndim(mask_i) < K.ndim(input_i):\n                    # Mask is smaller than the input, expand it\n                    masks.append(K.expand_dims(mask_i))\n                else:\n                    masks.append(mask_i)\n            concatenated = K.concatenate(masks, axis=self.concat_axis)\n            return K.all(concatenated, axis=-1, keepdims=False)\n        elif self.mode in ['cos', 'dot']:\n            return None\n        elif callable(self.mode):\n            if callable(self._output_mask):\n                return self._output_mask(mask)\n            else:\n                return self._output_mask\n        else:\n            # This should have been caught earlier.\n            raise ValueError('Invalid merge mode: {}'.format(self.mode))",
        "begin_line": 293,
        "end_line": 327,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Merge.get_config#329",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.get_config(self)",
        "snippet": "    def get_config(self):\n        if isinstance(self.mode, python_types.LambdaType):\n            mode = func_dump(self.mode)\n            mode_type = 'lambda'\n        elif callable(self.mode):\n            mode = self.mode.__name__\n            mode_type = 'function'\n        else:\n            mode = self.mode\n            mode_type = 'raw'\n\n        if isinstance(self._output_shape, python_types.LambdaType):\n            output_shape = func_dump(self._output_shape)\n            output_shape_type = 'lambda'\n        elif callable(self._output_shape):\n            output_shape = self._output_shape.__name__\n            output_shape_type = 'function'\n        else:\n            output_shape = self._output_shape\n            output_shape_type = 'raw'\n\n        if isinstance(self._output_mask, python_types.LambdaType):\n            output_mask = func_dump(self._output_mask)\n            output_mask_type = 'lambda'\n        elif callable(self._output_mask):\n            output_mask = self._output_mask.__name__\n            output_mask_type = 'function'\n        else:\n            output_mask = self._output_mask\n            output_mask_type = 'raw'\n\n        return {'name': self.name,\n                'mode': mode,\n                'mode_type': mode_type,\n                'concat_axis': self.concat_axis,\n                'dot_axes': self.dot_axes,\n                'output_shape': output_shape,\n                'output_shape_type': output_shape_type,\n                'output_mask': output_mask,\n                'output_mask_type': output_mask_type,\n                'arguments': self.arguments}",
        "begin_line": 329,
        "end_line": 369,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Merge.from_config#372",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        config = config.copy()\n        mode_type = config.pop('mode_type')\n        if mode_type == 'function':\n            mode = globals()[config['mode']]\n        elif mode_type == 'lambda':\n            mode = func_load(config['mode'], globs=globals())\n        else:\n            mode = config['mode']\n\n        output_shape_type = config.pop('output_shape_type', None)\n        if output_shape_type == 'function':\n            output_shape = globals()[config['output_shape']]\n        elif output_shape_type == 'lambda':\n            output_shape = func_load(config['output_shape'],\n                                     globs=globals())\n        else:\n            output_shape = config.get('output_shape')\n\n        output_mask_type = config.pop('output_mask_type', None)\n        if output_mask_type == 'function':\n            output_mask = globals()[config['output_mask']]\n        elif output_mask_type == 'lambda':\n            output_mask = func_load(config['output_mask'],\n                                    globs=globals())\n        else:\n            output_mask = config.get('output_mask')\n\n        config['mode'] = mode\n        config['output_shape'] = output_shape\n        config['output_mask'] = output_mask\n        return super(Merge, cls).from_config(config)",
        "begin_line": 372,
        "end_line": 403,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.merge#406",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers",
        "signature": "keras.legacy.layers.merge(inputs, mode='sum', concat_axis=-1, dot_axes=-1, output_shape=None, output_mask=None, arguments=None, name=None)",
        "snippet": "def merge(inputs, mode='sum', concat_axis=-1,\n          dot_axes=-1, output_shape=None, output_mask=None,\n          arguments=None, name=None):\n    \"\"\"Functional merge, to apply to Keras tensors (NOT layers).\n    Returns a Keras tensor.\n    # Example\n    ```python\n    tensor_a = Input(shape=(32,))\n    tensor_b = Input(shape=(32,))\n    merged_tensor = merge([tensor_a, tensor_b], mode='concat', concat_axis=1)\n    ```\n    # Arguments\n        mode: String or lambda/function. If string, must be one\n            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'.\n            If lambda/function, it should take as input a list of tensors\n            and return a single tensor.\n        concat_axis: Integer, axis to use in mode `concat`.\n        dot_axes: Integer or tuple of integers,\n            axes to use in mode `dot` or `cos`.\n        output_shape: Shape tuple (tuple of integers), or lambda/function\n            to compute output_shape (only if merge mode is a lambda/function).\n            If the latter case, it should take as input a list of shape tuples\n            (1:1 mapping to input tensors) and return a single shape tuple,\n            including the batch size\n            (same convention as the `compute_output_shape` method of layers).\n        node_indices: Optional list of integers containing\n            the output node index for each input layer\n            (in case some input layers have multiple output nodes).\n            will default to an array of 0s if not provided.\n        tensor_indices: Optional list of indices of output tensors\n            to consider for merging\n            (in case some input layer node returns multiple tensors).\n    \"\"\"\n    warnings.warn('The `merge` function is deprecated '\n                  'and will be removed after 08/2017. '\n                  'Use instead layers from `keras.layers.merge`, '\n                  'e.g. `add`, `concatenate`, etc.', stacklevel=2)\n    all_keras_tensors = True\n    for x in inputs:\n        if not hasattr(x, '_keras_history'):\n            all_keras_tensors = False\n            break\n    if all_keras_tensors:\n        input_layers = []\n        node_indices = []\n        tensor_indices = []\n        for x in inputs:\n            input_layer, node_index, tensor_index = x._keras_history\n            input_layers.append(input_layer)\n            node_indices.append(node_index)\n            tensor_indices.append(tensor_index)\n        merge_layer = Merge(input_layers, mode=mode,\n                            concat_axis=concat_axis,\n                            dot_axes=dot_axes,\n                            output_shape=output_shape,\n                            output_mask=output_mask,\n                            arguments=arguments,\n                            node_indices=node_indices,\n                            tensor_indices=tensor_indices,\n                            name=name)\n        return merge_layer._inbound_nodes[0].output_tensors[0]\n    else:\n        merge_layer = Merge(mode=mode,\n                            concat_axis=concat_axis,\n                            dot_axes=dot_axes,\n                            output_shape=output_shape,\n                            output_mask=output_mask,\n                            arguments=arguments,\n                            name=name)\n        return merge_layer(inputs)",
        "begin_line": 406,
        "end_line": 475,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.MaxoutDense.__init__#522",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.MaxoutDense",
        "signature": "keras.legacy.layers.MaxoutDense.__init__(self, output_dim, nb_feature=4, init='glorot_uniform', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, **kwargs)",
        "snippet": "    def __init__(self, output_dim,\n                 nb_feature=4,\n                 init='glorot_uniform',\n                 weights=None,\n                 W_regularizer=None,\n                 b_regularizer=None,\n                 activity_regularizer=None,\n                 W_constraint=None,\n                 b_constraint=None,\n                 bias=True,\n                 input_dim=None,\n                 **kwargs):\n        warnings.warn('The `MaxoutDense` layer is deprecated '\n                      'and will be removed after 06/2017.')\n        self.output_dim = output_dim\n        self.nb_feature = nb_feature\n        self.init = initializers.get(init)\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.initial_weights = weights\n        self.input_spec = InputSpec(ndim=2)\n\n        self.input_dim = input_dim\n        if self.input_dim:\n            kwargs['input_shape'] = (self.input_dim,)\n        super(MaxoutDense, self).__init__(**kwargs)",
        "begin_line": 522,
        "end_line": 554,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.MaxoutDense.build#556",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.MaxoutDense",
        "signature": "keras.legacy.layers.MaxoutDense.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[1]\n        self.input_spec = InputSpec(dtype=K.floatx(),\n                                    shape=(None, input_dim))\n\n        self.W = self.add_weight((self.nb_feature, input_dim, self.output_dim),\n                                 initializer=self.init,\n                                 name='W',\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        if self.bias:\n            self.b = self.add_weight((self.nb_feature, self.output_dim,),\n                                     initializer='zero',\n                                     name='b',\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n            del self.initial_weights\n        self.built = True",
        "begin_line": 556,
        "end_line": 578,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.MaxoutDense.compute_output_shape#580",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.MaxoutDense",
        "signature": "keras.legacy.layers.MaxoutDense.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) == 2\n        return (input_shape[0], self.output_dim)",
        "begin_line": 580,
        "end_line": 582,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.MaxoutDense.call#584",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.MaxoutDense",
        "signature": "keras.legacy.layers.MaxoutDense.call(self, x)",
        "snippet": "    def call(self, x):\n        # no activation, this layer is only linear.\n        output = K.dot(x, self.W)\n        if self.bias:\n            output += self.b\n        output = K.max(output, axis=1)\n        return output",
        "begin_line": 584,
        "end_line": 590,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.MaxoutDense.get_config#592",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.MaxoutDense",
        "signature": "keras.legacy.layers.MaxoutDense.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'output_dim': self.output_dim,\n                  'init': initializers.serialize(self.init),\n                  'nb_feature': self.nb_feature,\n                  'W_regularizer': regularizers.serialize(self.W_regularizer),\n                  'b_regularizer': regularizers.serialize(self.b_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'W_constraint': constraints.serialize(self.W_constraint),\n                  'b_constraint': constraints.serialize(self.b_constraint),\n                  'bias': self.bias,\n                  'input_dim': self.input_dim}\n        base_config = super(MaxoutDense, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 592,
        "end_line": 604,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Highway.__init__#647",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Highway",
        "signature": "keras.legacy.layers.Highway.__init__(self, init='glorot_uniform', activation=None, weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, **kwargs)",
        "snippet": "    def __init__(self,\n                 init='glorot_uniform',\n                 activation=None,\n                 weights=None,\n                 W_regularizer=None,\n                 b_regularizer=None,\n                 activity_regularizer=None,\n                 W_constraint=None,\n                 b_constraint=None,\n                 bias=True,\n                 input_dim=None,\n                 **kwargs):\n        warnings.warn('The `Highway` layer is deprecated '\n                      'and will be removed after 06/2017.')\n        if 'transform_bias' in kwargs:\n            kwargs.pop('transform_bias')\n            warnings.warn('`transform_bias` argument is deprecated and '\n                          'has been removed.')\n        self.init = initializers.get(init)\n        self.activation = activations.get(activation)\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.initial_weights = weights\n        self.input_spec = InputSpec(ndim=2)\n\n        self.input_dim = input_dim\n        if self.input_dim:\n            kwargs['input_shape'] = (self.input_dim,)\n        super(Highway, self).__init__(**kwargs)",
        "begin_line": 647,
        "end_line": 682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Highway.build#684",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Highway",
        "signature": "keras.legacy.layers.Highway.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[1]\n        self.input_spec = InputSpec(dtype=K.floatx(),\n                                    shape=(None, input_dim))\n\n        self.W = self.add_weight((input_dim, input_dim),\n                                 initializer=self.init,\n                                 name='W',\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.W_carry = self.add_weight((input_dim, input_dim),\n                                       initializer=self.init,\n                                       name='W_carry')\n        if self.bias:\n            self.b = self.add_weight((input_dim,),\n                                     initializer='zero',\n                                     name='b',\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n            self.b_carry = self.add_weight((input_dim,),\n                                           initializer='one',\n                                           name='b_carry')\n        else:\n            self.b_carry = None\n\n        if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n            del self.initial_weights\n        self.built = True",
        "begin_line": 684,
        "end_line": 712,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Highway.call#714",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Highway",
        "signature": "keras.legacy.layers.Highway.call(self, x)",
        "snippet": "    def call(self, x):\n        y = K.dot(x, self.W_carry)\n        if self.bias:\n            y += self.b_carry\n        transform_weight = activations.sigmoid(y)\n        y = K.dot(x, self.W)\n        if self.bias:\n            y += self.b\n        act = self.activation(y)\n        act *= transform_weight\n        output = act + (1 - transform_weight) * x\n        return output",
        "begin_line": 714,
        "end_line": 725,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Highway.get_config#727",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Highway",
        "signature": "keras.legacy.layers.Highway.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'init': initializers.serialize(self.init),\n                  'activation': activations.serialize(self.activation),\n                  'W_regularizer': regularizers.serialize(self.W_regularizer),\n                  'b_regularizer': regularizers.serialize(self.b_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'W_constraint': constraints.serialize(self.W_constraint),\n                  'b_constraint': constraints.serialize(self.b_constraint),\n                  'bias': self.bias,\n                  'input_dim': self.input_dim}\n        base_config = super(Highway, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 727,
        "end_line": 738,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.AtrousConvolution1D#741",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers",
        "signature": "keras.legacy.layers.AtrousConvolution1D(*args, **kwargs)",
        "snippet": "def AtrousConvolution1D(*args, **kwargs):\n    from ..layers import Conv1D\n    if 'atrous_rate' in kwargs:\n        rate = kwargs.pop('atrous_rate')\n    else:\n        rate = 1\n    kwargs['dilation_rate'] = rate\n    warnings.warn('The `AtrousConvolution1D` layer '\n                  ' has been deprecated. Use instead '\n                  'the `Conv1D` layer with the `dilation_rate` '\n                  'argument.')\n    return Conv1D(*args, **kwargs)",
        "begin_line": 741,
        "end_line": 752,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.AtrousConvolution2D#755",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers",
        "signature": "keras.legacy.layers.AtrousConvolution2D(*args, **kwargs)",
        "snippet": "def AtrousConvolution2D(*args, **kwargs):\n    from ..layers import Conv2D\n    if 'atrous_rate' in kwargs:\n        rate = kwargs.pop('atrous_rate')\n    else:\n        rate = 1\n    kwargs['dilation_rate'] = rate\n    warnings.warn('The `AtrousConvolution2D` layer '\n                  ' has been deprecated. Use instead '\n                  'the `Conv2D` layer with the `dilation_rate` '\n                  'argument.')\n    return Conv2D(*args, **kwargs)",
        "begin_line": 755,
        "end_line": 766,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.__init__#891",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.__init__(self, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, implementation=0, **kwargs)",
        "snippet": "    def __init__(self, return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 implementation=0,\n                 **kwargs):\n        super(Recurrent, self).__init__(**kwargs)\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n        self.go_backwards = go_backwards\n\n        self.stateful = stateful\n        self.unroll = unroll\n        self.implementation = implementation\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.state_spec = None\n        self.dropout = 0\n        self.recurrent_dropout = 0",
        "begin_line": 891,
        "end_line": 910,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.compute_output_shape#912",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        if self.return_sequences:\n            output_shape = (input_shape[0], input_shape[1], self.units)\n        else:\n            output_shape = (input_shape[0], self.units)\n\n        if self.return_state:\n            state_shape = [(input_shape[0], self.units) for _ in self.states]\n            return [output_shape] + state_shape\n        else:\n            return output_shape",
        "begin_line": 912,
        "end_line": 925,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.compute_mask#927",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.compute_mask(self, inputs, mask)",
        "snippet": "    def compute_mask(self, inputs, mask):\n        if isinstance(mask, list):\n            mask = mask[0]\n        output_mask = mask if self.return_sequences else None\n        if self.return_state:\n            state_mask = [None for _ in self.states]\n            return [output_mask] + state_mask\n        else:\n            return output_mask",
        "begin_line": 927,
        "end_line": 935,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.step#937",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.step(self, inputs, states)",
        "snippet": "    def step(self, inputs, states):\n        raise NotImplementedError",
        "begin_line": 937,
        "end_line": 938,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.get_constants#940",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.get_constants(self, inputs, training=None)",
        "snippet": "    def get_constants(self, inputs, training=None):\n        return []",
        "begin_line": 940,
        "end_line": 941,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.get_initial_state#943",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.get_initial_state(self, inputs)",
        "snippet": "    def get_initial_state(self, inputs):\n        # build an all-zero tensor of shape (samples, output_dim)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        initial_state = K.tile(initial_state, [1, self.units])  # (samples, output_dim)\n        initial_state = [initial_state for _ in range(len(self.states))]\n        return initial_state",
        "begin_line": 943,
        "end_line": 950,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.preprocess_input#952",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.preprocess_input(self, inputs, training=None)",
        "snippet": "    def preprocess_input(self, inputs, training=None):\n        return inputs",
        "begin_line": 952,
        "end_line": 953,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.__call__#955",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.__call__(self, inputs, initial_state=None, **kwargs)",
        "snippet": "    def __call__(self, inputs, initial_state=None, **kwargs):\n\n        # If there are multiple inputs, then\n        # they should be the main input and `initial_state`\n        # e.g. when loading model from file\n        if isinstance(inputs, (list, tuple)) and len(inputs) > 1 and initial_state is None:\n            initial_state = inputs[1:]\n            inputs = inputs[0]\n\n        # If `initial_state` is specified,\n        # and if it a Keras tensor,\n        # then add it to the inputs and temporarily\n        # modify the input spec to include the state.\n        if initial_state is None:\n            return super(Recurrent, self).__call__(inputs, **kwargs)\n\n        if not isinstance(initial_state, (list, tuple)):\n            initial_state = [initial_state]\n\n        is_keras_tensor = hasattr(initial_state[0], '_keras_history')\n        for tensor in initial_state:\n            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n                raise ValueError('The initial state of an RNN layer cannot be'\n                                 ' specified with a mix of Keras tensors and'\n                                 ' non-Keras tensors')\n\n        if is_keras_tensor:\n            # Compute the full input spec, including state\n            input_spec = self.input_spec\n            state_spec = self.state_spec\n            if not isinstance(input_spec, list):\n                input_spec = [input_spec]\n            if not isinstance(state_spec, list):\n                state_spec = [state_spec]\n            self.input_spec = input_spec + state_spec\n\n            # Compute the full inputs, including state\n            inputs = [inputs] + list(initial_state)\n\n            # Perform the call\n            output = super(Recurrent, self).__call__(inputs, **kwargs)\n\n            # Restore original input spec\n            self.input_spec = input_spec\n            return output\n        else:\n            kwargs['initial_state'] = initial_state\n            return super(Recurrent, self).__call__(inputs, **kwargs)",
        "begin_line": 955,
        "end_line": 1002,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.call#1004",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            initial_state = inputs[1:]\n            inputs = inputs[0]\n        elif initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if isinstance(mask, list):\n            mask = mask[0]\n\n        if len(initial_state) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_state)) +\n                             ' initial states.')\n        input_shape = K.int_shape(inputs)\n        timesteps = input_shape[1]\n        if self.unroll and timesteps in [None, 1]:\n            raise ValueError('Cannot unroll a RNN if the '\n                             'time dimension is undefined or equal to 1. \\n'\n                             '- If using a Sequential model, '\n                             'specify the time dimension by passing '\n                             'an `input_shape` or `batch_input_shape` '\n                             'argument to your first layer. If your '\n                             'first layer is an Embedding, you can '\n                             'also use the `input_length` argument.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a `shape` '\n                             'or `batch_shape` argument to your Input layer.')\n        constants = self.get_constants(inputs, training=None)\n        preprocessed_input = self.preprocess_input(inputs, training=None)\n        last_output, outputs, states = K.rnn(self.step,\n                                             preprocessed_input,\n                                             initial_state,\n                                             go_backwards=self.go_backwards,\n                                             mask=mask,\n                                             constants=constants,\n                                             unroll=self.unroll,\n                                             input_length=timesteps)\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        # Properly set learning phase\n        if 0 < self.dropout + self.recurrent_dropout:\n            last_output._uses_learning_phase = True\n            outputs._uses_learning_phase = True\n\n        if self.return_sequences:\n            output = outputs\n        else:\n            output = last_output\n\n        if self.return_state:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            else:\n                states = list(states)\n            return [output] + states\n        else:\n            return output",
        "begin_line": 1004,
        "end_line": 1073,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.reset_states#1075",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.reset_states(self, states=None)",
        "snippet": "    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError('Layer must be stateful.')\n        batch_size = self.input_spec[0].shape[0]\n        if not batch_size:\n            raise ValueError('If a RNN is stateful, it needs to know '\n                             'its batch size. Specify the batch size '\n                             'of your input tensors: \\n'\n                             '- If using a Sequential model, '\n                             'specify the batch size by passing '\n                             'a `batch_input_shape` '\n                             'argument to your first layer.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a '\n                             '`batch_shape` argument to your Input layer.')\n        # initialize state if None\n        if self.states[0] is None:\n            self.states = [K.zeros((batch_size, self.units))\n                           for _ in self.states]\n        elif states is None:\n            for state in self.states:\n                K.set_value(state, np.zeros((batch_size, self.units)))\n        else:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            if len(states) != len(self.states):\n                raise ValueError('Layer ' + self.name + ' expects ' +\n                                 str(len(self.states)) + ' states, '\n                                 'but it received ' + str(len(states)) +\n                                 ' state values. Input received: ' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if value.shape != (batch_size, self.units):\n                    raise ValueError('State ' + str(index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected shape=' +\n                                     str((batch_size, self.units)) +\n                                     ', found shape=' + str(value.shape))\n                K.set_value(state, value)",
        "begin_line": 1075,
        "end_line": 1113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.get_config#1115",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'return_sequences': self.return_sequences,\n                  'return_state': self.return_state,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful,\n                  'unroll': self.unroll,\n                  'implementation': self.implementation}\n        base_config = super(Recurrent, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1115,
        "end_line": 1123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.ConvRecurrent2D.__init__#1197",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.ConvRecurrent2D",
        "signature": "keras.legacy.layers.ConvRecurrent2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), return_sequences=False, go_backwards=False, stateful=False, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 return_sequences=False,\n                 go_backwards=False,\n                 stateful=False,\n                 **kwargs):\n        super(ConvRecurrent2D, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, 2, 'dilation_rate')\n        self.return_sequences = return_sequences\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.input_spec = [InputSpec(ndim=5)]\n        self.state_spec = None",
        "begin_line": 1197,
        "end_line": 1218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.ConvRecurrent2D.compute_output_shape#1220",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.ConvRecurrent2D",
        "signature": "keras.legacy.layers.ConvRecurrent2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n        if self.data_format == 'channels_first':\n            rows = input_shape[3]\n            cols = input_shape[4]\n        elif self.data_format == 'channels_last':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        rows = conv_utils.conv_output_length(rows,\n                                             self.kernel_size[0],\n                                             padding=self.padding,\n                                             stride=self.strides[0],\n                                             dilation=self.dilation_rate[0])\n        cols = conv_utils.conv_output_length(cols,\n                                             self.kernel_size[1],\n                                             padding=self.padding,\n                                             stride=self.strides[1],\n                                             dilation=self.dilation_rate[1])\n        if self.return_sequences:\n            if self.data_format == 'channels_first':\n                output_shape = (input_shape[0], input_shape[1],\n                                self.filters, rows, cols)\n            elif self.data_format == 'channels_last':\n                output_shape = (input_shape[0], input_shape[1],\n                                rows, cols, self.filters)\n        else:\n            if self.data_format == 'channels_first':\n                output_shape = (input_shape[0], self.filters, rows, cols)\n            elif self.data_format == 'channels_last':\n                output_shape = (input_shape[0], rows, cols, self.filters)\n\n        if self.return_state:\n            if self.data_format == 'channels_first':\n                output_shape = [output_shape] + [(input_shape[0], self.filters, rows, cols) for _ in range(2)]\n            elif self.data_format == 'channels_last':\n                output_shape = [output_shape] + [(input_shape[0], rows, cols, self.filters) for _ in range(2)]\n\n        return output_shape",
        "begin_line": 1220,
        "end_line": 1258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.legacy.layers.ConvRecurrent2D.get_config#1260",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.ConvRecurrent2D",
        "signature": "keras.legacy.layers.ConvRecurrent2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'filters': self.filters,\n                  'kernel_size': self.kernel_size,\n                  'strides': self.strides,\n                  'padding': self.padding,\n                  'data_format': self.data_format,\n                  'dilation_rate': self.dilation_rate,\n                  'return_sequences': self.return_sequences,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful}\n        base_config = super(ConvRecurrent2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1260,
        "end_line": 1271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.__init__#27",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.__init__(self, layer, **kwargs)",
        "snippet": "    def __init__(self, layer, **kwargs):\n        self.layer = layer\n        # Tracks mapping of Wrapper inputs to inner layer inputs. Useful when\n        # the inner layer has update ops that depend on its inputs (as opposed\n        # to the inputs to the Wrapper layer).\n        self._input_map = {}\n        super(Wrapper, self).__init__(**kwargs)",
        "begin_line": 27,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.95291872117067e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.build#35",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.build(self, input_shape=None)",
        "snippet": "    def build(self, input_shape=None):\n        self.built = True",
        "begin_line": 35,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.activity_regularizer#39",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.activity_regularizer(self)",
        "snippet": "    def activity_regularizer(self):\n        if hasattr(self.layer, 'activity_regularizer'):\n            return self.layer.activity_regularizer\n        else:\n            return None",
        "begin_line": 39,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.trainable#46",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.trainable(self)",
        "snippet": "    def trainable(self):\n        return self.layer.trainable",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.trainable#50",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.trainable(self, value)",
        "snippet": "    def trainable(self, value):\n        self.layer.trainable = value",
        "begin_line": 50,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.trainable_weights#54",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        return self.layer.trainable_weights",
        "begin_line": 54,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.non_trainable_weights#58",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        return self.layer.non_trainable_weights",
        "begin_line": 58,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.updates#62",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.updates(self)",
        "snippet": "    def updates(self):\n        if hasattr(self.layer, 'updates'):\n            return self.layer.updates\n        return []",
        "begin_line": 62,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_updates_for#67",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_updates_for(self, inputs=None)",
        "snippet": "    def get_updates_for(self, inputs=None):\n        # If the wrapper modifies the inputs, use the modified inputs to\n        # get the updates from the inner layer.\n        inner_inputs = inputs\n        if inputs is not None:\n            uid = _object_list_uid(inputs)\n            if uid in self._input_map:\n                inner_inputs = self._input_map[uid]\n\n        updates = self.layer.get_updates_for(inner_inputs)\n        updates += super(Wrapper, self).get_updates_for(inputs)\n        return updates",
        "begin_line": 67,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.losses#81",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.losses(self)",
        "snippet": "    def losses(self):\n        if hasattr(self.layer, 'losses'):\n            return self.layer.losses\n        return []",
        "begin_line": 81,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_losses_for#86",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_losses_for(self, inputs=None)",
        "snippet": "    def get_losses_for(self, inputs=None):\n        if inputs is None:\n            losses = self.layer.get_losses_for(None)\n            return losses + super(Wrapper, self).get_losses_for(None)\n        return super(Wrapper, self).get_losses_for(inputs)",
        "begin_line": 86,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_weights#92",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_weights(self)",
        "snippet": "    def get_weights(self):\n        return self.layer.get_weights()",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.set_weights#95",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        self.layer.set_weights(weights)",
        "begin_line": 95,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_config#98",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'layer': {'class_name': self.layer.__class__.__name__,\n                            'config': self.layer.get_config()}}\n        base_config = super(Wrapper, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 98,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.from_config#105",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        layer = deserialize_layer(config.pop('layer'),\n                                  custom_objects=custom_objects)\n        return cls(layer, **config)",
        "begin_line": 105,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.__init__#157",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.__init__(self, layer, **kwargs)",
        "snippet": "    def __init__(self, layer, **kwargs):\n        super(TimeDistributed, self).__init__(layer, **kwargs)\n        self.supports_masking = True",
        "begin_line": 157,
        "end_line": 159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.build#161",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        assert len(input_shape) >= 3\n        self.input_spec = InputSpec(shape=input_shape)\n        child_input_shape = (input_shape[0],) + input_shape[2:]\n        if not self.layer.built:\n            self.layer.build(child_input_shape)\n            self.layer.built = True\n        super(TimeDistributed, self).build()",
        "begin_line": 161,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.compute_output_shape#170",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        child_input_shape = (input_shape[0],) + input_shape[2:]\n        child_output_shape = self.layer.compute_output_shape(child_input_shape)\n        timesteps = input_shape[1]\n        return (child_output_shape[0], timesteps) + child_output_shape[1:]",
        "begin_line": 170,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.call#176",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.call(self, inputs, training=None, mask=None)",
        "snippet": "    def call(self, inputs, training=None, mask=None):\n        kwargs = {}\n        if has_arg(self.layer.call, 'training'):\n            kwargs['training'] = training\n        uses_learning_phase = False\n\n        input_shape = K.int_shape(inputs)\n        if input_shape[0]:\n            # batch size matters, use rnn-based implementation\n            def step(x, _):\n                global uses_learning_phase\n                output = self.layer.call(x, **kwargs)\n                if hasattr(output, '_uses_learning_phase'):\n                    uses_learning_phase = (output._uses_learning_phase or\n                                           uses_learning_phase)\n                return output, []\n\n            _, outputs, _ = K.rnn(step, inputs,\n                                  initial_states=[],\n                                  input_length=input_shape[1],\n                                  unroll=False)\n            y = outputs\n        else:\n            # No batch size specified, therefore the layer will be able\n            # to process batches of any size.\n            # We can go with reshape-based implementation for performance.\n            input_length = input_shape[1]\n            if not input_length:\n                input_length = K.shape(inputs)[1]\n            # Shape: (num_samples * timesteps, ...). And track the\n            # transformation in self._input_map.\n            input_uid = _object_list_uid(inputs)\n            inputs = K.reshape(inputs, (-1,) + input_shape[2:])\n            self._input_map[input_uid] = inputs\n            # (num_samples * timesteps, ...)\n            y = self.layer.call(inputs, **kwargs)\n            if hasattr(y, '_uses_learning_phase'):\n                uses_learning_phase = y._uses_learning_phase\n            # Shape: (num_samples, timesteps, ...)\n            output_shape = self.compute_output_shape(input_shape)\n            y = K.reshape(y, (-1, input_length) + output_shape[2:])\n\n        # Apply activity regularizer if any:\n        if (hasattr(self.layer, 'activity_regularizer') and\n           self.layer.activity_regularizer is not None):\n            regularization_loss = self.layer.activity_regularizer(y)\n            self.add_loss(regularization_loss, inputs)\n\n        if uses_learning_phase:\n            y._uses_learning_phase = True\n        return y",
        "begin_line": 176,
        "end_line": 226,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.step#185",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.step(x, _)",
        "snippet": "            def step(x, _):\n                global uses_learning_phase\n                output = self.layer.call(x, **kwargs)\n                if hasattr(output, '_uses_learning_phase'):\n                    uses_learning_phase = (output._uses_learning_phase or\n                                           uses_learning_phase)\n                return output, []",
        "begin_line": 185,
        "end_line": 191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.__init__#256",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.__init__(self, layer, merge_mode='concat', weights=None, **kwargs)",
        "snippet": "    def __init__(self, layer, merge_mode='concat', weights=None, **kwargs):\n        if merge_mode not in ['sum', 'mul', 'ave', 'concat', None]:\n            raise ValueError('Invalid merge mode. '\n                             'Merge mode should be one of '\n                             '{\"sum\", \"mul\", \"ave\", \"concat\", None}')\n        self.forward_layer = copy.copy(layer)\n        config = layer.get_config()\n        config['go_backwards'] = not config['go_backwards']\n        self.backward_layer = layer.__class__.from_config(config)\n        self.forward_layer.name = 'forward_' + self.forward_layer.name\n        self.backward_layer.name = 'backward_' + self.backward_layer.name\n        self.merge_mode = merge_mode\n        if weights:\n            nw = len(weights)\n            self.forward_layer.initial_weights = weights[:nw // 2]\n            self.backward_layer.initial_weights = weights[nw // 2:]\n        self.stateful = layer.stateful\n        self.return_sequences = layer.return_sequences\n        self.return_state = layer.return_state\n        self.supports_masking = True\n        self._trainable = True\n        super(Bidirectional, self).__init__(layer, **kwargs)\n        self.input_spec = layer.input_spec",
        "begin_line": 256,
        "end_line": 278,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.276090374906894e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.trainable#281",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.trainable(self)",
        "snippet": "    def trainable(self):\n        return self._trainable",
        "begin_line": 281,
        "end_line": 282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.trainable#285",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.trainable(self, value)",
        "snippet": "    def trainable(self, value):\n        self._trainable = value\n        self.forward_layer.trainable = value\n        self.backward_layer.trainable = value",
        "begin_line": 285,
        "end_line": 288,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.276090374906894e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.get_weights#290",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.get_weights(self)",
        "snippet": "    def get_weights(self):\n        return self.forward_layer.get_weights() + self.backward_layer.get_weights()",
        "begin_line": 290,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.set_weights#293",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        nw = len(weights)\n        self.forward_layer.set_weights(weights[:nw // 2])\n        self.backward_layer.set_weights(weights[nw // 2:])",
        "begin_line": 293,
        "end_line": 296,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.compute_output_shape#298",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        output_shape = self.forward_layer.compute_output_shape(input_shape)\n        if self.return_state:\n            state_shape = output_shape[1:]\n            output_shape = output_shape[0]\n\n        if self.merge_mode == 'concat':\n            output_shape = list(output_shape)\n            output_shape[-1] *= 2\n            output_shape = tuple(output_shape)\n        elif self.merge_mode is None:\n            output_shape = [output_shape, copy.copy(output_shape)]\n\n        if self.return_state:\n            if self.merge_mode is None:\n                return output_shape + state_shape + copy.copy(state_shape)\n            return [output_shape] + state_shape + copy.copy(state_shape)\n        return output_shape",
        "begin_line": 298,
        "end_line": 315,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.__call__#317",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.__call__(self, inputs, initial_state=None, **kwargs)",
        "snippet": "    def __call__(self, inputs, initial_state=None, **kwargs):\n        if isinstance(inputs, list):\n            if len(inputs) > 1:\n                initial_state = inputs[1:]\n            inputs = inputs[0]\n\n        if initial_state is None:\n            return super(Bidirectional, self).__call__(inputs, **kwargs)\n\n        # Standardize `initial_state` into list\n        if isinstance(initial_state, tuple):\n            initial_state = list(initial_state)\n        elif not isinstance(initial_state, list):\n            initial_state = [initial_state]\n\n        # Check if `initial_state` can be splitted into half\n        num_states = len(initial_state)\n        if num_states % 2 > 0:\n            raise ValueError(\n                'When passing `initial_state` to a Bidirectional RNN, the state '\n                'should be a list containing the states of the underlying RNNs. '\n                'Found: ' + str(initial_state))\n\n        # Applies the same workaround as in `RNN.__call__`, without handling constants\n        kwargs['initial_state'] = initial_state\n        additional_inputs = initial_state\n        additional_specs = [InputSpec(shape=K.int_shape(state))\n                            for state in initial_state]\n        self.forward_layer.state_spec = additional_specs[:num_states // 2]\n        self.backward_layer.state_spec = additional_specs[num_states // 2:]\n\n        is_keras_tensor = K.is_keras_tensor(additional_inputs[0])\n        for tensor in additional_inputs:\n            if K.is_keras_tensor(tensor) != is_keras_tensor:\n                raise ValueError('The initial state of a Bidirectional'\n                                 ' layer cannot be specified with a mix of'\n                                 ' Keras tensors and non-Keras tensors'\n                                 ' (a \"Keras tensor\" is a tensor that was'\n                                 ' returned by a Keras layer, or by `Input`)')\n\n        if is_keras_tensor:\n            # Compute the full input spec, including state\n            full_input = [inputs] + additional_inputs\n            full_input_spec = self.input_spec + additional_specs\n\n            # Perform the call with temporarily replaced input_spec\n            original_input_spec = self.input_spec\n            self.input_spec = full_input_spec\n            output = super(Bidirectional, self).__call__(full_input, **kwargs)\n            self.input_spec = original_input_spec\n            return output\n        else:\n            return super(Bidirectional, self).__call__(inputs, **kwargs)",
        "begin_line": 317,
        "end_line": 369,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.call#371",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.call(self, inputs, training=None, mask=None, initial_state=None)",
        "snippet": "    def call(self, inputs, training=None, mask=None, initial_state=None):\n        kwargs = {}\n        if has_arg(self.layer.call, 'training'):\n            kwargs['training'] = training\n        if has_arg(self.layer.call, 'mask'):\n            kwargs['mask'] = mask\n\n        if initial_state is not None and has_arg(self.layer.call, 'initial_state'):\n            forward_state = initial_state[:len(initial_state) // 2]\n            backward_state = initial_state[len(initial_state) // 2:]\n            y = self.forward_layer.call(inputs, initial_state=forward_state, **kwargs)\n            y_rev = self.backward_layer.call(inputs, initial_state=backward_state, **kwargs)\n        else:\n            y = self.forward_layer.call(inputs, **kwargs)\n            y_rev = self.backward_layer.call(inputs, **kwargs)\n\n        if self.return_state:\n            states = y[1:] + y_rev[1:]\n            y = y[0]\n            y_rev = y_rev[0]\n\n        if self.return_sequences:\n            y_rev = K.reverse(y_rev, 1)\n        if self.merge_mode == 'concat':\n            output = K.concatenate([y, y_rev])\n        elif self.merge_mode == 'sum':\n            output = y + y_rev\n        elif self.merge_mode == 'ave':\n            output = (y + y_rev) / 2\n        elif self.merge_mode == 'mul':\n            output = y * y_rev\n        elif self.merge_mode is None:\n            output = [y, y_rev]\n\n        # Properly set learning phase\n        if (getattr(y, '_uses_learning_phase', False) or\n           getattr(y_rev, '_uses_learning_phase', False)):\n            if self.merge_mode is None:\n                for out in output:\n                    out._uses_learning_phase = True\n            else:\n                output._uses_learning_phase = True\n\n        if self.return_state:\n            if self.merge_mode is None:\n                return output + states\n            return [output] + states\n        return output",
        "begin_line": 371,
        "end_line": 418,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.reset_states#420",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.reset_states(self)",
        "snippet": "    def reset_states(self):\n        self.forward_layer.reset_states()\n        self.backward_layer.reset_states()",
        "begin_line": 420,
        "end_line": 422,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.build#424",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        with K.name_scope(self.forward_layer.name):\n            self.forward_layer.build(input_shape)\n        with K.name_scope(self.backward_layer.name):\n            self.backward_layer.build(input_shape)\n        self.built = True",
        "begin_line": 424,
        "end_line": 429,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.276090374906894e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.compute_mask#431",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.compute_mask(self, inputs, mask)",
        "snippet": "    def compute_mask(self, inputs, mask):\n        if self.return_sequences:\n            if not self.merge_mode:\n                return [mask, mask]\n            else:\n                return mask\n        else:\n            return None",
        "begin_line": 431,
        "end_line": 438,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.trainable_weights#441",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if hasattr(self.forward_layer, 'trainable_weights'):\n            return (self.forward_layer.trainable_weights +\n                    self.backward_layer.trainable_weights)\n        return []",
        "begin_line": 441,
        "end_line": 445,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.non_trainable_weights#448",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        if hasattr(self.forward_layer, 'non_trainable_weights'):\n            return (self.forward_layer.non_trainable_weights +\n                    self.backward_layer.non_trainable_weights)\n        return []",
        "begin_line": 448,
        "end_line": 452,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.updates#455",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.updates(self)",
        "snippet": "    def updates(self):\n        if hasattr(self.forward_layer, 'updates'):\n            return self.forward_layer.updates + self.backward_layer.updates\n        return []",
        "begin_line": 455,
        "end_line": 458,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.losses#461",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.losses(self)",
        "snippet": "    def losses(self):\n        if hasattr(self.forward_layer, 'losses'):\n            return self.forward_layer.losses + self.backward_layer.losses\n        return []",
        "begin_line": 461,
        "end_line": 464,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.get_config#474",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'merge_mode': self.merge_mode}\n        base_config = super(Bidirectional, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 474,
        "end_line": 477,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.__init__#44",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.__init__(self, datapath, dataset, start=0, end=None, normalizer=None)",
        "snippet": "    def __init__(self, datapath, dataset, start=0, end=None, normalizer=None):\n        if h5py is None:\n            raise ImportError('The use of HDF5Matrix requires '\n                              'HDF5 and h5py installed.')\n\n        if datapath not in list(self.refs.keys()):\n            f = h5py.File(datapath)\n            self.refs[datapath] = f\n        else:\n            f = self.refs[datapath]\n        self.data = f[dataset]\n        self.start = start\n        if end is None:\n            self.end = self.data.shape[0]\n        else:\n            self.end = end\n        self.normalizer = normalizer",
        "begin_line": 44,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.__len__#62",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.__len__(self)",
        "snippet": "    def __len__(self):\n        return self.end - self.start",
        "begin_line": 62,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.__getitem__#65",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        if isinstance(key, slice):\n            start, stop = key.start, key.stop\n            if start is None:\n                start = 0\n            if stop is None:\n                stop = self.shape[0]\n            if stop + self.start <= self.end:\n                idx = slice(start + self.start, stop + self.start)\n            else:\n                raise IndexError\n        elif isinstance(key, (int, np.integer)):\n            if key + self.start < self.end:\n                idx = key + self.start\n            else:\n                raise IndexError\n        elif isinstance(key, np.ndarray):\n            if np.max(key) + self.start < self.end:\n                idx = (self.start + key).tolist()\n            else:\n                raise IndexError\n        elif isinstance(key, list):\n            if max(key) + self.start < self.end:\n                idx = [x + self.start for x in key]\n            else:\n                raise IndexError\n        else:\n            raise IndexError\n        if self.normalizer is not None:\n            return self.normalizer(self.data[idx])\n        else:\n            return self.data[idx]",
        "begin_line": 65,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.shape#99",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.shape(self)",
        "snippet": "    def shape(self):\n        \"\"\"Gets a numpy-style shape tuple giving the dataset dimensions.\n\n        # Returns\n            A numpy-style shape tuple.\n        \"\"\"\n        return (self.end - self.start,) + self.data.shape[1:]",
        "begin_line": 99,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.dtype#108",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.dtype(self)",
        "snippet": "    def dtype(self):\n        \"\"\"Gets the datatype of the dataset.\n\n        # Returns\n            A numpy dtype string.\n        \"\"\"\n        return self.data.dtype",
        "begin_line": 108,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.ndim#117",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.ndim(self)",
        "snippet": "    def ndim(self):\n        \"\"\"Gets the number of dimensions (rank) of the dataset.\n\n        # Returns\n            An integer denoting the number of dimensions (rank) of the dataset.\n        \"\"\"\n        return self.data.ndim",
        "begin_line": 117,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.size#126",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.size(self)",
        "snippet": "    def size(self):\n        \"\"\"Gets the total dataset size (number of elements).\n\n        # Returns\n            An integer denoting the number of elements in the dataset.\n        \"\"\"\n        return np.prod(self.shape)",
        "begin_line": 126,
        "end_line": 132,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.io_utils.ask_to_proceed_with_overwrite#135",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils",
        "signature": "keras.utils.io_utils.ask_to_proceed_with_overwrite(filepath)",
        "snippet": "def ask_to_proceed_with_overwrite(filepath):\n    \"\"\"Produces a prompt asking about overwriting a file.\n\n    # Arguments\n        filepath: the path to the file to be overwritten.\n\n    # Returns\n        True if we can proceed with overwrite, False otherwise.\n    \"\"\"\n    overwrite = six.moves.input('[WARNING] %s already exists - overwrite? '\n                                '[y/n]' % (filepath)).strip().lower()\n    while overwrite not in ('y', 'n'):\n        overwrite = six.moves.input('Enter \"y\" (overwrite) or \"n\" '\n                                    '(cancel).').strip().lower()\n    if overwrite == 'n':\n        return False\n    print('[TIP] Next time specify overwrite=True!')\n    return True",
        "begin_line": 135,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.training_utils._get_available_devices#13",
        "src_path": "keras/utils/training_utils.py",
        "class_name": "keras.utils.training_utils",
        "signature": "keras.utils.training_utils._get_available_devices()",
        "snippet": "def _get_available_devices():\n    return [x.name for x in K.get_session().list_devices()]",
        "begin_line": 13,
        "end_line": 14,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.training_utils._normalize_device_name#17",
        "src_path": "keras/utils/training_utils.py",
        "class_name": "keras.utils.training_utils",
        "signature": "keras.utils.training_utils._normalize_device_name(name)",
        "snippet": "def _normalize_device_name(name):\n    name = '/' + ':'.join(name.lower().replace('/', '').split(':')[-2:])\n    return name",
        "begin_line": 17,
        "end_line": 19,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.training_utils.multi_gpu_model#22",
        "src_path": "keras/utils/training_utils.py",
        "class_name": "keras.utils.training_utils",
        "signature": "keras.utils.training_utils.multi_gpu_model(model, gpus=None)",
        "snippet": "def multi_gpu_model(model, gpus=None):\n    \"\"\"Replicates a model on different GPUs.\n\n    Specifically, this function implements single-machine\n    multi-GPU data parallelism. It works in the following way:\n\n    - Divide the model's input(s) into multiple sub-batches.\n    - Apply a model copy on each sub-batch. Every model copy\n        is executed on a dedicated GPU.\n    - Concatenate the results (on CPU) into one big batch.\n\n    E.g. if your `batch_size` is 64 and you use `gpus=2`,\n    then we will divide the input into 2 sub-batches of 32 samples,\n    process each sub-batch on one GPU, then return the full\n    batch of 64 processed samples.\n\n    This induces quasi-linear speedup on up to 8 GPUs.\n\n    This function is only available with the TensorFlow backend\n    for the time being.\n\n    # Arguments\n        model: A Keras model instance. To avoid OOM errors,\n            this model could have been built on CPU, for instance\n            (see usage example below).\n        gpus: Integer >= 2 or list of integers, number of GPUs or\n            list of GPU IDs on which to create model replicas.\n\n    # Returns\n        A Keras `Model` instance which can be used just like the initial\n        `model` argument, but which distributes its workload on multiple GPUs.\n\n    # Example\n\n    ```python\n        import tensorflow as tf\n        from keras.applications import Xception\n        from keras.utils import multi_gpu_model\n        import numpy as np\n\n        num_samples = 1000\n        height = 224\n        width = 224\n        num_classes = 1000\n\n        # Instantiate the base model (or \"template\" model).\n        # We recommend doing this with under a CPU device scope,\n        # so that the model's weights are hosted on CPU memory.\n        # Otherwise they may end up hosted on a GPU, which would\n        # complicate weight sharing.\n        with tf.device('/cpu:0'):\n            model = Xception(weights=None,\n                             input_shape=(height, width, 3),\n                             classes=num_classes)\n\n        # Replicates the model on 8 GPUs.\n        # This assumes that your machine has 8 available GPUs.\n        parallel_model = multi_gpu_model(model, gpus=8)\n        parallel_model.compile(loss='categorical_crossentropy',\n                               optimizer='rmsprop')\n\n        # Generate dummy data.\n        x = np.random.random((num_samples, height, width, 3))\n        y = np.random.random((num_samples, num_classes))\n\n        # This `fit` call will be distributed on 8 GPUs.\n        # Since the batch size is 256, each GPU will process 32 samples.\n        parallel_model.fit(x, y, epochs=20, batch_size=256)\n\n        # Save model via the template model (which shares the same weights):\n        model.save('my_model.h5')\n    ```\n\n    # On model saving\n\n    To save the multi-gpu model, use `.save(fname)` or `.save_weights(fname)`\n    with the template model (the argument you passed to `multi_gpu_model`),\n    rather than the model returned by `multi_gpu_model`.\n    \"\"\"\n    if K.backend() != 'tensorflow':\n        raise ValueError('`multi_gpu_model` is only available '\n                         'with the TensorFlow backend.')\n\n    available_devices = _get_available_devices()\n    available_devices = [_normalize_device_name(name) for name in available_devices]\n    if not gpus:\n        # Using all visible GPUs when not specifying `gpus`\n        # e.g. CUDA_VISIBLE_DEVICES=0,2 python3 keras_mgpu.py\n        gpus = len([x for x in available_devices if 'gpu' in x])\n\n    if isinstance(gpus, (list, tuple)):\n        if len(gpus) <= 1:\n            raise ValueError('For multi-gpu usage to be effective, '\n                             'call `multi_gpu_model` with `len(gpus) >= 2`. '\n                             'Received: `gpus=%s`' % gpus)\n        num_gpus = len(gpus)\n        target_gpu_ids = gpus\n    else:\n        if gpus <= 1:\n            raise ValueError('For multi-gpu usage to be effective, '\n                             'call `multi_gpu_model` with `gpus >= 2`. '\n                             'Received: `gpus=%d`' % gpus)\n        num_gpus = gpus\n        target_gpu_ids = range(num_gpus)\n\n    import tensorflow as tf\n\n    target_devices = ['/cpu:0'] + ['/gpu:%d' % i for i in target_gpu_ids]\n    for device in target_devices:\n        if device not in available_devices:\n            raise ValueError(\n                'To call `multi_gpu_model` with `gpus=%d`, '\n                'we expect the following devices to be available: %s. '\n                'However this machine only has: %s. '\n                'Try reducing `gpus`.' % (gpus,\n                                          target_devices,\n                                          available_devices))\n\n    def get_slice(data, i, parts):\n        shape = tf.shape(data)\n        batch_size = shape[:1]\n        input_shape = shape[1:]\n        step = batch_size // parts\n        if i == num_gpus - 1:\n            size = batch_size - step * i\n        else:\n            size = step\n        size = tf.concat([size, input_shape], axis=0)\n        stride = tf.concat([step, input_shape * 0], axis=0)\n        start = stride * i\n        return tf.slice(data, start, size)\n\n    all_outputs = []\n    for i in range(len(model.outputs)):\n        all_outputs.append([])\n\n    # Place a copy of the model on each GPU,\n    # each getting a slice of the inputs.\n    for i, gpu_id in enumerate(target_gpu_ids):\n        with tf.device('/gpu:%d' % gpu_id):\n            with tf.name_scope('replica_%d' % gpu_id):\n                inputs = []\n                # Retrieve a slice of the input.\n                for x in model.inputs:\n                    input_shape = tuple(x.get_shape().as_list())[1:]\n                    slice_i = Lambda(get_slice,\n                                     output_shape=input_shape,\n                                     arguments={'i': i,\n                                                'parts': num_gpus})(x)\n                    inputs.append(slice_i)\n\n                # Apply model on slice\n                # (creating a model replica on the target device).\n                outputs = model(inputs)\n                if not isinstance(outputs, list):\n                    outputs = [outputs]\n\n                # Save the outputs for merging back together later.\n                for o in range(len(outputs)):\n                    all_outputs[o].append(outputs[o])\n\n    # Merge outputs on CPU.\n    with tf.device('/cpu:0'):\n        merged = []\n        for name, outputs in zip(model.output_names, all_outputs):\n            merged.append(concatenate(outputs,\n                                      axis=0, name=name))\n        return Model(model.inputs, merged)",
        "begin_line": 22,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.layer_utils.count_params#12",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.count_params(weights)",
        "snippet": "def count_params(weights):\n    \"\"\"Count the total number of scalars composing the weights.\n\n    # Arguments\n        weights: An iterable containing the weights on which to compute params\n\n    # Returns\n        The total number of scalars composing the weights\n    \"\"\"\n    return int(np.sum([K.count_params(p) for p in set(weights)]))",
        "begin_line": 12,
        "end_line": 21,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0022935779816513763,
            "pseudo_dstar_susp": 0.0011574074074074073,
            "pseudo_tarantula_susp": 0.0014792899408284023,
            "pseudo_op2_susp": 0.0011574074074074073,
            "pseudo_barinel_susp": 0.0014792899408284023
        }
    },
    {
        "name": "keras.utils.layer_utils.print_summary#24",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.print_summary(model, line_length=None, positions=None, print_fn=None)",
        "snippet": "def print_summary(model, line_length=None, positions=None, print_fn=None):\n    \"\"\"Prints a summary of a model.\n\n    # Arguments\n        model: Keras model instance.\n        line_length: Total length of printed lines\n            (e.g. set this to adapt the display to different\n            terminal window sizes).\n        positions: Relative or absolute positions of log elements in each line.\n            If not provided, defaults to `[.33, .55, .67, 1.]`.\n        print_fn: Print function to use.\n            It will be called on each line of the summary.\n            You can set it to a custom function\n            in order to capture the string summary.\n            It defaults to `print` (prints to stdout).\n    \"\"\"\n    if print_fn is None:\n        print_fn = print\n\n    if model.__class__.__name__ == 'Sequential':\n        sequential_like = True\n    else:\n        sequential_like = True\n        nodes_by_depth = model._nodes_by_depth.values()\n        nodes = []\n        for v in nodes_by_depth:\n            if (len(v) > 1) or (len(v) == 1 and len(v[0].inbound_layers) > 1):\n                # if the model has multiple nodes\n                # or if the nodes have multiple inbound_layers\n                # the model is no longer sequential\n                sequential_like = False\n                break\n            nodes += v\n        if sequential_like:\n            # search for shared layers\n            for layer in model.layers:\n                flag = False\n                for node in layer._inbound_nodes:\n                    if node in nodes:\n                        if flag:\n                            sequential_like = False\n                            break\n                        else:\n                            flag = True\n                if not sequential_like:\n                    break\n\n    if sequential_like:\n        line_length = line_length or 65\n        positions = positions or [.45, .85, 1.]\n        if positions[-1] <= 1:\n            positions = [int(line_length * p) for p in positions]\n        # header names for the different log elements\n        to_display = ['Layer (type)', 'Output Shape', 'Param #']\n    else:\n        line_length = line_length or 98\n        positions = positions or [.33, .55, .67, 1.]\n        if positions[-1] <= 1:\n            positions = [int(line_length * p) for p in positions]\n        # header names for the different log elements\n        to_display = ['Layer (type)', 'Output Shape', 'Param #', 'Connected to']\n        relevant_nodes = []\n        for v in model._nodes_by_depth.values():\n            relevant_nodes += v\n\n    def print_row(fields, positions):\n        line = ''\n        for i in range(len(fields)):\n            if i > 0:\n                line = line[:-1] + ' '\n            line += str(fields[i])\n            line = line[:positions[i]]\n            line += ' ' * (positions[i] - len(line))\n        print_fn(line)\n\n    print_fn('_' * line_length)\n    print_row(to_display, positions)\n    print_fn('=' * line_length)\n\n    def print_layer_summary(layer):\n        try:\n            output_shape = layer.output_shape\n        except AttributeError:\n            output_shape = 'multiple'\n        name = layer.name\n        cls_name = layer.__class__.__name__\n        fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]\n        print_row(fields, positions)\n\n    def print_layer_summary_with_connections(layer):\n        \"\"\"Prints a summary for a single layer.\n\n        # Arguments\n            layer: target layer.\n        \"\"\"\n        try:\n            output_shape = layer.output_shape\n        except AttributeError:\n            output_shape = 'multiple'\n        connections = []\n        for node in layer._inbound_nodes:\n            if relevant_nodes and node not in relevant_nodes:\n                # node is not part of the current network\n                continue\n            for i in range(len(node.inbound_layers)):\n                inbound_layer = node.inbound_layers[i].name\n                inbound_node_index = node.node_indices[i]\n                inbound_tensor_index = node.tensor_indices[i]\n                connections.append(inbound_layer + '[' + str(inbound_node_index) + '][' + str(inbound_tensor_index) + ']')\n\n        name = layer.name\n        cls_name = layer.__class__.__name__\n        if not connections:\n            first_connection = ''\n        else:\n            first_connection = connections[0]\n        fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params(), first_connection]\n        print_row(fields, positions)\n        if len(connections) > 1:\n            for i in range(1, len(connections)):\n                fields = ['', '', '', connections[i]]\n                print_row(fields, positions)\n\n    layers = model.layers\n    for i in range(len(layers)):\n        if sequential_like:\n            print_layer_summary(layers[i])\n        else:\n            print_layer_summary_with_connections(layers[i])\n        if i == len(layers) - 1:\n            print_fn('=' * line_length)\n        else:\n            print_fn('_' * line_length)\n\n    model._check_trainable_weights_consistency()\n    if hasattr(model, '_collected_trainable_weights'):\n        trainable_count = count_params(model._collected_trainable_weights)\n    else:\n        trainable_count = count_params(model.trainable_weights)\n\n    non_trainable_count = int(\n        np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n\n    print_fn('Total params: {:,}'.format(trainable_count + non_trainable_count))\n    print_fn('Trainable params: {:,}'.format(trainable_count))\n    print_fn('Non-trainable params: {:,}'.format(non_trainable_count))\n    print_fn('_' * line_length)",
        "begin_line": 24,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.001184834123222749,
            "pseudo_tarantula_susp": 0.009259259259259259,
            "pseudo_op2_susp": 0.001184834123222749,
            "pseudo_barinel_susp": 0.009259259259259259
        }
    },
    {
        "name": "keras.utils.layer_utils.print_row#89",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.print_row(fields, positions)",
        "snippet": "    def print_row(fields, positions):\n        line = ''\n        for i in range(len(fields)):\n            if i > 0:\n                line = line[:-1] + ' '\n            line += str(fields[i])\n            line = line[:positions[i]]\n            line += ' ' * (positions[i] - len(line))\n        print_fn(line)",
        "begin_line": 89,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002386634844868735,
            "pseudo_dstar_susp": 0.0011655011655011655,
            "pseudo_tarantula_susp": 0.001658374792703151,
            "pseudo_op2_susp": 0.0011655011655011655,
            "pseudo_barinel_susp": 0.001658374792703151
        }
    },
    {
        "name": "keras.utils.layer_utils.print_layer_summary#103",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.print_layer_summary(layer)",
        "snippet": "    def print_layer_summary(layer):\n        try:\n            output_shape = layer.output_shape\n        except AttributeError:\n            output_shape = 'multiple'\n        name = layer.name\n        cls_name = layer.__class__.__name__\n        fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]\n        print_row(fields, positions)",
        "begin_line": 103,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006333122229259025,
            "pseudo_dstar_susp": 0.00048590864917395527,
            "pseudo_tarantula_susp": 0.0010905125408942203,
            "pseudo_op2_susp": 0.00048590864917395527,
            "pseudo_barinel_susp": 0.0010905125408942203
        }
    },
    {
        "name": "keras.utils.layer_utils.print_layer_summary_with_connections#113",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.print_layer_summary_with_connections(layer)",
        "snippet": "    def print_layer_summary_with_connections(layer):\n        \"\"\"Prints a summary for a single layer.\n\n        # Arguments\n            layer: target layer.\n        \"\"\"\n        try:\n            output_shape = layer.output_shape\n        except AttributeError:\n            output_shape = 'multiple'\n        connections = []\n        for node in layer._inbound_nodes:\n            if relevant_nodes and node not in relevant_nodes:\n                # node is not part of the current network\n                continue\n            for i in range(len(node.inbound_layers)):\n                inbound_layer = node.inbound_layers[i].name\n                inbound_node_index = node.node_indices[i]\n                inbound_tensor_index = node.tensor_indices[i]\n                connections.append(inbound_layer + '[' + str(inbound_node_index) + '][' + str(inbound_tensor_index) + ']')\n\n        name = layer.name\n        cls_name = layer.__class__.__name__\n        if not connections:\n            first_connection = ''\n        else:\n            first_connection = connections[0]\n        fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params(), first_connection]\n        print_row(fields, positions)\n        if len(connections) > 1:\n            for i in range(1, len(connections)):\n                fields = ['', '', '', connections[i]]\n                print_row(fields, positions)",
        "begin_line": 113,
        "end_line": 145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0011750881316098707,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0011750881316098707,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.utils.layer_utils.convert_all_kernels_in_model#173",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.convert_all_kernels_in_model(model)",
        "snippet": "def convert_all_kernels_in_model(model):\n    \"\"\"Converts all convolution kernels in a model from Theano to TensorFlow.\n\n    Also works from TensorFlow to Theano.\n\n    # Arguments\n        model: target model for the conversion.\n    \"\"\"\n    # Note: SeparableConvolution not included\n    # since only supported by TF.\n    conv_classes = {\n        'Conv1D',\n        'Conv2D',\n        'Conv3D',\n        'Conv2DTranspose',\n    }\n    to_assign = []\n    for layer in model.layers:\n        if layer.__class__.__name__ in conv_classes:\n            original_kernel = K.get_value(layer.kernel)\n            converted_kernel = convert_kernel(original_kernel)\n            to_assign.append((layer.kernel, converted_kernel))\n    K.batch_set_value(to_assign)",
        "begin_line": 173,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.layer_utils.convert_dense_weights_data_format#198",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.convert_dense_weights_data_format(dense, previous_feature_map_shape, target_data_format='channels_first')",
        "snippet": "def convert_dense_weights_data_format(dense,\n                                      previous_feature_map_shape,\n                                      target_data_format='channels_first'):\n    \"\"\"Utility useful when changing a convnet's `data_format`.\n\n    When porting the weights of a convnet from one data format to the other,\n    if the convnet includes a `Flatten` layer\n    (applied to the last convolutional feature map)\n    followed by a `Dense` layer, the weights of that `Dense` layer\n    should be updated to reflect the new dimension ordering.\n\n    # Arguments\n        dense: The target `Dense` layer.\n        previous_feature_map_shape: A shape tuple of 3 integers,\n            e.g. `(512, 7, 7)`. The shape of the convolutional\n            feature map right before the `Flatten` layer that\n            came before the target `Dense` layer.\n        target_data_format: One of \"channels_last\", \"channels_first\".\n            Set it \"channels_last\"\n            if converting a \"channels_first\" model to \"channels_last\",\n            or reciprocally.\n    \"\"\"\n    assert target_data_format in {'channels_last', 'channels_first'}\n    kernel, bias = dense.get_weights()\n    for i in range(kernel.shape[1]):\n        if target_data_format == 'channels_first':\n            c, h, w = previous_feature_map_shape\n            original_fm_shape = (h, w, c)\n            ki = kernel[:, i].reshape(original_fm_shape)\n            ki = np.transpose(ki, (2, 0, 1))  # last -> first\n        else:\n            h, w, c = previous_feature_map_shape\n            original_fm_shape = (c, h, w)\n            ki = kernel[:, i].reshape(original_fm_shape)\n            ki = np.transpose(ki, (1, 2, 0))  # first -> last\n        kernel[:, i] = np.reshape(ki, (np.prod(previous_feature_map_shape),))\n    dense.set_weights([kernel, bias])",
        "begin_line": 198,
        "end_line": 234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.__init__.backend#89",
        "src_path": "keras/backend/__init__.py",
        "class_name": "keras.backend.__init__",
        "signature": "keras.backend.__init__.backend()",
        "snippet": "def backend():\n    \"\"\"Publicly accessible method\n    for determining the current backend.\n\n    # Returns\n        String, the name of the backend Keras is currently using.\n\n    # Example\n    ```python\n        >>> keras.backend.backend()\n        'tensorflow'\n    ```\n    \"\"\"\n    return _BACKEND",
        "begin_line": 89,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002638522427440633,
            "pseudo_dstar_susp": 0.024390243902439025,
            "pseudo_tarantula_susp": 0.0008628127696289905,
            "pseudo_op2_susp": 0.024390243902439025,
            "pseudo_barinel_susp": 0.0008628127696289905
        }
    },
    {
        "name": "keras.preprocessing.text.text_to_word_sequence#24",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text",
        "signature": "keras.preprocessing.text.text_to_word_sequence(text, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')",
        "snippet": "def text_to_word_sequence(text,\n                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                          lower=True, split=\" \"):\n    \"\"\"Converts a text to a sequence of words (or tokens).\n\n    # Arguments\n        text: Input text (string).\n        filters: Sequence of characters to filter out.\n        lower: Whether to convert the input to lowercase.\n        split: Sentence split marker (string).\n\n    # Returns\n        A list of words (or tokens).\n    \"\"\"\n    if lower:\n        text = text.lower()\n\n    if sys.version_info < (3,) and isinstance(text, unicode):\n        translate_map = dict((ord(c), unicode(split)) for c in filters)\n    else:\n        translate_map = maketrans(filters, split * len(filters))\n\n    text = text.translate(translate_map)\n    seq = text.split(split)\n    return [i for i in seq if i]",
        "begin_line": 24,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.text.one_hot#51",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text",
        "signature": "keras.preprocessing.text.one_hot(text, n, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')",
        "snippet": "def one_hot(text, n,\n            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n            lower=True,\n            split=' '):\n    \"\"\"One-hot encodes a text into a list of word indexes of size n.\n\n    This is a wrapper to the `hashing_trick` function using `hash` as the\n    hashing function; unicity of word to index mapping non-guaranteed.\n\n    # Arguments\n        text: Input text (string).\n        n: Dimension of the hashing space.\n        filters: Sequence of characters to filter out.\n        lower: Whether to convert the input to lowercase.\n        split: Sentence split marker (string).\n\n    # Returns\n        A list of integer word indices (unicity non-guaranteed).\n    \"\"\"\n    return hashing_trick(text, n,\n                         hash_function=hash,\n                         filters=filters,\n                         lower=lower,\n                         split=split)",
        "begin_line": 51,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.text.hashing_trick#77",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text",
        "signature": "keras.preprocessing.text.hashing_trick(text, n, hash_function=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')",
        "snippet": "def hashing_trick(text, n,\n                  hash_function=None,\n                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                  lower=True,\n                  split=' '):\n    \"\"\"Converts a text to a sequence of indexes in a fixed-size hashing space.\n\n    # Arguments\n        text: Input text (string).\n        n: Dimension of the hashing space.\n        hash_function: if `None` uses python `hash` function, can be 'md5' or\n            any function that takes in input a string and returns a int.\n            Note that `hash` is not a stable hashing function, so\n            it is not consistent across different runs, while 'md5'\n            is a stable hashing function.\n        filters: Sequence of characters to filter out.\n        lower: Whether to convert the input to lowercase.\n        split: Sentence split marker (string).\n\n    # Returns\n        A list of integer word indices (unicity non-guaranteed).\n\n    `0` is a reserved index that won't be assigned to any word.\n\n    Two or more words may be assigned to the same index, due to possible\n    collisions by the hashing function.\n    The [probability](https://en.wikipedia.org/wiki/Birthday_problem#Probability_table)\n    of a collision is in relation to the dimension of the hashing space and\n    the number of distinct objects.\n    \"\"\"\n    if hash_function is None:\n        hash_function = hash\n    elif hash_function == 'md5':\n        hash_function = lambda w: int(md5(w.encode()).hexdigest(), 16)\n\n    seq = text_to_word_sequence(text,\n                                filters=filters,\n                                lower=lower,\n                                split=split)\n    return [(hash_function(w) % (n - 1) + 1) for w in seq]",
        "begin_line": 77,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.__init__#148",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.__init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, **kwargs)",
        "snippet": "    def __init__(self, num_words=None,\n                 filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                 lower=True,\n                 split=' ',\n                 char_level=False,\n                 oov_token=None,\n                 **kwargs):\n        # Legacy support\n        if 'nb_words' in kwargs:\n            warnings.warn('The `nb_words` argument in `Tokenizer` '\n                          'has been renamed `num_words`.')\n            num_words = kwargs.pop('nb_words')\n        if kwargs:\n            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n\n        self.word_counts = OrderedDict()\n        self.word_docs = {}\n        self.filters = filters\n        self.split = split\n        self.lower = lower\n        self.num_words = num_words\n        self.document_count = 0\n        self.char_level = char_level\n        self.oov_token = oov_token\n        self.index_docs = {}",
        "begin_line": 148,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.fit_on_texts#174",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.fit_on_texts(self, texts)",
        "snippet": "    def fit_on_texts(self, texts):\n        \"\"\"Updates internal vocabulary based on a list of texts.\n        In the case where texts contains lists, we assume each entry of the lists\n        to be a token.\n\n        Required before using `texts_to_sequences` or `texts_to_matrix`.\n\n        # Arguments\n            texts: can be a list of strings,\n                a generator of strings (for memory-efficiency),\n                or a list of list of strings.\n        \"\"\"\n        for text in texts:\n            self.document_count += 1\n            if self.char_level or isinstance(text, list):\n                seq = text\n            else:\n                seq = text_to_word_sequence(text,\n                                            self.filters,\n                                            self.lower,\n                                            self.split)\n            for w in seq:\n                if w in self.word_counts:\n                    self.word_counts[w] += 1\n                else:\n                    self.word_counts[w] = 1\n            for w in set(seq):\n                if w in self.word_docs:\n                    self.word_docs[w] += 1\n                else:\n                    self.word_docs[w] = 1\n\n        wcounts = list(self.word_counts.items())\n        wcounts.sort(key=lambda x: x[1], reverse=True)\n        sorted_voc = [wc[0] for wc in wcounts]\n        # note that index 0 is reserved, never assigned to an existing word\n        self.word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1)))))\n\n        if self.oov_token is not None:\n            i = self.word_index.get(self.oov_token)\n            if i is None:\n                self.word_index[self.oov_token] = len(self.word_index) + 1\n\n        for w, c in list(self.word_docs.items()):\n            self.index_docs[self.word_index[w]] = c",
        "begin_line": 174,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.fit_on_sequences#220",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.fit_on_sequences(self, sequences)",
        "snippet": "    def fit_on_sequences(self, sequences):\n        \"\"\"Updates internal vocabulary based on a list of sequences.\n\n        Required before using `sequences_to_matrix`\n        (if `fit_on_texts` was never called).\n\n        # Arguments\n            sequences: A list of sequence.\n                A \"sequence\" is a list of integer word indices.\n        \"\"\"\n        self.document_count += len(sequences)\n        for seq in sequences:\n            seq = set(seq)\n            for i in seq:\n                if i not in self.index_docs:\n                    self.index_docs[i] = 1\n                else:\n                    self.index_docs[i] += 1",
        "begin_line": 220,
        "end_line": 237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.texts_to_sequences#239",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.texts_to_sequences(self, texts)",
        "snippet": "    def texts_to_sequences(self, texts):\n        \"\"\"Transforms each text in texts in a sequence of integers.\n\n        Only top \"num_words\" most frequent words will be taken into account.\n        Only words known by the tokenizer will be taken into account.\n\n        # Arguments\n            texts: A list of texts (strings).\n\n        # Returns\n            A list of sequences.\n        \"\"\"\n        res = []\n        for vect in self.texts_to_sequences_generator(texts):\n            res.append(vect)\n        return res",
        "begin_line": 239,
        "end_line": 254,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.texts_to_sequences_generator#256",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.texts_to_sequences_generator(self, texts)",
        "snippet": "    def texts_to_sequences_generator(self, texts):\n        \"\"\"Transforms each text in `texts` in a sequence of integers.\n        Each item in texts can also be a list, in which case we assume each item of that list\n        to be a token.\n\n        Only top \"num_words\" most frequent words will be taken into account.\n        Only words known by the tokenizer will be taken into account.\n\n        # Arguments\n            texts: A list of texts (strings).\n\n        # Yields\n            Yields individual sequences.\n        \"\"\"\n        num_words = self.num_words\n        for text in texts:\n            if self.char_level or isinstance(text, list):\n                seq = text\n            else:\n                seq = text_to_word_sequence(text,\n                                            self.filters,\n                                            self.lower,\n                                            self.split)\n            vect = []\n            for w in seq:\n                i = self.word_index.get(w)\n                if i is not None:\n                    if num_words and i >= num_words:\n                        continue\n                    else:\n                        vect.append(i)\n                elif self.oov_token is not None:\n                    i = self.word_index.get(self.oov_token)\n                    if i is not None:\n                        vect.append(i)\n            yield vect",
        "begin_line": 256,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.texts_to_matrix#293",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.texts_to_matrix(self, texts, mode='binary')",
        "snippet": "    def texts_to_matrix(self, texts, mode='binary'):\n        \"\"\"Convert a list of texts to a Numpy matrix.\n\n        # Arguments\n            texts: list of strings.\n            mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n\n        # Returns\n            A Numpy matrix.\n        \"\"\"\n        sequences = self.texts_to_sequences(texts)\n        return self.sequences_to_matrix(sequences, mode=mode)",
        "begin_line": 293,
        "end_line": 304,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.sequences_to_matrix#306",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.sequences_to_matrix(self, sequences, mode='binary')",
        "snippet": "    def sequences_to_matrix(self, sequences, mode='binary'):\n        \"\"\"Converts a list of sequences into a Numpy matrix.\n\n        # Arguments\n            sequences: list of sequences\n                (a sequence is a list of integer word indices).\n            mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n\n        # Returns\n            A Numpy matrix.\n\n        # Raises\n            ValueError: In case of invalid `mode` argument,\n                or if the Tokenizer requires to be fit to sample data.\n        \"\"\"\n        if not self.num_words:\n            if self.word_index:\n                num_words = len(self.word_index) + 1\n            else:\n                raise ValueError('Specify a dimension (num_words argument), '\n                                 'or fit on some text data first.')\n        else:\n            num_words = self.num_words\n\n        if mode == 'tfidf' and not self.document_count:\n            raise ValueError('Fit the Tokenizer on some data '\n                             'before using tfidf mode.')\n\n        x = np.zeros((len(sequences), num_words))\n        for i, seq in enumerate(sequences):\n            if not seq:\n                continue\n            counts = {}\n            for j in seq:\n                if j >= num_words:\n                    continue\n                if j not in counts:\n                    counts[j] = 1.\n                else:\n                    counts[j] += 1\n            for j, c in list(counts.items()):\n                if mode == 'count':\n                    x[i][j] = c\n                elif mode == 'freq':\n                    x[i][j] = c / len(seq)\n                elif mode == 'binary':\n                    x[i][j] = 1\n                elif mode == 'tfidf':\n                    # Use weighting scheme 2 in\n                    # https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n                    tf = 1 + np.log(c)\n                    idf = np.log(1 + self.document_count /\n                                 (1 + self.index_docs.get(j, 0)))\n                    x[i][j] = tf * idf\n                else:\n                    raise ValueError('Unknown vectorization mode:', mode)\n        return x",
        "begin_line": 306,
        "end_line": 362,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.LeakyReLU.__init__#40",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.LeakyReLU",
        "signature": "keras.layers.advanced_activations.LeakyReLU.__init__(self, alpha=0.3, **kwargs)",
        "snippet": "    def __init__(self, alpha=0.3, **kwargs):\n        super(LeakyReLU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha = K.cast_to_floatx(alpha)",
        "begin_line": 40,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.LeakyReLU.call#45",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.LeakyReLU",
        "signature": "keras.layers.advanced_activations.LeakyReLU.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.relu(inputs, alpha=self.alpha)",
        "begin_line": 45,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.LeakyReLU.get_config#48",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.LeakyReLU",
        "signature": "keras.layers.advanced_activations.LeakyReLU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'alpha': float(self.alpha)}\n        base_config = super(LeakyReLU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 48,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.LeakyReLU.compute_output_shape#53",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.LeakyReLU",
        "signature": "keras.layers.advanced_activations.LeakyReLU.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.PReLU.__init__#91",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.PReLU",
        "signature": "keras.layers.advanced_activations.PReLU.__init__(self, alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None, **kwargs)",
        "snippet": "    def __init__(self, alpha_initializer='zeros',\n                 alpha_regularizer=None,\n                 alpha_constraint=None,\n                 shared_axes=None,\n                 **kwargs):\n        super(PReLU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha_initializer = initializers.get(alpha_initializer)\n        self.alpha_regularizer = regularizers.get(alpha_regularizer)\n        self.alpha_constraint = constraints.get(alpha_constraint)\n        if shared_axes is None:\n            self.shared_axes = None\n        elif not isinstance(shared_axes, (list, tuple)):\n            self.shared_axes = [shared_axes]\n        else:\n            self.shared_axes = list(shared_axes)",
        "begin_line": 91,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.PReLU.build#108",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.PReLU",
        "signature": "keras.layers.advanced_activations.PReLU.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        param_shape = list(input_shape[1:])\n        self.param_broadcast = [False] * len(param_shape)\n        if self.shared_axes is not None:\n            for i in self.shared_axes:\n                param_shape[i - 1] = 1\n                self.param_broadcast[i - 1] = True\n        self.alpha = self.add_weight(shape=param_shape,\n                                     name='alpha',\n                                     initializer=self.alpha_initializer,\n                                     regularizer=self.alpha_regularizer,\n                                     constraint=self.alpha_constraint)\n        # Set input spec\n        axes = {}\n        if self.shared_axes:\n            for i in range(1, len(input_shape)):\n                if i not in self.shared_axes:\n                    axes[i] = input_shape[i]\n        self.input_spec = InputSpec(ndim=len(input_shape), axes=axes)\n        self.built = True",
        "begin_line": 108,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.PReLU.call#129",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.PReLU",
        "signature": "keras.layers.advanced_activations.PReLU.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        pos = K.relu(inputs)\n        if K.backend() == 'theano':\n            neg = (K.pattern_broadcast(self.alpha, self.param_broadcast) *\n                   (inputs - K.abs(inputs)) * 0.5)\n        else:\n            neg = -self.alpha * K.relu(-inputs)\n        return pos + neg",
        "begin_line": 129,
        "end_line": 136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.PReLU.get_config#138",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.PReLU",
        "signature": "keras.layers.advanced_activations.PReLU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'alpha_initializer': initializers.serialize(self.alpha_initializer),\n            'alpha_regularizer': regularizers.serialize(self.alpha_regularizer),\n            'alpha_constraint': constraints.serialize(self.alpha_constraint),\n            'shared_axes': self.shared_axes\n        }\n        base_config = super(PReLU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 138,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.PReLU.compute_output_shape#148",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.PReLU",
        "signature": "keras.layers.advanced_activations.PReLU.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 148,
        "end_line": 149,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.ELU.__init__#174",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ELU",
        "signature": "keras.layers.advanced_activations.ELU.__init__(self, alpha=1.0, **kwargs)",
        "snippet": "    def __init__(self, alpha=1.0, **kwargs):\n        super(ELU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha = K.cast_to_floatx(alpha)",
        "begin_line": 174,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.ELU.call#179",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ELU",
        "signature": "keras.layers.advanced_activations.ELU.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.elu(inputs, self.alpha)",
        "begin_line": 179,
        "end_line": 180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.ELU.get_config#182",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ELU",
        "signature": "keras.layers.advanced_activations.ELU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'alpha': float(self.alpha)}\n        base_config = super(ELU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 182,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.ELU.compute_output_shape#187",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ELU",
        "signature": "keras.layers.advanced_activations.ELU.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 187,
        "end_line": 188,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.ThresholdedReLU.__init__#213",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ThresholdedReLU",
        "signature": "keras.layers.advanced_activations.ThresholdedReLU.__init__(self, theta=1.0, **kwargs)",
        "snippet": "    def __init__(self, theta=1.0, **kwargs):\n        super(ThresholdedReLU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.theta = K.cast_to_floatx(theta)",
        "begin_line": 213,
        "end_line": 216,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.ThresholdedReLU.call#218",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ThresholdedReLU",
        "signature": "keras.layers.advanced_activations.ThresholdedReLU.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        return inputs * K.cast(K.greater(inputs, self.theta), K.floatx())",
        "begin_line": 218,
        "end_line": 219,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.ThresholdedReLU.get_config#221",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ThresholdedReLU",
        "signature": "keras.layers.advanced_activations.ThresholdedReLU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'theta': float(self.theta)}\n        base_config = super(ThresholdedReLU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 221,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.ThresholdedReLU.compute_output_shape#226",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ThresholdedReLU",
        "signature": "keras.layers.advanced_activations.ThresholdedReLU.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 226,
        "end_line": 227,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.Softmax.__init__#245",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.Softmax",
        "signature": "keras.layers.advanced_activations.Softmax.__init__(self, axis=-1, **kwargs)",
        "snippet": "    def __init__(self, axis=-1, **kwargs):\n        super(Softmax, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.axis = axis",
        "begin_line": 245,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.Softmax.call#250",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.Softmax",
        "signature": "keras.layers.advanced_activations.Softmax.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return activations.softmax(inputs, axis=self.axis)",
        "begin_line": 250,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.Softmax.get_config#253",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.Softmax",
        "signature": "keras.layers.advanced_activations.Softmax.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'axis': self.axis}\n        base_config = super(Softmax, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 253,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.advanced_activations.Softmax.compute_output_shape#258",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.Softmax",
        "signature": "keras.layers.advanced_activations.Softmax.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 258,
        "end_line": 259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.sequence.pad_sequences#13",
        "src_path": "keras/preprocessing/sequence.py",
        "class_name": "keras.preprocessing.sequence",
        "signature": "keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)",
        "snippet": "def pad_sequences(sequences, maxlen=None, dtype='int32',\n                  padding='pre', truncating='pre', value=0.):\n    \"\"\"Pads each sequence to the same length (length of the longest sequence).\n\n    If maxlen is provided, any sequence longer\n    than maxlen is truncated to maxlen.\n    Truncation happens off either the beginning (default) or\n    the end of the sequence.\n\n    Supports post-padding and pre-padding (default).\n\n    # Arguments\n        sequences: list of lists where each element is a sequence\n        maxlen: int, maximum length\n        dtype: type to cast the resulting sequence.\n        padding: 'pre' or 'post', pad either before or after each sequence.\n        truncating: 'pre' or 'post', remove values from sequences larger than\n            maxlen either in the beginning or in the end of the sequence\n        value: float, value to pad the sequences to the desired value.\n\n    # Returns\n        x: numpy array with dimensions (number_of_sequences, maxlen)\n\n    # Raises\n        ValueError: in case of invalid values for `truncating` or `padding`,\n            or in case of invalid shape for a `sequences` entry.\n    \"\"\"\n    if not hasattr(sequences, '__len__'):\n        raise ValueError('`sequences` must be iterable.')\n    lengths = []\n    for x in sequences:\n        if not hasattr(x, '__len__'):\n            raise ValueError('`sequences` must be a list of iterables. '\n                             'Found non-iterable: ' + str(x))\n        lengths.append(len(x))\n\n    num_samples = len(sequences)\n    if maxlen is None:\n        maxlen = np.max(lengths)\n\n    # take the sample shape from the first non empty sequence\n    # checking for consistency in the main loop below.\n    sample_shape = tuple()\n    for s in sequences:\n        if len(s) > 0:\n            sample_shape = np.asarray(s).shape[1:]\n            break\n\n    x = (np.ones((num_samples, maxlen) + sample_shape) * value).astype(dtype)\n    for idx, s in enumerate(sequences):\n        if not len(s):\n            continue  # empty list/array was found\n        if truncating == 'pre':\n            trunc = s[-maxlen:]\n        elif truncating == 'post':\n            trunc = s[:maxlen]\n        else:\n            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n\n        # check `trunc` has expected shape\n        trunc = np.asarray(trunc, dtype=dtype)\n        if trunc.shape[1:] != sample_shape:\n            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n                             (trunc.shape[1:], idx, sample_shape))\n\n        if padding == 'post':\n            x[idx, :len(trunc)] = trunc\n        elif padding == 'pre':\n            x[idx, -len(trunc):] = trunc\n        else:\n            raise ValueError('Padding type \"%s\" not understood' % padding)\n    return x",
        "begin_line": 13,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.sequence.make_sampling_table#87",
        "src_path": "keras/preprocessing/sequence.py",
        "class_name": "keras.preprocessing.sequence",
        "signature": "keras.preprocessing.sequence.make_sampling_table(size, sampling_factor=1e-05)",
        "snippet": "def make_sampling_table(size, sampling_factor=1e-5):\n    \"\"\"Generates a word rank-based probabilistic sampling table.\n\n    This generates an array where the ith element\n    is the probability that a word of rank i would be sampled,\n    according to the sampling distribution used in word2vec.\n\n    The word2vec formula is:\n        p(word) = min(1, sqrt(word.frequency/sampling_factor) / (word.frequency/sampling_factor))\n\n    We assume that the word frequencies follow Zipf's law (s=1) to derive\n    a numerical approximation of frequency(rank):\n       frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))\n        where gamma is the Euler-Mascheroni constant.\n\n    # Arguments\n        size: int, number of possible words to sample.\n        sampling_factor: the sampling factor in the word2vec formula.\n\n    # Returns\n        A 1D Numpy array of length `size` where the ith entry\n        is the probability that a word of rank i should be sampled.\n    \"\"\"\n    gamma = 0.577\n    rank = np.arange(size)\n    rank[0] = 1\n    inv_fq = rank * (np.log(rank) + gamma) + 0.5 - 1. / (12. * rank)\n    f = sampling_factor * inv_fq\n\n    return np.minimum(1., f / np.sqrt(f))",
        "begin_line": 87,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.sequence.skipgrams#119",
        "src_path": "keras/preprocessing/sequence.py",
        "class_name": "keras.preprocessing.sequence",
        "signature": "keras.preprocessing.sequence.skipgrams(sequence, vocabulary_size, window_size=4, negative_samples=1.0, shuffle=True, categorical=False, sampling_table=None, seed=None)",
        "snippet": "def skipgrams(sequence, vocabulary_size,\n              window_size=4, negative_samples=1., shuffle=True,\n              categorical=False, sampling_table=None, seed=None):\n    \"\"\"Generates skipgram word pairs.\n\n    Takes a sequence (list of indexes of words),\n    returns couples of [word_index, other_word index] and labels (1s or 0s),\n    where label = 1 if 'other_word' belongs to the context of 'word',\n    and label=0 if 'other_word' is randomly sampled\n\n    # Arguments\n        sequence: a word sequence (sentence), encoded as a list\n            of word indices (integers). If using a `sampling_table`,\n            word indices are expected to match the rank\n            of the words in a reference dataset (e.g. 10 would encode\n            the 10-th most frequently occurring token).\n            Note that index 0 is expected to be a non-word and will be skipped.\n        vocabulary_size: int. maximum possible word index + 1\n        window_size: int. actually half-window.\n            The window of a word wi will be [i-window_size, i+window_size+1]\n        negative_samples: float >= 0. 0 for no negative (=random) samples.\n            1 for same number as positive samples. etc.\n        shuffle: whether to shuffle the word couples before returning them.\n        categorical: bool. if False, labels will be\n            integers (eg. [0, 1, 1 .. ]),\n            if True labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]\n        sampling_table: 1D array of size `vocabulary_size` where the entry i\n            encodes the probability to sample a word of rank i.\n        seed: random seed.\n\n    # Returns\n        couples, labels: where `couples` are int pairs and\n            `labels` are either 0 or 1.\n\n    # Note\n        By convention, index 0 in the vocabulary is\n        a non-word and will be skipped.\n    \"\"\"\n    couples = []\n    labels = []\n    for i, wi in enumerate(sequence):\n        if not wi:\n            continue\n        if sampling_table is not None:\n            if sampling_table[wi] < random.random():\n                continue\n\n        window_start = max(0, i - window_size)\n        window_end = min(len(sequence), i + window_size + 1)\n        for j in range(window_start, window_end):\n            if j != i:\n                wj = sequence[j]\n                if not wj:\n                    continue\n                couples.append([wi, wj])\n                if categorical:\n                    labels.append([0, 1])\n                else:\n                    labels.append(1)\n\n    if negative_samples > 0:\n        num_negative_samples = int(len(labels) * negative_samples)\n        words = [c[0] for c in couples]\n        random.shuffle(words)\n\n        couples += [[words[i % len(words)],\n                    random.randint(1, vocabulary_size - 1)] for i in range(num_negative_samples)]\n        if categorical:\n            labels += [[1, 0]] * num_negative_samples\n        else:\n            labels += [0] * num_negative_samples\n\n    if shuffle:\n        if seed is None:\n            seed = random.randint(0, 10e6)\n        random.seed(seed)\n        random.shuffle(couples)\n        random.seed(seed)\n        random.shuffle(labels)\n\n    return couples, labels",
        "begin_line": 119,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.preprocessing.sequence._remove_long_seq#202",
        "src_path": "keras/preprocessing/sequence.py",
        "class_name": "keras.preprocessing.sequence",
        "signature": "keras.preprocessing.sequence._remove_long_seq(maxlen, seq, label)",
        "snippet": "def _remove_long_seq(maxlen, seq, label):\n    \"\"\"Removes sequences that exceed the maximum length.\n\n    # Arguments\n        maxlen: int, maximum length\n        seq: list of lists where each sublist is a sequence\n        label: list where each element is an integer\n\n    # Returns\n        new_seq, new_label: shortened lists for `seq` and `label`.\n    \"\"\"\n    new_seq, new_label = [], []\n    for x, y in zip(seq, label):\n        if len(x) < maxlen:\n            new_seq.append(x)\n            new_label.append(y)\n    return new_seq, new_label",
        "begin_line": 202,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.datasets.boston_housing.load_data#11",
        "src_path": "keras/datasets/boston_housing.py",
        "class_name": "keras.datasets.boston_housing",
        "signature": "keras.datasets.boston_housing.load_data(path='boston_housing.npz', test_split=0.2, seed=113)",
        "snippet": "def load_data(path='boston_housing.npz', test_split=0.2, seed=113):\n    \"\"\"Loads the Boston Housing dataset.\n\n    # Arguments\n        path: path where to cache the dataset locally\n            (relative to ~/.keras/datasets).\n        test_split: fraction of the data to reserve as test set.\n        seed: Random seed for shuffling the data\n            before computing the test split.\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n    \"\"\"\n    assert 0 <= test_split < 1\n    path = get_file(path,\n                    origin='https://s3.amazonaws.com/keras-datasets/boston_housing.npz',\n                    file_hash='f553886a1f8d56431e820c5b82552d9d95cfcb96d1e678153f8839538947dff5')\n    f = np.load(path)\n    x = f['x']\n    y = f['y']\n    f.close()\n\n    np.random.seed(seed)\n    indices = np.arange(len(x))\n    np.random.shuffle(indices)\n    x = x[indices]\n    y = y[indices]\n\n    x_train = np.array(x[:int(len(x) * (1 - test_split))])\n    y_train = np.array(y[:int(len(x) * (1 - test_split))])\n    x_test = np.array(x[int(len(x) * (1 - test_split)):])\n    y_test = np.array(y[int(len(x) * (1 - test_split)):])\n    return (x_train, y_train), (x_test, y_test)",
        "begin_line": 11,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.vgg19.VGG19#37",
        "src_path": "keras/applications/vgg19.py",
        "class_name": "keras.applications.vgg19",
        "signature": "keras.applications.vgg19.VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def VGG19(include_top=True, weights='imagenet',\n          input_tensor=None, input_shape=None,\n          pooling=None,\n          classes=1000):\n    \"\"\"Instantiates the VGG19 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format='channels_last'` in your Keras config\n    at ~/.keras/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 224)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 48.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=48,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    # Block 1\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n    # Block 2\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n\n    # Block 4\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n\n    # Block 5\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n\n    if include_top:\n        # Classification block\n        x = Flatten(name='flatten')(x)\n        x = Dense(4096, activation='relu', name='fc1')(x)\n        x = Dense(4096, activation='relu', name='fc2')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='vgg19')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n                                    WEIGHTS_PATH,\n                                    cache_subdir='models',\n                                    file_hash='cbe5617147190e668d6c5d5026f83318')\n        else:\n            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                    WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models',\n                                    file_hash='253f8cb515780f3b799900260a226db6')\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n            if include_top:\n                maxpool = model.get_layer(name='block5_pool')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name='fc1')\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model",
        "begin_line": 37,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.vis_utils._check_pydot#23",
        "src_path": "keras/utils/vis_utils.py",
        "class_name": "keras.utils.vis_utils",
        "signature": "keras.utils.vis_utils._check_pydot()",
        "snippet": "def _check_pydot():\n    try:\n        # Attempt to create an image of a blank graph\n        # to check the pydot/graphviz installation.\n        pydot.Dot.create(pydot.Dot())\n    except Exception:\n        # pydot raises a generic Exception here,\n        # so no specific class can be caught.\n        raise ImportError('Failed to import pydot. You must install pydot'\n                          ' and graphviz for `pydotprint` to work.')",
        "begin_line": 23,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.utils.vis_utils.model_to_dot#35",
        "src_path": "keras/utils/vis_utils.py",
        "class_name": "keras.utils.vis_utils",
        "signature": "keras.utils.vis_utils.model_to_dot(model, show_shapes=False, show_layer_names=True, rankdir='TB')",
        "snippet": "def model_to_dot(model,\n                 show_shapes=False,\n                 show_layer_names=True,\n                 rankdir='TB'):\n    \"\"\"Convert a Keras model to dot format.\n\n    # Arguments\n        model: A Keras model instance.\n        show_shapes: whether to display shape information.\n        show_layer_names: whether to display layer names.\n        rankdir: `rankdir` argument passed to PyDot,\n            a string specifying the format of the plot:\n            'TB' creates a vertical plot;\n            'LR' creates a horizontal plot.\n\n    # Returns\n        A `pydot.Dot` instance representing the Keras model.\n    \"\"\"\n    from ..layers.wrappers import Wrapper\n    from ..models import Sequential\n\n    _check_pydot()\n    dot = pydot.Dot()\n    dot.set('rankdir', rankdir)\n    dot.set('concentrate', True)\n    dot.set_node_defaults(shape='record')\n\n    if isinstance(model, Sequential):\n        if not model.built:\n            model.build()\n        model = model.model\n    layers = model.layers\n\n    # Create graph nodes.\n    for layer in layers:\n        layer_id = str(id(layer))\n\n        # Append a wrapped layer's label to node's label, if it exists.\n        layer_name = layer.name\n        class_name = layer.__class__.__name__\n        if isinstance(layer, Wrapper):\n            layer_name = '{}({})'.format(layer_name, layer.layer.name)\n            child_class_name = layer.layer.__class__.__name__\n            class_name = '{}({})'.format(class_name, child_class_name)\n\n        # Create node's label.\n        if show_layer_names:\n            label = '{}: {}'.format(layer_name, class_name)\n        else:\n            label = class_name\n\n        # Rebuild the label as a table including input/output shapes.\n        if show_shapes:\n            try:\n                outputlabels = str(layer.output_shape)\n            except AttributeError:\n                outputlabels = 'multiple'\n            if hasattr(layer, 'input_shape'):\n                inputlabels = str(layer.input_shape)\n            elif hasattr(layer, 'input_shapes'):\n                inputlabels = ', '.join(\n                    [str(ishape) for ishape in layer.input_shapes])\n            else:\n                inputlabels = 'multiple'\n            label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label,\n                                                           inputlabels,\n                                                           outputlabels)\n        node = pydot.Node(layer_id, label=label)\n        dot.add_node(node)\n\n    # Connect nodes with edges.\n    for layer in layers:\n        layer_id = str(id(layer))\n        for i, node in enumerate(layer._inbound_nodes):\n            node_key = layer.name + '_ib-' + str(i)\n            if node_key in model._container_nodes:\n                for inbound_layer in node.inbound_layers:\n                    inbound_layer_id = str(id(inbound_layer))\n                    layer_id = str(id(layer))\n                    dot.add_edge(pydot.Edge(inbound_layer_id, layer_id))\n    return dot",
        "begin_line": 35,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.utils.vis_utils.plot_model#118",
        "src_path": "keras/utils/vis_utils.py",
        "class_name": "keras.utils.vis_utils",
        "signature": "keras.utils.vis_utils.plot_model(model, to_file='model.png', show_shapes=False, show_layer_names=True, rankdir='TB')",
        "snippet": "def plot_model(model,\n               to_file='model.png',\n               show_shapes=False,\n               show_layer_names=True,\n               rankdir='TB'):\n    \"\"\"Converts a Keras model to dot format and save to a file.\n\n    # Arguments\n        model: A Keras model instance\n        to_file: File name of the plot image.\n        show_shapes: whether to display shape information.\n        show_layer_names: whether to display layer names.\n        rankdir: `rankdir` argument passed to PyDot,\n            a string specifying the format of the plot:\n            'TB' creates a vertical plot;\n            'LR' creates a horizontal plot.\n    \"\"\"\n    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)\n    _, extension = os.path.splitext(to_file)\n    if not extension:\n        extension = 'png'\n    else:\n        extension = extension[1:]\n    dot.write(to_file, format=extension)",
        "begin_line": 118,
        "end_line": 141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_uid#58",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_uid(prefix='')",
        "snippet": "def get_uid(prefix=''):\n    \"\"\"Get the uid for the default graph.\n\n    # Arguments\n        prefix: An optional prefix of the graph.\n\n    # Returns\n        A unique identifier for the graph.\n    \"\"\"\n    global _GRAPH_UID_DICTS\n    graph = tf.get_default_graph()\n    if graph not in _GRAPH_UID_DICTS:\n        _GRAPH_UID_DICTS[graph] = defaultdict(int)\n    _GRAPH_UID_DICTS[graph][prefix] += 1\n    return _GRAPH_UID_DICTS[graph][prefix]",
        "begin_line": 58,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009823182711198428,
            "pseudo_dstar_susp": 0.003968253968253968,
            "pseudo_tarantula_susp": 0.0006226650062266501,
            "pseudo_op2_susp": 0.003968253968253968,
            "pseudo_barinel_susp": 0.0006226650062266501
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.reset_uids#75",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.reset_uids()",
        "snippet": "def reset_uids():\n    \"\"\"Reset graph identifiers.\"\"\"\n    global _GRAPH_UID_DICTS\n    _GRAPH_UID_DICTS = {}",
        "begin_line": 75,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000683526999316473,
            "pseudo_dstar_susp": 0.0019083969465648854,
            "pseudo_tarantula_susp": 0.00047778308647873863,
            "pseudo_op2_susp": 0.0019083969465648854,
            "pseudo_barinel_susp": 0.00047778308647873863
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.clear_session#81",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.clear_session()",
        "snippet": "def clear_session():\n    \"\"\"Destroys the current TF graph and creates a new one.\n\n    Useful to avoid clutter from old models / layers.\n    \"\"\"\n    global _SESSION\n    global _GRAPH_LEARNING_PHASES\n    tf.reset_default_graph()\n    reset_uids()\n    _SESSION = None\n    phase = tf.placeholder_with_default(False,\n                                        shape=(),\n                                        name='keras_learning_phase')\n    _GRAPH_LEARNING_PHASES = {}\n    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = phase",
        "begin_line": 81,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000683526999316473,
            "pseudo_dstar_susp": 0.0019083969465648854,
            "pseudo_tarantula_susp": 0.00047778308647873863,
            "pseudo_op2_susp": 0.0019083969465648854,
            "pseudo_barinel_susp": 0.00047778308647873863
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.manual_variable_initialization#98",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.manual_variable_initialization(value)",
        "snippet": "def manual_variable_initialization(value):\n    \"\"\"Sets the manual variable initialization flag.\n\n    This boolean flag determines whether\n    variables should be initialized\n    as they are instantiated (default), or if\n    the user should handle the initialization\n    (e.g. via `tf.initialize_all_variables()`).\n\n    # Arguments\n        value: Python boolean.\n    \"\"\"\n    global _MANUAL_VAR_INIT\n    _MANUAL_VAR_INIT = value",
        "begin_line": 98,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.learning_phase#114",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.learning_phase()",
        "snippet": "def learning_phase():\n    \"\"\"Returns the learning phase flag.\n\n    The learning phase flag is a bool tensor (0 = test, 1 = train)\n    to be passed as input to any Keras function\n    that uses a different behavior at train time and test time.\n\n    # Returns\n        Learning phase (scalar integer tensor or Python integer).\n    \"\"\"\n    graph = tf.get_default_graph()\n    if graph not in _GRAPH_LEARNING_PHASES:\n        phase = tf.placeholder_with_default(False,\n                                            shape=(),\n                                            name='keras_learning_phase')\n        _GRAPH_LEARNING_PHASES[graph] = phase\n    return _GRAPH_LEARNING_PHASES[graph]",
        "begin_line": 114,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.453786523553965e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.set_learning_phase#133",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.set_learning_phase(value)",
        "snippet": "def set_learning_phase(value):\n    \"\"\"Sets the learning phase to a fixed value.\n\n    # Arguments\n        value: Learning phase value, either 0 or 1 (integers).\n\n    # Raises\n        ValueError: if `value` is neither `0` nor `1`.\n    \"\"\"\n    global _GRAPH_LEARNING_PHASES\n    if value not in {0, 1}:\n        raise ValueError('Expected learning phase to be '\n                         '0 or 1.')\n    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = value",
        "begin_line": 133,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_session#149",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_session()",
        "snippet": "def get_session():\n    \"\"\"Returns the TF session to be used by the backend.\n\n    If a default TensorFlow session is available, we will return it.\n\n    Else, we will return the global Keras session.\n\n    If no global Keras session exists at this point:\n    we will create a new global session.\n\n    Note that you can manually set the global session\n    via `K.set_session(sess)`.\n\n    # Returns\n        A TensorFlow session.\n    \"\"\"\n    global _SESSION\n\n    default_session = tf.get_default_session()\n\n    if default_session is not None:\n        session = default_session\n    else:\n        if _SESSION is None:\n            if not os.environ.get('OMP_NUM_THREADS'):\n                config = tf.ConfigProto(allow_soft_placement=True)\n            else:\n                num_thread = int(os.environ.get('OMP_NUM_THREADS'))\n                config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n                                        allow_soft_placement=True)\n            _SESSION = tf.Session(config=config)\n        session = _SESSION\n    if not _MANUAL_VAR_INIT:\n        with session.graph.as_default():\n            variables = tf.global_variables()\n            candidate_vars = []\n            for v in variables:\n                if not getattr(v, '_keras_initialized', False):\n                    candidate_vars.append(v)\n            if candidate_vars:\n                # This step is expensive, so we only run it on variables\n                # not already marked as initialized.\n                is_initialized = session.run(\n                    [tf.is_variable_initialized(v) for v in candidate_vars])\n                uninitialized_vars = []\n                for flag, v in zip(is_initialized, candidate_vars):\n                    if not flag:\n                        uninitialized_vars.append(v)\n                    v._keras_initialized = True\n                if uninitialized_vars:\n                    session.run(tf.variables_initializer(uninitialized_vars))\n    # hack for list_devices() function.\n    # list_devices() function is not available under tensorflow r1.3.\n    if not hasattr(session, 'list_devices'):\n        session.list_devices = lambda: device_lib.list_local_devices()\n    return session",
        "begin_line": 149,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006896551724137931,
            "pseudo_dstar_susp": 1.0,
            "pseudo_tarantula_susp": 0.0009107468123861566,
            "pseudo_op2_susp": 1.0,
            "pseudo_barinel_susp": 0.0009107468123861566
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.set_session#207",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.set_session(session)",
        "snippet": "def set_session(session):\n    \"\"\"Sets the global TensorFlow session.\n\n    # Arguments\n        session: A TF Session.\n    \"\"\"\n    global _SESSION\n    _SESSION = session",
        "begin_line": 207,
        "end_line": 214,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._TfDeviceCaptureOp.__init__#222",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend._TfDeviceCaptureOp",
        "signature": "keras.backend.tensorflow_backend._TfDeviceCaptureOp.__init__(self)",
        "snippet": "    def __init__(self):\n        self.device = None",
        "begin_line": 222,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006293266205160479,
            "pseudo_dstar_susp": 0.000484027105517909,
            "pseudo_tarantula_susp": 0.0010799136069114472,
            "pseudo_op2_susp": 0.000484027105517909,
            "pseudo_barinel_susp": 0.0010799136069114472
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._TfDeviceCaptureOp._set_device#225",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend._TfDeviceCaptureOp",
        "signature": "keras.backend.tensorflow_backend._TfDeviceCaptureOp._set_device(self, device)",
        "snippet": "    def _set_device(self, device):\n        \"\"\"This method captures TF's explicit device scope setting.\"\"\"\n        self.device = device",
        "begin_line": 225,
        "end_line": 227,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._get_current_tf_device#230",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._get_current_tf_device()",
        "snippet": "def _get_current_tf_device():\n    \"\"\"Return explicit device of current context, otherwise returns `None`.\n\n    # Returns\n        If the current device scope is explicitly set, it returns a string with\n        the device (`CPU` or `GPU`). If the scope is not explicitly set, it will\n        return `None`.\n    \"\"\"\n    g = tf.get_default_graph()\n    op = _TfDeviceCaptureOp()\n    g._apply_device_functions(op)\n    return op.device",
        "begin_line": 230,
        "end_line": 241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006293266205160479,
            "pseudo_dstar_susp": 0.000484027105517909,
            "pseudo_tarantula_susp": 0.0010799136069114472,
            "pseudo_op2_susp": 0.000484027105517909,
            "pseudo_barinel_susp": 0.0010799136069114472
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._is_current_explicit_device#244",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._is_current_explicit_device(device_type)",
        "snippet": "def _is_current_explicit_device(device_type):\n    \"\"\"Check if the current device is explicitly set on the device type specified.\n\n    # Arguments\n        device_type: A string containing `GPU` or `CPU` (case-insensitive).\n\n    # Returns\n        A boolean indicating if the current device scope is explicitly set on the device type.\n\n    # Raises\n        ValueError: If the `device_type` string indicates an unsupported device.\n    \"\"\"\n    device_type = device_type.upper()\n    if device_type not in ['CPU', 'GPU']:\n        raise ValueError('`device_type` should be either \"CPU\" or \"GPU\".')\n    device = _get_current_tf_device()\n    return (device is not None and device.device_type == device_type.upper())",
        "begin_line": 244,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006293266205160479,
            "pseudo_dstar_susp": 0.000484027105517909,
            "pseudo_tarantula_susp": 0.0010799136069114472,
            "pseudo_op2_susp": 0.000484027105517909,
            "pseudo_barinel_susp": 0.0010799136069114472
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._get_available_gpus#263",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._get_available_gpus()",
        "snippet": "def _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    global _LOCAL_DEVICES\n    if _LOCAL_DEVICES is None:\n        _LOCAL_DEVICES = get_session().list_devices()\n    return [x.name for x in _LOCAL_DEVICES if x.device_type == 'GPU']",
        "begin_line": 263,
        "end_line": 272,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00129366106080207,
            "pseudo_dstar_susp": 0.0011402508551881414,
            "pseudo_tarantula_susp": 0.0010799136069114472,
            "pseudo_op2_susp": 0.0011402508551881414,
            "pseudo_barinel_susp": 0.0010799136069114472
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._has_nchw_support#275",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._has_nchw_support()",
        "snippet": "def _has_nchw_support():\n    \"\"\"Check whether the current scope supports NCHW ops.\n\n    TensorFlow does not support NCHW on CPU. Therefore we check if we are not explicitly put on\n    CPU, and have GPUs available. In this case there will be soft-placing on the GPU device.\n\n    # Returns\n        bool: if the current scope device placement would support nchw\n    \"\"\"\n    explicitly_on_cpu = _is_current_explicit_device('CPU')\n    gpus_available = len(_get_available_gpus()) > 0\n    return (not explicitly_on_cpu and gpus_available)",
        "begin_line": 275,
        "end_line": 286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006293266205160479,
            "pseudo_dstar_susp": 0.000484027105517909,
            "pseudo_tarantula_susp": 0.0010799136069114472,
            "pseudo_op2_susp": 0.000484027105517909,
            "pseudo_barinel_susp": 0.0010799136069114472
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._to_tensor#291",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._to_tensor(x, dtype)",
        "snippet": "def _to_tensor(x, dtype):\n    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n\n    # Arguments\n        x: An object to be converted (numpy array, list, tensors).\n        dtype: The destination type.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.convert_to_tensor(x, dtype=dtype)",
        "begin_line": 291,
        "end_line": 301,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000724112961622013,
            "pseudo_dstar_susp": 0.0016051364365971107,
            "pseudo_tarantula_susp": 0.0006472491909385113,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.0006472491909385113
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.is_sparse#304",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.is_sparse(tensor)",
        "snippet": "def is_sparse(tensor):\n    \"\"\"Returns whether a tensor is a sparse tensor.\n\n    # Arguments\n        tensor: A tensor instance.\n\n    # Returns\n        A boolean.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> a = K.placeholder((2, 2), sparse=False)\n        >>> print(K.is_sparse(a))\n        False\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n    ```\n    \"\"\"\n    return isinstance(tensor, tf.SparseTensor)",
        "begin_line": 304,
        "end_line": 324,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0058823529411764705,
            "pseudo_dstar_susp": 0.5,
            "pseudo_tarantula_susp": 0.0009345794392523365,
            "pseudo_op2_susp": 0.5,
            "pseudo_barinel_susp": 0.0009345794392523365
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.to_dense#327",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.to_dense(tensor)",
        "snippet": "def to_dense(tensor):\n    \"\"\"Converts a sparse tensor into a dense tensor and returns it.\n\n    # Arguments\n        tensor: A tensor instance (potentially sparse).\n\n    # Returns\n        A dense tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n        >>> c = K.to_dense(b)\n        >>> print(K.is_sparse(c))\n        False\n    ```\n    \"\"\"\n    if is_sparse(tensor):\n        return tf.sparse_tensor_to_dense(tensor)\n    else:\n        return tensor",
        "begin_line": 327,
        "end_line": 350,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00684931506849315,
            "pseudo_dstar_susp": 0.022222222222222223,
            "pseudo_tarantula_susp": 0.0012853470437017994,
            "pseudo_op2_susp": 0.022222222222222223,
            "pseudo_barinel_susp": 0.0012853470437017994
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.variable#356",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.variable(value, dtype=None, name=None, constraint=None)",
        "snippet": "def variable(value, dtype=None, name=None, constraint=None):\n    \"\"\"Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val, dtype='float64', name='example_var')\n        >>> K.dtype(kvar)\n        'float64'\n        >>> print(kvar)\n        example_var\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]])\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if hasattr(value, 'tocoo'):\n        sparse_coo = value.tocoo()\n        indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                  np.expand_dims(sparse_coo.col, 1)), 1)\n        v = tf.SparseTensor(indices=indices,\n                            values=sparse_coo.data,\n                            dense_shape=sparse_coo.shape)\n        v._keras_shape = sparse_coo.shape\n        v._uses_learning_phase = False\n        return v\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n    if isinstance(value, np.ndarray):\n        v._keras_shape = value.shape\n    elif hasattr(value, 'get_shape'):\n        v._keras_shape = int_shape(value)\n    v._uses_learning_phase = False\n    # TODO: move to Variable constructor when supported in public release.\n    try:\n        v.constraint = constraint\n    except AttributeError:\n        v._constraint = constraint\n    return v",
        "begin_line": 356,
        "end_line": 406,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005681818181818182,
            "pseudo_dstar_susp": 0.125,
            "pseudo_tarantula_susp": 0.001092896174863388,
            "pseudo_op2_susp": 0.125,
            "pseudo_barinel_susp": 0.001092896174863388
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.constant#409",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.constant(value, dtype=None, shape=None, name=None)",
        "snippet": "def constant(value, dtype=None, shape=None, name=None):\n    \"\"\"Creates a constant tensor.\n\n    # Arguments\n        value: A constant value (or list)\n        dtype: The type of the elements of the resulting tensor.\n        shape: Optional dimensions of resulting tensor.\n        name: Optional name for the tensor.\n\n    # Returns\n        A Constant Tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    return tf.constant(value, dtype=dtype, shape=shape, name=name)",
        "begin_line": 409,
        "end_line": 423,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011173184357541898,
            "pseudo_dstar_susp": 0.005,
            "pseudo_tarantula_susp": 0.0006548788474132286,
            "pseudo_op2_susp": 0.005,
            "pseudo_barinel_susp": 0.0006548788474132286
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.is_keras_tensor#426",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.is_keras_tensor(x)",
        "snippet": "def is_keras_tensor(x):\n    \"\"\"Returns whether `x` is a Keras tensor.\n\n    A \"Keras tensor\" is a tensor that was returned by a Keras layer,\n    (`Layer` class) or by `Input`.\n\n    # Arguments\n        x: A candidate tensor.\n\n    # Returns\n        A boolean: Whether the argument is a Keras tensor.\n\n    # Raises\n        ValueError: In case `x` is not a symbolic tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> from keras.layers import Input, Dense\n        >>> np_var = numpy.array([1, 2])\n        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n        ValueError\n        >>> k_var = tf.placeholder('float32', shape=(1,1))\n        >>> K.is_keras_tensor(k_var) # A variable indirectly created outside of keras is not a Keras tensor.\n        False\n        >>> keras_var = K.variable(np_var)\n        >>> K.is_keras_tensor(keras_var)  # A variable created with the keras backend is not a Keras tensor.\n        False\n        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is not a Keras tensor.\n        False\n        >>> keras_input = Input([10])\n        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n        True\n        >>> keras_layer_output = Dense(10)(keras_input)\n        >>> K.is_keras_tensor(keras_layer_output) # Any Keras layer output is a Keras tensor.\n        True\n    ```\n    \"\"\"\n    if not isinstance(x, (tf.Tensor,\n                          tf_variables.Variable,\n                          tf.SparseTensor)):\n        raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\n                         'Expected a symbolic tensor instance.')\n    return hasattr(x, '_keras_history')",
        "begin_line": 426,
        "end_line": 470,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008795074758135445,
            "pseudo_dstar_susp": 0.0026954177897574125,
            "pseudo_tarantula_susp": 0.0005790387955993051,
            "pseudo_op2_susp": 0.0026954177897574125,
            "pseudo_barinel_susp": 0.0005790387955993051
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.placeholder#473",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None)",
        "snippet": "def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n    \"\"\"Instantiates a placeholder tensor and returns it.\n\n    # Arguments\n        shape: Shape of the placeholder\n            (integer tuple, may include `None` entries).\n        ndim: Number of axes of the tensor.\n            At least one of {`shape`, `ndim`} must be specified.\n            If both are specified, `shape` is used.\n        dtype: Placeholder type.\n        sparse: Boolean, whether the placeholder should have a sparse type.\n        name: Optional name string for the placeholder.\n\n    # Returns\n        Tensor instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> input_ph = K.placeholder(shape=(2, 4, 5))\n        >>> input_ph._keras_shape\n        (2, 4, 5)\n        >>> input_ph\n        <tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if not shape:\n        if ndim:\n            shape = tuple([None for _ in range(ndim)])\n    if sparse:\n        x = tf.sparse_placeholder(dtype, shape=shape, name=name)\n    else:\n        x = tf.placeholder(dtype, shape=shape, name=name)\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    return x",
        "begin_line": 473,
        "end_line": 510,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008156606851549756,
            "pseudo_dstar_susp": 0.0022172949002217295,
            "pseudo_tarantula_susp": 0.0005470459518599562,
            "pseudo_op2_susp": 0.0022172949002217295,
            "pseudo_barinel_susp": 0.0005470459518599562
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.is_placeholder#513",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.is_placeholder(x)",
        "snippet": "def is_placeholder(x):\n    \"\"\"Returns whether `x` is a placeholder.\n\n    # Arguments\n        x: A candidate placeholder.\n\n    # Returns\n        Boolean.\n    \"\"\"\n    try:\n        return x.op.type == 'Placeholder'\n    except AttributeError:\n        return False",
        "begin_line": 513,
        "end_line": 525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.shape#528",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.shape(x)",
        "snippet": "def shape(x):\n    \"\"\"Returns the symbolic shape of a tensor or variable.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A symbolic shape (which is itself a tensor).\n\n    # Examples\n    ```python\n        # TensorFlow example\n        >>> from keras import backend as K\n        >>> tf_session = K.get_session()\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> inputs = keras.backend.placeholder(shape=(2, 4, 5))\n        >>> K.shape(kvar)\n        <tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>\n        >>> K.shape(inputs)\n        <tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>\n        # To get integer shape (Instead, you can use K.int_shape(x))\n        >>> K.shape(kvar).eval(session=tf_session)\n        array([2, 2], dtype=int32)\n        >>> K.shape(inputs).eval(session=tf_session)\n        array([2, 4, 5], dtype=int32)\n    ```\n    \"\"\"\n    return tf.shape(x)",
        "begin_line": 528,
        "end_line": 556,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005,
            "pseudo_dstar_susp": 0.00044822949350067237,
            "pseudo_tarantula_susp": 0.0008183306055646482,
            "pseudo_op2_susp": 0.00044822949350067237,
            "pseudo_barinel_susp": 0.0008183306055646482
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.int_shape#559",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.int_shape(x)",
        "snippet": "def int_shape(x):\n    \"\"\"Returns the shape of tensor or variable as a tuple of int or None entries.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tuple of integers (or None entries).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> K.int_shape(inputs)\n        (2, 4, 5)\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.int_shape(kvar)\n        (2, 2)\n    ```\n    \"\"\"\n    if hasattr(x, '_keras_shape'):\n        return x._keras_shape\n    try:\n        return tuple(x.get_shape().as_list())\n    except ValueError:\n        return None",
        "begin_line": 559,
        "end_line": 585,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.012345679012345678,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.012345679012345678,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ndim#588",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ndim(x)",
        "snippet": "def ndim(x):\n    \"\"\"Returns the number of axes in a tensor, as an integer.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        Integer (scalar), number of axes.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.ndim(inputs)\n        3\n        >>> K.ndim(kvar)\n        2\n    ```\n    \"\"\"\n    dims = x.get_shape()._dims\n    if dims is not None:\n        return len(dims)\n    return None",
        "begin_line": 588,
        "end_line": 612,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.012658227848101266,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.012658227848101266,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.dtype#615",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.dtype(x)",
        "snippet": "def dtype(x):\n    \"\"\"Returns the dtype of a Keras tensor or variable, as a string.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        String, dtype of `x`.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> K.dtype(K.placeholder(shape=(2,4,5)))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))\n        'float64'\n        # Keras variable\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]))\n        >>> K.dtype(kvar)\n        'float32_ref'\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.dtype(kvar)\n        'float32_ref'\n    ```\n    \"\"\"\n    return x.dtype.base_dtype.name",
        "begin_line": 615,
        "end_line": 642,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0016863406408094434,
            "pseudo_dstar_susp": 0.013157894736842105,
            "pseudo_tarantula_susp": 0.0008156606851549756,
            "pseudo_op2_susp": 0.013157894736842105,
            "pseudo_barinel_susp": 0.0008156606851549756
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.eval#645",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.eval(x)",
        "snippet": "def eval(x):\n    \"\"\"Evaluates the value of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A Numpy array.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]], dtype=float32)\n    ```\n    \"\"\"\n    return to_dense(x).eval(session=get_session())",
        "begin_line": 645,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.007142857142857143,
            "pseudo_dstar_susp": 0.0196078431372549,
            "pseudo_tarantula_susp": 0.0017421602787456446,
            "pseudo_op2_susp": 0.0196078431372549,
            "pseudo_barinel_susp": 0.0017421602787456446
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.zeros#666",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.zeros(shape, dtype=None, name=None)",
        "snippet": "def zeros(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable\n        dtype: String, data type of returned Keras variable\n        name: String, name of returned Keras variable\n\n    # Returns\n        A variable (including Keras metadata), filled with `0.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.zeros((3,4))\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n    if py_all(v.get_shape().as_list()):\n        return variable(v, dtype=dtype, name=name)\n    return v",
        "begin_line": 666,
        "end_line": 695,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003940110323089047,
            "pseudo_dstar_susp": 0.00039277297721916735,
            "pseudo_tarantula_susp": 0.00047961630695443646,
            "pseudo_op2_susp": 0.00039277297721916735,
            "pseudo_barinel_susp": 0.00047961630695443646
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ones#698",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ones(shape, dtype=None, name=None)",
        "snippet": "def ones(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, filled with `1.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.ones((3,4))\n        >>> K.eval(kvar)\n        array([[ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    v = tf.ones(shape=shape, dtype=tf_dtype, name=name)\n    if py_all(v.get_shape().as_list()):\n        return variable(v, dtype=dtype, name=name)\n    return v",
        "begin_line": 698,
        "end_line": 727,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.eye#730",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.eye(size, dtype=None, name=None)",
        "snippet": "def eye(size, dtype=None, name=None):\n    \"\"\"Instantiate an identity matrix and returns it.\n\n    # Arguments\n        size: Integer, number of rows/columns.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, an identity matrix.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.eye(3)\n        >>> K.eval(kvar)\n        array([[ 1.,  0.,  0.],\n               [ 0.,  1.,  0.],\n               [ 0.,  0.,  1.]], dtype=float32)\n    ```\n\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    return variable(tf.eye(size, dtype=tf_dtype), dtype, name)",
        "begin_line": 730,
        "end_line": 755,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.zeros_like#758",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.zeros_like(x, dtype=None, name=None)",
        "snippet": "def zeros_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or Keras tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with zeros.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_zeros = K.zeros_like(kvar)\n        >>> K.eval(kvar_zeros)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    return tf.zeros_like(x, dtype=dtype, name=name)",
        "begin_line": 758,
        "end_line": 780,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.415647015202076e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ones_like#783",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ones_like(x, dtype=None, name=None)",
        "snippet": "def ones_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with ones.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_ones = K.ones_like(kvar)\n        >>> K.eval(kvar_ones)\n        array([[ 1.,  1.,  1.],\n               [ 1.,  1.,  1.]], dtype=float32)\n    ```\n    \"\"\"\n    return tf.ones_like(x, dtype=dtype, name=name)",
        "begin_line": 783,
        "end_line": 805,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.identity#808",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.identity(x, name=None)",
        "snippet": "def identity(x, name=None):\n    \"\"\"Returns a tensor with the same content as the input tensor.\n\n    # Arguments\n        x: The input tensor.\n        name: String, name for the variable to create.\n\n    # Returns\n        A tensor of the same shape, type and content.\n    \"\"\"\n    return tf.identity(x, name)",
        "begin_line": 808,
        "end_line": 818,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_uniform_variable#821",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)",
        "snippet": "def random_uniform_variable(shape, low, high, dtype=None,\n                            name=None, seed=None):\n    \"\"\"Instantiates a variable with values drawn from a uniform distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        low: Float, lower boundary of the output interval.\n        high: Float, upper boundary of the output interval.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_uniform_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab40b10>\n        >>> K.eval(kvar)\n        array([[ 0.10940075,  0.10047495,  0.476143  ],\n               [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    value = tf.random_uniform_initializer(\n        low, high, dtype=tf_dtype, seed=seed)(shape)\n    return variable(value, dtype=dtype, name=name)",
        "begin_line": 821,
        "end_line": 855,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_normal_variable#858",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)",
        "snippet": "def random_normal_variable(shape, mean, scale, dtype=None,\n                           name=None, seed=None):\n    \"\"\"Instantiates a variable with values drawn from a normal distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        mean: Float, mean of the normal distribution.\n        scale: Float, standard deviation of the normal distribution.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_normal_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>\n        >>> K.eval(kvar)\n        array([[ 1.19591331,  0.68685907, -0.63814116],\n               [ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    value = tf.random_normal_initializer(\n        mean, scale, dtype=tf_dtype, seed=seed)(shape)\n    return variable(value, dtype=dtype, name=name)",
        "begin_line": 858,
        "end_line": 892,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.count_params#895",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.count_params(x)",
        "snippet": "def count_params(x):\n    \"\"\"Returns the static number of elements in a Keras variable or tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n\n    # Returns\n        Integer, the number of elements in `x`, i.e., the product of the\n        array's static dimensions.\n\n    # Example\n    ```python\n        >>> kvar = K.zeros((2,3))\n        >>> K.count_params(kvar)\n        6\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    return np.prod(int_shape(x))",
        "begin_line": 895,
        "end_line": 915,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001026694045174538,
            "pseudo_dstar_susp": 0.0005333333333333334,
            "pseudo_tarantula_susp": 0.0013774104683195593,
            "pseudo_op2_susp": 0.0005333333333333334,
            "pseudo_barinel_susp": 0.0013774104683195593
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.cast#918",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.cast(x, dtype)",
        "snippet": "def cast(x, dtype):\n    \"\"\"Casts a tensor to a different dtype and returns it.\n\n    You can cast a Keras variable but it still returns a Keras tensor.\n\n    # Arguments\n        x: Keras tensor (or variable).\n        dtype: String, either (`'float16'`, `'float32'`, or `'float64'`).\n\n    # Returns\n        Keras tensor with dtype `dtype`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> input = K.placeholder((2, 3), dtype='float32')\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # It doesn't work in-place as below.\n        >>> K.cast(input, dtype='float16')\n        <tf.Tensor 'Cast_1:0' shape=(2, 3) dtype=float16>\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # you need to assign it.\n        >>> input = K.cast(input, dtype='float16')\n        >>> input\n        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>\n    ```\n    \"\"\"\n    return tf.cast(x, dtype)",
        "begin_line": 918,
        "end_line": 947,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004361098996947231,
            "pseudo_dstar_susp": 0.0008726003490401396,
            "pseudo_tarantula_susp": 0.00038022813688212925,
            "pseudo_op2_susp": 0.0008726003490401396,
            "pseudo_barinel_susp": 0.00038022813688212925
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.update#953",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.update(x, new_x)",
        "snippet": "def update(x, new_x):\n    \"\"\"Update the value of `x` to `new_x`.\n\n    # Arguments\n        x: A `Variable`.\n        new_x: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign(x, new_x)",
        "begin_line": 953,
        "end_line": 963,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003681885125184094,
            "pseudo_dstar_susp": 0.0003681885125184094,
            "pseudo_tarantula_susp": 0.00036927621861152144,
            "pseudo_op2_susp": 0.0003681885125184094,
            "pseudo_barinel_susp": 0.00036927621861152144
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.update_add#966",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.update_add(x, increment)",
        "snippet": "def update_add(x, increment):\n    \"\"\"Update the value of `x` by adding `increment`.\n\n    # Arguments\n        x: A `Variable`.\n        increment: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign_add(x, increment)",
        "begin_line": 966,
        "end_line": 976,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003598416696653472,
            "pseudo_dstar_susp": 0.0003598416696653472,
            "pseudo_tarantula_susp": 0.00036088054853843375,
            "pseudo_op2_susp": 0.0003598416696653472,
            "pseudo_barinel_susp": 0.00036088054853843375
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.update_sub#979",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.update_sub(x, decrement)",
        "snippet": "def update_sub(x, decrement):\n    \"\"\"Update the value of `x` by subtracting `decrement`.\n\n    # Arguments\n        x: A `Variable`.\n        decrement: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign_sub(x, decrement)",
        "begin_line": 979,
        "end_line": 989,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.moving_average_update#992",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.moving_average_update(x, value, momentum)",
        "snippet": "def moving_average_update(x, value, momentum):\n    \"\"\"Compute the moving average of a variable.\n\n    # Arguments\n        x: A `Variable`.\n        value: A tensor with the same shape as `x`.\n        momentum: The moving average momentum.\n\n    # Returns\n        An operation to update the variable.\n    \"\"\"\n    return moving_averages.assign_moving_average(\n        x, value, momentum, zero_debias=True)",
        "begin_line": 992,
        "end_line": 1004,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.877737513786041e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.dot#1009",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.dot(x, y)",
        "snippet": "def dot(x, y):\n    \"\"\"Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n\n    When attempting to multiply a nD tensor\n    with a nD tensor, it reproduces the Theano behavior.\n    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor, dot product of `x` and `y`.\n\n    # Examples\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(2, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>\n    ```\n\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(32, 28, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>\n    ```\n\n    ```python\n        # Theano-like behavior example\n        >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n        >>> y = K.ones((4, 3, 5))\n        >>> xy = K.dot(x, y)\n        >>> K.int_shape(xy)\n        (2, 4, 5)\n    ```\n    \"\"\"\n    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n        x_shape = []\n        for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):\n            if i is not None:\n                x_shape.append(i)\n            else:\n                x_shape.append(s)\n        x_shape = tuple(x_shape)\n        y_shape = []\n        for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):\n            if i is not None:\n                y_shape.append(i)\n            else:\n                y_shape.append(s)\n        y_shape = tuple(y_shape)\n        y_permute_dim = list(range(ndim(y)))\n        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n        xt = tf.reshape(x, [-1, x_shape[-1]])\n        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n        return tf.reshape(tf.matmul(xt, yt),\n                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n    if is_sparse(x):\n        out = tf.sparse_tensor_dense_matmul(x, y)\n    else:\n        out = tf.matmul(x, y)\n    return out",
        "begin_line": 1009,
        "end_line": 1076,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003389830508474576,
            "pseudo_dstar_susp": 0.014492753623188406,
            "pseudo_tarantula_susp": 0.0037735849056603774,
            "pseudo_op2_susp": 0.014492753623188406,
            "pseudo_barinel_susp": 0.0037735849056603774
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_dot#1079",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_dot(x, y, axes=None)",
        "snippet": "def batch_dot(x, y, axes=None):\n    \"\"\"Batchwise dot product.\n\n    `batch_dot` is used to compute dot product of `x` and `y` when\n    `x` and `y` are data in batch, i.e. in a shape of\n    `(batch_size, :)`.\n    `batch_dot` results in a tensor or variable with less dimensions\n    than the input. If the number of dimensions is reduced to 1,\n    we use `expand_dims` to make sure that ndim is at least 2.\n\n    # Arguments\n        x: Keras tensor or variable with `ndim >= 2`.\n        y: Keras tensor or variable with `ndim >= 2`.\n        axes: list of (or single) int with target dimensions.\n            The lengths of `axes[0]` and `axes[1]` should be the same.\n\n    # Returns\n        A tensor with shape equal to the concatenation of `x`'s shape\n        (less the dimension that was summed over) and `y`'s shape\n        (less the batch dimension and the dimension that was summed over).\n        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n\n    # Examples\n        Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n        `batch_dot(x, y, axes=1) = [[17], [53]]` which is the main diagonal\n        of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n        elements.\n\n        Shape inference:\n        Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.\n        If `axes` is (1, 2), to find the output shape of resultant tensor,\n            loop through each dimension in `x`'s shape and `y`'s shape:\n\n        * `x.shape[0]` : 100 : append to output shape\n        * `x.shape[1]` : 20 : do not append to output shape,\n            dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n        * `y.shape[0]` : 100 : do not append to output shape,\n            always ignore first dimension of `y`\n        * `y.shape[1]` : 30 : append to output shape\n        * `y.shape[2]` : 20 : do not append to output shape,\n            dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n        `output_shape` = `(100, 30)`\n\n    ```python\n        >>> x_batch = K.ones(shape=(32, 20, 1))\n        >>> y_batch = K.ones(shape=(32, 30, 20))\n        >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n        >>> K.int_shape(xy_batch_dot)\n        (32, 1, 30)\n    ```\n    \"\"\"\n    if isinstance(axes, int):\n        axes = (axes, axes)\n    x_ndim = ndim(x)\n    y_ndim = ndim(y)\n    if x_ndim > y_ndim:\n        diff = x_ndim - y_ndim\n        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n    elif y_ndim > x_ndim:\n        diff = y_ndim - x_ndim\n        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n    else:\n        diff = 0\n    if ndim(x) == 2 and ndim(y) == 2:\n        if axes[0] == axes[1]:\n            out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n        else:\n            out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])\n    else:\n        if axes is not None:\n            adj_x = None if axes[0] == ndim(x) - 1 else True\n            adj_y = True if axes[1] == ndim(y) - 1 else None\n        else:\n            adj_x = None\n            adj_y = None\n        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n    if diff:\n        if x_ndim > y_ndim:\n            idx = x_ndim + y_ndim - 3\n        else:\n            idx = x_ndim - 1\n        out = tf.squeeze(out, list(range(idx, idx + diff)))\n    if ndim(out) == 1:\n        out = expand_dims(out, 1)\n    return out",
        "begin_line": 1079,
        "end_line": 1163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.transpose#1166",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.transpose(x)",
        "snippet": "def transpose(x):\n    \"\"\"Transposes a tensor and returns it.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n\n    # Examples\n    ```python\n        >>> var = K.variable([[1, 2, 3], [4, 5, 6]])\n        >>> K.eval(var)\n        array([[ 1.,  2.,  3.],\n               [ 4.,  5.,  6.]], dtype=float32)\n        >>> var_transposed = K.transpose(var)\n        >>> K.eval(var_transposed)\n        array([[ 1.,  4.],\n               [ 2.,  5.],\n               [ 3.,  6.]], dtype=float32)\n    ```\n\n    ```python\n        >>> inputs = K.placeholder((2, 3))\n        >>> inputs\n        <tf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32>\n        >>> input_transposed = K.transpose(inputs)\n        >>> input_transposed\n        <tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32>\n\n    ```\n    \"\"\"\n    return tf.transpose(x)",
        "begin_line": 1166,
        "end_line": 1198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.gather#1201",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.gather(reference, indices)",
        "snippet": "def gather(reference, indices):\n    \"\"\"Retrieves the elements of indices `indices` in the tensor `reference`.\n\n    # Arguments\n        reference: A tensor.\n        indices: An integer tensor of indices.\n\n    # Returns\n        A tensor of same type as `reference`.\n    \"\"\"\n    return tf.gather(reference, indices)",
        "begin_line": 1201,
        "end_line": 1211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.171937566396992e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.max#1217",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.max(x, axis=None, keepdims=False)",
        "snippet": "def max(x, axis=None, keepdims=False):\n    \"\"\"Maximum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to find maximum values.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with maximum values of `x`.\n    \"\"\"\n    return tf.reduce_max(x, axis, keepdims)",
        "begin_line": 1217,
        "end_line": 1231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008424599831508003,
            "pseudo_dstar_susp": 0.0005257623554153522,
            "pseudo_tarantula_susp": 0.0013227513227513227,
            "pseudo_op2_susp": 0.0005257623554153522,
            "pseudo_barinel_susp": 0.0013227513227513227
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.min#1234",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.min(x, axis=None, keepdims=False)",
        "snippet": "def min(x, axis=None, keepdims=False):\n    \"\"\"Minimum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to find minimum values.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with miminum values of `x`.\n    \"\"\"\n    return tf.reduce_min(x, axis, keepdims)",
        "begin_line": 1234,
        "end_line": 1248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sum#1251",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sum(x, axis=None, keepdims=False)",
        "snippet": "def sum(x, axis=None, keepdims=False):\n    \"\"\"Sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to sum over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with sum of `x`.\n    \"\"\"\n    return tf.reduce_sum(x, axis, keepdims)",
        "begin_line": 1251,
        "end_line": 1265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.224389539083947e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.prod#1268",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.prod(x, axis=None, keepdims=False)",
        "snippet": "def prod(x, axis=None, keepdims=False):\n    \"\"\"Multiplies the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the product of elements of `x`.\n    \"\"\"\n    return tf.reduce_prod(x, axis, keepdims)",
        "begin_line": 1268,
        "end_line": 1282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002386634844868735,
            "pseudo_dstar_susp": 0.0011655011655011655,
            "pseudo_tarantula_susp": 0.001658374792703151,
            "pseudo_op2_susp": 0.0011655011655011655,
            "pseudo_barinel_susp": 0.001658374792703151
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.cumsum#1285",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.cumsum(x, axis=0)",
        "snippet": "def cumsum(x, axis=0):\n    \"\"\"Cumulative sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the sum.\n\n    # Returns\n        A tensor of the cumulative sum of values of `x` along `axis`.\n    \"\"\"\n    return tf.cumsum(x, axis=axis)",
        "begin_line": 1285,
        "end_line": 1295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.cumprod#1298",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.cumprod(x, axis=0)",
        "snippet": "def cumprod(x, axis=0):\n    \"\"\"Cumulative product of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n\n    # Returns\n        A tensor of the cumulative product of values of `x` along `axis`.\n    \"\"\"\n    return tf.cumprod(x, axis=axis)",
        "begin_line": 1298,
        "end_line": 1308,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.var#1311",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.var(x, axis=None, keepdims=False)",
        "snippet": "def var(x, axis=None, keepdims=False):\n    \"\"\"Variance of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the variance.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the variance of elements of `x`.\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    m = tf.reduce_mean(x, axis, True)\n    devs_squared = tf.square(x - m)\n    return tf.reduce_mean(devs_squared,\n                          axis,\n                          keepdims)",
        "begin_line": 1311,
        "end_line": 1331,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.std#1334",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.std(x, axis=None, keepdims=False)",
        "snippet": "def std(x, axis=None, keepdims=False):\n    \"\"\"Standard deviation of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the standard deviation.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the standard deviation of elements of `x`.\n    \"\"\"\n    return tf.sqrt(var(x, axis=axis, keepdims=keepdims))",
        "begin_line": 1334,
        "end_line": 1348,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.mean#1351",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.mean(x, axis=None, keepdims=False)",
        "snippet": "def mean(x, axis=None, keepdims=False):\n    \"\"\"Mean of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: A list of integer. Axes to compute the mean.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1 for each entry in `axis`. If `keepdims` is `True`,\n            the reduced dimensions are retained with length 1.\n\n    # Returns\n        A tensor with the mean of elements of `x`.\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    return tf.reduce_mean(x, axis, keepdims)",
        "begin_line": 1351,
        "end_line": 1367,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006464124111182935,
            "pseudo_dstar_susp": 0.0015479876160990713,
            "pseudo_tarantula_susp": 0.0005089058524173028,
            "pseudo_op2_susp": 0.0015479876160990713,
            "pseudo_barinel_susp": 0.0005089058524173028
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.any#1370",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.any(x, axis=None, keepdims=False)",
        "snippet": "def any(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical OR).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_any(x, axis, keepdims)",
        "begin_line": 1370,
        "end_line": 1382,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.all#1385",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.all(x, axis=None, keepdims=False)",
        "snippet": "def all(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical AND).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_all(x, axis, keepdims)",
        "begin_line": 1385,
        "end_line": 1397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.argmax#1400",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.argmax(x, axis=-1)",
        "snippet": "def argmax(x, axis=-1):\n    \"\"\"Returns the index of the maximum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.argmax(x, axis)",
        "begin_line": 1400,
        "end_line": 1410,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005141388174807198,
            "pseudo_dstar_susp": 0.00045871559633027525,
            "pseudo_tarantula_susp": 0.000859106529209622,
            "pseudo_op2_susp": 0.00045871559633027525,
            "pseudo_barinel_susp": 0.000859106529209622
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.argmin#1413",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.argmin(x, axis=-1)",
        "snippet": "def argmin(x, axis=-1):\n    \"\"\"Returns the index of the minimum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.argmin(x, axis)",
        "begin_line": 1413,
        "end_line": 1423,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.square#1426",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.square(x)",
        "snippet": "def square(x):\n    \"\"\"Element-wise square.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.square(x)",
        "begin_line": 1426,
        "end_line": 1435,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00035124692658939234,
            "pseudo_dstar_susp": 0.00035124692658939234,
            "pseudo_tarantula_susp": 0.00035161744022503517,
            "pseudo_op2_susp": 0.00035124692658939234,
            "pseudo_barinel_susp": 0.00035161744022503517
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.abs#1438",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.abs(x)",
        "snippet": "def abs(x):\n    \"\"\"Element-wise absolute value.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.abs(x)",
        "begin_line": 1438,
        "end_line": 1447,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.649938800489595e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sqrt#1450",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sqrt(x)",
        "snippet": "def sqrt(x):\n    \"\"\"Element-wise square root.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    inf = _to_tensor(np.inf, x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, inf)\n    return tf.sqrt(x)",
        "begin_line": 1450,
        "end_line": 1462,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003741114852225963,
            "pseudo_dstar_susp": 0.00037397157816005983,
            "pseudo_tarantula_susp": 0.00038022813688212925,
            "pseudo_op2_susp": 0.00037397157816005983,
            "pseudo_barinel_susp": 0.00038022813688212925
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.exp#1465",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.exp(x)",
        "snippet": "def exp(x):\n    \"\"\"Element-wise exponential.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.exp(x)",
        "begin_line": 1465,
        "end_line": 1474,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.log#1477",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.log(x)",
        "snippet": "def log(x):\n    \"\"\"Element-wise log.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.log(x)",
        "begin_line": 1477,
        "end_line": 1486,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.logsumexp#1489",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.logsumexp(x, axis=None, keepdims=False)",
        "snippet": "def logsumexp(x, axis=None, keepdims=False):\n    \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n\n    This function is more numerically stable than log(sum(exp(x))).\n    It avoids overflows caused by taking the exp of large inputs and\n    underflows caused by taking the log of small inputs.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to reduce over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`, the reduced dimension is\n            retained with length 1.\n\n    # Returns\n        The reduced tensor.\n    \"\"\"\n    return tf.reduce_logsumexp(x, axis, keepdims)",
        "begin_line": 1489,
        "end_line": 1507,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.171937566396992e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.round#1510",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.round(x)",
        "snippet": "def round(x):\n    \"\"\"Element-wise rounding to the closest integer.\n\n    In case of tie, the rounding mode used is \"half to even\".\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.round(x)",
        "begin_line": 1510,
        "end_line": 1521,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sign#1524",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sign(x)",
        "snippet": "def sign(x):\n    \"\"\"Element-wise sign.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.sign(x)",
        "begin_line": 1524,
        "end_line": 1533,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.pow#1536",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.pow(x, a)",
        "snippet": "def pow(x, a):\n    \"\"\"Element-wise exponentiation.\n\n    # Arguments\n        x: Tensor or variable.\n        a: Python integer.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.pow(x, a)",
        "begin_line": 1536,
        "end_line": 1546,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.687576875768758e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.clip#1549",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.clip(x, min_value, max_value)",
        "snippet": "def clip(x, min_value, max_value):\n    \"\"\"Element-wise value clipping.\n\n    # Arguments\n        x: Tensor or variable.\n        min_value: Python float or integer.\n        max_value: Python float or integer.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if max_value is not None and max_value < min_value:\n        max_value = min_value\n    if max_value is None:\n        max_value = np.inf\n    min_value = _to_tensor(min_value, x.dtype.base_dtype)\n    max_value = _to_tensor(max_value, x.dtype.base_dtype)\n    return tf.clip_by_value(x, min_value, max_value)",
        "begin_line": 1549,
        "end_line": 1566,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.equal#1569",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.equal(x, y)",
        "snippet": "def equal(x, y):\n    \"\"\"Element-wise equality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.equal(x, y)",
        "begin_line": 1569,
        "end_line": 1579,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004887585532746823,
            "pseudo_dstar_susp": 0.0004450378282153983,
            "pseudo_tarantula_susp": 0.0008038585209003215,
            "pseudo_op2_susp": 0.0004450378282153983,
            "pseudo_barinel_susp": 0.0008038585209003215
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.not_equal#1582",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.not_equal(x, y)",
        "snippet": "def not_equal(x, y):\n    \"\"\"Element-wise inequality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.not_equal(x, y)",
        "begin_line": 1582,
        "end_line": 1592,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004784688995215311,
            "pseudo_dstar_susp": 0.000975609756097561,
            "pseudo_tarantula_susp": 0.00040048057669203043,
            "pseudo_op2_susp": 0.000975609756097561,
            "pseudo_barinel_susp": 0.00040048057669203043
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.greater#1595",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.greater(x, y)",
        "snippet": "def greater(x, y):\n    \"\"\"Element-wise truth value of (x > y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.greater(x, y)",
        "begin_line": 1595,
        "end_line": 1605,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.greater_equal#1608",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.greater_equal(x, y)",
        "snippet": "def greater_equal(x, y):\n    \"\"\"Element-wise truth value of (x >= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.greater_equal(x, y)",
        "begin_line": 1608,
        "end_line": 1618,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.less#1621",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.less(x, y)",
        "snippet": "def less(x, y):\n    \"\"\"Element-wise truth value of (x < y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.less(x, y)",
        "begin_line": 1621,
        "end_line": 1631,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.less_equal#1634",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.less_equal(x, y)",
        "snippet": "def less_equal(x, y):\n    \"\"\"Element-wise truth value of (x <= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.less_equal(x, y)",
        "begin_line": 1634,
        "end_line": 1644,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.maximum#1647",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.maximum(x, y)",
        "snippet": "def maximum(x, y):\n    \"\"\"Element-wise maximum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.maximum(x, y)",
        "begin_line": 1647,
        "end_line": 1657,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.21422704123542e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.minimum#1660",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.minimum(x, y)",
        "snippet": "def minimum(x, y):\n    \"\"\"Element-wise minimum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.minimum(x, y)",
        "begin_line": 1660,
        "end_line": 1670,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sin#1673",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sin(x)",
        "snippet": "def sin(x):\n    \"\"\"Computes sin of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.sin(x)",
        "begin_line": 1673,
        "end_line": 1682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.cos#1685",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.cos(x)",
        "snippet": "def cos(x):\n    \"\"\"Computes cos of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.cos(x)",
        "begin_line": 1685,
        "end_line": 1694,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._regular_normalize_batch_in_training#1697",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._regular_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
        "snippet": "def _regular_normalize_batch_in_training(x, gamma, beta,\n                                         reduction_axes, epsilon=1e-3):\n    \"\"\"Non-fused version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              None, None, False)\n    normed = tf.nn.batch_normalization(x, mean, var,\n                                       beta, gamma,\n                                       epsilon)\n    return normed, mean, var",
        "begin_line": 1697,
        "end_line": 1717,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._broadcast_normalize_batch_in_training#1720",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._broadcast_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
        "snippet": "def _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                           reduction_axes, epsilon=1e-3):\n    \"\"\"Non-fused, broadcast version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              None, None, False)\n    target_shape = []\n    for axis in range(ndim(x)):\n        if axis in reduction_axes:\n            target_shape.append(1)\n        else:\n            target_shape.append(tf.shape(x)[axis])\n    target_shape = tf.stack(target_shape)\n\n    broadcast_mean = tf.reshape(mean, target_shape)\n    broadcast_var = tf.reshape(var, target_shape)\n    if gamma is None:\n        broadcast_gamma = None\n    else:\n        broadcast_gamma = tf.reshape(gamma, target_shape)\n    if beta is None:\n        broadcast_beta = None\n    else:\n        broadcast_beta = tf.reshape(beta, target_shape)\n\n    normed = tf.nn.batch_normalization(\n        x,\n        broadcast_mean,\n        broadcast_var,\n        broadcast_beta,\n        broadcast_gamma,\n        epsilon)\n    return normed, mean, var",
        "begin_line": 1720,
        "end_line": 1763,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._fused_normalize_batch_in_training#1766",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._fused_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
        "snippet": "def _fused_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n                                       epsilon=1e-3):\n    \"\"\"Fused version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    if list(reduction_axes) == [0, 1, 2]:\n        normalization_axis = 3\n        tf_data_format = 'NHWC'\n    else:\n        normalization_axis = 1\n        tf_data_format = 'NCHW'\n\n    if gamma is None:\n        gamma = tf.constant(1.0,\n                            dtype=x.dtype,\n                            shape=[x.get_shape()[normalization_axis]])\n    if beta is None:\n        beta = tf.constant(0.0,\n                           dtype=x.dtype,\n                           shape=[x.get_shape()[normalization_axis]])\n\n    return tf.nn.fused_batch_norm(\n        x,\n        gamma,\n        beta,\n        epsilon=epsilon,\n        data_format=tf_data_format)",
        "begin_line": 1766,
        "end_line": 1802,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.normalize_batch_in_training#1805",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
        "snippet": "def normalize_batch_in_training(x, gamma, beta,\n                                reduction_axes, epsilon=1e-3):\n    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    if ndim(x) == 4 and list(reduction_axes) in [[0, 1, 2], [0, 2, 3]]:\n        if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                                          reduction_axes,\n                                                          epsilon=epsilon)\n        return _fused_normalize_batch_in_training(\n            x, gamma, beta, reduction_axes,\n            epsilon=epsilon)\n    else:\n        if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n            return _regular_normalize_batch_in_training(x, gamma, beta,\n                                                        reduction_axes,\n                                                        epsilon=epsilon)\n        else:\n            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                                          reduction_axes,\n                                                          epsilon=epsilon)",
        "begin_line": 1805,
        "end_line": 1836,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_normalization#1839",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_normalization(x, mean, var, beta, gamma, epsilon=0.001)",
        "snippet": "def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n    \"\"\"Applies batch normalization on x given mean, var, beta and gamma.\n\n    I.e. returns:\n    `output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta`\n\n    # Arguments\n        x: Input tensor or variable.\n        mean: Mean of batch.\n        var: Variance of batch.\n        beta: Tensor with which to center the input.\n        gamma: Tensor by which to scale the input.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.batch_normalization(x, mean, var, beta, gamma, epsilon)",
        "begin_line": 1839,
        "end_line": 1856,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.877737513786041e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.concatenate#1861",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.concatenate(tensors, axis=-1)",
        "snippet": "def concatenate(tensors, axis=-1):\n    \"\"\"Concatenates a list of tensors alongside the specified axis.\n\n    # Arguments\n        tensors: list of tensors to concatenate.\n        axis: concatenation axis.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if axis < 0:\n        rank = ndim(tensors[0])\n        if rank:\n            axis %= rank\n        else:\n            axis = 0\n\n    if py_all([is_sparse(x) for x in tensors]):\n        return tf.sparse_concat(axis, tensors)\n    else:\n        return tf.concat([to_dense(x) for x in tensors], axis)",
        "begin_line": 1861,
        "end_line": 1881,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0011148272017837235,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0011148272017837235,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.reshape#1884",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.reshape(x, shape)",
        "snippet": "def reshape(x, shape):\n    \"\"\"Reshapes a tensor to the specified shape.\n\n    # Arguments\n        x: Tensor or variable.\n        shape: Target shape tuple.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.reshape(x, shape)",
        "begin_line": 1884,
        "end_line": 1894,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.551159102922299e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.permute_dimensions#1897",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.permute_dimensions(x, pattern)",
        "snippet": "def permute_dimensions(x, pattern):\n    \"\"\"Permutes axes in a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        pattern: A tuple of\n            dimension indices, e.g. `(0, 2, 1)`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.transpose(x, perm=pattern)",
        "begin_line": 1897,
        "end_line": 1908,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.resize_images#1911",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.resize_images(x, height_factor, width_factor, data_format)",
        "snippet": "def resize_images(x, height_factor, width_factor, data_format):\n    \"\"\"Resizes the images contained in a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    if data_format == 'channels_first':\n        original_shape = int_shape(x)\n        new_shape = tf.shape(x)[2:]\n        new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n        x = permute_dimensions(x, [0, 2, 3, 1])\n        x = tf.image.resize_nearest_neighbor(x, new_shape)\n        x = permute_dimensions(x, [0, 3, 1, 2])\n        x.set_shape((None, None, original_shape[2] * height_factor if original_shape[2] is not None else None,\n                     original_shape[3] * width_factor if original_shape[3] is not None else None))\n        return x\n    elif data_format == 'channels_last':\n        original_shape = int_shape(x)\n        new_shape = tf.shape(x)[1:3]\n        new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n        x = tf.image.resize_nearest_neighbor(x, new_shape)\n        x.set_shape((None, original_shape[1] * height_factor if original_shape[1] is not None else None,\n                     original_shape[2] * width_factor if original_shape[2] is not None else None, None))\n        return x\n    else:\n        raise ValueError('Unknown data_format: ' + str(data_format))",
        "begin_line": 1911,
        "end_line": 1945,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.resize_volumes#1948",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.resize_volumes(x, depth_factor, height_factor, width_factor, data_format)",
        "snippet": "def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    \"\"\"Resizes the volume contained in a 5D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        depth_factor: Positive integer.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    if data_format == 'channels_first':\n        output = repeat_elements(x, depth_factor, axis=2)\n        output = repeat_elements(output, height_factor, axis=3)\n        output = repeat_elements(output, width_factor, axis=4)\n        return output\n    elif data_format == 'channels_last':\n        output = repeat_elements(x, depth_factor, axis=1)\n        output = repeat_elements(output, height_factor, axis=2)\n        output = repeat_elements(output, width_factor, axis=3)\n        return output\n    else:\n        raise ValueError('Unknown data_format: ' + str(data_format))",
        "begin_line": 1948,
        "end_line": 1975,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.repeat_elements#1978",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.repeat_elements(x, rep, axis)",
        "snippet": "def repeat_elements(x, rep, axis):\n    \"\"\"Repeats the elements of a tensor along an axis, like `np.repeat`.\n\n    If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output\n    will have shape `(s1, s2 * rep, s3)`.\n\n    # Arguments\n        x: Tensor or variable.\n        rep: Python integer, number of times to repeat.\n        axis: Axis along which to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x_shape = x.get_shape().as_list()\n    # For static axis\n    if x_shape[axis] is not None:\n        # slices along the repeat axis\n        splits = tf.split(value=x, num_or_size_splits=x_shape[axis], axis=axis)\n        # repeat each slice the given number of reps\n        x_rep = [s for s in splits for _ in range(rep)]\n        return concatenate(x_rep, axis)\n\n    # Here we use tf.tile to mimic behavior of np.repeat so that\n    # we can handle dynamic shapes (that include None).\n    # To do that, we need an auxiliary axis to repeat elements along\n    # it and then merge them along the desired axis.\n\n    # Repeating\n    auxiliary_axis = axis + 1\n    x_shape = tf.shape(x)\n    x_rep = tf.expand_dims(x, axis=auxiliary_axis)\n    reps = np.ones(len(x.get_shape()) + 1)\n    reps[auxiliary_axis] = rep\n    x_rep = tf.tile(x_rep, reps)\n\n    # Merging\n    reps = np.delete(reps, auxiliary_axis)\n    reps[axis] = rep\n    reps = tf.constant(reps, dtype='int32')\n    x_shape = x_shape * reps\n    x_rep = tf.reshape(x_rep, x_shape)\n\n    # Fix shape representation\n    x_shape = x.get_shape().as_list()\n    x_rep.set_shape(x_shape)\n    x_rep._keras_shape = tuple(x_shape)\n    return x_rep",
        "begin_line": 1978,
        "end_line": 2025,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.repeat#2028",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.repeat(x, n)",
        "snippet": "def repeat(x, n):\n    \"\"\"Repeats a 2D tensor.\n\n    if `x` has shape (samples, dim) and `n` is `2`,\n    the output will have shape `(samples, 2, dim)`.\n\n    # Arguments\n        x: Tensor or variable.\n        n: Python integer, number of times to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    assert ndim(x) == 2\n    x = tf.expand_dims(x, 1)\n    pattern = tf.stack([1, n, 1])\n    return tf.tile(x, pattern)",
        "begin_line": 2028,
        "end_line": 2044,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.arange#2047",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.arange(start, stop=None, step=1, dtype='int32')",
        "snippet": "def arange(start, stop=None, step=1, dtype='int32'):\n    \"\"\"Creates a 1D tensor containing a sequence of integers.\n\n    The function arguments use the same convention as\n    Theano's arange: if only one argument is provided,\n    it is in fact the \"stop\" argument and \"start\" is 0.\n\n    The default type of the returned tensor is `'int32'` to\n    match TensorFlow's default.\n\n    # Arguments\n        start: Start value.\n        stop: Stop value.\n        step: Difference between two successive values.\n        dtype: Integer dtype to use.\n\n    # Returns\n        An integer tensor.\n\n    \"\"\"\n    # Match the behavior of numpy and Theano by returning an empty sequence.\n    if stop is None:\n        try:\n            if start < 0:\n                start = 0\n        except TypeError:\n            # Handle case where start is a tensor\n            start = tf.cond(start < 0,\n                            true_fn=lambda: tf.constant(0, dtype=start.dtype),\n                            false_fn=lambda: start)\n\n    result = tf.range(start, limit=stop, delta=step, name='arange')\n    if dtype != 'int32':\n        result = cast(result, dtype)\n    return result",
        "begin_line": 2047,
        "end_line": 2081,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.tile#2084",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.tile(x, n)",
        "snippet": "def tile(x, n):\n    \"\"\"Creates a tensor by tiling `x` by `n`.\n\n    # Arguments\n        x: A tensor or variable\n        n: A list of integer. The length must be the same as the number of\n            dimensions in `x`.\n\n    # Returns\n        A tiled tensor.\n    \"\"\"\n    if isinstance(n, int):\n        n = [n]\n    return tf.tile(x, n)",
        "begin_line": 2084,
        "end_line": 2097,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.432181345224824e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.flatten#2100",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.flatten(x)",
        "snippet": "def flatten(x):\n    \"\"\"Flatten a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor, reshaped into 1-D\n    \"\"\"\n    return tf.reshape(x, [-1])",
        "begin_line": 2100,
        "end_line": 2109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_flatten#2112",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_flatten(x)",
        "snippet": "def batch_flatten(x):\n    \"\"\"Turn a nD tensor into a 2D tensor with same 0th dimension.\n\n    In other words, it flattens each data samples of a batch.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))\n    return x",
        "begin_line": 2112,
        "end_line": 2124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002506265664160401,
            "pseudo_dstar_susp": 0.0006596306068601583,
            "pseudo_tarantula_susp": 0.0029585798816568047,
            "pseudo_op2_susp": 0.0006596306068601583,
            "pseudo_barinel_susp": 0.0029585798816568047
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.expand_dims#2127",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.expand_dims(x, axis=-1)",
        "snippet": "def expand_dims(x, axis=-1):\n    \"\"\"Adds a 1-sized dimension at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Position where to add a new axis.\n\n    # Returns\n        A tensor with expanded dimensions.\n    \"\"\"\n    return tf.expand_dims(x, axis)",
        "begin_line": 2127,
        "end_line": 2137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004152823920265781,
            "pseudo_dstar_susp": 0.0004139072847682119,
            "pseudo_tarantula_susp": 0.0005790387955993051,
            "pseudo_op2_susp": 0.0004139072847682119,
            "pseudo_barinel_susp": 0.0005790387955993051
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.squeeze#2140",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.squeeze(x, axis)",
        "snippet": "def squeeze(x, axis):\n    \"\"\"Removes a 1-dimension from the tensor at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Axis to drop.\n\n    # Returns\n        A tensor with the same data as `x` but reduced dimensions.\n    \"\"\"\n    return tf.squeeze(x, [axis])",
        "begin_line": 2140,
        "end_line": 2150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.temporal_padding#2153",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.temporal_padding(x, padding=(1, 1))",
        "snippet": "def temporal_padding(x, padding=(1, 1)):\n    \"\"\"Pads the middle dimension of a 3D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 integers, how many zeros to\n            add at the start and end of dim 1.\n\n    # Returns\n        A padded 3D tensor.\n    \"\"\"\n    assert len(padding) == 2\n    pattern = [[0, 0], [padding[0], padding[1]], [0, 0]]\n    return tf.pad(x, pattern)",
        "begin_line": 2153,
        "end_line": 2166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.spatial_2d_padding#2169",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None)",
        "snippet": "def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    \"\"\"Pads the 2nd and 3rd dimensions of a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 tuples, padding pattern.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A padded 4D tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    assert len(padding) == 2\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    if data_format == 'channels_first':\n        pattern = [[0, 0],\n                   [0, 0],\n                   list(padding[0]),\n                   list(padding[1])]\n    else:\n        pattern = [[0, 0],\n                   list(padding[0]), list(padding[1]),\n                   [0, 0]]\n    return tf.pad(x, pattern)",
        "begin_line": 2169,
        "end_line": 2200,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.spatial_3d_padding#2203",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None)",
        "snippet": "def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    \"\"\"Pads 5D tensor with zeros along the depth, height, width dimensions.\n\n    Pads these dimensions with respectively\n    \"padding[0]\", \"padding[1]\" and \"padding[2]\" zeros left and right.\n\n    For 'channels_last' data_format,\n    the 2nd, 3rd and 4th dimension will be padded.\n    For 'channels_first' data_format,\n    the 3rd, 4th and 5th dimension will be padded.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 3 tuples, padding pattern.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A padded 5D tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n\n    \"\"\"\n    assert len(padding) == 3\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    assert len(padding[2]) == 2\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    if data_format == 'channels_first':\n        pattern = [\n            [0, 0],\n            [0, 0],\n            [padding[0][0], padding[0][1]],\n            [padding[1][0], padding[1][1]],\n            [padding[2][0], padding[2][1]]\n        ]\n    else:\n        pattern = [\n            [0, 0],\n            [padding[0][0], padding[0][1]],\n            [padding[1][0], padding[1][1]],\n            [padding[2][0], padding[2][1]],\n            [0, 0]\n        ]\n    return tf.pad(x, pattern)",
        "begin_line": 2203,
        "end_line": 2251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.stack#2254",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.stack(x, axis=0)",
        "snippet": "def stack(x, axis=0):\n    \"\"\"Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n\n    # Arguments\n        x: List of tensors.\n        axis: Axis along which to perform stacking.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.stack(x, axis=axis)",
        "begin_line": 2254,
        "end_line": 2264,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.one_hot#2267",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.one_hot(indices, num_classes)",
        "snippet": "def one_hot(indices, num_classes):\n    \"\"\"Computes the one-hot representation of an integer tensor.\n\n    # Arguments\n        indices: nD integer tensor of shape\n            `(batch_size, dim1, dim2, ... dim(n-1))`\n        num_classes: Integer, number of classes to consider.\n\n    # Returns\n        (n + 1)D one hot representation of the input\n        with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`\n    \"\"\"\n    return tf.one_hot(indices, depth=num_classes, axis=-1)",
        "begin_line": 2267,
        "end_line": 2279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.reverse#2282",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.reverse(x, axes)",
        "snippet": "def reverse(x, axes):\n    \"\"\"Reverse a tensor along the specified axes.\n\n    # Arguments\n        x: Tensor to reverse.\n        axes: Integer or iterable of integers.\n            Axes to reverse.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if isinstance(axes, int):\n        axes = [axes]\n    return tf.reverse(x, axes)",
        "begin_line": 2282,
        "end_line": 2295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00129366106080207,
            "pseudo_dstar_susp": 0.0005656108597285068,
            "pseudo_tarantula_susp": 0.001658374792703151,
            "pseudo_op2_susp": 0.0005656108597285068,
            "pseudo_barinel_susp": 0.001658374792703151
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_value#2301",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_value(x)",
        "snippet": "def get_value(x):\n    \"\"\"Returns the value of a variable.\n\n    # Arguments\n        x: input variable.\n\n    # Returns\n        A Numpy array.\n    \"\"\"\n    return x.eval(session=get_session())",
        "begin_line": 2301,
        "end_line": 2310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.445461990916536e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_get_value#2313",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_get_value(ops)",
        "snippet": "def batch_get_value(ops):\n    \"\"\"Returns the value of more than one tensor variable.\n\n    # Arguments\n        ops: list of ops to run.\n\n    # Returns\n        A list of Numpy arrays.\n    \"\"\"\n    if ops:\n        return get_session().run(ops)\n    else:\n        return []",
        "begin_line": 2313,
        "end_line": 2325,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.359434795407713e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.set_value#2328",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.set_value(x, value)",
        "snippet": "def set_value(x, value):\n    \"\"\"Sets the value of a variable, from a Numpy array.\n\n    # Arguments\n        x: Tensor to set to a new value.\n        value: Value to set the tensor to, as a Numpy array\n            (of the same shape).\n    \"\"\"\n    value = np.asarray(value, dtype=dtype(x))\n    tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n    if hasattr(x, '_assign_placeholder'):\n        assign_placeholder = x._assign_placeholder\n        assign_op = x._assign_op\n    else:\n        assign_placeholder = tf.placeholder(tf_dtype, shape=value.shape)\n        assign_op = x.assign(assign_placeholder)\n        x._assign_placeholder = assign_placeholder\n        x._assign_op = assign_op\n    get_session().run(assign_op, feed_dict={assign_placeholder: value})",
        "begin_line": 2328,
        "end_line": 2346,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_set_value#2349",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_set_value(tuples)",
        "snippet": "def batch_set_value(tuples):\n    \"\"\"Sets the values of many tensor variables at once.\n\n    # Arguments\n        tuples: a list of tuples `(tensor, value)`.\n            `value` should be a Numpy array.\n    \"\"\"\n    if tuples:\n        assign_ops = []\n        feed_dict = {}\n        for x, value in tuples:\n            value = np.asarray(value, dtype=dtype(x))\n            tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n            if hasattr(x, '_assign_placeholder'):\n                assign_placeholder = x._assign_placeholder\n                assign_op = x._assign_op\n            else:\n                assign_placeholder = tf.placeholder(tf_dtype,\n                                                    shape=value.shape)\n                assign_op = x.assign(assign_placeholder)\n                x._assign_placeholder = assign_placeholder\n                x._assign_op = assign_op\n            assign_ops.append(assign_op)\n            feed_dict[assign_placeholder] = value\n        get_session().run(assign_ops, feed_dict=feed_dict)",
        "begin_line": 2349,
        "end_line": 2373,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_variable_shape#2376",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_variable_shape(x)",
        "snippet": "def get_variable_shape(x):\n    \"\"\"Returns the shape of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A tuple of integers.\n    \"\"\"\n    return int_shape(x)",
        "begin_line": 2376,
        "end_line": 2385,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.print_tensor#2388",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.print_tensor(x, message='')",
        "snippet": "def print_tensor(x, message=''):\n    \"\"\"Prints `message` and the tensor value when evaluated.\n\n     Note that `print_tensor` returns a new tensor identical to `x`\n     which should be used in the following code. Otherwise the\n     print operation is not taken into account during evaluation.\n\n     # Example\n     ```python\n         >>> x = K.print_tensor(x, message=\"x is: \")\n     ```\n\n    # Arguments\n        x: Tensor to print.\n        message: Message to print jointly with the tensor.\n\n    # Returns\n        The same tensor `x`, unchanged.\n    \"\"\"\n    return tf.Print(x, [x], message)",
        "begin_line": 2388,
        "end_line": 2407,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.Function.__init__#2432",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend.Function",
        "signature": "keras.backend.tensorflow_backend.Function.__init__(self, inputs, outputs, updates=None, name=None, **session_kwargs)",
        "snippet": "    def __init__(self, inputs, outputs, updates=None, name=None, **session_kwargs):\n        updates = updates or []\n        if not isinstance(inputs, (list, tuple)):\n            raise TypeError('`inputs` to a TensorFlow backend function '\n                            'should be a list or tuple.')\n        if not isinstance(outputs, (list, tuple)):\n            raise TypeError('`outputs` of a TensorFlow backend function '\n                            'should be a list or tuple.')\n        if not isinstance(updates, (list, tuple)):\n            raise TypeError('`updates` in a TensorFlow backend function '\n                            'should be a list or tuple.')\n        self.inputs = list(inputs)\n        self.outputs = list(outputs)\n        with tf.control_dependencies(self.outputs):\n            updates_ops = []\n            for update in updates:\n                if isinstance(update, tuple):\n                    p, new_p = update\n                    updates_ops.append(tf.assign(p, new_p))\n                else:\n                    # assumed already an op\n                    updates_ops.append(update)\n            self.updates_op = tf.group(*updates_ops)\n        self.name = name\n        # additional tensor substitutions\n        self.feed_dict = session_kwargs.pop('feed_dict', {})\n        # additional operations\n        self.fetches = session_kwargs.pop('fetches', [])\n        if not isinstance(self.fetches, list):\n            self.fetches = [self.fetches]\n        self.session_kwargs = session_kwargs",
        "begin_line": 2432,
        "end_line": 2462,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004210526315789474,
            "pseudo_dstar_susp": 0.000856898029134533,
            "pseudo_tarantula_susp": 0.00037509377344336085,
            "pseudo_op2_susp": 0.000856898029134533,
            "pseudo_barinel_susp": 0.00037509377344336085
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.Function.__call__#2464",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend.Function",
        "signature": "keras.backend.tensorflow_backend.Function.__call__(self, inputs)",
        "snippet": "    def __call__(self, inputs):\n        if not isinstance(inputs, (list, tuple)):\n            raise TypeError('`inputs` should be a list or tuple.')\n        feed_dict = self.feed_dict.copy()\n        for tensor, value in zip(self.inputs, inputs):\n            if is_sparse(tensor):\n                sparse_coo = value.tocoo()\n                indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                          np.expand_dims(sparse_coo.col, 1)), 1)\n                value = (indices, sparse_coo.data, sparse_coo.shape)\n            feed_dict[tensor] = value\n        fetches = self.outputs + [self.updates_op] + self.fetches\n        session = get_session()\n        updated = session.run(fetches=fetches, feed_dict=feed_dict,\n                              **self.session_kwargs)\n        return updated[:len(self.outputs)]",
        "begin_line": 2464,
        "end_line": 2479,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00042354934349851756,
            "pseudo_dstar_susp": 0.0008673026886383347,
            "pseudo_tarantula_susp": 0.00037778617302606723,
            "pseudo_op2_susp": 0.0008673026886383347,
            "pseudo_barinel_susp": 0.00037778617302606723
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.function#2482",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.function(inputs, outputs, updates=None, **kwargs)",
        "snippet": "def function(inputs, outputs, updates=None, **kwargs):\n    \"\"\"Instantiates a Keras function.\n\n    # Arguments\n        inputs: List of placeholder tensors.\n        outputs: List of output tensors.\n        updates: List of update ops.\n        **kwargs: Passed to `tf.Session.run`.\n\n    # Returns\n        Output values as Numpy arrays.\n\n    # Raises\n        ValueError: if invalid kwargs are passed in.\n    \"\"\"\n    if kwargs:\n        for key in kwargs:\n            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):\n                msg = 'Invalid argument \"%s\" passed to K.function with TensorFlow backend' % key\n                raise ValueError(msg)\n    return Function(inputs, outputs, updates=updates, **kwargs)",
        "begin_line": 2482,
        "end_line": 2502,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004210526315789474,
            "pseudo_dstar_susp": 0.000856898029134533,
            "pseudo_tarantula_susp": 0.00037509377344336085,
            "pseudo_op2_susp": 0.000856898029134533,
            "pseudo_barinel_susp": 0.00037509377344336085
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.gradients#2505",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.gradients(loss, variables)",
        "snippet": "def gradients(loss, variables):\n    \"\"\"Returns the gradients of `variables` w.r.t. `loss`.\n\n    # Arguments\n        loss: Scalar tensor to minimize.\n        variables: List of variables.\n\n    # Returns\n        A gradients tensor.\n    \"\"\"\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)",
        "begin_line": 2505,
        "end_line": 2515,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003629764065335753,
            "pseudo_dstar_susp": 0.0003629764065335753,
            "pseudo_tarantula_susp": 0.00036403349108117945,
            "pseudo_op2_susp": 0.0003629764065335753,
            "pseudo_barinel_susp": 0.00036403349108117945
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.stop_gradient#2518",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.stop_gradient(variables)",
        "snippet": "def stop_gradient(variables):\n    \"\"\"Returns `variables` but with zero gradient w.r.t. every other variable.\n\n    # Arguments\n        variables: tensor or list of tensors to consider constant with respect\n            to any other variable.\n\n    # Returns\n        A single tensor or a list of tensors (depending on the passed argument)\n            that has constant gradient with respect to any other variable.\n    \"\"\"\n    if isinstance(variables, (list, tuple)):\n        return map(tf.stop_gradient, variables)\n    else:\n        return tf.stop_gradient(variables)",
        "begin_line": 2518,
        "end_line": 2532,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.rnn#2537",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)",
        "snippet": "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    \"\"\"Iterates over the time dimension of a tensor.\n\n    # Arguments\n        step_function: RNN step function.\n            Parameters:\n                inputs: tensor with shape `(samples, ...)` (no time dimension),\n                    representing input for the batch of samples at a certain\n                    time step.\n                states: list of tensors.\n            Returns:\n                outputs: tensor with shape `(samples, output_dim)`\n                    (no time dimension).\n                new_states: list of tensors, same length and shapes\n                    as 'states'. The first state in the list must be the\n                    output tensor at the previous timestep.\n        inputs: tensor of temporal data of shape `(samples, time, ...)`\n            (at least 3D).\n        initial_states: tensor with shape (samples, output_dim)\n            (no time dimension),\n            containing the initial values for the states used in\n            the step function.\n        go_backwards: boolean. If True, do the iteration over the time\n            dimension in reverse order and return the reversed sequence.\n        mask: binary tensor with shape `(samples, time, 1)`,\n            with a zero for every element that is masked.\n        constants: a list of constant values passed at each step.\n        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n        input_length: not relevant in the TensorFlow implementation.\n            Must be specified if using unrolling with Theano.\n\n    # Returns\n        A tuple, `(last_output, outputs, new_states)`.\n\n            last_output: the latest output of the rnn, of shape `(samples, ...)`\n            outputs: tensor with shape `(samples, time, ...)` where each\n                entry `outputs[s, t]` is the output of the step function\n                at time `t` for sample `s`.\n            new_states: list of tensors, latest states returned by\n                the step function, of shape `(samples, ...)`.\n\n    # Raises\n        ValueError: if input dimension is less than 3.\n        ValueError: if `unroll` is `True` but input timestep is not a fixed number.\n        ValueError: if `mask` is provided (not `None`) but states is not provided\n            (`len(states)` == 0).\n    \"\"\"\n    ndim = len(inputs.get_shape())\n    if ndim < 3:\n        raise ValueError('Input should be at least 3D.')\n\n    # Transpose to time-major, i.e.\n    # from (batch, time, ...) to (time, batch, ...)\n    axes = [1, 0] + list(range(2, ndim))\n    inputs = tf.transpose(inputs, (axes))\n\n    if mask is not None:\n        if mask.dtype != tf.bool:\n            mask = tf.cast(mask, tf.bool)\n        if len(mask.get_shape()) == ndim - 1:\n            mask = expand_dims(mask)\n        mask = tf.transpose(mask, axes)\n\n    if constants is None:\n        constants = []\n\n    global uses_learning_phase\n    uses_learning_phase = False\n\n    if unroll:\n        if not inputs.get_shape()[0]:\n            raise ValueError('Unrolling requires a '\n                             'fixed number of timesteps.')\n        states = initial_states\n        successive_states = []\n        successive_outputs = []\n\n        input_list = tf.unstack(inputs)\n        if go_backwards:\n            input_list.reverse()\n\n        if mask is not None:\n            mask_list = tf.unstack(mask)\n            if go_backwards:\n                mask_list.reverse()\n\n            for inp, mask_t in zip(input_list, mask_list):\n                output, new_states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n\n                # tf.where needs its condition tensor\n                # to be the same shape as its two\n                # result tensors, but in our case\n                # the condition (mask) tensor is\n                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n                # So we need to\n                # broadcast the mask to match the shape of A and B.\n                # That's what the tile call does,\n                # it just repeats the mask along its second dimension\n                # n times.\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n\n                if not successive_outputs:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = successive_outputs[-1]\n\n                output = tf.where(tiled_mask_t, output, prev_output)\n\n                return_states = []\n                for state, new_state in zip(states, new_states):\n                    # (see earlier comment for tile explanation)\n                    tiled_mask_t = tf.tile(mask_t,\n                                           tf.stack([1, tf.shape(new_state)[1]]))\n                    return_states.append(tf.where(tiled_mask_t,\n                                                  new_state,\n                                                  state))\n                states = return_states\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n        else:\n            for inp in input_list:\n                output, states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n\n    else:\n        if go_backwards:\n            inputs = reverse(inputs, 0)\n\n        states = tuple(initial_states)\n\n        time_steps = tf.shape(inputs)[0]\n        outputs, _ = step_function(inputs[0], initial_states + constants)\n        output_ta = tensor_array_ops.TensorArray(\n            dtype=outputs.dtype,\n            size=time_steps,\n            tensor_array_name='output_ta')\n        input_ta = tensor_array_ops.TensorArray(\n            dtype=inputs.dtype,\n            size=time_steps,\n            tensor_array_name='input_ta')\n        input_ta = input_ta.unstack(inputs)\n        time = tf.constant(0, dtype='int32', name='time')\n\n        if mask is not None:\n            if not states:\n                raise ValueError('No initial states provided! '\n                                 'When using masking in an RNN, you should '\n                                 'provide initial states '\n                                 '(and your step function should return '\n                                 'as its first state at time `t` '\n                                 'the output at time `t-1`).')\n            if go_backwards:\n                mask = reverse(mask, 0)\n\n            mask_ta = tensor_array_ops.TensorArray(\n                dtype=tf.bool,\n                size=time_steps,\n                tensor_array_name='mask_ta')\n            mask_ta = mask_ta.unstack(mask)\n\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                mask_t = mask_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n                output = tf.where(tiled_mask_t, output, states[0])\n                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n        else:\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n\n        final_outputs = control_flow_ops.while_loop(\n            cond=lambda time, *_: time < time_steps,\n            body=_step,\n            loop_vars=(time, output_ta) + states,\n            parallel_iterations=32,\n            swap_memory=True)\n        last_time = final_outputs[0]\n        output_ta = final_outputs[1]\n        new_states = final_outputs[2:]\n\n        outputs = output_ta.stack()\n        last_output = output_ta.read(last_time - 1)\n\n    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n    outputs = tf.transpose(outputs, axes)\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, outputs, new_states",
        "begin_line": 2537,
        "end_line": 2778,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._step#2711",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._step(time, output_ta_t, *states)",
        "snippet": "            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                mask_t = mask_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n                output = tf.where(tiled_mask_t, output, states[0])\n                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)",
        "begin_line": 2711,
        "end_line": 2737,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._step#2739",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._step(time, output_ta_t, *states)",
        "snippet": "            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)",
        "begin_line": 2739,
        "end_line": 2760,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.switch#2781",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.switch(condition, then_expression, else_expression)",
        "snippet": "def switch(condition, then_expression, else_expression):\n    \"\"\"Switches between two operations depending on a scalar value.\n\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: tensor (`int` or `bool`).\n        then_expression: either a tensor, or a callable that returns a tensor.\n        else_expression: either a tensor, or a callable that returns a tensor.\n\n    # Returns\n        The selected tensor.\n\n    # Raises\n        ValueError: If rank of `condition` is greater than rank of expressions.\n    \"\"\"\n    if condition.dtype != tf.bool:\n        condition = tf.cast(condition, 'bool')\n    cond_ndim = ndim(condition)\n    if not cond_ndim:\n        if not callable(then_expression):\n            def then_expression_fn():\n                return then_expression\n        else:\n            then_expression_fn = then_expression\n        if not callable(else_expression):\n            def else_expression_fn():\n                return else_expression\n        else:\n            else_expression_fn = else_expression\n        x = tf.cond(condition,\n                    then_expression_fn,\n                    else_expression_fn)\n    else:\n        # tf.where needs its condition tensor\n        # to be the same shape as its two\n        # result tensors\n        if callable(then_expression):\n            then_expression = then_expression()\n        if callable(else_expression):\n            else_expression = else_expression()\n        expr_ndim = ndim(then_expression)\n        if cond_ndim > expr_ndim:\n            raise ValueError('Rank of `condition` should be less than or'\n                             ' equal to rank of `then_expression` and '\n                             '`else_expression`. ndim(condition)=' +\n                             str(cond_ndim) + ', ndim(then_expression)'\n                             '=' + str(expr_ndim))\n        if cond_ndim > 1:\n            ndim_diff = expr_ndim - cond_ndim\n            cond_shape = tf.concat([tf.shape(condition), [1] * ndim_diff], axis=0)\n            condition = tf.reshape(condition, cond_shape)\n            expr_shape = tf.shape(then_expression)\n            shape_diff = expr_shape - cond_shape\n            tile_shape = tf.where(shape_diff > 0, expr_shape, tf.ones_like(expr_shape))\n            condition = tf.tile(condition, tile_shape)\n        x = tf.where(condition, then_expression, else_expression)\n    return x",
        "begin_line": 2781,
        "end_line": 2839,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.then_expression_fn#2803",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.then_expression_fn()",
        "snippet": "            def then_expression_fn():\n                return then_expression",
        "begin_line": 2803,
        "end_line": 2804,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.877737513786041e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.else_expression_fn#2808",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.else_expression_fn()",
        "snippet": "            def else_expression_fn():\n                return else_expression",
        "begin_line": 2808,
        "end_line": 2809,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.57002271006813e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.in_train_phase#2842",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.in_train_phase(x, alt, training=None)",
        "snippet": "def in_train_phase(x, alt, training=None):\n    \"\"\"Selects `x` in train phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in train phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on the `training` flag.\n        the `training` flag defaults to `K.learning_phase()`.\n    \"\"\"\n    if training is None:\n        training = learning_phase()\n        uses_learning_phase = True\n    else:\n        uses_learning_phase = False\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n\n    elif training is 0 or training is False:\n        if callable(alt):\n            return alt()\n        else:\n            return alt\n\n    # else: assume learning phase is a placeholder tensor.\n    x = switch(training, x, alt)\n    if uses_learning_phase:\n        x._uses_learning_phase = True\n    return x",
        "begin_line": 2842,
        "end_line": 2882,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.in_test_phase#2885",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.in_test_phase(x, alt, training=None)",
        "snippet": "def in_test_phase(x, alt, training=None):\n    \"\"\"Selects `x` in test phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in test phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on `K.learning_phase`.\n    \"\"\"\n    return in_train_phase(alt, x, training=training)",
        "begin_line": 2885,
        "end_line": 2902,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.relu#2907",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.relu(x, alpha=0.0, max_value=None)",
        "snippet": "def relu(x, alpha=0., max_value=None):\n    \"\"\"Rectified linear unit.\n\n    With default values, it returns element-wise `max(x, 0)`.\n\n    # Arguments\n        x: A tensor or variable.\n        alpha: A scalar, slope of negative section (default=`0.`).\n        max_value: Saturation threshold.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if alpha != 0.:\n        x = tf.nn.leaky_relu(x, alpha)\n    else:\n        x = tf.nn.relu(x)\n\n    if max_value is not None:\n        max_value = _to_tensor(max_value, x.dtype.base_dtype)\n        x = tf.minimum(x, max_value)\n    return x",
        "begin_line": 2907,
        "end_line": 2928,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.009009009009009009,
            "pseudo_dstar_susp": 0.0011363636363636363,
            "pseudo_tarantula_susp": 0.009259259259259259,
            "pseudo_op2_susp": 0.0011363636363636363,
            "pseudo_barinel_susp": 0.009259259259259259
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.elu#2931",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.elu(x, alpha=1.0)",
        "snippet": "def elu(x, alpha=1.):\n    \"\"\"Exponential linear unit.\n\n    # Arguments\n        x: A tensor or variable to compute the activation function for.\n        alpha: A scalar, slope of negative section.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    res = tf.nn.elu(x)\n    if alpha == 1:\n        return res\n    else:\n        return tf.where(x > 0, res, alpha * res)",
        "begin_line": 2931,
        "end_line": 2945,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0045662100456621,
            "pseudo_dstar_susp": 0.0007251631617113851,
            "pseudo_tarantula_susp": 0.005050505050505051,
            "pseudo_op2_susp": 0.0007251631617113851,
            "pseudo_barinel_susp": 0.005050505050505051
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.softmax#2948",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.softmax(x)",
        "snippet": "def softmax(x):\n    \"\"\"Softmax of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softmax(x)",
        "begin_line": 2948,
        "end_line": 2957,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013812154696132596,
            "pseudo_dstar_susp": 0.001141552511415525,
            "pseudo_tarantula_susp": 0.0010976948408342481,
            "pseudo_op2_susp": 0.001141552511415525,
            "pseudo_barinel_susp": 0.0010976948408342481
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.softplus#2960",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.softplus(x)",
        "snippet": "def softplus(x):\n    \"\"\"Softplus of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softplus(x)",
        "begin_line": 2960,
        "end_line": 2969,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003389830508474576,
            "pseudo_dstar_susp": 0.0006925207756232687,
            "pseudo_tarantula_susp": 0.0037735849056603774,
            "pseudo_op2_susp": 0.0006925207756232687,
            "pseudo_barinel_susp": 0.0037735849056603774
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.softsign#2972",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.softsign(x)",
        "snippet": "def softsign(x):\n    \"\"\"Softsign of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softsign(x)",
        "begin_line": 2972,
        "end_line": 2981,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.categorical_crossentropy#2984",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.categorical_crossentropy(target, output, from_logits=False)",
        "snippet": "def categorical_crossentropy(target, output, from_logits=False):\n    \"\"\"Categorical crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor of the same shape as `output`.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n\n    # Returns\n        Output tensor.\n    \"\"\"\n    # Note: tf.nn.softmax_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # scale preds so that the class probas of each sample sum to 1\n        output /= tf.reduce_sum(output,\n                                len(output.get_shape()) - 1,\n                                True)\n        # manual computation of crossentropy\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n        return - tf.reduce_sum(target * tf.log(output),\n                               len(output.get_shape()) - 1)\n    else:\n        return tf.nn.softmax_cross_entropy_with_logits(labels=target,\n                                                       logits=output)",
        "begin_line": 2984,
        "end_line": 3012,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000425531914893617,
            "pseudo_dstar_susp": 0.00041841004184100416,
            "pseudo_tarantula_susp": 0.0006706908115358819,
            "pseudo_op2_susp": 0.00041841004184100416,
            "pseudo_barinel_susp": 0.0006706908115358819
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sparse_categorical_crossentropy#3015",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sparse_categorical_crossentropy(target, output, from_logits=False)",
        "snippet": "def sparse_categorical_crossentropy(target, output, from_logits=False):\n    \"\"\"Categorical crossentropy with integer targets.\n\n    # Arguments\n        target: An integer tensor.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n\n    # Returns\n        Output tensor.\n    \"\"\"\n    # Note: tf.nn.sparse_softmax_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n        output = tf.log(output)\n\n    output_shape = output.get_shape()\n    targets = cast(flatten(target), 'int64')\n    logits = tf.reshape(output, [-1, int(output_shape[-1])])\n    res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n        labels=targets,\n        logits=logits)\n    if len(output_shape) >= 3:\n        # if our output includes timestep dimension\n        # or spatial dimensions we need to reshape\n        return tf.reshape(res, tf.shape(output)[:-1])\n    else:\n        return res",
        "begin_line": 3015,
        "end_line": 3047,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.binary_crossentropy#3050",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.binary_crossentropy(target, output, from_logits=False)",
        "snippet": "def binary_crossentropy(target, output, from_logits=False):\n    \"\"\"Binary crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor with the same shape as `output`.\n        output: A tensor.\n        from_logits: Whether `output` is expected to be a logits tensor.\n            By default, we consider that `output`\n            encodes a probability distribution.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    # Note: tf.nn.sigmoid_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # transform back to logits\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n        output = tf.log(output / (1 - output))\n\n    return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n                                                   logits=output)",
        "begin_line": 3050,
        "end_line": 3072,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0019083969465648854,
            "pseudo_dstar_susp": 0.0006361323155216285,
            "pseudo_tarantula_susp": 0.002531645569620253,
            "pseudo_op2_susp": 0.0006361323155216285,
            "pseudo_barinel_susp": 0.002531645569620253
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sigmoid#3075",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sigmoid(x)",
        "snippet": "def sigmoid(x):\n    \"\"\"Element-wise sigmoid.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.sigmoid(x)",
        "begin_line": 3075,
        "end_line": 3084,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027397260273972603,
            "pseudo_dstar_susp": 0.0006734006734006734,
            "pseudo_tarantula_susp": 0.003257328990228013,
            "pseudo_op2_susp": 0.0006734006734006734,
            "pseudo_barinel_susp": 0.003257328990228013
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.hard_sigmoid#3087",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.hard_sigmoid(x)",
        "snippet": "def hard_sigmoid(x):\n    \"\"\"Segment-wise linear approximation of sigmoid.\n\n    Faster than sigmoid.\n    Returns `0.` if `x < -2.5`, `1.` if `x > 2.5`.\n    In `-2.5 <= x <= 2.5`, returns `0.2 * x + 0.5`.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = (0.2 * x) + 0.5\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    one = _to_tensor(1., x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, one)\n    return x",
        "begin_line": 3087,
        "end_line": 3104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004278990158322636,
            "pseudo_dstar_susp": 0.00042052144659377626,
            "pseudo_tarantula_susp": 0.0006830601092896175,
            "pseudo_op2_susp": 0.00042052144659377626,
            "pseudo_barinel_susp": 0.0006830601092896175
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.tanh#3107",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.tanh(x)",
        "snippet": "def tanh(x):\n    \"\"\"Element-wise tanh.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.tanh(x)",
        "begin_line": 3107,
        "end_line": 3116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00039494470774091627,
            "pseudo_dstar_susp": 0.0003937007874015748,
            "pseudo_tarantula_susp": 0.0004930966469428008,
            "pseudo_op2_susp": 0.0003937007874015748,
            "pseudo_barinel_susp": 0.0004930966469428008
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.dropout#3119",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.dropout(x, level, noise_shape=None, seed=None)",
        "snippet": "def dropout(x, level, noise_shape=None, seed=None):\n    \"\"\"Sets entries in `x` to zero at random, while scaling the entire tensor.\n\n    # Arguments\n        x: tensor\n        level: fraction of the entries in the tensor\n            that will be set to 0.\n        noise_shape: shape for randomly generated keep/drop flags,\n            must be broadcastable to the shape of `x`\n        seed: random seed to ensure determinism.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    retain_prob = 1. - level\n    if seed is None:\n        seed = np.random.randint(10e6)\n    # the dummy 1. works around a TF bug\n    # (float32_ref vs. float32 incompatibility)\n    return tf.nn.dropout(x * 1., retain_prob, noise_shape, seed=seed)",
        "begin_line": 3119,
        "end_line": 3138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.592437931819907e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.l2_normalize#3141",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.l2_normalize(x, axis=None)",
        "snippet": "def l2_normalize(x, axis=None):\n    \"\"\"Normalizes a tensor wrt the L2 norm alongside the specified axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform normalization.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.l2_normalize(x, axis=axis)",
        "begin_line": 3141,
        "end_line": 3151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.in_top_k#3154",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.in_top_k(predictions, targets, k)",
        "snippet": "def in_top_k(predictions, targets, k):\n    \"\"\"Returns whether the `targets` are in the top `k` `predictions`.\n\n    # Arguments\n        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n        k: An `int`, number of top elements to consider.\n\n    # Returns\n        A 1D tensor of length `batch_size` and type `bool`.\n        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n        values of `predictions[i]`.\n    \"\"\"\n    return tf.nn.in_top_k(predictions, targets, k)",
        "begin_line": 3154,
        "end_line": 3167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._preprocess_conv1d_input#3173",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._preprocess_conv1d_input(x, data_format)",
        "snippet": "def _preprocess_conv1d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv1d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NHWC'  # to pass TF Conv2dNative operations\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 1))  # NCW -> NWC\n        else:\n            tf_data_format = 'NCHW'\n    return x, tf_data_format",
        "begin_line": 3173,
        "end_line": 3191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._preprocess_conv2d_input#3194",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._preprocess_conv2d_input(x, data_format)",
        "snippet": "def _preprocess_conv2d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv2d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n        else:\n            tf_data_format = 'NCHW'\n    return x, tf_data_format",
        "begin_line": 3194,
        "end_line": 3212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002207505518763797,
            "pseudo_dstar_susp": 0.0011507479861910242,
            "pseudo_tarantula_susp": 0.002136752136752137,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.002136752136752137
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._preprocess_conv3d_input#3215",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._preprocess_conv3d_input(x, data_format)",
        "snippet": "def _preprocess_conv3d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv3d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NDHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 4, 1))\n        else:\n            tf_data_format = 'NCDHW'\n    return x, tf_data_format",
        "begin_line": 3215,
        "end_line": 3233,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002506265664160401,
            "pseudo_dstar_susp": 0.0006596306068601583,
            "pseudo_tarantula_susp": 0.0029585798816568047,
            "pseudo_op2_susp": 0.0006596306068601583,
            "pseudo_barinel_susp": 0.0029585798816568047
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._preprocess_padding#3236",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._preprocess_padding(padding)",
        "snippet": "def _preprocess_padding(padding):\n    \"\"\"Convert keras' padding to tensorflow's padding.\n\n    # Arguments\n        padding: string, `\"same\"` or `\"valid\"`.\n\n    # Returns\n        a string, `\"SAME\"` or `\"VALID\"`.\n\n    # Raises\n        ValueError: if `padding` is invalid.\n    \"\"\"\n    if padding == 'same':\n        padding = 'SAME'\n    elif padding == 'valid':\n        padding = 'VALID'\n    else:\n        raise ValueError('Invalid padding: ' + str(padding))\n    return padding",
        "begin_line": 3236,
        "end_line": 3254,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0038314176245210726,
            "pseudo_dstar_susp": 0.001841620626151013,
            "pseudo_tarantula_susp": 0.0017761989342806395,
            "pseudo_op2_susp": 0.001841620626151013,
            "pseudo_barinel_susp": 0.0017761989342806395
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv1d#3257",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv1d(x, kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
        "snippet": "def conv1d(x, kernel, strides=1, padding='valid',\n           data_format=None, dilation_rate=1):\n    \"\"\"1D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: stride integer.\n        padding: string, `\"same\"`, `\"causal\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: integer dilate rate.\n\n    # Returns\n        A tensor, result of 1D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    kernel_shape = kernel.get_shape().as_list()\n    if padding == 'causal':\n        # causal (dilated) convolution:\n        left_pad = dilation_rate * (kernel_shape[0] - 1)\n        x = temporal_padding(x, (left_pad, 0))\n        padding = 'valid'\n    padding = _preprocess_padding(padding)\n    if data_format == 'channels_last':\n        tf_data_format = 'NWC'\n    else:\n        tf_data_format = 'NCW'\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=(dilation_rate,),\n        strides=(strides,),\n        padding=padding,\n        data_format=tf_data_format)\n    return x",
        "begin_line": 3257,
        "end_line": 3298,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv2d#3301",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv2d(x, kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
        "snippet": "def conv2d(x, kernel, strides=(1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 2 integers.\n\n    # Returns\n        A tensor, result of 2D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3301,
        "end_line": 3339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000741839762611276,
            "pseudo_dstar_susp": 0.0005151983513652757,
            "pseudo_tarantula_susp": 0.0012531328320802004,
            "pseudo_op2_susp": 0.0005151983513652757,
            "pseudo_barinel_susp": 0.0012531328320802004
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv2d_transpose#3342",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv2d_transpose(x, kernel, output_shape, strides=(1, 1), padding='valid', data_format=None)",
        "snippet": "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"2D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 2D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3342,
        "end_line": 3391,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.separable_conv1d#3394",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
        "snippet": "def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                     padding='valid', data_format=None, dilation_rate=1):\n    \"\"\"1D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: stride integer.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: integer dilation rate.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        spatial_start_dim = 1\n        strides = (1,) + strides * 2 + (1,)\n    else:\n        spatial_start_dim = 2\n        strides = (1, 1) + strides * 2\n    x = tf.expand_dims(x, spatial_start_dim)\n    depthwise_kernel = tf.expand_dims(depthwise_kernel, 0)\n    pointwise_kernel = tf.expand_dims(pointwise_kernel, 0)\n    dilation_rate = (1,) + dilation_rate\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n\n    x = tf.squeeze(x, [spatial_start_dim])\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 2, 1))  # NWC -> NCW\n\n    return x",
        "begin_line": 3394,
        "end_line": 3442,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.separable_conv2d#3445",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
        "snippet": "def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3445,
        "end_line": 3484,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.009009009009009009,
            "pseudo_dstar_susp": 0.0007739938080495357,
            "pseudo_tarantula_susp": 0.009259259259259259,
            "pseudo_op2_susp": 0.0007739938080495357,
            "pseudo_barinel_susp": 0.009259259259259259
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.depthwise_conv2d#3487",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
        "snippet": "def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n                     data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.depthwise_conv2d(x, depthwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3487,
        "end_line": 3525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv3d#3528",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv3d(x, kernel, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1))",
        "snippet": "def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1, 1)):\n    \"\"\"3D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 3 integers.\n\n    # Returns\n        A tensor, result of 3D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
        "begin_line": 3528,
        "end_line": 3564,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv3d_transpose#3567",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1), padding='valid', data_format=None)",
        "snippet": "def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"3D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: input tensor.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, \"same\" or \"valid\".\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 3D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[4],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NDHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv3d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
        "begin_line": 3567,
        "end_line": 3617,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.pool2d#3620",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.pool2d(x, pool_size, strides=(1, 1), padding='valid', data_format=None, pool_mode='max')",
        "snippet": "def pool2d(x, pool_size, strides=(1, 1),\n           padding='valid', data_format=None,\n           pool_mode='max'):\n    \"\"\"2D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 2 integers.\n        strides: tuple of 2 integers.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        pool_mode: string, `\"max\"` or `\"avg\"`.\n\n    # Returns\n        A tensor, result of 2D pooling.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n        ValueError: if `pool_mode` is neither `\"max\"` or `\"avg\"`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == 'max':\n        x = tf.nn.max_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    elif pool_mode == 'avg':\n        x = tf.nn.avg_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    else:\n        raise ValueError('Invalid pool_mode: ' + str(pool_mode))\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3620,
        "end_line": 3667,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.pool3d#3670",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.pool3d(x, pool_size, strides=(1, 1, 1), padding='valid', data_format=None, pool_mode='max')",
        "snippet": "def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n           data_format=None, pool_mode='max'):\n    \"\"\"3D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 3 integers.\n        strides: tuple of 3 integers.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        pool_mode: string, `\"max\"` or `\"avg\"`.\n\n    # Returns\n        A tensor, result of 3D pooling.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n        ValueError: if `pool_mode` is neither `\"max\"` or `\"avg\"`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NDHWC':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == 'max':\n        x = tf.nn.max_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    elif pool_mode == 'avg':\n        x = tf.nn.avg_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    else:\n        raise ValueError('Invalid pool_mode: ' + str(pool_mode))\n\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
        "begin_line": 3670,
        "end_line": 3716,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.009009009009009009,
            "pseudo_dstar_susp": 0.0007739938080495357,
            "pseudo_tarantula_susp": 0.009259259259259259,
            "pseudo_op2_susp": 0.0007739938080495357,
            "pseudo_barinel_susp": 0.009259259259259259
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.bias_add#3719",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.bias_add(x, bias, data_format=None)",
        "snippet": "def bias_add(x, bias, data_format=None):\n    \"\"\"Adds a bias vector to a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        bias: Bias tensor to add.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: In one of the two cases below:\n                    1. invalid `data_format` argument.\n                    2. invalid bias shape.\n                       the bias should be either a vector or\n                       a tensor with ndim(x) - 1 dimension\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n    bias_shape = int_shape(bias)\n    if len(bias_shape) != 1 and len(bias_shape) != ndim(x) - 1:\n        raise ValueError('Unexpected bias dimensions %d, expect to be 1 or %d dimensions'\n                         % (len(bias_shape), ndim(x)))\n    if ndim(x) == 5:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1, 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[3]) + bias_shape[:3])\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, 1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 4:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                if _has_nchw_support():\n                    x = tf.nn.bias_add(x, bias,\n                                       data_format='NCHW')\n                else:\n                    x += reshape(bias, (1, bias_shape[0], 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x = tf.nn.bias_add(x, bias,\n                                   data_format='NHWC')\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 3:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1))\n            else:\n                x += reshape(bias, (1, bias_shape[1], bias_shape[0]))\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1, ) + bias_shape)\n    else:\n        x = tf.nn.bias_add(x, bias)\n    return x",
        "begin_line": 3719,
        "end_line": 3785,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001594896331738437,
            "pseudo_dstar_susp": 0.007142857142857143,
            "pseudo_tarantula_susp": 0.001199040767386091,
            "pseudo_op2_susp": 0.007142857142857143,
            "pseudo_barinel_susp": 0.001199040767386091
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_normal#3790",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
        "snippet": "def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with normal distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: A float, mean of the normal distribution to draw samples.\n        stddev: A float, standard deviation of the normal distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.random_normal(shape, mean=mean, stddev=stddev,\n                            dtype=dtype, seed=seed)",
        "begin_line": 3790,
        "end_line": 3809,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_uniform#3812",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None)",
        "snippet": "def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with uniform distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        minval: A float, lower boundary of the uniform distribution\n            to draw samples.\n        maxval: A float, upper boundary of the uniform distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.random_uniform(shape, minval=minval, maxval=maxval,\n                             dtype=dtype, seed=seed)",
        "begin_line": 3812,
        "end_line": 3832,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0012091898428053204,
            "pseudo_dstar_susp": 0.005847953216374269,
            "pseudo_tarantula_susp": 0.0006775067750677507,
            "pseudo_op2_susp": 0.005847953216374269,
            "pseudo_barinel_susp": 0.0006775067750677507
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_binomial#3835",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_binomial(shape, p=0.0, dtype=None, seed=None)",
        "snippet": "def random_binomial(shape, p=0.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with random binomial distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        p: A float, `0. <= p <= 1`, probability of binomial distribution.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.where(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,\n                    tf.ones(shape, dtype=dtype),\n                    tf.zeros(shape, dtype=dtype))",
        "begin_line": 3835,
        "end_line": 3853,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.truncated_normal#3856",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
        "snippet": "def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with truncated random normal distribution of values.\n\n    The generated values follow a normal distribution\n    with specified mean and standard deviation,\n    except that values whose magnitude is more than\n    two standard deviations from the mean are dropped and re-picked.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: Mean of the values.\n        stddev: Standard deviation of the values.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.truncated_normal(shape, mean, stddev, dtype=dtype, seed=seed)",
        "begin_line": 3856,
        "end_line": 3878,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ctc_label_dense_to_sparse#3888",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ctc_label_dense_to_sparse(labels, label_lengths)",
        "snippet": "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(label_shape[0]),\n                                                  max_num_labels_tns), reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n    indices = tf.transpose(tf.reshape(concatenate([batch_ind, label_ind], axis=0), [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))",
        "begin_line": 3888,
        "end_line": 3922,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.range_less_than#3902",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.range_less_than(_, current_input)",
        "snippet": "    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)",
        "begin_line": 3902,
        "end_line": 3904,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ctc_batch_cost#3925",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)",
        "snippet": "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    \"\"\"Runs CTC loss algorithm on each batch element.\n\n    # Arguments\n        y_true: tensor `(samples, max_string_length)`\n            containing the truth labels.\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_pred`.\n        label_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_true`.\n\n    # Returns\n        Tensor with shape (samples,1) containing the\n            CTC loss of each element.\n    \"\"\"\n    label_length = tf.to_int32(tf.squeeze(label_length))\n    input_length = tf.to_int32(tf.squeeze(input_length))\n    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))\n\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n\n    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,\n                                       labels=sparse_labels,\n                                       sequence_length=input_length), 1)",
        "begin_line": 3925,
        "end_line": 3950,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ctc_decode#3953",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1)",
        "snippet": "def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n               top_paths=1):\n    \"\"\"Decodes the output of a softmax.\n\n    Can use either greedy search (also known as best path)\n    or a constrained dictionary search.\n\n    # Arguments\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, )` containing the sequence length for\n            each batch item in `y_pred`.\n        greedy: perform much faster best-path search if `true`.\n            This does not use a dictionary.\n        beam_width: if `greedy` is `false`: a beam search decoder will be used\n            with a beam of this width.\n        top_paths: if `greedy` is `false`,\n            how many of the most probable paths will be returned.\n\n    # Returns\n        Tuple:\n            List: if `greedy` is `true`, returns a list of one element that\n                contains the decoded sequence.\n                If `false`, returns the `top_paths` most probable\n                decoded sequences.\n                Important: blank labels are returned as `-1`.\n            Tensor `(top_paths, )` that contains\n                the log probability of each decoded sequence.\n    \"\"\"\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n    input_length = tf.to_int32(input_length)\n\n    if greedy:\n        (decoded, log_prob) = ctc.ctc_greedy_decoder(\n            inputs=y_pred,\n            sequence_length=input_length)\n    else:\n        (decoded, log_prob) = ctc.ctc_beam_search_decoder(\n            inputs=y_pred,\n            sequence_length=input_length, beam_width=beam_width,\n            top_paths=top_paths)\n\n    decoded_dense = [tf.sparse_to_dense(st.indices, st.dense_shape, st.values, default_value=-1)\n                     for st in decoded]\n    return (decoded_dense, log_prob)",
        "begin_line": 3953,
        "end_line": 3997,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.001184834123222749,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.001184834123222749,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.map_fn#4002",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.map_fn(fn, elems, name=None, dtype=None)",
        "snippet": "def map_fn(fn, elems, name=None, dtype=None):\n    \"\"\"Map the function fn over the elements elems and return the outputs.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems\n        elems: tensor\n        name: A string name for the map node in the graph\n        dtype: Output data type.\n\n    # Returns\n        Tensor with dtype `dtype`.\n    \"\"\"\n    return tf.map_fn(fn, elems, name=name, dtype=dtype)",
        "begin_line": 4002,
        "end_line": 4014,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.foldl#4017",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.foldl(fn, elems, initializer=None, name=None)",
        "snippet": "def foldl(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from left to right.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[0]` in case of None)\n        name: A string name for the foldl node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    \"\"\"\n    return tf.foldl(fn, elems, initializer=initializer, name=name)",
        "begin_line": 4017,
        "end_line": 4030,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.foldr#4033",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.foldr(fn, elems, initializer=None, name=None)",
        "snippet": "def foldr(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from right to left.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[-1]` in case of None)\n        name: A string name for the foldr node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    \"\"\"\n    return tf.foldr(fn, elems, initializer=initializer, name=name)",
        "begin_line": 4033,
        "end_line": 4046,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.local_conv1d#4049",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.local_conv1d(inputs, kernel, kernel_size, strides, data_format=None)",
        "snippet": "def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n    \"\"\"Apply 1D conv with un-shared weights.\n\n    # Arguments\n        inputs: 3D tensor with shape: (batch_size, steps, input_dim)\n        kernel: the unshared weight for convolution,\n                with shape (output_length, feature_dim, filters)\n        kernel_size: a tuple of a single integer,\n                     specifying the length of the 1D convolution window\n        strides: a tuple of a single integer,\n                 specifying the stride length of the convolution\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        the tensor after 1d conv with un-shared weights, with shape (batch_size, output_length, filters)\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    stride = strides[0]\n    kernel_shape = int_shape(kernel)\n    output_length, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_length):\n        slice_length = slice(i * stride,\n                             i * stride + kernel_size[0])\n        xs.append(reshape(inputs[:, slice_length, :],\n                          (1, -1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=0)\n    # Shape: `(output_length, batch_size, filters)`.\n    output = batch_dot(x_aggregate, kernel)\n    return permute_dimensions(output, (1, 0, 2))",
        "begin_line": 4049,
        "end_line": 4086,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.local_conv2d#4089",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None)",
        "snippet": "def local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None):\n    \"\"\"Apply 2D conv with un-shared weights.\n\n    # Arguments\n        inputs: 4D tensor with shape:\n                (batch_size, filters, new_rows, new_cols)\n                if data_format='channels_first'\n                or 4D tensor with shape:\n                (batch_size, new_rows, new_cols, filters)\n                if data_format='channels_last'.\n        kernel: the unshared weight for convolution,\n                with shape (output_items, feature_dim, filters)\n        kernel_size: a tuple of 2 integers, specifying the\n                     width and height of the 2D convolution window.\n        strides: a tuple of 2 integers, specifying the strides\n                 of the convolution along the width and height.\n        output_shape: a tuple with (output_row, output_col)\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        A 4d tensor with shape:\n        (batch_size, filters, new_rows, new_cols)\n        if data_format='channels_first'\n        or 4D tensor with shape:\n        (batch_size, new_rows, new_cols, filters)\n        if data_format='channels_last'.\n\n    # Raises\n        ValueError: if `data_format` is neither\n                    `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    stride_row, stride_col = strides\n    output_row, output_col = output_shape\n    kernel_shape = int_shape(kernel)\n    _, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_row):\n        for j in range(output_col):\n            slice_row = slice(i * stride_row,\n                              i * stride_row + kernel_size[0])\n            slice_col = slice(j * stride_col,\n                              j * stride_col + kernel_size[1])\n            if data_format == 'channels_first':\n                xs.append(reshape(inputs[:, :, slice_row, slice_col],\n                                  (1, -1, feature_dim)))\n            else:\n                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                  (1, -1, feature_dim)))\n\n    x_aggregate = concatenate(xs, axis=0)\n    output = batch_dot(x_aggregate, kernel)\n    output = reshape(output,\n                     (output_row, output_col, -1, filters))\n\n    if data_format == 'channels_first':\n        output = permute_dimensions(output, (2, 3, 0, 1))\n    else:\n        output = permute_dimensions(output, (2, 0, 1, 3))\n    return output",
        "begin_line": 4089,
        "end_line": 4153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.conv_utils.normalize_tuple#12",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.normalize_tuple(value, n, name)",
        "snippet": "def normalize_tuple(value, n, name):\n    \"\"\"Transforms a single int or iterable of ints into an int tuple.\n\n    # Arguments\n        value: The value to validate and convert. Could an int, or any iterable\n          of ints.\n        n: The size of the tuple to be returned.\n        name: The name of the argument being validated, e.g. \"strides\" or\n          \"kernel_size\". This is only used to format error messages.\n\n    # Returns\n        A tuple of n integers.\n\n    # Raises\n        ValueError: If something else than an int/long or iterable thereof was\n        passed.\n    \"\"\"\n    if isinstance(value, int):\n        return (value,) * n\n    else:\n        try:\n            value_tuple = tuple(value)\n        except TypeError:\n            raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                             str(n) + ' integers. Received: ' + str(value))\n        if len(value_tuple) != n:\n            raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                             str(n) + ' integers. Received: ' + str(value))\n        for single_value in value_tuple:\n            try:\n                int(single_value)\n            except ValueError:\n                raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                                 str(n) + ' integers. Received: ' + str(value) + ' '\n                                 'including element ' + str(single_value) + ' of type' +\n                                 ' ' + str(type(single_value)))\n    return value_tuple",
        "begin_line": 12,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004462293618920125,
            "pseudo_dstar_susp": 0.00043725404459991256,
            "pseudo_tarantula_susp": 0.0007722007722007722,
            "pseudo_op2_susp": 0.00043725404459991256,
            "pseudo_barinel_susp": 0.0007722007722007722
        }
    },
    {
        "name": "keras.utils.conv_utils.normalize_data_format#51",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.normalize_data_format(value)",
        "snippet": "def normalize_data_format(value):\n    if value is None:\n        value = K.image_data_format()\n    data_format = value.lower()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('The `data_format` argument must be one of '\n                         '\"channels_first\", \"channels_last\". Received: ' +\n                         str(value))\n    return data_format",
        "begin_line": 51,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005282620179609086,
            "pseudo_dstar_susp": 0.00046274872744099955,
            "pseudo_tarantula_susp": 0.0009033423667570009,
            "pseudo_op2_susp": 0.00046274872744099955,
            "pseudo_barinel_susp": 0.0009049773755656109
        }
    },
    {
        "name": "keras.utils.conv_utils.normalize_padding#62",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.normalize_padding(value)",
        "snippet": "def normalize_padding(value):\n    padding = value.lower()\n    allowed = {'valid', 'same', 'causal'}\n    if K.backend() == 'theano':\n        allowed.add('full')\n    if padding not in allowed:\n        raise ValueError('The `padding` argument must be one of \"valid\", \"same\" (or \"causal\" for Conv1D). '\n                         'Received: ' + str(padding))\n    return padding",
        "begin_line": 62,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005178663904712584,
            "pseudo_dstar_susp": 0.0004601932811780948,
            "pseudo_tarantula_susp": 0.0008665511265164644,
            "pseudo_op2_susp": 0.0004601932811780948,
            "pseudo_barinel_susp": 0.0008665511265164644
        }
    },
    {
        "name": "keras.utils.conv_utils.convert_kernel#73",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.convert_kernel(kernel)",
        "snippet": "def convert_kernel(kernel):\n    \"\"\"Converts a Numpy kernel matrix from Theano format to TensorFlow format.\n\n    Also works reciprocally, since the transformation is its own inverse.\n\n    # Arguments\n        kernel: Numpy array (3D, 4D or 5D).\n\n    # Returns\n        The converted kernel.\n\n    # Raises\n        ValueError: in case of invalid kernel shape or invalid data_format.\n    \"\"\"\n    kernel = np.asarray(kernel)\n    if not 3 <= kernel.ndim <= 5:\n        raise ValueError('Invalid kernel shape:', kernel.shape)\n    slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n    no_flip = (slice(None, None), slice(None, None))\n    slices[-2:] = no_flip\n    return np.copy(kernel[slices])",
        "begin_line": 73,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.conv_utils.conv_output_length#96",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.conv_output_length(input_length, filter_size, padding, stride, dilation=1)",
        "snippet": "def conv_output_length(input_length, filter_size,\n                       padding, stride, dilation=1):\n    \"\"\"Determines output length of a convolution given input length.\n\n    # Arguments\n        input_length: integer.\n        filter_size: integer.\n        padding: one of \"same\", \"valid\", \"full\".\n        stride: integer.\n        dilation: dilation rate, integer.\n\n    # Returns\n        The output length (integer).\n    \"\"\"\n    if input_length is None:\n        return None\n    assert padding in {'same', 'valid', 'full', 'causal'}\n    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n    if padding == 'same':\n        output_length = input_length\n    elif padding == 'valid':\n        output_length = input_length - dilated_filter_size + 1\n    elif padding == 'causal':\n        output_length = input_length\n    elif padding == 'full':\n        output_length = input_length + dilated_filter_size - 1\n    return (output_length + stride - 1) // stride",
        "begin_line": 96,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005685048322910744,
            "pseudo_dstar_susp": 0.00048192771084337347,
            "pseudo_tarantula_susp": 0.0010683760683760685,
            "pseudo_op2_susp": 0.00048192771084337347,
            "pseudo_barinel_susp": 0.0010683760683760685
        }
    },
    {
        "name": "keras.utils.conv_utils.conv_input_length#125",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.conv_input_length(output_length, filter_size, padding, stride)",
        "snippet": "def conv_input_length(output_length, filter_size, padding, stride):\n    \"\"\"Determines input length of a convolution given output length.\n\n    # Arguments\n        output_length: integer.\n        filter_size: integer.\n        padding: one of \"same\", \"valid\", \"full\".\n        stride: integer.\n\n    # Returns\n        The input length (integer).\n    \"\"\"\n    if output_length is None:\n        return None\n    assert padding in {'same', 'valid', 'full'}\n    if padding == 'same':\n        pad = filter_size // 2\n    elif padding == 'valid':\n        pad = 0\n    elif padding == 'full':\n        pad = filter_size - 1\n    return (output_length - 1) * stride - 2 * pad + filter_size",
        "begin_line": 125,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.conv_utils.deconv_length#149",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.deconv_length(dim_size, stride_size, kernel_size, padding)",
        "snippet": "def deconv_length(dim_size, stride_size, kernel_size, padding):\n    if dim_size is None:\n        return None\n    if padding == 'valid':\n        dim_size = dim_size * stride_size + max(kernel_size - stride_size, 0)\n    elif padding == 'full':\n        dim_size = dim_size * stride_size - (stride_size + kernel_size - 2)\n    elif padding == 'same':\n        dim_size = dim_size * stride_size\n    return dim_size",
        "begin_line": 149,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.densenet.dense_block#50",
        "src_path": "keras/applications/densenet.py",
        "class_name": "keras.applications.densenet",
        "signature": "keras.applications.densenet.dense_block(x, blocks, name)",
        "snippet": "def dense_block(x, blocks, name):\n    \"\"\"A dense block.\n\n    # Arguments\n        x: input tensor.\n        blocks: integer, the number of building blocks.\n        name: string, block label.\n\n    # Returns\n        output tensor for the block.\n    \"\"\"\n    for i in range(blocks):\n        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n    return x",
        "begin_line": 50,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.densenet.transition_block#66",
        "src_path": "keras/applications/densenet.py",
        "class_name": "keras.applications.densenet",
        "signature": "keras.applications.densenet.transition_block(x, reduction, name)",
        "snippet": "def transition_block(x, reduction, name):\n    \"\"\"A transition block.\n\n    # Arguments\n        x: input tensor.\n        reduction: float, compression rate at transition layers.\n        name: string, block label.\n\n    # Returns\n        output tensor for the block.\n    \"\"\"\n    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                           name=name + '_bn')(x)\n    x = Activation('relu', name=name + '_relu')(x)\n    x = Conv2D(int(K.int_shape(x)[bn_axis] * reduction), 1, use_bias=False,\n               name=name + '_conv')(x)\n    x = AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n    return x",
        "begin_line": 66,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.densenet.conv_block#87",
        "src_path": "keras/applications/densenet.py",
        "class_name": "keras.applications.densenet",
        "signature": "keras.applications.densenet.conv_block(x, growth_rate, name)",
        "snippet": "def conv_block(x, growth_rate, name):\n    \"\"\"A building block for a dense block.\n\n    # Arguments\n        x: input tensor.\n        growth_rate: float, growth rate at dense layers.\n        name: string, block label.\n\n    # Returns\n        output tensor for the block.\n    \"\"\"\n    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                            name=name + '_0_bn')(x)\n    x1 = Activation('relu', name=name + '_0_relu')(x1)\n    x1 = Conv2D(4 * growth_rate, 1, use_bias=False,\n                name=name + '_1_conv')(x1)\n    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                            name=name + '_1_bn')(x1)\n    x1 = Activation('relu', name=name + '_1_relu')(x1)\n    x1 = Conv2D(growth_rate, 3, padding='same', use_bias=False,\n                name=name + '_2_conv')(x1)\n    x = Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n    return x",
        "begin_line": 87,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.densenet.DenseNet#113",
        "src_path": "keras/applications/densenet.py",
        "class_name": "keras.applications.densenet",
        "signature": "keras.applications.densenet.DenseNet(blocks, include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def DenseNet(blocks,\n             include_top=True,\n             weights='imagenet',\n             input_tensor=None,\n             input_shape=None,\n             pooling=None,\n             classes=1000):\n    \"\"\"Instantiates the DenseNet architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format='channels_last'` in your Keras config\n    at ~/.keras/keras.json.\n\n    The model and the weights are compatible with\n    TensorFlow, Theano, and CNTK. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        blocks: numbers of building blocks for the four dense layers.\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 224)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels.\n        pooling: optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=221,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n\n    x = ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n    x = Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)\n    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                           name='conv1/bn')(x)\n    x = Activation('relu', name='conv1/relu')(x)\n    x = ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n    x = MaxPooling2D(3, strides=2, name='pool1')(x)\n\n    x = dense_block(x, blocks[0], name='conv2')\n    x = transition_block(x, 0.5, name='pool2')\n    x = dense_block(x, blocks[1], name='conv3')\n    x = transition_block(x, 0.5, name='pool3')\n    x = dense_block(x, blocks[2], name='conv4')\n    x = transition_block(x, 0.5, name='pool4')\n    x = dense_block(x, blocks[3], name='conv5')\n\n    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                           name='bn')(x)\n\n    if include_top:\n        x = GlobalAveragePooling2D(name='avg_pool')(x)\n        x = Dense(classes, activation='softmax', name='fc1000')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D(name='avg_pool')(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D(name='max_pool')(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    # Create model.\n    if blocks == [6, 12, 24, 16]:\n        model = Model(inputs, x, name='densenet121')\n    elif blocks == [6, 12, 32, 32]:\n        model = Model(inputs, x, name='densenet169')\n    elif blocks == [6, 12, 48, 32]:\n        model = Model(inputs, x, name='densenet201')\n    else:\n        model = Model(inputs, x, name='densenet')\n\n    # Load weights.\n    if weights == 'imagenet':\n        if include_top:\n            if blocks == [6, 12, 24, 16]:\n                weights_path = get_file(\n                    'densenet121_weights_tf_dim_ordering_tf_kernels.h5',\n                    DENSENET121_WEIGHT_PATH,\n                    cache_subdir='models',\n                    file_hash='0962ca643bae20f9b6771cb844dca3b0')\n            elif blocks == [6, 12, 32, 32]:\n                weights_path = get_file(\n                    'densenet169_weights_tf_dim_ordering_tf_kernels.h5',\n                    DENSENET169_WEIGHT_PATH,\n                    cache_subdir='models',\n                    file_hash='bcf9965cf5064a5f9eb6d7dc69386f43')\n            elif blocks == [6, 12, 48, 32]:\n                weights_path = get_file(\n                    'densenet201_weights_tf_dim_ordering_tf_kernels.h5',\n                    DENSENET201_WEIGHT_PATH,\n                    cache_subdir='models',\n                    file_hash='7bb75edd58cb43163be7e0005fbe95ef')\n        else:\n            if blocks == [6, 12, 24, 16]:\n                weights_path = get_file(\n                    'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                    DENSENET121_WEIGHT_PATH_NO_TOP,\n                    cache_subdir='models',\n                    file_hash='4912a53fbd2a69346e7f2c0b5ec8c6d3')\n            elif blocks == [6, 12, 32, 32]:\n                weights_path = get_file(\n                    'densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                    DENSENET169_WEIGHT_PATH_NO_TOP,\n                    cache_subdir='models',\n                    file_hash='50662582284e4cf834ce40ab4dfa58c6')\n            elif blocks == [6, 12, 48, 32]:\n                weights_path = get_file(\n                    'densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                    DENSENET201_WEIGHT_PATH_NO_TOP,\n                    cache_subdir='models',\n                    file_hash='1c2de60ee40562448dbac34a0737e798')\n        model.load_weights(weights_path)\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model",
        "begin_line": 113,
        "end_line": 286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.densenet.DenseNet121#289",
        "src_path": "keras/applications/densenet.py",
        "class_name": "keras.applications.densenet",
        "signature": "keras.applications.densenet.DenseNet121(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def DenseNet121(include_top=True,\n                weights='imagenet',\n                input_tensor=None,\n                input_shape=None,\n                pooling=None,\n                classes=1000):\n    return DenseNet([6, 12, 24, 16],\n                    include_top, weights,\n                    input_tensor, input_shape,\n                    pooling, classes)",
        "begin_line": 289,
        "end_line": 298,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.densenet.DenseNet169#301",
        "src_path": "keras/applications/densenet.py",
        "class_name": "keras.applications.densenet",
        "signature": "keras.applications.densenet.DenseNet169(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def DenseNet169(include_top=True,\n                weights='imagenet',\n                input_tensor=None,\n                input_shape=None,\n                pooling=None,\n                classes=1000):\n    return DenseNet([6, 12, 32, 32],\n                    include_top, weights,\n                    input_tensor, input_shape,\n                    pooling, classes)",
        "begin_line": 301,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.densenet.DenseNet201#313",
        "src_path": "keras/applications/densenet.py",
        "class_name": "keras.applications.densenet",
        "signature": "keras.applications.densenet.DenseNet201(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def DenseNet201(include_top=True,\n                weights='imagenet',\n                input_tensor=None,\n                input_shape=None,\n                pooling=None,\n                classes=1000):\n    return DenseNet([6, 12, 48, 32],\n                    include_top, weights,\n                    input_tensor, input_shape,\n                    pooling, classes)",
        "begin_line": 313,
        "end_line": 322,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.densenet.preprocess_input#325",
        "src_path": "keras/applications/densenet.py",
        "class_name": "keras.applications.densenet",
        "signature": "keras.applications.densenet.preprocess_input(x, data_format=None)",
        "snippet": "def preprocess_input(x, data_format=None):\n    \"\"\"Preprocesses a numpy array encoding a batch of images.\n\n    # Arguments\n        x: a 3D or 4D numpy array consists of RGB values within [0, 255].\n        data_format: data format of the image tensor.\n\n    # Returns\n        Preprocessed array.\n    \"\"\"\n    return imagenet_utils.preprocess_input(x, data_format, mode='torch')",
        "begin_line": 325,
        "end_line": 335,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.datasets.cifar.load_batch#12",
        "src_path": "keras/datasets/cifar.py",
        "class_name": "keras.datasets.cifar",
        "signature": "keras.datasets.cifar.load_batch(fpath, label_key='labels')",
        "snippet": "def load_batch(fpath, label_key='labels'):\n    \"\"\"Internal utility for parsing CIFAR data.\n\n    # Arguments\n        fpath: path the file to parse.\n        label_key: key for label data in the retrieve\n            dictionary.\n\n    # Returns\n        A tuple `(data, labels)`.\n    \"\"\"\n    with open(fpath, 'rb') as f:\n        if sys.version_info < (3,):\n            d = cPickle.load(f)\n        else:\n            d = cPickle.load(f, encoding='bytes')\n            # decode utf8\n            d_decoded = {}\n            for k, v in d.items():\n                d_decoded[k.decode('utf8')] = v\n            d = d_decoded\n    data = d['data']\n    labels = d[label_key]\n\n    data = data.reshape(data.shape[0], 3, 32, 32)\n    return data, labels",
        "begin_line": 12,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.__init__#47",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.__init__(self, cells, **kwargs)",
        "snippet": "    def __init__(self, cells, **kwargs):\n        for cell in cells:\n            if not hasattr(cell, 'call'):\n                raise ValueError('All cells must have a `call` method. '\n                                 'received cells:', cells)\n            if not hasattr(cell, 'state_size'):\n                raise ValueError('All cells must have a '\n                                 '`state_size` attribute. '\n                                 'received cells:', cells)\n        self.cells = cells\n        super(StackedRNNCells, self).__init__(**kwargs)",
        "begin_line": 47,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.state_size#60",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.state_size(self)",
        "snippet": "    def state_size(self):\n        # States are a flat list\n        # in reverse order of the cell stack.\n        # This allows to preserve the requirement\n        # `stack.state_size[0] == output_dim`.\n        # e.g. states of a 2-layer LSTM would be\n        # `[h2, c2, h1, c1]`\n        # (assuming one LSTM has states [h, c])\n        state_size = []\n        for cell in self.cells[::-1]:\n            if hasattr(cell.state_size, '__len__'):\n                state_size += list(cell.state_size)\n            else:\n                state_size.append(cell.state_size)\n        return tuple(state_size)",
        "begin_line": 60,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.call#76",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.call(self, inputs, states, constants=None, **kwargs)",
        "snippet": "    def call(self, inputs, states, constants=None, **kwargs):\n        # Recover per-cell states.\n        nested_states = []\n        for cell in self.cells[::-1]:\n            if hasattr(cell.state_size, '__len__'):\n                nested_states.append(states[:len(cell.state_size)])\n                states = states[len(cell.state_size):]\n            else:\n                nested_states.append([states[0]])\n                states = states[1:]\n        nested_states = nested_states[::-1]\n\n        # Call the cells in order and store the returned states.\n        new_nested_states = []\n        for cell, states in zip(self.cells, nested_states):\n            if has_arg(cell.call, 'constants'):\n                inputs, states = cell.call(inputs, states,\n                                           constants=constants,\n                                           **kwargs)\n            else:\n                inputs, states = cell.call(inputs, states, **kwargs)\n            new_nested_states.append(states)\n\n        # Format the new states as a flat list\n        # in reverse cell order.\n        states = []\n        for cell_states in new_nested_states[::-1]:\n            states += cell_states\n        return inputs, states",
        "begin_line": 76,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.build#106",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if isinstance(input_shape, list):\n            constants_shape = input_shape[1:]\n            input_shape = input_shape[0]\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                if has_arg(cell.call, 'constants'):\n                    cell.build([input_shape] + constants_shape)\n                else:\n                    cell.build(input_shape)\n            if hasattr(cell.state_size, '__len__'):\n                output_dim = cell.state_size[0]\n            else:\n                output_dim = cell.state_size\n            input_shape = (input_shape[0], output_dim)\n        self.built = True",
        "begin_line": 106,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.get_config#123",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.get_config(self)",
        "snippet": "    def get_config(self):\n        cells = []\n        for cell in self.cells:\n            cells.append({'class_name': cell.__class__.__name__,\n                          'config': cell.get_config()})\n        config = {'cells': cells}\n        base_config = super(StackedRNNCells, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 123,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.from_config#133",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        cells = []\n        for cell_config in config.pop('cells'):\n            cells.append(deserialize_layer(cell_config,\n                                           custom_objects=custom_objects))\n        return cls(cells, **config)",
        "begin_line": 133,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.trainable_weights#142",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        weights = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                weights += cell.trainable_weights\n        return weights",
        "begin_line": 142,
        "end_line": 149,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.non_trainable_weights#152",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        weights = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                weights += cell.non_trainable_weights\n        if not self.trainable:\n            trainable_weights = []\n            for cell in self.cells:\n                if isinstance(cell, Layer):\n                    trainable_weights += cell.trainable_weights\n            return trainable_weights + weights\n        return weights",
        "begin_line": 152,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.get_weights#165",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.get_weights(self)",
        "snippet": "    def get_weights(self):\n        \"\"\"Retrieves the weights of the model.\n\n        # Returns\n            A flat list of Numpy arrays.\n        \"\"\"\n        weights = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                weights += cell.weights\n        return K.batch_get_value(weights)",
        "begin_line": 165,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.set_weights#177",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the model.\n\n        # Arguments\n            weights: A list of Numpy arrays with shapes and types matching\n                the output of `model.get_weights()`.\n        \"\"\"\n        tuples = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                num_param = len(cell.weights)\n                weights = weights[:num_param]\n                for sw, w in zip(cell.weights, weights):\n                    tuples.append((sw, w))\n                weights = weights[num_param:]\n        K.batch_set_value(tuples)",
        "begin_line": 177,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.losses#195",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.losses(self)",
        "snippet": "    def losses(self):\n        losses = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                cell_losses = cell.losses\n                losses += cell_losses\n        return losses",
        "begin_line": 195,
        "end_line": 201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.get_losses_for#203",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.get_losses_for(self, inputs=None)",
        "snippet": "    def get_losses_for(self, inputs=None):\n        losses = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                cell_losses = cell.get_losses_for(inputs)\n                losses += cell_losses\n        return losses",
        "begin_line": 203,
        "end_line": 209,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.__init__#363",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.__init__(self, cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)",
        "snippet": "    def __init__(self, cell,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if isinstance(cell, (list, tuple)):\n            cell = StackedRNNCells(cell)\n        if not hasattr(cell, 'call'):\n            raise ValueError('`cell` should have a `call` method. '\n                             'The RNN was passed:', cell)\n        if not hasattr(cell, 'state_size'):\n            raise ValueError('The RNN cell should have '\n                             'an attribute `state_size` '\n                             '(tuple of integers, '\n                             'one integer per RNN state).')\n        super(RNN, self).__init__(**kwargs)\n        self.cell = cell\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.unroll = unroll\n\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.state_spec = None\n        self._states = None\n        self.constants_spec = None\n        self._num_constants = None",
        "begin_line": 363,
        "end_line": 393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.states#396",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.states(self)",
        "snippet": "    def states(self):\n        if self._states is None:\n            if isinstance(self.cell.state_size, int):\n                num_states = 1\n            else:\n                num_states = len(self.cell.state_size)\n            return [None for _ in range(num_states)]\n        return self._states",
        "begin_line": 396,
        "end_line": 403,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.171937566396992e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.states#406",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.states(self, states)",
        "snippet": "    def states(self, states):\n        self._states = states",
        "begin_line": 406,
        "end_line": 407,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.171937566396992e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.compute_output_shape#409",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        if hasattr(self.cell.state_size, '__len__'):\n            state_size = self.cell.state_size\n        else:\n            state_size = [self.cell.state_size]\n        output_dim = state_size[0]\n\n        if self.return_sequences:\n            output_shape = (input_shape[0], input_shape[1], output_dim)\n        else:\n            output_shape = (input_shape[0], output_dim)\n\n        if self.return_state:\n            state_shape = [(input_shape[0], dim) for dim in state_size]\n            return [output_shape] + state_shape\n        else:\n            return output_shape",
        "begin_line": 409,
        "end_line": 428,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.973210014351777e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.compute_mask#430",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.compute_mask(self, inputs, mask)",
        "snippet": "    def compute_mask(self, inputs, mask):\n        if isinstance(mask, list):\n            mask = mask[0]\n        output_mask = mask if self.return_sequences else None\n        if self.return_state:\n            state_mask = [None for _ in self.states]\n            return [output_mask] + state_mask\n        else:\n            return output_mask",
        "begin_line": 430,
        "end_line": 438,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.build#440",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        # Note input_shape will be list of shapes of initial states and\n        # constants if these are passed in __call__.\n        if self._num_constants is not None:\n            constants_shape = input_shape[-self._num_constants:]\n        else:\n            constants_shape = None\n\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        input_dim = input_shape[-1]\n        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n\n        # allow cell (if layer) to build before we set or validate state_spec\n        if isinstance(self.cell, Layer):\n            step_input_shape = (input_shape[0],) + input_shape[2:]\n            if constants_shape is not None:\n                self.cell.build([step_input_shape] + constants_shape)\n            else:\n                self.cell.build(step_input_shape)\n\n        # set or validate state_spec\n        if hasattr(self.cell.state_size, '__len__'):\n            state_size = list(self.cell.state_size)\n        else:\n            state_size = [self.cell.state_size]\n\n        if self.state_spec is not None:\n            # initial_state was passed in call, check compatibility\n            if [spec.shape[-1] for spec in self.state_spec] != state_size:\n                raise ValueError(\n                    'An `initial_state` was passed that is not compatible with '\n                    '`cell.state_size`. Received `state_spec`={}; '\n                    'however `cell.state_size` is '\n                    '{}'.format(self.state_spec, self.cell.state_size))\n        else:\n            self.state_spec = [InputSpec(shape=(None, dim))\n                               for dim in state_size]\n        if self.stateful:\n            self.reset_states()",
        "begin_line": 440,
        "end_line": 481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.get_initial_state#483",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.get_initial_state(self, inputs)",
        "snippet": "    def get_initial_state(self, inputs):\n        # build an all-zero tensor of shape (samples, output_dim)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        if hasattr(self.cell.state_size, '__len__'):\n            return [K.tile(initial_state, [1, dim])\n                    for dim in self.cell.state_size]\n        else:\n            return [K.tile(initial_state, [1, self.cell.state_size])]",
        "begin_line": 483,
        "end_line": 492,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.616146230007616e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.__call__#494",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.__call__(self, inputs, initial_state=None, constants=None, **kwargs)",
        "snippet": "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n        inputs, initial_state, constants = self._standardize_args(\n            inputs, initial_state, constants)\n\n        if initial_state is None and constants is None:\n            return super(RNN, self).__call__(inputs, **kwargs)\n\n        # If any of `initial_state` or `constants` are specified and are Keras\n        # tensors, then add them to the inputs and temporarily modify the\n        # input_spec to include them.\n\n        additional_inputs = []\n        additional_specs = []\n        if initial_state is not None:\n            kwargs['initial_state'] = initial_state\n            additional_inputs += initial_state\n            self.state_spec = [InputSpec(shape=K.int_shape(state))\n                               for state in initial_state]\n            additional_specs += self.state_spec\n        if constants is not None:\n            kwargs['constants'] = constants\n            additional_inputs += constants\n            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n                                   for constant in constants]\n            self._num_constants = len(constants)\n            additional_specs += self.constants_spec\n        # at this point additional_inputs cannot be empty\n        is_keras_tensor = K.is_keras_tensor(additional_inputs[0])\n        for tensor in additional_inputs:\n            if K.is_keras_tensor(tensor) != is_keras_tensor:\n                raise ValueError('The initial state or constants of an RNN'\n                                 ' layer cannot be specified with a mix of'\n                                 ' Keras tensors and non-Keras tensors'\n                                 ' (a \"Keras tensor\" is a tensor that was'\n                                 ' returned by a Keras layer, or by `Input`)')\n\n        if is_keras_tensor:\n            # Compute the full input spec, including state and constants\n            full_input = [inputs] + additional_inputs\n            full_input_spec = self.input_spec + additional_specs\n            # Perform the call with temporarily replaced input_spec\n            original_input_spec = self.input_spec\n            self.input_spec = full_input_spec\n            output = super(RNN, self).__call__(full_input, **kwargs)\n            self.input_spec = original_input_spec\n            return output\n        else:\n            return super(RNN, self).__call__(inputs, **kwargs)",
        "begin_line": 494,
        "end_line": 541,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.call#543",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.call(self, inputs, mask=None, training=None, initial_state=None, constants=None)",
        "snippet": "    def call(self,\n             inputs,\n             mask=None,\n             training=None,\n             initial_state=None,\n             constants=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            inputs = inputs[0]\n        if initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if isinstance(mask, list):\n            mask = mask[0]\n\n        if len(initial_state) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_state)) +\n                             ' initial states.')\n        input_shape = K.int_shape(inputs)\n        timesteps = input_shape[1]\n        if self.unroll and timesteps in [None, 1]:\n            raise ValueError('Cannot unroll a RNN if the '\n                             'time dimension is undefined or equal to 1. \\n'\n                             '- If using a Sequential model, '\n                             'specify the time dimension by passing '\n                             'an `input_shape` or `batch_input_shape` '\n                             'argument to your first layer. If your '\n                             'first layer is an Embedding, you can '\n                             'also use the `input_length` argument.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a `shape` '\n                             'or `batch_shape` argument to your Input layer.')\n\n        kwargs = {}\n        if has_arg(self.cell.call, 'training'):\n            kwargs['training'] = training\n\n        if constants:\n            if not has_arg(self.cell.call, 'constants'):\n                raise ValueError('RNN cell does not support constants')\n\n            def step(inputs, states):\n                constants = states[-self._num_constants:]\n                states = states[:-self._num_constants]\n                return self.cell.call(inputs, states, constants=constants,\n                                      **kwargs)\n        else:\n            def step(inputs, states):\n                return self.cell.call(inputs, states, **kwargs)\n\n        last_output, outputs, states = K.rnn(step,\n                                             inputs,\n                                             initial_state,\n                                             constants=constants,\n                                             go_backwards=self.go_backwards,\n                                             mask=mask,\n                                             unroll=self.unroll,\n                                             input_length=timesteps)\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        if self.return_sequences:\n            output = outputs\n        else:\n            output = last_output\n\n        # Properly set learning phase\n        if getattr(last_output, '_uses_learning_phase', False):\n            output._uses_learning_phase = True\n            for state in states:\n                state._uses_learning_phase = True\n\n        if self.return_state:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            else:\n                states = list(states)\n            return [output] + states\n        else:\n            return output",
        "begin_line": 543,
        "end_line": 633,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.step#592",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.step(inputs, states)",
        "snippet": "            def step(inputs, states):\n                constants = states[-self._num_constants:]\n                states = states[:-self._num_constants]\n                return self.cell.call(inputs, states, constants=constants,\n                                      **kwargs)",
        "begin_line": 592,
        "end_line": 596,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.step#598",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.step(inputs, states)",
        "snippet": "            def step(inputs, states):\n                return self.cell.call(inputs, states, **kwargs)",
        "begin_line": 598,
        "end_line": 599,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN._standardize_args#635",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN._standardize_args(self, inputs, initial_state, constants)",
        "snippet": "    def _standardize_args(self, inputs, initial_state, constants):\n        \"\"\"Standardize `__call__` to a single list of tensor inputs.\n\n        When running a model loaded from file, the input tensors\n        `initial_state` and `constants` can be passed to `RNN.__call__` as part\n        of `inputs` instead of by the dedicated keyword arguments. This method\n        makes sure the arguments are separated and that `initial_state` and\n        `constants` are lists of tensors (or None).\n\n        # Arguments\n            inputs: tensor or list/tuple of tensors\n            initial_state: tensor or list of tensors or None\n            constants: tensor or list of tensors or None\n\n        # Returns\n            inputs: tensor\n            initial_state: list of tensors or None\n            constants: list of tensors or None\n        \"\"\"\n        if isinstance(inputs, list):\n            assert initial_state is None and constants is None\n            if self._num_constants is not None:\n                constants = inputs[-self._num_constants:]\n                inputs = inputs[:-self._num_constants]\n            if len(inputs) > 1:\n                initial_state = inputs[1:]\n            inputs = inputs[0]\n\n        def to_list_or_none(x):\n            if x is None or isinstance(x, list):\n                return x\n            if isinstance(x, tuple):\n                return list(x)\n            return [x]\n\n        initial_state = to_list_or_none(initial_state)\n        constants = to_list_or_none(constants)\n\n        return inputs, initial_state, constants",
        "begin_line": 635,
        "end_line": 673,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.to_list_or_none#663",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.to_list_or_none(x)",
        "snippet": "        def to_list_or_none(x):\n            if x is None or isinstance(x, list):\n                return x\n            if isinstance(x, tuple):\n                return list(x)\n            return [x]",
        "begin_line": 663,
        "end_line": 668,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.reset_states#675",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.reset_states(self, states=None)",
        "snippet": "    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError('Layer must be stateful.')\n        batch_size = self.input_spec[0].shape[0]\n        if not batch_size:\n            raise ValueError('If a RNN is stateful, it needs to know '\n                             'its batch size. Specify the batch size '\n                             'of your input tensors: \\n'\n                             '- If using a Sequential model, '\n                             'specify the batch size by passing '\n                             'a `batch_input_shape` '\n                             'argument to your first layer.\\n'\n                             '- If using the functional API, specify '\n                             'the batch size by passing a '\n                             '`batch_shape` argument to your Input layer.')\n        # initialize state if None\n        if self.states[0] is None:\n            if hasattr(self.cell.state_size, '__len__'):\n                self.states = [K.zeros((batch_size, dim))\n                               for dim in self.cell.state_size]\n            else:\n                self.states = [K.zeros((batch_size, self.cell.state_size))]\n        elif states is None:\n            if hasattr(self.cell.state_size, '__len__'):\n                for state, dim in zip(self.states, self.cell.state_size):\n                    K.set_value(state, np.zeros((batch_size, dim)))\n            else:\n                K.set_value(self.states[0],\n                            np.zeros((batch_size, self.cell.state_size)))\n        else:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            if len(states) != len(self.states):\n                raise ValueError('Layer ' + self.name + ' expects ' +\n                                 str(len(self.states)) + ' states, '\n                                 'but it received ' + str(len(states)) +\n                                 ' state values. Input received: ' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if hasattr(self.cell.state_size, '__len__'):\n                    dim = self.cell.state_size[index]\n                else:\n                    dim = self.cell.state_size\n                if value.shape != (batch_size, dim):\n                    raise ValueError('State ' + str(index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected shape=' +\n                                     str((batch_size, dim)) +\n                                     ', found shape=' + str(value.shape))\n                # TODO: consider batch calls to `set_value`.\n                K.set_value(state, value)",
        "begin_line": 675,
        "end_line": 725,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.get_config#727",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'return_sequences': self.return_sequences,\n                  'return_state': self.return_state,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful,\n                  'unroll': self.unroll}\n        if self._num_constants is not None:\n            config['num_constants'] = self._num_constants\n\n        cell_config = self.cell.get_config()\n        config['cell'] = {'class_name': self.cell.__class__.__name__,\n                          'config': cell_config}\n        base_config = super(RNN, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 727,
        "end_line": 740,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.from_config#743",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        cell = deserialize_layer(config.pop('cell'),\n                                 custom_objects=custom_objects)\n        num_constants = config.pop('num_constants', None)\n        layer = cls(cell, **config)\n        layer._num_constants = num_constants\n        return layer",
        "begin_line": 743,
        "end_line": 750,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.trainable_weights#753",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        if isinstance(self.cell, Layer):\n            return self.cell.trainable_weights\n        return []",
        "begin_line": 753,
        "end_line": 758,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.non_trainable_weights#761",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        if isinstance(self.cell, Layer):\n            if not self.trainable:\n                return self.cell.weights\n            return self.cell.non_trainable_weights\n        return []",
        "begin_line": 761,
        "end_line": 766,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.losses#769",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.losses(self)",
        "snippet": "    def losses(self):\n        layer_losses = super(RNN, self).losses\n        if isinstance(self.cell, Layer):\n            return self.cell.losses + layer_losses\n        return layer_losses",
        "begin_line": 769,
        "end_line": 773,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.get_losses_for#775",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.get_losses_for(self, inputs=None)",
        "snippet": "    def get_losses_for(self, inputs=None):\n        if isinstance(self.cell, Layer):\n            cell_losses = self.cell.get_losses_for(inputs)\n            return cell_losses + super(RNN, self).get_losses_for(inputs)\n        return super(RNN, self).get_losses_for(inputs)",
        "begin_line": 775,
        "end_line": 779,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell.__init__#826",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell.__init__(self, units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 **kwargs):\n        super(SimpleRNNCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.state_size = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None",
        "begin_line": 826,
        "end_line": 862,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell.build#864",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                      name='kernel',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.units,),\n                                        name='bias',\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.built = True",
        "begin_line": 864,
        "end_line": 884,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell.call#886",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell.call(self, inputs, states, training=None)",
        "snippet": "    def call(self, inputs, states, training=None):\n        prev_output = states[0]\n        if 0 < self.dropout < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),\n                self.dropout,\n                training=training)\n        if (0 < self.recurrent_dropout < 1 and\n                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask = _generate_dropout_mask(\n                _generate_dropout_ones(inputs, self.units),\n                self.recurrent_dropout,\n                training=training)\n\n        dp_mask = self._dropout_mask\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        if dp_mask is not None:\n            h = K.dot(inputs * dp_mask, self.kernel)\n        else:\n            h = K.dot(inputs, self.kernel)\n        if self.bias is not None:\n            h = K.bias_add(h, self.bias)\n\n        if rec_dp_mask is not None:\n            prev_output *= rec_dp_mask\n        output = h + K.dot(prev_output, self.recurrent_kernel)\n        if self.activation is not None:\n            output = self.activation(output)\n\n        # Properly set learning phase on output tensor.\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                output._uses_learning_phase = True\n        return output, [output]",
        "begin_line": 886,
        "end_line": 920,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell.get_config#922",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout}\n        base_config = super(SimpleRNNCell, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 922,
        "end_line": 938,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.__init__#1005",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.__init__(self, units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if 'implementation' in kwargs:\n            kwargs.pop('implementation')\n            warnings.warn('The `implementation` argument '\n                          'in `SimpleRNN` has been deprecated. '\n                          'Please remove it from your layer call.')\n        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n            warnings.warn(\n                'RNN dropout is no longer supported with the Theano backend '\n                'due to technical limitations. '\n                'You can either set `dropout` and `recurrent_dropout` to 0, '\n                'or use the TensorFlow backend.')\n            dropout = 0.\n            recurrent_dropout = 0.\n\n        cell = SimpleRNNCell(units,\n                             activation=activation,\n                             use_bias=use_bias,\n                             kernel_initializer=kernel_initializer,\n                             recurrent_initializer=recurrent_initializer,\n                             bias_initializer=bias_initializer,\n                             kernel_regularizer=kernel_regularizer,\n                             recurrent_regularizer=recurrent_regularizer,\n                             bias_regularizer=bias_regularizer,\n                             kernel_constraint=kernel_constraint,\n                             recurrent_constraint=recurrent_constraint,\n                             bias_constraint=bias_constraint,\n                             dropout=dropout,\n                             recurrent_dropout=recurrent_dropout)\n        super(SimpleRNN, self).__init__(cell,\n                                        return_sequences=return_sequences,\n                                        return_state=return_state,\n                                        go_backwards=go_backwards,\n                                        stateful=stateful,\n                                        unroll=unroll,\n                                        **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)",
        "begin_line": 1005,
        "end_line": 1061,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.call#1063",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._dropout_mask = None\n        self.cell._recurrent_dropout_mask = None\n        return super(SimpleRNN, self).call(inputs,\n                                           mask=mask,\n                                           training=training,\n                                           initial_state=initial_state)",
        "begin_line": 1063,
        "end_line": 1069,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.931472081218273e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.units#1072",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.units(self)",
        "snippet": "    def units(self):\n        return self.cell.units",
        "begin_line": 1072,
        "end_line": 1073,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.activation#1076",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.activation(self)",
        "snippet": "    def activation(self):\n        return self.cell.activation",
        "begin_line": 1076,
        "end_line": 1077,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.use_bias#1080",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.use_bias(self)",
        "snippet": "    def use_bias(self):\n        return self.cell.use_bias",
        "begin_line": 1080,
        "end_line": 1081,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.kernel_initializer#1084",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.kernel_initializer(self)",
        "snippet": "    def kernel_initializer(self):\n        return self.cell.kernel_initializer",
        "begin_line": 1084,
        "end_line": 1085,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.recurrent_initializer#1088",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.recurrent_initializer(self)",
        "snippet": "    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer",
        "begin_line": 1088,
        "end_line": 1089,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.bias_initializer#1092",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.bias_initializer(self)",
        "snippet": "    def bias_initializer(self):\n        return self.cell.bias_initializer",
        "begin_line": 1092,
        "end_line": 1093,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.kernel_regularizer#1096",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.kernel_regularizer(self)",
        "snippet": "    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer",
        "begin_line": 1096,
        "end_line": 1097,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.recurrent_regularizer#1100",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.recurrent_regularizer(self)",
        "snippet": "    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer",
        "begin_line": 1100,
        "end_line": 1101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.bias_regularizer#1104",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.bias_regularizer(self)",
        "snippet": "    def bias_regularizer(self):\n        return self.cell.bias_regularizer",
        "begin_line": 1104,
        "end_line": 1105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.kernel_constraint#1108",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.kernel_constraint(self)",
        "snippet": "    def kernel_constraint(self):\n        return self.cell.kernel_constraint",
        "begin_line": 1108,
        "end_line": 1109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.recurrent_constraint#1112",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.recurrent_constraint(self)",
        "snippet": "    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint",
        "begin_line": 1112,
        "end_line": 1113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.bias_constraint#1116",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.bias_constraint(self)",
        "snippet": "    def bias_constraint(self):\n        return self.cell.bias_constraint",
        "begin_line": 1116,
        "end_line": 1117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.dropout#1120",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.dropout(self)",
        "snippet": "    def dropout(self):\n        return self.cell.dropout",
        "begin_line": 1120,
        "end_line": 1121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.recurrent_dropout#1124",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.recurrent_dropout(self)",
        "snippet": "    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout",
        "begin_line": 1124,
        "end_line": 1125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.get_config#1127",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout}\n        base_config = super(SimpleRNN, self).get_config()\n        del base_config['cell']\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1127,
        "end_line": 1145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.from_config#1148",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        if 'implementation' in config:\n            config.pop('implementation')\n        return cls(**config)",
        "begin_line": 1148,
        "end_line": 1151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.__init__#1213",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, reset_after=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 reset_after=False,\n                 **kwargs):\n        super(GRUCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.implementation = implementation\n        self.reset_after = reset_after\n        self.state_size = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None",
        "begin_line": 1213,
        "end_line": 1255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.build#1257",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[-1]\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 3),\n                                      name='kernel',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 3),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        if self.use_bias:\n            if not self.reset_after:\n                bias_shape = (3 * self.units,)\n            else:\n                # separate biases for input and recurrent kernels\n                # Note: the shape is intentionally different from CuDNNGRU biases\n                # `(2 * 3 * self.units,)`, so that we can distinguish the classes\n                # when loading and converting saved weights.\n                bias_shape = (2, 3 * self.units)\n            self.bias = self.add_weight(shape=bias_shape,\n                                        name='bias',\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n            if not self.reset_after:\n                self.input_bias, self.recurrent_bias = self.bias, None\n            else:\n                # NOTE: need to flatten, since slicing in CNTK gives 2D array\n                self.input_bias = K.flatten(self.bias[0])\n                self.recurrent_bias = K.flatten(self.bias[1])\n        else:\n            self.bias = None\n\n        # update gate\n        self.kernel_z = self.kernel[:, :self.units]\n        self.recurrent_kernel_z = self.recurrent_kernel[:, :self.units]\n        # reset gate\n        self.kernel_r = self.kernel[:, self.units: self.units * 2]\n        self.recurrent_kernel_r = self.recurrent_kernel[:,\n                                                        self.units:\n                                                        self.units * 2]\n        # new gate\n        self.kernel_h = self.kernel[:, self.units * 2:]\n        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2:]\n\n        if self.use_bias:\n            # bias for inputs\n            self.input_bias_z = self.input_bias[:self.units]\n            self.input_bias_r = self.input_bias[self.units: self.units * 2]\n            self.input_bias_h = self.input_bias[self.units * 2:]\n            # bias for hidden state - just for compatibility with CuDNN\n            if self.reset_after:\n                self.recurrent_bias_z = self.recurrent_bias[:self.units]\n                self.recurrent_bias_r = self.recurrent_bias[self.units: self.units * 2]\n                self.recurrent_bias_h = self.recurrent_bias[self.units * 2:]\n        else:\n            self.input_bias_z = None\n            self.input_bias_r = None\n            self.input_bias_h = None\n            if self.reset_after:\n                self.recurrent_bias_z = None\n                self.recurrent_bias_r = None\n                self.recurrent_bias_h = None\n        self.built = True",
        "begin_line": 1257,
        "end_line": 1324,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.call#1326",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.call(self, inputs, states, training=None)",
        "snippet": "    def call(self, inputs, states, training=None):\n        h_tm1 = states[0]  # previous memory\n\n        if 0 < self.dropout < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),\n                self.dropout,\n                training=training,\n                count=3)\n        if (0 < self.recurrent_dropout < 1 and\n                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask = _generate_dropout_mask(\n                _generate_dropout_ones(inputs, self.units),\n                self.recurrent_dropout,\n                training=training,\n                count=3)\n\n        # dropout matrices for input units\n        dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        if self.implementation == 1:\n            if 0. < self.dropout < 1.:\n                inputs_z = inputs * dp_mask[0]\n                inputs_r = inputs * dp_mask[1]\n                inputs_h = inputs * dp_mask[2]\n            else:\n                inputs_z = inputs\n                inputs_r = inputs\n                inputs_h = inputs\n\n            x_z = K.dot(inputs_z, self.kernel_z)\n            x_r = K.dot(inputs_r, self.kernel_r)\n            x_h = K.dot(inputs_h, self.kernel_h)\n            if self.use_bias:\n                x_z = K.bias_add(x_z, self.input_bias_z)\n                x_r = K.bias_add(x_r, self.input_bias_r)\n                x_h = K.bias_add(x_h, self.input_bias_h)\n\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1_z = h_tm1 * rec_dp_mask[0]\n                h_tm1_r = h_tm1 * rec_dp_mask[1]\n                h_tm1_h = h_tm1 * rec_dp_mask[2]\n            else:\n                h_tm1_z = h_tm1\n                h_tm1_r = h_tm1\n                h_tm1_h = h_tm1\n\n            recurrent_z = K.dot(h_tm1_z, self.recurrent_kernel_z)\n            recurrent_r = K.dot(h_tm1_r, self.recurrent_kernel_r)\n            if self.reset_after and self.use_bias:\n                recurrent_z = K.bias_add(recurrent_z, self.recurrent_bias_z)\n                recurrent_r = K.bias_add(recurrent_r, self.recurrent_bias_r)\n\n            z = self.recurrent_activation(x_z + recurrent_z)\n            r = self.recurrent_activation(x_r + recurrent_r)\n\n            # reset gate applied after/before matrix multiplication\n            if self.reset_after:\n                recurrent_h = K.dot(h_tm1_h, self.recurrent_kernel_h)\n                if self.use_bias:\n                    recurrent_h = K.bias_add(recurrent_h, self.recurrent_bias_h)\n                recurrent_h = r * recurrent_h\n            else:\n                recurrent_h = K.dot(r * h_tm1_h, self.recurrent_kernel_h)\n\n            hh = self.activation(x_h + recurrent_h)\n        else:\n            if 0. < self.dropout < 1.:\n                inputs *= dp_mask[0]\n\n            # inputs projected by all gate matrices at once\n            matrix_x = K.dot(inputs, self.kernel)\n            if self.use_bias:\n                # biases: bias_z_i, bias_r_i, bias_h_i\n                matrix_x = K.bias_add(matrix_x, self.input_bias)\n            x_z = matrix_x[:, :self.units]\n            x_r = matrix_x[:, self.units: 2 * self.units]\n            x_h = matrix_x[:, 2 * self.units:]\n\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1 *= rec_dp_mask[0]\n\n            if self.reset_after:\n                # hidden state projected by all gate matrices at once\n                matrix_inner = K.dot(h_tm1, self.recurrent_kernel)\n                if self.use_bias:\n                    matrix_inner = K.bias_add(matrix_inner, self.recurrent_bias)\n            else:\n                # hidden state projected separately for update/reset and new\n                matrix_inner = K.dot(h_tm1,\n                                     self.recurrent_kernel[:, :2 * self.units])\n\n            recurrent_z = matrix_inner[:, :self.units]\n            recurrent_r = matrix_inner[:, self.units: 2 * self.units]\n\n            z = self.recurrent_activation(x_z + recurrent_z)\n            r = self.recurrent_activation(x_r + recurrent_r)\n\n            if self.reset_after:\n                recurrent_h = r * matrix_inner[:, 2 * self.units:]\n            else:\n                recurrent_h = K.dot(r * h_tm1,\n                                    self.recurrent_kernel[:, 2 * self.units:])\n\n            hh = self.activation(x_h + recurrent_h)\n\n        # previous and candidate state mixed by update gate\n        h = z * h_tm1 + (1 - z) * hh\n\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase = True\n\n        return h, [h]",
        "begin_line": 1326,
        "end_line": 1441,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.get_config#1443",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation': activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout,\n                  'implementation': self.implementation,\n                  'reset_after': self.reset_after}\n        base_config = super(GRUCell, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1443,
        "end_line": 1462,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.__init__#1559",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, reset_after=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 reset_after=False,\n                 **kwargs):\n        if implementation == 0:\n            warnings.warn('`implementation=0` has been deprecated, '\n                          'and now defaults to `implementation=1`.'\n                          'Please update your layer call.')\n        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n            warnings.warn(\n                'RNN dropout is no longer supported with the Theano backend '\n                'due to technical limitations. '\n                'You can either set `dropout` and `recurrent_dropout` to 0, '\n                'or use the TensorFlow backend.')\n            dropout = 0.\n            recurrent_dropout = 0.\n\n        cell = GRUCell(units,\n                       activation=activation,\n                       recurrent_activation=recurrent_activation,\n                       use_bias=use_bias,\n                       kernel_initializer=kernel_initializer,\n                       recurrent_initializer=recurrent_initializer,\n                       bias_initializer=bias_initializer,\n                       kernel_regularizer=kernel_regularizer,\n                       recurrent_regularizer=recurrent_regularizer,\n                       bias_regularizer=bias_regularizer,\n                       kernel_constraint=kernel_constraint,\n                       recurrent_constraint=recurrent_constraint,\n                       bias_constraint=bias_constraint,\n                       dropout=dropout,\n                       recurrent_dropout=recurrent_dropout,\n                       implementation=implementation,\n                       reset_after=reset_after)\n        super(GRU, self).__init__(cell,\n                                  return_sequences=return_sequences,\n                                  return_state=return_state,\n                                  go_backwards=go_backwards,\n                                  stateful=stateful,\n                                  unroll=unroll,\n                                  **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)",
        "begin_line": 1559,
        "end_line": 1620,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.call#1622",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._dropout_mask = None\n        self.cell._recurrent_dropout_mask = None\n        return super(GRU, self).call(inputs,\n                                     mask=mask,\n                                     training=training,\n                                     initial_state=initial_state)",
        "begin_line": 1622,
        "end_line": 1628,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.931472081218273e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.units#1631",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.units(self)",
        "snippet": "    def units(self):\n        return self.cell.units",
        "begin_line": 1631,
        "end_line": 1632,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.activation#1635",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.activation(self)",
        "snippet": "    def activation(self):\n        return self.cell.activation",
        "begin_line": 1635,
        "end_line": 1636,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.recurrent_activation#1639",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.recurrent_activation(self)",
        "snippet": "    def recurrent_activation(self):\n        return self.cell.recurrent_activation",
        "begin_line": 1639,
        "end_line": 1640,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.use_bias#1643",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.use_bias(self)",
        "snippet": "    def use_bias(self):\n        return self.cell.use_bias",
        "begin_line": 1643,
        "end_line": 1644,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.kernel_initializer#1647",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.kernel_initializer(self)",
        "snippet": "    def kernel_initializer(self):\n        return self.cell.kernel_initializer",
        "begin_line": 1647,
        "end_line": 1648,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.recurrent_initializer#1651",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.recurrent_initializer(self)",
        "snippet": "    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer",
        "begin_line": 1651,
        "end_line": 1652,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.bias_initializer#1655",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.bias_initializer(self)",
        "snippet": "    def bias_initializer(self):\n        return self.cell.bias_initializer",
        "begin_line": 1655,
        "end_line": 1656,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.kernel_regularizer#1659",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.kernel_regularizer(self)",
        "snippet": "    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer",
        "begin_line": 1659,
        "end_line": 1660,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.recurrent_regularizer#1663",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.recurrent_regularizer(self)",
        "snippet": "    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer",
        "begin_line": 1663,
        "end_line": 1664,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.bias_regularizer#1667",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.bias_regularizer(self)",
        "snippet": "    def bias_regularizer(self):\n        return self.cell.bias_regularizer",
        "begin_line": 1667,
        "end_line": 1668,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.kernel_constraint#1671",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.kernel_constraint(self)",
        "snippet": "    def kernel_constraint(self):\n        return self.cell.kernel_constraint",
        "begin_line": 1671,
        "end_line": 1672,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.recurrent_constraint#1675",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.recurrent_constraint(self)",
        "snippet": "    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint",
        "begin_line": 1675,
        "end_line": 1676,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.bias_constraint#1679",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.bias_constraint(self)",
        "snippet": "    def bias_constraint(self):\n        return self.cell.bias_constraint",
        "begin_line": 1679,
        "end_line": 1680,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.dropout#1683",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.dropout(self)",
        "snippet": "    def dropout(self):\n        return self.cell.dropout",
        "begin_line": 1683,
        "end_line": 1684,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.recurrent_dropout#1687",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.recurrent_dropout(self)",
        "snippet": "    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout",
        "begin_line": 1687,
        "end_line": 1688,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.implementation#1691",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.implementation(self)",
        "snippet": "    def implementation(self):\n        return self.cell.implementation",
        "begin_line": 1691,
        "end_line": 1692,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.reset_after#1695",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.reset_after(self)",
        "snippet": "    def reset_after(self):\n        return self.cell.reset_after",
        "begin_line": 1695,
        "end_line": 1696,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.get_config#1698",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation': activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout,\n                  'implementation': self.implementation,\n                  'reset_after': self.reset_after}\n        base_config = super(GRU, self).get_config()\n        del base_config['cell']\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1698,
        "end_line": 1719,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.from_config#1722",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        if 'implementation' in config and config['implementation'] == 0:\n            config['implementation'] = 1\n        return cls(**config)",
        "begin_line": 1722,
        "end_line": 1725,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.__init__#1788",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 **kwargs):\n        super(LSTMCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.implementation = implementation\n        self.state_size = (self.units, self.units)\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None",
        "begin_line": 1788,
        "end_line": 1830,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.build#1832",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[-1]\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n                                      name='kernel',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 4),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        if self.use_bias:\n            if self.unit_forget_bias:\n                def bias_initializer(_, *args, **kwargs):\n                    return K.concatenate([\n                        self.bias_initializer((self.units,), *args, **kwargs),\n                        initializers.Ones()((self.units,), *args, **kwargs),\n                        self.bias_initializer((self.units * 2,), *args, **kwargs),\n                    ])\n            else:\n                bias_initializer = self.bias_initializer\n            self.bias = self.add_weight(shape=(self.units * 4,),\n                                        name='bias',\n                                        initializer=bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n\n        self.kernel_i = self.kernel[:, :self.units]\n        self.kernel_f = self.kernel[:, self.units: self.units * 2]\n        self.kernel_c = self.kernel[:, self.units * 2: self.units * 3]\n        self.kernel_o = self.kernel[:, self.units * 3:]\n\n        self.recurrent_kernel_i = self.recurrent_kernel[:, :self.units]\n        self.recurrent_kernel_f = self.recurrent_kernel[:, self.units: self.units * 2]\n        self.recurrent_kernel_c = self.recurrent_kernel[:, self.units * 2: self.units * 3]\n        self.recurrent_kernel_o = self.recurrent_kernel[:, self.units * 3:]\n\n        if self.use_bias:\n            self.bias_i = self.bias[:self.units]\n            self.bias_f = self.bias[self.units: self.units * 2]\n            self.bias_c = self.bias[self.units * 2: self.units * 3]\n            self.bias_o = self.bias[self.units * 3:]\n        else:\n            self.bias_i = None\n            self.bias_f = None\n            self.bias_c = None\n            self.bias_o = None\n        self.built = True",
        "begin_line": 1832,
        "end_line": 1884,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.bias_initializer#1848",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.bias_initializer(_, *args, **kwargs)",
        "snippet": "                def bias_initializer(_, *args, **kwargs):\n                    return K.concatenate([\n                        self.bias_initializer((self.units,), *args, **kwargs),\n                        initializers.Ones()((self.units,), *args, **kwargs),\n                        self.bias_initializer((self.units * 2,), *args, **kwargs),\n                    ])",
        "begin_line": 1848,
        "end_line": 1853,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.551159102922299e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.call#1886",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.call(self, inputs, states, training=None)",
        "snippet": "    def call(self, inputs, states, training=None):\n        if 0 < self.dropout < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),\n                self.dropout,\n                training=training,\n                count=4)\n        if (0 < self.recurrent_dropout < 1 and\n                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask = _generate_dropout_mask(\n                _generate_dropout_ones(inputs, self.units),\n                self.recurrent_dropout,\n                training=training,\n                count=4)\n\n        # dropout matrices for input units\n        dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        h_tm1 = states[0]  # previous memory state\n        c_tm1 = states[1]  # previous carry state\n\n        if self.implementation == 1:\n            if 0 < self.dropout < 1.:\n                inputs_i = inputs * dp_mask[0]\n                inputs_f = inputs * dp_mask[1]\n                inputs_c = inputs * dp_mask[2]\n                inputs_o = inputs * dp_mask[3]\n            else:\n                inputs_i = inputs\n                inputs_f = inputs\n                inputs_c = inputs\n                inputs_o = inputs\n            x_i = K.dot(inputs_i, self.kernel_i)\n            x_f = K.dot(inputs_f, self.kernel_f)\n            x_c = K.dot(inputs_c, self.kernel_c)\n            x_o = K.dot(inputs_o, self.kernel_o)\n            if self.use_bias:\n                x_i = K.bias_add(x_i, self.bias_i)\n                x_f = K.bias_add(x_f, self.bias_f)\n                x_c = K.bias_add(x_c, self.bias_c)\n                x_o = K.bias_add(x_o, self.bias_o)\n\n            if 0 < self.recurrent_dropout < 1.:\n                h_tm1_i = h_tm1 * rec_dp_mask[0]\n                h_tm1_f = h_tm1 * rec_dp_mask[1]\n                h_tm1_c = h_tm1 * rec_dp_mask[2]\n                h_tm1_o = h_tm1 * rec_dp_mask[3]\n            else:\n                h_tm1_i = h_tm1\n                h_tm1_f = h_tm1\n                h_tm1_c = h_tm1\n                h_tm1_o = h_tm1\n            i = self.recurrent_activation(x_i + K.dot(h_tm1_i,\n                                                      self.recurrent_kernel_i))\n            f = self.recurrent_activation(x_f + K.dot(h_tm1_f,\n                                                      self.recurrent_kernel_f))\n            c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c,\n                                                            self.recurrent_kernel_c))\n            o = self.recurrent_activation(x_o + K.dot(h_tm1_o,\n                                                      self.recurrent_kernel_o))\n        else:\n            if 0. < self.dropout < 1.:\n                inputs *= dp_mask[0]\n            z = K.dot(inputs, self.kernel)\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1 *= rec_dp_mask[0]\n            z += K.dot(h_tm1, self.recurrent_kernel)\n            if self.use_bias:\n                z = K.bias_add(z, self.bias)\n\n            z0 = z[:, :self.units]\n            z1 = z[:, self.units: 2 * self.units]\n            z2 = z[:, 2 * self.units: 3 * self.units]\n            z3 = z[:, 3 * self.units:]\n\n            i = self.recurrent_activation(z0)\n            f = self.recurrent_activation(z1)\n            c = f * c_tm1 + i * self.activation(z2)\n            o = self.recurrent_activation(z3)\n\n        h = o * self.activation(c)\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase = True\n        return h, [h, c]",
        "begin_line": 1886,
        "end_line": 1972,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.get_config#1974",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation': activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'unit_forget_bias': self.unit_forget_bias,\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout,\n                  'implementation': self.implementation}\n        base_config = super(LSTMCell, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1974,
        "end_line": 1993,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.010894816951053e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.__init__#2082",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if implementation == 0:\n            warnings.warn('`implementation=0` has been deprecated, '\n                          'and now defaults to `implementation=1`.'\n                          'Please update your layer call.')\n        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n            warnings.warn(\n                'RNN dropout is no longer supported with the Theano backend '\n                'due to technical limitations. '\n                'You can either set `dropout` and `recurrent_dropout` to 0, '\n                'or use the TensorFlow backend.')\n            dropout = 0.\n            recurrent_dropout = 0.\n\n        cell = LSTMCell(units,\n                        activation=activation,\n                        recurrent_activation=recurrent_activation,\n                        use_bias=use_bias,\n                        kernel_initializer=kernel_initializer,\n                        recurrent_initializer=recurrent_initializer,\n                        unit_forget_bias=unit_forget_bias,\n                        bias_initializer=bias_initializer,\n                        kernel_regularizer=kernel_regularizer,\n                        recurrent_regularizer=recurrent_regularizer,\n                        bias_regularizer=bias_regularizer,\n                        kernel_constraint=kernel_constraint,\n                        recurrent_constraint=recurrent_constraint,\n                        bias_constraint=bias_constraint,\n                        dropout=dropout,\n                        recurrent_dropout=recurrent_dropout,\n                        implementation=implementation)\n        super(LSTM, self).__init__(cell,\n                                   return_sequences=return_sequences,\n                                   return_state=return_state,\n                                   go_backwards=go_backwards,\n                                   stateful=stateful,\n                                   unroll=unroll,\n                                   **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)",
        "begin_line": 2082,
        "end_line": 2143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.call#2145",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._dropout_mask = None\n        self.cell._recurrent_dropout_mask = None\n        return super(LSTM, self).call(inputs,\n                                      mask=mask,\n                                      training=training,\n                                      initial_state=initial_state)",
        "begin_line": 2145,
        "end_line": 2151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.616146230007616e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.units#2154",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.units(self)",
        "snippet": "    def units(self):\n        return self.cell.units",
        "begin_line": 2154,
        "end_line": 2155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.activation#2158",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.activation(self)",
        "snippet": "    def activation(self):\n        return self.cell.activation",
        "begin_line": 2158,
        "end_line": 2159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_activation#2162",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_activation(self)",
        "snippet": "    def recurrent_activation(self):\n        return self.cell.recurrent_activation",
        "begin_line": 2162,
        "end_line": 2163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.use_bias#2166",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.use_bias(self)",
        "snippet": "    def use_bias(self):\n        return self.cell.use_bias",
        "begin_line": 2166,
        "end_line": 2167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.kernel_initializer#2170",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.kernel_initializer(self)",
        "snippet": "    def kernel_initializer(self):\n        return self.cell.kernel_initializer",
        "begin_line": 2170,
        "end_line": 2171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_initializer#2174",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_initializer(self)",
        "snippet": "    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer",
        "begin_line": 2174,
        "end_line": 2175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.bias_initializer#2178",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.bias_initializer(self)",
        "snippet": "    def bias_initializer(self):\n        return self.cell.bias_initializer",
        "begin_line": 2178,
        "end_line": 2179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.unit_forget_bias#2182",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.unit_forget_bias(self)",
        "snippet": "    def unit_forget_bias(self):\n        return self.cell.unit_forget_bias",
        "begin_line": 2182,
        "end_line": 2183,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.kernel_regularizer#2186",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.kernel_regularizer(self)",
        "snippet": "    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer",
        "begin_line": 2186,
        "end_line": 2187,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_regularizer#2190",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_regularizer(self)",
        "snippet": "    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer",
        "begin_line": 2190,
        "end_line": 2191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.bias_regularizer#2194",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.bias_regularizer(self)",
        "snippet": "    def bias_regularizer(self):\n        return self.cell.bias_regularizer",
        "begin_line": 2194,
        "end_line": 2195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.kernel_constraint#2198",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.kernel_constraint(self)",
        "snippet": "    def kernel_constraint(self):\n        return self.cell.kernel_constraint",
        "begin_line": 2198,
        "end_line": 2199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_constraint#2202",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_constraint(self)",
        "snippet": "    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint",
        "begin_line": 2202,
        "end_line": 2203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.bias_constraint#2206",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.bias_constraint(self)",
        "snippet": "    def bias_constraint(self):\n        return self.cell.bias_constraint",
        "begin_line": 2206,
        "end_line": 2207,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.dropout#2210",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.dropout(self)",
        "snippet": "    def dropout(self):\n        return self.cell.dropout",
        "begin_line": 2210,
        "end_line": 2211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_dropout#2214",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_dropout(self)",
        "snippet": "    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout",
        "begin_line": 2214,
        "end_line": 2215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.implementation#2218",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.implementation(self)",
        "snippet": "    def implementation(self):\n        return self.cell.implementation",
        "begin_line": 2218,
        "end_line": 2219,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.get_config#2221",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation': activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'unit_forget_bias': self.unit_forget_bias,\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout,\n                  'implementation': self.implementation}\n        base_config = super(LSTM, self).get_config()\n        del base_config['cell']\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 2221,
        "end_line": 2242,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.051529790660226e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.from_config#2245",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        if 'implementation' in config and config['implementation'] == 0:\n            config['implementation'] = 1\n        return cls(**config)",
        "begin_line": 2245,
        "end_line": 2248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.079502302658157e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent._generate_dropout_ones#2251",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent",
        "signature": "keras.layers.recurrent._generate_dropout_ones(inputs, dims)",
        "snippet": "def _generate_dropout_ones(inputs, dims):\n    # Currently, CNTK can't instantiate `ones` with symbolic shapes.\n    # Will update workaround once CNTK supports it.\n    if K.backend() == 'cntk':\n        ones = K.ones_like(K.reshape(inputs[:, 0], (-1, 1)))\n        return K.tile(ones, (1, dims))\n    else:\n        return K.ones((K.shape(inputs)[0], dims))",
        "begin_line": 2251,
        "end_line": 2258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.171937566396992e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent._generate_dropout_mask#2261",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent",
        "signature": "keras.layers.recurrent._generate_dropout_mask(ones, rate, training=None, count=1)",
        "snippet": "def _generate_dropout_mask(ones, rate, training=None, count=1):\n    def dropped_inputs():\n        return K.dropout(ones, rate)\n\n    if count > 1:\n        return [K.in_train_phase(\n            dropped_inputs,\n            ones,\n            training=training) for _ in range(count)]\n    return K.in_train_phase(\n        dropped_inputs,\n        ones,\n        training=training)",
        "begin_line": 2261,
        "end_line": 2273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.recurrent.dropped_inputs#2262",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent",
        "signature": "keras.layers.recurrent.dropped_inputs()",
        "snippet": "    def dropped_inputs():\n        return K.dropout(ones, rate)",
        "begin_line": 2262,
        "end_line": 2263,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.120178643930166e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge._Merge.__init__#20",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        super(_Merge, self).__init__(**kwargs)\n        self.supports_masking = True",
        "begin_line": 20,
        "end_line": 22,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006596306068601583,
            "pseudo_dstar_susp": 0.0004909180166912126,
            "pseudo_tarantula_susp": 0.0011185682326621924,
            "pseudo_op2_susp": 0.0004909180166912126,
            "pseudo_barinel_susp": 0.0011185682326621924
        }
    },
    {
        "name": "keras.layers.merge._Merge._merge_function#24",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        raise NotImplementedError",
        "begin_line": 24,
        "end_line": 25,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge._Merge._compute_elemwise_op_output_shape#27",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge._compute_elemwise_op_output_shape(self, shape1, shape2)",
        "snippet": "    def _compute_elemwise_op_output_shape(self, shape1, shape2):\n        \"\"\"Computes the shape of the resultant of an elementwise operation.\n\n        # Arguments\n            shape1: tuple or None. Shape of the first tensor\n            shape2: tuple or None. Shape of the second tensor\n\n        # Returns\n            expected output shape when an element-wise operation is\n            carried out on 2 tensors with shapes shape1 and shape2.\n            tuple or None.\n\n        # Raises\n            ValueError: if shape1 and shape2 are not compatible for\n                element-wise operations.\n        \"\"\"\n        if None in [shape1, shape2]:\n            return None\n        elif len(shape1) < len(shape2):\n            return self._compute_elemwise_op_output_shape(shape2, shape1)\n        elif not shape2:\n            return shape1\n        output_shape = list(shape1[:-len(shape2)])\n        for i, j in zip(shape1[-len(shape2):], shape2):\n            if i is None or j is None:\n                output_shape.append(None)\n            elif i == 1:\n                output_shape.append(j)\n            elif j == 1:\n                output_shape.append(i)\n            else:\n                if i != j:\n                    raise ValueError('Operands could not be broadcast '\n                                     'together with shapes ' +\n                                     str(shape1) + ' ' + str(shape2))\n                output_shape.append(i)\n        return tuple(output_shape)",
        "begin_line": 27,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge._Merge.build#65",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        # Used purely for shape validation.\n        if not isinstance(input_shape, list):\n            raise ValueError('A merge layer should be called '\n                             'on a list of inputs.')\n        if len(input_shape) < 2:\n            raise ValueError('A merge layer should be called '\n                             'on a list of at least 2 inputs. '\n                             'Got ' + str(len(input_shape)) + ' inputs.')\n        batch_sizes = [s[0] for s in input_shape if s is not None]\n        batch_sizes = set(batch_sizes)\n        batch_sizes -= set([None])\n        if len(batch_sizes) > 1:\n            raise ValueError('Can not merge tensors with different '\n                             'batch sizes. Got tensors with shapes : ' +\n                             str(input_shape))\n        if input_shape[0] is None:\n            output_shape = None\n        else:\n            output_shape = input_shape[0][1:]\n        for i in range(1, len(input_shape)):\n            if input_shape[i] is None:\n                shape = None\n            else:\n                shape = input_shape[i][1:]\n            output_shape = self._compute_elemwise_op_output_shape(output_shape, shape)\n        # If the inputs have different ranks, we have to reshape them\n        # to make them broadcastable.\n        if None not in input_shape and len(set(map(len, input_shape))) == 1:\n            self._reshape_required = False\n        else:\n            self._reshape_required = True",
        "begin_line": 65,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge._Merge.call#98",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if not isinstance(inputs, list):\n            raise ValueError('A merge layer should be called '\n                             'on a list of inputs.')\n        if self._reshape_required:\n            reshaped_inputs = []\n            input_ndims = list(map(K.ndim, inputs))\n            if None not in input_ndims:\n                # If ranks of all inputs are available,\n                # we simply expand each of them at axis=1\n                # until all of them have the same rank.\n                max_ndim = max(input_ndims)\n                for x in inputs:\n                    x_ndim = K.ndim(x)\n                    for _ in range(max_ndim - x_ndim):\n                        x = K.expand_dims(x, 1)\n                    reshaped_inputs.append(x)\n                return self._merge_function(reshaped_inputs)\n            else:\n                # Transpose all inputs so that batch size is the last dimension.\n                # (batch_size, dim1, dim2, ... ) -> (dim1, dim2, ... , batch_size)\n                transposed = False\n                for x in inputs:\n                    x_ndim = K.ndim(x)\n                    if x_ndim is None:\n                        x_shape = K.shape(x)\n                        batch_size = x_shape[0]\n                        new_shape = K.concatenate([x_shape[1:], K.expand_dims(batch_size)])\n                        x_transposed = K.reshape(x, K.stack([batch_size, K.prod(x_shape[1:])]))\n                        x_transposed = K.permute_dimensions(x_transposed, (1, 0))\n                        x_transposed = K.reshape(x_transposed, new_shape)\n                        reshaped_inputs.append(x_transposed)\n                        transposed = True\n                    elif x_ndim > 1:\n                        dims = list(range(1, x_ndim)) + [0]\n                        reshaped_inputs.append(K.permute_dimensions(x, dims))\n                        transposed = True\n                    else:\n                        # We don't transpose inputs if they are 1D vectors or scalars.\n                        reshaped_inputs.append(x)\n                y = self._merge_function(reshaped_inputs)\n                y_ndim = K.ndim(y)\n                if transposed:\n                    # If inputs have been transposed, we have to transpose the output too.\n                    if y_ndim is None:\n                        y_shape = K.shape(y)\n                        y_ndim = K.shape(y_shape)[0]\n                        batch_size = y_shape[y_ndim - 1]\n                        new_shape = K.concatenate([K.expand_dims(batch_size), y_shape[:y_ndim - 1]])\n                        y = K.reshape(y, (-1, batch_size))\n                        y = K.permute_dimensions(y, (1, 0))\n                        y = K.reshape(y, new_shape)\n                    elif y_ndim > 1:\n                        dims = [y_ndim - 1] + list(range(y_ndim - 1))\n                        y = K.permute_dimensions(y, dims)\n                return y\n        else:\n            return self._merge_function(inputs)",
        "begin_line": 98,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00066711140760507,
            "pseudo_dstar_susp": 0.0004943153732081067,
            "pseudo_tarantula_susp": 0.0011363636363636363,
            "pseudo_op2_susp": 0.0004943153732081067,
            "pseudo_barinel_susp": 0.0011363636363636363
        }
    },
    {
        "name": "keras.layers.merge._Merge.compute_output_shape#157",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if input_shape[0] is None:\n            output_shape = None\n        else:\n            output_shape = input_shape[0][1:]\n        for i in range(1, len(input_shape)):\n            if input_shape[i] is None:\n                shape = None\n            else:\n                shape = input_shape[i][1:]\n            output_shape = self._compute_elemwise_op_output_shape(output_shape, shape)\n        batch_sizes = [s[0] for s in input_shape if s is not None]\n        batch_sizes = set(batch_sizes)\n        batch_sizes -= set([None])\n        if len(batch_sizes) == 1:\n            output_shape = (list(batch_sizes)[0],) + output_shape\n        else:\n            output_shape = (None,) + output_shape\n        return output_shape",
        "begin_line": 157,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge._Merge.compute_mask#177",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if mask is None:\n            return None\n        if not isinstance(mask, list):\n            raise ValueError('`mask` should be a list.')\n        if not isinstance(inputs, list):\n            raise ValueError('`inputs` should be a list.')\n        if len(mask) != len(inputs):\n            raise ValueError('The lists `inputs` and `mask` '\n                             'should have the same length.')\n        if all([m is None for m in mask]):\n            return None\n        masks = [K.expand_dims(m, 0) for m in mask if m is not None]\n        return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)",
        "begin_line": 177,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Add._merge_function#216",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Add",
        "signature": "keras.layers.merge.Add._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output += inputs[i]\n        return output",
        "begin_line": 216,
        "end_line": 220,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Subtract.build#247",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Subtract",
        "signature": "keras.layers.merge.Subtract.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        super(Subtract, self).build(input_shape)\n        if len(input_shape) != 2:\n            raise ValueError('A `Subtract` layer should be called '\n                             'on exactly 2 inputs')",
        "begin_line": 247,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Subtract._merge_function#253",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Subtract",
        "signature": "keras.layers.merge.Subtract._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        if len(inputs) != 2:\n            raise ValueError('A `Subtract` layer should be called '\n                             'on exactly 2 inputs')\n        return inputs[0] - inputs[1]",
        "begin_line": 253,
        "end_line": 257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Multiply._merge_function#268",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Multiply",
        "signature": "keras.layers.merge.Multiply._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output *= inputs[i]\n        return output",
        "begin_line": 268,
        "end_line": 272,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Average._merge_function#283",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Average",
        "signature": "keras.layers.merge.Average._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output += inputs[i]\n        return output / len(inputs)",
        "begin_line": 283,
        "end_line": 287,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Maximum._merge_function#298",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Maximum",
        "signature": "keras.layers.merge.Maximum._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output = K.maximum(output, inputs[i])\n        return output",
        "begin_line": 298,
        "end_line": 302,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Minimum._merge_function#313",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Minimum",
        "signature": "keras.layers.merge.Minimum._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output = K.minimum(output, inputs[i])\n        return output",
        "begin_line": 313,
        "end_line": 317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.__init__#332",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.__init__(self, axis=-1, **kwargs)",
        "snippet": "    def __init__(self, axis=-1, **kwargs):\n        super(Concatenate, self).__init__(**kwargs)\n        self.axis = axis\n        self.supports_masking = True\n        self._reshape_required = False",
        "begin_line": 332,
        "end_line": 336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017574692442882249,
            "pseudo_dstar_susp": 0.0006222775357809583,
            "pseudo_tarantula_susp": 0.0023148148148148147,
            "pseudo_op2_susp": 0.0006222775357809583,
            "pseudo_barinel_susp": 0.0023148148148148147
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.build#338",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        # Used purely for shape validation.\n        if not isinstance(input_shape, list) or len(input_shape) < 2:\n            raise ValueError('A `Concatenate` layer should be called '\n                             'on a list of at least 2 inputs')\n        if all([shape is None for shape in input_shape]):\n            return\n        reduced_inputs_shapes = [list(shape) for shape in input_shape]\n        shape_set = set()\n        for i in range(len(reduced_inputs_shapes)):\n            del reduced_inputs_shapes[i][self.axis]\n            shape_set.add(tuple(reduced_inputs_shapes[i]))\n        if len(shape_set) > 1:\n            raise ValueError('A `Concatenate` layer requires '\n                             'inputs with matching shapes '\n                             'except for the concat axis. '\n                             'Got inputs shapes: %s' % (input_shape))",
        "begin_line": 338,
        "end_line": 354,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003389830508474576,
            "pseudo_dstar_susp": 0.0011723329425556857,
            "pseudo_tarantula_susp": 0.0023148148148148147,
            "pseudo_op2_susp": 0.0011723329425556857,
            "pseudo_barinel_susp": 0.0023148148148148147
        }
    },
    {
        "name": "keras.layers.merge.Concatenate._merge_function#356",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        return K.concatenate(inputs, axis=self.axis)",
        "begin_line": 356,
        "end_line": 357,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017574692442882249,
            "pseudo_dstar_susp": 0.0006222775357809583,
            "pseudo_tarantula_susp": 0.0023148148148148147,
            "pseudo_op2_susp": 0.0006222775357809583,
            "pseudo_barinel_susp": 0.0023148148148148147
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.compute_output_shape#359",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if not isinstance(input_shape, list):\n            raise ValueError('A `Concatenate` layer should be called '\n                             'on a list of inputs.')\n        input_shapes = input_shape\n        output_shape = list(input_shapes[0])\n        for shape in input_shapes[1:]:\n            if output_shape[self.axis] is None or shape[self.axis] is None:\n                output_shape[self.axis] = None\n                break\n            output_shape[self.axis] += shape[self.axis]\n        return tuple(output_shape)",
        "begin_line": 359,
        "end_line": 370,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017574692442882249,
            "pseudo_dstar_susp": 0.0006222775357809583,
            "pseudo_tarantula_susp": 0.0023148148148148147,
            "pseudo_op2_susp": 0.0006222775357809583,
            "pseudo_barinel_susp": 0.0023148148148148147
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.compute_mask#372",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if mask is None:\n            return None\n        if not isinstance(mask, list):\n            raise ValueError('`mask` should be a list.')\n        if not isinstance(inputs, list):\n            raise ValueError('`inputs` should be a list.')\n        if len(mask) != len(inputs):\n            raise ValueError('The lists `inputs` and `mask` '\n                             'should have the same length.')\n        if all([m is None for m in mask]):\n            return None\n        # Make a list of masks while making sure\n        # the dimensionality of each mask\n        # is the same as the corresponding input.\n        masks = []\n        for input_i, mask_i in zip(inputs, mask):\n            if mask_i is None:\n                # Input is unmasked. Append all 1s to masks,\n                masks.append(K.ones_like(input_i, dtype='bool'))\n            elif K.ndim(mask_i) < K.ndim(input_i):\n                # Mask is smaller than the input, expand it\n                masks.append(K.expand_dims(mask_i))\n            else:\n                masks.append(mask_i)\n        concatenated = K.concatenate(masks, axis=self.axis)\n        return K.all(concatenated, axis=-1, keepdims=False)",
        "begin_line": 372,
        "end_line": 398,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003389830508474576,
            "pseudo_dstar_susp": 0.0011723329425556857,
            "pseudo_tarantula_susp": 0.0023148148148148147,
            "pseudo_op2_susp": 0.0011723329425556857,
            "pseudo_barinel_susp": 0.0023148148148148147
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.get_config#400",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'axis': self.axis,\n        }\n        base_config = super(Concatenate, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 400,
        "end_line": 405,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006329113924050633,
            "pseudo_dstar_susp": 0.0007513148009015778,
            "pseudo_tarantula_susp": 0.006666666666666667,
            "pseudo_op2_susp": 0.0007513148009015778,
            "pseudo_barinel_susp": 0.006666666666666667
        }
    },
    {
        "name": "keras.layers.merge.Dot.__init__#426",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot.__init__(self, axes, normalize=False, **kwargs)",
        "snippet": "    def __init__(self, axes, normalize=False, **kwargs):\n        super(Dot, self).__init__(**kwargs)\n        if not isinstance(axes, int):\n            if not isinstance(axes, (list, tuple)):\n                raise TypeError('Invalid type for `axes` - '\n                                'should be a list or an int.')\n            if len(axes) != 2:\n                raise ValueError('Invalid format for `axes` - '\n                                 'should contain two elements.')\n            if not isinstance(axes[0], int) or not isinstance(axes[1], int):\n                raise ValueError('Invalid format for `axes` - '\n                                 'list elements should be \"int\".')\n        self.axes = axes\n        self.normalize = normalize\n        self.supports_masking = True\n        self._reshape_required = False",
        "begin_line": 426,
        "end_line": 441,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Dot.build#443",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        # Used purely for shape validation.\n        if not isinstance(input_shape, list) or len(input_shape) != 2:\n            raise ValueError('A `Dot` layer should be called '\n                             'on a list of 2 inputs.')\n        shape1 = input_shape[0]\n        shape2 = input_shape[1]\n        if shape1 is None or shape2 is None:\n            return\n        if isinstance(self.axes, int):\n            if self.axes < 0:\n                axes = [self.axes % len(shape1), self.axes % len(shape2)]\n            else:\n                axes = [self.axes] * 2\n        else:\n            axes = self.axes\n        if shape1[axes[0]] != shape2[axes[1]]:\n            raise ValueError(\n                'Dimension incompatibility '\n                '%s != %s. ' % (shape1[axes[0]], shape2[axes[1]]) +\n                'Layer shapes: %s, %s' % (shape1, shape2))",
        "begin_line": 443,
        "end_line": 463,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Dot._merge_function#465",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        if len(inputs) != 2:\n            raise ValueError('A `Dot` layer should be called '\n                             'on exactly 2 inputs')\n        x1 = inputs[0]\n        x2 = inputs[1]\n        if isinstance(self.axes, int):\n            if self.axes < 0:\n                axes = [self.axes % K.ndim(x1), self.axes % K.ndim(x2)]\n            else:\n                axes = [self.axes] * 2\n        else:\n            axes = []\n            for i in range(len(self.axes)):\n                if self.axes[i] < 0:\n                    axes.append(self.axes[i] % K.ndim(inputs[i]))\n                else:\n                    axes.append(self.axes[i])\n        if self.normalize:\n            x1 = K.l2_normalize(x1, axis=axes[0])\n            x2 = K.l2_normalize(x2, axis=axes[1])\n        output = K.batch_dot(x1, x2, axes)\n        return output",
        "begin_line": 465,
        "end_line": 487,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Dot.compute_output_shape#489",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if not isinstance(input_shape, list) or len(input_shape) != 2:\n            raise ValueError('A `Dot` layer should be called '\n                             'on a list of 2 inputs.')\n        shape1 = list(input_shape[0])\n        shape2 = list(input_shape[1])\n        if isinstance(self.axes, int):\n            if self.axes < 0:\n                axes = [self.axes % len(shape1), self.axes % len(shape2)]\n            else:\n                axes = [self.axes] * 2\n        else:\n            axes = self.axes\n        shape1.pop(axes[0])\n        shape2.pop(axes[1])\n        shape2.pop(0)\n        output_shape = shape1 + shape2\n        if len(output_shape) == 1:\n            output_shape += [1]\n        return tuple(output_shape)",
        "begin_line": 489,
        "end_line": 508,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Dot.compute_mask#510",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        return None",
        "begin_line": 510,
        "end_line": 511,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.Dot.get_config#513",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'axes': self.axes,\n            'normalize': self.normalize,\n        }\n        base_config = super(Dot, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 513,
        "end_line": 519,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.add#522",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.add(inputs, **kwargs)",
        "snippet": "def add(inputs, **kwargs):\n    \"\"\"Functional interface to the `Add` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the sum of the inputs.\n\n    # Examples\n\n    ```python\n        import keras\n\n        input1 = keras.layers.Input(shape=(16,))\n        x1 = keras.layers.Dense(8, activation='relu')(input1)\n        input2 = keras.layers.Input(shape=(32,))\n        x2 = keras.layers.Dense(8, activation='relu')(input2)\n        added = keras.layers.add([x1, x2])\n\n        out = keras.layers.Dense(4)(added)\n        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n    ```\n    \"\"\"\n    return Add(**kwargs)(inputs)",
        "begin_line": 522,
        "end_line": 547,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.subtract#550",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.subtract(inputs, **kwargs)",
        "snippet": "def subtract(inputs, **kwargs):\n    \"\"\"Functional interface to the `Subtract` layer.\n\n    # Arguments\n        inputs: A list of input tensors (exactly 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the difference of the inputs.\n\n    # Examples\n\n    ```python\n        import keras\n\n        input1 = keras.layers.Input(shape=(16,))\n        x1 = keras.layers.Dense(8, activation='relu')(input1)\n        input2 = keras.layers.Input(shape=(32,))\n        x2 = keras.layers.Dense(8, activation='relu')(input2)\n        subtracted = keras.layers.subtract([x1, x2])\n\n        out = keras.layers.Dense(4)(subtracted)\n        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n    ```\n    \"\"\"\n    return Subtract(**kwargs)(inputs)",
        "begin_line": 550,
        "end_line": 575,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.multiply#578",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.multiply(inputs, **kwargs)",
        "snippet": "def multiply(inputs, **kwargs):\n    \"\"\"Functional interface to the `Multiply` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the element-wise product of the inputs.\n    \"\"\"\n    return Multiply(**kwargs)(inputs)",
        "begin_line": 578,
        "end_line": 588,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.average#591",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.average(inputs, **kwargs)",
        "snippet": "def average(inputs, **kwargs):\n    \"\"\"Functional interface to the `Average` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the average of the inputs.\n    \"\"\"\n    return Average(**kwargs)(inputs)",
        "begin_line": 591,
        "end_line": 601,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.maximum#604",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.maximum(inputs, **kwargs)",
        "snippet": "def maximum(inputs, **kwargs):\n    \"\"\"Functional interface to the `Maximum` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the element-wise maximum of the inputs.\n    \"\"\"\n    return Maximum(**kwargs)(inputs)",
        "begin_line": 604,
        "end_line": 614,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.minimum#617",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.minimum(inputs, **kwargs)",
        "snippet": "def minimum(inputs, **kwargs):\n    \"\"\"Functional interface to the `Minimum` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the element-wise minimum of the inputs.\n    \"\"\"\n    return Minimum(**kwargs)(inputs)",
        "begin_line": 617,
        "end_line": 627,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.merge.concatenate#630",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.concatenate(inputs, axis=-1, **kwargs)",
        "snippet": "def concatenate(inputs, axis=-1, **kwargs):\n    \"\"\"Functional interface to the `Concatenate` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        axis: Concatenation axis.\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the concatenation of the inputs alongside axis `axis`.\n    \"\"\"\n    return Concatenate(axis=axis, **kwargs)(inputs)",
        "begin_line": 630,
        "end_line": 641,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002506265664160401,
            "pseudo_dstar_susp": 0.0006596306068601583,
            "pseudo_tarantula_susp": 0.0029585798816568047,
            "pseudo_op2_susp": 0.0006596306068601583,
            "pseudo_barinel_susp": 0.0029585798816568047
        }
    },
    {
        "name": "keras.layers.merge.dot#644",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.dot(inputs, axes, normalize=False, **kwargs)",
        "snippet": "def dot(inputs, axes, normalize=False, **kwargs):\n    \"\"\"Functional interface to the `Dot` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        axes: Integer or tuple of integers,\n            axis or axes along which to take the dot product.\n        normalize: Whether to L2-normalize samples along the\n            dot product axis before taking the dot product.\n            If set to True, then the output of the dot product\n            is the cosine proximity between the two samples.\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the dot product of the samples from the inputs.\n    \"\"\"\n    return Dot(axes=axes, normalize=normalize, **kwargs)(inputs)",
        "begin_line": 644,
        "end_line": 660,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.Initializer.__call__#18",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Initializer",
        "signature": "keras.initializers.Initializer.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        raise NotImplementedError",
        "begin_line": 18,
        "end_line": 19,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.Initializer.get_config#21",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Initializer",
        "signature": "keras.initializers.Initializer.get_config(self)",
        "snippet": "    def get_config(self):\n        return {}",
        "begin_line": 21,
        "end_line": 22,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003935458480913026,
            "pseudo_dstar_susp": 0.00039231071008238524,
            "pseudo_tarantula_susp": 0.00047596382674916705,
            "pseudo_op2_susp": 0.00039231071008238524,
            "pseudo_barinel_susp": 0.00047596382674916705
        }
    },
    {
        "name": "keras.initializers.Initializer.from_config#25",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Initializer",
        "signature": "keras.initializers.Initializer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        if 'dtype' in config:\n            # Initializers saved from `tf.keras`\n            # may contain an unused `dtype` argument.\n            config.pop('dtype')\n        return cls(**config)",
        "begin_line": 25,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001026694045174538,
            "pseudo_dstar_susp": 0.004291845493562232,
            "pseudo_tarantula_susp": 0.0006329113924050633,
            "pseudo_op2_susp": 0.004291845493562232,
            "pseudo_barinel_susp": 0.0006329113924050633
        }
    },
    {
        "name": "keras.initializers.Zeros.__call__#37",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Zeros",
        "signature": "keras.initializers.Zeros.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.constant(0, shape=shape, dtype=dtype)",
        "begin_line": 37,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0012091898428053204,
            "pseudo_dstar_susp": 0.005847953216374269,
            "pseudo_tarantula_susp": 0.0006775067750677507,
            "pseudo_op2_susp": 0.005847953216374269,
            "pseudo_barinel_susp": 0.0006775067750677507
        }
    },
    {
        "name": "keras.initializers.Ones.__call__#45",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Ones",
        "signature": "keras.initializers.Ones.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.constant(1, shape=shape, dtype=dtype)",
        "begin_line": 45,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.415647015202076e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.Constant.__init__#56",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Constant",
        "signature": "keras.initializers.Constant.__init__(self, value=0)",
        "snippet": "    def __init__(self, value=0):\n        self.value = value",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.Constant.__call__#59",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Constant",
        "signature": "keras.initializers.Constant.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.constant(self.value, shape=shape, dtype=dtype)",
        "begin_line": 59,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.Constant.get_config#62",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Constant",
        "signature": "keras.initializers.Constant.get_config(self)",
        "snippet": "    def get_config(self):\n        return {'value': self.value}",
        "begin_line": 62,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.RandomNormal.__init__#77",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomNormal",
        "signature": "keras.initializers.RandomNormal.__init__(self, mean=0.0, stddev=0.05, seed=None)",
        "snippet": "    def __init__(self, mean=0., stddev=0.05, seed=None):\n        self.mean = mean\n        self.stddev = stddev\n        self.seed = seed",
        "begin_line": 77,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.120178643930166e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.RandomNormal.__call__#82",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomNormal",
        "signature": "keras.initializers.RandomNormal.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.random_normal(shape, self.mean, self.stddev,\n                               dtype=dtype, seed=self.seed)",
        "begin_line": 82,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.RandomNormal.get_config#86",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomNormal",
        "signature": "keras.initializers.RandomNormal.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'mean': self.mean,\n            'stddev': self.stddev,\n            'seed': self.seed\n        }",
        "begin_line": 86,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.21422704123542e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.RandomUniform.__init__#105",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomUniform",
        "signature": "keras.initializers.RandomUniform.__init__(self, minval=-0.05, maxval=0.05, seed=None)",
        "snippet": "    def __init__(self, minval=-0.05, maxval=0.05, seed=None):\n        self.minval = minval\n        self.maxval = maxval\n        self.seed = seed",
        "begin_line": 105,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.931472081218273e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.RandomUniform.__call__#110",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomUniform",
        "signature": "keras.initializers.RandomUniform.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.random_uniform(shape, self.minval, self.maxval,\n                                dtype=dtype, seed=self.seed)",
        "begin_line": 110,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.010894816951053e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.RandomUniform.get_config#114",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomUniform",
        "signature": "keras.initializers.RandomUniform.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'minval': self.minval,\n            'maxval': self.maxval,\n            'seed': self.seed,\n        }",
        "begin_line": 114,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.TruncatedNormal.__init__#138",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.TruncatedNormal",
        "signature": "keras.initializers.TruncatedNormal.__init__(self, mean=0.0, stddev=0.05, seed=None)",
        "snippet": "    def __init__(self, mean=0., stddev=0.05, seed=None):\n        self.mean = mean\n        self.stddev = stddev\n        self.seed = seed",
        "begin_line": 138,
        "end_line": 141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.TruncatedNormal.__call__#143",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.TruncatedNormal",
        "signature": "keras.initializers.TruncatedNormal.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.truncated_normal(shape, self.mean, self.stddev,\n                                  dtype=dtype, seed=self.seed)",
        "begin_line": 143,
        "end_line": 145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.TruncatedNormal.get_config#147",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.TruncatedNormal",
        "signature": "keras.initializers.TruncatedNormal.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'mean': self.mean,\n            'stddev': self.stddev,\n            'seed': self.seed\n        }",
        "begin_line": 147,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.VarianceScaling.__init__#180",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.VarianceScaling",
        "signature": "keras.initializers.VarianceScaling.__init__(self, scale=1.0, mode='fan_in', distribution='normal', seed=None)",
        "snippet": "    def __init__(self, scale=1.0,\n                 mode='fan_in',\n                 distribution='normal',\n                 seed=None):\n        if scale <= 0.:\n            raise ValueError('`scale` must be a positive float. Got:', scale)\n        mode = mode.lower()\n        if mode not in {'fan_in', 'fan_out', 'fan_avg'}:\n            raise ValueError('Invalid `mode` argument: '\n                             'expected on of {\"fan_in\", \"fan_out\", \"fan_avg\"} '\n                             'but got', mode)\n        distribution = distribution.lower()\n        if distribution not in {'normal', 'uniform'}:\n            raise ValueError('Invalid `distribution` argument: '\n                             'expected one of {\"normal\", \"uniform\"} '\n                             'but got', distribution)\n        self.scale = scale\n        self.mode = mode\n        self.distribution = distribution\n        self.seed = seed",
        "begin_line": 180,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010626992561105207,
            "pseudo_dstar_susp": 0.004830917874396135,
            "pseudo_tarantula_susp": 0.000651890482398957,
            "pseudo_op2_susp": 0.004830917874396135,
            "pseudo_barinel_susp": 0.000651890482398957
        }
    },
    {
        "name": "keras.initializers.VarianceScaling.__call__#201",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.VarianceScaling",
        "signature": "keras.initializers.VarianceScaling.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        fan_in, fan_out = _compute_fans(shape)\n        scale = self.scale\n        if self.mode == 'fan_in':\n            scale /= max(1., fan_in)\n        elif self.mode == 'fan_out':\n            scale /= max(1., fan_out)\n        else:\n            scale /= max(1., float(fan_in + fan_out) / 2)\n        if self.distribution == 'normal':\n            stddev = np.sqrt(scale)\n            return K.truncated_normal(shape, 0., stddev,\n                                      dtype=dtype, seed=self.seed)\n        else:\n            limit = np.sqrt(3. * scale)\n            return K.random_uniform(shape, -limit, limit,\n                                    dtype=dtype, seed=self.seed)",
        "begin_line": 201,
        "end_line": 217,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013458950201884253,
            "pseudo_dstar_susp": 0.006535947712418301,
            "pseudo_tarantula_susp": 0.0007507507507507507,
            "pseudo_op2_susp": 0.006535947712418301,
            "pseudo_barinel_susp": 0.0007507507507507507
        }
    },
    {
        "name": "keras.initializers.VarianceScaling.get_config#219",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.VarianceScaling",
        "signature": "keras.initializers.VarianceScaling.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'scale': self.scale,\n            'mode': self.mode,\n            'distribution': self.distribution,\n            'seed': self.seed\n        }",
        "begin_line": 219,
        "end_line": 225,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00039494470774091627,
            "pseudo_dstar_susp": 0.0003937007874015748,
            "pseudo_tarantula_susp": 0.0004930966469428008,
            "pseudo_op2_susp": 0.0003937007874015748,
            "pseudo_barinel_susp": 0.0004930966469428008
        }
    },
    {
        "name": "keras.initializers.Orthogonal.__init__#239",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Orthogonal",
        "signature": "keras.initializers.Orthogonal.__init__(self, gain=1.0, seed=None)",
        "snippet": "    def __init__(self, gain=1., seed=None):\n        self.gain = gain\n        self.seed = seed",
        "begin_line": 239,
        "end_line": 241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.241653993772178e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.Orthogonal.__call__#243",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Orthogonal",
        "signature": "keras.initializers.Orthogonal.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        num_rows = 1\n        for dim in shape[:-1]:\n            num_rows *= dim\n        num_cols = shape[-1]\n        flat_shape = (num_rows, num_cols)\n        if self.seed is not None:\n            np.random.seed(self.seed)\n        a = np.random.normal(0.0, 1.0, flat_shape)\n        u, _, v = np.linalg.svd(a, full_matrices=False)\n        # Pick the one with the correct shape.\n        q = u if u.shape == flat_shape else v\n        q = q.reshape(shape)\n        return self.gain * q[:shape[0], :shape[1]]",
        "begin_line": 243,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.254788160185723e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.Orthogonal.get_config#258",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Orthogonal",
        "signature": "keras.initializers.Orthogonal.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'gain': self.gain,\n            'seed': self.seed\n        }",
        "begin_line": 258,
        "end_line": 262,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.536362951239732e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.Identity.__init__#274",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Identity",
        "signature": "keras.initializers.Identity.__init__(self, gain=1.0)",
        "snippet": "    def __init__(self, gain=1.):\n        self.gain = gain",
        "begin_line": 274,
        "end_line": 275,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.Identity.__call__#277",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Identity",
        "signature": "keras.initializers.Identity.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        if len(shape) != 2 or shape[0] != shape[1]:\n            raise ValueError('Identity matrix initializer can only be used '\n                             'for 2D square matrices.')\n        else:\n            return self.gain * np.identity(shape[0])",
        "begin_line": 277,
        "end_line": 282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.Identity.get_config#284",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Identity",
        "signature": "keras.initializers.Identity.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'gain': self.gain\n        }",
        "begin_line": 284,
        "end_line": 287,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.lecun_uniform#290",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.lecun_uniform(seed=None)",
        "snippet": "def lecun_uniform(seed=None):\n    \"\"\"LeCun uniform initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(3 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        LeCun 98, Efficient Backprop,\n        http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\n    \"\"\"\n    return VarianceScaling(scale=1.,\n                           mode='fan_in',\n                           distribution='uniform',\n                           seed=seed)",
        "begin_line": 290,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.glorot_normal#313",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.glorot_normal(seed=None)",
        "snippet": "def glorot_normal(seed=None):\n    \"\"\"Glorot normal initializer, also called Xavier normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(2 / (fan_in + fan_out))`\n    where `fan_in` is the number of input units in the weight tensor\n    and `fan_out` is the number of output units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        Glorot & Bengio, AISTATS 2010\n        http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n    \"\"\"\n    return VarianceScaling(scale=1.,\n                           mode='fan_avg',\n                           distribution='normal',\n                           seed=seed)",
        "begin_line": 313,
        "end_line": 334,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.glorot_uniform#337",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.glorot_uniform(seed=None)",
        "snippet": "def glorot_uniform(seed=None):\n    \"\"\"Glorot uniform initializer, also called Xavier uniform initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(6 / (fan_in + fan_out))`\n    where `fan_in` is the number of input units in the weight tensor\n    and `fan_out` is the number of output units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        Glorot & Bengio, AISTATS 2010\n        http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n    \"\"\"\n    return VarianceScaling(scale=1.,\n                           mode='fan_avg',\n                           distribution='uniform',\n                           seed=seed)",
        "begin_line": 337,
        "end_line": 358,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001218026796589525,
            "pseudo_dstar_susp": 0.006060606060606061,
            "pseudo_tarantula_susp": 0.0006830601092896175,
            "pseudo_op2_susp": 0.006060606060606061,
            "pseudo_barinel_susp": 0.0006830601092896175
        }
    },
    {
        "name": "keras.initializers.he_normal#361",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.he_normal(seed=None)",
        "snippet": "def he_normal(seed=None):\n    \"\"\"He normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(2 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        He et al., http://arxiv.org/abs/1502.01852\n    \"\"\"\n    return VarianceScaling(scale=2.,\n                           mode='fan_in',\n                           distribution='normal',\n                           seed=seed)",
        "begin_line": 361,
        "end_line": 380,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.lecun_normal#383",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.lecun_normal(seed=None)",
        "snippet": "def lecun_normal(seed=None):\n    \"\"\"LeCun normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(1 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n        - [Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n    \"\"\"\n    return VarianceScaling(scale=1.,\n                           mode='fan_in',\n                           distribution='normal',\n                           seed=seed)",
        "begin_line": 383,
        "end_line": 403,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers.he_uniform#406",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.he_uniform(seed=None)",
        "snippet": "def he_uniform(seed=None):\n    \"\"\"He uniform variance scaling initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(6 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        He et al., http://arxiv.org/abs/1502.01852\n    \"\"\"\n    return VarianceScaling(scale=2.,\n                           mode='fan_in',\n                           distribution='uniform',\n                           seed=seed)",
        "begin_line": 406,
        "end_line": 425,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.initializers._compute_fans#442",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers._compute_fans(shape, data_format='channels_last')",
        "snippet": "def _compute_fans(shape, data_format='channels_last'):\n    \"\"\"Computes the number of input and output units for a weight shape.\n\n    # Arguments\n        shape: Integer shape tuple.\n        data_format: Image data format to use for convolution kernels.\n            Note that all kernels in Keras are standardized on the\n            `channels_last` ordering (even when inputs are set\n            to `channels_first`).\n\n    # Returns\n        A tuple of scalars, `(fan_in, fan_out)`.\n\n    # Raises\n        ValueError: in case of invalid `data_format` argument.\n    \"\"\"\n    if len(shape) == 2:\n        fan_in = shape[0]\n        fan_out = shape[1]\n    elif len(shape) in {3, 4, 5}:\n        # Assuming convolution kernels (1D, 2D or 3D).\n        # TH kernel shape: (depth, input_depth, ...)\n        # TF kernel shape: (..., input_depth, depth)\n        if data_format == 'channels_first':\n            receptive_field_size = np.prod(shape[2:])\n            fan_in = shape[1] * receptive_field_size\n            fan_out = shape[0] * receptive_field_size\n        elif data_format == 'channels_last':\n            receptive_field_size = np.prod(shape[:-2])\n            fan_in = shape[-2] * receptive_field_size\n            fan_out = shape[-1] * receptive_field_size\n        else:\n            raise ValueError('Invalid data_format: ' + data_format)\n    else:\n        # No specific assumptions.\n        fan_in = np.sqrt(np.prod(shape))\n        fan_out = np.sqrt(np.prod(shape))\n    return fan_in, fan_out",
        "begin_line": 442,
        "end_line": 479,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001402524544179523,
            "pseudo_dstar_susp": 0.006993006993006993,
            "pseudo_tarantula_susp": 0.0009416195856873823,
            "pseudo_op2_susp": 0.006993006993006993,
            "pseudo_barinel_susp": 0.0009416195856873823
        }
    },
    {
        "name": "keras.initializers.serialize#482",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.serialize(initializer)",
        "snippet": "def serialize(initializer):\n    return serialize_keras_object(initializer)",
        "begin_line": 482,
        "end_line": 483,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00039077764751856197,
            "pseudo_dstar_susp": 0.00038955979742890534,
            "pseudo_tarantula_susp": 0.0004338394793926247,
            "pseudo_op2_susp": 0.00038955979742890534,
            "pseudo_barinel_susp": 0.00043402777777777775
        }
    },
    {
        "name": "keras.initializers.deserialize#486",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='initializer')",
        "begin_line": 486,
        "end_line": 490,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001026694045174538,
            "pseudo_dstar_susp": 0.004291845493562232,
            "pseudo_tarantula_susp": 0.0006329113924050633,
            "pseudo_op2_susp": 0.004291845493562232,
            "pseudo_barinel_susp": 0.0006329113924050633
        }
    },
    {
        "name": "keras.initializers.get#493",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.get(identifier)",
        "snippet": "def get(identifier):\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret initializer identifier: ' +\n                         str(identifier))",
        "begin_line": 493,
        "end_line": 503,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011918951132300357,
            "pseudo_dstar_susp": 0.00546448087431694,
            "pseudo_tarantula_susp": 0.0006657789613848203,
            "pseudo_op2_susp": 0.00546448087431694,
            "pseudo_barinel_susp": 0.0006657789613848203
        }
    },
    {
        "name": "keras.engine.training._standardize_input_data#27",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._standardize_input_data(data, names, shapes=None, check_batch_axis=True, exception_prefix='')",
        "snippet": "def _standardize_input_data(data, names, shapes=None,\n                            check_batch_axis=True,\n                            exception_prefix=''):\n    \"\"\"Normalizes inputs and targets provided by users.\n\n    Users may pass data as a list of arrays, dictionary of arrays,\n    or as a single array. We normalize this to an ordered list of\n    arrays (same order as `names`), while checking that the provided\n    arrays have shapes that match the network's expectations.\n\n    # Arguments\n        data: User-provided input data (polymorphic).\n        names: List of expected array names.\n        shapes: Optional list of expected array shapes.\n        check_batch_axis: Boolean; whether to check that\n            the batch axis of the arrays matches the expected\n            value found in `shapes`.\n        exception_prefix: String prefix used for exception formatting.\n\n    # Returns\n        List of standardized input arrays (one array per model input).\n\n    # Raises\n        ValueError: in case of improperly formatted user-provided data.\n    \"\"\"\n    if not names:\n        if data is not None and hasattr(data, '__len__') and len(data):\n            raise ValueError('Error when checking model ' +\n                             exception_prefix + ': '\n                             'expected no data, but got:', data)\n        return []\n    if data is None:\n        return [None for _ in range(len(names))]\n\n    if isinstance(data, dict):\n        try:\n            data = [data[x].values if data[x].__class__.__name__ == 'DataFrame' else data[x] for x in names]\n        except KeyError as e:\n            raise ValueError(\n                'No data provided for \"' + e.args[0] + '\". Need data '\n                'for each key in: ' + str(names))\n    elif isinstance(data, list):\n        if len(names) == 1 and data and isinstance(data[0], (float, int)):\n            data = [np.asarray(data)]\n        else:\n            data = [x.values if x.__class__.__name__ == 'DataFrame' else x for x in data]\n    else:\n        data = data.values if data.__class__.__name__ == 'DataFrame' else data\n        data = [data]\n    data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]\n\n    if len(data) != len(names):\n        if data and hasattr(data[0], 'shape'):\n            raise ValueError(\n                'Error when checking model ' + exception_prefix +\n                ': the list of Numpy arrays that you are passing to '\n                'your model is not the size the model expected. '\n                'Expected to see ' + str(len(names)) + ' array(s), '\n                'but instead got the following list of ' +\n                str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n        elif len(names) > 1:\n            raise ValueError(\n                'Error when checking model ' + exception_prefix +\n                ': you are passing a list as input to your model, '\n                'but the model expects a list of ' + str(len(names)) +\n                ' Numpy arrays instead. The list you passed was: ' +\n                str(data)[:200])\n        elif len(data) == 1 and not hasattr(data[0], 'shape'):\n            raise TypeError(\n                'Error when checking model ' + exception_prefix +\n                ': data should be a Numpy array, or list/dict of '\n                'Numpy arrays. Found: ' + str(data)[:200] + '...')\n        elif len(names) == 1:\n            data = [np.asarray(data)]\n\n    # Check shapes compatibility.\n    if shapes:\n        for i in range(len(names)):\n            if shapes[i] is not None:\n                data_shape = data[i].shape\n                shape = shapes[i]\n                if data[i].ndim != len(shape):\n                    raise ValueError(\n                        'Error when checking ' + exception_prefix +\n                        ': expected ' + names[i] + ' to have ' +\n                        str(len(shape)) + ' dimensions, but got array '\n                        'with shape ' + str(data_shape))\n                if not check_batch_axis:\n                    data_shape = data_shape[1:]\n                    shape = shape[1:]\n                for dim, ref_dim in zip(data_shape, shape):\n                    if ref_dim != dim and ref_dim:\n                        raise ValueError(\n                            'Error when checking ' + exception_prefix +\n                            ': expected ' + names[i] + ' to have shape ' +\n                            str(shape) + ' but got array with shape ' +\n                            str(data_shape))\n    return data",
        "begin_line": 27,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006618133686300463,
            "pseudo_dstar_susp": 0.0011210762331838565,
            "pseudo_tarantula_susp": 0.000859106529209622,
            "pseudo_op2_susp": 0.0011210762331838565,
            "pseudo_barinel_susp": 0.000859106529209622
        }
    },
    {
        "name": "keras.engine.training._standardize_sample_or_class_weights#127",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._standardize_sample_or_class_weights(x_weight, output_names, weight_type)",
        "snippet": "def _standardize_sample_or_class_weights(x_weight, output_names, weight_type):\n    \"\"\"Maps `sample_weight` or `class_weight` to model outputs.\n\n    # Arguments\n        x_weight: User-provided `sample_weight` or `class_weight` argument.\n        output_names: List of output names (strings) in the model.\n        weight_type: A string used purely for exception printing.\n\n    # Returns\n        A list of `sample_weight` or `class_weight` where there are exactly\n            one element per model output.\n\n    # Raises\n        ValueError: In case of invalid user-provided argument.\n    \"\"\"\n    if x_weight is None or len(x_weight) == 0:\n        return [None for _ in output_names]\n    if len(output_names) == 1:\n        if isinstance(x_weight, list) and len(x_weight) == 1:\n            return x_weight\n        if isinstance(x_weight, dict) and output_names[0] in x_weight:\n            return [x_weight[output_names[0]]]\n        else:\n            return [x_weight]\n    if isinstance(x_weight, list):\n        if len(x_weight) != len(output_names):\n            raise ValueError('Provided `' + weight_type + '` was a list of ' +\n                             str(len(x_weight)) +\n                             ' elements, but the model has ' +\n                             str(len(output_names)) + ' outputs. '\n                             'You should provide one `' + weight_type + '`'\n                             'array per model output.')\n        return x_weight\n    if isinstance(x_weight, dict):\n        x_weights = []\n        for name in output_names:\n            x_weights.append(x_weight.get(name))\n        return x_weights\n    else:\n        raise TypeError('The model has multiple outputs, so `' +\n                        weight_type + '` '\n                        'should be either a list or a dict. '\n                        'Provided `' + weight_type +\n                        '` type not understood: ' +\n                        str(x_weight))",
        "begin_line": 127,
        "end_line": 171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003389830508474576,
            "pseudo_dstar_susp": 0.0008460236886632825,
            "pseudo_tarantula_susp": 0.0037735849056603774,
            "pseudo_op2_susp": 0.0008460236886632825,
            "pseudo_barinel_susp": 0.0037735849056603774
        }
    },
    {
        "name": "keras.engine.training._standardize_class_weights#174",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._standardize_class_weights(class_weight, output_names)",
        "snippet": "def _standardize_class_weights(class_weight, output_names):\n    return _standardize_sample_or_class_weights(class_weight,\n                                                output_names,\n                                                'class_weight')",
        "begin_line": 174,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003541076487252125,
            "pseudo_dstar_susp": 0.0003541076487252125,
            "pseudo_tarantula_susp": 0.00035486160397445,
            "pseudo_op2_susp": 0.0003541076487252125,
            "pseudo_barinel_susp": 0.00035486160397445
        }
    },
    {
        "name": "keras.engine.training._standardize_sample_weights#180",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._standardize_sample_weights(sample_weight, output_names)",
        "snippet": "def _standardize_sample_weights(sample_weight, output_names):\n    return _standardize_sample_or_class_weights(sample_weight,\n                                                output_names,\n                                                'sample_weight')",
        "begin_line": 180,
        "end_line": 183,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003541076487252125,
            "pseudo_dstar_susp": 0.0003541076487252125,
            "pseudo_tarantula_susp": 0.00035486160397445,
            "pseudo_op2_susp": 0.0003541076487252125,
            "pseudo_barinel_susp": 0.00035486160397445
        }
    },
    {
        "name": "keras.engine.training._check_array_lengths#186",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._check_array_lengths(inputs, targets, weights=None)",
        "snippet": "def _check_array_lengths(inputs, targets, weights=None):\n    \"\"\"Checks if batch axes are the same for numpy arrays.\n\n    # Arguments\n        inputs: list of Numpy arrays of inputs.\n        targets: list of Numpy arrays of targets.\n        weights: list of Numpy arrays of sample weights.\n\n    # Raises\n        ValueError: in case of incorrectly formatted data.\n    \"\"\"\n    def set_of_lengths(x):\n        # return a set with the variation between\n        # different shapes, with None => 0\n        if x is None:\n            return {0}\n        else:\n            return set([0 if y is None else y.shape[0] for y in x])\n\n    set_x = set_of_lengths(inputs)\n    set_y = set_of_lengths(targets)\n    set_w = set_of_lengths(weights)\n    if len(set_x) > 1:\n        raise ValueError('All input arrays (x) should have '\n                         'the same number of samples. Got array shapes: ' +\n                         str([x.shape for x in inputs]))\n    if len(set_y) > 1:\n        raise ValueError('All target arrays (y) should have '\n                         'the same number of samples. Got array shapes: ' +\n                         str([y.shape for y in targets]))\n    if set_x and set_y and list(set_x)[0] != list(set_y)[0]:\n        raise ValueError('Input arrays should have '\n                         'the same number of samples as target arrays. '\n                         'Found ' + str(list(set_x)[0]) + ' input samples '\n                         'and ' + str(list(set_y)[0]) + ' target samples.')\n    if len(set_w) > 1:\n        raise ValueError('All sample_weight arrays should have '\n                         'the same number of samples. Got array shapes: ' +\n                         str([w.shape for w in weights]))\n    if set_y and set_w and list(set_y)[0] != list(set_w)[0]:\n        raise ValueError('Sample_weight arrays should have '\n                         'the same number of samples as target arrays. Got ' +\n                         str(list(set_y)[0]) + ' input samples and ' +\n                         str(list(set_w)[0]) + ' target samples.')",
        "begin_line": 186,
        "end_line": 229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003541076487252125,
            "pseudo_dstar_susp": 0.0003541076487252125,
            "pseudo_tarantula_susp": 0.00035486160397445,
            "pseudo_op2_susp": 0.0003541076487252125,
            "pseudo_barinel_susp": 0.00035486160397445
        }
    },
    {
        "name": "keras.engine.training.set_of_lengths#197",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training.set_of_lengths(x)",
        "snippet": "    def set_of_lengths(x):\n        # return a set with the variation between\n        # different shapes, with None => 0\n        if x is None:\n            return {0}\n        else:\n            return set([0 if y is None else y.shape[0] for y in x])",
        "begin_line": 197,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003766478342749529,
            "pseudo_dstar_susp": 0.0008460236886632825,
            "pseudo_tarantula_susp": 0.00035486160397445,
            "pseudo_op2_susp": 0.0008460236886632825,
            "pseudo_barinel_susp": 0.00035486160397445
        }
    },
    {
        "name": "keras.engine.training._check_loss_and_target_compatibility#232",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._check_loss_and_target_compatibility(targets, loss_fns, output_shapes)",
        "snippet": "def _check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n    \"\"\"Does validation on the compatibility of targets and loss functions.\n\n    This helps prevent users from using loss functions incorrectly.\n\n    # Arguments\n        targets: list of Numpy arrays of targets.\n        loss_fns: list of loss functions.\n        output_shapes: list of shapes of model outputs.\n\n    # Raises\n        ValueError: if a loss function or target array\n            is incompatible with an output.\n    \"\"\"\n    key_losses = {losses.mean_squared_error,\n                  losses.binary_crossentropy,\n                  losses.categorical_crossentropy}\n    for y, loss, shape in zip(targets, loss_fns, output_shapes):\n        if y is None or loss is None:\n            continue\n        if loss is losses.categorical_crossentropy:\n            if y.shape[-1] == 1:\n                raise ValueError(\n                    'You are passing a target array of shape ' + str(y.shape) +\n                    ' while using as loss `categorical_crossentropy`. '\n                    '`categorical_crossentropy` expects '\n                    'targets to be binary matrices (1s and 0s) '\n                    'of shape (samples, classes). '\n                    'If your targets are integer classes, '\n                    'you can convert them to the expected format via:\\n'\n                    '```\\n'\n                    'from keras.utils import to_categorical\\n'\n                    'y_binary = to_categorical(y_int)\\n'\n                    '```\\n'\n                    '\\n'\n                    'Alternatively, you can use the loss function '\n                    '`sparse_categorical_crossentropy` instead, '\n                    'which does expect integer targets.')\n        if loss in key_losses:\n            for target_dim, out_dim in zip(y.shape[1:], shape[1:]):\n                if out_dim is not None and target_dim != out_dim:\n                    raise ValueError(\n                        'A target array with shape ' + str(y.shape) +\n                        ' was passed for an output of shape ' + str(shape) +\n                        ' while using as loss `' + loss.__name__ + '`. '\n                        'This loss expects '\n                        'targets to have the same shape '\n                        'as the output.')",
        "begin_line": 232,
        "end_line": 279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00036589828027808267,
            "pseudo_dstar_susp": 0.00036589828027808267,
            "pseudo_tarantula_susp": 0.0003669724770642202,
            "pseudo_op2_susp": 0.00036589828027808267,
            "pseudo_barinel_susp": 0.0003669724770642202
        }
    },
    {
        "name": "keras.engine.training._collect_metrics#282",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._collect_metrics(metrics, output_names)",
        "snippet": "def _collect_metrics(metrics, output_names):\n    \"\"\"Maps metric functions to model outputs.\n\n    # Arguments\n        metrics: a list or dict of metric functions.\n        output_names: a list of the names (strings) of model outputs.\n\n    # Returns\n        A list (one entry per model output) of lists of metric functions.\n        For instance, if the model has 2 outputs, and for the first output\n        we want to compute \"binary_accuracy\" and \"binary_crossentropy\",\n        and just \"binary_accuracy\" for the second output,\n        the list would look like:\n            `[[binary_accuracy, binary_crossentropy], [binary_accuracy]]`\n\n    # Raises\n        TypeError: if an incorrect type is passed for the `metrics` argument.\n    \"\"\"\n    if not metrics:\n        return [[] for _ in output_names]\n    if isinstance(metrics, list):\n        # we then apply all metrics to all outputs.\n        return [copy.copy(metrics) for _ in output_names]\n    elif isinstance(metrics, dict):\n        nested_metrics = []\n        for name in output_names:\n            output_metrics = metrics.get(name, [])\n            if not isinstance(output_metrics, list):\n                output_metrics = [output_metrics]\n            nested_metrics.append(output_metrics)\n        return nested_metrics\n    else:\n        raise TypeError('Type of `metrics` argument not understood. '\n                        'Expected a list or dictionary, found: ' +\n                        str(metrics))",
        "begin_line": 282,
        "end_line": 316,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006418485237483953,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.0007905138339920949,
            "pseudo_op2_susp": 0.001876172607879925,
            "pseudo_barinel_susp": 0.0007905138339920949
        }
    },
    {
        "name": "keras.engine.training._batch_shuffle#319",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._batch_shuffle(index_array, batch_size)",
        "snippet": "def _batch_shuffle(index_array, batch_size):\n    \"\"\"Shuffles an array in a batch-wise fashion.\n\n    Useful for shuffling HDF5 arrays\n    (where one cannot access arbitrary indices).\n\n    # Arguments\n        index_array: array of indices to be shuffled.\n        batch_size: integer.\n\n    # Returns\n        The `index_array` array, shuffled in a batch-wise fashion.\n    \"\"\"\n    batch_count = int(len(index_array) / batch_size)\n    # to reshape we need to be cleanly divisible by batch size\n    # we stash extra items and reappend them after shuffling\n    last_batch = index_array[batch_count * batch_size:]\n    index_array = index_array[:batch_count * batch_size]\n    index_array = index_array.reshape((batch_count, batch_size))\n    np.random.shuffle(index_array)\n    index_array = index_array.flatten()\n    return np.append(index_array, last_batch)",
        "begin_line": 319,
        "end_line": 340,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.training._make_batches#343",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._make_batches(size, batch_size)",
        "snippet": "def _make_batches(size, batch_size):\n    \"\"\"Returns a list of batch indices (tuples of indices).\n\n    # Arguments\n        size: Integer, total size of the data to slice into batches.\n        batch_size: Integer, batch size.\n\n    # Returns\n        A list of tuples of array indices.\n    \"\"\"\n    num_batches = (size + batch_size - 1) // batch_size  # round up\n    return [(i * batch_size, min(size, (i + 1) * batch_size))\n            for i in range(num_batches)]",
        "begin_line": 343,
        "end_line": 355,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000376081233546446,
            "pseudo_dstar_susp": 0.0008438818565400844,
            "pseudo_tarantula_susp": 0.00035161744022503517,
            "pseudo_op2_susp": 0.0008438818565400844,
            "pseudo_barinel_susp": 0.00035161744022503517
        }
    },
    {
        "name": "keras.engine.training._slice_arrays#358",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._slice_arrays(arrays, start=None, stop=None)",
        "snippet": "def _slice_arrays(arrays, start=None, stop=None):\n    \"\"\"Slice an array or list of arrays.\n\n    This takes an array-like, or a list of\n    array-likes, and outputs:\n        - arrays[start:stop] if `arrays` is an array-like\n        - [x[start:stop] for x in arrays] if `arrays` is a list\n\n    Can also work on list/array of indices: `_slice_arrays(x, indices)`\n\n    # Arguments\n        arrays: Single array or list of arrays.\n        start: can be an integer index (start index)\n            or a list/array of indices\n        stop: integer (stop index); should be None if\n            `start` was a list.\n\n    # Returns\n        A slice of the array(s).\n    \"\"\"\n    if arrays is None:\n        return [None]\n    elif isinstance(arrays, list):\n        if hasattr(start, '__len__'):\n            # hdf5 datasets only support list objects as indices\n            if hasattr(start, 'shape'):\n                start = start.tolist()\n            return [None if x is None else x[start] for x in arrays]\n        else:\n            return [None if x is None else x[start:stop] for x in arrays]\n    else:\n        if hasattr(start, '__len__'):\n            if hasattr(start, 'shape'):\n                start = start.tolist()\n            return arrays[start]\n        elif hasattr(start, '__getitem__'):\n            return arrays[start:stop]\n        else:\n            return [None]",
        "begin_line": 358,
        "end_line": 396,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000376081233546446,
            "pseudo_dstar_susp": 0.0008438818565400844,
            "pseudo_tarantula_susp": 0.00035161744022503517,
            "pseudo_op2_susp": 0.0008438818565400844,
            "pseudo_barinel_susp": 0.00035161744022503517
        }
    },
    {
        "name": "keras.engine.training._weighted_masked_objective#399",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._weighted_masked_objective(fn)",
        "snippet": "def _weighted_masked_objective(fn):\n    \"\"\"Adds support for masking and sample-weighting to an objective function.\n\n    It transforms an objective function `fn(y_true, y_pred)`\n    into a sample-weighted, cost-masked objective function\n    `fn(y_true, y_pred, weights, mask)`.\n\n    # Arguments\n        fn: The objective function to wrap,\n            with signature `fn(y_true, y_pred)`.\n\n    # Returns\n        A function with signature `fn(y_true, y_pred, weights, mask)`.\n    \"\"\"\n    if fn is None:\n        return None\n\n    def weighted(y_true, y_pred, weights, mask=None):\n        \"\"\"Wrapper function.\n\n        # Arguments\n            y_true: `y_true` argument of `fn`.\n            y_pred: `y_pred` argument of `fn`.\n            weights: Weights tensor.\n            mask: Mask tensor.\n\n        # Returns\n            Scalar tensor.\n        \"\"\"\n        # score_array has ndim >= 2\n        score_array = fn(y_true, y_pred)\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in Theano\n            mask = K.cast(mask, K.floatx())\n            # mask should have the same shape as score_array\n            score_array *= mask\n            #  the loss per batch should be proportional\n            #  to the number of unmasked samples.\n            score_array /= K.mean(mask)\n\n        # apply sample weighting\n        if weights is not None:\n            # reduce score_array to same ndim as weight array\n            ndim = K.ndim(score_array)\n            weight_ndim = K.ndim(weights)\n            score_array = K.mean(score_array, axis=list(range(weight_ndim, ndim)))\n            score_array *= weights\n            score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n        return K.mean(score_array)\n    return weighted",
        "begin_line": 399,
        "end_line": 448,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00046446818392940084,
            "pseudo_dstar_susp": 0.0009199632014719411,
            "pseudo_tarantula_susp": 0.00039032006245121,
            "pseudo_op2_susp": 0.0009199632014719411,
            "pseudo_barinel_susp": 0.00039032006245121
        }
    },
    {
        "name": "keras.engine.training.weighted#416",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training.weighted(y_true, y_pred, weights, mask=None)",
        "snippet": "    def weighted(y_true, y_pred, weights, mask=None):\n        \"\"\"Wrapper function.\n\n        # Arguments\n            y_true: `y_true` argument of `fn`.\n            y_pred: `y_pred` argument of `fn`.\n            weights: Weights tensor.\n            mask: Mask tensor.\n\n        # Returns\n            Scalar tensor.\n        \"\"\"\n        # score_array has ndim >= 2\n        score_array = fn(y_true, y_pred)\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in Theano\n            mask = K.cast(mask, K.floatx())\n            # mask should have the same shape as score_array\n            score_array *= mask\n            #  the loss per batch should be proportional\n            #  to the number of unmasked samples.\n            score_array /= K.mean(mask)\n\n        # apply sample weighting\n        if weights is not None:\n            # reduce score_array to same ndim as weight array\n            ndim = K.ndim(score_array)\n            weight_ndim = K.ndim(weights)\n            score_array = K.mean(score_array, axis=list(range(weight_ndim, ndim)))\n            score_array *= weights\n            score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n        return K.mean(score_array)",
        "begin_line": 416,
        "end_line": 447,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006365372374283895,
            "pseudo_dstar_susp": 0.00186219739292365,
            "pseudo_tarantula_susp": 0.00040048057669203043,
            "pseudo_op2_susp": 0.00186219739292365,
            "pseudo_barinel_susp": 0.00040048057669203043
        }
    },
    {
        "name": "keras.engine.training._standardize_weights#451",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._standardize_weights(y, sample_weight=None, class_weight=None, sample_weight_mode=None)",
        "snippet": "def _standardize_weights(y, sample_weight=None, class_weight=None,\n                         sample_weight_mode=None):\n    \"\"\"Performs sample weight validation and standardization.\n\n    Everything gets normalized to a single sample-wise (or timestep-wise)\n    weight array.\n\n    # Arguments\n        y: Numpy array of model targets to be weighted.\n        sample_weight: User-provided `sample_weight` argument.\n        class_weight: User-provided `class_weight` argument.\n        sample_weight_mode: One of `None` or `\"temporal\"`.\n            `\"temporal\"` indicated that we expect 2D weight data\n            that will be applied to the last 2 dimensions of\n            the targets (i.e. we are weighting timesteps, not samples).\n\n    # Returns\n        A numpy array of target weights, one entry per sample to weight.\n\n    # Raises\n        ValueError: In case of invalid user-provided arguments.\n    \"\"\"\n    if sample_weight_mode is not None:\n        if sample_weight_mode != 'temporal':\n            raise ValueError('\"sample_weight_mode '\n                             'should be None or \"temporal\". '\n                             'Found: ' + str(sample_weight_mode))\n        if len(y.shape) < 3:\n            raise ValueError('Found a sample_weight array for '\n                             'an input with shape ' +\n                             str(y.shape) + '. '\n                             'Timestep-wise sample weighting (use of '\n                             'sample_weight_mode=\"temporal\") is restricted to '\n                             'outputs that are at least 3D, i.e. that have '\n                             'a time dimension.')\n        if sample_weight is not None and len(sample_weight.shape) != 2:\n            raise ValueError('Found a sample_weight array with shape ' +\n                             str(sample_weight.shape) + '. '\n                             'In order to use timestep-wise sample weighting, '\n                             'you should pass a 2D sample_weight array.')\n    else:\n        if sample_weight is not None and len(sample_weight.shape) != 1:\n            raise ValueError('Found a sample_weight array with shape ' +\n                             str(sample_weight.shape) + '. '\n                             'In order to use timestep-wise sample weights, '\n                             'you should specify '\n                             'sample_weight_mode=\"temporal\" '\n                             'in compile(). If you just mean to use '\n                             'sample-wise weights, make sure your '\n                             'sample_weight array is 1D.')\n\n    if sample_weight is not None:\n        if len(sample_weight.shape) > len(y.shape):\n            raise ValueError('Found a sample_weight with shape' +\n                             str(sample_weight.shape) + '.'\n                             'Expected sample_weight with rank '\n                             'less than or equal to ' + str(len(y.shape)))\n\n        if y.shape[:sample_weight.ndim] != sample_weight.shape:\n            raise ValueError('Found a sample_weight array with shape ' +\n                             str(sample_weight.shape) + ' for an input with shape ' +\n                             str(y.shape) + '. '\n                             'sample_weight cannot be broadcast.')\n        return sample_weight\n    elif isinstance(class_weight, dict):\n        if len(y.shape) > 2:\n            raise ValueError('`class_weight` not supported for '\n                             '3+ dimensional targets.')\n        if y.shape[1] > 1:\n            y_classes = np.argmax(y, axis=1)\n        elif y.shape[1] == 1:\n            y_classes = np.reshape(y, y.shape[0])\n        else:\n            y_classes = y\n\n        weights = np.asarray([class_weight[cls] for cls in y_classes\n                              if cls in class_weight])\n\n        if len(weights) != len(y_classes):\n            # subtract the sets to pick all missing classes\n            existing_classes = set(y_classes)\n            existing_class_weight = set(class_weight.keys())\n            raise ValueError('`class_weight` must contain all classes in the data.'\n                             ' The classes %s exist in the data but not in '\n                             '`class_weight`.'\n                             % (existing_classes - existing_class_weight))\n        return weights\n    else:\n        if sample_weight_mode is None:\n            return np.ones((y.shape[0],), dtype=K.floatx())\n        else:\n            return np.ones((y.shape[0], y.shape[1]), dtype=K.floatx())",
        "begin_line": 451,
        "end_line": 542,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011173184357541898,
            "pseudo_dstar_susp": 0.0005455537370430987,
            "pseudo_tarantula_susp": 0.0014792899408284023,
            "pseudo_op2_susp": 0.0005455537370430987,
            "pseudo_barinel_susp": 0.0014792899408284023
        }
    },
    {
        "name": "keras.engine.training.Model.compile#549",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)",
        "snippet": "    def compile(self, optimizer, loss=None, metrics=None, loss_weights=None,\n                sample_weight_mode=None, weighted_metrics=None,\n                target_tensors=None, **kwargs):\n        \"\"\"Configures the model for training.\n\n        # Arguments\n            optimizer: String (name of optimizer) or optimizer instance.\n                See [optimizers](/optimizers).\n            loss: String (name of objective function) or objective function.\n                See [losses](/losses).\n                If the model has multiple outputs, you can use a different loss\n                on each output by passing a dictionary or a list of losses.\n                The loss value that will be minimized by the model\n                will then be the sum of all individual losses.\n            metrics: List of metrics to be evaluated by the model\n                during training and testing.\n                Typically you will use `metrics=['accuracy']`.\n                To specify different metrics for different outputs of a\n                multi-output model, you could also pass a dictionary,\n                such as `metrics={'output_a': 'accuracy'}`.\n            loss_weights: Optional list or dictionary specifying scalar\n                coefficients (Python floats) to weight the loss contributions\n                of different model outputs.\n                The loss value that will be minimized by the model\n                will then be the *weighted sum* of all individual losses,\n                weighted by the `loss_weights` coefficients.\n                If a list, it is expected to have a 1:1 mapping\n                to the model's outputs. If a tensor, it is expected to map\n                output names (strings) to scalar coefficients.\n            sample_weight_mode: If you need to do timestep-wise\n                sample weighting (2D weights), set this to `\"temporal\"`.\n                `None` defaults to sample-wise weights (1D).\n                If the model has multiple outputs, you can use a different\n                `sample_weight_mode` on each output by passing a\n                dictionary or a list of modes.\n            weighted_metrics: List of metrics to be evaluated and weighted\n                by sample_weight or class_weight during training and testing.\n            target_tensors: By default, Keras will create placeholders for the\n                model's target, which will be fed with the target data during\n                training. If instead you would like to use your own\n                target tensors (in turn, Keras will not expect external\n                Numpy data for these targets at training time), you\n                can specify them via the `target_tensors` argument. It can be\n                a single tensor (for a single-output model), a list of tensors,\n                or a dict mapping output names to target tensors.\n            **kwargs: When using the Theano/CNTK backends, these arguments\n                are passed into `K.function`.\n                When using the TensorFlow backend,\n                these arguments are passed into `tf.Session.run`.\n\n        # Raises\n            ValueError: In case of invalid arguments for\n                `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n        \"\"\"\n        loss = loss or {}\n        self.optimizer = optimizers.get(optimizer)\n        self.loss = loss\n        self.loss_weights = loss_weights\n        self.sample_weight_mode = sample_weight_mode\n\n        # Prepare loss functions.\n        if isinstance(loss, dict):\n            for name in loss:\n                if name not in self.output_names:\n                    raise ValueError('Unknown entry in loss '\n                                     'dictionary: \"' + name + '\". '\n                                     'Only expected the following keys: ' +\n                                     str(self.output_names))\n            loss_functions = []\n            for name in self.output_names:\n                if name not in loss:\n                    warnings.warn('Output \"' + name +\n                                  '\" missing from loss dictionary. '\n                                  'We assume this was done on purpose, '\n                                  'and we will not be expecting '\n                                  'any data to be passed to \"' + name +\n                                  '\" during training.', stacklevel=2)\n                loss_functions.append(losses.get(loss.get(name)))\n        elif isinstance(loss, list):\n            if len(loss) != len(self.outputs):\n                raise ValueError('When passing a list as loss, '\n                                 'it should have one entry per model outputs. '\n                                 'The model has ' + str(len(self.outputs)) +\n                                 ' outputs, but you passed loss=' +\n                                 str(loss))\n            loss_functions = [losses.get(l) for l in loss]\n        else:\n            loss_function = losses.get(loss)\n            loss_functions = [loss_function for _ in range(len(self.outputs))]\n        self.loss_functions = loss_functions\n        weighted_losses = [_weighted_masked_objective(fn) for fn in loss_functions]\n        skip_target_indices = []\n        skip_target_weighing_indices = []\n        self._feed_outputs = []\n        self._feed_output_names = []\n        self._feed_output_shapes = []\n        self._feed_loss_fns = []\n        for i in range(len(weighted_losses)):\n            if weighted_losses[i] is None:\n                skip_target_indices.append(i)\n                skip_target_weighing_indices.append(i)\n\n        # Prepare output masks.\n        masks = self.compute_mask(self.inputs, mask=None)\n        if masks is None:\n            masks = [None for _ in self.outputs]\n        if not isinstance(masks, list):\n            masks = [masks]\n\n        # Prepare loss weights.\n        if loss_weights is None:\n            loss_weights_list = [1. for _ in range(len(self.outputs))]\n        elif isinstance(loss_weights, dict):\n            for name in loss_weights:\n                if name not in self.output_names:\n                    raise ValueError('Unknown entry in loss_weights '\n                                     'dictionary: \"' + name + '\". '\n                                     'Only expected the following keys: ' +\n                                     str(self.output_names))\n            loss_weights_list = []\n            for name in self.output_names:\n                loss_weights_list.append(loss_weights.get(name, 1.))\n        elif isinstance(loss_weights, list):\n            if len(loss_weights) != len(self.outputs):\n                raise ValueError('When passing a list as loss_weights, '\n                                 'it should have one entry per model output. '\n                                 'The model has ' + str(len(self.outputs)) +\n                                 ' outputs, but you passed loss_weights=' +\n                                 str(loss_weights))\n            loss_weights_list = loss_weights\n        else:\n            raise TypeError('Could not interpret loss_weights argument: ' +\n                            str(loss_weights) +\n                            ' - expected a list of dicts.')\n\n        # Prepare targets of model.\n        self.targets = []\n        self._feed_targets = []\n        if target_tensors is not None:\n            if isinstance(target_tensors, list):\n                if len(target_tensors) != len(self.outputs):\n                    raise ValueError(\n                        'When passing a list as `target_tensors`, '\n                        'it should have one entry per model output. '\n                        'The model has ' + str(len(self.outputs)) +\n                        ' outputs, but you passed target_tensors=' +\n                        str(target_tensors))\n            elif isinstance(target_tensors, dict):\n                for name in target_tensors:\n                    if name not in self.output_names:\n                        raise ValueError('Unknown entry in `target_tensors` '\n                                         'dictionary: \"' + name + '\". '\n                                         'Only expected the following keys: ' +\n                                         str(self.output_names))\n                tmp_target_tensors = []\n                for name in self.output_names:\n                    tmp_target_tensors.append(target_tensors.get(name, None))\n                target_tensors = tmp_target_tensors\n            else:\n                raise TypeError('Expected `target_tensors` to be '\n                                'a list or dict, but got:', target_tensors)\n        for i in range(len(self.outputs)):\n            if i in skip_target_indices:\n                self.targets.append(None)\n            else:\n                shape = self._internal_output_shapes[i]\n                name = self.output_names[i]\n                if target_tensors is not None:\n                    target = target_tensors[i]\n                else:\n                    target = None\n                if target is None or K.is_placeholder(target):\n                    if target is None:\n                        target = K.placeholder(ndim=len(shape),\n                                               name=name + '_target',\n                                               sparse=K.is_sparse(self.outputs[i]),\n                                               dtype=K.dtype(self.outputs[i]))\n                    self._feed_targets.append(target)\n                    self._feed_outputs.append(self.outputs[i])\n                    self._feed_output_names.append(name)\n                    self._feed_output_shapes.append(shape)\n                    self._feed_loss_fns.append(self.loss_functions[i])\n                else:\n                    skip_target_weighing_indices.append(i)\n                self.targets.append(target)\n\n        # Prepare sample weights.\n        sample_weights = []\n        sample_weight_modes = []\n        if isinstance(sample_weight_mode, dict):\n            for name in sample_weight_mode:\n                if name not in self.output_names:\n                    raise ValueError('Unknown entry in '\n                                     'sample_weight_mode dictionary: \"' +\n                                     name + '\". '\n                                     'Only expected the following keys: ' +\n                                     str(self.output_names))\n            for i, name in enumerate(self.output_names):\n                if i in skip_target_weighing_indices:\n                    weight = None\n                    sample_weight_modes.append(None)\n                else:\n                    if name not in sample_weight_mode:\n                        raise ValueError('Output \"' + name +\n                                         '\" missing from sample_weight_modes '\n                                         'dictionary')\n                    if sample_weight_mode.get(name) == 'temporal':\n                        weight = K.placeholder(ndim=2,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append('temporal')\n                    else:\n                        weight = K.placeholder(ndim=1,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append(None)\n                sample_weights.append(weight)\n        elif isinstance(sample_weight_mode, list):\n            if len(sample_weight_mode) != len(self.outputs):\n                raise ValueError('When passing a list as sample_weight_mode, '\n                                 'it should have one entry per model output. '\n                                 'The model has ' + str(len(self.outputs)) +\n                                 ' outputs, but you passed '\n                                 'sample_weight_mode=' +\n                                 str(sample_weight_mode))\n            for i in range(len(self.output_names)):\n                if i in skip_target_weighing_indices:\n                    weight = None\n                    sample_weight_modes.append(None)\n                else:\n                    mode = sample_weight_mode[i]\n                    name = self.output_names[i]\n                    if mode == 'temporal':\n                        weight = K.placeholder(ndim=2,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append('temporal')\n                    else:\n                        weight = K.placeholder(ndim=1,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append(None)\n                sample_weights.append(weight)\n        else:\n            for i, name in enumerate(self.output_names):\n                if i in skip_target_weighing_indices:\n                    sample_weight_modes.append(None)\n                    sample_weights.append(None)\n                else:\n                    if sample_weight_mode == 'temporal':\n                        sample_weights.append(\n                            K.placeholder(ndim=2,\n                                          name=name + '_sample_weights'))\n                        sample_weight_modes.append('temporal')\n                    else:\n                        sample_weights.append(\n                            K.placeholder(ndim=1,\n                                          name=name + '_sample_weights'))\n                        sample_weight_modes.append(None)\n        self.sample_weight_modes = sample_weight_modes\n        self._feed_sample_weight_modes = []\n        for i in range(len(self.outputs)):\n            if i not in skip_target_weighing_indices:\n                self._feed_sample_weight_modes.append(self.sample_weight_modes[i])\n\n        # Prepare metrics.\n        self.metrics = metrics or []\n        self.weighted_metrics = weighted_metrics\n        self.metrics_names = ['loss']\n        self.metrics_tensors = []\n\n        # Compute total loss.\n        total_loss = None\n        with K.name_scope('loss'):\n            for i in range(len(self.outputs)):\n                if i in skip_target_indices:\n                    continue\n                y_true = self.targets[i]\n                y_pred = self.outputs[i]\n                weighted_loss = weighted_losses[i]\n                sample_weight = sample_weights[i]\n                mask = masks[i]\n                loss_weight = loss_weights_list[i]\n                with K.name_scope(self.output_names[i] + '_loss'):\n                    output_loss = weighted_loss(y_true, y_pred,\n                                                sample_weight, mask)\n                if len(self.outputs) > 1:\n                    self.metrics_tensors.append(output_loss)\n                    self.metrics_names.append(self.output_names[i] + '_loss')\n                if total_loss is None:\n                    total_loss = loss_weight * output_loss\n                else:\n                    total_loss += loss_weight * output_loss\n            if total_loss is None:\n                if not self.losses:\n                    raise ValueError('The model cannot be compiled '\n                                     'because it has no loss to optimize.')\n                else:\n                    total_loss = 0.\n\n            # Add regularization penalties\n            # and other layer-specific losses.\n            for loss_tensor in self.losses:\n                total_loss += loss_tensor\n\n        # List of same size as output_names.\n        # contains tuples (metrics for output, names of metrics).\n        nested_metrics = _collect_metrics(metrics, self.output_names)\n        nested_weighted_metrics = _collect_metrics(weighted_metrics, self.output_names)\n        self.metrics_updates = []\n        self.stateful_metric_names = []\n        with K.name_scope('metrics'):\n            for i in range(len(self.outputs)):\n                if i in skip_target_indices:\n                    continue\n\n                y_true = self.targets[i]\n                y_pred = self.outputs[i]\n                weights = sample_weights[i]\n                output_metrics = nested_metrics[i]\n                output_weighted_metrics = nested_weighted_metrics[i]\n\n                def handle_metrics(metrics, weights=None):\n                    metric_name_prefix = 'weighted_' if weights is not None else ''\n\n                    for metric in metrics:\n                        if metric in ('accuracy', 'acc', 'crossentropy', 'ce'):\n                            # custom handling of accuracy/crossentropy\n                            # (because of class mode duality)\n                            output_shape = self._internal_output_shapes[i]\n                            if (output_shape[-1] == 1 or\n                               self.loss_functions[i] == losses.binary_crossentropy):\n                                # case: binary accuracy/crossentropy\n                                if metric in ('accuracy', 'acc'):\n                                    metric_fn = metrics_module.binary_accuracy\n                                elif metric in ('crossentropy', 'ce'):\n                                    metric_fn = metrics_module.binary_crossentropy\n                            elif self.loss_functions[i] == losses.sparse_categorical_crossentropy:\n                                # case: categorical accuracy/crossentropy with sparse targets\n                                if metric in ('accuracy', 'acc'):\n                                    metric_fn = metrics_module.sparse_categorical_accuracy\n                                elif metric in ('crossentropy', 'ce'):\n                                    metric_fn = metrics_module.sparse_categorical_crossentropy\n                            else:\n                                # case: categorical accuracy/crossentropy\n                                if metric in ('accuracy', 'acc'):\n                                    metric_fn = metrics_module.categorical_accuracy\n                                elif metric in ('crossentropy', 'ce'):\n                                    metric_fn = metrics_module.categorical_crossentropy\n                            if metric in ('accuracy', 'acc'):\n                                    suffix = 'acc'\n                            elif metric in ('crossentropy', 'ce'):\n                                    suffix = 'ce'\n                            weighted_metric_fn = _weighted_masked_objective(metric_fn)\n                            metric_name = metric_name_prefix + suffix\n                        else:\n                            metric_fn = metrics_module.get(metric)\n                            weighted_metric_fn = _weighted_masked_objective(metric_fn)\n                            # Get metric name as string\n                            if hasattr(metric_fn, 'name'):\n                                metric_name = metric_fn.name\n                            else:\n                                metric_name = metric_fn.__name__\n                            metric_name = metric_name_prefix + metric_name\n\n                        with K.name_scope(metric_name):\n                            metric_result = weighted_metric_fn(y_true, y_pred,\n                                                               weights=weights,\n                                                               mask=masks[i])\n\n                        # Append to self.metrics_names, self.metric_tensors,\n                        # self.stateful_metric_names\n                        if len(self.output_names) > 1:\n                            metric_name = self.output_names[i] + '_' + metric_name\n                        # Dedupe name\n                        j = 1\n                        base_metric_name = metric_name\n                        while metric_name in self.metrics_names:\n                            metric_name = base_metric_name + '_' + str(j)\n                            j += 1\n                        self.metrics_names.append(metric_name)\n                        self.metrics_tensors.append(metric_result)\n\n                        # Keep track of state updates created by\n                        # stateful metrics (i.e. metrics layers).\n                        if isinstance(metric_fn, Layer):\n                            self.stateful_metric_names.append(metric_name)\n                            self.metrics_updates += metric_fn.updates\n\n                handle_metrics(output_metrics)\n                handle_metrics(output_weighted_metrics, weights=weights)\n\n        # Prepare gradient updates and state updates.\n        self.total_loss = total_loss\n        self.sample_weights = sample_weights\n        self._feed_sample_weights = []\n        for i in range(len(self.sample_weights)):\n            if i not in skip_target_weighing_indices:\n                self._feed_sample_weights.append(sample_weights[i])\n\n        # Functions for train, test and predict will\n        # be compiled lazily when required.\n        # This saves time when the user is not using all functions.\n        self._function_kwargs = kwargs\n\n        self.train_function = None\n        self.test_function = None\n        self.predict_function = None\n\n        # Collected trainable weights, sorted in topological order.\n        trainable_weights = self.trainable_weights\n        self._collected_trainable_weights = trainable_weights",
        "begin_line": 549,
        "end_line": 956,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006476683937823834,
            "pseudo_dstar_susp": 0.0018832391713747645,
            "pseudo_tarantula_susp": 0.00041203131437989287,
            "pseudo_op2_susp": 0.0018832391713747645,
            "pseudo_barinel_susp": 0.00041203131437989287
        }
    },
    {
        "name": "keras.engine.training.Model.handle_metrics#867",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.handle_metrics(metrics, weights=None)",
        "snippet": "                def handle_metrics(metrics, weights=None):\n                    metric_name_prefix = 'weighted_' if weights is not None else ''\n\n                    for metric in metrics:\n                        if metric in ('accuracy', 'acc', 'crossentropy', 'ce'):\n                            # custom handling of accuracy/crossentropy\n                            # (because of class mode duality)\n                            output_shape = self._internal_output_shapes[i]\n                            if (output_shape[-1] == 1 or\n                               self.loss_functions[i] == losses.binary_crossentropy):\n                                # case: binary accuracy/crossentropy\n                                if metric in ('accuracy', 'acc'):\n                                    metric_fn = metrics_module.binary_accuracy\n                                elif metric in ('crossentropy', 'ce'):\n                                    metric_fn = metrics_module.binary_crossentropy\n                            elif self.loss_functions[i] == losses.sparse_categorical_crossentropy:\n                                # case: categorical accuracy/crossentropy with sparse targets\n                                if metric in ('accuracy', 'acc'):\n                                    metric_fn = metrics_module.sparse_categorical_accuracy\n                                elif metric in ('crossentropy', 'ce'):\n                                    metric_fn = metrics_module.sparse_categorical_crossentropy\n                            else:\n                                # case: categorical accuracy/crossentropy\n                                if metric in ('accuracy', 'acc'):\n                                    metric_fn = metrics_module.categorical_accuracy\n                                elif metric in ('crossentropy', 'ce'):\n                                    metric_fn = metrics_module.categorical_crossentropy\n                            if metric in ('accuracy', 'acc'):\n                                    suffix = 'acc'\n                            elif metric in ('crossentropy', 'ce'):\n                                    suffix = 'ce'\n                            weighted_metric_fn = _weighted_masked_objective(metric_fn)\n                            metric_name = metric_name_prefix + suffix\n                        else:\n                            metric_fn = metrics_module.get(metric)\n                            weighted_metric_fn = _weighted_masked_objective(metric_fn)\n                            # Get metric name as string\n                            if hasattr(metric_fn, 'name'):\n                                metric_name = metric_fn.name\n                            else:\n                                metric_name = metric_fn.__name__\n                            metric_name = metric_name_prefix + metric_name\n\n                        with K.name_scope(metric_name):\n                            metric_result = weighted_metric_fn(y_true, y_pred,\n                                                               weights=weights,\n                                                               mask=masks[i])\n\n                        # Append to self.metrics_names, self.metric_tensors,\n                        # self.stateful_metric_names\n                        if len(self.output_names) > 1:\n                            metric_name = self.output_names[i] + '_' + metric_name\n                        # Dedupe name\n                        j = 1\n                        base_metric_name = metric_name\n                        while metric_name in self.metrics_names:\n                            metric_name = base_metric_name + '_' + str(j)\n                            j += 1\n                        self.metrics_names.append(metric_name)\n                        self.metrics_tensors.append(metric_result)\n\n                        # Keep track of state updates created by\n                        # stateful metrics (i.e. metrics layers).\n                        if isinstance(metric_fn, Layer):\n                            self.stateful_metric_names.append(metric_name)\n                            self.metrics_updates += metric_fn.updates",
        "begin_line": 867,
        "end_line": 932,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000641025641025641,
            "pseudo_dstar_susp": 0.0018726591760299626,
            "pseudo_tarantula_susp": 0.0009140767824497258,
            "pseudo_op2_susp": 0.0018726591760299626,
            "pseudo_barinel_susp": 0.0009140767824497258
        }
    },
    {
        "name": "keras.engine.training.Model._check_trainable_weights_consistency#958",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._check_trainable_weights_consistency(self)",
        "snippet": "    def _check_trainable_weights_consistency(self):\n        \"\"\"Check trainable weights count consistency.\n\n        This will raise a warning if `trainable_weights` and\n        `_collected_trainable_weights` are inconsistent (i.e. have different\n        number of parameters).\n        Inconsistency will typically arise when one modifies `model.trainable`\n        without calling `model.compile` again.\n        \"\"\"\n        if not hasattr(self, '_collected_trainable_weights'):\n            return\n\n        if (len(self.trainable_weights) !=\n                len(self._collected_trainable_weights)):\n            warnings.warn(UserWarning(\n                'Discrepancy between trainable weights and collected trainable'\n                ' weights, did you set `model.trainable` without calling'\n                ' `model.compile` after ?'))",
        "begin_line": 958,
        "end_line": 975,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013812154696132596,
            "pseudo_dstar_susp": 0.0010460251046025104,
            "pseudo_tarantula_susp": 0.0017761989342806395,
            "pseudo_op2_susp": 0.0010460251046025104,
            "pseudo_barinel_susp": 0.0017761989342806395
        }
    },
    {
        "name": "keras.engine.training.Model._make_train_function#977",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._make_train_function(self)",
        "snippet": "    def _make_train_function(self):\n        if not hasattr(self, 'train_function'):\n            raise RuntimeError('You must compile your model before using it.')\n        self._check_trainable_weights_consistency()\n        if self.train_function is None:\n            inputs = self._feed_inputs + self._feed_targets + self._feed_sample_weights\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                inputs += [K.learning_phase()]\n\n            with K.name_scope('training'):\n                with K.name_scope(self.optimizer.__class__.__name__):\n                    training_updates = self.optimizer.get_updates(\n                        params=self._collected_trainable_weights,\n                        loss=self.total_loss)\n                updates = self.updates + training_updates + self.metrics_updates\n                # Gets loss and metrics. Updates weights at each call.\n                self.train_function = K.function(inputs,\n                                                 [self.total_loss] + self.metrics_tensors,\n                                                 updates=updates,\n                                                 name='train_function',\n                                                 **self._function_kwargs)",
        "begin_line": 977,
        "end_line": 997,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003629764065335753,
            "pseudo_dstar_susp": 0.0003629764065335753,
            "pseudo_tarantula_susp": 0.00036403349108117945,
            "pseudo_op2_susp": 0.0003629764065335753,
            "pseudo_barinel_susp": 0.00036403349108117945
        }
    },
    {
        "name": "keras.engine.training.Model._make_test_function#999",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._make_test_function(self)",
        "snippet": "    def _make_test_function(self):\n        if not hasattr(self, 'test_function'):\n            raise RuntimeError('You must compile your model before using it.')\n        if self.test_function is None:\n            inputs = self._feed_inputs + self._feed_targets + self._feed_sample_weights\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                inputs += [K.learning_phase()]\n            # Return loss and metrics, no gradient updates.\n            # Does update the network states.\n            self.test_function = K.function(inputs,\n                                            [self.total_loss] + self.metrics_tensors,\n                                            updates=self.state_updates + self.metrics_updates,\n                                            name='test_function',\n                                            **self._function_kwargs)",
        "begin_line": 999,
        "end_line": 1012,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004887585532746823,
            "pseudo_dstar_susp": 0.0004450378282153983,
            "pseudo_tarantula_susp": 0.0008038585209003215,
            "pseudo_op2_susp": 0.0004450378282153983,
            "pseudo_barinel_susp": 0.0008038585209003215
        }
    },
    {
        "name": "keras.engine.training.Model._make_predict_function#1014",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._make_predict_function(self)",
        "snippet": "    def _make_predict_function(self):\n        if not hasattr(self, 'predict_function'):\n            self.predict_function = None\n        if self.predict_function is None:\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                inputs = self._feed_inputs + [K.learning_phase()]\n            else:\n                inputs = self._feed_inputs\n            # Gets network outputs. Does not update weights.\n            # Does update the network states.\n            kwargs = getattr(self, '_function_kwargs', {})\n            self.predict_function = K.function(inputs,\n                                               self.outputs,\n                                               updates=self.state_updates,\n                                               name='predict_function',\n                                               **kwargs)",
        "begin_line": 1014,
        "end_line": 1029,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.640586797066015e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.training.Model._check_num_samples#1031",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._check_num_samples(self, ins, batch_size=None, steps=None, steps_name='steps')",
        "snippet": "    def _check_num_samples(self, ins, batch_size=None, steps=None, steps_name='steps'):\n        \"\"\"Determine the number of samples provided for training and evaluation.\n\n        The number of samples is not defined when running with `steps`,\n        in which case the number of samples is set to `None`.\n\n        # Arguments\n            ins: List of tensors to be fed to the Keras function.\n            batch_size: Integer batch size or `None` if not defined.\n            steps: Total number of steps (batches of samples)\n                before declaring `_predict_loop` finished.\n                Ignored with the default value of `None`.\n            steps_name: The public API's parameter name for `steps`.\n\n        # Raises\n            ValueError: when `steps` is `None` and the attribute `ins.shape`\n            does not exist. Also raises ValueError when `steps` is not `None`\n            and `batch_size` is not `None` because they are mutually\n            exclusive.\n\n        # Returns\n            When steps is `None`, returns the number of samples to be\n            processed based on the size of the first dimension of the\n            first input numpy array. When steps is not `None` and\n            `batch_size` is `None`, returns `None`.\n\n        # Raises\n            ValueError: In case of invalid arguments.\n        \"\"\"\n        if steps is not None:\n            num_samples = None\n            if batch_size is not None:\n                raise ValueError('If ' + steps_name +\n                                 ' is set, the `batch_size` must be None.')\n        elif ins and hasattr(ins[0], 'shape'):\n            num_samples = ins[0].shape[0]\n        else:\n            raise ValueError('Either the input data should have '\n                             'a defined shape, or ' + steps_name +\n                             ' should be specified.')\n        return num_samples",
        "begin_line": 1031,
        "end_line": 1071,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00035124692658939234,
            "pseudo_dstar_susp": 0.00035124692658939234,
            "pseudo_tarantula_susp": 0.00035161744022503517,
            "pseudo_op2_susp": 0.00035124692658939234,
            "pseudo_barinel_susp": 0.00035161744022503517
        }
    },
    {
        "name": "keras.engine.training.Model._fit_loop#1073",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._fit_loop(self, f, ins, out_labels=None, batch_size=None, epochs=100, verbose=1, callbacks=None, val_f=None, val_ins=None, shuffle=True, callback_metrics=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)",
        "snippet": "    def _fit_loop(self, f, ins, out_labels=None, batch_size=None,\n                  epochs=100, verbose=1, callbacks=None,\n                  val_f=None, val_ins=None, shuffle=True,\n                  callback_metrics=None, initial_epoch=0,\n                  steps_per_epoch=None, validation_steps=None):\n        \"\"\"Abstract fit function for `f(ins)`.\n\n        Assume that f returns a list, labeled by out_labels.\n\n        # Arguments\n            f: Keras function returning a list of tensors\n            ins: List of tensors to be fed to `f`\n            out_labels: List of strings, display names of\n                the outputs of `f`\n            batch_size: Integer batch size or None if unknown.\n            epochs: Number of times to iterate over the data\n            verbose: Verbosity mode, 0, 1 or 2\n            callbacks: List of callbacks to be called during training\n            val_f: Keras function to call for validation\n            val_ins: List of tensors to be fed to `val_f`\n            shuffle: Whether to shuffle the data at the beginning of each epoch\n            callback_metrics: List of strings, the display names of the metrics\n                passed to the callbacks. They should be the\n                concatenation of list the display names of the outputs of\n                 `f` and the list of display names of the outputs of `f_val`.\n            initial_epoch: Epoch at which to start training\n                (useful for resuming a previous training run)\n            steps_per_epoch: Total number of steps (batches of samples)\n                before declaring one epoch finished and starting the\n                next epoch. Ignored with the default value of `None`.\n            validation_steps: Number of steps to run validation for\n                (only if doing validation from data tensors).\n                Ignored with the default value of `None`.\n\n        # Returns\n            `History` object.\n        \"\"\"\n        do_validation = False\n        if val_f and val_ins:\n            do_validation = True\n            if verbose and ins and hasattr(ins[0], 'shape') and hasattr(val_ins[0], 'shape'):\n                print('Train on %d samples, validate on %d samples' %\n                      (ins[0].shape[0], val_ins[0].shape[0]))\n        if validation_steps:\n            do_validation = True\n            if steps_per_epoch is None:\n                raise ValueError('Can only use `validation_steps` '\n                                 'when doing step-wise '\n                                 'training, i.e. `steps_per_epoch` '\n                                 'must be set.')\n\n        num_train_samples = self._check_num_samples(ins, batch_size,\n                                                    steps_per_epoch,\n                                                    'steps_per_epoch')\n        if num_train_samples is not None:\n            index_array = np.arange(num_train_samples)\n\n        self.history = cbks.History()\n        _callbacks = [cbks.BaseLogger(\n            stateful_metrics=self.stateful_metric_names)]\n        if verbose:\n            if steps_per_epoch is not None:\n                count_mode = 'steps'\n            else:\n                count_mode = 'samples'\n            _callbacks.append(\n                cbks.ProgbarLogger(\n                    count_mode,\n                    stateful_metrics=self.stateful_metric_names))\n        _callbacks += (callbacks or []) + [self.history]\n        callbacks = cbks.CallbackList(_callbacks)\n        out_labels = out_labels or []\n\n        # it's possible to callback a different model than self\n        # (used by Sequential models)\n        if hasattr(self, 'callback_model') and self.callback_model:\n            callback_model = self.callback_model\n        else:\n            callback_model = self\n\n        callbacks.set_model(callback_model)\n        callbacks.set_params({\n            'batch_size': batch_size,\n            'epochs': epochs,\n            'steps': steps_per_epoch,\n            'samples': num_train_samples,\n            'verbose': verbose,\n            'do_validation': do_validation,\n            'metrics': callback_metrics or [],\n        })\n        callbacks.on_train_begin()\n        callback_model.stop_training = False\n        for cbk in callbacks:\n            cbk.validation_data = val_ins\n\n        # To prevent a slowdown, we find beforehand the arrays that need conversion.\n        feed = self._feed_inputs + self._feed_targets + self._feed_sample_weights\n        indices_for_conversion_to_dense = []\n        for i in range(len(feed)):\n            if issparse(ins[i]) and not K.is_sparse(feed[i]):\n                indices_for_conversion_to_dense.append(i)\n\n        for epoch in range(initial_epoch, epochs):\n            # Reset stateful metrics\n            for m in self.metrics:\n                if isinstance(m, Layer):\n                    m.reset_states()\n            callbacks.on_epoch_begin(epoch)\n            epoch_logs = {}\n            if steps_per_epoch is not None:\n                for step_index in range(steps_per_epoch):\n                    batch_logs = {}\n                    batch_logs['batch'] = step_index\n                    batch_logs['size'] = 1\n                    callbacks.on_batch_begin(step_index, batch_logs)\n                    outs = f(ins)\n\n                    if not isinstance(outs, list):\n                        outs = [outs]\n                    for l, o in zip(out_labels, outs):\n                        batch_logs[l] = o\n\n                    callbacks.on_batch_end(step_index, batch_logs)\n                    if callback_model.stop_training:\n                        break\n\n                if do_validation:\n                    val_outs = self._test_loop(val_f, val_ins,\n                                               batch_size=batch_size,\n                                               steps=validation_steps,\n                                               verbose=0)\n                    if not isinstance(val_outs, list):\n                        val_outs = [val_outs]\n                    # Same labels assumed.\n                    for l, o in zip(out_labels, val_outs):\n                        epoch_logs['val_' + l] = o\n            else:\n                if shuffle == 'batch':\n                    index_array = _batch_shuffle(index_array, batch_size)\n                elif shuffle:\n                    np.random.shuffle(index_array)\n\n                batches = _make_batches(num_train_samples, batch_size)\n                for batch_index, (batch_start, batch_end) in enumerate(batches):\n                    batch_ids = index_array[batch_start:batch_end]\n                    try:\n                        if isinstance(ins[-1], float):\n                            # Do not slice the training phase flag.\n                            ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n                        else:\n                            ins_batch = _slice_arrays(ins, batch_ids)\n                    except TypeError:\n                        raise TypeError('TypeError while preparing batch. '\n                                        'If using HDF5 input data, '\n                                        'pass shuffle=\"batch\".')\n                    batch_logs = {}\n                    batch_logs['batch'] = batch_index\n                    batch_logs['size'] = len(batch_ids)\n                    callbacks.on_batch_begin(batch_index, batch_logs)\n                    for i in indices_for_conversion_to_dense:\n                        ins_batch[i] = ins_batch[i].toarray()\n\n                    outs = f(ins_batch)\n                    if not isinstance(outs, list):\n                        outs = [outs]\n                    for l, o in zip(out_labels, outs):\n                        batch_logs[l] = o\n\n                    callbacks.on_batch_end(batch_index, batch_logs)\n                    if callback_model.stop_training:\n                        break\n\n                    if batch_index == len(batches) - 1:  # Last batch.\n                        if do_validation:\n                            val_outs = self._test_loop(val_f, val_ins,\n                                                       batch_size=batch_size,\n                                                       verbose=0)\n                            if not isinstance(val_outs, list):\n                                val_outs = [val_outs]\n                            # Same labels assumed.\n                            for l, o in zip(out_labels, val_outs):\n                                epoch_logs['val_' + l] = o\n            callbacks.on_epoch_end(epoch, epoch_logs)\n            if callback_model.stop_training:\n                break\n        callbacks.on_train_end()\n        return self.history",
        "begin_line": 1073,
        "end_line": 1259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.training.Model._predict_loop#1261",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._predict_loop(self, f, ins, batch_size=32, verbose=0, steps=None)",
        "snippet": "    def _predict_loop(self, f, ins, batch_size=32, verbose=0, steps=None):\n        \"\"\"Abstract method to loop over some data in batches.\n\n        # Arguments\n            f: Keras function returning a list of tensors.\n            ins: list of tensors to be fed to `f`.\n            batch_size: integer batch size.\n            verbose: verbosity mode.\n            steps: Total number of steps (batches of samples)\n                before declaring `_predict_loop` finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            Array of predictions (if the model has a single output)\n            or list of arrays of predictions\n            (if the model has multiple outputs).\n        \"\"\"\n        num_samples = self._check_num_samples(ins, batch_size,\n                                              steps,\n                                              'steps')\n        if verbose == 1:\n            if steps is not None:\n                progbar = Progbar(target=steps)\n            else:\n                progbar = Progbar(target=num_samples)\n\n        indices_for_conversion_to_dense = []\n        for i in range(len(self._feed_inputs)):\n            if issparse(ins[i]) and not K.is_sparse(self._feed_inputs[i]):\n                indices_for_conversion_to_dense.append(i)\n\n        if steps is not None:\n            # Step-based predictions.\n            # Since we do not know how many samples\n            # we will see, we cannot pre-allocate\n            # the returned Numpy arrays.\n            # Instead, we store one array per batch seen\n            # and concatenate them upon returning.\n            unconcatenated_outs = []\n            for step in range(steps):\n                batch_outs = f(ins)\n                if not isinstance(batch_outs, list):\n                    batch_outs = [batch_outs]\n                if step == 0:\n                    for batch_out in batch_outs:\n                        unconcatenated_outs.append([])\n                for i, batch_out in enumerate(batch_outs):\n                    unconcatenated_outs[i].append(batch_out)\n                if verbose == 1:\n                    progbar.update(step + 1)\n            if len(unconcatenated_outs) == 1:\n                return np.concatenate(unconcatenated_outs[0], axis=0)\n            return [np.concatenate(unconcatenated_outs[i], axis=0)\n                    for i in range(len(unconcatenated_outs))]\n        else:\n            # Sample-based predictions.\n            outs = []\n            batches = _make_batches(num_samples, batch_size)\n            index_array = np.arange(num_samples)\n            for batch_index, (batch_start, batch_end) in enumerate(batches):\n                batch_ids = index_array[batch_start:batch_end]\n                if ins and isinstance(ins[-1], float):\n                    # Do not slice the training phase flag.\n                    ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n                else:\n                    ins_batch = _slice_arrays(ins, batch_ids)\n                for i in indices_for_conversion_to_dense:\n                    ins_batch[i] = ins_batch[i].toarray()\n\n                batch_outs = f(ins_batch)\n                if not isinstance(batch_outs, list):\n                    batch_outs = [batch_outs]\n                if batch_index == 0:\n                    # Pre-allocate the results arrays.\n                    for batch_out in batch_outs:\n                        shape = (num_samples,) + batch_out.shape[1:]\n                        outs.append(np.zeros(shape, dtype=batch_out.dtype))\n                for i, batch_out in enumerate(batch_outs):\n                    outs[i][batch_start:batch_end] = batch_out\n                if verbose == 1:\n                    progbar.update(batch_end)\n            if len(outs) == 1:\n                return outs[0]\n            return outs",
        "begin_line": 1261,
        "end_line": 1344,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.training.Model._test_loop#1346",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._test_loop(self, f, ins, batch_size=None, verbose=0, steps=None)",
        "snippet": "    def _test_loop(self, f, ins, batch_size=None, verbose=0, steps=None):\n        \"\"\"Abstract method to loop over some data in batches.\n\n        # Arguments\n            f: Keras function returning a list of tensors.\n            ins: list of tensors to be fed to `f`.\n            batch_size: integer batch size or `None`.\n            verbose: verbosity mode.\n            steps: Total number of steps (batches of samples)\n                before declaring predictions finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            Scalar loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n\n        if hasattr(self, 'metrics'):\n            for m in self.metrics:\n                if isinstance(m, Layer):\n                    m.reset_states()\n            stateful_metric_indices = [\n                i for i, name in enumerate(self.metrics_names)\n                if str(name) in self.stateful_metric_names]\n        else:\n            stateful_metric_indices = []\n\n        num_samples = self._check_num_samples(ins, batch_size,\n                                              steps,\n                                              'steps')\n        outs = []\n        if verbose == 1:\n            if steps is not None:\n                progbar = Progbar(target=steps)\n            else:\n                progbar = Progbar(target=num_samples)\n\n        # To prevent a slowdown, we find beforehand the arrays that need conversion.\n        feed = self._feed_inputs + self._feed_targets + self._feed_sample_weights\n        indices_for_conversion_to_dense = []\n        for i in range(len(feed)):\n            if issparse(ins[i]) and not K.is_sparse(feed[i]):\n                indices_for_conversion_to_dense.append(i)\n\n        if steps is not None:\n            for step in range(steps):\n                batch_outs = f(ins)\n                if isinstance(batch_outs, list):\n                    if step == 0:\n                        for _ in enumerate(batch_outs):\n                            outs.append(0.)\n                    for i, batch_out in enumerate(batch_outs):\n                        if i in stateful_metric_indices:\n                            outs[i] = batch_out\n                        else:\n                            outs[i] += batch_out\n                else:\n                    if step == 0:\n                        outs.append(0.)\n                    outs[0] += batch_outs\n                if verbose == 1:\n                    progbar.update(step + 1)\n            for i in range(len(outs)):\n                if i not in stateful_metric_indices:\n                    outs[i] /= steps\n        else:\n            batches = _make_batches(num_samples, batch_size)\n            index_array = np.arange(num_samples)\n            for batch_index, (batch_start, batch_end) in enumerate(batches):\n                batch_ids = index_array[batch_start:batch_end]\n                if isinstance(ins[-1], float):\n                    # Do not slice the training phase flag.\n                    ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n                else:\n                    ins_batch = _slice_arrays(ins, batch_ids)\n                for i in indices_for_conversion_to_dense:\n                    ins_batch[i] = ins_batch[i].toarray()\n\n                batch_outs = f(ins_batch)\n                if isinstance(batch_outs, list):\n                    if batch_index == 0:\n                        for batch_out in enumerate(batch_outs):\n                            outs.append(0.)\n                    for i, batch_out in enumerate(batch_outs):\n                        if i in stateful_metric_indices:\n                            outs[i] = batch_out\n                        else:\n                            outs[i] += batch_out * len(batch_ids)\n                else:\n                    if batch_index == 0:\n                        outs.append(0.)\n                    outs[0] += batch_outs * len(batch_ids)\n\n                if verbose == 1:\n                    progbar.update(batch_end)\n            for i in range(len(outs)):\n                if i not in stateful_metric_indices:\n                    outs[i] /= num_samples\n        if len(outs) == 1:\n            return outs[0]\n        return outs",
        "begin_line": 1346,
        "end_line": 1448,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000794912559618442,
            "pseudo_dstar_susp": 0.0011185682326621924,
            "pseudo_tarantula_susp": 0.0013003901170351106,
            "pseudo_op2_susp": 0.0011185682326621924,
            "pseudo_barinel_susp": 0.0013003901170351106
        }
    },
    {
        "name": "keras.engine.training.Model._standardize_user_data#1450",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._standardize_user_data(self, x, y, sample_weight=None, class_weight=None, check_array_lengths=True, batch_size=None)",
        "snippet": "    def _standardize_user_data(self, x, y,\n                               sample_weight=None, class_weight=None,\n                               check_array_lengths=True, batch_size=None):\n        if not hasattr(self, 'optimizer'):\n            raise RuntimeError('You must compile a model before '\n                               'training/testing. '\n                               'Use `model.compile(optimizer, loss)`.')\n\n        output_shapes = []\n        for output_shape, loss_fn in zip(self._feed_output_shapes, self._feed_loss_fns):\n            if loss_fn is losses.sparse_categorical_crossentropy:\n                output_shapes.append(output_shape[:-1] + (1,))\n            elif (not hasattr(loss_fn, '__name__') or\n                  getattr(losses, loss_fn.__name__, None) is None):\n                # If `loss_fn` is not a function (e.g. callable class)\n                # or if it not in the `losses` module, then\n                # it is a user-defined loss and we make no assumptions\n                # about it.\n                output_shapes.append(None)\n            else:\n                output_shapes.append(output_shape)\n        # `check_batch_axis` is set to False since `x` may contain multiple batches\n        #  and in general `x[0].shape[0] != self._feed_input_shapes[0][0]`\n        x = _standardize_input_data(x, self._feed_input_names,\n                                    self._feed_input_shapes,\n                                    check_batch_axis=False,\n                                    exception_prefix='input')\n        y = _standardize_input_data(y, self._feed_output_names,\n                                    output_shapes,\n                                    check_batch_axis=False,\n                                    exception_prefix='target')\n        sample_weights = _standardize_sample_weights(sample_weight,\n                                                     self._feed_output_names)\n        class_weights = _standardize_class_weights(class_weight,\n                                                   self._feed_output_names)\n        sample_weights = [_standardize_weights(ref, sw, cw, mode)\n                          for (ref, sw, cw, mode)\n                          in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\n        if check_array_lengths:\n            _check_array_lengths(x, y, sample_weights)\n        _check_loss_and_target_compatibility(y,\n                                             self._feed_loss_fns,\n                                             self._feed_output_shapes)\n        if self.stateful and batch_size:\n            if x[0].shape[0] % batch_size != 0:\n                raise ValueError('In a stateful network, '\n                                 'you should only pass inputs with '\n                                 'a number of samples that can be '\n                                 'divided by the batch size. Found: ' +\n                                 str(x[0].shape[0]) + ' samples')\n        return x, y, sample_weights",
        "begin_line": 1450,
        "end_line": 1501,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003766478342749529,
            "pseudo_dstar_susp": 0.0008460236886632825,
            "pseudo_tarantula_susp": 0.00036403349108117945,
            "pseudo_op2_susp": 0.0008460236886632825,
            "pseudo_barinel_susp": 0.00036403349108117945
        }
    },
    {
        "name": "keras.engine.training.Model.fit#1503",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs)",
        "snippet": "    def fit(self,\n            x=None,\n            y=None,\n            batch_size=None,\n            epochs=1,\n            verbose=1,\n            callbacks=None,\n            validation_split=0.,\n            validation_data=None,\n            shuffle=True,\n            class_weight=None,\n            sample_weight=None,\n            initial_epoch=0,\n            steps_per_epoch=None,\n            validation_steps=None,\n            **kwargs):\n        \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n\n        # Arguments\n            x: Numpy array of training data (if the model has a single input),\n                or list of Numpy arrays (if the model has multiple inputs).\n                If input layers in the model are named, you can also pass a\n                dictionary mapping input names to Numpy arrays.\n                `x` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            y: Numpy array of target (label) data\n                (if the model has a single output),\n                or list of Numpy arrays (if the model has multiple outputs).\n                If output layers in the model are named, you can also pass a\n                dictionary mapping output names to Numpy arrays.\n                `y` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            batch_size: Integer or `None`.\n                Number of samples per gradient update.\n                If unspecified, `batch_size` will default to 32.\n            epochs: Integer. Number of epochs to train the model.\n                An epoch is an iteration over the entire `x` and `y`\n                data provided.\n                Note that in conjunction with `initial_epoch`,\n                `epochs` is to be understood as \"final epoch\".\n                The model is not trained for a number of iterations\n                given by `epochs`, but merely until the epoch\n                of index `epochs` is reached.\n            verbose: Integer. 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = progress bar, 2 = one line per epoch.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during training.\n                See [callbacks](/callbacks).\n            validation_split: Float between 0 and 1.\n                Fraction of the training data to be used as validation data.\n                The model will set apart this fraction of the training data,\n                will not train on it, and will evaluate\n                the loss and any model metrics\n                on this data at the end of each epoch.\n                The validation data is selected from the last samples\n                in the `x` and `y` data provided, before shuffling.\n            validation_data: tuple `(x_val, y_val)` or tuple\n                `(x_val, y_val, val_sample_weights)` on which to evaluate\n                the loss and any model metrics at the end of each epoch.\n                The model will not be trained on this data.\n                `validation_data` will override `validation_split`.\n            shuffle: Boolean (whether to shuffle the training data\n                before each epoch) or str (for 'batch').\n                'batch' is a special option for dealing with the\n                limitations of HDF5 data; it shuffles in batch-sized chunks.\n                Has no effect when `steps_per_epoch` is not `None`.\n            class_weight: Optional dictionary mapping class indices (integers)\n                to a weight (float) value, used for weighting the loss function\n                (during training only).\n                This can be useful to tell the model to\n                \"pay more attention\" to samples from\n                an under-represented class.\n            sample_weight: Optional Numpy array of weights for\n                the training samples, used for weighting the loss function\n                (during training only). You can either pass a flat (1D)\n                Numpy array with the same length as the input samples\n                (1:1 mapping between weights and samples),\n                or in the case of temporal data,\n                you can pass a 2D array with shape\n                `(samples, sequence_length)`,\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                `sample_weight_mode=\"temporal\"` in `compile()`.\n            initial_epoch: Integer.\n                Epoch at which to start training\n                (useful for resuming a previous training run).\n            steps_per_epoch: Integer or `None`.\n                Total number of steps (batches of samples)\n                before declaring one epoch finished and starting the\n                next epoch. When training with input tensors such as\n                TensorFlow data tensors, the default `None` is equal to\n                the number of samples in your dataset divided by\n                the batch size, or 1 if that cannot be determined.\n            validation_steps: Only relevant if `steps_per_epoch`\n                is specified. Total number of steps (batches of samples)\n                to validate before stopping.\n\n        # Returns\n            A `History` object. Its `History.history` attribute is\n            a record of training loss values and metrics values\n            at successive epochs, as well as validation loss values\n            and validation metrics values (if applicable).\n\n        # Raises\n            RuntimeError: If the model was never compiled.\n            ValueError: In case of mismatch between the provided input data\n                and what the model expects.\n        \"\"\"\n        # Backwards compatibility\n        if batch_size is None and steps_per_epoch is None:\n            batch_size = 32\n        # Legacy support\n        if 'nb_epoch' in kwargs:\n            warnings.warn('The `nb_epoch` argument in `fit` '\n                          'has been renamed `epochs`.', stacklevel=2)\n            epochs = kwargs.pop('nb_epoch')\n        if kwargs:\n            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n        if x is None and y is None and steps_per_epoch is None:\n            raise ValueError('If fitting from data tensors, '\n                             'you should specify the `steps_per_epoch` '\n                             'argument.')\n        # Validate user data.\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            class_weight=class_weight,\n            batch_size=batch_size)\n        # Prepare validation data.\n        do_validation = False\n        if validation_data:\n            do_validation = True\n            if len(validation_data) == 2:\n                val_x, val_y = validation_data\n                val_sample_weight = None\n            elif len(validation_data) == 3:\n                val_x, val_y, val_sample_weight = validation_data\n            else:\n                raise ValueError('When passing validation_data, '\n                                 'it must contain 2 (x_val, y_val) '\n                                 'or 3 (x_val, y_val, val_sample_weights) '\n                                 'items, however it contains %d items' %\n                                 len(validation_data))\n\n            val_x, val_y, val_sample_weights = self._standardize_user_data(\n                val_x, val_y,\n                sample_weight=val_sample_weight,\n                batch_size=batch_size)\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                val_ins = val_x + val_y + val_sample_weights + [0.]\n            else:\n                val_ins = val_x + val_y + val_sample_weights\n\n        elif validation_split and 0. < validation_split < 1.:\n            do_validation = True\n            if hasattr(x[0], 'shape'):\n                split_at = int(x[0].shape[0] * (1. - validation_split))\n            else:\n                split_at = int(len(x[0]) * (1. - validation_split))\n            x, val_x = (_slice_arrays(x, 0, split_at), _slice_arrays(x, split_at))\n            y, val_y = (_slice_arrays(y, 0, split_at), _slice_arrays(y, split_at))\n            sample_weights, val_sample_weights = (\n                _slice_arrays(sample_weights, 0, split_at),\n                _slice_arrays(sample_weights, split_at))\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                val_ins = val_x + val_y + val_sample_weights + [0.]\n            else:\n                val_ins = val_x + val_y + val_sample_weights\n\n        elif validation_steps:\n            do_validation = True\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                val_ins = [0.]\n\n        # Prepare input arrays and training function.\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + y + sample_weights + [1.]\n        else:\n            ins = x + y + sample_weights\n        self._make_train_function()\n        f = self.train_function\n\n        # Prepare display labels.\n        out_labels = self.metrics_names\n\n        if do_validation:\n            self._make_test_function()\n            val_f = self.test_function\n            callback_metrics = copy.copy(out_labels) + ['val_' + n for n in out_labels]\n        else:\n            callback_metrics = copy.copy(out_labels)\n            val_f = None\n            val_ins = []\n\n        # Delegate logic to `_fit_loop`.\n        return self._fit_loop(f, ins, out_labels=out_labels,\n                              batch_size=batch_size, epochs=epochs,\n                              verbose=verbose, callbacks=callbacks,\n                              val_f=val_f, val_ins=val_ins, shuffle=shuffle,\n                              callback_metrics=callback_metrics,\n                              initial_epoch=initial_epoch,\n                              steps_per_epoch=steps_per_epoch,\n                              validation_steps=validation_steps)",
        "begin_line": 1503,
        "end_line": 1705,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.training.Model.evaluate#1707",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)",
        "snippet": "    def evaluate(self, x=None, y=None,\n                 batch_size=None,\n                 verbose=1,\n                 sample_weight=None,\n                 steps=None):\n        \"\"\"Returns the loss value & metrics values for the model in test mode.\n\n        Computation is done in batches.\n\n        # Arguments\n            x: Numpy array of test data (if the model has a single input),\n                or list of Numpy arrays (if the model has multiple inputs).\n                If input layers in the model are named, you can also pass a\n                dictionary mapping input names to Numpy arrays.\n                `x` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            y: Numpy array of target (label) data\n                (if the model has a single output),\n                or list of Numpy arrays (if the model has multiple outputs).\n                If output layers in the model are named, you can also pass a\n                dictionary mapping output names to Numpy arrays.\n                `y` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            batch_size: Integer or `None`.\n                Number of samples per evaluation step.\n                If unspecified, `batch_size` will default to 32.\n            verbose: 0 or 1. Verbosity mode.\n                0 = silent, 1 = progress bar.\n            sample_weight: Optional Numpy array of weights for\n                the test samples, used for weighting the loss function.\n                You can either pass a flat (1D)\n                Numpy array with the same length as the input samples\n                (1:1 mapping between weights and samples),\n                or in the case of temporal data,\n                you can pass a 2D array with shape\n                `(samples, sequence_length)`,\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                `sample_weight_mode=\"temporal\"` in `compile()`.\n            steps: Integer or `None`.\n                Total number of steps (batches of samples)\n                before declaring the evaluation round finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n        # Backwards compatibility.\n        if batch_size is None and steps is None:\n            batch_size = 32\n        if x is None and y is None and steps is None:\n            raise ValueError('If evaluating from data tensors, '\n                             'you should specify the `steps` '\n                             'argument.')\n        # Validate user data.\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            batch_size=batch_size)\n        # Prepare inputs, delegate logic to `_test_loop`.\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + y + sample_weights + [0.]\n        else:\n            ins = x + y + sample_weights\n        self._make_test_function()\n        f = self.test_function\n        return self._test_loop(f, ins,\n                               batch_size=batch_size,\n                               verbose=verbose,\n                               steps=steps)",
        "begin_line": 1707,
        "end_line": 1779,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006397952655150352,
            "pseudo_dstar_susp": 0.0004868549172346641,
            "pseudo_tarantula_susp": 0.0010976948408342481,
            "pseudo_op2_susp": 0.0004868549172346641,
            "pseudo_barinel_susp": 0.0010976948408342481
        }
    },
    {
        "name": "keras.engine.training.Model.predict#1781",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.predict(self, x, batch_size=None, verbose=0, steps=None)",
        "snippet": "    def predict(self, x,\n                batch_size=None,\n                verbose=0,\n                steps=None):\n        \"\"\"Generates output predictions for the input samples.\n\n        Computation is done in batches.\n\n        # Arguments\n            x: The input data, as a Numpy array\n                (or list of Numpy arrays if the model has multiple outputs).\n            batch_size: Integer. If unspecified, it will default to 32.\n            verbose: Verbosity mode, 0 or 1.\n            steps: Total number of steps (batches of samples)\n                before declaring the prediction round finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            Numpy array(s) of predictions.\n\n        # Raises\n            ValueError: In case of mismatch between the provided\n                input data and the model's expectations,\n                or in case a stateful model receives a number of samples\n                that is not a multiple of the batch size.\n        \"\"\"\n        # Backwards compatibility.\n        if batch_size is None and steps is None:\n            batch_size = 32\n        if x is None and steps is None:\n            raise ValueError('If predicting from data tensors, '\n                             'you should specify the `steps` '\n                             'argument.')\n        # Validate user data.\n        x = _standardize_input_data(x, self._feed_input_names,\n                                    self._feed_input_shapes,\n                                    check_batch_axis=False)\n        if self.stateful:\n            if x[0].shape[0] > batch_size and x[0].shape[0] % batch_size != 0:\n                raise ValueError('In a stateful network, '\n                                 'you should only pass inputs with '\n                                 'a number of samples that can be '\n                                 'divided by the batch size. Found: ' +\n                                 str(x[0].shape[0]) + ' samples. '\n                                 'Batch size: ' + str(batch_size) + '.')\n\n        # Prepare inputs, delegate logic to `_predict_loop`.\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + [0.]\n        else:\n            ins = x\n        self._make_predict_function()\n        f = self.predict_function\n        return self._predict_loop(f, ins, batch_size=batch_size,\n                                  verbose=verbose, steps=steps)",
        "begin_line": 1781,
        "end_line": 1835,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.training.Model.train_on_batch#1837",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.train_on_batch(self, x, y, sample_weight=None, class_weight=None)",
        "snippet": "    def train_on_batch(self, x, y,\n                       sample_weight=None,\n                       class_weight=None):\n        \"\"\"Runs a single gradient update on a single batch of data.\n\n        # Arguments\n            x: Numpy array of training data,\n                or list of Numpy arrays if the model has multiple inputs.\n                If all inputs in the model are named,\n                you can also pass a dictionary\n                mapping input names to Numpy arrays.\n            y: Numpy array of target data,\n                or list of Numpy arrays if the model has multiple outputs.\n                If all outputs in the model are named,\n                you can also pass a dictionary\n                mapping output names to Numpy arrays.\n            sample_weight: Optional array of the same length as x, containing\n                weights to apply to the model's loss for each sample.\n                In the case of temporal data, you can pass a 2D array\n                with shape (samples, sequence_length),\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                sample_weight_mode=\"temporal\" in compile().\n            class_weight: Optional dictionary mapping\n                class indices (integers) to\n                a weight (float) to apply to the model's loss for the samples\n                from this class during training.\n                This can be useful to tell the model to \"pay more attention\" to\n                samples from an under-represented class.\n\n        # Returns\n            Scalar training loss\n            (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            class_weight=class_weight)\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + y + sample_weights + [1.]\n        else:\n            ins = x + y + sample_weights\n        self._make_train_function()\n        outputs = self.train_function(ins)\n        if len(outputs) == 1:\n            return outputs[0]\n        return outputs",
        "begin_line": 1837,
        "end_line": 1886,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003755163349605708,
            "pseudo_dstar_susp": 0.000375234521575985,
            "pseudo_tarantula_susp": 0.00041118421052631577,
            "pseudo_op2_susp": 0.000375234521575985,
            "pseudo_barinel_susp": 0.00041118421052631577
        }
    },
    {
        "name": "keras.engine.training.Model.test_on_batch#1888",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.test_on_batch(self, x, y, sample_weight=None)",
        "snippet": "    def test_on_batch(self, x, y, sample_weight=None):\n        \"\"\"Test the model on a single batch of samples.\n\n        # Arguments\n            x: Numpy array of test data,\n                or list of Numpy arrays if the model has multiple inputs.\n                If all inputs in the model are named,\n                you can also pass a dictionary\n                mapping input names to Numpy arrays.\n            y: Numpy array of target data,\n                or list of Numpy arrays if the model has multiple outputs.\n                If all outputs in the model are named,\n                you can also pass a dictionary\n                mapping output names to Numpy arrays.\n            sample_weight: Optional array of the same length as x, containing\n                weights to apply to the model's loss for each sample.\n                In the case of temporal data, you can pass a 2D array\n                with shape (samples, sequence_length),\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                sample_weight_mode=\"temporal\" in compile().\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight)\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + y + sample_weights + [0.]\n        else:\n            ins = x + y + sample_weights\n        self._make_test_function()\n        outputs = self.test_function(ins)\n        if len(outputs) == 1:\n            return outputs[0]\n        return outputs",
        "begin_line": 1888,
        "end_line": 1927,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0019083969465648854,
            "pseudo_dstar_susp": 0.0006361323155216285,
            "pseudo_tarantula_susp": 0.002531645569620253,
            "pseudo_op2_susp": 0.0006361323155216285,
            "pseudo_barinel_susp": 0.002531645569620253
        }
    },
    {
        "name": "keras.engine.training.Model.predict_on_batch#1929",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.predict_on_batch(self, x)",
        "snippet": "    def predict_on_batch(self, x):\n        \"\"\"Returns predictions for a single batch of samples.\n\n        # Arguments\n            x: Input samples, as a Numpy array.\n\n        # Returns\n            Numpy array(s) of predictions.\n        \"\"\"\n        x = _standardize_input_data(x, self._feed_input_names,\n                                    self._feed_input_shapes)\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + [0.]\n        else:\n            ins = x\n        self._make_predict_function()\n        outputs = self.predict_function(ins)\n        if len(outputs) == 1:\n            return outputs[0]\n        return outputs",
        "begin_line": 1929,
        "end_line": 1948,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.engine.training.Model.fit_generator#1951",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)",
        "snippet": "    def fit_generator(self,\n                      generator,\n                      steps_per_epoch=None,\n                      epochs=1,\n                      verbose=1,\n                      callbacks=None,\n                      validation_data=None,\n                      validation_steps=None,\n                      class_weight=None,\n                      max_queue_size=10,\n                      workers=1,\n                      use_multiprocessing=False,\n                      shuffle=True,\n                      initial_epoch=0):\n        \"\"\"Trains the model on data yielded batch-by-batch by a Python generator.\n\n        The generator is run in parallel to the model, for efficiency.\n        For instance, this allows you to do real-time data augmentation\n        on images on CPU in parallel to training your model on GPU.\n\n        The use of `keras.utils.Sequence` guarantees the ordering\n        and guarantees the single use of every input per epoch when\n        using `use_multiprocessing=True`.\n\n        # Arguments\n            generator: A generator or an instance of `Sequence`\n                (`keras.utils.Sequence`) object in order to avoid\n                duplicate data when using multiprocessing.\n                The output of the generator must be either\n                - a tuple `(inputs, targets)`\n                - a tuple `(inputs, targets, sample_weights)`.\n                This tuple (a single output of the generator) makes a single\n                batch. Therefore, all arrays in this tuple must have the same\n                length (equal to the size of this batch). Different batches\n                may have different sizes. For example, the last batch of the\n                epoch is commonly smaller than the others, if the size of the\n                dataset is not divisible by the batch size.\n                The generator is expected to loop over its data\n                indefinitely. An epoch finishes when `steps_per_epoch`\n                batches have been seen by the model.\n            steps_per_epoch: Integer.\n                Total number of steps (batches of samples)\n                to yield from `generator` before declaring one epoch\n                finished and starting the next epoch. It should typically\n                be equal to the number of samples of your dataset\n                divided by the batch size.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n            epochs: Integer. Number of epochs to train the model.\n                An epoch is an iteration over the entire data provided,\n                as defined by `steps_per_epoch`.\n                Note that in conjunction with `initial_epoch`,\n                `epochs` is to be understood as \"final epoch\".\n                The model is not trained for a number of iterations\n                given by `epochs`, but merely until the epoch\n                of index `epochs` is reached.\n            verbose: Integer. 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = progress bar, 2 = one line per epoch.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during training.\n                See [callbacks](/callbacks).\n            validation_data: This can be either\n                - a generator for the validation data\n                - tuple `(x_val, y_val)`\n                - tuple `(x_val, y_val, val_sample_weights)`\n                on which to evaluate\n                the loss and any model metrics at the end of each epoch.\n                The model will not be trained on this data.\n            validation_steps: Only relevant if `validation_data`\n                is a generator. Total number of steps (batches of samples)\n                to yield from `validation_data` generator before stopping.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(validation_data)` as a number of steps.\n            class_weight: Optional dictionary mapping class indices (integers)\n                to a weight (float) value, used for weighting the loss function\n                (during training only).\n                This can be useful to tell the model to\n                \"pay more attention\" to samples from\n                an under-represented class.\n            max_queue_size: Integer. Maximum size for the generator queue.\n                If unspecified, `max_queue_size` will default to 10.\n            workers: Integer. Maximum number of processes to spin up\n                when using process based threading.\n                If unspecified, `workers` will default to 1. If 0, will\n                execute the generator on the main thread.\n            use_multiprocessing: Boolean. If True, use process based threading.\n                If unspecified, `use_multiprocessing` will default to False.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can't be passed\n                easily to children processes.\n            shuffle: Boolean. Whether to shuffle the training data\n                in batch-sized chunks before each epoch.\n                Only used with instances of `Sequence` (`keras.utils.Sequence`).\n            initial_epoch: Integer.\n                Epoch at which to start training\n                (useful for resuming a previous training run).\n\n        # Returns\n            A `History` object. Its `History.history` attribute is\n            a record of training loss values and metrics values\n            at successive epochs, as well as validation loss values\n            and validation metrics values (if applicable).\n\n        # Example\n\n        ```python\n            def generate_arrays_from_file(path):\n                while 1:\n                    with open(path) as f:\n                        for line in f:\n                            # create numpy arrays of input data\n                            # and labels, from each line in the file\n                            x1, x2, y = process_line(line)\n                            yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n\n            model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n                                steps_per_epoch=10000, epochs=10)\n        ```\n\n        # Raises\n            ValueError: In case the generator yields\n                data in an invalid format.\n        \"\"\"\n        wait_time = 0.01  # in seconds\n        epoch = initial_epoch\n\n        do_validation = bool(validation_data)\n        self._make_train_function()\n        if do_validation:\n            self._make_test_function()\n\n        is_sequence = isinstance(generator, Sequence)\n        if not is_sequence and use_multiprocessing and workers > 1:\n            warnings.warn(\n                UserWarning('Using a generator with `use_multiprocessing=True`'\n                            ' and multiple workers may duplicate your data.'\n                            ' Please consider using the`keras.utils.Sequence'\n                            ' class.'))\n        if steps_per_epoch is None:\n            if is_sequence:\n                steps_per_epoch = len(generator)\n            else:\n                raise ValueError('`steps_per_epoch=None` is only valid for a'\n                                 ' generator based on the `keras.utils.Sequence`'\n                                 ' class. Please specify `steps_per_epoch` or use'\n                                 ' the `keras.utils.Sequence` class.')\n\n        # python 2 has 'next', 3 has '__next__'\n        # avoid any explicit version checks\n        val_gen = (hasattr(validation_data, 'next') or\n                   hasattr(validation_data, '__next__') or\n                   isinstance(validation_data, Sequence))\n        if (val_gen and not isinstance(validation_data, Sequence) and\n                not validation_steps):\n            raise ValueError('`validation_steps=None` is only valid for a'\n                             ' generator based on the `keras.utils.Sequence`'\n                             ' class. Please specify `validation_steps` or use'\n                             ' the `keras.utils.Sequence` class.')\n\n        # Prepare display labels.\n        out_labels = self.metrics_names\n        callback_metrics = out_labels + ['val_' + n for n in out_labels]\n\n        # prepare callbacks\n        self.history = cbks.History()\n        _callbacks = [cbks.BaseLogger(\n            stateful_metrics=self.stateful_metric_names)]\n        if verbose:\n            _callbacks.append(\n                cbks.ProgbarLogger(\n                    count_mode='steps',\n                    stateful_metrics=self.stateful_metric_names))\n        _callbacks += (callbacks or []) + [self.history]\n        callbacks = cbks.CallbackList(_callbacks)\n\n        # it's possible to callback a different model than self:\n        if hasattr(self, 'callback_model') and self.callback_model:\n            callback_model = self.callback_model\n        else:\n            callback_model = self\n        callbacks.set_model(callback_model)\n        callbacks.set_params({\n            'epochs': epochs,\n            'steps': steps_per_epoch,\n            'verbose': verbose,\n            'do_validation': do_validation,\n            'metrics': callback_metrics,\n        })\n        callbacks.on_train_begin()\n\n        enqueuer = None\n        val_enqueuer = None\n\n        try:\n            if do_validation:\n                if val_gen:\n                    if workers > 0:\n                        if isinstance(validation_data, Sequence):\n                            val_enqueuer = OrderedEnqueuer(\n                                validation_data,\n                                use_multiprocessing=use_multiprocessing)\n                            if validation_steps is None:\n                                validation_steps = len(validation_data)\n                        else:\n                            val_enqueuer = GeneratorEnqueuer(\n                                validation_data,\n                                use_multiprocessing=use_multiprocessing,\n                                wait_time=wait_time)\n                        val_enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                        validation_generator = val_enqueuer.get()\n                    else:\n                        validation_generator = validation_data\n                else:\n                    if len(validation_data) == 2:\n                        val_x, val_y = validation_data\n                        val_sample_weight = None\n                    elif len(validation_data) == 3:\n                        val_x, val_y, val_sample_weight = validation_data\n                    else:\n                        raise ValueError('`validation_data` should be a tuple '\n                                         '`(val_x, val_y, val_sample_weight)` '\n                                         'or `(val_x, val_y)`. Found: ' +\n                                         str(validation_data))\n                    val_x, val_y, val_sample_weights = self._standardize_user_data(\n                        val_x, val_y, val_sample_weight)\n                    val_data = val_x + val_y + val_sample_weights\n                    if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                        val_data += [0.]\n                    for cbk in callbacks:\n                        cbk.validation_data = val_data\n\n            if workers > 0:\n                if is_sequence:\n                    enqueuer = OrderedEnqueuer(generator,\n                                               use_multiprocessing=use_multiprocessing,\n                                               shuffle=shuffle)\n                else:\n                    enqueuer = GeneratorEnqueuer(generator,\n                                                 use_multiprocessing=use_multiprocessing,\n                                                 wait_time=wait_time)\n                enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                output_generator = enqueuer.get()\n            else:\n                output_generator = generator\n\n            callback_model.stop_training = False\n            # Construct epoch logs.\n            epoch_logs = {}\n            while epoch < epochs:\n                callbacks.on_epoch_begin(epoch)\n                steps_done = 0\n                batch_index = 0\n                while steps_done < steps_per_epoch:\n                    generator_output = next(output_generator)\n\n                    if not hasattr(generator_output, '__len__'):\n                        raise ValueError('Output of generator should be '\n                                         'a tuple `(x, y, sample_weight)` '\n                                         'or `(x, y)`. Found: ' +\n                                         str(generator_output))\n\n                    if len(generator_output) == 2:\n                        x, y = generator_output\n                        sample_weight = None\n                    elif len(generator_output) == 3:\n                        x, y, sample_weight = generator_output\n                    else:\n                        raise ValueError('Output of generator should be '\n                                         'a tuple `(x, y, sample_weight)` '\n                                         'or `(x, y)`. Found: ' +\n                                         str(generator_output))\n                    # build batch logs\n                    batch_logs = {}\n                    if isinstance(x, list):\n                        batch_size = x[0].shape[0]\n                    elif isinstance(x, dict):\n                        batch_size = list(x.values())[0].shape[0]\n                    else:\n                        batch_size = x.shape[0]\n                    batch_logs['batch'] = batch_index\n                    batch_logs['size'] = batch_size\n                    callbacks.on_batch_begin(batch_index, batch_logs)\n\n                    outs = self.train_on_batch(x, y,\n                                               sample_weight=sample_weight,\n                                               class_weight=class_weight)\n\n                    if not isinstance(outs, list):\n                        outs = [outs]\n                    for l, o in zip(out_labels, outs):\n                        batch_logs[l] = o\n\n                    callbacks.on_batch_end(batch_index, batch_logs)\n\n                    batch_index += 1\n                    steps_done += 1\n\n                    # Epoch finished.\n                    if steps_done >= steps_per_epoch and do_validation:\n                        if val_gen:\n                            val_outs = self.evaluate_generator(\n                                validation_generator,\n                                validation_steps,\n                                workers=0)\n                        else:\n                            # No need for try/except because\n                            # data has already been validated.\n                            val_outs = self.evaluate(\n                                val_x, val_y,\n                                batch_size=batch_size,\n                                sample_weight=val_sample_weights,\n                                verbose=0)\n                        if not isinstance(val_outs, list):\n                            val_outs = [val_outs]\n                        # Same labels assumed.\n                        for l, o in zip(out_labels, val_outs):\n                            epoch_logs['val_' + l] = o\n\n                    if callback_model.stop_training:\n                        break\n\n                callbacks.on_epoch_end(epoch, epoch_logs)\n                epoch += 1\n                if callback_model.stop_training:\n                    break\n\n        finally:\n            try:\n                if enqueuer is not None:\n                    enqueuer.stop()\n            finally:\n                if val_enqueuer is not None:\n                    val_enqueuer.stop()\n\n        callbacks.on_train_end()\n        return self.history",
        "begin_line": 1951,
        "end_line": 2289,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0011695906432748538,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0011695906432748538,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.engine.training.Model.evaluate_generator#2292",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.evaluate_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False)",
        "snippet": "    def evaluate_generator(self, generator, steps=None,\n                           max_queue_size=10,\n                           workers=1,\n                           use_multiprocessing=False):\n        \"\"\"Evaluates the model on a data generator.\n\n        The generator should return the same kind of data\n        as accepted by `test_on_batch`.\n\n        # Arguments\n            generator: Generator yielding tuples (inputs, targets)\n                or (inputs, targets, sample_weights)\n                or an instance of Sequence (keras.utils.Sequence)\n                object in order to avoid duplicate data\n                when using multiprocessing.\n            steps: Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n            max_queue_size: maximum size for the generator queue\n            workers: Integer. Maximum number of processes to spin up\n                when using process based threading.\n                If unspecified, `workers` will default to 1. If 0, will\n                execute the generator on the main thread.\n            use_multiprocessing: if True, use process based threading.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can't be passed\n                easily to children processes.\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            ValueError: In case the generator yields\n                data in an invalid format.\n        \"\"\"\n        self._make_test_function()\n\n        steps_done = 0\n        wait_time = 0.01\n        all_outs = []\n        batch_sizes = []\n        is_sequence = isinstance(generator, Sequence)\n        if not is_sequence and use_multiprocessing and workers > 1:\n            warnings.warn(\n                UserWarning('Using a generator with `use_multiprocessing=True`'\n                            ' and multiple workers may duplicate your data.'\n                            ' Please consider using the`keras.utils.Sequence'\n                            ' class.'))\n        if steps is None:\n            if is_sequence:\n                steps = len(generator)\n            else:\n                raise ValueError('`steps=None` is only valid for a generator'\n                                 ' based on the `keras.utils.Sequence` class.'\n                                 ' Please specify `steps` or use the'\n                                 ' `keras.utils.Sequence` class.')\n        enqueuer = None\n\n        try:\n            if workers > 0:\n                if is_sequence:\n                    enqueuer = OrderedEnqueuer(generator,\n                                               use_multiprocessing=use_multiprocessing)\n                else:\n                    enqueuer = GeneratorEnqueuer(generator,\n                                                 use_multiprocessing=use_multiprocessing,\n                                                 wait_time=wait_time)\n                enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                output_generator = enqueuer.get()\n            else:\n                output_generator = generator\n\n            while steps_done < steps:\n                generator_output = next(output_generator)\n                if not hasattr(generator_output, '__len__'):\n                    raise ValueError('Output of generator should be a tuple '\n                                     '(x, y, sample_weight) '\n                                     'or (x, y). Found: ' +\n                                     str(generator_output))\n                if len(generator_output) == 2:\n                    x, y = generator_output\n                    sample_weight = None\n                elif len(generator_output) == 3:\n                    x, y, sample_weight = generator_output\n                else:\n                    raise ValueError('Output of generator should be a tuple '\n                                     '(x, y, sample_weight) '\n                                     'or (x, y). Found: ' +\n                                     str(generator_output))\n                outs = self.test_on_batch(x, y, sample_weight=sample_weight)\n\n                if isinstance(x, list):\n                    batch_size = x[0].shape[0]\n                elif isinstance(x, dict):\n                    batch_size = list(x.values())[0].shape[0]\n                else:\n                    batch_size = x.shape[0]\n                if batch_size == 0:\n                    raise ValueError('Received an empty batch. '\n                                     'Batches should at least contain one item.')\n                all_outs.append(outs)\n\n                steps_done += 1\n                batch_sizes.append(batch_size)\n\n        finally:\n            if enqueuer is not None:\n                enqueuer.stop()\n\n        if not isinstance(outs, list):\n            return np.average(np.asarray(all_outs),\n                              weights=batch_sizes)\n        else:\n            averages = []\n            for i in range(len(outs)):\n                averages.append(np.average([out[i] for out in all_outs],\n                                           weights=batch_sizes))\n            return averages",
        "begin_line": 2292,
        "end_line": 2416,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.023809523809523808,
            "pseudo_dstar_susp": 0.0008156606851549756,
            "pseudo_tarantula_susp": 0.02564102564102564,
            "pseudo_op2_susp": 0.0008156606851549756,
            "pseudo_barinel_susp": 0.02564102564102564
        }
    },
    {
        "name": "keras.engine.training.Model.predict_generator#2419",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)",
        "snippet": "    def predict_generator(self, generator, steps=None,\n                          max_queue_size=10,\n                          workers=1,\n                          use_multiprocessing=False,\n                          verbose=0):\n        \"\"\"Generates predictions for the input samples from a data generator.\n\n        The generator should return the same kind of data as accepted by\n        `predict_on_batch`.\n\n        # Arguments\n            generator: Generator yielding batches of input samples\n                or an instance of Sequence (keras.utils.Sequence)\n                object in order to avoid duplicate data\n                when using multiprocessing.\n            steps: Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n            max_queue_size: Maximum size for the generator queue.\n            workers: Integer. Maximum number of processes to spin up\n                when using process based threading.\n                If unspecified, `workers` will default to 1. If 0, will\n                execute the generator on the main thread.\n            use_multiprocessing: If `True`, use process based threading.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can't be passed\n                easily to children processes.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            Numpy array(s) of predictions.\n\n        # Raises\n            ValueError: In case the generator yields\n                data in an invalid format.\n        \"\"\"\n        self._make_predict_function()\n\n        steps_done = 0\n        wait_time = 0.01\n        all_outs = []\n        is_sequence = isinstance(generator, Sequence)\n        if not is_sequence and use_multiprocessing and workers > 1:\n            warnings.warn(\n                UserWarning('Using a generator with `use_multiprocessing=True`'\n                            ' and multiple workers may duplicate your data.'\n                            ' Please consider using the`keras.utils.Sequence'\n                            ' class.'))\n        if steps is None:\n            if is_sequence:\n                steps = len(generator)\n            else:\n                raise ValueError('`steps=None` is only valid for a generator'\n                                 ' based on the `keras.utils.Sequence` class.'\n                                 ' Please specify `steps` or use the'\n                                 ' `keras.utils.Sequence` class.')\n        enqueuer = None\n\n        try:\n            if workers > 0:\n                if is_sequence:\n                    enqueuer = OrderedEnqueuer(generator,\n                                               use_multiprocessing=use_multiprocessing)\n                else:\n                    enqueuer = GeneratorEnqueuer(generator,\n                                                 use_multiprocessing=use_multiprocessing,\n                                                 wait_time=wait_time)\n                enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                output_generator = enqueuer.get()\n            else:\n                output_generator = generator\n\n            if verbose == 1:\n                progbar = Progbar(target=steps)\n\n            while steps_done < steps:\n                generator_output = next(output_generator)\n                if isinstance(generator_output, tuple):\n                    # Compatibility with the generators\n                    # used for training.\n                    if len(generator_output) == 2:\n                        x, _ = generator_output\n                    elif len(generator_output) == 3:\n                        x, _, _ = generator_output\n                    else:\n                        raise ValueError('Output of generator should be '\n                                         'a tuple `(x, y, sample_weight)` '\n                                         'or `(x, y)`. Found: ' +\n                                         str(generator_output))\n                else:\n                    # Assumes a generator that only\n                    # yields inputs (not targets and sample weights).\n                    x = generator_output\n\n                outs = self.predict_on_batch(x)\n                if not isinstance(outs, list):\n                    outs = [outs]\n\n                if not all_outs:\n                    for out in outs:\n                        all_outs.append([])\n\n                for i, out in enumerate(outs):\n                    all_outs[i].append(out)\n                steps_done += 1\n                if verbose == 1:\n                    progbar.update(steps_done)\n\n        finally:\n            if enqueuer is not None:\n                enqueuer.stop()\n\n        if len(all_outs) == 1:\n            if steps_done == 1:\n                return all_outs[0][0]\n            else:\n                return np.concatenate(all_outs[0])\n        if steps_done == 1:\n            return [out[0] for out in all_outs]\n        else:\n            return [np.concatenate(out) for out in all_outs]",
        "begin_line": 2419,
        "end_line": 2543,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.xception.Xception#50",
        "src_path": "keras/applications/xception.py",
        "class_name": "keras.applications.xception",
        "signature": "keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def Xception(include_top=True, weights='imagenet',\n             input_tensor=None, input_shape=None,\n             pooling=None,\n             classes=1000):\n    \"\"\"Instantiates the Xception architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. This model is available for TensorFlow only,\n    and can only be used with inputs following the TensorFlow\n    data format `(width, height, channels)`.\n    You should set `image_data_format='channels_last'` in your Keras config\n    located at ~/.keras/keras.json.\n\n    Note that the default input image size for this model is 299x299.\n\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(299, 299, 3)`.\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 71.\n            E.g. `(150, 150, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    \"\"\"\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    if K.backend() != 'tensorflow':\n        raise RuntimeError('The Xception model is only available with '\n                           'the TensorFlow backend.')\n    if K.image_data_format() != 'channels_last':\n        warnings.warn('The Xception model is only available for the '\n                      'input data format \"channels_last\" '\n                      '(width, height, channels). '\n                      'However your settings specify the default '\n                      'data format \"channels_first\" (channels, width, height). '\n                      'You should set `image_data_format=\"channels_last\"` in your Keras '\n                      'config located at ~/.keras/keras.json. '\n                      'The model being returned right now will expect inputs '\n                      'to follow the \"channels_last\" data format.')\n        K.set_image_data_format('channels_last')\n        old_data_format = 'channels_first'\n    else:\n        old_data_format = None\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=299,\n                                      min_size=71,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=False,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, name='block1_conv1')(img_input)\n    x = BatchNormalization(name='block1_conv1_bn')(x)\n    x = Activation('relu', name='block1_conv1_act')(x)\n    x = Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n    x = BatchNormalization(name='block1_conv2_bn')(x)\n    x = Activation('relu', name='block1_conv2_act')(x)\n\n    residual = Conv2D(128, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv1')(x)\n    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n    x = Activation('relu', name='block2_sepconv2_act')(x)\n    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv2')(x)\n    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block2_pool')(x)\n    x = layers.add([x, residual])\n\n    residual = Conv2D(256, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = Activation('relu', name='block3_sepconv1_act')(x)\n    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv1')(x)\n    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n    x = Activation('relu', name='block3_sepconv2_act')(x)\n    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv2')(x)\n    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block3_pool')(x)\n    x = layers.add([x, residual])\n\n    residual = Conv2D(728, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = Activation('relu', name='block4_sepconv1_act')(x)\n    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv1')(x)\n    x = BatchNormalization(name='block4_sepconv1_bn')(x)\n    x = Activation('relu', name='block4_sepconv2_act')(x)\n    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv2')(x)\n    x = BatchNormalization(name='block4_sepconv2_bn')(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block4_pool')(x)\n    x = layers.add([x, residual])\n\n    for i in range(8):\n        residual = x\n        prefix = 'block' + str(i + 5)\n\n        x = Activation('relu', name=prefix + '_sepconv1_act')(x)\n        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv1')(x)\n        x = BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n        x = Activation('relu', name=prefix + '_sepconv2_act')(x)\n        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv2')(x)\n        x = BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n        x = Activation('relu', name=prefix + '_sepconv3_act')(x)\n        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv3')(x)\n        x = BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n\n        x = layers.add([x, residual])\n\n    residual = Conv2D(1024, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = Activation('relu', name='block13_sepconv1_act')(x)\n    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block13_sepconv1')(x)\n    x = BatchNormalization(name='block13_sepconv1_bn')(x)\n    x = Activation('relu', name='block13_sepconv2_act')(x)\n    x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False, name='block13_sepconv2')(x)\n    x = BatchNormalization(name='block13_sepconv2_bn')(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block13_pool')(x)\n    x = layers.add([x, residual])\n\n    x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False, name='block14_sepconv1')(x)\n    x = BatchNormalization(name='block14_sepconv1_bn')(x)\n    x = Activation('relu', name='block14_sepconv1_act')(x)\n\n    x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')(x)\n    x = BatchNormalization(name='block14_sepconv2_bn')(x)\n    x = Activation('relu', name='block14_sepconv2_act')(x)\n\n    if include_top:\n        x = GlobalAveragePooling2D(name='avg_pool')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='xception')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels.h5',\n                                    TF_WEIGHTS_PATH,\n                                    cache_subdir='models',\n                                    file_hash='0a58e3b7378bc2990ea3b43d5981f1f6')\n        else:\n            weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                    TF_WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models',\n                                    file_hash='b0042744bf5b25fce3cb969f33bebb97')\n        model.load_weights(weights_path)\n    elif weights is not None:\n        model.load_weights(weights)\n\n    if old_data_format:\n        K.set_image_data_format(old_data_format)\n    return model",
        "begin_line": 50,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.applications.xception.preprocess_input#272",
        "src_path": "keras/applications/xception.py",
        "class_name": "keras.applications.xception",
        "signature": "keras.applications.xception.preprocess_input(x)",
        "snippet": "def preprocess_input(x):\n    \"\"\"Preprocesses a numpy array encoding a batch of images.\n\n    # Arguments\n        x: a 4D numpy array consists of RGB values within [0, 255].\n\n    # Returns\n        Preprocessed array.\n    \"\"\"\n    return imagenet_utils.preprocess_input(x, mode='tf')",
        "begin_line": 272,
        "end_line": 281,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.datasets.cifar100.load_data#14",
        "src_path": "keras/datasets/cifar100.py",
        "class_name": "keras.datasets.cifar100",
        "signature": "keras.datasets.cifar100.load_data(label_mode='fine')",
        "snippet": "def load_data(label_mode='fine'):\n    \"\"\"Loads CIFAR100 dataset.\n\n    # Arguments\n        label_mode: one of \"fine\", \"coarse\".\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n\n    # Raises\n        ValueError: in case of invalid `label_mode`.\n    \"\"\"\n    if label_mode not in ['fine', 'coarse']:\n        raise ValueError('`label_mode` must be one of `\"fine\"`, `\"coarse\"`.')\n\n    dirname = 'cifar-100-python'\n    origin = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n    path = get_file(dirname, origin=origin, untar=True)\n\n    fpath = os.path.join(path, 'train')\n    x_train, y_train = load_batch(fpath, label_key=label_mode + '_labels')\n\n    fpath = os.path.join(path, 'test')\n    x_test, y_test = load_batch(fpath, label_key=label_mode + '_labels')\n\n    y_train = np.reshape(y_train, (len(y_train), 1))\n    y_test = np.reshape(y_test, (len(y_test), 1))\n\n    if K.image_data_format() == 'channels_last':\n        x_train = x_train.transpose(0, 2, 3, 1)\n        x_test = x_test.transpose(0, 2, 3, 1)\n\n    return (x_train, y_train), (x_test, y_test)",
        "begin_line": 14,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.clip_norm#20",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers",
        "signature": "keras.optimizers.clip_norm(g, c, n)",
        "snippet": "def clip_norm(g, c, n):\n    if c <= 0:  # if clipnorm == 0 no need to add ops to the graph\n        return g\n\n    # tf require using a special op to multiply IndexedSliced by scalar\n    if K.backend() == 'tensorflow':\n        condition = n >= c\n        then_expression = tf.scalar_mul(c / n, g)\n        else_expression = g\n\n        # saving the shape to avoid converting sparse tensor to dense\n        if isinstance(then_expression, tf.Tensor):\n            g_shape = copy.copy(then_expression.get_shape())\n        elif isinstance(then_expression, tf.IndexedSlices):\n            g_shape = copy.copy(then_expression.dense_shape)\n        if condition.dtype != tf.bool:\n            condition = tf.cast(condition, 'bool')\n        g = tf.cond(condition,\n                    lambda: then_expression,\n                    lambda: else_expression)\n        if isinstance(then_expression, tf.Tensor):\n            g.set_shape(g_shape)\n        elif isinstance(then_expression, tf.IndexedSlices):\n            g._dense_shape = g_shape\n    else:\n        g = K.switch(K.greater_equal(n, c), g * c / n, g)\n    return g",
        "begin_line": 20,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Optimizer.__init__#63",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        allowed_kwargs = {'clipnorm', 'clipvalue'}\n        for k in kwargs:\n            if k not in allowed_kwargs:\n                raise TypeError('Unexpected keyword argument '\n                                'passed to optimizer: ' + str(k))\n        self.__dict__.update(kwargs)\n        self.updates = []\n        self.weights = []",
        "begin_line": 63,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00046446818392940084,
            "pseudo_dstar_susp": 0.0009199632014719411,
            "pseudo_tarantula_susp": 0.00039032006245121,
            "pseudo_op2_susp": 0.0009199632014719411,
            "pseudo_barinel_susp": 0.00039032006245121
        }
    },
    {
        "name": "keras.optimizers.Optimizer.get_gradients#77",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.get_gradients(self, loss, params)",
        "snippet": "    def get_gradients(self, loss, params):\n        grads = K.gradients(loss, params)\n        if None in grads:\n            raise ValueError('An operation has `None` for gradient. '\n                             'Please make sure that all of your ops have a '\n                             'gradient defined (i.e. are differentiable). '\n                             'Common ops without gradient: '\n                             'K.argmax, K.round, K.eval.')\n        if hasattr(self, 'clipnorm') and self.clipnorm > 0:\n            norm = K.sqrt(sum([K.sum(K.square(g)) for g in grads]))\n            grads = [clip_norm(g, self.clipnorm, norm) for g in grads]\n        if hasattr(self, 'clipvalue') and self.clipvalue > 0:\n            grads = [K.clip(g, -self.clipvalue, self.clipvalue) for g in grads]\n        return grads",
        "begin_line": 77,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003629764065335753,
            "pseudo_dstar_susp": 0.0003629764065335753,
            "pseudo_tarantula_susp": 0.00036403349108117945,
            "pseudo_op2_susp": 0.0003629764065335753,
            "pseudo_barinel_susp": 0.00036403349108117945
        }
    },
    {
        "name": "keras.optimizers.Optimizer.set_weights#92",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the optimizer, from Numpy arrays.\n\n        Should only be called after computing the gradients\n        (otherwise the optimizer has no weights).\n\n        # Arguments\n            weights: a list of Numpy arrays. The number\n                of arrays and their shape must match\n                number of the dimensions of the weights\n                of the optimizer (i.e. it should match the\n                output of `get_weights`).\n\n        # Raises\n            ValueError: in case of incompatible weight shapes.\n        \"\"\"\n        params = self.weights\n        if len(params) != len(weights):\n            raise ValueError('Length of the specified weight list (' +\n                             str(len(weights)) +\n                             ') does not match the number of weights ' +\n                             'of the optimizer (' + str(len(params)) + ')')\n        weight_value_tuples = []\n        param_values = K.batch_get_value(params)\n        for pv, p, w in zip(param_values, params, weights):\n            if pv.shape != w.shape:\n                raise ValueError('Optimizer weight shape ' +\n                                 str(pv.shape) +\n                                 ' not compatible with '\n                                 'provided weight shape ' + str(w.shape))\n            weight_value_tuples.append((p, w))\n        K.batch_set_value(weight_value_tuples)",
        "begin_line": 92,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Optimizer.get_weights#125",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.get_weights(self)",
        "snippet": "    def get_weights(self):\n        \"\"\"Returns the current value of the weights of the optimizer.\n\n        # Returns\n            A list of numpy arrays.\n        \"\"\"\n        return K.batch_get_value(self.weights)",
        "begin_line": 125,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Optimizer.get_config#133",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {}\n        if hasattr(self, 'clipnorm'):\n            config['clipnorm'] = self.clipnorm\n        if hasattr(self, 'clipvalue'):\n            config['clipvalue'] = self.clipvalue\n        return config",
        "begin_line": 133,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Optimizer.from_config#142",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        return cls(**config)",
        "begin_line": 142,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000493339911198816,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.00040966816878328555,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.00040966816878328555
        }
    },
    {
        "name": "keras.optimizers.SGD.__init__#160",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.SGD",
        "signature": "keras.optimizers.SGD.__init__(self, lr=0.01, momentum=0.0, decay=0.0, nesterov=False, **kwargs)",
        "snippet": "    def __init__(self, lr=0.01, momentum=0., decay=0.,\n                 nesterov=False, **kwargs):\n        super(SGD, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.momentum = K.variable(momentum, name='momentum')\n            self.decay = K.variable(decay, name='decay')\n        self.initial_decay = decay\n        self.nesterov = nesterov",
        "begin_line": 160,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.SGD.get_updates#172",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.SGD",
        "signature": "keras.optimizers.SGD.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n        # momentum\n        shapes = [K.int_shape(p) for p in params]\n        moments = [K.zeros(shape) for shape in shapes]\n        self.weights = [self.iterations] + moments\n        for p, g, m in zip(params, grads, moments):\n            v = self.momentum * m - lr * g  # velocity\n            self.updates.append(K.update(m, v))\n\n            if self.nesterov:\n                new_p = p + self.momentum * v - lr * g\n            else:\n                new_p = p + v\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 172,
        "end_line": 198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.SGD.get_config#200",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.SGD",
        "signature": "keras.optimizers.SGD.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'momentum': float(K.get_value(self.momentum)),\n                  'decay': float(K.get_value(self.decay)),\n                  'nesterov': self.nesterov}\n        base_config = super(SGD, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 200,
        "end_line": 206,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.RMSprop.__init__#229",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.RMSprop",
        "signature": "keras.optimizers.RMSprop.__init__(self, lr=0.001, rho=0.9, epsilon=None, decay=0.0, **kwargs)",
        "snippet": "    def __init__(self, lr=0.001, rho=0.9, epsilon=None, decay=0.,\n                 **kwargs):\n        super(RMSprop, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr, name='lr')\n            self.rho = K.variable(rho, name='rho')\n            self.decay = K.variable(decay, name='decay')\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay",
        "begin_line": 229,
        "end_line": 240,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0003728560775540641,
            "pseudo_dstar_susp": 0.0003728560775540641,
            "pseudo_tarantula_susp": 0.00037778617302606723,
            "pseudo_op2_susp": 0.0003728560775540641,
            "pseudo_barinel_susp": 0.00037778617302606723
        }
    },
    {
        "name": "keras.optimizers.RMSprop.get_updates#243",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.RMSprop",
        "signature": "keras.optimizers.RMSprop.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        accumulators = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        self.weights = accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        for p, g, a in zip(params, grads, accumulators):\n            # update accumulator\n            new_a = self.rho * a + (1. - self.rho) * K.square(g)\n            self.updates.append(K.update(a, new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 243,
        "end_line": 265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.RMSprop.get_config#267",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.RMSprop",
        "signature": "keras.optimizers.RMSprop.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'rho': float(K.get_value(self.rho)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon}\n        base_config = super(RMSprop, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 267,
        "end_line": 273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.259259259259259e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Adagrad.__init__#291",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adagrad",
        "signature": "keras.optimizers.Adagrad.__init__(self, lr=0.01, epsilon=None, decay=0.0, **kwargs)",
        "snippet": "    def __init__(self, lr=0.01, epsilon=None, decay=0., **kwargs):\n        super(Adagrad, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr, name='lr')\n            self.decay = K.variable(decay, name='decay')\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay",
        "begin_line": 291,
        "end_line": 300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Adagrad.get_updates#303",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adagrad",
        "signature": "keras.optimizers.Adagrad.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        shapes = [K.int_shape(p) for p in params]\n        accumulators = [K.zeros(shape) for shape in shapes]\n        self.weights = accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        for p, g, a in zip(params, grads, accumulators):\n            new_a = a + K.square(g)  # update accumulator\n            self.updates.append(K.update(a, new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 303,
        "end_line": 325,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Adagrad.get_config#327",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adagrad",
        "signature": "keras.optimizers.Adagrad.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon}\n        base_config = super(Adagrad, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 327,
        "end_line": 332,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Adadelta.__init__#352",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adadelta",
        "signature": "keras.optimizers.Adadelta.__init__(self, lr=1.0, rho=0.95, epsilon=None, decay=0.0, **kwargs)",
        "snippet": "    def __init__(self, lr=1.0, rho=0.95, epsilon=None, decay=0.,\n                 **kwargs):\n        super(Adadelta, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr, name='lr')\n            self.decay = K.variable(decay, name='decay')\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.rho = rho\n        self.epsilon = epsilon\n        self.initial_decay = decay",
        "begin_line": 352,
        "end_line": 363,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0019083969465648854,
            "pseudo_dstar_susp": 0.0006361323155216285,
            "pseudo_tarantula_susp": 0.002531645569620253,
            "pseudo_op2_susp": 0.0006361323155216285,
            "pseudo_barinel_susp": 0.002531645569620253
        }
    },
    {
        "name": "keras.optimizers.Adadelta.get_updates#366",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adadelta",
        "signature": "keras.optimizers.Adadelta.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        shapes = [K.int_shape(p) for p in params]\n        accumulators = [K.zeros(shape) for shape in shapes]\n        delta_accumulators = [K.zeros(shape) for shape in shapes]\n        self.weights = accumulators + delta_accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):\n            # update accumulator\n            new_a = self.rho * a + (1. - self.rho) * K.square(g)\n            self.updates.append(K.update(a, new_a))\n\n            # use the new accumulator and the *old* delta_accumulator\n            update = g * K.sqrt(d_a + self.epsilon) / K.sqrt(new_a + self.epsilon)\n            new_p = p - lr * update\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n\n            # update delta_accumulator\n            new_d_a = self.rho * d_a + (1 - self.rho) * K.square(update)\n            self.updates.append(K.update(d_a, new_d_a))\n        return self.updates",
        "begin_line": 366,
        "end_line": 397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.007042253521126761,
            "pseudo_dstar_susp": 0.001177856301531213,
            "pseudo_tarantula_susp": 0.0037735849056603774,
            "pseudo_op2_susp": 0.001177856301531213,
            "pseudo_barinel_susp": 0.0037735849056603774
        }
    },
    {
        "name": "keras.optimizers.Adadelta.get_config#399",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adadelta",
        "signature": "keras.optimizers.Adadelta.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'rho': self.rho,\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon}\n        base_config = super(Adadelta, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 399,
        "end_line": 405,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Adam.__init__#428",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adam",
        "signature": "keras.optimizers.Adam.__init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False, **kwargs)",
        "snippet": "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0., amsgrad=False, **kwargs):\n        super(Adam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay\n        self.amsgrad = amsgrad",
        "begin_line": 428,
        "end_line": 441,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Adam.get_updates#444",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adam",
        "signature": "keras.optimizers.Adam.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        else:\n            vhats = [K.zeros(1) for _ in params]\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n            if self.amsgrad:\n                vhat_t = K.maximum(vhat, v_t)\n                p_t = p - lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n                self.updates.append(K.update(vhat, vhat_t))\n            else:\n                p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 444,
        "end_line": 484,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Adam.get_config#486",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adam",
        "signature": "keras.optimizers.Adam.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon,\n                  'amsgrad': self.amsgrad}\n        base_config = super(Adam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 486,
        "end_line": 494,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.613535858488752e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Adamax.__init__#513",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adamax",
        "signature": "keras.optimizers.Adamax.__init__(self, lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, **kwargs)",
        "snippet": "    def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0., **kwargs):\n        super(Adamax, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay",
        "begin_line": 513,
        "end_line": 525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Adamax.get_updates#528",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adamax",
        "signature": "keras.optimizers.Adamax.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr / (1. - K.pow(self.beta_1, t))\n\n        shapes = [K.int_shape(p) for p in params]\n        # zero init of 1st moment\n        ms = [K.zeros(shape) for shape in shapes]\n        # zero init of exponentially weighted infinity norm\n        us = [K.zeros(shape) for shape in shapes]\n        self.weights = [self.iterations] + ms + us\n\n        for p, g, m, u in zip(params, grads, ms, us):\n\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            u_t = K.maximum(self.beta_2 * u, K.abs(g))\n            p_t = p - lr_t * m_t / (u_t + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(u, u_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 528,
        "end_line": 562,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Adamax.get_config#564",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adamax",
        "signature": "keras.optimizers.Adamax.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon}\n        base_config = super(Adamax, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 564,
        "end_line": 571,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Nadam.__init__#594",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Nadam",
        "signature": "keras.optimizers.Nadam.__init__(self, lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004, **kwargs)",
        "snippet": "    def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, schedule_decay=0.004, **kwargs):\n        super(Nadam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.m_schedule = K.variable(1., name='m_schedule')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.schedule_decay = schedule_decay",
        "begin_line": 594,
        "end_line": 606,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Nadam.get_updates#609",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Nadam",
        "signature": "keras.optimizers.Nadam.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n\n        # Due to the recommendations in [2], i.e. warming momentum schedule\n        momentum_cache_t = self.beta_1 * (\n            1. - 0.5 * (K.pow(K.cast_to_floatx(0.96), t * self.schedule_decay)))\n        momentum_cache_t_1 = self.beta_1 * (\n            1. - 0.5 * (K.pow(K.cast_to_floatx(0.96), (t + 1) * self.schedule_decay)))\n        m_schedule_new = self.m_schedule * momentum_cache_t\n        m_schedule_next = self.m_schedule * momentum_cache_t * momentum_cache_t_1\n        self.updates.append((self.m_schedule, m_schedule_new))\n\n        shapes = [K.int_shape(p) for p in params]\n        ms = [K.zeros(shape) for shape in shapes]\n        vs = [K.zeros(shape) for shape in shapes]\n\n        self.weights = [self.iterations] + ms + vs\n\n        for p, g, m, v in zip(params, grads, ms, vs):\n            # the following equations given in [1]\n            g_prime = g / (1. - m_schedule_new)\n            m_t = self.beta_1 * m + (1. - self.beta_1) * g\n            m_t_prime = m_t / (1. - m_schedule_next)\n            v_t = self.beta_2 * v + (1. - self.beta_2) * K.square(g)\n            v_t_prime = v_t / (1. - K.pow(self.beta_2, t))\n            m_t_bar = (1. - momentum_cache_t) * g_prime + momentum_cache_t_1 * m_t_prime\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n\n            p_t = p - self.lr * m_t_bar / (K.sqrt(v_t_prime) + self.epsilon)\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 609,
        "end_line": 650,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.Nadam.get_config#652",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Nadam",
        "signature": "keras.optimizers.Nadam.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'epsilon': self.epsilon,\n                  'schedule_decay': self.schedule_decay}\n        base_config = super(Nadam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 652,
        "end_line": 659,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.TFOptimizer.__init__#666",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.TFOptimizer",
        "signature": "keras.optimizers.TFOptimizer.__init__(self, optimizer)",
        "snippet": "    def __init__(self, optimizer):\n        self.optimizer = optimizer\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')",
        "begin_line": 666,
        "end_line": 669,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.TFOptimizer.get_updates#672",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.TFOptimizer",
        "signature": "keras.optimizers.TFOptimizer.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.optimizer.compute_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n        opt_update = self.optimizer.apply_gradients(\n            grads, global_step=self.iterations)\n        self.updates.append(opt_update)\n        return self.updates",
        "begin_line": 672,
        "end_line": 678,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.TFOptimizer.weights#681",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.TFOptimizer",
        "signature": "keras.optimizers.TFOptimizer.weights(self)",
        "snippet": "    def weights(self):\n        raise NotImplementedError",
        "begin_line": 681,
        "end_line": 682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.TFOptimizer.get_config#684",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.TFOptimizer",
        "signature": "keras.optimizers.TFOptimizer.get_config(self)",
        "snippet": "    def get_config(self):\n        raise NotImplementedError",
        "begin_line": 684,
        "end_line": 685,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.TFOptimizer.from_config#687",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.TFOptimizer",
        "signature": "keras.optimizers.TFOptimizer.from_config(self, config)",
        "snippet": "    def from_config(self, config):\n        raise NotImplementedError",
        "begin_line": 687,
        "end_line": 688,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.serialize#702",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers",
        "signature": "keras.optimizers.serialize(optimizer)",
        "snippet": "def serialize(optimizer):\n    return serialize_keras_object(optimizer)",
        "begin_line": 702,
        "end_line": 703,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.433836552247617e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.optimizers.deserialize#706",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers",
        "signature": "keras.optimizers.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    \"\"\"Inverse of the `serialize` function.\n\n    # Arguments\n        config: Optimizer configuration dictionary.\n        custom_objects: Optional dictionary mapping\n            names (strings) to custom objects\n            (classes and functions)\n            to be considered during deserialization.\n\n    # Returns\n        A Keras Optimizer instance.\n    \"\"\"\n    all_classes = {\n        'sgd': SGD,\n        'rmsprop': RMSprop,\n        'adagrad': Adagrad,\n        'adadelta': Adadelta,\n        'adam': Adam,\n        'adamax': Adamax,\n        'nadam': Nadam,\n        'tfoptimizer': TFOptimizer,\n    }\n    # Make deserialization case-insensitive for built-in optimizers.\n    if config['class_name'].lower() in all_classes:\n        config['class_name'] = config['class_name'].lower()\n    return deserialize_keras_object(config,\n                                    module_objects=all_classes,\n                                    custom_objects=custom_objects,\n                                    printable_module_name='optimizer')",
        "begin_line": 706,
        "end_line": 735,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000493339911198816,
            "pseudo_dstar_susp": 0.001026694045174538,
            "pseudo_tarantula_susp": 0.00040966816878328555,
            "pseudo_op2_susp": 0.001026694045174538,
            "pseudo_barinel_susp": 0.00040966816878328555
        }
    },
    {
        "name": "keras.optimizers.get#738",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers",
        "signature": "keras.optimizers.get(identifier)",
        "snippet": "def get(identifier):\n    \"\"\"Retrieves a Keras Optimizer instance.\n\n    # Arguments\n        identifier: Optimizer identifier, one of\n            - String: name of an optimizer\n            - Dictionary: configuration dictionary.\n            - Keras Optimizer instance (it will be returned unchanged).\n            - TensorFlow Optimizer instance\n                (it will be wrapped as a Keras Optimizer).\n\n    # Returns\n        A Keras Optimizer instance.\n\n    # Raises\n        ValueError: If `identifier` cannot be interpreted.\n    \"\"\"\n    if K.backend() == 'tensorflow':\n        # Wrap TF optimizer instances\n        if isinstance(identifier, tf.train.Optimizer):\n            return TFOptimizer(identifier)\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    if isinstance(identifier, Optimizer):\n        return identifier\n    else:\n        raise ValueError('Could not interpret optimizer identifier: ' +\n                         str(identifier))",
        "begin_line": 738,
        "end_line": 768,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005005005005005005,
            "pseudo_dstar_susp": 0.0010460251046025104,
            "pseudo_tarantula_susp": 0.00041407867494824016,
            "pseudo_op2_susp": 0.0010460251046025104,
            "pseudo_barinel_susp": 0.00041407867494824016
        }
    },
    {
        "name": "keras.datasets.reuters.load_data#15",
        "src_path": "keras/datasets/reuters.py",
        "class_name": "keras.datasets.reuters",
        "signature": "keras.datasets.reuters.load_data(path='reuters.npz', num_words=None, skip_top=0, maxlen=None, test_split=0.2, seed=113, start_char=1, oov_char=2, index_from=3, **kwargs)",
        "snippet": "def load_data(path='reuters.npz', num_words=None, skip_top=0,\n              maxlen=None, test_split=0.2, seed=113,\n              start_char=1, oov_char=2, index_from=3, **kwargs):\n    \"\"\"Loads the Reuters newswire classification dataset.\n\n    # Arguments\n        path: where to cache the data (relative to `~/.keras/dataset`).\n        num_words: max number of words to include. Words are ranked\n            by how often they occur (in the training set) and only\n            the most frequent words are kept\n        skip_top: skip the top N most frequently occurring words\n            (which may not be informative).\n        maxlen: truncate sequences after this length.\n        test_split: Fraction of the dataset to be used as test data.\n        seed: random seed for sample shuffling.\n        start_char: The start of a sequence will be marked with this character.\n            Set to 1 because 0 is usually the padding character.\n        oov_char: words that were cut out because of the `num_words`\n            or `skip_top` limit will be replaced with this character.\n        index_from: index actual words with this index and higher.\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n\n    Note that the 'out of vocabulary' character is only used for\n    words that were present in the training set but are not included\n    because they're not making the `num_words` cut here.\n    Words that were not seen in the training set but are in the test set\n    have simply been skipped.\n    \"\"\"\n    # Legacy support\n    if 'nb_words' in kwargs:\n        warnings.warn('The `nb_words` argument in `load_data` '\n                      'has been renamed `num_words`.')\n        num_words = kwargs.pop('nb_words')\n    if kwargs:\n        raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n\n    path = get_file(path,\n                    origin='https://s3.amazonaws.com/text-datasets/reuters.npz',\n                    file_hash='87aedbeb0cb229e378797a632c1997b6')\n    with np.load(path) as f:\n        xs, labels = f['x'], f['y']\n\n    np.random.seed(seed)\n    indices = np.arange(len(xs))\n    np.random.shuffle(indices)\n    xs = xs[indices]\n    labels = labels[indices]\n\n    if start_char is not None:\n        xs = [[start_char] + [w + index_from for w in x] for x in xs]\n    elif index_from:\n        xs = [[w + index_from for w in x] for x in xs]\n\n    if maxlen:\n        xs, labels = _remove_long_seq(maxlen, xs, labels)\n\n    if not num_words:\n        num_words = max([max(x) for x in xs])\n\n    # by convention, use 2 as OOV word\n    # reserve 'index_from' (=3 by default) characters:\n    # 0 (padding), 1 (start), 2 (OOV)\n    if oov_char is not None:\n        xs = [[w if skip_top <= w < num_words else oov_char for w in x] for x in xs]\n    else:\n        xs = [[w for w in x if skip_top <= w < num_words] for x in xs]\n\n    idx = int(len(xs) * (1 - test_split))\n    x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n    x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n\n    return (x_train, y_train), (x_test, y_test)",
        "begin_line": 15,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.datasets.reuters.get_word_index#91",
        "src_path": "keras/datasets/reuters.py",
        "class_name": "keras.datasets.reuters",
        "signature": "keras.datasets.reuters.get_word_index(path='reuters_word_index.json')",
        "snippet": "def get_word_index(path='reuters_word_index.json'):\n    \"\"\"Retrieves the dictionary mapping word indices back to words.\n\n    # Arguments\n        path: where to cache the data (relative to `~/.keras/dataset`).\n\n    # Returns\n        The word index dictionary.\n    \"\"\"\n    path = get_file(path,\n                    origin='https://s3.amazonaws.com/text-datasets/reuters_word_index.json',\n                    file_hash='4d44cc38712099c9e383dc6e5f11a921')\n    f = open(path)\n    data = json.load(f)\n    f.close()\n    return data",
        "begin_line": 91,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.generic_utils.CustomObjectScope.__init__#41",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.CustomObjectScope",
        "signature": "keras.utils.generic_utils.CustomObjectScope.__init__(self, *args)",
        "snippet": "    def __init__(self, *args):\n        self.custom_objects = args\n        self.backup = None",
        "begin_line": 41,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008244023083264633,
            "pseudo_dstar_susp": 0.00228310502283105,
            "pseudo_tarantula_susp": 0.0005509641873278236,
            "pseudo_op2_susp": 0.00228310502283105,
            "pseudo_barinel_susp": 0.0005509641873278236
        }
    },
    {
        "name": "keras.utils.generic_utils.CustomObjectScope.__enter__#45",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.CustomObjectScope",
        "signature": "keras.utils.generic_utils.CustomObjectScope.__enter__(self)",
        "snippet": "    def __enter__(self):\n        self.backup = _GLOBAL_CUSTOM_OBJECTS.copy()\n        for objects in self.custom_objects:\n            _GLOBAL_CUSTOM_OBJECTS.update(objects)\n        return self",
        "begin_line": 45,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008244023083264633,
            "pseudo_dstar_susp": 0.00228310502283105,
            "pseudo_tarantula_susp": 0.0005509641873278236,
            "pseudo_op2_susp": 0.00228310502283105,
            "pseudo_barinel_susp": 0.0005509641873278236
        }
    },
    {
        "name": "keras.utils.generic_utils.CustomObjectScope.__exit__#51",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.CustomObjectScope",
        "signature": "keras.utils.generic_utils.CustomObjectScope.__exit__(self, *args, **kwargs)",
        "snippet": "    def __exit__(self, *args, **kwargs):\n        _GLOBAL_CUSTOM_OBJECTS.clear()\n        _GLOBAL_CUSTOM_OBJECTS.update(self.backup)",
        "begin_line": 51,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008244023083264633,
            "pseudo_dstar_susp": 0.00228310502283105,
            "pseudo_tarantula_susp": 0.0005509641873278236,
            "pseudo_op2_susp": 0.00228310502283105,
            "pseudo_barinel_susp": 0.0005509641873278236
        }
    },
    {
        "name": "keras.utils.generic_utils.custom_object_scope#56",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.custom_object_scope(*args)",
        "snippet": "def custom_object_scope(*args):\n    \"\"\"Provides a scope that changes to `_GLOBAL_CUSTOM_OBJECTS` cannot escape.\n\n    Convenience wrapper for `CustomObjectScope`.\n    Code within a `with` statement will be able to access custom objects\n    by name. Changes to global custom objects persist\n    within the enclosing `with` statement. At end of the `with` statement,\n    global custom objects are reverted to state\n    at beginning of the `with` statement.\n\n    # Example\n\n    Consider a custom object `MyObject`\n\n    ```python\n        with custom_object_scope({'MyObject':MyObject}):\n            layer = Dense(..., kernel_regularizer='MyObject')\n            # save, load, etc. will recognize custom object by name\n    ```\n\n    # Arguments\n        *args: Variable length list of dictionaries of name,\n            class pairs to add to custom objects.\n\n    # Returns\n        Object of type `CustomObjectScope`.\n    \"\"\"\n    return CustomObjectScope(*args)",
        "begin_line": 56,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.generic_utils.get_custom_objects#86",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.get_custom_objects()",
        "snippet": "def get_custom_objects():\n    \"\"\"Retrieves a live reference to the global dictionary of custom objects.\n\n    Updating and clearing custom objects using `custom_object_scope`\n    is preferred, but `get_custom_objects` can\n    be used to directly access `_GLOBAL_CUSTOM_OBJECTS`.\n\n    # Example\n\n    ```python\n        get_custom_objects().clear()\n        get_custom_objects()['MyObject'] = MyObject\n    ```\n\n    # Returns\n        Global dictionary of names to classes (`_GLOBAL_CUSTOM_OBJECTS`).\n    \"\"\"\n    return _GLOBAL_CUSTOM_OBJECTS",
        "begin_line": 86,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.generic_utils.serialize_keras_object#106",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.serialize_keras_object(instance)",
        "snippet": "def serialize_keras_object(instance):\n    if instance is None:\n        return None\n    if hasattr(instance, 'get_config'):\n        return {\n            'class_name': instance.__class__.__name__,\n            'config': instance.get_config()\n        }\n    if hasattr(instance, '__name__'):\n        return instance.__name__\n    else:\n        raise ValueError('Cannot serialize', instance)",
        "begin_line": 106,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00039077764751856197,
            "pseudo_dstar_susp": 0.00038955979742890534,
            "pseudo_tarantula_susp": 0.0004338394793926247,
            "pseudo_op2_susp": 0.00038955979742890534,
            "pseudo_barinel_susp": 0.00043402777777777775
        }
    },
    {
        "name": "keras.utils.generic_utils.deserialize_keras_object#120",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.deserialize_keras_object(identifier, module_objects=None, custom_objects=None, printable_module_name='object')",
        "snippet": "def deserialize_keras_object(identifier, module_objects=None,\n                             custom_objects=None,\n                             printable_module_name='object'):\n    if isinstance(identifier, dict):\n        # In this case we are dealing with a Keras config dictionary.\n        config = identifier\n        if 'class_name' not in config or 'config' not in config:\n            raise ValueError('Improper config format: ' + str(config))\n        class_name = config['class_name']\n        if custom_objects and class_name in custom_objects:\n            cls = custom_objects[class_name]\n        elif class_name in _GLOBAL_CUSTOM_OBJECTS:\n            cls = _GLOBAL_CUSTOM_OBJECTS[class_name]\n        else:\n            module_objects = module_objects or {}\n            cls = module_objects.get(class_name)\n            if cls is None:\n                raise ValueError('Unknown ' + printable_module_name +\n                                 ': ' + class_name)\n        if hasattr(cls, 'from_config'):\n            custom_objects = custom_objects or {}\n            if has_arg(cls.from_config, 'custom_objects'):\n                return cls.from_config(config['config'],\n                                       custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n                                                           list(custom_objects.items())))\n            with CustomObjectScope(custom_objects):\n                return cls.from_config(config['config'])\n        else:\n            # Then `cls` may be a function returning a class.\n            # in this case by convention `config` holds\n            # the kwargs of the function.\n            custom_objects = custom_objects or {}\n            with CustomObjectScope(custom_objects):\n                return cls(**config['config'])\n    elif isinstance(identifier, six.string_types):\n        function_name = identifier\n        if custom_objects and function_name in custom_objects:\n            fn = custom_objects.get(function_name)\n        elif function_name in _GLOBAL_CUSTOM_OBJECTS:\n            fn = _GLOBAL_CUSTOM_OBJECTS[function_name]\n        else:\n            fn = module_objects.get(function_name)\n            if fn is None:\n                raise ValueError('Unknown ' + printable_module_name +\n                                 ':' + function_name)\n        return fn\n    else:\n        raise ValueError('Could not interpret serialized ' +\n                         printable_module_name + ': ' + identifier)",
        "begin_line": 120,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011976047904191617,
            "pseudo_dstar_susp": 0.00558659217877095,
            "pseudo_tarantula_susp": 0.0010683760683760685,
            "pseudo_op2_susp": 0.00558659217877095,
            "pseudo_barinel_susp": 0.0010683760683760685
        }
    },
    {
        "name": "keras.utils.generic_utils.func_dump#171",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.func_dump(func)",
        "snippet": "def func_dump(func):\n    \"\"\"Serializes a user defined function.\n\n    # Arguments\n        func: the function to serialize.\n\n    # Returns\n        A tuple `(code, defaults, closure)`.\n    \"\"\"\n    raw_code = marshal.dumps(func.__code__)\n    code = codecs.encode(raw_code, 'base64').decode('ascii')\n    defaults = func.__defaults__\n    if func.__closure__:\n        closure = tuple(c.cell_contents for c in func.__closure__)\n    else:\n        closure = None\n    return code, defaults, closure",
        "begin_line": 171,
        "end_line": 187,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.generic_utils.func_load#190",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.func_load(code, defaults=None, closure=None, globs=None)",
        "snippet": "def func_load(code, defaults=None, closure=None, globs=None):\n    \"\"\"Deserializes a user defined function.\n\n    # Arguments\n        code: bytecode of the function.\n        defaults: defaults of the function.\n        closure: closure of the function.\n        globs: dictionary of global objects.\n\n    # Returns\n        A function object.\n    \"\"\"\n    if isinstance(code, (tuple, list)):  # unpack previous dump\n        code, defaults, closure = code\n        if isinstance(defaults, list):\n            defaults = tuple(defaults)\n\n    def ensure_value_to_cell(value):\n        \"\"\"Ensures that a value is converted to a python cell object.\n\n        # Arguments\n            value: Any value that needs to be casted to the cell type\n\n        # Returns\n            A value wrapped as a cell object (see function \"func_load\")\n\n        \"\"\"\n        def dummy_fn():\n            value  # just access it so it gets captured in .__closure__\n\n        cell_value = dummy_fn.__closure__[0]\n        if not isinstance(value, type(cell_value)):\n            return cell_value\n        else:\n            return value\n\n    if closure is not None:\n        closure = tuple(ensure_value_to_cell(_) for _ in closure)\n    try:\n        raw_code = codecs.decode(code.encode('ascii'), 'base64')\n        code = marshal.loads(raw_code)\n    except (UnicodeEncodeError, binascii.Error, ValueError):\n        # backwards compatibility for models serialized prior to 2.1.2\n        raw_code = code.encode('raw_unicode_escape')\n        code = marshal.loads(raw_code)\n    if globs is None:\n        globs = globals()\n    return python_types.FunctionType(code, globs,\n                                     name=code.co_name,\n                                     argdefs=defaults,\n                                     closure=closure)",
        "begin_line": 190,
        "end_line": 240,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.generic_utils.ensure_value_to_cell#207",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.ensure_value_to_cell(value)",
        "snippet": "    def ensure_value_to_cell(value):\n        \"\"\"Ensures that a value is converted to a python cell object.\n\n        # Arguments\n            value: Any value that needs to be casted to the cell type\n\n        # Returns\n            A value wrapped as a cell object (see function \"func_load\")\n\n        \"\"\"\n        def dummy_fn():\n            value  # just access it so it gets captured in .__closure__\n\n        cell_value = dummy_fn.__closure__[0]\n        if not isinstance(value, type(cell_value)):\n            return cell_value\n        else:\n            return value",
        "begin_line": 207,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.generic_utils.dummy_fn#217",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.dummy_fn()",
        "snippet": "        def dummy_fn():\n            value  # just access it so it gets captured in .__closure__",
        "begin_line": 217,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.utils.generic_utils.has_arg#243",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.has_arg(fn, name, accept_all=False)",
        "snippet": "def has_arg(fn, name, accept_all=False):\n    \"\"\"Checks if a callable accepts a given keyword argument.\n\n    For Python 2, checks if there is an argument with the given name.\n\n    For Python 3, checks if there is an argument with the given name, and\n    also whether this argument can be called with a keyword (i.e. if it is\n    not a positional-only argument).\n\n    # Arguments\n        fn: Callable to inspect.\n        name: Check if `fn` can be called with `name` as a keyword argument.\n        accept_all: What to return if there is no parameter called `name`\n                    but the function accepts a `**kwargs` argument.\n\n    # Returns\n        bool, whether `fn` accepts a `name` keyword argument.\n    \"\"\"\n    if sys.version_info < (3,):\n        arg_spec = inspect.getargspec(fn)\n        if accept_all and arg_spec.keywords is not None:\n            return True\n        return (name in arg_spec.args)\n    elif sys.version_info < (3, 3):\n        arg_spec = inspect.getfullargspec(fn)\n        if accept_all and arg_spec.varkw is not None:\n            return True\n        return (name in arg_spec.args or\n                name in arg_spec.kwonlyargs)\n    else:\n        signature = inspect.signature(fn)\n        parameter = signature.parameters.get(name)\n        if parameter is None:\n            if accept_all:\n                for param in signature.parameters.values():\n                    if param.kind == inspect.Parameter.VAR_KEYWORD:\n                        return True\n            return False\n        return (parameter.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD,\n                                   inspect.Parameter.KEYWORD_ONLY))",
        "begin_line": 243,
        "end_line": 282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007547169811320754,
            "pseudo_dstar_susp": 0.0021231422505307855,
            "pseudo_tarantula_susp": 0.0005017561465127947,
            "pseudo_op2_susp": 0.0021231422505307855,
            "pseudo_barinel_susp": 0.0005017561465127947
        }
    },
    {
        "name": "keras.utils.generic_utils.Progbar.__init__#299",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.Progbar",
        "signature": "keras.utils.generic_utils.Progbar.__init__(self, target, width=30, verbose=1, interval=0.05, stateful_metrics=None)",
        "snippet": "    def __init__(self, target, width=30, verbose=1, interval=0.05,\n                 stateful_metrics=None):\n        self.target = target\n        self.width = width\n        self.verbose = verbose\n        self.interval = interval\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()\n\n        self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and\n                                  sys.stdout.isatty()) or\n                                 'ipykernel' in sys.modules)\n        self._total_width = 0\n        self._seen_so_far = 0\n        self._values = collections.OrderedDict()\n        self._start = time.time()\n        self._last_update = 0",
        "begin_line": 299,
        "end_line": 317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00043122035360068997,
            "pseudo_dstar_susp": 0.000423728813559322,
            "pseudo_tarantula_susp": 0.0007022471910112359,
            "pseudo_op2_susp": 0.000423728813559322,
            "pseudo_barinel_susp": 0.0007022471910112359
        }
    },
    {
        "name": "keras.utils.generic_utils.Progbar.update#319",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.Progbar",
        "signature": "keras.utils.generic_utils.Progbar.update(self, current, values=None)",
        "snippet": "    def update(self, current, values=None):\n        \"\"\"Updates the progress bar.\n\n        # Arguments\n            current: Index of current step.\n            values: List of tuples:\n                `(name, value_for_last_step)`.\n                If `name` is in `stateful_metrics`,\n                `value_for_last_step` will be displayed as-is.\n                Else, an average of the metric over time will be displayed.\n        \"\"\"\n        values = values or []\n        for k, v in values:\n            if k not in self.stateful_metrics:\n                if k not in self._values:\n                    self._values[k] = [v * (current - self._seen_so_far),\n                                       current - self._seen_so_far]\n                else:\n                    self._values[k][0] += v * (current - self._seen_so_far)\n                    self._values[k][1] += (current - self._seen_so_far)\n            else:\n                self._values[k] = v\n        self._seen_so_far = current\n\n        now = time.time()\n        info = ' - %.0fs' % (now - self._start)\n        if self.verbose == 1:\n            if (now - self._last_update < self.interval and\n                    self.target is not None and current < self.target):\n                return\n\n            prev_total_width = self._total_width\n            if self._dynamic_display:\n                sys.stdout.write('\\b' * prev_total_width)\n                sys.stdout.write('\\r')\n            else:\n                sys.stdout.write('\\n')\n\n            if self.target is not None:\n                numdigits = int(np.floor(np.log10(self.target))) + 1\n                barstr = '%%%dd/%d [' % (numdigits, self.target)\n                bar = barstr % current\n                prog = float(current) / self.target\n                prog_width = int(self.width * prog)\n                if prog_width > 0:\n                    bar += ('=' * (prog_width - 1))\n                    if current < self.target:\n                        bar += '>'\n                    else:\n                        bar += '='\n                bar += ('.' * (self.width - prog_width))\n                bar += ']'\n            else:\n                bar = '%7d/Unknown' % current\n\n            self._total_width = len(bar)\n            sys.stdout.write(bar)\n\n            if current:\n                time_per_unit = (now - self._start) / current\n            else:\n                time_per_unit = 0\n            if self.target is not None and current < self.target:\n                eta = time_per_unit * (self.target - current)\n                if eta > 3600:\n                    eta_format = '%d:%02d:%02d' % (eta // 3600, (eta % 3600) // 60, eta % 60)\n                elif eta > 60:\n                    eta_format = '%d:%02d' % (eta // 60, eta % 60)\n                else:\n                    eta_format = '%ds' % eta\n\n                info = ' - ETA: %s' % eta_format\n            else:\n                if time_per_unit >= 1:\n                    info += ' %.0fs/step' % time_per_unit\n                elif time_per_unit >= 1e-3:\n                    info += ' %.0fms/step' % (time_per_unit * 1e3)\n                else:\n                    info += ' %.0fus/step' % (time_per_unit * 1e6)\n\n            for k in self._values:\n                info += ' - %s:' % k\n                if isinstance(self._values[k], list):\n                    avg = np.mean(\n                        self._values[k][0] / max(1, self._values[k][1]))\n                    if abs(avg) > 1e-3:\n                        info += ' %.4f' % avg\n                    else:\n                        info += ' %.4e' % avg\n                else:\n                    info += ' %s' % self._values[k]\n\n            self._total_width += len(info)\n            if prev_total_width > self._total_width:\n                info += (' ' * (prev_total_width - self._total_width))\n\n            if self.target is not None and current >= self.target:\n                info += '\\n'\n\n            sys.stdout.write(info)\n            sys.stdout.flush()\n\n        elif self.verbose == 2:\n            if self.target is None or current >= self.target:\n                for k in self._values:\n                    info += ' - %s:' % k\n                    avg = np.mean(\n                        self._values[k][0] / max(1, self._values[k][1]))\n                    if avg > 1e-3:\n                        info += ' %.4f' % avg\n                    else:\n                        info += ' %.4e' % avg\n                info += '\\n'\n\n                sys.stdout.write(info)\n                sys.stdout.flush()\n\n        self._last_update = now",
        "begin_line": 319,
        "end_line": 436,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006329113924050633,
            "pseudo_dstar_susp": 0.0007513148009015778,
            "pseudo_tarantula_susp": 0.006666666666666667,
            "pseudo_op2_susp": 0.0007513148009015778,
            "pseudo_barinel_susp": 0.006666666666666667
        }
    },
    {
        "name": "keras.utils.generic_utils.Progbar.add#438",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.Progbar",
        "signature": "keras.utils.generic_utils.Progbar.add(self, n, values=None)",
        "snippet": "    def add(self, n, values=None):\n        self.update(self._seen_so_far + n, values)",
        "begin_line": 438,
        "end_line": 439,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.regularizers.Regularizer.__call__#17",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers.Regularizer",
        "signature": "keras.regularizers.Regularizer.__call__(self, x)",
        "snippet": "    def __call__(self, x):\n        return 0.",
        "begin_line": 17,
        "end_line": 18,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.regularizers.Regularizer.from_config#21",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers.Regularizer",
        "signature": "keras.regularizers.Regularizer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        return cls(**config)",
        "begin_line": 21,
        "end_line": 22,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.171937566396992e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.regularizers.L1L2.__init__#33",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers.L1L2",
        "signature": "keras.regularizers.L1L2.__init__(self, l1=0.0, l2=0.0)",
        "snippet": "    def __init__(self, l1=0., l2=0.):\n        self.l1 = K.cast_to_floatx(l1)\n        self.l2 = K.cast_to_floatx(l2)",
        "begin_line": 33,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.489514679448772e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.regularizers.L1L2.__call__#37",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers.L1L2",
        "signature": "keras.regularizers.L1L2.__call__(self, x)",
        "snippet": "    def __call__(self, x):\n        regularization = 0.\n        if self.l1:\n            regularization += K.sum(self.l1 * K.abs(x))\n        if self.l2:\n            regularization += K.sum(self.l2 * K.square(x))\n        return regularization",
        "begin_line": 37,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.079502302658157e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.regularizers.L1L2.get_config#45",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers.L1L2",
        "signature": "keras.regularizers.L1L2.get_config(self)",
        "snippet": "    def get_config(self):\n        return {'l1': float(self.l1),\n                'l2': float(self.l2)}",
        "begin_line": 45,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.668123610152595e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.regularizers.l1#53",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.l1(l=0.01)",
        "snippet": "def l1(l=0.01):\n    return L1L2(l1=l)",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.668123610152595e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.regularizers.l2#57",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.l2(l=0.01)",
        "snippet": "def l2(l=0.01):\n    return L1L2(l2=l)",
        "begin_line": 57,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.640586797066015e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.regularizers.l1_l2#61",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.l1_l2(l1=0.01, l2=0.01)",
        "snippet": "def l1_l2(l1=0.01, l2=0.01):\n    return L1L2(l1=l1, l2=l2)",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.regularizers.serialize#65",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.serialize(regularizer)",
        "snippet": "def serialize(regularizer):\n    return serialize_keras_object(regularizer)",
        "begin_line": 65,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00039077764751856197,
            "pseudo_dstar_susp": 0.00038955979742890534,
            "pseudo_tarantula_susp": 0.0004338394793926247,
            "pseudo_op2_susp": 0.00038955979742890534,
            "pseudo_barinel_susp": 0.00043402777777777775
        }
    },
    {
        "name": "keras.regularizers.deserialize#69",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='regularizer')",
        "begin_line": 69,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.551159102922299e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.regularizers.get#76",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.get(identifier)",
        "snippet": "def get(identifier):\n    if identifier is None:\n        return None\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret regularizer identifier: ' +\n                         str(identifier))",
        "begin_line": 76,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010504201680672268,
            "pseudo_dstar_susp": 0.004629629629629629,
            "pseudo_tarantula_susp": 0.000641025641025641,
            "pseudo_op2_susp": 0.004629629629629629,
            "pseudo_barinel_susp": 0.000641025641025641
        }
    },
    {
        "name": "keras.layers.core.Masking.__init__#56",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.__init__(self, mask_value=0.0, **kwargs)",
        "snippet": "    def __init__(self, mask_value=0., **kwargs):\n        super(Masking, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.mask_value = mask_value",
        "begin_line": 56,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Masking.compute_mask#61",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        return K.any(K.not_equal(inputs, self.mask_value), axis=-1)",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Masking.call#64",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        boolean_mask = K.any(K.not_equal(inputs, self.mask_value),\n                             axis=-1, keepdims=True)\n        return inputs * K.cast(boolean_mask, K.dtype(inputs))",
        "begin_line": 64,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Masking.get_config#69",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'mask_value': self.mask_value}\n        base_config = super(Masking, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 69,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Masking.compute_output_shape#74",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 74,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Dropout.__init__#99",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout.__init__(self, rate, noise_shape=None, seed=None, **kwargs)",
        "snippet": "    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n        super(Dropout, self).__init__(**kwargs)\n        self.rate = min(1., max(0., rate))\n        self.noise_shape = noise_shape\n        self.seed = seed\n        self.supports_masking = True",
        "begin_line": 99,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00010962508221881167,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Dropout._get_noise_shape#106",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout._get_noise_shape(self, inputs)",
        "snippet": "    def _get_noise_shape(self, inputs):\n        if self.noise_shape is None:\n            return self.noise_shape\n\n        symbolic_shape = K.shape(inputs)\n        noise_shape = [symbolic_shape[axis] if shape is None else shape\n                       for axis, shape in enumerate(self.noise_shape)]\n        return tuple(noise_shape)",
        "begin_line": 106,
        "end_line": 113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Dropout.call#115",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        if 0. < self.rate < 1.:\n            noise_shape = self._get_noise_shape(inputs)\n\n            def dropped_inputs():\n                return K.dropout(inputs, self.rate, noise_shape,\n                                 seed=self.seed)\n            return K.in_train_phase(dropped_inputs, inputs,\n                                    training=training)\n        return inputs",
        "begin_line": 115,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.010894816951053e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Dropout.dropped_inputs#119",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout.dropped_inputs()",
        "snippet": "            def dropped_inputs():\n                return K.dropout(inputs, self.rate, noise_shape,\n                                 seed=self.seed)",
        "begin_line": 119,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.010894816951053e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Dropout.get_config#126",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'rate': self.rate,\n                  'noise_shape': self.noise_shape,\n                  'seed': self.seed}\n        base_config = super(Dropout, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 126,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Dropout.compute_output_shape#133",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 133,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.010894816951053e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout1D.__init__#163",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout1D",
        "signature": "keras.layers.core.SpatialDropout1D.__init__(self, rate, **kwargs)",
        "snippet": "    def __init__(self, rate, **kwargs):\n        super(SpatialDropout1D, self).__init__(rate, **kwargs)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 163,
        "end_line": 165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout1D._get_noise_shape#167",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout1D",
        "signature": "keras.layers.core.SpatialDropout1D._get_noise_shape(self, inputs)",
        "snippet": "    def _get_noise_shape(self, inputs):\n        input_shape = K.shape(inputs)\n        noise_shape = (input_shape[0], 1, input_shape[2])\n        return noise_shape",
        "begin_line": 167,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout2D.__init__#208",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout2D",
        "signature": "keras.layers.core.SpatialDropout2D.__init__(self, rate, data_format=None, **kwargs)",
        "snippet": "    def __init__(self, rate, data_format=None, **kwargs):\n        super(SpatialDropout2D, self).__init__(rate, **kwargs)\n        if data_format is None:\n            data_format = K.image_data_format()\n        if data_format not in {'channels_last', 'channels_first'}:\n            raise ValueError('`data_format` must be in '\n                             '{`\"channels_last\"`, `\"channels_first\"`}')\n        self.data_format = data_format\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 208,
        "end_line": 216,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout2D._get_noise_shape#218",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout2D",
        "signature": "keras.layers.core.SpatialDropout2D._get_noise_shape(self, inputs)",
        "snippet": "    def _get_noise_shape(self, inputs):\n        input_shape = K.shape(inputs)\n        if self.data_format == 'channels_first':\n            noise_shape = (input_shape[0], input_shape[1], 1, 1)\n        else:\n            noise_shape = (input_shape[0], 1, 1, input_shape[3])\n        return noise_shape",
        "begin_line": 218,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout3D.__init__#261",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout3D",
        "signature": "keras.layers.core.SpatialDropout3D.__init__(self, rate, data_format=None, **kwargs)",
        "snippet": "    def __init__(self, rate, data_format=None, **kwargs):\n        super(SpatialDropout3D, self).__init__(rate, **kwargs)\n        if data_format is None:\n            data_format = K.image_data_format()\n        if data_format not in {'channels_last', 'channels_first'}:\n            raise ValueError('`data_format` must be in '\n                             '{`\"channels_last\"`, `\"channels_first\"`}')\n        self.data_format = data_format\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 261,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout3D._get_noise_shape#271",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout3D",
        "signature": "keras.layers.core.SpatialDropout3D._get_noise_shape(self, inputs)",
        "snippet": "    def _get_noise_shape(self, inputs):\n        input_shape = K.shape(inputs)\n        if self.data_format == 'channels_first':\n            noise_shape = (input_shape[0], input_shape[1], 1, 1, 1)\n        else:\n            noise_shape = (input_shape[0], 1, 1, 1, input_shape[4])\n        return noise_shape",
        "begin_line": 271,
        "end_line": 277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Activation.__init__#297",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Activation",
        "signature": "keras.layers.core.Activation.__init__(self, activation, **kwargs)",
        "snippet": "    def __init__(self, activation, **kwargs):\n        super(Activation, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.activation = activations.get(activation)",
        "begin_line": 297,
        "end_line": 300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.47887218607434e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Activation.call#302",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Activation",
        "signature": "keras.layers.core.Activation.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return self.activation(inputs)",
        "begin_line": 302,
        "end_line": 303,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.47887218607434e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Activation.get_config#305",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Activation",
        "signature": "keras.layers.core.Activation.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'activation': activations.serialize(self.activation)}\n        base_config = super(Activation, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 305,
        "end_line": 308,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.577064928381508e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Activation.compute_output_shape#310",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Activation",
        "signature": "keras.layers.core.Activation.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 310,
        "end_line": 311,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 7.47887218607434e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Reshape.__init__#349",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Reshape",
        "signature": "keras.layers.core.Reshape.__init__(self, target_shape, **kwargs)",
        "snippet": "    def __init__(self, target_shape, **kwargs):\n        super(Reshape, self).__init__(**kwargs)\n        self.target_shape = tuple(target_shape)",
        "begin_line": 349,
        "end_line": 351,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Reshape._fix_unknown_dimension#353",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Reshape",
        "signature": "keras.layers.core.Reshape._fix_unknown_dimension(self, input_shape, output_shape)",
        "snippet": "    def _fix_unknown_dimension(self, input_shape, output_shape):\n        \"\"\"Finds and replaces a missing dimension in an output shape.\n\n        This is a near direct port of the internal Numpy function\n        `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`\n\n        # Arguments\n            input_shape: original shape of array being reshaped\n            output_shape: target shape of the array, with at most\n                a single -1 which indicates a dimension that should be\n                derived from the input shape.\n\n        # Returns\n            The new output shape with a `-1` replaced with its computed value.\n\n        # Raises\n            ValueError: if `input_shape` and `output_shape` do not match.\n        \"\"\"\n        output_shape = list(output_shape)\n        msg = 'total size of new array must be unchanged'\n\n        known, unknown = 1, None\n        for index, dim in enumerate(output_shape):\n            if dim < 0:\n                if unknown is None:\n                    unknown = index\n                else:\n                    raise ValueError('Can only specify one unknown dimension.')\n            else:\n                known *= dim\n\n        original = np.prod(input_shape, dtype=int)\n        if unknown is not None:\n            if known == 0 or original % known != 0:\n                raise ValueError(msg)\n            output_shape[unknown] = original // known\n        elif original != known:\n            raise ValueError(msg)\n\n        return tuple(output_shape)",
        "begin_line": 353,
        "end_line": 392,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Reshape.compute_output_shape#394",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Reshape",
        "signature": "keras.layers.core.Reshape.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if None in input_shape[1:]:\n            # input shape (partially) unknown? replace -1's with None's\n            return ((input_shape[0],) +\n                    tuple(s if s != -1 else None for s in self.target_shape))\n        else:\n            # input shape known? then we can compute the output shape\n            return (input_shape[0],) + self._fix_unknown_dimension(\n                input_shape[1:], self.target_shape)",
        "begin_line": 394,
        "end_line": 402,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Reshape.call#404",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Reshape",
        "signature": "keras.layers.core.Reshape.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.reshape(inputs, (K.shape(inputs)[0],) + self.target_shape)",
        "begin_line": 404,
        "end_line": 405,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Reshape.get_config#407",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Reshape",
        "signature": "keras.layers.core.Reshape.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'target_shape': self.target_shape}\n        base_config = super(Reshape, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 407,
        "end_line": 410,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Permute.__init__#443",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Permute",
        "signature": "keras.layers.core.Permute.__init__(self, dims, **kwargs)",
        "snippet": "    def __init__(self, dims, **kwargs):\n        super(Permute, self).__init__(**kwargs)\n        self.dims = tuple(dims)\n        self.input_spec = InputSpec(ndim=len(self.dims) + 1)",
        "begin_line": 443,
        "end_line": 446,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Permute.compute_output_shape#448",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Permute",
        "signature": "keras.layers.core.Permute.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        input_shape = list(input_shape)\n        output_shape = copy.copy(input_shape)\n        for i, dim in enumerate(self.dims):\n            target_dim = input_shape[dim]\n            output_shape[i + 1] = target_dim\n        return tuple(output_shape)",
        "begin_line": 448,
        "end_line": 454,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Permute.call#456",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Permute",
        "signature": "keras.layers.core.Permute.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.permute_dimensions(inputs, (0,) + self.dims)",
        "begin_line": 456,
        "end_line": 457,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Permute.get_config#459",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Permute",
        "signature": "keras.layers.core.Permute.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'dims': self.dims}\n        base_config = super(Permute, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 459,
        "end_line": 462,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Flatten.__init__#482",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Flatten",
        "signature": "keras.layers.core.Flatten.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        super(Flatten, self).__init__(**kwargs)\n        self.input_spec = InputSpec(min_ndim=3)",
        "begin_line": 482,
        "end_line": 484,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027397260273972603,
            "pseudo_dstar_susp": 0.0006734006734006734,
            "pseudo_tarantula_susp": 0.003257328990228013,
            "pseudo_op2_susp": 0.0006734006734006734,
            "pseudo_barinel_susp": 0.003257328990228013
        }
    },
    {
        "name": "keras.layers.core.Flatten.compute_output_shape#486",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Flatten",
        "signature": "keras.layers.core.Flatten.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if not all(input_shape[1:]):\n            raise ValueError('The shape of the input to \"Flatten\" '\n                             'is not fully defined '\n                             '(got ' + str(input_shape[1:]) + '. '\n                             'Make sure to pass a complete \"input_shape\" '\n                             'or \"batch_input_shape\" argument to the first '\n                             'layer in your model.')\n        return (input_shape[0], np.prod(input_shape[1:]))",
        "begin_line": 486,
        "end_line": 494,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027397260273972603,
            "pseudo_dstar_susp": 0.0006734006734006734,
            "pseudo_tarantula_susp": 0.003257328990228013,
            "pseudo_op2_susp": 0.0006734006734006734,
            "pseudo_barinel_susp": 0.003257328990228013
        }
    },
    {
        "name": "keras.layers.core.Flatten.call#496",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Flatten",
        "signature": "keras.layers.core.Flatten.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.batch_flatten(inputs)",
        "begin_line": 496,
        "end_line": 497,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027397260273972603,
            "pseudo_dstar_susp": 0.0006734006734006734,
            "pseudo_tarantula_susp": 0.003257328990228013,
            "pseudo_op2_susp": 0.0006734006734006734,
            "pseudo_barinel_susp": 0.003257328990228013
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.__init__#525",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.__init__(self, n, **kwargs)",
        "snippet": "    def __init__(self, n, **kwargs):\n        super(RepeatVector, self).__init__(**kwargs)\n        self.n = n\n        self.input_spec = InputSpec(ndim=2)",
        "begin_line": 525,
        "end_line": 528,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.compute_output_shape#530",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.n, input_shape[1])",
        "begin_line": 530,
        "end_line": 531,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.call#533",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.repeat(inputs, self.n)",
        "begin_line": 533,
        "end_line": 534,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.get_config#536",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'n': self.n}\n        base_config = super(RepeatVector, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 536,
        "end_line": 539,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Lambda.__init__#601",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.__init__(self, function, output_shape=None, mask=None, arguments=None, **kwargs)",
        "snippet": "    def __init__(self, function, output_shape=None,\n                 mask=None, arguments=None, **kwargs):\n        super(Lambda, self).__init__(**kwargs)\n        self.function = function\n        self.arguments = arguments if arguments else {}\n        if mask is not None:\n            self.supports_masking = True\n        self.mask = mask\n\n        if output_shape is None:\n            self._output_shape = None\n        elif isinstance(output_shape, (tuple, list)):\n            self._output_shape = tuple(output_shape)\n        else:\n            if not callable(output_shape):\n                raise TypeError('In Lambda, `output_shape` '\n                                'must be a list, a tuple, or a function.')\n            self._output_shape = output_shape",
        "begin_line": 601,
        "end_line": 618,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Lambda.compute_output_shape#620",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self._output_shape is None:\n            # With TensorFlow, we can infer the output shape directly:\n            if K.backend() == 'tensorflow':\n                if isinstance(input_shape, list):\n                    xs = [K.placeholder(shape=shape) for shape in input_shape]\n                    x = self.call(xs)\n                else:\n                    x = K.placeholder(shape=input_shape)\n                    x = self.call(x)\n                if isinstance(x, list):\n                    return [K.int_shape(x_elem) for x_elem in x]\n                else:\n                    return K.int_shape(x)\n            # Otherwise, we default to the input shape.\n            warnings.warn('`output_shape` argument not specified for layer {} '\n                          'and cannot be automatically inferred '\n                          'with the Theano backend. '\n                          'Defaulting to output shape `{}` '\n                          '(same as input shape). '\n                          'If the expected output shape is different, '\n                          'specify it via the `output_shape` argument.'\n                          .format(self.name, input_shape))\n            return input_shape\n        elif isinstance(self._output_shape, (tuple, list)):\n            if isinstance(input_shape, list):\n                num_samples = input_shape[0][0]\n            else:\n                num_samples = input_shape[0] if input_shape else None\n            return (num_samples,) + tuple(self._output_shape)\n        else:\n            shape = self._output_shape(input_shape)\n            if not isinstance(shape, (list, tuple)):\n                raise ValueError('`output_shape` function must return a tuple or a list of tuples.')\n            if isinstance(shape, list):\n                if isinstance(shape[0], int) or shape[0] is None:\n                    shape = tuple(shape)\n            return shape",
        "begin_line": 620,
        "end_line": 657,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Lambda.call#659",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        arguments = self.arguments\n        if has_arg(self.function, 'mask'):\n            arguments['mask'] = mask\n        return self.function(inputs, **arguments)",
        "begin_line": 659,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 9.040773890245005e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Lambda.compute_mask#665",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if callable(self.mask):\n            return self.mask(inputs, mask)\n        return self.mask",
        "begin_line": 665,
        "end_line": 668,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Lambda.get_config#670",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.get_config(self)",
        "snippet": "    def get_config(self):\n        if isinstance(self.function, python_types.LambdaType):\n            function = func_dump(self.function)\n            function_type = 'lambda'\n        else:\n            function = self.function.__name__\n            function_type = 'function'\n\n        if isinstance(self._output_shape, python_types.LambdaType):\n            output_shape = func_dump(self._output_shape)\n            output_shape_type = 'lambda'\n        elif callable(self._output_shape):\n            output_shape = self._output_shape.__name__\n            output_shape_type = 'function'\n        else:\n            output_shape = self._output_shape\n            output_shape_type = 'raw'\n\n        config = {'function': function,\n                  'function_type': function_type,\n                  'output_shape': output_shape,\n                  'output_shape_type': output_shape_type,\n                  'arguments': self.arguments}\n        base_config = super(Lambda, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 670,
        "end_line": 694,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Lambda.from_config#697",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        config = config.copy()\n        globs = globals()\n        if custom_objects:\n            globs = dict(list(globs.items()) + list(custom_objects.items()))\n        function_type = config.pop('function_type')\n        if function_type == 'function':\n            # Simple lookup in custom objects\n            function = deserialize_keras_object(\n                config['function'],\n                custom_objects=custom_objects,\n                printable_module_name='function in Lambda layer')\n        elif function_type == 'lambda':\n            # Unsafe deserialization from bytecode\n            function = func_load(config['function'], globs=globs)\n        else:\n            raise TypeError('Unknown function type:', function_type)\n\n        output_shape_type = config.pop('output_shape_type')\n        if output_shape_type == 'function':\n            # Simple lookup in custom objects\n            output_shape = deserialize_keras_object(\n                config['output_shape'],\n                custom_objects=custom_objects,\n                printable_module_name='output_shape function in Lambda layer')\n        elif output_shape_type == 'lambda':\n            # Unsafe deserialization from bytecode\n            output_shape = func_load(config['output_shape'], globs=globs)\n        else:\n            output_shape = config['output_shape']\n\n        # If arguments were numpy array, they have been saved as\n        # list. We need to recover the ndarray\n        if 'arguments' in config:\n            for key in config['arguments']:\n                if isinstance(config['arguments'][key], dict):\n                    arg_dict = config['arguments'][key]\n                    if 'type' in arg_dict and arg_dict['type'] == 'ndarray':\n                        # Overwrite the argument with its numpy translation\n                        config['arguments'][key] = np.array(arg_dict['value'])\n\n        config['function'] = function\n        config['output_shape'] = output_shape\n        return cls(**config)",
        "begin_line": 697,
        "end_line": 740,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.Dense.__init__#807",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.__init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n        super(Dense, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(min_ndim=2)\n        self.supports_masking = True",
        "begin_line": 807,
        "end_line": 832,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002012072434607646,
            "pseudo_dstar_susp": 0.008264462809917356,
            "pseudo_tarantula_susp": 0.0011363636363636363,
            "pseudo_op2_susp": 0.008264462809917356,
            "pseudo_barinel_susp": 0.0011363636363636363
        }
    },
    {
        "name": "keras.layers.core.Dense.build#834",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        assert len(input_shape) >= 2\n        input_dim = input_shape[-1]\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units),\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.units,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n        self.built = True",
        "begin_line": 834,
        "end_line": 852,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002173913043478261,
            "pseudo_dstar_susp": 0.011235955056179775,
            "pseudo_tarantula_susp": 0.001004016064257028,
            "pseudo_op2_susp": 0.011235955056179775,
            "pseudo_barinel_susp": 0.001004016064257028
        }
    },
    {
        "name": "keras.layers.core.Dense.call#854",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = K.dot(inputs, self.kernel)\n        if self.use_bias:\n            output = K.bias_add(output, self.bias)\n        if self.activation is not None:\n            output = self.activation(output)\n        return output",
        "begin_line": 854,
        "end_line": 860,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002173913043478261,
            "pseudo_dstar_susp": 0.011235955056179775,
            "pseudo_tarantula_susp": 0.001004016064257028,
            "pseudo_op2_susp": 0.011235955056179775,
            "pseudo_barinel_susp": 0.001004016064257028
        }
    },
    {
        "name": "keras.layers.core.Dense.compute_output_shape#862",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) >= 2\n        assert input_shape[-1]\n        output_shape = list(input_shape)\n        output_shape[-1] = self.units\n        return tuple(output_shape)",
        "begin_line": 862,
        "end_line": 867,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002109704641350211,
            "pseudo_dstar_susp": 0.00980392156862745,
            "pseudo_tarantula_susp": 0.0009852216748768472,
            "pseudo_op2_susp": 0.00980392156862745,
            "pseudo_barinel_susp": 0.0009852216748768472
        }
    },
    {
        "name": "keras.layers.core.Dense.get_config#869",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'units': self.units,\n            'activation': activations.serialize(self.activation),\n            'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(Dense, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 869,
        "end_line": 883,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005482456140350877,
            "pseudo_dstar_susp": 0.0004730368968779565,
            "pseudo_tarantula_susp": 0.0010256410256410256,
            "pseudo_op2_susp": 0.0004730368968779565,
            "pseudo_barinel_susp": 0.0010256410256410256
        }
    },
    {
        "name": "keras.layers.core.ActivityRegularization.__init__#902",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.ActivityRegularization",
        "signature": "keras.layers.core.ActivityRegularization.__init__(self, l1=0.0, l2=0.0, **kwargs)",
        "snippet": "    def __init__(self, l1=0., l2=0., **kwargs):\n        super(ActivityRegularization, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.l1 = l1\n        self.l2 = l2\n        self.activity_regularizer = regularizers.L1L2(l1=l1, l2=l2)",
        "begin_line": 902,
        "end_line": 907,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.ActivityRegularization.get_config#909",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.ActivityRegularization",
        "signature": "keras.layers.core.ActivityRegularization.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'l1': self.l1,\n                  'l2': self.l2}\n        base_config = super(ActivityRegularization, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 909,
        "end_line": 913,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.layers.core.ActivityRegularization.compute_output_shape#915",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.ActivityRegularization",
        "signature": "keras.layers.core.ActivityRegularization.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 915,
        "end_line": 916,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.metrics.binary_accuracy#26",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.binary_accuracy(y_true, y_pred)",
        "snippet": "def binary_accuracy(y_true, y_pred):\n    return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)",
        "begin_line": 26,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.816009873931059e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.metrics.categorical_accuracy#30",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.categorical_accuracy(y_true, y_pred)",
        "snippet": "def categorical_accuracy(y_true, y_pred):\n    return K.cast(K.equal(K.argmax(y_true, axis=-1),\n                          K.argmax(y_pred, axis=-1)),\n                  K.floatx())",
        "begin_line": 30,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005202913631633715,
            "pseudo_dstar_susp": 0.00046189376443418013,
            "pseudo_tarantula_susp": 0.0008849557522123894,
            "pseudo_op2_susp": 0.00046189376443418013,
            "pseudo_barinel_susp": 0.0008849557522123894
        }
    },
    {
        "name": "keras.metrics.sparse_categorical_accuracy#36",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.sparse_categorical_accuracy(y_true, y_pred)",
        "snippet": "def sparse_categorical_accuracy(y_true, y_pred):\n    return K.cast(K.equal(K.max(y_true, axis=-1),\n                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())),\n                  K.floatx())",
        "begin_line": 36,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00013048016701461377,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.metrics.top_k_categorical_accuracy#42",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)",
        "snippet": "def top_k_categorical_accuracy(y_true, y_pred, k=5):\n    return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k), axis=-1)",
        "begin_line": 42,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.metrics.sparse_top_k_categorical_accuracy#46",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=5)",
        "snippet": "def sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n    return K.mean(K.in_top_k(y_pred, K.cast(K.max(y_true, axis=-1), 'int32'), k), axis=-1)",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.metrics.serialize#59",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.serialize(metric)",
        "snippet": "def serialize(metric):\n    return serialize_keras_object(metric)",
        "begin_line": 59,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.0001487652484379649,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.metrics.deserialize#63",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='metric function')",
        "begin_line": 63,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 8.276090374906894e-05,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    },
    {
        "name": "keras.metrics.get#70",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.get(identifier)",
        "snippet": "def get(identifier):\n    if isinstance(identifier, dict):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif isinstance(identifier, six.string_types):\n        return deserialize(str(identifier))\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret '\n                         'metric function identifier:', identifier)",
        "begin_line": 70,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00011899095668729176,
            "pseudo_dstar_susp": 0.00011899095668729176,
            "pseudo_tarantula_susp": 0.00011899095668729176,
            "pseudo_op2_susp": 0.00022026431718061675,
            "pseudo_barinel_susp": 0.00011899095668729176
        }
    }
]