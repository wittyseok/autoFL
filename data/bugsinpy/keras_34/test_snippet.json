[
    {
        "name": "tests.test_multiprocessing.DummySequence.__getitem__#17",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing.DummySequence",
        "signature": "tests.test_multiprocessing.DummySequence.__getitem__(self, idx)",
        "snippet": "    def __getitem__(self, idx):\n        return np.zeros([10, 2]), np.ones([10])",
        "begin_line": 17,
        "end_line": 18,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.DummySequence.__len__#20",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing.DummySequence",
        "signature": "tests.test_multiprocessing.DummySequence.__len__(self)",
        "snippet": "    def __len__(self):\n        return 10",
        "begin_line": 20,
        "end_line": 21,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.in_tmpdir#25",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.in_tmpdir(tmpdir)",
        "snippet": "def in_tmpdir(tmpdir):\n    \"\"\"Runs a function in a temporary directory.\n\n    Checks that the directory is empty afterwards.\n    \"\"\"\n    with tmpdir.as_cwd():\n        yield None\n    assert not tmpdir.listdir()",
        "begin_line": 25,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.test_multiprocessing_training#36",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.test_multiprocessing_training()",
        "snippet": "def test_multiprocessing_training():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    arr_weights = np.random.random(50)\n\n    def custom_generator(use_weights=False):\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            if use_weights:\n                w = arr_weights[start: end]\n                yield X, y, w\n            else:\n                yield X, y\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2, )))\n    model.compile(loss='mse', optimizer='adadelta')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=STEPS_PER_EPOCH,\n                                epochs=1,\n                                verbose=1,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=True)\n    else:\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            epochs=1,\n                            verbose=1,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=WORKERS,\n                            use_multiprocessing=True)\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    model.fit_generator(custom_generator(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=1,\n                        verbose=1,\n                        validation_steps=None,\n                        max_queue_size=10,\n                        workers=WORKERS,\n                        use_multiprocessing=False)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(True),\n                                steps_per_epoch=STEPS_PER_EPOCH,\n                                validation_data=(arr_data[:10],\n                                                 arr_labels[:10],\n                                                 arr_weights[:10]),\n                                validation_steps=1,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n    else:\n        model.fit_generator(custom_generator(True),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            validation_data=(arr_data[:10],\n                                             arr_labels[:10],\n                                             arr_weights[:10]),\n                            validation_steps=1,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    model.fit_generator(custom_generator(True),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=(arr_data[:10],\n                                         arr_labels[:10],\n                                         arr_weights[:10]),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=1,\n                        use_multiprocessing=False)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(True),\n                                steps_per_epoch=STEPS_PER_EPOCH,\n                                validation_data=custom_generator(True),\n                                validation_steps=1,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n    else:\n        model.fit_generator(custom_generator(True),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            validation_data=custom_generator(True),\n                            validation_steps=1,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread AT A TIME, consume on main thread:\n    #   - Worker threads for training and validation run generator SEQUENTIALLY\n    model.fit_generator(custom_generator(True),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=custom_generator(True),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=1,\n                        use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.fit_generator(custom_generator(True),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=custom_generator(True),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=True)\n    model.fit_generator(custom_generator(True),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=custom_generator(True),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=False)\n\n    # - For Sequence\n    model.fit_generator(DummySequence(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=custom_generator(True),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=True)\n    model.fit_generator(DummySequence(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        validation_data=custom_generator(True),\n                        validation_steps=1,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=False)\n\n    # Test invalid use cases\n    def invalid_generator():\n        while True:\n            yield arr_data[:10], arr_data[:10], arr_labels[:10], arr_labels[:10]\n\n    # not specified `validation_steps`\n    with pytest.raises(ValueError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            validation_data=custom_generator(),\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False)\n\n    # validation data is neither a tuple nor a triple.\n    with pytest.raises(ValueError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            validation_data=(arr_data[:10],\n                                             arr_data[:10],\n                                             arr_labels[:10],\n                                             arr_weights[:10]),\n                            validation_steps=1,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False)\n\n    # validation generator is neither a tuple nor a triple.\n    with pytest.raises(ValueError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            validation_data=invalid_generator(),\n                            validation_steps=1,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False)",
        "begin_line": 36,
        "end_line": 239,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.custom_generator#41",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.custom_generator(use_weights=False)",
        "snippet": "    def custom_generator(use_weights=False):\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            if use_weights:\n                w = arr_weights[start: end]\n                yield X, y, w\n            else:\n                yield X, y",
        "begin_line": 41,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.invalid_generator#204",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.invalid_generator()",
        "snippet": "    def invalid_generator():\n        while True:\n            yield arr_data[:10], arr_data[:10], arr_labels[:10], arr_labels[:10]",
        "begin_line": 204,
        "end_line": 206,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.test_multiprocessing_training_from_file#243",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.test_multiprocessing_training_from_file(in_tmpdir)",
        "snippet": "def test_multiprocessing_training_from_file(in_tmpdir):\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    np.savez('data.npz', **{'data': arr_data, 'labels': arr_labels})\n\n    def custom_generator():\n\n        batch_size = 10\n        n_samples = 50\n\n        arr = np.load('data.npz')\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr['data'][start: end]\n            y = arr['labels'][start: end]\n            yield X, y\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2, )))\n    model.compile(loss='mse', optimizer='adadelta')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=STEPS_PER_EPOCH,\n                                epochs=1,\n                                verbose=1,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=True)\n    else:\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            epochs=1,\n                            verbose=1,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=WORKERS,\n                            use_multiprocessing=True)\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    model.fit_generator(custom_generator(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=1,\n                        verbose=1,\n                        validation_steps=None,\n                        max_queue_size=10,\n                        workers=WORKERS,\n                        use_multiprocessing=False)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=STEPS_PER_EPOCH,\n                                epochs=1,\n                                verbose=1,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n    else:\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            epochs=1,\n                            verbose=1,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    model.fit_generator(custom_generator(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=1,\n                        verbose=1,\n                        validation_steps=None,\n                        max_queue_size=10,\n                        workers=1,\n                        use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.fit_generator(custom_generator(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=1,\n                        verbose=1,\n                        validation_steps=None,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=True)\n    model.fit_generator(custom_generator(),\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=1,\n                        verbose=1,\n                        validation_steps=None,\n                        max_queue_size=10,\n                        workers=0,\n                        use_multiprocessing=False)\n\n    os.remove('data.npz')",
        "begin_line": 243,
        "end_line": 359,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.custom_generator#248",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.custom_generator()",
        "snippet": "    def custom_generator():\n\n        batch_size = 10\n        n_samples = 50\n\n        arr = np.load('data.npz')\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr['data'][start: end]\n            y = arr['labels'][start: end]\n            yield X, y",
        "begin_line": 248,
        "end_line": 261,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.test_multiprocessing_predicting#363",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.test_multiprocessing_predicting()",
        "snippet": "def test_multiprocessing_predicting():\n    arr_data = np.random.randint(0, 256, (50, 2))\n\n    def custom_generator():\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            yield X\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2, )))\n    model.compile(loss='mse', optimizer='adadelta')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `predict_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.predict_generator(custom_generator(),\n                                    steps=STEPS,\n                                    max_queue_size=10,\n                                    workers=WORKERS,\n                                    use_multiprocessing=True)\n    else:\n        model.predict_generator(custom_generator(),\n                                steps=STEPS,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=True)\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    model.predict_generator(custom_generator(),\n                            steps=STEPS,\n                            max_queue_size=10,\n                            workers=WORKERS,\n                            use_multiprocessing=False)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `predict_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.predict_generator(custom_generator(),\n                                    steps=STEPS,\n                                    max_queue_size=10,\n                                    workers=1,\n                                    use_multiprocessing=True)\n    else:\n        model.predict_generator(custom_generator(),\n                                steps=STEPS,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    model.predict_generator(custom_generator(),\n                            steps=STEPS,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False)\n\n    # - Main thread runs the generator without a queue\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.predict_generator(custom_generator(),\n                            steps=STEPS,\n                            max_queue_size=10,\n                            workers=0,\n                            use_multiprocessing=True)\n    model.predict_generator(custom_generator(),\n                            steps=STEPS,\n                            max_queue_size=10,\n                            workers=0,\n                            use_multiprocessing=False)",
        "begin_line": 363,
        "end_line": 447,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.custom_generator#366",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.custom_generator()",
        "snippet": "    def custom_generator():\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            yield X",
        "begin_line": 366,
        "end_line": 375,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.test_multiprocessing_evaluating#451",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.test_multiprocessing_evaluating()",
        "snippet": "def test_multiprocessing_evaluating():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n\n    def custom_generator():\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n\n    # Build a NN\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2, )))\n    model.compile(loss='mse', optimizer='adadelta')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries\n    #       -> make sure `evaluate_generator()` raises raises ValueError\n    #          exception and does not attempt to run the generator.\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=STEPS,\n                                     max_queue_size=10,\n                                     workers=WORKERS,\n                                     use_multiprocessing=True)\n    else:\n        model.evaluate_generator(custom_generator(),\n                                 steps=STEPS,\n                                 max_queue_size=10,\n                                 workers=WORKERS,\n                                 use_multiprocessing=True)\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    model.evaluate_generator(custom_generator(),\n                             steps=STEPS,\n                             max_queue_size=10,\n                             workers=WORKERS,\n                             use_multiprocessing=False)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=STEPS,\n                                     max_queue_size=10,\n                                     workers=1,\n                                     use_multiprocessing=True)\n    else:\n        model.evaluate_generator(custom_generator(),\n                                 steps=STEPS,\n                                 max_queue_size=10,\n                                 workers=1,\n                                 use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    model.evaluate_generator(custom_generator(),\n                             steps=STEPS,\n                             max_queue_size=10,\n                             workers=1,\n                             use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    model.evaluate_generator(custom_generator(),\n                             steps=STEPS,\n                             max_queue_size=10,\n                             workers=0,\n                             use_multiprocessing=True)\n    model.evaluate_generator(custom_generator(),\n                             steps=STEPS,\n                             max_queue_size=10,\n                             workers=0,\n                             use_multiprocessing=False)",
        "begin_line": 451,
        "end_line": 538,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.custom_generator#455",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.custom_generator()",
        "snippet": "    def custom_generator():\n        batch_size = 10\n        n_samples = 50\n\n        while True:\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y",
        "begin_line": 455,
        "end_line": 465,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.test_multiprocessing_fit_error#542",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.test_multiprocessing_fit_error()",
        "snippet": "def test_multiprocessing_fit_error():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    batch_size = 10\n    n_samples = 50\n    good_batches = 3\n\n    def custom_generator(use_weights=False):\n        \"\"\"Raises an exception after a few good batches\"\"\"\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n        raise RuntimeError\n\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2, )))\n    model.compile(loss='mse', optimizer='adadelta')\n\n    samples = batch_size * (good_batches + 1)\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=samples,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=samples,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=True)\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=samples,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=WORKERS,\n                            use_multiprocessing=False)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `fit_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=samples,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.fit_generator(custom_generator(),\n                                steps_per_epoch=samples,\n                                validation_steps=None,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=samples,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=samples,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=0,\n                            use_multiprocessing=True)\n    with pytest.raises(RuntimeError):\n        model.fit_generator(custom_generator(),\n                            steps_per_epoch=samples,\n                            validation_steps=None,\n                            max_queue_size=10,\n                            workers=0,\n                            use_multiprocessing=False)",
        "begin_line": 542,
        "end_line": 650,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.custom_generator#549",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.custom_generator(use_weights=False)",
        "snippet": "    def custom_generator(use_weights=False):\n        \"\"\"Raises an exception after a few good batches\"\"\"\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n        raise RuntimeError",
        "begin_line": 549,
        "end_line": 558,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.test_multiprocessing_evaluate_error#654",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.test_multiprocessing_evaluate_error()",
        "snippet": "def test_multiprocessing_evaluate_error():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    arr_labels = np.random.randint(0, 2, 50)\n    batch_size = 10\n    n_samples = 50\n    good_batches = 3\n\n    def custom_generator():\n        \"\"\"Raises an exception after a few good batches\"\"\"\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n        raise RuntimeError\n\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2, )))\n    model.compile(loss='mse', optimizer='adadelta')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=good_batches * WORKERS + 1,\n                                     max_queue_size=10,\n                                     workers=WORKERS,\n                                     use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=good_batches * WORKERS + 1,\n                                     max_queue_size=10,\n                                     workers=WORKERS,\n                                     use_multiprocessing=True)\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.evaluate_generator(custom_generator(),\n                                 steps=good_batches * WORKERS + 1,\n                                 max_queue_size=10,\n                                 workers=WORKERS,\n                                 use_multiprocessing=False)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=good_batches + 1,\n                                     max_queue_size=10,\n                                     workers=1,\n                                     use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.evaluate_generator(custom_generator(),\n                                     steps=good_batches + 1,\n                                     max_queue_size=10,\n                                     workers=1,\n                                     use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.evaluate_generator(custom_generator(),\n                                 steps=good_batches + 1,\n                                 max_queue_size=10,\n                                 workers=1,\n                                 use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.evaluate_generator(custom_generator(),\n                                 steps=good_batches + 1,\n                                 max_queue_size=10,\n                                 workers=0,\n                                 use_multiprocessing=True)\n    with pytest.raises(RuntimeError):\n        model.evaluate_generator(custom_generator(),\n                                 steps=good_batches + 1,\n                                 max_queue_size=10,\n                                 workers=0,\n                                 use_multiprocessing=False)",
        "begin_line": 654,
        "end_line": 752,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.custom_generator#661",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.custom_generator()",
        "snippet": "    def custom_generator():\n        \"\"\"Raises an exception after a few good batches\"\"\"\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            y = arr_labels[start: end]\n            yield X, y\n        raise RuntimeError",
        "begin_line": 661,
        "end_line": 670,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.test_multiprocessing_predict_error#756",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.test_multiprocessing_predict_error()",
        "snippet": "def test_multiprocessing_predict_error():\n    arr_data = np.random.randint(0, 256, (50, 2))\n    good_batches = 3\n\n    def custom_generator():\n        \"\"\"Raises an exception after a few good batches\"\"\"\n        batch_size = 10\n        n_samples = 50\n\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            yield X\n        raise RuntimeError\n\n    model = Sequential()\n    model.add(Dense(1, input_shape=(2, )))\n    model.compile(loss='mse', optimizer='adadelta')\n\n    # - Produce data on 4 worker processes, consume on main process:\n    #   - Each worker process runs OWN copy of generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `predict_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.predict_generator(custom_generator(),\n                                    steps=good_batches * WORKERS + 1,\n                                    max_queue_size=10,\n                                    workers=WORKERS,\n                                    use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.predict_generator(custom_generator(),\n                                    steps=good_batches * WORKERS + 1,\n                                    max_queue_size=10,\n                                    workers=WORKERS,\n                                    use_multiprocessing=True)\n\n    # - Produce data on 4 worker threads, consume on main thread:\n    #   - All worker threads share the SAME generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.predict_generator(custom_generator(),\n                                steps=good_batches * WORKERS + 1,\n                                max_queue_size=10,\n                                workers=WORKERS,\n                                use_multiprocessing=False)\n\n    # - Produce data on 1 worker process, consume on main process:\n    #   - Worker process runs generator\n    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n    #     process boundaries -> make sure `predict_generator()` raises ValueError\n    #     exception and does not attempt to run the generator.\n    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n    if os.name is 'nt':\n        with pytest.raises(ValueError):\n            model.predict_generator(custom_generator(),\n                                    steps=good_batches + 1,\n                                    max_queue_size=10,\n                                    workers=1,\n                                    use_multiprocessing=True)\n    else:\n        with pytest.raises(RuntimeError):\n            model.predict_generator(custom_generator(),\n                                    steps=good_batches + 1,\n                                    max_queue_size=10,\n                                    workers=1,\n                                    use_multiprocessing=True)\n\n    # - Produce data on 1 worker thread, consume on main thread:\n    #   - Worker thread is the only thread running the generator\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.predict_generator(custom_generator(),\n                                steps=good_batches + 1,\n                                max_queue_size=10,\n                                workers=1,\n                                use_multiprocessing=False)\n\n    # - Produce and consume data without a queue on main thread\n    #   - Make sure the value of `use_multiprocessing` is ignored\n    #   - Make sure `RuntimeError` exception bubbles up\n    with pytest.raises(RuntimeError):\n        model.predict_generator(custom_generator(),\n                                steps=good_batches + 1,\n                                max_queue_size=10,\n                                workers=0,\n                                use_multiprocessing=True)\n    with pytest.raises(RuntimeError):\n        model.predict_generator(custom_generator(),\n                                steps=good_batches + 1,\n                                max_queue_size=10,\n                                workers=0,\n                                use_multiprocessing=False)",
        "begin_line": 756,
        "end_line": 853,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.test_multiprocessing.custom_generator#760",
        "src_path": "tests/test_multiprocessing.py",
        "class_name": "tests.test_multiprocessing",
        "signature": "tests.test_multiprocessing.custom_generator()",
        "snippet": "    def custom_generator():\n        \"\"\"Raises an exception after a few good batches\"\"\"\n        batch_size = 10\n        n_samples = 50\n\n        for i in range(good_batches):\n            batch_index = np.random.randint(0, n_samples - batch_size)\n            start = batch_index\n            end = start + batch_size\n            X = arr_data[start: end]\n            yield X\n        raise RuntimeError",
        "begin_line": 760,
        "end_line": 771,
        "comment": "",
        "is_bug": false
    }
]