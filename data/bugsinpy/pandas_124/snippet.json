[
    {
        "name": "pandas.compat.numpy.function.CompatValidator.__call__#42",
        "src_path": "pandas/compat/numpy/function.py",
        "class_name": "pandas.compat.numpy.function.CompatValidator",
        "signature": "pandas.compat.numpy.function.CompatValidator.__call__(self, args, kwargs, fname=None, max_fname_arg_count=None, method=None)",
        "snippet": "    def __call__(self, args, kwargs, fname=None, max_fname_arg_count=None, method=None):\n        if args or kwargs:\n            fname = self.fname if fname is None else fname\n            max_fname_arg_count = (\n                self.max_fname_arg_count\n                if max_fname_arg_count is None\n                else max_fname_arg_count\n            )\n            method = self.method if method is None else method\n\n            if method == \"args\":\n                validate_args(fname, args, max_fname_arg_count, self.defaults)\n            elif method == \"kwargs\":\n                validate_kwargs(fname, kwargs, self.defaults)\n            elif method == \"both\":\n                validate_args_and_kwargs(\n                    fname, args, kwargs, max_fname_arg_count, self.defaults\n                )\n            else:\n                raise ValueError(f\"invalid validation method '{method}'\")",
        "begin_line": 42,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.conftest.pytest_runtest_setup#48",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.pytest_runtest_setup(item)",
        "snippet": "def pytest_runtest_setup(item):\n    if \"slow\" in item.keywords and item.config.getoption(\"--skip-slow\"):\n        pytest.skip(\"skipping due to --skip-slow\")\n\n    if \"slow\" not in item.keywords and item.config.getoption(\"--only-slow\"):\n        pytest.skip(\"skipping due to --only-slow\")\n\n    if \"network\" in item.keywords and item.config.getoption(\"--skip-network\"):\n        pytest.skip(\"skipping due to --skip-network\")\n\n    if \"db\" in item.keywords and item.config.getoption(\"--skip-db\"):\n        pytest.skip(\"skipping due to --skip-db\")\n\n    if \"high_memory\" in item.keywords and not item.config.getoption(\n        \"--run-high-memory\"\n    ):\n        pytest.skip(\"skipping high memory test since --run-high-memory was not set\")",
        "begin_line": 48,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.conftest.configure_tests#71",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.configure_tests()",
        "snippet": "def configure_tests():\n    pd.set_option(\"chained_assignment\", \"raise\")",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.conftest.add_imports#79",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.add_imports(doctest_namespace)",
        "snippet": "def add_imports(doctest_namespace):\n    doctest_namespace[\"np\"] = np\n    doctest_namespace[\"pd\"] = pd",
        "begin_line": 79,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.Registry.find#82",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.Registry",
        "signature": "pandas.core.dtypes.dtypes.Registry.find(self, dtype: Union[Type[ExtensionDtype], str])",
        "snippet": "    def find(\n        self, dtype: Union[Type[ExtensionDtype], str]\n    ) -> Optional[Type[ExtensionDtype]]:\n        \"\"\"\n        Parameters\n        ----------\n        dtype : Type[ExtensionDtype] or str\n\n        Returns\n        -------\n        return the first matching dtype, otherwise return None\n        \"\"\"\n        if not isinstance(dtype, str):\n            dtype_type = dtype\n            if not isinstance(dtype, type):\n                dtype_type = type(dtype)\n            if issubclass(dtype_type, ExtensionDtype):\n                return dtype\n\n            return None\n\n        for dtype_type in self.dtypes:\n            try:\n                return dtype_type.construct_from_string(dtype)\n            except TypeError:\n                pass\n\n        return None",
        "begin_line": 82,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.DatetimeTZDtype.construct_from_string#722",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.DatetimeTZDtype",
        "signature": "pandas.core.dtypes.dtypes.DatetimeTZDtype.construct_from_string(cls, string: str_type)",
        "snippet": "    def construct_from_string(cls, string: str_type):\n        \"\"\"\n        Construct a DatetimeTZDtype from a string.\n\n        Parameters\n        ----------\n        string : str\n            The string alias for this DatetimeTZDtype.\n            Should be formatted like ``datetime64[ns, <tz>]``,\n            where ``<tz>`` is the timezone name.\n\n        Examples\n        --------\n        >>> DatetimeTZDtype.construct_from_string('datetime64[ns, UTC]')\n        datetime64[ns, UTC]\n        \"\"\"\n        if isinstance(string, str):\n            msg = \"Could not construct DatetimeTZDtype from '{string}'\"\n            match = cls._match.match(string)\n            if match:\n                d = match.groupdict()\n                try:\n                    return cls(unit=d[\"unit\"], tz=d[\"tz\"])\n                except (KeyError, TypeError, ValueError) as err:\n                    # KeyError if maybe_get_tz tries and fails to get a\n                    #  pytz timezone (actually pytz.UnknownTimeZoneError).\n                    # TypeError if we pass a nonsense tz;\n                    # ValueError if we pass a unit other than \"ns\"\n                    raise TypeError(msg.format(string=string)) from err\n            raise TypeError(msg.format(string=string))\n\n        raise TypeError(\"Could not construct DatetimeTZDtype\")",
        "begin_line": 722,
        "end_line": 753,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.PeriodDtype.construct_from_string#874",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.PeriodDtype",
        "signature": "pandas.core.dtypes.dtypes.PeriodDtype.construct_from_string(cls, string)",
        "snippet": "    def construct_from_string(cls, string):\n        \"\"\"\n        Strict construction from a string, raise a TypeError if not\n        possible\n        \"\"\"\n        if (\n            isinstance(string, str)\n            and (string.startswith(\"period[\") or string.startswith(\"Period[\"))\n            or isinstance(string, ABCDateOffset)\n        ):\n            # do not parse string like U as period[U]\n            # avoid tuple to be regarded as freq\n            try:\n                return cls(freq=string)\n            except ValueError:\n                pass\n        raise TypeError(\"could not construct PeriodDtype\")",
        "begin_line": 874,
        "end_line": 890,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.PeriodDtype.is_dtype#920",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.PeriodDtype",
        "signature": "pandas.core.dtypes.dtypes.PeriodDtype.is_dtype(cls, dtype)",
        "snippet": "    def is_dtype(cls, dtype) -> bool:\n        \"\"\"\n        Return a boolean if we if the passed type is an actual dtype that we\n        can match (via string or type)\n        \"\"\"\n\n        if isinstance(dtype, str):\n            # PeriodDtype can be instantiated from freq string like \"U\",\n            # but doesn't regard freq str like \"U\" as dtype.\n            if dtype.startswith(\"period[\") or dtype.startswith(\"Period[\"):\n                try:\n                    if cls._parse_dtype_strict(dtype) is not None:\n                        return True\n                    else:\n                        return False\n                except ValueError:\n                    return False\n            else:\n                return False\n        return super().is_dtype(dtype)",
        "begin_line": 920,
        "end_line": 939,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.IntervalDtype.construct_from_string#1048",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.IntervalDtype",
        "signature": "pandas.core.dtypes.dtypes.IntervalDtype.construct_from_string(cls, string)",
        "snippet": "    def construct_from_string(cls, string):\n        \"\"\"\n        attempt to construct this type from a string, raise a TypeError\n        if its not possible\n        \"\"\"\n        if not isinstance(string, str):\n            msg = \"a string needs to be passed, got type {typ}\"\n            raise TypeError(msg.format(typ=type(string)))\n\n        if string.lower() == \"interval\" or cls._match.search(string) is not None:\n            return cls(string)\n\n        msg = (\n            \"Incorrectly formatted string passed to constructor. \"\n            \"Valid formats include Interval or Interval[dtype] \"\n            \"where dtype is numeric, datetime, or timedelta\"\n        )\n        raise TypeError(msg)",
        "begin_line": 1048,
        "end_line": 1065,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.IntervalDtype.is_dtype#1100",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.IntervalDtype",
        "signature": "pandas.core.dtypes.dtypes.IntervalDtype.is_dtype(cls, dtype)",
        "snippet": "    def is_dtype(cls, dtype) -> bool:\n        \"\"\"\n        Return a boolean if we if the passed type is an actual dtype that we\n        can match (via string or type)\n        \"\"\"\n\n        if isinstance(dtype, str):\n            if dtype.lower().startswith(\"interval\"):\n                try:\n                    if cls.construct_from_string(dtype) is not None:\n                        return True\n                    else:\n                        return False\n                except (ValueError, TypeError):\n                    return False\n            else:\n                return False\n        return super().is_dtype(dtype)",
        "begin_line": 1100,
        "end_line": 1117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.roperator.radd#8",
        "src_path": "pandas/core/ops/roperator.py",
        "class_name": "pandas.core.ops.roperator",
        "signature": "pandas.core.ops.roperator.radd(left, right)",
        "snippet": "def radd(left, right):\n    return right + left",
        "begin_line": 8,
        "end_line": 9,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex.__new__#47",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex.__new__(cls, data=None, dtype=None, copy=False, name=None, fastpath=None)",
        "snippet": "    def __new__(cls, data=None, dtype=None, copy=False, name=None, fastpath=None):\n\n        if fastpath is not None:\n            warnings.warn(\n                \"The 'fastpath' keyword is deprecated, and will be \"\n                \"removed in a future version.\",\n                FutureWarning,\n                stacklevel=2,\n            )\n            if fastpath:\n                return cls._simple_new(data, name=name)\n\n        # Coerce to ndarray if not already ndarray or Index\n        if not isinstance(data, (np.ndarray, Index)):\n            if is_scalar(data):\n                raise cls._scalar_data_error(data)\n\n            # other iterable of some kind\n            if not isinstance(data, (ABCSeries, list, tuple)):\n                data = list(data)\n\n            data = np.asarray(data, dtype=dtype)\n\n        if issubclass(data.dtype.type, str):\n            cls._string_data_error(data)\n\n        if copy or not is_dtype_equal(data.dtype, cls._default_dtype):\n            subarr = np.array(data, dtype=cls._default_dtype, copy=copy)\n            cls._assert_safe_casting(data, subarr)\n        else:\n            subarr = data\n\n        if name is None and hasattr(data, \"name\"):\n            name = data.name\n        return cls._simple_new(subarr, name=name)",
        "begin_line": 47,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex._shallow_copy#91",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex._shallow_copy(self, values=None, **kwargs)",
        "snippet": "    def _shallow_copy(self, values=None, **kwargs):\n        if values is not None and not self._can_hold_na:\n            # Ensure we are not returning an Int64Index with float data:\n            return self._shallow_copy_with_infer(values=values, **kwargs)\n        return super()._shallow_copy(values=values, **kwargs)",
        "begin_line": 91,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex.is_all_dates#146",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex.is_all_dates(self)",
        "snippet": "    def is_all_dates(self) -> bool:\n        \"\"\"\n        Checks that all the labels are datetime objects.\n        \"\"\"\n        return False",
        "begin_line": 146,
        "end_line": 150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.numeric.IntegerIndex.__contains__#218",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.IntegerIndex",
        "signature": "pandas.core.indexes.numeric.IntegerIndex.__contains__(self, key)",
        "snippet": "    def __contains__(self, key) -> bool:\n        \"\"\"\n        Check if key is a float and has a decimal. If it has, return False.\n        \"\"\"\n        hash(key)\n        try:\n            if is_float(key) and int(key) != key:\n                return False\n            return key in self._engine\n        except (OverflowError, TypeError, ValueError):\n            return False",
        "begin_line": 218,
        "end_line": 228,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.numeric.Int64Index.inferred_type#240",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.Int64Index",
        "signature": "pandas.core.indexes.numeric.Int64Index.inferred_type(self)",
        "snippet": "    def inferred_type(self) -> str:\n        \"\"\"Always 'integer' for ``Int64Index``\"\"\"\n        return \"integer\"",
        "begin_line": 240,
        "end_line": 242,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.numeric.Int64Index._convert_scalar_indexer#250",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.Int64Index",
        "signature": "pandas.core.indexes.numeric.Int64Index._convert_scalar_indexer(self, key, kind=None)",
        "snippet": "    def _convert_scalar_indexer(self, key, kind=None):\n        assert kind in [\"ix\", \"loc\", \"getitem\", \"iloc\", None]\n\n        # don't coerce ilocs to integers\n        if kind != \"iloc\":\n            key = self._maybe_cast_indexer(key)\n        return super()._convert_scalar_indexer(key, kind=kind)",
        "begin_line": 250,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.cat_core#49",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.cat_core(list_of_columns: List, sep: str)",
        "snippet": "def cat_core(list_of_columns: List, sep: str):\n    \"\"\"\n    Auxiliary function for :meth:`str.cat`\n\n    Parameters\n    ----------\n    list_of_columns : list of numpy arrays\n        List of arrays to be concatenated with sep;\n        these arrays may not contain NaNs!\n    sep : string\n        The separator string for concatenating the columns.\n\n    Returns\n    -------\n    nd.array\n        The concatenation of list_of_columns with sep.\n    \"\"\"\n    if sep == \"\":\n        # no need to interleave sep if it is empty\n        return np.sum(list_of_columns, axis=0)\n    list_with_sep = [sep] * (2 * len(list_of_columns) - 1)\n    list_with_sep[::2] = list_of_columns\n    return np.sum(list_with_sep, axis=0)",
        "begin_line": 49,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.cat_safe#74",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.cat_safe(list_of_columns: List, sep: str)",
        "snippet": "def cat_safe(list_of_columns: List, sep: str):\n    \"\"\"\n    Auxiliary function for :meth:`str.cat`.\n\n    Same signature as cat_core, but handles TypeErrors in concatenation, which\n    happen if the arrays in list_of columns have the wrong dtypes or content.\n\n    Parameters\n    ----------\n    list_of_columns : list of numpy arrays\n        List of arrays to be concatenated with sep;\n        these arrays may not contain NaNs!\n    sep : string\n        The separator string for concatenating the columns.\n\n    Returns\n    -------\n    nd.array\n        The concatenation of list_of_columns with sep.\n    \"\"\"\n    try:\n        result = cat_core(list_of_columns, sep)\n    except TypeError:\n        # if there are any non-string values (wrong dtype or hidden behind\n        # object dtype), np.sum will fail; catch and return with better message\n        for column in list_of_columns:\n            dtype = lib.infer_dtype(column, skipna=True)\n            if dtype not in [\"string\", \"empty\"]:\n                raise TypeError(\n                    \"Concatenation requires list-likes containing only \"\n                    \"strings (or missing values). Offending values found in \"\n                    \"column {}\".format(dtype)\n                ) from None\n    return result",
        "begin_line": 74,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings._na_map#110",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._na_map(f, arr, na_result=np.nan, dtype=object)",
        "snippet": "def _na_map(f, arr, na_result=np.nan, dtype=object):\n    # should really _check_ for NA\n    return _map(f, arr, na_mask=True, na_value=na_result, dtype=dtype)",
        "begin_line": 110,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings._map#115",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._map(f, arr, na_mask=False, na_value=np.nan, dtype=object)",
        "snippet": "def _map(f, arr, na_mask=False, na_value=np.nan, dtype=object):\n    if not len(arr):\n        return np.ndarray(0, dtype=dtype)\n\n    if isinstance(arr, ABCSeries):\n        arr = arr.values\n    if not isinstance(arr, np.ndarray):\n        arr = np.asarray(arr, dtype=object)\n    if na_mask:\n        mask = isna(arr)\n        convert = not np.all(mask)\n        try:\n            result = lib.map_infer_mask(arr, f, mask.view(np.uint8), convert)\n        except (TypeError, AttributeError) as e:\n            # Reraise the exception if callable `f` got wrong number of args.\n            # The user may want to be warned by this, instead of getting NaN\n            p_err = (\n                r\"((takes)|(missing)) (?(2)from \\d+ to )?\\d+ \"\n                r\"(?(3)required )positional arguments?\"\n            )\n\n            if len(e.args) >= 1 and re.search(p_err, e.args[0]):\n                # FIXME: this should be totally avoidable\n                raise e\n\n            def g(x):\n                try:\n                    return f(x)\n                except (TypeError, AttributeError):\n                    return na_value\n\n            return _map(g, arr, dtype=dtype)\n        if na_value is not np.nan:\n            np.putmask(result, mask, na_value)\n            if result.dtype == object:\n                result = lib.maybe_convert_objects(result)\n        return result\n    else:\n        return lib.map_infer(arr, f)",
        "begin_line": 115,
        "end_line": 153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_count#156",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_count(arr, pat, flags=0)",
        "snippet": "def str_count(arr, pat, flags=0):\n    \"\"\"\n    Count occurrences of pattern in each string of the Series/Index.\n\n    This function is used to count the number of times a particular regex\n    pattern is repeated in each of the string elements of the\n    :class:`~pandas.Series`.\n\n    Parameters\n    ----------\n    pat : str\n        Valid regular expression.\n    flags : int, default 0, meaning no flags\n        Flags for the `re` module. For a complete list, `see here\n        <https://docs.python.org/3/howto/regex.html#compilation-flags>`_.\n    **kwargs\n        For compatibility with other string methods. Not used.\n\n    Returns\n    -------\n    Series or Index\n        Same type as the calling object containing the integer counts.\n\n    See Also\n    --------\n    re : Standard library module for regular expressions.\n    str.count : Standard library version, without regular expression support.\n\n    Notes\n    -----\n    Some characters need to be escaped when passing in `pat`.\n    eg. ``'$'`` has a special meaning in regex and must be escaped when\n    finding this literal character.\n\n    Examples\n    --------\n    >>> s = pd.Series(['A', 'B', 'Aaba', 'Baca', np.nan, 'CABA', 'cat'])\n    >>> s.str.count('a')\n    0    0.0\n    1    0.0\n    2    2.0\n    3    2.0\n    4    NaN\n    5    0.0\n    6    1.0\n    dtype: float64\n\n    Escape ``'$'`` to find the literal dollar sign.\n\n    >>> s = pd.Series(['$', 'B', 'Aab$', '$$ca', 'C$B$', 'cat'])\n    >>> s.str.count('\\\\$')\n    0    1\n    1    0\n    2    1\n    3    2\n    4    2\n    5    0\n    dtype: int64\n\n    This is also available on Index\n\n    >>> pd.Index(['A', 'A', 'Aaba', 'cat']).str.count('a')\n    Int64Index([0, 0, 2, 1], dtype='int64')\n    \"\"\"\n    regex = re.compile(pat, flags=flags)\n    f = lambda x: len(regex.findall(x))\n    return _na_map(f, arr, dtype=int)",
        "begin_line": 156,
        "end_line": 222,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_contains#225",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_contains(arr, pat, case=True, flags=0, na=np.nan, regex=True)",
        "snippet": "def str_contains(arr, pat, case=True, flags=0, na=np.nan, regex=True):\n    \"\"\"\n    Test if pattern or regex is contained within a string of a Series or Index.\n\n    Return boolean Series or Index based on whether a given pattern or regex is\n    contained within a string of a Series or Index.\n\n    Parameters\n    ----------\n    pat : str\n        Character sequence or regular expression.\n    case : bool, default True\n        If True, case sensitive.\n    flags : int, default 0 (no flags)\n        Flags to pass through to the re module, e.g. re.IGNORECASE.\n    na : default NaN\n        Fill value for missing values.\n    regex : bool, default True\n        If True, assumes the pat is a regular expression.\n\n        If False, treats the pat as a literal string.\n\n    Returns\n    -------\n    Series or Index of boolean values\n        A Series or Index of boolean values indicating whether the\n        given pattern is contained within the string of each element\n        of the Series or Index.\n\n    See Also\n    --------\n    match : Analogous, but stricter, relying on re.match instead of re.search.\n    Series.str.startswith : Test if the start of each string element matches a\n        pattern.\n    Series.str.endswith : Same as startswith, but tests the end of string.\n\n    Examples\n    --------\n\n    Returning a Series of booleans using only a literal pattern.\n\n    >>> s1 = pd.Series(['Mouse', 'dog', 'house and parrot', '23', np.NaN])\n    >>> s1.str.contains('og', regex=False)\n    0    False\n    1     True\n    2    False\n    3    False\n    4      NaN\n    dtype: object\n\n    Returning an Index of booleans using only a literal pattern.\n\n    >>> ind = pd.Index(['Mouse', 'dog', 'house and parrot', '23.0', np.NaN])\n    >>> ind.str.contains('23', regex=False)\n    Index([False, False, False, True, nan], dtype='object')\n\n    Specifying case sensitivity using `case`.\n\n    >>> s1.str.contains('oG', case=True, regex=True)\n    0    False\n    1    False\n    2    False\n    3    False\n    4      NaN\n    dtype: object\n\n    Specifying `na` to be `False` instead of `NaN` replaces NaN values\n    with `False`. If Series or Index does not contain NaN values\n    the resultant dtype will be `bool`, otherwise, an `object` dtype.\n\n    >>> s1.str.contains('og', na=False, regex=True)\n    0    False\n    1     True\n    2    False\n    3    False\n    4    False\n    dtype: bool\n\n    Returning 'house' or 'dog' when either expression occurs in a string.\n\n    >>> s1.str.contains('house|dog', regex=True)\n    0    False\n    1     True\n    2     True\n    3    False\n    4      NaN\n    dtype: object\n\n    Ignoring case sensitivity using `flags` with regex.\n\n    >>> import re\n    >>> s1.str.contains('PARROT', flags=re.IGNORECASE, regex=True)\n    0    False\n    1    False\n    2     True\n    3    False\n    4      NaN\n    dtype: object\n\n    Returning any digit using regular expression.\n\n    >>> s1.str.contains('\\\\d', regex=True)\n    0    False\n    1    False\n    2    False\n    3     True\n    4      NaN\n    dtype: object\n\n    Ensure `pat` is a not a literal pattern when `regex` is set to True.\n    Note in the following example one might expect only `s2[1]` and `s2[3]` to\n    return `True`. However, '.0' as a regex matches any character\n    followed by a 0.\n\n    >>> s2 = pd.Series(['40', '40.0', '41', '41.0', '35'])\n    >>> s2.str.contains('.0', regex=True)\n    0     True\n    1     True\n    2    False\n    3     True\n    4    False\n    dtype: bool\n    \"\"\"\n    if regex:\n        if not case:\n            flags |= re.IGNORECASE\n\n        regex = re.compile(pat, flags=flags)\n\n        if regex.groups > 0:\n            warnings.warn(\n                \"This pattern has match groups. To actually get the\"\n                \" groups, use str.extract.\",\n                UserWarning,\n                stacklevel=3,\n            )\n\n        f = lambda x: bool(regex.search(x))\n    else:\n        if case:\n            f = lambda x: pat in x\n        else:\n            upper_pat = pat.upper()\n            f = lambda x: upper_pat in x\n            uppered = _na_map(lambda x: x.upper(), arr)\n            return _na_map(f, uppered, na, dtype=bool)\n    return _na_map(f, arr, na, dtype=bool)",
        "begin_line": 225,
        "end_line": 371,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_startswith#374",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_startswith(arr, pat, na=np.nan)",
        "snippet": "def str_startswith(arr, pat, na=np.nan):\n    \"\"\"\n    Test if the start of each string element matches a pattern.\n\n    Equivalent to :meth:`str.startswith`.\n\n    Parameters\n    ----------\n    pat : str\n        Character sequence. Regular expressions are not accepted.\n    na : object, default NaN\n        Object shown if element tested is not a string.\n\n    Returns\n    -------\n    Series or Index of bool\n        A Series of booleans indicating whether the given pattern matches\n        the start of each string element.\n\n    See Also\n    --------\n    str.startswith : Python standard library string method.\n    Series.str.endswith : Same as startswith, but tests the end of string.\n    Series.str.contains : Tests if string element contains a pattern.\n\n    Examples\n    --------\n    >>> s = pd.Series(['bat', 'Bear', 'cat', np.nan])\n    >>> s\n    0     bat\n    1    Bear\n    2     cat\n    3     NaN\n    dtype: object\n\n    >>> s.str.startswith('b')\n    0     True\n    1    False\n    2    False\n    3      NaN\n    dtype: object\n\n    Specifying `na` to be `False` instead of `NaN`.\n\n    >>> s.str.startswith('b', na=False)\n    0     True\n    1    False\n    2    False\n    3    False\n    dtype: bool\n    \"\"\"\n    f = lambda x: x.startswith(pat)\n    return _na_map(f, arr, na, dtype=bool)",
        "begin_line": 374,
        "end_line": 426,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_endswith#429",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_endswith(arr, pat, na=np.nan)",
        "snippet": "def str_endswith(arr, pat, na=np.nan):\n    \"\"\"\n    Test if the end of each string element matches a pattern.\n\n    Equivalent to :meth:`str.endswith`.\n\n    Parameters\n    ----------\n    pat : str\n        Character sequence. Regular expressions are not accepted.\n    na : object, default NaN\n        Object shown if element tested is not a string.\n\n    Returns\n    -------\n    Series or Index of bool\n        A Series of booleans indicating whether the given pattern matches\n        the end of each string element.\n\n    See Also\n    --------\n    str.endswith : Python standard library string method.\n    Series.str.startswith : Same as endswith, but tests the start of string.\n    Series.str.contains : Tests if string element contains a pattern.\n\n    Examples\n    --------\n    >>> s = pd.Series(['bat', 'bear', 'caT', np.nan])\n    >>> s\n    0     bat\n    1    bear\n    2     caT\n    3     NaN\n    dtype: object\n\n    >>> s.str.endswith('t')\n    0     True\n    1    False\n    2    False\n    3      NaN\n    dtype: object\n\n    Specifying `na` to be `False` instead of `NaN`.\n\n    >>> s.str.endswith('t', na=False)\n    0     True\n    1    False\n    2    False\n    3    False\n    dtype: bool\n    \"\"\"\n    f = lambda x: x.endswith(pat)\n    return _na_map(f, arr, na, dtype=bool)",
        "begin_line": 429,
        "end_line": 481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_replace#484",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_replace(arr, pat, repl, n=-1, case=None, flags=0, regex=True)",
        "snippet": "def str_replace(arr, pat, repl, n=-1, case=None, flags=0, regex=True):\n    r\"\"\"\n    Replace occurrences of pattern/regex in the Series/Index with\n    some other string. Equivalent to :meth:`str.replace` or\n    :func:`re.sub`.\n\n    Parameters\n    ----------\n    pat : str or compiled regex\n        String can be a character sequence or regular expression.\n    repl : str or callable\n        Replacement string or a callable. The callable is passed the regex\n        match object and must return a replacement string to be used.\n        See :func:`re.sub`.\n    n : int, default -1 (all)\n        Number of replacements to make from start.\n    case : bool, default None\n        Determines if replace is case sensitive:\n\n        - If True, case sensitive (the default if `pat` is a string)\n        - Set to False for case insensitive\n        - Cannot be set if `pat` is a compiled regex.\n\n    flags : int, default 0 (no flags)\n        Regex module flags, e.g. re.IGNORECASE. Cannot be set if `pat` is a compiled\n        regex.\n    regex : bool, default True\n        Determines if assumes the passed-in pattern is a regular expression:\n\n        - If True, assumes the passed-in pattern is a regular expression.\n        - If False, treats the pattern as a literal string\n        - Cannot be set to False if `pat` is a compiled regex or `repl` is\n          a callable.\n\n        .. versionadded:: 0.23.0\n\n    Returns\n    -------\n    Series or Index of object\n        A copy of the object with all matching occurrences of `pat` replaced by\n        `repl`.\n\n    Raises\n    ------\n    ValueError\n        * if `regex` is False and `repl` is a callable or `pat` is a compiled\n          regex\n        * if `pat` is a compiled regex and `case` or `flags` is set\n\n    Notes\n    -----\n    When `pat` is a compiled regex, all flags should be included in the\n    compiled regex. Use of `case`, `flags`, or `regex=False` with a compiled\n    regex will raise an error.\n\n    Examples\n    --------\n    When `pat` is a string and `regex` is True (the default), the given `pat`\n    is compiled as a regex. When `repl` is a string, it replaces matching\n    regex patterns as with :meth:`re.sub`. NaN value(s) in the Series are\n    left as is:\n\n    >>> pd.Series(['foo', 'fuz', np.nan]).str.replace('f.', 'ba', regex=True)\n    0    bao\n    1    baz\n    2    NaN\n    dtype: object\n\n    When `pat` is a string and `regex` is False, every `pat` is replaced with\n    `repl` as with :meth:`str.replace`:\n\n    >>> pd.Series(['f.o', 'fuz', np.nan]).str.replace('f.', 'ba', regex=False)\n    0    bao\n    1    fuz\n    2    NaN\n    dtype: object\n\n    When `repl` is a callable, it is called on every `pat` using\n    :func:`re.sub`. The callable should expect one positional argument\n    (a regex object) and return a string.\n\n    To get the idea:\n\n    >>> pd.Series(['foo', 'fuz', np.nan]).str.replace('f', repr)\n    0    <_sre.SRE_Match object; span=(0, 1), match='f'>oo\n    1    <_sre.SRE_Match object; span=(0, 1), match='f'>uz\n    2                                                  NaN\n    dtype: object\n\n    Reverse every lowercase alphabetic word:\n\n    >>> repl = lambda m: m.group(0)[::-1]\n    >>> pd.Series(['foo 123', 'bar baz', np.nan]).str.replace(r'[a-z]+', repl)\n    0    oof 123\n    1    rab zab\n    2        NaN\n    dtype: object\n\n    Using regex groups (extract second group and swap case):\n\n    >>> pat = r\"(?P<one>\\w+) (?P<two>\\w+) (?P<three>\\w+)\"\n    >>> repl = lambda m: m.group('two').swapcase()\n    >>> pd.Series(['One Two Three', 'Foo Bar Baz']).str.replace(pat, repl)\n    0    tWO\n    1    bAR\n    dtype: object\n\n    Using a compiled regex with flags\n\n    >>> import re\n    >>> regex_pat = re.compile(r'FUZ', flags=re.IGNORECASE)\n    >>> pd.Series(['foo', 'fuz', np.nan]).str.replace(regex_pat, 'bar')\n    0    foo\n    1    bar\n    2    NaN\n    dtype: object\n    \"\"\"\n\n    # Check whether repl is valid (GH 13438, GH 15055)\n    if not (isinstance(repl, str) or callable(repl)):\n        raise TypeError(\"repl must be a string or callable\")\n\n    is_compiled_re = is_re(pat)\n    if regex:\n        if is_compiled_re:\n            if (case is not None) or (flags != 0):\n                raise ValueError(\n                    \"case and flags cannot be set when pat is a compiled regex\"\n                )\n        else:\n            # not a compiled regex\n            # set default case\n            if case is None:\n                case = True\n\n            # add case flag, if provided\n            if case is False:\n                flags |= re.IGNORECASE\n        if is_compiled_re or len(pat) > 1 or flags or callable(repl):\n            n = n if n >= 0 else 0\n            compiled = re.compile(pat, flags=flags)\n            f = lambda x: compiled.sub(repl=repl, string=x, count=n)\n        else:\n            f = lambda x: x.replace(pat, repl, n)\n    else:\n        if is_compiled_re:\n            raise ValueError(\n                \"Cannot use a compiled regex as replacement pattern with regex=False\"\n            )\n        if callable(repl):\n            raise ValueError(\"Cannot use a callable replacement when regex=False\")\n        f = lambda x: x.replace(pat, repl, n)\n\n    return _na_map(f, arr)",
        "begin_line": 484,
        "end_line": 637,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_repeat#640",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_repeat(arr, repeats)",
        "snippet": "def str_repeat(arr, repeats):\n    \"\"\"\n    Duplicate each string in the Series or Index.\n\n    Parameters\n    ----------\n    repeats : int or sequence of int\n        Same value for all (int) or different value per (sequence).\n\n    Returns\n    -------\n    Series or Index of object\n        Series or Index of repeated string objects specified by\n        input parameter repeats.\n\n    Examples\n    --------\n    >>> s = pd.Series(['a', 'b', 'c'])\n    >>> s\n    0    a\n    1    b\n    2    c\n    dtype: object\n\n    Single int repeats string in Series\n\n    >>> s.str.repeat(repeats=2)\n    0    aa\n    1    bb\n    2    cc\n    dtype: object\n\n    Sequence of int repeats corresponding string in Series\n\n    >>> s.str.repeat(repeats=[1, 2, 3])\n    0      a\n    1     bb\n    2    ccc\n    dtype: object\n    \"\"\"\n    if is_scalar(repeats):\n\n        def scalar_rep(x):\n            try:\n                return bytes.__mul__(x, repeats)\n            except TypeError:\n                return str.__mul__(x, repeats)\n\n        return _na_map(scalar_rep, arr)\n    else:\n\n        def rep(x, r):\n            try:\n                return bytes.__mul__(x, r)\n            except TypeError:\n                return str.__mul__(x, r)\n\n        repeats = np.asarray(repeats, dtype=object)\n        result = libops.vec_binop(com.values_from_object(arr), repeats, rep)\n        return result",
        "begin_line": 640,
        "end_line": 699,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.scalar_rep#682",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.scalar_rep(x)",
        "snippet": "        def scalar_rep(x):\n            try:\n                return bytes.__mul__(x, repeats)\n            except TypeError:\n                return str.__mul__(x, repeats)",
        "begin_line": 682,
        "end_line": 686,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_match#702",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_match(arr, pat, case=True, flags=0, na=np.nan)",
        "snippet": "def str_match(arr, pat, case=True, flags=0, na=np.nan):\n    \"\"\"\n    Determine if each string matches a regular expression.\n\n    Parameters\n    ----------\n    pat : str\n        Character sequence or regular expression.\n    case : bool, default True\n        If True, case sensitive.\n    flags : int, default 0 (no flags)\n        Regex module flags, e.g. re.IGNORECASE.\n    na : default NaN\n        Fill value for missing values.\n\n    Returns\n    -------\n    Series/array of boolean values\n\n    See Also\n    --------\n    contains : Analogous, but less strict, relying on re.search instead of\n        re.match.\n    extract : Extract matched groups.\n    \"\"\"\n    if not case:\n        flags |= re.IGNORECASE\n\n    regex = re.compile(pat, flags=flags)\n\n    dtype = bool\n    f = lambda x: bool(regex.match(x))\n\n    return _na_map(f, arr, na, dtype=dtype)",
        "begin_line": 702,
        "end_line": 735,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings._get_single_group_name#738",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._get_single_group_name(rx)",
        "snippet": "def _get_single_group_name(rx):\n    try:\n        return list(rx.groupindex.keys()).pop()\n    except IndexError:\n        return None",
        "begin_line": 738,
        "end_line": 742,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings._groups_or_na_fun#745",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._groups_or_na_fun(regex)",
        "snippet": "def _groups_or_na_fun(regex):\n    \"\"\"Used in both extract_noexpand and extract_frame\"\"\"\n    if regex.groups == 0:\n        raise ValueError(\"pattern contains no capture groups\")\n    empty_row = [np.nan] * regex.groups\n\n    def f(x):\n        if not isinstance(x, str):\n            return empty_row\n        m = regex.search(x)\n        if m:\n            return [np.nan if item is None else item for item in m.groups()]\n        else:\n            return empty_row\n\n    return f",
        "begin_line": 745,
        "end_line": 760,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.f#751",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.f(x)",
        "snippet": "    def f(x):\n        if not isinstance(x, str):\n            return empty_row\n        m = regex.search(x)\n        if m:\n            return [np.nan if item is None else item for item in m.groups()]\n        else:\n            return empty_row",
        "begin_line": 751,
        "end_line": 758,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings._str_extract_noexpand#773",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._str_extract_noexpand(arr, pat, flags=0)",
        "snippet": "def _str_extract_noexpand(arr, pat, flags=0):\n    \"\"\"\n    Find groups in each string in the Series using passed regular\n    expression. This function is called from\n    str_extract(expand=False), and can return Series, DataFrame, or\n    Index.\n\n    \"\"\"\n    from pandas import DataFrame\n\n    regex = re.compile(pat, flags=flags)\n    groups_or_na = _groups_or_na_fun(regex)\n\n    if regex.groups == 1:\n        result = np.array([groups_or_na(val)[0] for val in arr], dtype=object)\n        name = _get_single_group_name(regex)\n    else:\n        if isinstance(arr, ABCIndexClass):\n            raise ValueError(\"only one regex group is supported with Index\")\n        name = None\n        names = dict(zip(regex.groupindex.values(), regex.groupindex.keys()))\n        columns = [names.get(1 + i, i) for i in range(regex.groups)]\n        if arr.empty:\n            result = DataFrame(columns=columns, dtype=object)\n        else:\n            result = DataFrame(\n                [groups_or_na(val) for val in arr],\n                columns=columns,\n                index=arr.index,\n                dtype=object,\n            )\n    return result, name",
        "begin_line": 773,
        "end_line": 804,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings._str_extract_frame#807",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._str_extract_frame(arr, pat, flags=0)",
        "snippet": "def _str_extract_frame(arr, pat, flags=0):\n    \"\"\"\n    For each subject string in the Series, extract groups from the\n    first match of regular expression pat. This function is called from\n    str_extract(expand=True), and always returns a DataFrame.\n\n    \"\"\"\n    from pandas import DataFrame\n\n    regex = re.compile(pat, flags=flags)\n    groups_or_na = _groups_or_na_fun(regex)\n    names = dict(zip(regex.groupindex.values(), regex.groupindex.keys()))\n    columns = [names.get(1 + i, i) for i in range(regex.groups)]\n\n    if len(arr) == 0:\n        return DataFrame(columns=columns, dtype=object)\n    try:\n        result_index = arr.index\n    except AttributeError:\n        result_index = None\n    dtype = _result_dtype(arr)\n    return DataFrame(\n        [groups_or_na(val) for val in arr],\n        columns=columns,\n        index=result_index,\n        dtype=dtype,\n    )",
        "begin_line": 807,
        "end_line": 833,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_extract#836",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_extract(arr, pat, flags=0, expand=True)",
        "snippet": "def str_extract(arr, pat, flags=0, expand=True):\n    r\"\"\"\n    Extract capture groups in the regex `pat` as columns in a DataFrame.\n\n    For each subject string in the Series, extract groups from the\n    first match of regular expression `pat`.\n\n    Parameters\n    ----------\n    pat : str\n        Regular expression pattern with capturing groups.\n    flags : int, default 0 (no flags)\n        Flags from the ``re`` module, e.g. ``re.IGNORECASE``, that\n        modify regular expression matching for things like case,\n        spaces, etc. For more details, see :mod:`re`.\n    expand : bool, default True\n        If True, return DataFrame with one column per capture group.\n        If False, return a Series/Index if there is one capture group\n        or DataFrame if there are multiple capture groups.\n\n    Returns\n    -------\n    DataFrame or Series or Index\n        A DataFrame with one row for each subject string, and one\n        column for each group. Any capture group names in regular\n        expression pat will be used for column names; otherwise\n        capture group numbers will be used. The dtype of each result\n        column is always object, even when no match is found. If\n        ``expand=False`` and pat has only one capture group, then\n        return a Series (if subject is a Series) or Index (if subject\n        is an Index).\n\n    See Also\n    --------\n    extractall : Returns all matches (not just the first match).\n\n    Examples\n    --------\n    A pattern with two groups will return a DataFrame with two columns.\n    Non-matches will be NaN.\n\n    >>> s = pd.Series(['a1', 'b2', 'c3'])\n    >>> s.str.extract(r'([ab])(\\d)')\n         0    1\n    0    a    1\n    1    b    2\n    2  NaN  NaN\n\n    A pattern may contain optional groups.\n\n    >>> s.str.extract(r'([ab])?(\\d)')\n         0  1\n    0    a  1\n    1    b  2\n    2  NaN  3\n\n    Named groups will become column names in the result.\n\n    >>> s.str.extract(r'(?P<letter>[ab])(?P<digit>\\d)')\n      letter digit\n    0      a     1\n    1      b     2\n    2    NaN   NaN\n\n    A pattern with one group will return a DataFrame with one column\n    if expand=True.\n\n    >>> s.str.extract(r'[ab](\\d)', expand=True)\n         0\n    0    1\n    1    2\n    2  NaN\n\n    A pattern with one group will return a Series if expand=False.\n\n    >>> s.str.extract(r'[ab](\\d)', expand=False)\n    0      1\n    1      2\n    2    NaN\n    dtype: object\n    \"\"\"\n    if not isinstance(expand, bool):\n        raise ValueError(\"expand must be True or False\")\n    if expand:\n        return _str_extract_frame(arr._orig, pat, flags=flags)\n    else:\n        result, name = _str_extract_noexpand(arr._parent, pat, flags=flags)\n        return arr._wrap_result(result, name=name, expand=expand)",
        "begin_line": 836,
        "end_line": 923,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_get_dummies#1038",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_get_dummies(arr, sep='|')",
        "snippet": "def str_get_dummies(arr, sep=\"|\"):\n    \"\"\"\n    Split each string in the Series by sep and return a DataFrame\n    of dummy/indicator variables.\n\n    Parameters\n    ----------\n    sep : str, default \"|\"\n        String to split on.\n\n    Returns\n    -------\n    DataFrame\n        Dummy variables corresponding to values of the Series.\n\n    See Also\n    --------\n    get_dummies : Convert categorical variable into dummy/indicator\n        variables.\n\n    Examples\n    --------\n    >>> pd.Series(['a|b', 'a', 'a|c']).str.get_dummies()\n       a  b  c\n    0  1  1  0\n    1  1  0  0\n    2  1  0  1\n\n    >>> pd.Series(['a|b', np.nan, 'a|c']).str.get_dummies()\n       a  b  c\n    0  1  1  0\n    1  0  0  0\n    2  1  0  1\n    \"\"\"\n    arr = arr.fillna(\"\")\n    try:\n        arr = sep + arr + sep\n    except TypeError:\n        arr = sep + arr.astype(str) + sep\n\n    tags = set()\n    for ts in arr.str.split(sep):\n        tags.update(ts)\n    tags = sorted(tags - {\"\"})\n\n    dummies = np.empty((len(arr), len(tags)), dtype=np.int64)\n\n    for i, t in enumerate(tags):\n        pat = sep + t + sep\n        dummies[:, i] = lib.map_infer(arr.to_numpy(), lambda x: pat in x)\n    return dummies, tags",
        "begin_line": 1038,
        "end_line": 1088,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_join#1091",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_join(arr, sep)",
        "snippet": "def str_join(arr, sep):\n    \"\"\"\n    Join lists contained as elements in the Series/Index with passed delimiter.\n\n    If the elements of a Series are lists themselves, join the content of these\n    lists using the delimiter passed to the function.\n    This function is an equivalent to :meth:`str.join`.\n\n    Parameters\n    ----------\n    sep : str\n        Delimiter to use between list entries.\n\n    Returns\n    -------\n    Series/Index: object\n        The list entries concatenated by intervening occurrences of the\n        delimiter.\n\n    Raises\n    ------\n    AttributeError\n        If the supplied Series contains neither strings nor lists.\n\n    See Also\n    --------\n    str.join : Standard library version of this method.\n    Series.str.split : Split strings around given separator/delimiter.\n\n    Notes\n    -----\n    If any of the list items is not a string object, the result of the join\n    will be `NaN`.\n\n    Examples\n    --------\n    Example with a list that contains non-string elements.\n\n    >>> s = pd.Series([['lion', 'elephant', 'zebra'],\n    ...                [1.1, 2.2, 3.3],\n    ...                ['cat', np.nan, 'dog'],\n    ...                ['cow', 4.5, 'goat'],\n    ...                ['duck', ['swan', 'fish'], 'guppy']])\n    >>> s\n    0        [lion, elephant, zebra]\n    1                [1.1, 2.2, 3.3]\n    2                [cat, nan, dog]\n    3               [cow, 4.5, goat]\n    4    [duck, [swan, fish], guppy]\n    dtype: object\n\n    Join all lists using a '-'. The lists containing object(s) of types other\n    than str will produce a NaN.\n\n    >>> s.str.join('-')\n    0    lion-elephant-zebra\n    1                    NaN\n    2                    NaN\n    3                    NaN\n    4                    NaN\n    dtype: object\n    \"\"\"\n    return _na_map(sep.join, arr)",
        "begin_line": 1091,
        "end_line": 1153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_findall#1156",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_findall(arr, pat, flags=0)",
        "snippet": "def str_findall(arr, pat, flags=0):\n    \"\"\"\n    Find all occurrences of pattern or regular expression in the Series/Index.\n\n    Equivalent to applying :func:`re.findall` to all the elements in the\n    Series/Index.\n\n    Parameters\n    ----------\n    pat : str\n        Pattern or regular expression.\n    flags : int, default 0\n        Flags from ``re`` module, e.g. `re.IGNORECASE` (default is 0, which\n        means no flags).\n\n    Returns\n    -------\n    Series/Index of lists of strings\n        All non-overlapping matches of pattern or regular expression in each\n        string of this Series/Index.\n\n    See Also\n    --------\n    count : Count occurrences of pattern or regular expression in each string\n        of the Series/Index.\n    extractall : For each string in the Series, extract groups from all matches\n        of regular expression and return a DataFrame with one row for each\n        match and one column for each group.\n    re.findall : The equivalent ``re`` function to all non-overlapping matches\n        of pattern or regular expression in string, as a list of strings.\n\n    Examples\n    --------\n\n    >>> s = pd.Series(['Lion', 'Monkey', 'Rabbit'])\n\n    The search for the pattern 'Monkey' returns one match:\n\n    >>> s.str.findall('Monkey')\n    0          []\n    1    [Monkey]\n    2          []\n    dtype: object\n\n    On the other hand, the search for the pattern 'MONKEY' doesn't return any\n    match:\n\n    >>> s.str.findall('MONKEY')\n    0    []\n    1    []\n    2    []\n    dtype: object\n\n    Flags can be added to the pattern or regular expression. For instance,\n    to find the pattern 'MONKEY' ignoring the case:\n\n    >>> import re\n    >>> s.str.findall('MONKEY', flags=re.IGNORECASE)\n    0          []\n    1    [Monkey]\n    2          []\n    dtype: object\n\n    When the pattern matches more than one string in the Series, all matches\n    are returned:\n\n    >>> s.str.findall('on')\n    0    [on]\n    1    [on]\n    2      []\n    dtype: object\n\n    Regular expressions are supported too. For instance, the search for all the\n    strings ending with the word 'on' is shown next:\n\n    >>> s.str.findall('on$')\n    0    [on]\n    1      []\n    2      []\n    dtype: object\n\n    If the pattern is found more than once in the same string, then a list of\n    multiple strings is returned:\n\n    >>> s.str.findall('b')\n    0        []\n    1        []\n    2    [b, b]\n    dtype: object\n    \"\"\"\n    regex = re.compile(pat, flags=flags)\n    return _na_map(regex.findall, arr)",
        "begin_line": 1156,
        "end_line": 1247,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_find#1250",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_find(arr, sub, start=0, end=None, side='left')",
        "snippet": "def str_find(arr, sub, start=0, end=None, side=\"left\"):\n    \"\"\"\n    Return indexes in each strings in the Series/Index where the\n    substring is fully contained between [start:end]. Return -1 on failure.\n\n    Parameters\n    ----------\n    sub : str\n        Substring being searched.\n    start : int\n        Left edge index.\n    end : int\n        Right edge index.\n    side : {'left', 'right'}, default 'left'\n        Specifies a starting side, equivalent to ``find`` or ``rfind``.\n\n    Returns\n    -------\n    Series or Index\n        Indexes where substring is found.\n    \"\"\"\n\n    if not isinstance(sub, str):\n        msg = \"expected a string object, not {0}\"\n        raise TypeError(msg.format(type(sub).__name__))\n\n    if side == \"left\":\n        method = \"find\"\n    elif side == \"right\":\n        method = \"rfind\"\n    else:  # pragma: no cover\n        raise ValueError(\"Invalid side\")\n\n    if end is None:\n        f = lambda x: getattr(x, method)(sub, start)\n    else:\n        f = lambda x: getattr(x, method)(sub, start, end)\n\n    return _na_map(f, arr, dtype=int)",
        "begin_line": 1250,
        "end_line": 1288,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_pad#1311",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_pad(arr, width, side='left', fillchar=' ')",
        "snippet": "def str_pad(arr, width, side=\"left\", fillchar=\" \"):\n    \"\"\"\n    Pad strings in the Series/Index up to width.\n\n    Parameters\n    ----------\n    width : int\n        Minimum width of resulting string; additional characters will be filled\n        with character defined in `fillchar`.\n    side : {'left', 'right', 'both'}, default 'left'\n        Side from which to fill resulting string.\n    fillchar : str, default ' '\n        Additional character for filling, default is whitespace.\n\n    Returns\n    -------\n    Series or Index of object\n        Returns Series or Index with minimum number of char in object.\n\n    See Also\n    --------\n    Series.str.rjust : Fills the left side of strings with an arbitrary\n        character. Equivalent to ``Series.str.pad(side='left')``.\n    Series.str.ljust : Fills the right side of strings with an arbitrary\n        character. Equivalent to ``Series.str.pad(side='right')``.\n    Series.str.center : Fills boths sides of strings with an arbitrary\n        character. Equivalent to ``Series.str.pad(side='both')``.\n    Series.str.zfill : Pad strings in the Series/Index by prepending '0'\n        character. Equivalent to ``Series.str.pad(side='left', fillchar='0')``.\n\n    Examples\n    --------\n    >>> s = pd.Series([\"caribou\", \"tiger\"])\n    >>> s\n    0    caribou\n    1      tiger\n    dtype: object\n\n    >>> s.str.pad(width=10)\n    0       caribou\n    1         tiger\n    dtype: object\n\n    >>> s.str.pad(width=10, side='right', fillchar='-')\n    0    caribou---\n    1    tiger-----\n    dtype: object\n\n    >>> s.str.pad(width=10, side='both', fillchar='-')\n    0    -caribou--\n    1    --tiger---\n    dtype: object\n    \"\"\"\n    if not isinstance(fillchar, str):\n        msg = \"fillchar must be a character, not {0}\"\n        raise TypeError(msg.format(type(fillchar).__name__))\n\n    if len(fillchar) != 1:\n        raise TypeError(\"fillchar must be a character, not str\")\n\n    if not is_integer(width):\n        msg = \"width must be of integer type, not {0}\"\n        raise TypeError(msg.format(type(width).__name__))\n\n    if side == \"left\":\n        f = lambda x: x.rjust(width, fillchar)\n    elif side == \"right\":\n        f = lambda x: x.ljust(width, fillchar)\n    elif side == \"both\":\n        f = lambda x: x.center(width, fillchar)\n    else:  # pragma: no cover\n        raise ValueError(\"Invalid side\")\n\n    return _na_map(f, arr)",
        "begin_line": 1311,
        "end_line": 1384,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_split#1387",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_split(arr, pat=None, n=None)",
        "snippet": "def str_split(arr, pat=None, n=None):\n\n    if pat is None:\n        if n is None or n == 0:\n            n = -1\n        f = lambda x: x.split(pat, n)\n    else:\n        if len(pat) == 1:\n            if n is None or n == 0:\n                n = -1\n            f = lambda x: x.split(pat, n)\n        else:\n            if n is None or n == -1:\n                n = 0\n            regex = re.compile(pat)\n            f = lambda x: regex.split(x, maxsplit=n)\n    res = _na_map(f, arr)\n    return res",
        "begin_line": 1387,
        "end_line": 1404,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_rsplit#1407",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_rsplit(arr, pat=None, n=None)",
        "snippet": "def str_rsplit(arr, pat=None, n=None):\n\n    if n is None or n == 0:\n        n = -1\n    f = lambda x: x.rsplit(pat, n)\n    res = _na_map(f, arr)\n    return res",
        "begin_line": 1407,
        "end_line": 1413,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_slice#1416",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_slice(arr, start=None, stop=None, step=None)",
        "snippet": "def str_slice(arr, start=None, stop=None, step=None):\n    \"\"\"\n    Slice substrings from each element in the Series or Index.\n\n    Parameters\n    ----------\n    start : int, optional\n        Start position for slice operation.\n    stop : int, optional\n        Stop position for slice operation.\n    step : int, optional\n        Step size for slice operation.\n\n    Returns\n    -------\n    Series or Index of object\n        Series or Index from sliced substring from original string object.\n\n    See Also\n    --------\n    Series.str.slice_replace : Replace a slice with a string.\n    Series.str.get : Return element at position.\n        Equivalent to `Series.str.slice(start=i, stop=i+1)` with `i`\n        being the position.\n\n    Examples\n    --------\n    >>> s = pd.Series([\"koala\", \"fox\", \"chameleon\"])\n    >>> s\n    0        koala\n    1          fox\n    2    chameleon\n    dtype: object\n\n    >>> s.str.slice(start=1)\n    0        oala\n    1          ox\n    2    hameleon\n    dtype: object\n\n    >>> s.str.slice(start=-1)\n    0           a\n    1           x\n    2           n\n    dtype: object\n\n    >>> s.str.slice(stop=2)\n    0    ko\n    1    fo\n    2    ch\n    dtype: object\n\n    >>> s.str.slice(step=2)\n    0      kaa\n    1       fx\n    2    caeen\n    dtype: object\n\n    >>> s.str.slice(start=0, stop=5, step=3)\n    0    kl\n    1     f\n    2    cm\n    dtype: object\n\n    Equivalent behaviour to:\n\n    >>> s.str[0:5:3]\n    0    kl\n    1     f\n    2    cm\n    dtype: object\n    \"\"\"\n    obj = slice(start, stop, step)\n    f = lambda x: x[obj]\n    return _na_map(f, arr)",
        "begin_line": 1416,
        "end_line": 1490,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_strip#1584",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_strip(arr, to_strip=None, side='both')",
        "snippet": "def str_strip(arr, to_strip=None, side=\"both\"):\n    \"\"\"\n    Strip whitespace (including newlines) from each string in the\n    Series/Index.\n\n    Parameters\n    ----------\n    to_strip : str or unicode\n    side : {'left', 'right', 'both'}, default 'both'\n\n    Returns\n    -------\n    Series or Index\n    \"\"\"\n    if side == \"both\":\n        f = lambda x: x.strip(to_strip)\n    elif side == \"left\":\n        f = lambda x: x.lstrip(to_strip)\n    elif side == \"right\":\n        f = lambda x: x.rstrip(to_strip)\n    else:  # pragma: no cover\n        raise ValueError(\"Invalid side\")\n    return _na_map(f, arr)",
        "begin_line": 1584,
        "end_line": 1606,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_wrap#1609",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_wrap(arr, width, **kwargs)",
        "snippet": "def str_wrap(arr, width, **kwargs):\n    r\"\"\"\n    Wrap long strings in the Series/Index to be formatted in\n    paragraphs with length less than a given width.\n\n    This method has the same keyword parameters and defaults as\n    :class:`textwrap.TextWrapper`.\n\n    Parameters\n    ----------\n    width : int\n        Maximum line width.\n    expand_tabs : bool, optional\n        If True, tab characters will be expanded to spaces (default: True).\n    replace_whitespace : bool, optional\n        If True, each whitespace character (as defined by string.whitespace)\n        remaining after tab expansion will be replaced by a single space\n        (default: True).\n    drop_whitespace : bool, optional\n        If True, whitespace that, after wrapping, happens to end up at the\n        beginning or end of a line is dropped (default: True).\n    break_long_words : bool, optional\n        If True, then words longer than width will be broken in order to ensure\n        that no lines are longer than width. If it is false, long words will\n        not be broken, and some lines may be longer than width (default: True).\n    break_on_hyphens : bool, optional\n        If True, wrapping will occur preferably on whitespace and right after\n        hyphens in compound words, as it is customary in English. If false,\n        only whitespaces will be considered as potentially good places for line\n        breaks, but you need to set break_long_words to false if you want truly\n        insecable words (default: True).\n\n    Returns\n    -------\n    Series or Index\n\n    Notes\n    -----\n    Internally, this method uses a :class:`textwrap.TextWrapper` instance with\n    default settings. To achieve behavior matching R's stringr library str_wrap\n    function, use the arguments:\n\n    - expand_tabs = False\n    - replace_whitespace = True\n    - drop_whitespace = True\n    - break_long_words = False\n    - break_on_hyphens = False\n\n    Examples\n    --------\n\n    >>> s = pd.Series(['line to be wrapped', 'another line to be wrapped'])\n    >>> s.str.wrap(12)\n    0             line to be\\nwrapped\n    1    another line\\nto be\\nwrapped\n    dtype: object\n    \"\"\"\n    kwargs[\"width\"] = width\n\n    tw = textwrap.TextWrapper(**kwargs)\n\n    return _na_map(lambda s: \"\\n\".join(tw.wrap(s)), arr)",
        "begin_line": 1609,
        "end_line": 1670,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_get#1693",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_get(arr, i)",
        "snippet": "def str_get(arr, i):\n    \"\"\"\n    Extract element from each component at specified position.\n\n    Extract element from lists, tuples, or strings in each element in the\n    Series/Index.\n\n    Parameters\n    ----------\n    i : int\n        Position of element to extract.\n\n    Returns\n    -------\n    Series or Index\n\n    Examples\n    --------\n    >>> s = pd.Series([\"String\",\n    ...               (1, 2, 3),\n    ...               [\"a\", \"b\", \"c\"],\n    ...               123,\n    ...               -456,\n    ...               {1: \"Hello\", \"2\": \"World\"}])\n    >>> s\n    0                        String\n    1                     (1, 2, 3)\n    2                     [a, b, c]\n    3                           123\n    4                          -456\n    5    {1: 'Hello', '2': 'World'}\n    dtype: object\n\n    >>> s.str.get(1)\n    0        t\n    1        2\n    2        b\n    3      NaN\n    4      NaN\n    5    Hello\n    dtype: object\n\n    >>> s.str.get(-1)\n    0      g\n    1      3\n    2      c\n    3    NaN\n    4    NaN\n    5    None\n    dtype: object\n    \"\"\"\n\n    def f(x):\n        if isinstance(x, dict):\n            return x.get(i)\n        elif len(x) > i >= -len(x):\n            return x[i]\n        return np.nan\n\n    return _na_map(f, arr)",
        "begin_line": 1693,
        "end_line": 1752,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.f#1745",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.f(x)",
        "snippet": "    def f(x):\n        if isinstance(x, dict):\n            return x.get(i)\n        elif len(x) > i >= -len(x):\n            return x[i]\n        return np.nan",
        "begin_line": 1745,
        "end_line": 1750,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_decode#1755",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_decode(arr, encoding, errors='strict')",
        "snippet": "def str_decode(arr, encoding, errors=\"strict\"):\n    \"\"\"\n    Decode character string in the Series/Index using indicated encoding.\n    Equivalent to :meth:`str.decode` in python2 and :meth:`bytes.decode` in\n    python3.\n\n    Parameters\n    ----------\n    encoding : str\n    errors : str, optional\n\n    Returns\n    -------\n    Series or Index\n    \"\"\"\n    if encoding in _cpython_optimized_decoders:\n        # CPython optimized implementation\n        f = lambda x: x.decode(encoding, errors)\n    else:\n        decoder = codecs.getdecoder(encoding)\n        f = lambda x: decoder(x, errors)[0]\n    return _na_map(f, arr)",
        "begin_line": 1755,
        "end_line": 1776,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.str_encode#1779",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_encode(arr, encoding, errors='strict')",
        "snippet": "def str_encode(arr, encoding, errors=\"strict\"):\n    \"\"\"\n    Encode character string in the Series/Index using indicated encoding.\n    Equivalent to :meth:`str.encode`.\n\n    Parameters\n    ----------\n    encoding : str\n    errors : str, optional\n\n    Returns\n    -------\n    encoded : Series/Index of objects\n    \"\"\"\n    if encoding in _cpython_optimized_encoders:\n        # CPython optimized implementation\n        f = lambda x: x.encode(encoding, errors)\n    else:\n        encoder = codecs.getencoder(encoding)\n        f = lambda x: encoder(x, errors)[0]\n    return _na_map(f, arr)",
        "begin_line": 1779,
        "end_line": 1799,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings._forbid_nonstring_types#1851",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._forbid_nonstring_types(func)",
        "snippet": "    def _forbid_nonstring_types(func):\n        func_name = func.__name__ if name is None else name\n\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            if self._inferred_dtype not in allowed_types:\n                msg = (\n                    \"Cannot use .str.{name} with values of inferred dtype \"\n                    \"{inf_type!r}.\".format(\n                        name=func_name, inf_type=self._inferred_dtype\n                    )\n                )\n                raise TypeError(msg)\n            return func(self, *args, **kwargs)\n\n        wrapper.__name__ = func_name\n        return wrapper",
        "begin_line": 1851,
        "end_line": 1867,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.wrapper#1855",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.wrapper(self, *args, **kwargs)",
        "snippet": "        def wrapper(self, *args, **kwargs):\n            if self._inferred_dtype not in allowed_types:\n                msg = (\n                    \"Cannot use .str.{name} with values of inferred dtype \"\n                    \"{inf_type!r}.\".format(\n                        name=func_name, inf_type=self._inferred_dtype\n                    )\n                )\n                raise TypeError(msg)\n            return func(self, *args, **kwargs)",
        "begin_line": 1855,
        "end_line": 1864,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings._noarg_wrapper#1872",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._noarg_wrapper(f, name=None, docstring=None, forbidden_types=['bytes'], returns_string=True, **kargs)",
        "snippet": "def _noarg_wrapper(\n    f,\n    name=None,\n    docstring=None,\n    forbidden_types=[\"bytes\"],\n    returns_string=True,\n    **kargs,\n):\n    @forbid_nonstring_types(forbidden_types, name=name)\n    def wrapper(self):\n        result = _na_map(f, self._parent, **kargs)\n        return self._wrap_result(result, returns_string=returns_string)\n\n    wrapper.__name__ = f.__name__ if name is None else name\n    if docstring is not None:\n        wrapper.__doc__ = docstring\n    else:\n        raise ValueError(\"Provide docstring\")\n\n    return wrapper",
        "begin_line": 1872,
        "end_line": 1891,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.wrapper#1881",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.wrapper(self)",
        "snippet": "    def wrapper(self):\n        result = _na_map(f, self._parent, **kargs)\n        return self._wrap_result(result, returns_string=returns_string)",
        "begin_line": 1881,
        "end_line": 1883,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings._pat_wrapper#1894",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._pat_wrapper(f, flags=False, na=False, name=None, forbidden_types=['bytes'], returns_string=True, **kwargs)",
        "snippet": "def _pat_wrapper(\n    f,\n    flags=False,\n    na=False,\n    name=None,\n    forbidden_types=[\"bytes\"],\n    returns_string=True,\n    **kwargs,\n):\n    @forbid_nonstring_types(forbidden_types, name=name)\n    def wrapper1(self, pat):\n        result = f(self._parent, pat)\n        return self._wrap_result(result, returns_string=returns_string)\n\n    @forbid_nonstring_types(forbidden_types, name=name)\n    def wrapper2(self, pat, flags=0, **kwargs):\n        result = f(self._parent, pat, flags=flags, **kwargs)\n        return self._wrap_result(result, returns_string=returns_string)\n\n    @forbid_nonstring_types(forbidden_types, name=name)\n    def wrapper3(self, pat, na=np.nan):\n        result = f(self._parent, pat, na=na)\n        return self._wrap_result(result, returns_string=returns_string)\n\n    wrapper = wrapper3 if na else wrapper2 if flags else wrapper1\n\n    wrapper.__name__ = f.__name__ if name is None else name\n    if f.__doc__:\n        wrapper.__doc__ = f.__doc__\n\n    return wrapper",
        "begin_line": 1894,
        "end_line": 1924,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.wrapper2#1909",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.wrapper2(self, pat, flags=0, **kwargs)",
        "snippet": "    def wrapper2(self, pat, flags=0, **kwargs):\n        result = f(self._parent, pat, flags=flags, **kwargs)\n        return self._wrap_result(result, returns_string=returns_string)",
        "begin_line": 1909,
        "end_line": 1911,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.wrapper3#1914",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.wrapper3(self, pat, na=np.nan)",
        "snippet": "    def wrapper3(self, pat, na=np.nan):\n        result = f(self._parent, pat, na=na)\n        return self._wrap_result(result, returns_string=returns_string)",
        "begin_line": 1914,
        "end_line": 1916,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.__init__#1950",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.__init__(self, data)",
        "snippet": "    def __init__(self, data):\n        self._inferred_dtype = self._validate(data)\n        self._is_categorical = is_categorical_dtype(data)\n        self._is_string = data.dtype.name == \"string\"\n\n        # .values.categories works for both Series/Index\n        self._parent = data.values.categories if self._is_categorical else data\n        # save orig to blow up categoricals to the right type\n        self._orig = data\n        self._freeze()",
        "begin_line": 1950,
        "end_line": 1959,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods._validate#1962",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods._validate(data)",
        "snippet": "    def _validate(data):\n        \"\"\"\n        Auxiliary function for StringMethods, infers and checks dtype of data.\n\n        This is a \"first line of defence\" at the creation of the StringMethods-\n        object (see _make_accessor), and just checks that the dtype is in the\n        *union* of the allowed types over all string methods below; this\n        restriction is then refined on a per-method basis using the decorator\n        @forbid_nonstring_types (more info in the corresponding docstring).\n\n        This really should exclude all series/index with any non-string values,\n        but that isn't practical for performance reasons until we have a str\n        dtype (GH 9343 / 13877)\n\n        Parameters\n        ----------\n        data : The content of the Series\n\n        Returns\n        -------\n        dtype : inferred dtype of data\n        \"\"\"\n        from pandas import StringDtype\n\n        if isinstance(data, ABCMultiIndex):\n            raise AttributeError(\n                \"Can only use .str accessor with Index, not MultiIndex\"\n            )\n\n        # see _libs/lib.pyx for list of inferred types\n        allowed_types = [\"string\", \"empty\", \"bytes\", \"mixed\", \"mixed-integer\"]\n\n        values = getattr(data, \"values\", data)  # Series / Index\n        values = getattr(values, \"categories\", values)  # categorical / normal\n\n        # explicitly allow StringDtype\n        if isinstance(values.dtype, StringDtype):\n            return \"string\"\n\n        try:\n            inferred_dtype = lib.infer_dtype(values, skipna=True)\n        except ValueError:\n            # GH#27571 mostly occurs with ExtensionArray\n            inferred_dtype = None\n\n        if inferred_dtype not in allowed_types:\n            raise AttributeError(\"Can only use .str accessor with string values!\")\n        return inferred_dtype",
        "begin_line": 1962,
        "end_line": 2009,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods._wrap_result#2025",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods._wrap_result(self, result, use_codes=True, name=None, expand=None, fill_value=np.nan, returns_string=True)",
        "snippet": "    def _wrap_result(\n        self,\n        result,\n        use_codes=True,\n        name=None,\n        expand=None,\n        fill_value=np.nan,\n        returns_string=True,\n    ):\n\n        from pandas import Index, Series, MultiIndex\n\n        # for category, we do the stuff on the categories, so blow it up\n        # to the full series again\n        # But for some operations, we have to do the stuff on the full values,\n        # so make it possible to skip this step as the method already did this\n        # before the transformation...\n        if use_codes and self._is_categorical:\n            # if self._orig is a CategoricalIndex, there is no .cat-accessor\n            result = take_1d(\n                result, Series(self._orig, copy=False).cat.codes, fill_value=fill_value\n            )\n\n        if not hasattr(result, \"ndim\") or not hasattr(result, \"dtype\"):\n            return result\n        assert result.ndim < 3\n\n        # We can be wrapping a string / object / categorical result, in which\n        # case we'll want to return the same dtype as the input.\n        # Or we can be wrapping a numeric output, in which case we don't want\n        # to return a StringArray.\n        if self._is_string and returns_string:\n            dtype = \"string\"\n        else:\n            dtype = None\n\n        if expand is None:\n            # infer from ndim if expand is not specified\n            expand = result.ndim != 1\n\n        elif expand is True and not isinstance(self._orig, ABCIndexClass):\n            # required when expand=True is explicitly specified\n            # not needed when inferred\n\n            def cons_row(x):\n                if is_list_like(x):\n                    return x\n                else:\n                    return [x]\n\n            result = [cons_row(x) for x in result]\n            if result:\n                # propagate nan values to match longest sequence (GH 18450)\n                max_len = max(len(x) for x in result)\n                result = [\n                    x * max_len if len(x) == 0 or x[0] is np.nan else x for x in result\n                ]\n\n        if not isinstance(expand, bool):\n            raise ValueError(\"expand must be True or False\")\n\n        if expand is False:\n            # if expand is False, result should have the same name\n            # as the original otherwise specified\n            if name is None:\n                name = getattr(result, \"name\", None)\n            if name is None:\n                # do not use logical or, _orig may be a DataFrame\n                # which has \"name\" column\n                name = self._orig.name\n\n        # Wait until we are sure result is a Series or Index before\n        # checking attributes (GH 12180)\n        if isinstance(self._orig, ABCIndexClass):\n            # if result is a boolean np.array, return the np.array\n            # instead of wrapping it into a boolean Index (GH 8875)\n            if is_bool_dtype(result):\n                return result\n\n            if expand:\n                result = list(result)\n                out = MultiIndex.from_tuples(result, names=name)\n                if out.nlevels == 1:\n                    # We had all tuples of length-one, which are\n                    # better represented as a regular Index.\n                    out = out.get_level_values(0)\n                return out\n            else:\n                return Index(result, name=name)\n        else:\n            index = self._orig.index\n            if expand:\n                cons = self._orig._constructor_expanddim\n                result = cons(result, columns=name, index=index, dtype=dtype)\n            else:\n                # Must be a Series\n                cons = self._orig._constructor\n                result = cons(result, name=name, index=index, dtype=dtype)\n            return result",
        "begin_line": 2025,
        "end_line": 2123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.cons_row#2069",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.cons_row(x)",
        "snippet": "            def cons_row(x):\n                if is_list_like(x):\n                    return x\n                else:\n                    return [x]",
        "begin_line": 2069,
        "end_line": 2073,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods._get_series_list#2125",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods._get_series_list(self, others)",
        "snippet": "    def _get_series_list(self, others):\n        \"\"\"\n        Auxiliary function for :meth:`str.cat`. Turn potentially mixed input\n        into a list of Series (elements without an index must match the length\n        of the calling Series/Index).\n\n        Parameters\n        ----------\n        others : Series, DataFrame, np.ndarray, list-like or list-like of\n            Objects that are either Series, Index or np.ndarray (1-dim).\n\n        Returns\n        -------\n        list of Series\n            Others transformed into list of Series.\n        \"\"\"\n        from pandas import Series, DataFrame\n\n        # self._orig is either Series or Index\n        idx = self._orig if isinstance(self._orig, ABCIndexClass) else self._orig.index\n\n        # Generally speaking, all objects without an index inherit the index\n        # `idx` of the calling Series/Index - i.e. must have matching length.\n        # Objects with an index (i.e. Series/Index/DataFrame) keep their own.\n        if isinstance(others, ABCSeries):\n            return [others]\n        elif isinstance(others, ABCIndexClass):\n            return [Series(others.values, index=others)]\n        elif isinstance(others, ABCDataFrame):\n            return [others[x] for x in others]\n        elif isinstance(others, np.ndarray) and others.ndim == 2:\n            others = DataFrame(others, index=idx)\n            return [others[x] for x in others]\n        elif is_list_like(others, allow_sets=False):\n            others = list(others)  # ensure iterators do not get read twice etc\n\n            # in case of list-like `others`, all elements must be\n            # either Series/Index/np.ndarray (1-dim)...\n            if all(\n                isinstance(x, (ABCSeries, ABCIndexClass))\n                or (isinstance(x, np.ndarray) and x.ndim == 1)\n                for x in others\n            ):\n                los = []\n                while others:  # iterate through list and append each element\n                    los = los + self._get_series_list(others.pop(0))\n                return los\n            # ... or just strings\n            elif all(not is_list_like(x) for x in others):\n                return [Series(others, index=idx)]\n        raise TypeError(\n            \"others must be Series, Index, DataFrame, np.ndarrary \"\n            \"or list-like (either containing only strings or \"\n            \"containing only objects of type Series/Index/\"\n            \"np.ndarray[1-dim])\"\n        )",
        "begin_line": 2125,
        "end_line": 2180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.cat#2183",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.cat(self, others=None, sep=None, na_rep=None, join='left')",
        "snippet": "    def cat(self, others=None, sep=None, na_rep=None, join=\"left\"):\n        \"\"\"\n        Concatenate strings in the Series/Index with given separator.\n\n        If `others` is specified, this function concatenates the Series/Index\n        and elements of `others` element-wise.\n        If `others` is not passed, then all values in the Series/Index are\n        concatenated into a single string with a given `sep`.\n\n        Parameters\n        ----------\n        others : Series, Index, DataFrame, np.ndarray or list-like\n            Series, Index, DataFrame, np.ndarray (one- or two-dimensional) and\n            other list-likes of strings must have the same length as the\n            calling Series/Index, with the exception of indexed objects (i.e.\n            Series/Index/DataFrame) if `join` is not None.\n\n            If others is a list-like that contains a combination of Series,\n            Index or np.ndarray (1-dim), then all elements will be unpacked and\n            must satisfy the above criteria individually.\n\n            If others is None, the method returns the concatenation of all\n            strings in the calling Series/Index.\n        sep : str, default ''\n            The separator between the different elements/columns. By default\n            the empty string `''` is used.\n        na_rep : str or None, default None\n            Representation that is inserted for all missing values:\n\n            - If `na_rep` is None, and `others` is None, missing values in the\n              Series/Index are omitted from the result.\n            - If `na_rep` is None, and `others` is not None, a row containing a\n              missing value in any of the columns (before concatenation) will\n              have a missing value in the result.\n        join : {'left', 'right', 'outer', 'inner'}, default 'left'\n            Determines the join-style between the calling Series/Index and any\n            Series/Index/DataFrame in `others` (objects without an index need\n            to match the length of the calling Series/Index). To disable\n            alignment, use `.values` on any Series/Index/DataFrame in `others`.\n\n            .. versionadded:: 0.23.0\n            .. versionchanged:: 1.0.0\n                Changed default of `join` from None to `'left'`.\n\n        Returns\n        -------\n        str, Series or Index\n            If `others` is None, `str` is returned, otherwise a `Series/Index`\n            (same type as caller) of objects is returned.\n\n        See Also\n        --------\n        split : Split each string in the Series/Index.\n        join : Join lists contained as elements in the Series/Index.\n\n        Examples\n        --------\n        When not passing `others`, all values are concatenated into a single\n        string:\n\n        >>> s = pd.Series(['a', 'b', np.nan, 'd'])\n        >>> s.str.cat(sep=' ')\n        'a b d'\n\n        By default, NA values in the Series are ignored. Using `na_rep`, they\n        can be given a representation:\n\n        >>> s.str.cat(sep=' ', na_rep='?')\n        'a b ? d'\n\n        If `others` is specified, corresponding values are concatenated with\n        the separator. Result will be a Series of strings.\n\n        >>> s.str.cat(['A', 'B', 'C', 'D'], sep=',')\n        0    a,A\n        1    b,B\n        2    NaN\n        3    d,D\n        dtype: object\n\n        Missing values will remain missing in the result, but can again be\n        represented using `na_rep`\n\n        >>> s.str.cat(['A', 'B', 'C', 'D'], sep=',', na_rep='-')\n        0    a,A\n        1    b,B\n        2    -,C\n        3    d,D\n        dtype: object\n\n        If `sep` is not specified, the values are concatenated without\n        separation.\n\n        >>> s.str.cat(['A', 'B', 'C', 'D'], na_rep='-')\n        0    aA\n        1    bB\n        2    -C\n        3    dD\n        dtype: object\n\n        Series with different indexes can be aligned before concatenation. The\n        `join`-keyword works as in other methods.\n\n        >>> t = pd.Series(['d', 'a', 'e', 'c'], index=[3, 0, 4, 2])\n        >>> s.str.cat(t, join='left', na_rep='-')\n        0    aa\n        1    b-\n        2    -c\n        3    dd\n        dtype: object\n        >>>\n        >>> s.str.cat(t, join='outer', na_rep='-')\n        0    aa\n        1    b-\n        2    -c\n        3    dd\n        4    -e\n        dtype: object\n        >>>\n        >>> s.str.cat(t, join='inner', na_rep='-')\n        0    aa\n        2    -c\n        3    dd\n        dtype: object\n        >>>\n        >>> s.str.cat(t, join='right', na_rep='-')\n        3    dd\n        0    aa\n        4    -e\n        2    -c\n        dtype: object\n\n        For more examples, see :ref:`here <text.concatenate>`.\n        \"\"\"\n        from pandas import Index, Series, concat\n\n        if isinstance(others, str):\n            raise ValueError(\"Did you mean to supply a `sep` keyword?\")\n        if sep is None:\n            sep = \"\"\n\n        if isinstance(self._orig, ABCIndexClass):\n            data = Series(self._orig, index=self._orig)\n        else:  # Series\n            data = self._orig\n\n        # concatenate Series/Index with itself if no \"others\"\n        if others is None:\n            data = ensure_object(data)\n            na_mask = isna(data)\n            if na_rep is None and na_mask.any():\n                data = data[~na_mask]\n            elif na_rep is not None and na_mask.any():\n                data = np.where(na_mask, na_rep, data)\n            return sep.join(data)\n\n        try:\n            # turn anything in \"others\" into lists of Series\n            others = self._get_series_list(others)\n        except ValueError:  # do not catch TypeError raised by _get_series_list\n            raise ValueError(\n                \"If `others` contains arrays or lists (or other \"\n                \"list-likes without an index), these must all be \"\n                \"of the same length as the calling Series/Index.\"\n            )\n\n        # align if required\n        if any(not data.index.equals(x.index) for x in others):\n            # Need to add keys for uniqueness in case of duplicate columns\n            others = concat(\n                others,\n                axis=1,\n                join=(join if join == \"inner\" else \"outer\"),\n                keys=range(len(others)),\n                sort=False,\n                copy=False,\n            )\n            data, others = data.align(others, join=join)\n            others = [others[x] for x in others]  # again list of Series\n\n        all_cols = [ensure_object(x) for x in [data] + others]\n        na_masks = np.array([isna(x) for x in all_cols])\n        union_mask = np.logical_or.reduce(na_masks, axis=0)\n\n        if na_rep is None and union_mask.any():\n            # no na_rep means NaNs for all rows where any column has a NaN\n            # only necessary if there are actually any NaNs\n            result = np.empty(len(data), dtype=object)\n            np.putmask(result, union_mask, np.nan)\n\n            not_masked = ~union_mask\n            result[not_masked] = cat_safe([x[not_masked] for x in all_cols], sep)\n        elif na_rep is not None and union_mask.any():\n            # fill NaNs with na_rep in case there are actually any NaNs\n            all_cols = [\n                np.where(nm, na_rep, col) for nm, col in zip(na_masks, all_cols)\n            ]\n            result = cat_safe(all_cols, sep)\n        else:\n            # no NaNs - can just concatenate\n            result = cat_safe(all_cols, sep)\n\n        if isinstance(self._orig, ABCIndexClass):\n            # add dtype for case that result is all-NA\n            result = Index(result, dtype=object, name=self._orig.name)\n        else:  # Series\n            if is_categorical_dtype(self._orig.dtype):\n                # We need to infer the new categories.\n                dtype = None\n            else:\n                dtype = self._orig.dtype\n            result = Series(result, dtype=dtype, index=data.index, name=self._orig.name)\n        return result",
        "begin_line": 2183,
        "end_line": 2395,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.split#2531",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.split(self, pat=None, n=-1, expand=False)",
        "snippet": "    def split(self, pat=None, n=-1, expand=False):\n        result = str_split(self._parent, pat, n=n)\n        return self._wrap_result(result, expand=expand, returns_string=expand)",
        "begin_line": 2531,
        "end_line": 2533,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.rsplit#2537",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.rsplit(self, pat=None, n=-1, expand=False)",
        "snippet": "    def rsplit(self, pat=None, n=-1, expand=False):\n        result = str_rsplit(self._parent, pat, n=n)\n        return self._wrap_result(result, expand=expand, returns_string=expand)",
        "begin_line": 2537,
        "end_line": 2539,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.partition#2637",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.partition(self, sep=' ', expand=True)",
        "snippet": "    def partition(self, sep=\" \", expand=True):\n        f = lambda x: x.partition(sep)\n        result = _na_map(f, self._parent)\n        return self._wrap_result(result, expand=expand, returns_string=expand)",
        "begin_line": 2637,
        "end_line": 2640,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.rpartition#2653",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.rpartition(self, sep=' ', expand=True)",
        "snippet": "    def rpartition(self, sep=\" \", expand=True):\n        f = lambda x: x.rpartition(sep)\n        result = _na_map(f, self._parent)\n        return self._wrap_result(result, expand=expand, returns_string=expand)",
        "begin_line": 2653,
        "end_line": 2656,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.get#2659",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.get(self, i)",
        "snippet": "    def get(self, i):\n        result = str_get(self._parent, i)\n        return self._wrap_result(result)",
        "begin_line": 2659,
        "end_line": 2661,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.join#2665",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.join(self, sep)",
        "snippet": "    def join(self, sep):\n        result = str_join(self._parent, sep)\n        return self._wrap_result(result)",
        "begin_line": 2665,
        "end_line": 2667,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.contains#2671",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.contains(self, pat, case=True, flags=0, na=np.nan, regex=True)",
        "snippet": "    def contains(self, pat, case=True, flags=0, na=np.nan, regex=True):\n        result = str_contains(\n            self._parent, pat, case=case, flags=flags, na=na, regex=regex\n        )\n        return self._wrap_result(result, fill_value=na, returns_string=False)",
        "begin_line": 2671,
        "end_line": 2675,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.match#2679",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.match(self, pat, case=True, flags=0, na=np.nan)",
        "snippet": "    def match(self, pat, case=True, flags=0, na=np.nan):\n        result = str_match(self._parent, pat, case=case, flags=flags, na=na)\n        return self._wrap_result(result, fill_value=na, returns_string=False)",
        "begin_line": 2679,
        "end_line": 2681,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.replace#2685",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.replace(self, pat, repl, n=-1, case=None, flags=0, regex=True)",
        "snippet": "    def replace(self, pat, repl, n=-1, case=None, flags=0, regex=True):\n        result = str_replace(\n            self._parent, pat, repl, n=n, case=case, flags=flags, regex=regex\n        )\n        return self._wrap_result(result)",
        "begin_line": 2685,
        "end_line": 2689,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.repeat#2693",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.repeat(self, repeats)",
        "snippet": "    def repeat(self, repeats):\n        result = str_repeat(self._parent, repeats)\n        return self._wrap_result(result)",
        "begin_line": 2693,
        "end_line": 2695,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.pad#2699",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.pad(self, width, side='left', fillchar=' ')",
        "snippet": "    def pad(self, width, side=\"left\", fillchar=\" \"):\n        result = str_pad(self._parent, width, side=side, fillchar=fillchar)\n        return self._wrap_result(result)",
        "begin_line": 2699,
        "end_line": 2701,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.center#2724",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.center(self, width, fillchar=' ')",
        "snippet": "    def center(self, width, fillchar=\" \"):\n        return self.pad(width, side=\"both\", fillchar=fillchar)",
        "begin_line": 2724,
        "end_line": 2725,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.slice#2802",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.slice(self, start=None, stop=None, step=None)",
        "snippet": "    def slice(self, start=None, stop=None, step=None):\n        result = str_slice(self._parent, start, stop, step)\n        return self._wrap_result(result)",
        "begin_line": 2802,
        "end_line": 2804,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.decode#2813",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.decode(self, encoding, errors='strict')",
        "snippet": "    def decode(self, encoding, errors=\"strict\"):\n        # need to allow bytes here\n        result = str_decode(self._parent, encoding, errors)\n        # TODO: Not sure how to handle this.\n        return self._wrap_result(result, returns_string=False)",
        "begin_line": 2813,
        "end_line": 2817,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.encode#2821",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.encode(self, encoding, errors='strict')",
        "snippet": "    def encode(self, encoding, errors=\"strict\"):\n        result = str_encode(self._parent, encoding, errors)\n        return self._wrap_result(result, returns_string=False)",
        "begin_line": 2821,
        "end_line": 2823,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.strip#2894",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.strip(self, to_strip=None)",
        "snippet": "    def strip(self, to_strip=None):\n        result = str_strip(self._parent, to_strip, side=\"both\")\n        return self._wrap_result(result)",
        "begin_line": 2894,
        "end_line": 2896,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.lstrip#2900",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.lstrip(self, to_strip=None)",
        "snippet": "    def lstrip(self, to_strip=None):\n        result = str_strip(self._parent, to_strip, side=\"left\")\n        return self._wrap_result(result)",
        "begin_line": 2900,
        "end_line": 2902,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.rstrip#2906",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.rstrip(self, to_strip=None)",
        "snippet": "    def rstrip(self, to_strip=None):\n        result = str_strip(self._parent, to_strip, side=\"right\")\n        return self._wrap_result(result)",
        "begin_line": 2906,
        "end_line": 2908,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.wrap#2912",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.wrap(self, width, **kwargs)",
        "snippet": "    def wrap(self, width, **kwargs):\n        result = str_wrap(self._parent, width, **kwargs)\n        return self._wrap_result(result)",
        "begin_line": 2912,
        "end_line": 2914,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.get_dummies#2918",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.get_dummies(self, sep='|')",
        "snippet": "    def get_dummies(self, sep=\"|\"):\n        # we need to cast to Series of strings as only that has all\n        # methods available for making the dummies...\n        data = self._orig.astype(str) if self._is_categorical else self._parent\n        result, name = str_get_dummies(data, sep)\n        return self._wrap_result(\n            result,\n            use_codes=(not self._is_categorical),\n            name=name,\n            expand=True,\n            returns_string=False,\n        )",
        "begin_line": 2918,
        "end_line": 2929,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.extract#2950",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.extract(self, pat, flags=0, expand=True)",
        "snippet": "    def extract(self, pat, flags=0, expand=True):\n        return str_extract(self, pat, flags=flags, expand=expand)",
        "begin_line": 2950,
        "end_line": 2951,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.find#2992",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.find(self, sub, start=0, end=None)",
        "snippet": "    def find(self, sub, start=0, end=None):\n        result = str_find(self._parent, sub, start=start, end=end, side=\"left\")\n        return self._wrap_result(result, returns_string=False)",
        "begin_line": 2992,
        "end_line": 2994,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.rfind#3005",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.rfind(self, sub, start=0, end=None)",
        "snippet": "    def rfind(self, sub, start=0, end=None):\n        result = str_find(self._parent, sub, start=start, end=end, side=\"right\")\n        return self._wrap_result(result, returns_string=False)",
        "begin_line": 3005,
        "end_line": 3007,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.__init__#123",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.__init__(self, blocks: Sequence[Block], axes: Sequence[Index], do_integrity_check: bool=True)",
        "snippet": "    def __init__(\n        self,\n        blocks: Sequence[Block],\n        axes: Sequence[Index],\n        do_integrity_check: bool = True,\n    ):\n        self.axes = [ensure_index(ax) for ax in axes]\n        self.blocks = tuple(blocks)  # type: Tuple[Block, ...]\n\n        for block in blocks:\n            if self.ndim != block.ndim:\n                raise AssertionError(\n                    \"Number of Block dimensions ({block}) must equal \"\n                    \"number of axes ({self})\".format(block=block.ndim, self=self.ndim)\n                )\n\n        if do_integrity_check:\n            self._verify_integrity()\n\n        self._consolidate_check()\n\n        self._rebuild_blknos_and_blklocs()",
        "begin_line": 123,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.shape#165",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.shape(self)",
        "snippet": "    def shape(self):\n        return tuple(len(ax) for ax in self.axes)",
        "begin_line": 165,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.ndim#169",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.ndim(self)",
        "snippet": "    def ndim(self) -> int:\n        return len(self.axes)",
        "begin_line": 169,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._rebuild_blknos_and_blklocs#213",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._rebuild_blknos_and_blklocs(self)",
        "snippet": "    def _rebuild_blknos_and_blklocs(self):\n        \"\"\"\n        Update mgr._blknos / mgr._blklocs.\n        \"\"\"\n        new_blknos = np.empty(self.shape[0], dtype=np.int64)\n        new_blklocs = np.empty(self.shape[0], dtype=np.int64)\n        new_blknos.fill(-1)\n        new_blklocs.fill(-1)\n\n        for blkno, blk in enumerate(self.blocks):\n            rl = blk.mgr_locs\n            new_blknos[rl.indexer] = blkno\n            new_blklocs[rl.indexer] = np.arange(len(rl))\n\n        if (new_blknos == -1).any():\n            raise AssertionError(\"Gaps in blk ref_locs\")\n\n        self._blknos = new_blknos\n        self._blklocs = new_blklocs",
        "begin_line": 213,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.items#234",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.items(self)",
        "snippet": "    def items(self):\n        return self.axes[0]",
        "begin_line": 234,
        "end_line": 235,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.__len__#322",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.__len__(self)",
        "snippet": "    def __len__(self) -> int:\n        return len(self.items)",
        "begin_line": 322,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._verify_integrity#337",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._verify_integrity(self)",
        "snippet": "    def _verify_integrity(self):\n        mgr_shape = self.shape\n        tot_items = sum(len(x.mgr_locs) for x in self.blocks)\n        for block in self.blocks:\n            if block._verify_integrity and block.shape[1:] != mgr_shape[1:]:\n                construction_error(tot_items, block.shape[1:], self.axes)\n        if len(self.items) != tot_items:\n            raise AssertionError(\n                \"Number of manager items must equal union of \"\n                \"block items\\n# manager items: {0}, # \"\n                \"tot_items: {1}\".format(len(self.items), tot_items)\n            )",
        "begin_line": 337,
        "end_line": 348,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.apply#350",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.apply(self, f, axes=None, filter=None, do_integrity_check=False, consolidate=True, **kwargs)",
        "snippet": "    def apply(\n        self,\n        f,\n        axes=None,\n        filter=None,\n        do_integrity_check=False,\n        consolidate=True,\n        **kwargs,\n    ):\n        \"\"\"\n        iterate over the blocks, collect and create a new block manager\n\n        Parameters\n        ----------\n        f : the callable or function name to operate on at the block level\n        axes : optional (if not supplied, use self.axes)\n        filter : list, if supplied, only call the block if the filter is in\n                 the block\n        do_integrity_check : boolean, default False. Do the block manager\n            integrity check\n        consolidate: boolean, default True. Join together blocks having same\n            dtype\n\n        Returns\n        -------\n        Block Manager (new object)\n\n        \"\"\"\n\n        result_blocks = []\n\n        # filter kwarg is used in replace-* family of methods\n        if filter is not None:\n            filter_locs = set(self.items.get_indexer_for(filter))\n            if len(filter_locs) == len(self.items):\n                # All items are included, as if there were no filtering\n                filter = None\n            else:\n                kwargs[\"filter\"] = filter_locs\n\n        if consolidate:\n            self._consolidate_inplace()\n\n        if f == \"where\":\n            align_copy = True\n            if kwargs.get(\"align\", True):\n                align_keys = [\"other\", \"cond\"]\n            else:\n                align_keys = [\"cond\"]\n        elif f == \"putmask\":\n            align_copy = False\n            if kwargs.get(\"align\", True):\n                align_keys = [\"new\", \"mask\"]\n            else:\n                align_keys = [\"mask\"]\n        elif f == \"fillna\":\n            # fillna internally does putmask, maybe it's better to do this\n            # at mgr, not block level?\n            align_copy = False\n            align_keys = [\"value\"]\n        else:\n            align_keys = []\n\n        # TODO(EA): may interfere with ExtensionBlock.setitem for blocks\n        # with a .values attribute.\n        aligned_args = {\n            k: kwargs[k]\n            for k in align_keys\n            if not isinstance(kwargs[k], ABCExtensionArray)\n            and hasattr(kwargs[k], \"values\")\n        }\n\n        for b in self.blocks:\n            if filter is not None:\n                if not b.mgr_locs.isin(filter_locs).any():\n                    result_blocks.append(b)\n                    continue\n\n            if aligned_args:\n                b_items = self.items[b.mgr_locs.indexer]\n\n                for k, obj in aligned_args.items():\n                    axis = obj._info_axis_number\n                    kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy)\n\n            applied = getattr(b, f)(**kwargs)\n            result_blocks = _extend_blocks(applied, result_blocks)\n\n        if len(result_blocks) == 0:\n            return self.make_empty(axes or self.axes)\n        bm = self.__class__(\n            result_blocks, axes or self.axes, do_integrity_check=do_integrity_check\n        )\n        bm._consolidate_inplace()\n        return bm",
        "begin_line": 350,
        "end_line": 444,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.setitem#556",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.setitem(self, **kwargs)",
        "snippet": "    def setitem(self, **kwargs):\n        return self.apply(\"setitem\", **kwargs)",
        "begin_line": 556,
        "end_line": 557,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.is_consolidated#643",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.is_consolidated(self)",
        "snippet": "    def is_consolidated(self):\n        \"\"\"\n        Return True if more than one block with the same dtype\n        \"\"\"\n        if not self._known_consolidated:\n            self._consolidate_check()\n        return self._is_consolidated",
        "begin_line": 643,
        "end_line": 649,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._consolidate_check#651",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._consolidate_check(self)",
        "snippet": "    def _consolidate_check(self):\n        ftypes = [blk.ftype for blk in self.blocks]\n        self._is_consolidated = len(ftypes) == len(set(ftypes))\n        self._known_consolidated = True",
        "begin_line": 651,
        "end_line": 654,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.is_view#680",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.is_view(self)",
        "snippet": "    def is_view(self):\n        \"\"\" return a boolean if we are a single block and are a view \"\"\"\n        if len(self.blocks) == 1:\n            return self.blocks[0].is_view\n\n        # It is technically possible to figure out which blocks are views\n        # e.g. [ b.values.base is not None for b in self.blocks ]\n        # but then we have the case of possibly some blocks being a view\n        # and some blocks not. setting in theory is possible on the non-view\n        # blocks w/o causing a SettingWithCopy raise/warn. But this is a bit\n        # complicated\n\n        return False",
        "begin_line": 680,
        "end_line": 692,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.consolidate#916",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.consolidate(self)",
        "snippet": "    def consolidate(self):\n        \"\"\"\n        Join together blocks having same dtype\n\n        Returns\n        -------\n        y : BlockManager\n        \"\"\"\n        if self.is_consolidated():\n            return self\n\n        bm = self.__class__(self.blocks, self.axes)\n        bm._is_consolidated = False\n        bm._consolidate_inplace()\n        return bm",
        "begin_line": 916,
        "end_line": 930,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager._consolidate_inplace#932",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager._consolidate_inplace(self)",
        "snippet": "    def _consolidate_inplace(self):\n        if not self.is_consolidated():\n            self.blocks = tuple(_consolidate(self.blocks))\n            self._is_consolidated = True\n            self._known_consolidated = True\n            self._rebuild_blknos_and_blklocs()",
        "begin_line": 932,
        "end_line": 937,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.BlockManager.iget#968",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.BlockManager",
        "signature": "pandas.core.internals.managers.BlockManager.iget(self, i)",
        "snippet": "    def iget(self, i):\n        \"\"\"\n        Return the data as a SingleBlockManager if possible\n\n        Otherwise return as a ndarray\n        \"\"\"\n        block = self.blocks[self._blknos[i]]\n        values = block.iget(self._blklocs[i])\n\n        # shortcut for select a single-dim from a 2-dim BM\n        return SingleBlockManager(\n            [\n                block.make_block_same_class(\n                    values, placement=slice(0, len(values)), ndim=1\n                )\n            ],\n            self.axes[1],\n        )",
        "begin_line": 968,
        "end_line": 985,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.__init__#1456",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.__init__(self, block: Block, axis: Union[Index, List[Index]], do_integrity_check: bool=False, fastpath: bool=False)",
        "snippet": "    def __init__(\n        self,\n        block: Block,\n        axis: Union[Index, List[Index]],\n        do_integrity_check: bool = False,\n        fastpath: bool = False,\n    ):\n        if isinstance(axis, list):\n            if len(axis) != 1:\n                raise ValueError(\n                    \"cannot create SingleBlockManager with more than 1 axis\"\n                )\n            axis = axis[0]\n\n        # passed from constructor, single block, single axis\n        if fastpath:\n            self.axes = [axis]\n            if isinstance(block, list):\n\n                # empty block\n                if len(block) == 0:\n                    block = [np.array([])]\n                elif len(block) != 1:\n                    raise ValueError(\n                        \"Cannot create SingleBlockManager with more than 1 block\"\n                    )\n                block = block[0]\n        else:\n            self.axes = [ensure_index(axis)]\n\n            # create the block here\n            if isinstance(block, list):\n\n                # provide consolidation to the interleaved_dtype\n                if len(block) > 1:\n                    dtype = _interleaved_dtype(block)\n                    block = [b.astype(dtype) for b in block]\n                    block = _consolidate(block)\n\n                if len(block) != 1:\n                    raise ValueError(\n                        \"Cannot create SingleBlockManager with more than 1 block\"\n                    )\n                block = block[0]\n\n        if not isinstance(block, Block):\n            block = make_block(block, placement=slice(0, len(axis)), ndim=1)\n\n        self.blocks = tuple([block])",
        "begin_line": 1456,
        "end_line": 1504,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager._block#1510",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager._block(self)",
        "snippet": "    def _block(self):\n        return self.blocks[0]",
        "begin_line": 1510,
        "end_line": 1511,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.get_slice#1527",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.get_slice(self, slobj, axis=0)",
        "snippet": "    def get_slice(self, slobj, axis=0):\n        if axis >= self.ndim:\n            raise IndexError(\"Requested axis not found in manager\")\n\n        return self.__class__(\n            self._block._slice(slobj), self.index[slobj], fastpath=True\n        )",
        "begin_line": 1527,
        "end_line": 1533,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.index#1536",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.index(self)",
        "snippet": "    def index(self):\n        return self.axes[0]",
        "begin_line": 1536,
        "end_line": 1537,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.dtype#1544",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.dtype(self)",
        "snippet": "    def dtype(self):\n        return self._block.dtype",
        "begin_line": 1544,
        "end_line": 1545,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.external_values#1567",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.external_values(self)",
        "snippet": "    def external_values(self):\n        return self._block.external_values()",
        "begin_line": 1567,
        "end_line": 1568,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.internal_values#1570",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.internal_values(self)",
        "snippet": "    def internal_values(self):\n        return self._block.internal_values()",
        "begin_line": 1570,
        "end_line": 1571,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.get_values#1573",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.get_values(self)",
        "snippet": "    def get_values(self):\n        \"\"\" return a dense type view \"\"\"\n        return np.array(self._block.to_dense(), copy=False)",
        "begin_line": 1573,
        "end_line": 1575,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.is_consolidated#1581",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.is_consolidated(self)",
        "snippet": "    def is_consolidated(self):\n        return True",
        "begin_line": 1581,
        "end_line": 1582,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager._consolidate_inplace#1587",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager._consolidate_inplace(self)",
        "snippet": "    def _consolidate_inplace(self):\n        pass",
        "begin_line": 1587,
        "end_line": 1588,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.create_block_manager_from_arrays#1672",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers.create_block_manager_from_arrays(arrays, names, axes)",
        "snippet": "def create_block_manager_from_arrays(arrays, names, axes):\n\n    try:\n        blocks = form_blocks(arrays, names, axes)\n        mgr = BlockManager(blocks, axes)\n        mgr._consolidate_inplace()\n        return mgr\n    except ValueError as e:\n        construction_error(len(arrays), arrays[0].shape, axes, e)",
        "begin_line": 1672,
        "end_line": 1680,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers.form_blocks#1707",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers.form_blocks(arrays, names, axes)",
        "snippet": "def form_blocks(arrays, names, axes):\n    # put \"leftover\" items in float bucket, where else?\n    # generalize?\n    items_dict = defaultdict(list)\n    extra_locs = []\n\n    names_idx = ensure_index(names)\n    if names_idx.equals(axes[0]):\n        names_indexer = np.arange(len(names_idx))\n    else:\n        assert names_idx.intersection(axes[0]).is_unique\n        names_indexer = names_idx.get_indexer_for(axes[0])\n\n    for i, name_idx in enumerate(names_indexer):\n        if name_idx == -1:\n            extra_locs.append(i)\n            continue\n\n        k = names[name_idx]\n        v = arrays[name_idx]\n\n        block_type = get_block_type(v)\n        items_dict[block_type.__name__].append((i, k, v))\n\n    blocks = []\n    if len(items_dict[\"FloatBlock\"]):\n        float_blocks = _multi_blockify(items_dict[\"FloatBlock\"])\n        blocks.extend(float_blocks)\n\n    if len(items_dict[\"ComplexBlock\"]):\n        complex_blocks = _multi_blockify(items_dict[\"ComplexBlock\"])\n        blocks.extend(complex_blocks)\n\n    if len(items_dict[\"TimeDeltaBlock\"]):\n        timedelta_blocks = _multi_blockify(items_dict[\"TimeDeltaBlock\"])\n        blocks.extend(timedelta_blocks)\n\n    if len(items_dict[\"IntBlock\"]):\n        int_blocks = _multi_blockify(items_dict[\"IntBlock\"])\n        blocks.extend(int_blocks)\n\n    if len(items_dict[\"DatetimeBlock\"]):\n        datetime_blocks = _simple_blockify(items_dict[\"DatetimeBlock\"], _NS_DTYPE)\n        blocks.extend(datetime_blocks)\n\n    if len(items_dict[\"DatetimeTZBlock\"]):\n        dttz_blocks = [\n            make_block(array, klass=DatetimeTZBlock, placement=[i])\n            for i, _, array in items_dict[\"DatetimeTZBlock\"]\n        ]\n        blocks.extend(dttz_blocks)\n\n    if len(items_dict[\"BoolBlock\"]):\n        bool_blocks = _simple_blockify(items_dict[\"BoolBlock\"], np.bool_)\n        blocks.extend(bool_blocks)\n\n    if len(items_dict[\"ObjectBlock\"]) > 0:\n        object_blocks = _simple_blockify(items_dict[\"ObjectBlock\"], np.object_)\n        blocks.extend(object_blocks)\n\n    if len(items_dict[\"CategoricalBlock\"]) > 0:\n        cat_blocks = [\n            make_block(array, klass=CategoricalBlock, placement=[i])\n            for i, _, array in items_dict[\"CategoricalBlock\"]\n        ]\n        blocks.extend(cat_blocks)\n\n    if len(items_dict[\"ExtensionBlock\"]):\n\n        external_blocks = [\n            make_block(array, klass=ExtensionBlock, placement=[i])\n            for i, _, array in items_dict[\"ExtensionBlock\"]\n        ]\n\n        blocks.extend(external_blocks)\n\n    if len(items_dict[\"ObjectValuesExtensionBlock\"]):\n        external_blocks = [\n            make_block(array, klass=ObjectValuesExtensionBlock, placement=[i])\n            for i, _, array in items_dict[\"ObjectValuesExtensionBlock\"]\n        ]\n\n        blocks.extend(external_blocks)\n\n    if len(extra_locs):\n        shape = (len(extra_locs),) + tuple(len(x) for x in axes[1:])\n\n        # empty items -> dtype object\n        block_values = np.empty(shape, dtype=object)\n        block_values.fill(np.nan)\n\n        na_block = make_block(block_values, placement=extra_locs)\n        blocks.append(na_block)\n\n    return blocks",
        "begin_line": 1707,
        "end_line": 1801,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers._simple_blockify#1804",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._simple_blockify(tuples, dtype)",
        "snippet": "def _simple_blockify(tuples, dtype):\n    \"\"\" return a single array of a block that has a single dtype; if dtype is\n    not None, coerce to this dtype\n    \"\"\"\n    values, placement = _stack_arrays(tuples, dtype)\n\n    # TODO: CHECK DTYPE?\n    if dtype is not None and values.dtype != dtype:  # pragma: no cover\n        values = values.astype(dtype)\n\n    block = make_block(values, placement=placement)\n    return [block]",
        "begin_line": 1804,
        "end_line": 1815,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers._stack_arrays#1835",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._stack_arrays(tuples, dtype)",
        "snippet": "def _stack_arrays(tuples, dtype):\n\n    # fml\n    def _asarray_compat(x):\n        if isinstance(x, ABCSeries):\n            return x._values\n        else:\n            return np.asarray(x)\n\n    def _shape_compat(x):\n        if isinstance(x, ABCSeries):\n            return (len(x),)\n        else:\n            return x.shape\n\n    placement, names, arrays = zip(*tuples)\n\n    first = arrays[0]\n    shape = (len(arrays),) + _shape_compat(first)\n\n    stacked = np.empty(shape, dtype=dtype)\n    for i, arr in enumerate(arrays):\n        stacked[i] = _asarray_compat(arr)\n\n    return stacked, placement",
        "begin_line": 1835,
        "end_line": 1859,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers._asarray_compat#1838",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._asarray_compat(x)",
        "snippet": "    def _asarray_compat(x):\n        if isinstance(x, ABCSeries):\n            return x._values\n        else:\n            return np.asarray(x)",
        "begin_line": 1838,
        "end_line": 1842,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.managers._shape_compat#1844",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers",
        "signature": "pandas.core.internals.managers._shape_compat(x)",
        "snippet": "    def _shape_compat(x):\n        if isinstance(x, ABCSeries):\n            return (len(x),)\n        else:\n            return x.shape",
        "begin_line": 1844,
        "end_line": 1848,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.missing.dispatch_fill_zeros#136",
        "src_path": "pandas/core/ops/missing.py",
        "class_name": "pandas.core.ops.missing",
        "signature": "pandas.core.ops.missing.dispatch_fill_zeros(op, left, right, result)",
        "snippet": "def dispatch_fill_zeros(op, left, right, result):\n    \"\"\"\n    Call fill_zeros with the appropriate fill value depending on the operation,\n    with special logic for divmod and rdivmod.\n\n    Parameters\n    ----------\n    op : function (operator.add, operator.div, ...)\n    left : object (np.ndarray for non-reversed ops)\n    right : object (np.ndarray for reversed ops)\n    result : ndarray\n\n    Returns\n    -------\n    result : np.ndarray\n\n    Notes\n    -----\n    For divmod and rdivmod, the `result` parameter and returned `result`\n    is a 2-tuple of ndarray objects.\n    \"\"\"\n    if op is divmod:\n        result = (\n            mask_zero_div_zero(left, right, result[0]),\n            fill_zeros(result[1], left, right),\n        )\n    elif op is rdivmod:\n        result = (\n            mask_zero_div_zero(right, left, result[0]),\n            fill_zeros(result[1], right, left),\n        )\n    elif op is operator.floordiv:\n        # Note: no need to do this for truediv; in py3 numpy behaves the way\n        #  we want.\n        result = mask_zero_div_zero(left, right, result)\n    elif op is op is rfloordiv:\n        # Note: no need to do this for rtruediv; in py3 numpy behaves the way\n        #  we want.\n        result = mask_zero_div_zero(right, left, result)\n    elif op is operator.mod:\n        result = fill_zeros(result, left, right)\n    elif op is rmod:\n        result = fill_zeros(result, right, left)\n    return result",
        "begin_line": 136,
        "end_line": 179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.base.NoNewAttributesMixin._freeze#101",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.NoNewAttributesMixin",
        "signature": "pandas.core.base.NoNewAttributesMixin._freeze(self)",
        "snippet": "    def _freeze(self):\n        \"\"\"Prevents setting additional attributes\"\"\"\n        object.__setattr__(self, \"__frozen\", True)",
        "begin_line": 101,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.base.NoNewAttributesMixin.__setattr__#106",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.NoNewAttributesMixin",
        "signature": "pandas.core.base.NoNewAttributesMixin.__setattr__(self, key, value)",
        "snippet": "    def __setattr__(self, key, value):\n        # _cache is used by a decorator\n        # We need to check both 1.) cls.__dict__ and 2.) getattr(self, key)\n        # because\n        # 1.) getattr is false for attributes that raise errors\n        # 2.) cls.__dict__ doesn't traverse into base classes\n        if getattr(self, \"__frozen\", False) and not (\n            key == \"_cache\"\n            or key in type(self).__dict__\n            or getattr(self, key, None) is not None\n        ):\n            raise AttributeError(\n                \"You cannot add any new attribute '{key}'\".format(key=key)\n            )\n        object.__setattr__(self, key, value)",
        "begin_line": 106,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.ndim#714",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.ndim(self)",
        "snippet": "    def ndim(self) -> int:\n        \"\"\"\n        Number of dimensions of the underlying data, by definition 1.\n        \"\"\"\n        return 1",
        "begin_line": 714,
        "end_line": 718,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.size#791",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.size(self)",
        "snippet": "    def size(self):\n        \"\"\"\n        Return the number of elements in the underlying data.\n        \"\"\"\n        return len(self._values)",
        "begin_line": 791,
        "end_line": 795,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.array#828",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.array(self)",
        "snippet": "    def array(self) -> ExtensionArray:\n        \"\"\"\n        The ExtensionArray of the data backing this Series or Index.\n\n        .. versionadded:: 0.24.0\n\n        Returns\n        -------\n        ExtensionArray\n            An ExtensionArray of the values stored within. For extension\n            types, this is the actual array. For NumPy native types, this\n            is a thin (no copy) wrapper around :class:`numpy.ndarray`.\n\n            ``.array`` differs ``.values`` which may require converting the\n            data to a different form.\n\n        See Also\n        --------\n        Index.to_numpy : Similar method that always returns a NumPy array.\n        Series.to_numpy : Similar method that always returns a NumPy array.\n\n        Notes\n        -----\n        This table lays out the different array types for each extension\n        dtype within pandas.\n\n        ================== =============================\n        dtype              array type\n        ================== =============================\n        category           Categorical\n        period             PeriodArray\n        interval           IntervalArray\n        IntegerNA          IntegerArray\n        datetime64[ns, tz] DatetimeArray\n        ================== =============================\n\n        For any 3rd-party extension types, the array type will be an\n        ExtensionArray.\n\n        For all remaining dtypes ``.array`` will be a\n        :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\n        stored within. If you absolutely need a NumPy array (possibly with\n        copying / coercing data), then use :meth:`Series.to_numpy` instead.\n\n        Examples\n        --------\n\n        For regular NumPy types like int, and float, a PandasArray\n        is returned.\n\n        >>> pd.Series([1, 2, 3]).array\n        <PandasArray>\n        [1, 2, 3]\n        Length: 3, dtype: int64\n\n        For extension types, like Categorical, the actual ExtensionArray\n        is returned\n\n        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n        >>> ser.array\n        [a, b, a]\n        Categories (2, object): [a, b]\n        \"\"\"\n        # As a mixin, we depend on the mixing class having _values.\n        # Special mixin syntax may be developed in the future:\n        # https://github.com/python/typing/issues/246\n        result = self._values  # type: ignore\n\n        if is_datetime64_ns_dtype(result.dtype):\n            from pandas.arrays import DatetimeArray\n\n            result = DatetimeArray(result)\n        elif is_timedelta64_ns_dtype(result.dtype):\n            from pandas.arrays import TimedeltaArray\n\n            result = TimedeltaArray(result)\n\n        elif not is_extension_array_dtype(result.dtype):\n            from pandas.core.arrays.numpy_ import PandasArray\n\n            result = PandasArray(result)\n\n        return result",
        "begin_line": 828,
        "end_line": 910,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin._ndarray_values#1009",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin._ndarray_values(self)",
        "snippet": "    def _ndarray_values(self) -> np.ndarray:\n        \"\"\"\n        The data as an ndarray, possibly losing information.\n\n        The expectation is that this is cheap to compute, and is primarily\n        used for interacting with our indexers.\n\n        - categorical -> codes\n        \"\"\"\n        if is_extension_array_dtype(self):\n            return self.array._ndarray_values\n        # As a mixin, we depend on the mixing class having values.\n        # Special mixin syntax may be developed in the future:\n        # https://github.com/python/typing/issues/246\n        return self.values  # type: ignore",
        "begin_line": 1009,
        "end_line": 1023,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.empty#1026",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.empty(self)",
        "snippet": "    def empty(self):\n        return not self.size",
        "begin_line": 1026,
        "end_line": 1027,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.base.IndexOpsMixin.__iter__#1181",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.IndexOpsMixin",
        "signature": "pandas.core.base.IndexOpsMixin.__iter__(self)",
        "snippet": "    def __iter__(self):\n        \"\"\"\n        Return an iterator of the values.\n\n        These are each a scalar type, which is a Python scalar\n        (for str, int, float) or a pandas scalar\n        (for Timestamp/Timedelta/Interval/Period)\n\n        Returns\n        -------\n        iterator\n        \"\"\"\n        # We are explicitly making element iterators.\n        if self.dtype.kind in [\"m\", \"M\"]:\n            return map(com.maybe_box_datetimelike, self._values)\n        elif is_extension_array_dtype(self._values):\n            return iter(self._values)\n        else:\n            return map(self._values.item, range(self._values.size))",
        "begin_line": 1181,
        "end_line": 1199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasDtype.__init__#41",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasDtype",
        "signature": "pandas.core.arrays.numpy_.PandasDtype.__init__(self, dtype)",
        "snippet": "    def __init__(self, dtype):\n        dtype = np.dtype(dtype)\n        self._dtype = dtype\n        self._name = dtype.name\n        self._type = dtype.type",
        "begin_line": 41,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.__init__#124",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.__init__(self, values, copy=False)",
        "snippet": "    def __init__(self, values, copy=False):\n        if isinstance(values, type(self)):\n            values = values._ndarray\n        if not isinstance(values, np.ndarray):\n            raise ValueError(\n                \"'values' must be a NumPy array, not {typ}\".format(\n                    typ=type(values).__name__\n                )\n            )\n\n        if values.ndim != 1:\n            raise ValueError(\"PandasArray must be 1-dimensional.\")\n\n        if copy:\n            values = values.copy()\n\n        self._ndarray = values\n        self._dtype = PandasDtype(values.dtype)",
        "begin_line": 124,
        "end_line": 141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.__array__#171",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.__array__(self, dtype=None)",
        "snippet": "    def __array__(self, dtype=None):\n        return np.asarray(self._ndarray, dtype=dtype)",
        "begin_line": 171,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.to_numpy#403",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.to_numpy(self, dtype=None, copy=False)",
        "snippet": "    def to_numpy(self, dtype=None, copy=False):\n        \"\"\"\n        Convert the PandasArray to a :class:`numpy.ndarray`.\n\n        By default, this requires no coercion or copying of data.\n\n        Parameters\n        ----------\n        dtype : numpy.dtype\n            The NumPy dtype to pass to :func:`numpy.asarray`.\n        copy : bool, default False\n            Whether to copy the underlying data.\n\n        Returns\n        -------\n        ndarray\n        \"\"\"\n        result = np.asarray(self._ndarray, dtype=dtype)\n        if copy and result is self._ndarray:\n            result = result.copy()\n\n        return result",
        "begin_line": 403,
        "end_line": 424,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.common.is_bool_indexer#98",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.is_bool_indexer(key: Any)",
        "snippet": "def is_bool_indexer(key: Any) -> bool:\n    \"\"\"\n    Check whether `key` is a valid boolean indexer.\n\n    Parameters\n    ----------\n    key : Any\n        Only list-likes may be considered boolean indexers.\n        All other types are not considered a boolean indexer.\n        For array-like input, boolean ndarrays or ExtensionArrays\n        with ``_is_boolean`` set are considered boolean indexers.\n\n    Returns\n    -------\n    bool\n\n    Raises\n    ------\n    ValueError\n        When the array is an object-dtype ndarray or ExtensionArray\n        and contains missing values.\n    \"\"\"\n    na_msg = \"cannot index with vector containing NA / NaN values\"\n    if isinstance(key, (ABCSeries, np.ndarray, ABCIndex)) or (\n        is_array_like(key) and is_extension_array_dtype(key.dtype)\n    ):\n        if key.dtype == np.object_:\n            key = np.asarray(values_from_object(key))\n\n            if not lib.is_bool_array(key):\n                if isna(key).any():\n                    raise ValueError(na_msg)\n                return False\n            return True\n        elif is_bool_dtype(key.dtype):\n            # an ndarray with bool-dtype by definition has no missing values.\n            # So we only need to check for NAs in ExtensionArrays\n            if is_extension_array_dtype(key.dtype):\n                if np.any(key.isna()):\n                    raise ValueError(na_msg)\n            return True\n    elif isinstance(key, list):\n        try:\n            arr = np.asarray(key)\n            return arr.dtype == np.bool_ and len(arr) == len(key)\n        except TypeError:  # pragma: no cover\n            return False\n\n    return False",
        "begin_line": 98,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.common.cast_scalar_indexer#149",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.cast_scalar_indexer(val)",
        "snippet": "def cast_scalar_indexer(val):\n    \"\"\"\n    To avoid numpy DeprecationWarnings, cast float to integer where valid.\n\n    Parameters\n    ----------\n    val : scalar\n\n    Returns\n    -------\n    outval : scalar\n    \"\"\"\n    # assumes lib.is_scalar(val)\n    if lib.is_float(val) and val == int(val):\n        return int(val)\n    return val",
        "begin_line": 149,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.common.asarray_tuplesafe#217",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.asarray_tuplesafe(values, dtype=None)",
        "snippet": "def asarray_tuplesafe(values, dtype=None):\n\n    if not (isinstance(values, (list, tuple)) or hasattr(values, \"__array__\")):\n        values = list(values)\n    elif isinstance(values, ABCIndexClass):\n        return values.values\n\n    if isinstance(values, list) and dtype in [np.object_, object]:\n        return construct_1d_object_array_from_listlike(values)\n\n    result = np.asarray(values, dtype=dtype)\n\n    if issubclass(result.dtype.type, str):\n        result = np.asarray(values, dtype=object)\n\n    if result.ndim == 2:\n        # Avoid building an array of arrays:\n        values = [tuple(x) for x in values]\n        result = construct_1d_object_array_from_listlike(values)\n\n    return result",
        "begin_line": 217,
        "end_line": 237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.common.maybe_iterable_to_list#273",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.maybe_iterable_to_list(obj: Union[Iterable, Any])",
        "snippet": "def maybe_iterable_to_list(obj: Union[Iterable, Any]) -> Union[list, Any]:\n    \"\"\"\n    If obj is Iterable but not list-like, consume into list.\n    \"\"\"\n    if isinstance(obj, abc.Iterable) and not isinstance(obj, abc.Sized):\n        return list(obj)\n    return obj",
        "begin_line": 273,
        "end_line": 279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.common.is_null_slice#282",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.is_null_slice(obj)",
        "snippet": "def is_null_slice(obj):\n    \"\"\"\n    We have a null slice.\n    \"\"\"\n    return (\n        isinstance(obj, slice)\n        and obj.start is None\n        and obj.stop is None\n        and obj.step is None\n    )",
        "begin_line": 282,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.common.apply_if_callable#328",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.apply_if_callable(maybe_callable, obj, **kwargs)",
        "snippet": "def apply_if_callable(maybe_callable, obj, **kwargs):\n    \"\"\"\n    Evaluate possibly callable input using obj and kwargs if it is callable,\n    otherwise return as it is.\n\n    Parameters\n    ----------\n    maybe_callable : possibly a callable\n    obj : NDFrame\n    **kwargs\n    \"\"\"\n\n    if callable(maybe_callable):\n        return maybe_callable(obj, **kwargs)\n\n    return maybe_callable",
        "begin_line": 328,
        "end_line": 343,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.accessor.CachedAccessor.__get__#169",
        "src_path": "pandas/core/accessor.py",
        "class_name": "pandas.core.accessor.CachedAccessor",
        "signature": "pandas.core.accessor.CachedAccessor.__get__(self, obj, cls)",
        "snippet": "    def __get__(self, obj, cls):\n        if obj is None:\n            # we're accessing the attribute of the class, i.e., Dataset.geo\n            return self._accessor\n        accessor_obj = self._accessor(obj)\n        # Replace the property with the accessor object. Inspired by:\n        # http://www.pydanny.com/cached-property.html\n        # We need to use object.__setattr__ because we overwrite __setattr__ on\n        # NDFrame\n        object.__setattr__(obj, self._name, accessor_obj)\n        return accessor_obj",
        "begin_line": 169,
        "end_line": 179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_number#29",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_number(obj)",
        "snippet": "def is_number(obj) -> bool:\n    \"\"\"\n    Check if the object is a number.\n\n    Returns True when the object is a number, and False if is not.\n\n    Parameters\n    ----------\n    obj : any type\n        The object to check if is a number.\n\n    Returns\n    -------\n    is_number : bool\n        Whether `obj` is a number or not.\n\n    See Also\n    --------\n    api.types.is_integer: Checks a subgroup of numbers.\n\n    Examples\n    --------\n    >>> pd.api.types.is_number(1)\n    True\n    >>> pd.api.types.is_number(7.15)\n    True\n\n    Booleans are valid because they are int subclass.\n\n    >>> pd.api.types.is_number(False)\n    True\n\n    >>> pd.api.types.is_number(\"foo\")\n    False\n    >>> pd.api.types.is_number(\"5\")\n    False\n    \"\"\"\n\n    return isinstance(obj, (Number, np.number))",
        "begin_line": 29,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_iterator#96",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_iterator(obj)",
        "snippet": "def is_iterator(obj) -> bool:\n    \"\"\"\n    Check if the object is an iterator.\n\n    For example, lists are considered iterators\n    but not strings or datetime objects.\n\n    Parameters\n    ----------\n    obj : The object to check\n\n    Returns\n    -------\n    is_iter : bool\n        Whether `obj` is an iterator.\n\n    Examples\n    --------\n    >>> is_iterator([1, 2, 3])\n    True\n    >>> is_iterator(datetime(2017, 1, 1))\n    False\n    >>> is_iterator(\"foo\")\n    False\n    >>> is_iterator(1)\n    False\n    \"\"\"\n\n    if not hasattr(obj, \"__iter__\"):\n        return False\n\n    return hasattr(obj, \"__next__\")",
        "begin_line": 96,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_re#168",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_re(obj)",
        "snippet": "def is_re(obj) -> bool:\n    \"\"\"\n    Check if the object is a regex pattern instance.\n\n    Parameters\n    ----------\n    obj : The object to check\n\n    Returns\n    -------\n    is_regex : bool\n        Whether `obj` is a regex pattern.\n\n    Examples\n    --------\n    >>> is_re(re.compile(\".*\"))\n    True\n    >>> is_re(\"foo\")\n    False\n    \"\"\"\n    return isinstance(obj, Pattern)",
        "begin_line": 168,
        "end_line": 188,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_array_like#220",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_array_like(obj)",
        "snippet": "def is_array_like(obj) -> bool:\n    \"\"\"\n    Check if the object is array-like.\n\n    For an object to be considered array-like, it must be list-like and\n    have a `dtype` attribute.\n\n    Parameters\n    ----------\n    obj : The object to check\n\n    Returns\n    -------\n    is_array_like : bool\n        Whether `obj` has array-like properties.\n\n    Examples\n    --------\n    >>> is_array_like(np.array([1, 2, 3]))\n    True\n    >>> is_array_like(pd.Series([\"a\", \"b\"]))\n    True\n    >>> is_array_like(pd.Index([\"2016-01-01\"]))\n    True\n    >>> is_array_like([1, 2, 3])\n    False\n    >>> is_array_like((\"a\", \"b\"))\n    False\n    \"\"\"\n\n    return is_list_like(obj) and hasattr(obj, \"dtype\")",
        "begin_line": 220,
        "end_line": 250,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_hashable#358",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_hashable(obj)",
        "snippet": "def is_hashable(obj) -> bool:\n    \"\"\"\n    Return True if hash(obj) will succeed, False otherwise.\n\n    Some types will pass a test against collections.abc.Hashable but fail when\n    they are actually hashed with hash().\n\n    Distinguish between these and other types by trying the call to hash() and\n    seeing if they raise TypeError.\n\n    Returns\n    -------\n    bool\n\n    Examples\n    --------\n    >>> a = ([],)\n    >>> isinstance(a, collections.abc.Hashable)\n    True\n    >>> is_hashable(a)\n    False\n    \"\"\"\n    # Unfortunately, we can't use isinstance(obj, collections.abc.Hashable),\n    # which can be faster than calling hash. That is because numpy scalars\n    # fail this test.\n\n    # Reconsider this decision once this numpy bug is fixed:\n    # https://github.com/numpy/numpy/issues/5562\n\n    try:\n        hash(obj)\n    except TypeError:\n        return False\n    else:\n        return True",
        "begin_line": 358,
        "end_line": 392,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_sequence#395",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_sequence(obj)",
        "snippet": "def is_sequence(obj) -> bool:\n    \"\"\"\n    Check if the object is a sequence of objects.\n    String types are not included as sequences here.\n\n    Parameters\n    ----------\n    obj : The object to check\n\n    Returns\n    -------\n    is_sequence : bool\n        Whether `obj` is a sequence of objects.\n\n    Examples\n    --------\n    >>> l = [1, 2, 3]\n    >>>\n    >>> is_sequence(l)\n    True\n    >>> is_sequence(iter(l))\n    False\n    \"\"\"\n\n    try:\n        iter(obj)  # Can iterate over it.\n        len(obj)  # Has a length associated with it.\n        return not isinstance(obj, (str, bytes))\n    except (TypeError, AttributeError):\n        return False",
        "begin_line": 395,
        "end_line": 424,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.frozen.FrozenList.__eq__#82",
        "src_path": "pandas/core/indexes/frozen.py",
        "class_name": "pandas.core.indexes.frozen.FrozenList",
        "signature": "pandas.core.indexes.frozen.FrozenList.__eq__(self, other)",
        "snippet": "    def __eq__(self, other):\n        if isinstance(other, (tuple, FrozenList)):\n            other = list(other)\n        return super().__eq__(other)",
        "begin_line": 82,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util._decorators._deprecate_kwarg#177",
        "src_path": "pandas/util/_decorators.py",
        "class_name": "pandas.util._decorators",
        "signature": "pandas.util._decorators._deprecate_kwarg(func: F)",
        "snippet": "    def _deprecate_kwarg(func: F) -> F:\n        @wraps(func)\n        def wrapper(*args, **kwargs) -> Callable[..., Any]:\n            old_arg_value = kwargs.pop(old_arg_name, None)\n\n            if old_arg_value is not None:\n                if new_arg_name is None:\n                    msg = (\n                        \"the '{old_name}' keyword is deprecated and will be \"\n                        \"removed in a future version. \"\n                        \"Please take steps to stop the use of '{old_name}'\"\n                    ).format(old_name=old_arg_name)\n                    warnings.warn(msg, FutureWarning, stacklevel=stacklevel)\n                    kwargs[old_arg_name] = old_arg_value\n                    return func(*args, **kwargs)\n\n                elif mapping is not None:\n                    if callable(mapping):\n                        new_arg_value = mapping(old_arg_value)\n                    else:\n                        new_arg_value = mapping.get(old_arg_value, old_arg_value)\n                    msg = (\n                        \"the {old_name}={old_val!r} keyword is deprecated, \"\n                        \"use {new_name}={new_val!r} instead\"\n                    ).format(\n                        old_name=old_arg_name,\n                        old_val=old_arg_value,\n                        new_name=new_arg_name,\n                        new_val=new_arg_value,\n                    )\n                else:\n                    new_arg_value = old_arg_value\n                    msg = (\n                        \"the '{old_name}' keyword is deprecated, \"\n                        \"use '{new_name}' instead\"\n                    ).format(old_name=old_arg_name, new_name=new_arg_name)\n\n                warnings.warn(msg, FutureWarning, stacklevel=stacklevel)\n                if kwargs.get(new_arg_name) is not None:\n                    msg = (\n                        \"Can only specify '{old_name}' or '{new_name}', not both\"\n                    ).format(old_name=old_arg_name, new_name=new_arg_name)\n                    raise TypeError(msg)\n                else:\n                    kwargs[new_arg_name] = new_arg_value\n            return func(*args, **kwargs)\n\n        return cast(F, wrapper)",
        "begin_line": 177,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util._decorators.wrapper#179",
        "src_path": "pandas/util/_decorators.py",
        "class_name": "pandas.util._decorators",
        "signature": "pandas.util._decorators.wrapper(*args, **kwargs)",
        "snippet": "        def wrapper(*args, **kwargs) -> Callable[..., Any]:\n            old_arg_value = kwargs.pop(old_arg_name, None)\n\n            if old_arg_value is not None:\n                if new_arg_name is None:\n                    msg = (\n                        \"the '{old_name}' keyword is deprecated and will be \"\n                        \"removed in a future version. \"\n                        \"Please take steps to stop the use of '{old_name}'\"\n                    ).format(old_name=old_arg_name)\n                    warnings.warn(msg, FutureWarning, stacklevel=stacklevel)\n                    kwargs[old_arg_name] = old_arg_value\n                    return func(*args, **kwargs)\n\n                elif mapping is not None:\n                    if callable(mapping):\n                        new_arg_value = mapping(old_arg_value)\n                    else:\n                        new_arg_value = mapping.get(old_arg_value, old_arg_value)\n                    msg = (\n                        \"the {old_name}={old_val!r} keyword is deprecated, \"\n                        \"use {new_name}={new_val!r} instead\"\n                    ).format(\n                        old_name=old_arg_name,\n                        old_val=old_arg_value,\n                        new_name=new_arg_name,\n                        new_val=new_arg_value,\n                    )\n                else:\n                    new_arg_value = old_arg_value\n                    msg = (\n                        \"the '{old_name}' keyword is deprecated, \"\n                        \"use '{new_name}' instead\"\n                    ).format(old_name=old_arg_name, new_name=new_arg_name)\n\n                warnings.warn(msg, FutureWarning, stacklevel=stacklevel)\n                if kwargs.get(new_arg_name) is not None:\n                    msg = (\n                        \"Can only specify '{old_name}' or '{new_name}', not both\"\n                    ).format(old_name=old_arg_name, new_name=new_arg_name)\n                    raise TypeError(msg)\n                else:\n                    kwargs[new_arg_name] = new_arg_value\n            return func(*args, **kwargs)",
        "begin_line": 179,
        "end_line": 222,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter.__init__#230",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter.__init__(self, series: 'Series', buf: Optional[IO[str]]=None, length: bool=True, header: bool=True, index: bool=True, na_rep: str='NaN', name: bool=False, float_format: Optional[str]=None, dtype: bool=True, max_rows: Optional[int]=None, min_rows: Optional[int]=None)",
        "snippet": "    def __init__(\n        self,\n        series: \"Series\",\n        buf: Optional[IO[str]] = None,\n        length: bool = True,\n        header: bool = True,\n        index: bool = True,\n        na_rep: str = \"NaN\",\n        name: bool = False,\n        float_format: Optional[str] = None,\n        dtype: bool = True,\n        max_rows: Optional[int] = None,\n        min_rows: Optional[int] = None,\n    ):\n        self.series = series\n        self.buf = buf if buf is not None else StringIO()\n        self.name = name\n        self.na_rep = na_rep\n        self.header = header\n        self.length = length\n        self.index = index\n        self.max_rows = max_rows\n        self.min_rows = min_rows\n\n        if float_format is None:\n            float_format = get_option(\"display.float_format\")\n        self.float_format = float_format\n        self.dtype = dtype\n        self.adj = _get_adjustment()\n\n        self._chk_truncate()",
        "begin_line": 230,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter._chk_truncate#262",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter._chk_truncate(self)",
        "snippet": "    def _chk_truncate(self) -> None:\n        from pandas.core.reshape.concat import concat\n\n        min_rows = self.min_rows\n        max_rows = self.max_rows\n        # truncation determined by max_rows, actual truncated number of rows\n        # used below by min_rows\n        truncate_v = max_rows and (len(self.series) > max_rows)\n        series = self.series\n        if truncate_v:\n            max_rows = cast(int, max_rows)\n            if min_rows:\n                # if min_rows is set (not None or 0), set max_rows to minimum\n                # of both\n                max_rows = min(min_rows, max_rows)\n            if max_rows == 1:\n                row_num = max_rows\n                series = series.iloc[:max_rows]\n            else:\n                row_num = max_rows // 2\n                series = concat((series.iloc[:row_num], series.iloc[-row_num:]))\n            self.tr_row_num = row_num  # type: Optional[int]\n        else:\n            self.tr_row_num = None\n        self.tr_series = series\n        self.truncate_v = truncate_v",
        "begin_line": 262,
        "end_line": 287,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter._get_footer#289",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter._get_footer(self)",
        "snippet": "    def _get_footer(self) -> str:\n        name = self.series.name\n        footer = \"\"\n\n        if getattr(self.series.index, \"freq\", None) is not None:\n            footer += \"Freq: {freq}\".format(freq=self.series.index.freqstr)\n\n        if self.name is not False and name is not None:\n            if footer:\n                footer += \", \"\n\n            series_name = pprint_thing(name, escape_chars=(\"\\t\", \"\\r\", \"\\n\"))\n            footer += (\n                (\"Name: {sname}\".format(sname=series_name)) if name is not None else \"\"\n            )\n\n        if self.length is True or (self.length == \"truncate\" and self.truncate_v):\n            if footer:\n                footer += \", \"\n            footer += \"Length: {length}\".format(length=len(self.series))\n\n        if self.dtype is not False and self.dtype is not None:\n            name = getattr(self.tr_series.dtype, \"name\", None)\n            if name:\n                if footer:\n                    footer += \", \"\n                footer += \"dtype: {typ}\".format(typ=pprint_thing(name))\n\n        # level infos are added to the end and in a new line, like it is done\n        # for Categoricals\n        if is_categorical_dtype(self.tr_series.dtype):\n            level_info = self.tr_series._values._repr_categories_info()\n            if footer:\n                footer += \"\\n\"\n            footer += level_info\n\n        return str(footer)",
        "begin_line": 289,
        "end_line": 325,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter._get_formatted_index#327",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter._get_formatted_index(self)",
        "snippet": "    def _get_formatted_index(self) -> Tuple[List[str], bool]:\n        index = self.tr_series.index\n        is_multi = isinstance(index, ABCMultiIndex)\n\n        if is_multi:\n            have_header = any(name for name in index.names)\n            fmt_index = index.format(names=True)\n        else:\n            have_header = index.name is not None\n            fmt_index = index.format(name=True)\n        return fmt_index, have_header",
        "begin_line": 327,
        "end_line": 337,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter._get_formatted_values#339",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter._get_formatted_values(self)",
        "snippet": "    def _get_formatted_values(self) -> List[str]:\n        return format_array(\n            self.tr_series._values,\n            None,\n            float_format=self.float_format,\n            na_rep=self.na_rep,\n        )",
        "begin_line": 339,
        "end_line": 345,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.SeriesFormatter.to_string#347",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.SeriesFormatter",
        "signature": "pandas.io.formats.format.SeriesFormatter.to_string(self)",
        "snippet": "    def to_string(self) -> str:\n        series = self.tr_series\n        footer = self._get_footer()\n\n        if len(series) == 0:\n            return \"{name}([], {footer})\".format(\n                name=self.series.__class__.__name__, footer=footer\n            )\n\n        fmt_index, have_header = self._get_formatted_index()\n        fmt_values = self._get_formatted_values()\n\n        if self.truncate_v:\n            n_header_rows = 0\n            row_num = self.tr_row_num\n            row_num = cast(int, row_num)\n            width = self.adj.len(fmt_values[row_num - 1])\n            if width > 3:\n                dot_str = \"...\"\n            else:\n                dot_str = \"..\"\n            # Series uses mode=center because it has single value columns\n            # DataFrame uses mode=left\n            dot_str = self.adj.justify([dot_str], width, mode=\"center\")[0]\n            fmt_values.insert(row_num + n_header_rows, dot_str)\n            fmt_index.insert(row_num + 1, \"\")\n\n        if self.index:\n            result = self.adj.adjoin(3, *[fmt_index[1:], fmt_values])\n        else:\n            result = self.adj.adjoin(3, fmt_values)\n\n        if self.header and have_header:\n            result = fmt_index[0] + \"\\n\" + result\n\n        if footer:\n            result += \"\\n\" + footer\n\n        return str(\"\".join(result))",
        "begin_line": 347,
        "end_line": 385,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.TextAdjustment.__init__#389",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.TextAdjustment",
        "signature": "pandas.io.formats.format.TextAdjustment.__init__(self)",
        "snippet": "    def __init__(self):\n        self.encoding = get_option(\"display.encoding\")",
        "begin_line": 389,
        "end_line": 390,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.TextAdjustment.len#392",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.TextAdjustment",
        "signature": "pandas.io.formats.format.TextAdjustment.len(self, text: str)",
        "snippet": "    def len(self, text: str) -> int:\n        return len(text)",
        "begin_line": 392,
        "end_line": 393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.TextAdjustment.justify#395",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.TextAdjustment",
        "signature": "pandas.io.formats.format.TextAdjustment.justify(self, texts: Any, max_len: int, mode: str='right')",
        "snippet": "    def justify(self, texts: Any, max_len: int, mode: str = \"right\") -> List[str]:\n        return justify(texts, max_len, mode=mode)",
        "begin_line": 395,
        "end_line": 396,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.TextAdjustment.adjoin#398",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.TextAdjustment",
        "signature": "pandas.io.formats.format.TextAdjustment.adjoin(self, space: int, *lists, **kwargs)",
        "snippet": "    def adjoin(self, space: int, *lists, **kwargs) -> str:\n        return adjoin(space, *lists, strlen=self.len, justfunc=self.justify, **kwargs)",
        "begin_line": 398,
        "end_line": 399,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format._get_adjustment#441",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format._get_adjustment()",
        "snippet": "def _get_adjustment() -> TextAdjustment:\n    use_east_asian_width = get_option(\"display.unicode.east_asian_width\")\n    if use_east_asian_width:\n        return EastAsianTextAdjustment()\n    else:\n        return TextAdjustment()",
        "begin_line": 441,
        "end_line": 446,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.format_array#1089",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format.format_array(values: Any, formatter: Optional[Callable], float_format: Optional[float_format_type]=None, na_rep: str='NaN', digits: Optional[int]=None, space: Optional[Union[str, int]]=None, justify: str='right', decimal: str='.', leading_space: Optional[bool]=None)",
        "snippet": "def format_array(\n    values: Any,\n    formatter: Optional[Callable],\n    float_format: Optional[float_format_type] = None,\n    na_rep: str = \"NaN\",\n    digits: Optional[int] = None,\n    space: Optional[Union[str, int]] = None,\n    justify: str = \"right\",\n    decimal: str = \".\",\n    leading_space: Optional[bool] = None,\n) -> List[str]:\n    \"\"\"\n    Format an array for printing.\n\n    Parameters\n    ----------\n    values\n    formatter\n    float_format\n    na_rep\n    digits\n    space\n    justify\n    decimal\n    leading_space : bool, optional\n        Whether the array should be formatted with a leading space.\n        When an array as a column of a Series or DataFrame, we do want\n        the leading space to pad between columns.\n\n        When formatting an Index subclass\n        (e.g. IntervalIndex._format_native_types), we don't want the\n        leading space since it should be left-aligned.\n\n    Returns\n    -------\n    List[str]\n    \"\"\"\n\n    if is_datetime64_dtype(values.dtype):\n        fmt_klass = Datetime64Formatter  # type: Type[GenericArrayFormatter]\n    elif is_datetime64tz_dtype(values):\n        fmt_klass = Datetime64TZFormatter\n    elif is_timedelta64_dtype(values.dtype):\n        fmt_klass = Timedelta64Formatter\n    elif is_extension_array_dtype(values.dtype):\n        fmt_klass = ExtensionArrayFormatter\n    elif is_float_dtype(values.dtype) or is_complex_dtype(values.dtype):\n        fmt_klass = FloatArrayFormatter\n    elif is_integer_dtype(values.dtype):\n        fmt_klass = IntArrayFormatter\n    else:\n        fmt_klass = GenericArrayFormatter\n\n    if space is None:\n        space = get_option(\"display.column_space\")\n\n    if float_format is None:\n        float_format = get_option(\"display.float_format\")\n\n    if digits is None:\n        digits = get_option(\"display.precision\")\n\n    fmt_obj = fmt_klass(\n        values,\n        digits=digits,\n        na_rep=na_rep,\n        float_format=float_format,\n        formatter=formatter,\n        space=space,\n        justify=justify,\n        decimal=decimal,\n        leading_space=leading_space,\n    )\n\n    return fmt_obj.get_result()",
        "begin_line": 1089,
        "end_line": 1163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.GenericArrayFormatter.__init__#1167",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.GenericArrayFormatter",
        "signature": "pandas.io.formats.format.GenericArrayFormatter.__init__(self, values: Any, digits: int=7, formatter: Optional[Callable]=None, na_rep: str='NaN', space: Union[str, int]=12, float_format: Optional[float_format_type]=None, justify: str='right', decimal: str='.', quoting: Optional[int]=None, fixed_width: bool=True, leading_space: Optional[bool]=None)",
        "snippet": "    def __init__(\n        self,\n        values: Any,\n        digits: int = 7,\n        formatter: Optional[Callable] = None,\n        na_rep: str = \"NaN\",\n        space: Union[str, int] = 12,\n        float_format: Optional[float_format_type] = None,\n        justify: str = \"right\",\n        decimal: str = \".\",\n        quoting: Optional[int] = None,\n        fixed_width: bool = True,\n        leading_space: Optional[bool] = None,\n    ):\n        self.values = values\n        self.digits = digits\n        self.na_rep = na_rep\n        self.space = space\n        self.formatter = formatter\n        self.float_format = float_format\n        self.justify = justify\n        self.decimal = decimal\n        self.quoting = quoting\n        self.fixed_width = fixed_width\n        self.leading_space = leading_space",
        "begin_line": 1167,
        "end_line": 1191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.GenericArrayFormatter.get_result#1193",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.GenericArrayFormatter",
        "signature": "pandas.io.formats.format.GenericArrayFormatter.get_result(self)",
        "snippet": "    def get_result(self) -> List[str]:\n        fmt_values = self._format_strings()\n        return _make_fixed_width(fmt_values, self.justify)",
        "begin_line": 1193,
        "end_line": 1195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.GenericArrayFormatter._format_strings#1197",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.GenericArrayFormatter",
        "signature": "pandas.io.formats.format.GenericArrayFormatter._format_strings(self)",
        "snippet": "    def _format_strings(self) -> List[str]:\n        if self.float_format is None:\n            float_format = get_option(\"display.float_format\")\n            if float_format is None:\n                fmt_str = \"{{x: .{prec:d}g}}\".format(\n                    prec=get_option(\"display.precision\")\n                )\n                float_format = lambda x: fmt_str.format(x=x)\n        else:\n            float_format = self.float_format\n\n        formatter = (\n            self.formatter\n            if self.formatter is not None\n            else (lambda x: pprint_thing(x, escape_chars=(\"\\t\", \"\\r\", \"\\n\")))\n        )\n\n        def _format(x):\n            if self.na_rep is not None and is_scalar(x) and isna(x):\n                try:\n                    # try block for np.isnat specifically\n                    # determine na_rep if x is None or NaT-like\n                    if x is None:\n                        return \"None\"\n                    elif x is NaT or np.isnat(x):\n                        return \"NaT\"\n                except (TypeError, ValueError):\n                    # np.isnat only handles datetime or timedelta objects\n                    pass\n                return self.na_rep\n            elif isinstance(x, PandasObject):\n                return \"{x}\".format(x=x)\n            else:\n                # object dtype\n                return \"{x}\".format(x=formatter(x))\n\n        vals = self.values\n        if isinstance(vals, Index):\n            vals = vals._values\n        elif isinstance(vals, ABCSparseArray):\n            vals = vals.values\n\n        is_float_type = lib.map_infer(vals, is_float) & notna(vals)\n        leading_space = self.leading_space\n        if leading_space is None:\n            leading_space = is_float_type.any()\n\n        fmt_values = []\n        for i, v in enumerate(vals):\n            if not is_float_type[i] and leading_space:\n                fmt_values.append(\" {v}\".format(v=_format(v)))\n            elif is_float_type[i]:\n                fmt_values.append(float_format(v))\n            else:\n                if leading_space is False:\n                    # False specifically, so that the default is\n                    # to include a space if we get here.\n                    tpl = \"{v}\"\n                else:\n                    tpl = \" {v}\"\n                fmt_values.append(tpl.format(v=_format(v)))\n\n        return fmt_values",
        "begin_line": 1197,
        "end_line": 1259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.GenericArrayFormatter._format#1214",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.GenericArrayFormatter",
        "signature": "pandas.io.formats.format.GenericArrayFormatter._format(x)",
        "snippet": "        def _format(x):\n            if self.na_rep is not None and is_scalar(x) and isna(x):\n                try:\n                    # try block for np.isnat specifically\n                    # determine na_rep if x is None or NaT-like\n                    if x is None:\n                        return \"None\"\n                    elif x is NaT or np.isnat(x):\n                        return \"NaT\"\n                except (TypeError, ValueError):\n                    # np.isnat only handles datetime or timedelta objects\n                    pass\n                return self.na_rep\n            elif isinstance(x, PandasObject):\n                return \"{x}\".format(x=x)\n            else:\n                # object dtype\n                return \"{x}\".format(x=formatter(x))",
        "begin_line": 1214,
        "end_line": 1231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.IntArrayFormatter._format_strings#1428",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format.IntArrayFormatter",
        "signature": "pandas.io.formats.format.IntArrayFormatter._format_strings(self)",
        "snippet": "    def _format_strings(self) -> List[str]:\n        formatter = self.formatter or (lambda x: \"{x: d}\".format(x=x))\n        fmt_values = [formatter(x) for x in self.values]\n        return fmt_values",
        "begin_line": 1428,
        "end_line": 1431,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format._make_fixed_width#1719",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format._make_fixed_width(strings: List[str], justify: str='right', minimum: Optional[int]=None, adj: Optional[TextAdjustment]=None)",
        "snippet": "def _make_fixed_width(\n    strings: List[str],\n    justify: str = \"right\",\n    minimum: Optional[int] = None,\n    adj: Optional[TextAdjustment] = None,\n) -> List[str]:\n\n    if len(strings) == 0 or justify == \"all\":\n        return strings\n\n    if adj is None:\n        adj = _get_adjustment()\n\n    max_len = max(adj.len(x) for x in strings)\n\n    if minimum is not None:\n        max_len = max(minimum, max_len)\n\n    conf_max = get_option(\"display.max_colwidth\")\n    if conf_max is not None and max_len > conf_max:\n        max_len = conf_max\n\n    def just(x):\n        if conf_max is not None:\n            if (conf_max > 3) & (adj.len(x) > max_len):\n                x = x[: max_len - 3] + \"...\"\n        return x\n\n    strings = [just(x) for x in strings]\n    result = adj.justify(strings, max_len, mode=justify)\n    return result",
        "begin_line": 1719,
        "end_line": 1749,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.format.just#1741",
        "src_path": "pandas/io/formats/format.py",
        "class_name": "pandas.io.formats.format",
        "signature": "pandas.io.formats.format.just(x)",
        "snippet": "    def just(x):\n        if conf_max is not None:\n            if (conf_max > 3) & (adj.len(x) > max_len):\n                x = x[: max_len - 3] + \"...\"\n        return x",
        "begin_line": 1741,
        "end_line": 1745,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.__init__#111",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.__init__(self, values, placement, ndim=None)",
        "snippet": "    def __init__(self, values, placement, ndim=None):\n        self.ndim = self._check_ndim(values, ndim)\n        self.mgr_locs = placement\n        self.values = values\n\n        if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):\n            raise ValueError(\n                \"Wrong number of items passed {val}, placement implies \"\n                \"{mgr}\".format(val=len(self.values), mgr=len(self.mgr_locs))\n            )",
        "begin_line": 111,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block._check_ndim#122",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block._check_ndim(self, values, ndim)",
        "snippet": "    def _check_ndim(self, values, ndim):\n        \"\"\"\n        ndim inference and validation.\n\n        Infers ndim from 'values' if not provided to __init__.\n        Validates that values.ndim and ndim are consistent if and only if\n        the class variable '_validate_ndim' is True.\n\n        Parameters\n        ----------\n        values : array-like\n        ndim : int or None\n\n        Returns\n        -------\n        ndim : int\n\n        Raises\n        ------\n        ValueError : the number of dimensions do not match\n        \"\"\"\n        if ndim is None:\n            ndim = values.ndim\n\n        if self._validate_ndim and values.ndim != ndim:\n            msg = \"Wrong number of dimensions. values.ndim != ndim [{} != {}]\"\n            raise ValueError(msg.format(values.ndim, ndim))\n\n        return ndim",
        "begin_line": 122,
        "end_line": 150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.is_view#170",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.is_view(self)",
        "snippet": "    def is_view(self):\n        \"\"\" return a boolean if I am possibly a view \"\"\"\n        return self.values.base is not None",
        "begin_line": 170,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.external_values#194",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.external_values(self, dtype=None)",
        "snippet": "    def external_values(self, dtype=None):\n        \"\"\" return an outside world format, currently just the ndarray \"\"\"\n        return self.values",
        "begin_line": 194,
        "end_line": 196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.internal_values#198",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.internal_values(self, dtype=None)",
        "snippet": "    def internal_values(self, dtype=None):\n        \"\"\" return an internal format, currently just the ndarray\n        this should be the pure internal API format\n        \"\"\"\n        return self.values",
        "begin_line": 198,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.to_dense#219",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.to_dense(self)",
        "snippet": "    def to_dense(self):\n        return self.values.view()",
        "begin_line": 219,
        "end_line": 220,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.mgr_locs#227",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.mgr_locs(self)",
        "snippet": "    def mgr_locs(self):\n        return self._mgr_locs",
        "begin_line": 227,
        "end_line": 228,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.mgr_locs#231",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.mgr_locs(self, new_mgr_locs)",
        "snippet": "    def mgr_locs(self, new_mgr_locs):\n        if not isinstance(new_mgr_locs, libinternals.BlockPlacement):\n            new_mgr_locs = libinternals.BlockPlacement(new_mgr_locs)\n\n        self._mgr_locs = new_mgr_locs",
        "begin_line": 231,
        "end_line": 235,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.make_block#244",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.make_block(self, values, placement=None)",
        "snippet": "    def make_block(self, values, placement=None):\n        \"\"\"\n        Create a new block, with type inference propagate any values that are\n        not specified\n        \"\"\"\n        if placement is None:\n            placement = self.mgr_locs\n\n        return make_block(values, placement=placement, ndim=self.ndim)",
        "begin_line": 244,
        "end_line": 252,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.make_block_same_class#254",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.make_block_same_class(self, values, placement=None, ndim=None, dtype=None)",
        "snippet": "    def make_block_same_class(self, values, placement=None, ndim=None, dtype=None):\n        \"\"\" Wrap given values in a block of same type as self. \"\"\"\n        if dtype is not None:\n            # issue 19431 fastparquet is passing this\n            warnings.warn(\n                \"dtype argument is deprecated, will be removed in a future release.\",\n                FutureWarning,\n            )\n        if placement is None:\n            placement = self.mgr_locs\n        if ndim is None:\n            ndim = self.ndim\n        return make_block(\n            values, placement=placement, ndim=ndim, klass=self.__class__, dtype=dtype\n        )",
        "begin_line": 254,
        "end_line": 268,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block._slice#302",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block._slice(self, slicer)",
        "snippet": "    def _slice(self, slicer):\n        \"\"\" return a slice of my values \"\"\"\n        return self.values[slicer]",
        "begin_line": 302,
        "end_line": 304,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.shape#327",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.shape(self)",
        "snippet": "    def shape(self):\n        return self.values.shape",
        "begin_line": 327,
        "end_line": 328,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.dtype#331",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.dtype(self)",
        "snippet": "    def dtype(self):\n        return self.values.dtype",
        "begin_line": 331,
        "end_line": 332,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.ftype#335",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.ftype(self)",
        "snippet": "    def ftype(self):\n        if getattr(self.values, \"_pandas_ftype\", False):\n            dtype = self.dtype.subtype\n        else:\n            dtype = self.dtype\n        return \"{dtype}:{ftype}\".format(dtype=dtype, ftype=self._ftype)",
        "begin_line": 335,
        "end_line": 340,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.iget#356",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.iget(self, i)",
        "snippet": "    def iget(self, i):\n        return self.values[i]",
        "begin_line": 356,
        "end_line": 357,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.setitem#792",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.setitem(self, indexer, value)",
        "snippet": "    def setitem(self, indexer, value):\n        \"\"\"\n        Set the value inplace, returning a a maybe different typed block.\n\n        Parameters\n        ----------\n        indexer : tuple, list-like, array-like, slice\n            The subset of self.values to set\n        value : object\n            The value being set\n\n        Returns\n        -------\n        Block\n\n        Notes\n        -----\n        `indexer` is a direct slice/positional indexer. `value` must\n        be a compatible shape.\n        \"\"\"\n        transpose = self.ndim == 2\n\n        # coerce None values, if appropriate\n        if value is None:\n            if self.is_numeric:\n                value = np.nan\n\n        # coerce if block dtype can store value\n        values = self.values\n        if self._can_hold_element(value):\n            # We only get here for non-Extension Blocks, so _try_coerce_args\n            #  is only relevant for DatetimeBlock and TimedeltaBlock\n            if lib.is_scalar(value):\n                value = convert_scalar(values, value)\n\n        else:\n            # current dtype cannot store value, coerce to common dtype\n            find_dtype = False\n\n            if hasattr(value, \"dtype\"):\n                dtype = value.dtype\n                find_dtype = True\n\n            elif lib.is_scalar(value) and not isna(value):\n                dtype, _ = infer_dtype_from_scalar(value, pandas_dtype=True)\n                find_dtype = True\n\n            if find_dtype:\n                dtype = find_common_type([values.dtype, dtype])\n                if not is_dtype_equal(self.dtype, dtype):\n                    b = self.astype(dtype)\n                    return b.setitem(indexer, value)\n\n        # value must be storeable at this moment\n        if is_extension_array_dtype(getattr(value, \"dtype\", None)):\n            # We need to be careful not to allow through strings that\n            #  can be parsed to EADtypes\n            arr_value = value\n        else:\n            arr_value = np.array(value)\n\n        # cast the values to a type that can hold nan (if necessary)\n        if not self._can_hold_element(value):\n            dtype, _ = maybe_promote(arr_value.dtype)\n            values = values.astype(dtype)\n\n        if transpose:\n            values = values.T\n\n        # length checking\n        check_setitem_lengths(indexer, value, values)\n\n        if is_empty_indexer(indexer, arr_value):\n            # GH#8669 empty indexers\n            pass\n\n        elif is_scalar_indexer(indexer, arr_value):\n            # setting a single element for each dim and with a rhs that could\n            #  be e.g. a list; see GH#6043\n            values[indexer] = value\n\n        # if we are an exact match (ex-broadcasting),\n        # then use the resultant dtype\n        elif (\n            len(arr_value.shape)\n            and arr_value.shape[0] == values.shape[0]\n            and arr_value.size == values.size\n        ):\n            values[indexer] = value\n            try:\n                values = values.astype(arr_value.dtype)\n            except ValueError:\n                pass\n\n        # set\n        else:\n            values[indexer] = value\n\n        if transpose:\n            values = values.T\n        block = self.make_block(values)\n        return block",
        "begin_line": 792,
        "end_line": 893,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.ObjectBlock.__init__#2537",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.ObjectBlock",
        "signature": "pandas.core.internals.blocks.ObjectBlock.__init__(self, values, placement=None, ndim=2)",
        "snippet": "    def __init__(self, values, placement=None, ndim=2):\n        if issubclass(values.dtype.type, str):\n            values = np.array(values, dtype=object)\n\n        super().__init__(values, ndim=ndim, placement=placement)",
        "begin_line": 2537,
        "end_line": 2541,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.ObjectBlock._can_hold_element#2598",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.ObjectBlock",
        "signature": "pandas.core.internals.blocks.ObjectBlock._can_hold_element(self, element: Any)",
        "snippet": "    def _can_hold_element(self, element: Any) -> bool:\n        return True",
        "begin_line": 2598,
        "end_line": 2599,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.get_block_type#2956",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks.get_block_type(values, dtype=None)",
        "snippet": "def get_block_type(values, dtype=None):\n    \"\"\"\n    Find the appropriate Block subclass to use for the given values and dtype.\n\n    Parameters\n    ----------\n    values : ndarray-like\n    dtype : numpy or pandas dtype\n\n    Returns\n    -------\n    cls : class, subclass of Block\n    \"\"\"\n    dtype = dtype or values.dtype\n    vtype = dtype.type\n\n    if is_sparse(dtype):\n        # Need this first(ish) so that Sparse[datetime] is sparse\n        cls = ExtensionBlock\n    elif is_categorical(values):\n        cls = CategoricalBlock\n    elif issubclass(vtype, np.datetime64):\n        assert not is_datetime64tz_dtype(values)\n        cls = DatetimeBlock\n    elif is_datetime64tz_dtype(values):\n        cls = DatetimeTZBlock\n    elif is_interval_dtype(dtype) or is_period_dtype(dtype):\n        cls = ObjectValuesExtensionBlock\n    elif is_extension_array_dtype(values):\n        cls = ExtensionBlock\n    elif issubclass(vtype, np.floating):\n        cls = FloatBlock\n    elif issubclass(vtype, np.timedelta64):\n        assert issubclass(vtype, np.integer)\n        cls = TimeDeltaBlock\n    elif issubclass(vtype, np.complexfloating):\n        cls = ComplexBlock\n    elif issubclass(vtype, np.integer):\n        cls = IntBlock\n    elif dtype == np.bool_:\n        cls = BoolBlock\n    else:\n        cls = ObjectBlock\n    return cls",
        "begin_line": 2956,
        "end_line": 2999,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks.make_block#3002",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks.make_block(values, placement, klass=None, ndim=None, dtype=None, fastpath=None)",
        "snippet": "def make_block(values, placement, klass=None, ndim=None, dtype=None, fastpath=None):\n    # Ensure that we don't allow PandasArray / PandasDtype in internals.\n    # For now, blocks should be backed by ndarrays when possible.\n    if isinstance(values, ABCPandasArray):\n        values = values.to_numpy()\n        if ndim and ndim > 1:\n            values = np.atleast_2d(values)\n\n    if isinstance(dtype, PandasDtype):\n        dtype = dtype.numpy_dtype\n\n    if fastpath is not None:\n        # GH#19265 pyarrow is passing this\n        warnings.warn(\n            \"fastpath argument is deprecated, will be removed in a future release.\",\n            FutureWarning,\n        )\n    if klass is None:\n        dtype = dtype or values.dtype\n        klass = get_block_type(values, dtype)\n\n    elif klass is DatetimeTZBlock and not is_datetime64tz_dtype(values):\n        # TODO: This is no longer hit internally; does it need to be retained\n        #  for e.g. pyarrow?\n        values = DatetimeArray._simple_new(values, dtype=dtype)\n\n    return klass(values, ndim=ndim, placement=placement)",
        "begin_line": 3002,
        "end_line": 3028,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.blocks._extend_blocks#3034",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks._extend_blocks(result, blocks=None)",
        "snippet": "def _extend_blocks(result, blocks=None):\n    \"\"\" return a new extended blocks, givin the result \"\"\"\n    from pandas.core.internals import BlockManager\n\n    if blocks is None:\n        blocks = []\n    if isinstance(result, list):\n        for r in result:\n            if isinstance(r, list):\n                blocks.extend(r)\n            else:\n                blocks.append(r)\n    elif isinstance(result, BlockManager):\n        blocks.extend(result.blocks)\n    else:\n        blocks.append(result)\n    return blocks",
        "begin_line": 3034,
        "end_line": 3050,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.dispatch.should_extension_dispatch#24",
        "src_path": "pandas/core/ops/dispatch.py",
        "class_name": "pandas.core.ops.dispatch",
        "signature": "pandas.core.ops.dispatch.should_extension_dispatch(left: ABCSeries, right: Any)",
        "snippet": "def should_extension_dispatch(left: ABCSeries, right: Any) -> bool:\n    \"\"\"\n    Identify cases where Series operation should use dispatch_to_extension_op.\n\n    Parameters\n    ----------\n    left : Series\n    right : object\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    if (\n        is_extension_array_dtype(left.dtype)\n        or is_datetime64_dtype(left.dtype)\n        or is_timedelta64_dtype(left.dtype)\n    ):\n        return True\n\n    if not is_scalar(right) and is_extension_array_dtype(right):\n        # GH#22378 disallow scalar to exclude e.g. \"category\", \"Int64\"\n        return True\n\n    return False",
        "begin_line": 24,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.common._unpack_zerodim_and_defer#30",
        "src_path": "pandas/core/ops/common.py",
        "class_name": "pandas.core.ops.common",
        "signature": "pandas.core.ops.common._unpack_zerodim_and_defer(method, name: str)",
        "snippet": "def _unpack_zerodim_and_defer(method, name: str):\n    \"\"\"\n    Boilerplate for pandas conventions in arithmetic and comparison methods.\n\n    Ensure method returns NotImplemented when operating against \"senior\"\n    classes.  Ensure zero-dimensional ndarrays are always unpacked.\n\n    Parameters\n    ----------\n    method : binary method\n    name : str\n\n    Returns\n    -------\n    method\n    \"\"\"\n\n    is_cmp = name.strip(\"__\") in {\"eq\", \"ne\", \"lt\", \"le\", \"gt\", \"ge\"}\n\n    @wraps(method)\n    def new_method(self, other):\n\n        if is_cmp and isinstance(self, ABCIndexClass) and isinstance(other, ABCSeries):\n            # For comparison ops, Index does *not* defer to Series\n            pass\n        else:\n            for cls in [ABCDataFrame, ABCSeries, ABCIndexClass]:\n                if isinstance(self, cls):\n                    break\n                if isinstance(other, cls):\n                    return NotImplemented\n\n        other = item_from_zerodim(other)\n\n        return method(self, other)\n\n    return new_method",
        "begin_line": 30,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.common.new_method#50",
        "src_path": "pandas/core/ops/common.py",
        "class_name": "pandas.core.ops.common",
        "signature": "pandas.core.ops.common.new_method(self, other)",
        "snippet": "    def new_method(self, other):\n\n        if is_cmp and isinstance(self, ABCIndexClass) and isinstance(other, ABCSeries):\n            # For comparison ops, Index does *not* defer to Series\n            pass\n        else:\n            for cls in [ABCDataFrame, ABCSeries, ABCIndexClass]:\n                if isinstance(self, cls):\n                    break\n                if isinstance(other, cls):\n                    return NotImplemented\n\n        other = item_from_zerodim(other)\n\n        return method(self, other)",
        "begin_line": 50,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.base.ExtensionDtype.construct_from_string#195",
        "src_path": "pandas/core/dtypes/base.py",
        "class_name": "pandas.core.dtypes.base.ExtensionDtype",
        "signature": "pandas.core.dtypes.base.ExtensionDtype.construct_from_string(cls, string: str)",
        "snippet": "    def construct_from_string(cls, string: str):\n        r\"\"\"\n        Construct this type from a string.\n\n        This is useful mainly for data types that accept parameters.\n        For example, a period dtype accepts a frequency parameter that\n        can be set as ``period[H]`` (where H means hourly frequency).\n\n        By default, in the abstract class, just the name of the type is\n        expected. But subclasses can overwrite this method to accept\n        parameters.\n\n        Parameters\n        ----------\n        string : str\n            The name of the type, for example ``category``.\n\n        Returns\n        -------\n        ExtensionDtype\n            Instance of the dtype.\n\n        Raises\n        ------\n        TypeError\n            If a class cannot be constructed from this 'string'.\n\n        Examples\n        --------\n        For extension dtypes with arguments the following may be an\n        adequate implementation.\n\n        >>> @classmethod\n        ... def construct_from_string(cls, string):\n        ...     pattern = re.compile(r\"^my_type\\[(?P<arg_name>.+)\\]$\")\n        ...     match = pattern.match(string)\n        ...     if match:\n        ...         return cls(**match.groupdict())\n        ...     else:\n        ...         raise TypeError(\"Cannot construct a '{}' from \"\n        ...                         \"'{}'\".format(cls.__name__, string))\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\"Expects a string, got {typ}\".format(typ=type(string)))\n        if string != cls.name:\n            raise TypeError(\n                \"Cannot construct a '{cls}' from '{string}'\".format(\n                    cls=cls.__name__, string=string\n                )\n            )\n        return cls()",
        "begin_line": 195,
        "end_line": 245,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.base.ExtensionDtype.is_dtype#248",
        "src_path": "pandas/core/dtypes/base.py",
        "class_name": "pandas.core.dtypes.base.ExtensionDtype",
        "signature": "pandas.core.dtypes.base.ExtensionDtype.is_dtype(cls, dtype)",
        "snippet": "    def is_dtype(cls, dtype) -> bool:\n        \"\"\"\n        Check if we match 'dtype'.\n\n        Parameters\n        ----------\n        dtype : object\n            The object to check.\n\n        Returns\n        -------\n        is_dtype : bool\n\n        Notes\n        -----\n        The default implementation is True if\n\n        1. ``cls.construct_from_string(dtype)`` is an instance\n           of ``cls``.\n        2. ``dtype`` is an object and is an instance of ``cls``\n        3. ``dtype`` has a ``dtype`` attribute, and any of the above\n           conditions is true for ``dtype.dtype``.\n        \"\"\"\n        dtype = getattr(dtype, \"dtype\", dtype)\n\n        if isinstance(dtype, (ABCSeries, ABCIndexClass, ABCDataFrame, np.dtype)):\n            # https://github.com/pandas-dev/pandas/issues/22960\n            # avoid passing data to `construct_from_string`. This could\n            # cause a FutureWarning from numpy about failing elementwise\n            # comparison from, e.g., comparing DataFrame == 'category'.\n            return False\n        elif dtype is None:\n            return False\n        elif isinstance(dtype, cls):\n            return True\n        try:\n            return cls.construct_from_string(dtype) is not None\n        except TypeError:\n            return False",
        "begin_line": 248,
        "end_line": 286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_castable#987",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_castable(arr)",
        "snippet": "def maybe_castable(arr) -> bool:\n    # return False to force a non-fastpath\n\n    # check datetime64[ns]/timedelta64[ns] are valid\n    # otherwise try to coerce\n    kind = arr.dtype.kind\n    if kind == \"M\":\n        return is_datetime64_ns_dtype(arr.dtype)\n    elif kind == \"m\":\n        return is_timedelta64_ns_dtype(arr.dtype)\n\n    return arr.dtype.name not in _POSSIBLY_CAST_DTYPES",
        "begin_line": 987,
        "end_line": 998,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_infer_to_datetimelike#1001",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_infer_to_datetimelike(value, convert_dates: bool=False)",
        "snippet": "def maybe_infer_to_datetimelike(value, convert_dates: bool = False):\n    \"\"\"\n    we might have a array (or single object) that is datetime like,\n    and no dtype is passed don't change the value unless we find a\n    datetime/timedelta set\n\n    this is pretty strict in that a datetime/timedelta is REQUIRED\n    in addition to possible nulls/string likes\n\n    Parameters\n    ----------\n    value : np.array / Series / Index / list-like\n    convert_dates : bool, default False\n       if True try really hard to convert dates (such as datetime.date), other\n       leave inferred dtype 'date' alone\n\n    \"\"\"\n\n    # TODO: why not timedelta?\n    if isinstance(\n        value, (ABCDatetimeIndex, ABCPeriodIndex, ABCDatetimeArray, ABCPeriodArray)\n    ):\n        return value\n    elif isinstance(value, ABCSeries):\n        if isinstance(value._values, ABCDatetimeIndex):\n            return value._values\n\n    v = value\n\n    if not is_list_like(v):\n        v = [v]\n    v = np.array(v, copy=False)\n\n    # we only care about object dtypes\n    if not is_object_dtype(v):\n        return value\n\n    shape = v.shape\n    if not v.ndim == 1:\n        v = v.ravel()\n\n    if not len(v):\n        return value\n\n    def try_datetime(v):\n        # safe coerce to datetime64\n        try:\n            # GH19671\n            v = tslib.array_to_datetime(v, require_iso8601=True, errors=\"raise\")[0]\n        except ValueError:\n\n            # we might have a sequence of the same-datetimes with tz's\n            # if so coerce to a DatetimeIndex; if they are not the same,\n            # then these stay as object dtype, xref GH19671\n            from pandas._libs.tslibs import conversion\n            from pandas import DatetimeIndex\n\n            try:\n\n                values, tz = conversion.datetime_to_datetime64(v)\n                return DatetimeIndex(values).tz_localize(\"UTC\").tz_convert(tz=tz)\n            except (ValueError, TypeError):\n                pass\n\n        except Exception:\n            pass\n\n        return v.reshape(shape)\n\n    def try_timedelta(v):\n        # safe coerce to timedelta64\n\n        # will try first with a string & object conversion\n        from pandas import to_timedelta\n\n        try:\n            return to_timedelta(v)._ndarray_values.reshape(shape)\n        except ValueError:\n            return v.reshape(shape)\n\n    inferred_type = lib.infer_datetimelike_array(ensure_object(v))\n\n    if inferred_type == \"date\" and convert_dates:\n        value = try_datetime(v)\n    elif inferred_type == \"datetime\":\n        value = try_datetime(v)\n    elif inferred_type == \"timedelta\":\n        value = try_timedelta(v)\n    elif inferred_type == \"nat\":\n\n        # if all NaT, return as datetime\n        if isna(v).all():\n            value = try_datetime(v)\n        else:\n\n            # We have at least a NaT and a string\n            # try timedelta first to avoid spurious datetime conversions\n            # e.g. '00:00:01' is a timedelta but technically is also a datetime\n            value = try_timedelta(v)\n            if lib.infer_dtype(value, skipna=False) in [\"mixed\"]:\n                # cannot skip missing values, as NaT implies that the string\n                # is actually a datetime\n                value = try_datetime(v)\n\n    return value",
        "begin_line": 1001,
        "end_line": 1105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_cast_to_datetime#1108",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_cast_to_datetime(value, dtype, errors: str='raise')",
        "snippet": "def maybe_cast_to_datetime(value, dtype, errors: str = \"raise\"):\n    \"\"\" try to cast the array/value to a datetimelike dtype, converting float\n    nan to iNaT\n    \"\"\"\n    from pandas.core.tools.timedeltas import to_timedelta\n    from pandas.core.tools.datetimes import to_datetime\n\n    if dtype is not None:\n        if isinstance(dtype, str):\n            dtype = np.dtype(dtype)\n\n        is_datetime64 = is_datetime64_dtype(dtype)\n        is_datetime64tz = is_datetime64tz_dtype(dtype)\n        is_timedelta64 = is_timedelta64_dtype(dtype)\n\n        if is_datetime64 or is_datetime64tz or is_timedelta64:\n\n            # Force the dtype if needed.\n            msg = (\n                \"The '{dtype}' dtype has no unit. \"\n                \"Please pass in '{dtype}[ns]' instead.\"\n            )\n\n            if is_datetime64 and not is_dtype_equal(dtype, _NS_DTYPE):\n\n                # pandas supports dtype whose granularity is less than [ns]\n                # e.g., [ps], [fs], [as]\n                if dtype <= np.dtype(\"M8[ns]\"):\n                    if dtype.name == \"datetime64\":\n                        raise ValueError(msg.format(dtype=dtype.name))\n                    dtype = _NS_DTYPE\n                else:\n                    raise TypeError(\n                        \"cannot convert datetimelike to \"\n                        \"dtype [{dtype}]\".format(dtype=dtype)\n                    )\n            elif is_datetime64tz:\n\n                # our NaT doesn't support tz's\n                # this will coerce to DatetimeIndex with\n                # a matching dtype below\n                if is_scalar(value) and isna(value):\n                    value = [value]\n\n            elif is_timedelta64 and not is_dtype_equal(dtype, _TD_DTYPE):\n\n                # pandas supports dtype whose granularity is less than [ns]\n                # e.g., [ps], [fs], [as]\n                if dtype <= np.dtype(\"m8[ns]\"):\n                    if dtype.name == \"timedelta64\":\n                        raise ValueError(msg.format(dtype=dtype.name))\n                    dtype = _TD_DTYPE\n                else:\n                    raise TypeError(\n                        \"cannot convert timedeltalike to \"\n                        \"dtype [{dtype}]\".format(dtype=dtype)\n                    )\n\n            if is_scalar(value):\n                if value == iNaT or isna(value):\n                    value = iNaT\n            else:\n                value = np.array(value, copy=False)\n\n                # have a scalar array-like (e.g. NaT)\n                if value.ndim == 0:\n                    value = iNaT\n\n                # we have an array of datetime or timedeltas & nulls\n                elif np.prod(value.shape) or not is_dtype_equal(value.dtype, dtype):\n                    try:\n                        if is_datetime64:\n                            value = to_datetime(value, errors=errors)\n                            # GH 25843: Remove tz information since the dtype\n                            # didn't specify one\n                            if value.tz is not None:\n                                value = value.tz_localize(None)\n                            value = value._values\n                        elif is_datetime64tz:\n                            # The string check can be removed once issue #13712\n                            # is solved. String data that is passed with a\n                            # datetime64tz is assumed to be naive which should\n                            # be localized to the timezone.\n                            is_dt_string = is_string_dtype(value)\n                            value = to_datetime(value, errors=errors).array\n                            if is_dt_string:\n                                # Strings here are naive, so directly localize\n                                value = value.tz_localize(dtype.tz)\n                            else:\n                                # Numeric values are UTC at this point,\n                                # so localize and convert\n                                value = value.tz_localize(\"UTC\").tz_convert(dtype.tz)\n                        elif is_timedelta64:\n                            value = to_timedelta(value, errors=errors)._values\n                    except OutOfBoundsDatetime:\n                        raise\n                    except (AttributeError, ValueError, TypeError):\n                        pass\n\n        # coerce datetimelike to object\n        elif is_datetime64_dtype(value) and not is_datetime64_dtype(dtype):\n            if is_object_dtype(dtype):\n                if value.dtype != _NS_DTYPE:\n                    value = value.astype(_NS_DTYPE)\n                ints = np.asarray(value).view(\"i8\")\n                return tslib.ints_to_pydatetime(ints)\n\n            # we have a non-castable dtype that was passed\n            raise TypeError(\"Cannot cast datetime64 to {dtype}\".format(dtype=dtype))\n\n    else:\n\n        is_array = isinstance(value, np.ndarray)\n\n        # catch a datetime/timedelta that is not of ns variety\n        # and no coercion specified\n        if is_array and value.dtype.kind in [\"M\", \"m\"]:\n            dtype = value.dtype\n\n            if dtype.kind == \"M\" and dtype != _NS_DTYPE:\n                value = tslibs.conversion.ensure_datetime64ns(value)\n\n            elif dtype.kind == \"m\" and dtype != _TD_DTYPE:\n                value = to_timedelta(value)\n\n        # only do this if we have an array and the dtype of the array is not\n        # setup already we are not an integer/object, so don't bother with this\n        # conversion\n        elif not (\n            is_array\n            and not (\n                issubclass(value.dtype.type, np.integer) or value.dtype == np.object_\n            )\n        ):\n            value = maybe_infer_to_datetimelike(value)\n\n    return value",
        "begin_line": 1108,
        "end_line": 1244,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.cast.construct_1d_arraylike_from_scalar#1323",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.construct_1d_arraylike_from_scalar(value, length: int, dtype)",
        "snippet": "def construct_1d_arraylike_from_scalar(value, length: int, dtype):\n    \"\"\"\n    create a np.ndarray / pandas type of specified shape and dtype\n    filled with values\n\n    Parameters\n    ----------\n    value : scalar value\n    length : int\n    dtype : pandas_dtype / np.dtype\n\n    Returns\n    -------\n    np.ndarray / pandas type of length, filled with value\n\n    \"\"\"\n    if is_extension_array_dtype(dtype):\n        cls = dtype.construct_array_type()\n        subarr = cls._from_sequence([value] * length, dtype=dtype)\n\n    else:\n        if not isinstance(dtype, (np.dtype, type(np.dtype))):\n            dtype = dtype.dtype\n\n        if length and is_integer_dtype(dtype) and isna(value):\n            # coerce if we have nan for an integer dtype\n            dtype = np.dtype(\"float64\")\n        elif isinstance(dtype, np.dtype) and dtype.kind in (\"U\", \"S\"):\n            # we need to coerce to object dtype to avoid\n            # to allow numpy to take our string as a scalar value\n            dtype = object\n            if not isna(value):\n                value = ensure_str(value)\n\n        subarr = np.empty(length, dtype=dtype)\n        subarr.fill(value)\n\n    return subarr",
        "begin_line": 1323,
        "end_line": 1360,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.cast.construct_1d_object_array_from_listlike#1363",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.construct_1d_object_array_from_listlike(values)",
        "snippet": "def construct_1d_object_array_from_listlike(values):\n    \"\"\"\n    Transform any list-like object in a 1-dimensional numpy array of object\n    dtype.\n\n    Parameters\n    ----------\n    values : any iterable which has a len()\n\n    Raises\n    ------\n    TypeError\n        * If `values` does not have a len()\n\n    Returns\n    -------\n    1-dimensional numpy array of dtype object\n    \"\"\"\n    # numpy will try to interpret nested lists as further dimensions, hence\n    # making a 1D array that contains list-likes is a bit tricky:\n    result = np.empty(len(values), dtype=\"object\")\n    result[:] = values\n    return result",
        "begin_line": 1363,
        "end_line": 1385,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.cast.construct_1d_ndarray_preserving_na#1388",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.construct_1d_ndarray_preserving_na(values, dtype=None, copy: bool=False)",
        "snippet": "def construct_1d_ndarray_preserving_na(values, dtype=None, copy: bool = False):\n    \"\"\"\n    Construct a new ndarray, coercing `values` to `dtype`, preserving NA.\n\n    Parameters\n    ----------\n    values : Sequence\n    dtype : numpy.dtype, optional\n    copy : bool, default False\n        Note that copies may still be made with ``copy=False`` if casting\n        is required.\n\n    Returns\n    -------\n    arr : ndarray[dtype]\n\n    Examples\n    --------\n    >>> np.array([1.0, 2.0, None], dtype='str')\n    array(['1.0', '2.0', 'None'], dtype='<U4')\n\n    >>> construct_1d_ndarray_preserving_na([1.0, 2.0, None], dtype=np.dtype('str'))\n    array(['1.0', '2.0', None], dtype=object)\n    \"\"\"\n    subarr = np.array(values, dtype=dtype, copy=copy)\n\n    if dtype is not None and dtype.kind in (\"U\", \"S\"):\n        # GH-21083\n        # We can't just return np.array(subarr, dtype='str') since\n        # NumPy will convert the non-string objects into strings\n        # Including NA values. Se we have to go\n        # string -> object -> update NA, which requires an\n        # additional pass over the data.\n        na_values = isna(values)\n        subarr2 = subarr.astype(object)\n        subarr2[na_values] = np.asarray(values, dtype=object)[na_values]\n        subarr = subarr2\n\n    return subarr",
        "begin_line": 1388,
        "end_line": 1426,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_cast_to_integer_array#1429",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_cast_to_integer_array(arr, dtype, copy: bool=False)",
        "snippet": "def maybe_cast_to_integer_array(arr, dtype, copy: bool = False):\n    \"\"\"\n    Takes any dtype and returns the casted version, raising for when data is\n    incompatible with integer/unsigned integer dtypes.\n\n    .. versionadded:: 0.24.0\n\n    Parameters\n    ----------\n    arr : array-like\n        The array to cast.\n    dtype : str, np.dtype\n        The integer dtype to cast the array to.\n    copy: bool, default False\n        Whether to make a copy of the array before returning.\n\n    Returns\n    -------\n    int_arr : ndarray\n        An array of integer or unsigned integer dtype\n\n    Raises\n    ------\n    OverflowError : the dtype is incompatible with the data\n    ValueError : loss of precision has occurred during casting\n\n    Examples\n    --------\n    If you try to coerce negative values to unsigned integers, it raises:\n\n    >>> Series([-1], dtype=\"uint64\")\n    Traceback (most recent call last):\n        ...\n    OverflowError: Trying to coerce negative values to unsigned integers\n\n    Also, if you try to coerce float values to integers, it raises:\n\n    >>> Series([1, 2, 3.5], dtype=\"int64\")\n    Traceback (most recent call last):\n        ...\n    ValueError: Trying to coerce float values to integers\n    \"\"\"\n\n    try:\n        if not hasattr(arr, \"astype\"):\n            casted = np.array(arr, dtype=dtype, copy=copy)\n        else:\n            casted = arr.astype(dtype, copy=copy)\n    except OverflowError:\n        raise OverflowError(\n            \"The elements provided in the data cannot all be \"\n            \"casted to the dtype {dtype}\".format(dtype=dtype)\n        )\n\n    if np.array_equal(arr, casted):\n        return casted\n\n    # We do this casting to allow for proper\n    # data and dtype checking.\n    #\n    # We didn't do this earlier because NumPy\n    # doesn't handle `uint64` correctly.\n    arr = np.asarray(arr)\n\n    if is_unsigned_integer_dtype(dtype) and (arr < 0).any():\n        raise OverflowError(\"Trying to coerce negative values to unsigned integers\")\n\n    if is_integer_dtype(dtype) and (is_float_dtype(arr) or is_object_dtype(arr)):\n        raise ValueError(\"Trying to coerce float values to integers\")",
        "begin_line": 1429,
        "end_line": 1497,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.array_ops.na_arithmetic_op#128",
        "src_path": "pandas/core/ops/array_ops.py",
        "class_name": "pandas.core.ops.array_ops",
        "signature": "pandas.core.ops.array_ops.na_arithmetic_op(left, right, op, str_rep: str)",
        "snippet": "def na_arithmetic_op(left, right, op, str_rep: str):\n    \"\"\"\n    Return the result of evaluating op on the passed in values.\n\n    If native types are not compatible, try coersion to object dtype.\n\n    Parameters\n    ----------\n    left : np.ndarray\n    right : np.ndarray or scalar\n    str_rep : str or None\n\n    Returns\n    -------\n    array-like\n\n    Raises\n    ------\n    TypeError : invalid operation\n    \"\"\"\n    import pandas.core.computation.expressions as expressions\n\n    try:\n        result = expressions.evaluate(op, str_rep, left, right)\n    except TypeError:\n        result = masked_arith_op(left, right, op)\n\n    return missing.dispatch_fill_zeros(op, left, right, result)",
        "begin_line": 128,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.array_ops.arithmetic_op#158",
        "src_path": "pandas/core/ops/array_ops.py",
        "class_name": "pandas.core.ops.array_ops",
        "signature": "pandas.core.ops.array_ops.arithmetic_op(left: Union[np.ndarray, ABCExtensionArray], right: Any, op, str_rep: str)",
        "snippet": "def arithmetic_op(\n    left: Union[np.ndarray, ABCExtensionArray], right: Any, op, str_rep: str\n):\n    \"\"\"\n    Evaluate an arithmetic operation `+`, `-`, `*`, `/`, `//`, `%`, `**`, ...\n\n    Parameters\n    ----------\n    left : np.ndarray or ExtensionArray\n    right : object\n        Cannot be a DataFrame or Index.  Series is *not* excluded.\n    op : {operator.add, operator.sub, ...}\n        Or one of the reversed variants from roperator.\n    str_rep : str\n\n    Returns\n    -------\n    ndarrray or ExtensionArray\n        Or a 2-tuple of these in the case of divmod or rdivmod.\n    \"\"\"\n\n    from pandas.core.ops import maybe_upcast_for_op\n\n    keep_null_freq = isinstance(\n        right,\n        (\n            ABCDatetimeIndex,\n            ABCDatetimeArray,\n            ABCTimedeltaIndex,\n            ABCTimedeltaArray,\n            Timestamp,\n        ),\n    )\n\n    # NB: We assume that extract_array has already been called on `left`, but\n    #  cannot make the same assumption about `right`.  This is because we need\n    #  to define `keep_null_freq` before calling extract_array on it.\n    lvalues = left\n    rvalues = extract_array(right, extract_numpy=True)\n\n    rvalues = maybe_upcast_for_op(rvalues, lvalues.shape)\n\n    if should_extension_dispatch(left, rvalues) or isinstance(\n        rvalues, (ABCTimedeltaArray, ABCDatetimeArray, Timestamp)\n    ):\n        # TimedeltaArray, DatetimeArray, and Timestamp are included here\n        #  because they have `freq` attribute which is handled correctly\n        #  by dispatch_to_extension_op.\n        res_values = dispatch_to_extension_op(op, lvalues, rvalues, keep_null_freq)\n\n    else:\n        with np.errstate(all=\"ignore\"):\n            res_values = na_arithmetic_op(lvalues, rvalues, op, str_rep)\n\n    return res_values",
        "begin_line": 158,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.__init__.get_op_result_name#65",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.get_op_result_name(left, right)",
        "snippet": "def get_op_result_name(left, right):\n    \"\"\"\n    Find the appropriate name to pin to an operation result.  This result\n    should always be either an Index or a Series.\n\n    Parameters\n    ----------\n    left : {Series, Index}\n    right : object\n\n    Returns\n    -------\n    name : object\n        Usually a string\n    \"\"\"\n    # `left` is always a Series when called from within ops\n    if isinstance(right, (ABCSeries, ABCIndexClass)):\n        name = _maybe_match_name(left, right)\n    else:\n        name = left.name\n    return name",
        "begin_line": 65,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.__init__.maybe_upcast_for_op#123",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.maybe_upcast_for_op(obj, shape: Tuple[int, ...])",
        "snippet": "def maybe_upcast_for_op(obj, shape: Tuple[int, ...]):\n    \"\"\"\n    Cast non-pandas objects to pandas types to unify behavior of arithmetic\n    and comparison operations.\n\n    Parameters\n    ----------\n    obj: object\n    shape : tuple[int]\n\n    Returns\n    -------\n    out : object\n\n    Notes\n    -----\n    Be careful to call this *after* determining the `name` attribute to be\n    attached to the result of the arithmetic operation.\n    \"\"\"\n    from pandas.core.arrays import DatetimeArray, TimedeltaArray\n\n    if type(obj) is datetime.timedelta:\n        # GH#22390  cast up to Timedelta to rely on Timedelta\n        # implementation; otherwise operation against numeric-dtype\n        # raises TypeError\n        return Timedelta(obj)\n    elif isinstance(obj, np.datetime64):\n        # GH#28080 numpy casts integer-dtype to datetime64 when doing\n        #  array[int] + datetime64, which we do not allow\n        if isna(obj):\n            # Avoid possible ambiguities with pd.NaT\n            obj = obj.astype(\"datetime64[ns]\")\n            right = np.broadcast_to(obj, shape)\n            return DatetimeArray(right)\n\n        return Timestamp(obj)\n\n    elif isinstance(obj, np.timedelta64):\n        if isna(obj):\n            # wrapping timedelta64(\"NaT\") in Timedelta returns NaT,\n            #  which would incorrectly be treated as a datetime-NaT, so\n            #  we broadcast and wrap in a TimedeltaArray\n            obj = obj.astype(\"timedelta64[ns]\")\n            right = np.broadcast_to(obj, shape)\n            return TimedeltaArray(right)\n\n        # In particular non-nanosecond timedelta64 needs to be cast to\n        #  nanoseconds, or else we get undesired behavior like\n        #  np.timedelta64(3, 'D') / 2 == np.timedelta64(1, 'D')\n        return Timedelta(obj)\n\n    elif isinstance(obj, np.ndarray) and is_timedelta64_dtype(obj.dtype):\n        # GH#22390 Unfortunately we need to special-case right-hand\n        # timedelta64 dtypes because numpy casts integer dtypes to\n        # timedelta64 when operating with timedelta64\n        return TimedeltaArray._from_sequence(obj)\n    return obj",
        "begin_line": 123,
        "end_line": 179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.__init__._align_method_SERIES#389",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__._align_method_SERIES(left, right, align_asobject=False)",
        "snippet": "def _align_method_SERIES(left, right, align_asobject=False):\n    \"\"\" align lhs and rhs Series \"\"\"\n\n    # ToDo: Different from _align_method_FRAME, list, tuple and ndarray\n    # are not coerced here\n    # because Series has inconsistencies described in #13637\n\n    if isinstance(right, ABCSeries):\n        # avoid repeated alignment\n        if not left.index.equals(right.index):\n\n            if align_asobject:\n                # to keep original value's dtype for bool ops\n                left = left.astype(object)\n                right = right.astype(object)\n\n            left, right = left.align(right, copy=False)\n\n    return left, right",
        "begin_line": 389,
        "end_line": 407,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.__init__._construct_result#410",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__._construct_result(left: ABCSeries, result: Union[np.ndarray, ABCExtensionArray], index: ABCIndexClass, name)",
        "snippet": "def _construct_result(\n    left: ABCSeries,\n    result: Union[np.ndarray, ABCExtensionArray],\n    index: ABCIndexClass,\n    name,\n):\n    \"\"\"\n    Construct an appropriately-labelled Series from the result of an op.\n\n    Parameters\n    ----------\n    left : Series\n    result : ndarray or ExtensionArray\n    index : Index\n    name : object\n\n    Returns\n    -------\n    Series\n        In the case of __divmod__ or __rdivmod__, a 2-tuple of Series.\n    \"\"\"\n    if isinstance(result, tuple):\n        # produced by divmod or rdivmod\n        return (\n            _construct_result(left, result[0], index=index, name=name),\n            _construct_result(left, result[1], index=index, name=name),\n        )\n\n    # We do not pass dtype to ensure that the Series constructor\n    #  does inference in the case where `result` has object-dtype.\n    out = left._constructor(result, index=index)\n    out = out.__finalize__(left)\n\n    # Set the result's name after __finalize__ is called because __finalize__\n    #  would set it back to self.name\n    out.name = name\n    return out",
        "begin_line": 410,
        "end_line": 446,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.__init__._arith_method_SERIES#449",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__._arith_method_SERIES(cls, op, special)",
        "snippet": "def _arith_method_SERIES(cls, op, special):\n    \"\"\"\n    Wrapper function for Series arithmetic operations, to avoid\n    code duplication.\n    \"\"\"\n    str_rep = _get_opstr(op)\n    op_name = _get_op_name(op, special)\n\n    @unpack_zerodim_and_defer(op_name)\n    def wrapper(left, right):\n\n        left, right = _align_method_SERIES(left, right)\n        res_name = get_op_result_name(left, right)\n\n        lvalues = extract_array(left, extract_numpy=True)\n        result = arithmetic_op(lvalues, right, op, str_rep)\n\n        return _construct_result(left, result, index=left.index, name=res_name)\n\n    wrapper.__name__ = op_name\n    return wrapper",
        "begin_line": 449,
        "end_line": 469,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.ops.__init__.wrapper#458",
        "src_path": "pandas/core/ops/__init__.py",
        "class_name": "pandas.core.ops.__init__",
        "signature": "pandas.core.ops.__init__.wrapper(left, right)",
        "snippet": "    def wrapper(left, right):\n\n        left, right = _align_method_SERIES(left, right)\n        res_name = get_op_result_name(left, right)\n\n        lvalues = extract_array(left, extract_numpy=True)\n        result = arithmetic_op(lvalues, right, op, str_rep)\n\n        return _construct_result(left, result, index=left.index, name=res_name)",
        "begin_line": 458,
        "end_line": 466,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.classes#208",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.classes(*klasses)",
        "snippet": "def classes(*klasses) -> Callable:\n    \"\"\" evaluate if the tipo is a subclass of the klasses \"\"\"\n    return lambda tipo: issubclass(tipo, klasses)",
        "begin_line": 208,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.classes_and_not_datetimelike#213",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.classes_and_not_datetimelike(*klasses)",
        "snippet": "def classes_and_not_datetimelike(*klasses) -> Callable:\n    \"\"\"\n    evaluate if the tipo is a subclass of the klasses\n    and not a datetimelike\n    \"\"\"\n    return lambda tipo: (\n        issubclass(tipo, klasses)\n        and not issubclass(tipo, (np.datetime64, np.timedelta64))\n    )",
        "begin_line": 213,
        "end_line": 221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_object_dtype#224",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_object_dtype(arr_or_dtype)",
        "snippet": "def is_object_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the object dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the object dtype.\n\n    Examples\n    --------\n    >>> is_object_dtype(object)\n    True\n    >>> is_object_dtype(int)\n    False\n    >>> is_object_dtype(np.array([], dtype=object))\n    True\n    >>> is_object_dtype(np.array([], dtype=int))\n    False\n    >>> is_object_dtype([1, 2, 3])\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.object_))",
        "begin_line": 224,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_sparse#254",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_sparse(arr)",
        "snippet": "def is_sparse(arr) -> bool:\n    \"\"\"\n    Check whether an array-like is a 1-D pandas sparse array.\n\n    Check that the one-dimensional array-like is a pandas sparse array.\n    Returns True if it is a pandas sparse array, not another type of\n    sparse array.\n\n    Parameters\n    ----------\n    arr : array-like\n        Array-like to check.\n\n    Returns\n    -------\n    bool\n        Whether or not the array-like is a pandas sparse array.\n\n    See Also\n    --------\n    Series.to_dense : Return dense representation of a Series.\n\n    Examples\n    --------\n    Returns `True` if the parameter is a 1-D pandas sparse array.\n\n    >>> is_sparse(pd.SparseArray([0, 0, 1, 0]))\n    True\n    >>> is_sparse(pd.Series(pd.SparseArray([0, 0, 1, 0])))\n    True\n\n    Returns `False` if the parameter is not sparse.\n\n    >>> is_sparse(np.array([0, 0, 1, 0]))\n    False\n    >>> is_sparse(pd.Series([0, 1, 0, 0]))\n    False\n\n    Returns `False` if the parameter is not a pandas sparse array.\n\n    >>> from scipy.sparse import bsr_matrix\n    >>> is_sparse(bsr_matrix([0, 1, 0, 0]))\n    False\n\n    Returns `False` if the parameter has more than one dimension.\n    \"\"\"\n    from pandas.core.arrays.sparse import SparseDtype\n\n    dtype = getattr(arr, \"dtype\", arr)\n    return isinstance(dtype, SparseDtype)",
        "begin_line": 254,
        "end_line": 303,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_categorical#345",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_categorical(arr)",
        "snippet": "def is_categorical(arr) -> bool:\n    \"\"\"\n    Check whether an array-like is a Categorical instance.\n\n    Parameters\n    ----------\n    arr : array-like\n        The array-like to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like is of a Categorical instance.\n\n    Examples\n    --------\n    >>> is_categorical([1, 2, 3])\n    False\n\n    Categoricals, Series Categoricals, and CategoricalIndex will return True.\n\n    >>> cat = pd.Categorical([1, 2, 3])\n    >>> is_categorical(cat)\n    True\n    >>> is_categorical(pd.Series(cat))\n    True\n    >>> is_categorical(pd.CategoricalIndex([1, 2, 3]))\n    True\n    \"\"\"\n\n    return isinstance(arr, ABCCategorical) or is_categorical_dtype(arr)",
        "begin_line": 345,
        "end_line": 375,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64_dtype#496",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the datetime64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the datetime64 dtype.\n\n    Examples\n    --------\n    >>> is_datetime64_dtype(object)\n    False\n    >>> is_datetime64_dtype(np.datetime64)\n    True\n    >>> is_datetime64_dtype(np.array([], dtype=int))\n    False\n    >>> is_datetime64_dtype(np.array([], dtype=np.datetime64))\n    True\n    >>> is_datetime64_dtype([1, 2, 3])\n    False\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes(np.datetime64))",
        "begin_line": 496,
        "end_line": 524,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64tz_dtype#527",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64tz_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64tz_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of a DatetimeTZDtype dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of a DatetimeTZDtype dtype.\n\n    Examples\n    --------\n    >>> is_datetime64tz_dtype(object)\n    False\n    >>> is_datetime64tz_dtype([1, 2, 3])\n    False\n    >>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3]))  # tz-naive\n    False\n    >>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    True\n\n    >>> dtype = DatetimeTZDtype(\"ns\", tz=\"US/Eastern\")\n    >>> s = pd.Series([], dtype=dtype)\n    >>> is_datetime64tz_dtype(dtype)\n    True\n    >>> is_datetime64tz_dtype(s)\n    True\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    return DatetimeTZDtype.is_dtype(arr_or_dtype)",
        "begin_line": 527,
        "end_line": 562,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_timedelta64_dtype#565",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_timedelta64_dtype(arr_or_dtype)",
        "snippet": "def is_timedelta64_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the timedelta64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the timedelta64 dtype.\n\n    Examples\n    --------\n    >>> is_timedelta64_dtype(object)\n    False\n    >>> is_timedelta64_dtype(np.timedelta64)\n    True\n    >>> is_timedelta64_dtype([1, 2, 3])\n    False\n    >>> is_timedelta64_dtype(pd.Series([], dtype=\"timedelta64[ns]\"))\n    True\n    >>> is_timedelta64_dtype('0 days')\n    False\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes(np.timedelta64))",
        "begin_line": 565,
        "end_line": 593,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_period_dtype#596",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_period_dtype(arr_or_dtype)",
        "snippet": "def is_period_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Period dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Period dtype.\n\n    Examples\n    --------\n    >>> is_period_dtype(object)\n    False\n    >>> is_period_dtype(PeriodDtype(freq=\"D\"))\n    True\n    >>> is_period_dtype([1, 2, 3])\n    False\n    >>> is_period_dtype(pd.Period(\"2017-01-01\"))\n    False\n    >>> is_period_dtype(pd.PeriodIndex([], freq=\"A\"))\n    True\n    \"\"\"\n\n    # TODO: Consider making Period an instance of PeriodDtype\n    if arr_or_dtype is None:\n        return False\n    return PeriodDtype.is_dtype(arr_or_dtype)",
        "begin_line": 596,
        "end_line": 627,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_interval_dtype#630",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_interval_dtype(arr_or_dtype)",
        "snippet": "def is_interval_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Interval dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Interval dtype.\n\n    Examples\n    --------\n    >>> is_interval_dtype(object)\n    False\n    >>> is_interval_dtype(IntervalDtype())\n    True\n    >>> is_interval_dtype([1, 2, 3])\n    False\n    >>>\n    >>> interval = pd.Interval(1, 2, closed=\"right\")\n    >>> is_interval_dtype(interval)\n    False\n    >>> is_interval_dtype(pd.IntervalIndex([interval]))\n    True\n    \"\"\"\n\n    # TODO: Consider making Interval an instance of IntervalDtype\n    if arr_or_dtype is None:\n        return False\n    return IntervalDtype.is_dtype(arr_or_dtype)",
        "begin_line": 630,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_categorical_dtype#666",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_categorical_dtype(arr_or_dtype)",
        "snippet": "def is_categorical_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Categorical dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Categorical dtype.\n\n    Examples\n    --------\n    >>> is_categorical_dtype(object)\n    False\n    >>> is_categorical_dtype(CategoricalDtype())\n    True\n    >>> is_categorical_dtype([1, 2, 3])\n    False\n    >>> is_categorical_dtype(pd.Categorical([1, 2, 3]))\n    True\n    >>> is_categorical_dtype(pd.CategoricalIndex([1, 2, 3]))\n    True\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    return CategoricalDtype.is_dtype(arr_or_dtype)",
        "begin_line": 666,
        "end_line": 696,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_string_dtype#699",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_string_dtype(arr_or_dtype)",
        "snippet": "def is_string_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of the string dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the string dtype.\n\n    Examples\n    --------\n    >>> is_string_dtype(str)\n    True\n    >>> is_string_dtype(object)\n    True\n    >>> is_string_dtype(int)\n    False\n    >>>\n    >>> is_string_dtype(np.array(['a', 'b']))\n    True\n    >>> is_string_dtype(pd.Series([1, 2]))\n    False\n    \"\"\"\n\n    # TODO: gh-15585: consider making the checks stricter.\n    def condition(dtype) -> bool:\n        return dtype.kind in (\"O\", \"S\", \"U\") and not is_period_dtype(dtype)\n\n    return _is_dtype(arr_or_dtype, condition)",
        "begin_line": 699,
        "end_line": 732,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.condition#729",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.condition(dtype)",
        "snippet": "    def condition(dtype) -> bool:\n        return dtype.kind in (\"O\", \"S\", \"U\") and not is_period_dtype(dtype)",
        "begin_line": 729,
        "end_line": 730,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_dtype_equal#802",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_dtype_equal(source, target)",
        "snippet": "def is_dtype_equal(source, target) -> bool:\n    \"\"\"\n    Check if two dtypes are equal.\n\n    Parameters\n    ----------\n    source : The first dtype to compare\n    target : The second dtype to compare\n\n    Returns\n    -------\n    boolean\n        Whether or not the two dtypes are equal.\n\n    Examples\n    --------\n    >>> is_dtype_equal(int, float)\n    False\n    >>> is_dtype_equal(\"int\", int)\n    True\n    >>> is_dtype_equal(object, \"category\")\n    False\n    >>> is_dtype_equal(CategoricalDtype(), \"category\")\n    True\n    >>> is_dtype_equal(DatetimeTZDtype(), \"datetime64\")\n    False\n    \"\"\"\n\n    try:\n        source = _get_dtype(source)\n        target = _get_dtype(target)\n        return source == target\n    except (TypeError, AttributeError):\n\n        # invalid comparison\n        # object == category will hit this\n        return False",
        "begin_line": 802,
        "end_line": 838,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_integer_dtype#892",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_integer_dtype(arr_or_dtype)",
        "snippet": "def is_integer_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of an integer dtype.\n\n    Unlike in `in_any_int_dtype`, timedelta64 instances will return False.\n\n    .. versionchanged:: 0.24.0\n\n       The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\n       as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of an integer dtype and\n        not an instance of timedelta64.\n\n    Examples\n    --------\n    >>> is_integer_dtype(str)\n    False\n    >>> is_integer_dtype(int)\n    True\n    >>> is_integer_dtype(float)\n    False\n    >>> is_integer_dtype(np.uint64)\n    True\n    >>> is_integer_dtype('int8')\n    True\n    >>> is_integer_dtype('Int8')\n    True\n    >>> is_integer_dtype(pd.Int8Dtype)\n    True\n    >>> is_integer_dtype(np.datetime64)\n    False\n    >>> is_integer_dtype(np.timedelta64)\n    False\n    >>> is_integer_dtype(np.array(['a', 'b']))\n    False\n    >>> is_integer_dtype(pd.Series([1, 2]))\n    True\n    >>> is_integer_dtype(np.array([], dtype=np.timedelta64))\n    False\n    >>> is_integer_dtype(pd.Index([1, 2.]))  # float\n    False\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes_and_not_datetimelike(np.integer))",
        "begin_line": 892,
        "end_line": 944,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_signed_integer_dtype#947",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_signed_integer_dtype(arr_or_dtype)",
        "snippet": "def is_signed_integer_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a signed integer dtype.\n\n    Unlike in `in_any_int_dtype`, timedelta64 instances will return False.\n\n    .. versionchanged:: 0.24.0\n\n       The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\n       as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a signed integer dtype\n        and not an instance of timedelta64.\n\n    Examples\n    --------\n    >>> is_signed_integer_dtype(str)\n    False\n    >>> is_signed_integer_dtype(int)\n    True\n    >>> is_signed_integer_dtype(float)\n    False\n    >>> is_signed_integer_dtype(np.uint64)  # unsigned\n    False\n    >>> is_signed_integer_dtype('int8')\n    True\n    >>> is_signed_integer_dtype('Int8')\n    True\n    >>> is_signed_dtype(pd.Int8Dtype)\n    True\n    >>> is_signed_integer_dtype(np.datetime64)\n    False\n    >>> is_signed_integer_dtype(np.timedelta64)\n    False\n    >>> is_signed_integer_dtype(np.array(['a', 'b']))\n    False\n    >>> is_signed_integer_dtype(pd.Series([1, 2]))\n    True\n    >>> is_signed_integer_dtype(np.array([], dtype=np.timedelta64))\n    False\n    >>> is_signed_integer_dtype(pd.Index([1, 2.]))  # float\n    False\n    >>> is_signed_integer_dtype(np.array([1, 2], dtype=np.uint32))  # unsigned\n    False\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes_and_not_datetimelike(np.signedinteger))",
        "begin_line": 947,
        "end_line": 1001,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_unsigned_integer_dtype#1004",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_unsigned_integer_dtype(arr_or_dtype)",
        "snippet": "def is_unsigned_integer_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of an unsigned integer dtype.\n\n    .. versionchanged:: 0.24.0\n\n       The nullable Integer dtypes (e.g. pandas.UInt64Dtype) are also\n       considered as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of an unsigned integer dtype.\n\n    Examples\n    --------\n    >>> is_unsigned_integer_dtype(str)\n    False\n    >>> is_unsigned_integer_dtype(int)  # signed\n    False\n    >>> is_unsigned_integer_dtype(float)\n    False\n    >>> is_unsigned_integer_dtype(np.uint64)\n    True\n    >>> is_unsigned_integer_dtype('uint8')\n    True\n    >>> is_unsigned_integer_dtype('UInt8')\n    True\n    >>> is_unsigned_integer_dtype(pd.UInt8Dtype)\n    True\n    >>> is_unsigned_integer_dtype(np.array(['a', 'b']))\n    False\n    >>> is_unsigned_integer_dtype(pd.Series([1, 2]))  # signed\n    False\n    >>> is_unsigned_integer_dtype(pd.Index([1, 2.]))  # float\n    False\n    >>> is_unsigned_integer_dtype(np.array([1, 2], dtype=np.uint32))\n    True\n    \"\"\"\n    return _is_dtype_type(\n        arr_or_dtype, classes_and_not_datetimelike(np.unsignedinteger)\n    )",
        "begin_line": 1004,
        "end_line": 1050,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64_any_dtype#1104",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64_any_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64_any_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of the datetime64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the datetime64 dtype.\n\n    Examples\n    --------\n    >>> is_datetime64_any_dtype(str)\n    False\n    >>> is_datetime64_any_dtype(int)\n    False\n    >>> is_datetime64_any_dtype(np.datetime64)  # can be tz-naive\n    True\n    >>> is_datetime64_any_dtype(DatetimeTZDtype(\"ns\", \"US/Eastern\"))\n    True\n    >>> is_datetime64_any_dtype(np.array(['a', 'b']))\n    False\n    >>> is_datetime64_any_dtype(np.array([1, 2]))\n    False\n    >>> is_datetime64_any_dtype(np.array([], dtype=np.datetime64))\n    True\n    >>> is_datetime64_any_dtype(pd.DatetimeIndex([1, 2, 3],\n                                dtype=np.datetime64))\n    True\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    return is_datetime64_dtype(arr_or_dtype) or is_datetime64tz_dtype(arr_or_dtype)",
        "begin_line": 1104,
        "end_line": 1141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64_ns_dtype#1144",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64_ns_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64_ns_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of the datetime64[ns] dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the datetime64[ns] dtype.\n\n    Examples\n    --------\n    >>> is_datetime64_ns_dtype(str)\n    False\n    >>> is_datetime64_ns_dtype(int)\n    False\n    >>> is_datetime64_ns_dtype(np.datetime64)  # no unit\n    False\n    >>> is_datetime64_ns_dtype(DatetimeTZDtype(\"ns\", \"US/Eastern\"))\n    True\n    >>> is_datetime64_ns_dtype(np.array(['a', 'b']))\n    False\n    >>> is_datetime64_ns_dtype(np.array([1, 2]))\n    False\n    >>> is_datetime64_ns_dtype(np.array([], dtype=np.datetime64))  # no unit\n    False\n    >>> is_datetime64_ns_dtype(np.array([],\n                               dtype=\"datetime64[ps]\"))  # wrong unit\n    False\n    >>> is_datetime64_ns_dtype(pd.DatetimeIndex([1, 2, 3],\n                               dtype=np.datetime64))  # has 'ns' unit\n    True\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    try:\n        tipo = _get_dtype(arr_or_dtype)\n    except TypeError:\n        if is_datetime64tz_dtype(arr_or_dtype):\n            tipo = _get_dtype(arr_or_dtype.dtype)\n        else:\n            return False\n    return tipo == _NS_DTYPE or getattr(tipo, \"base\", None) == _NS_DTYPE",
        "begin_line": 1144,
        "end_line": 1191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_timedelta64_ns_dtype#1194",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_timedelta64_ns_dtype(arr_or_dtype)",
        "snippet": "def is_timedelta64_ns_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of the timedelta64[ns] dtype.\n\n    This is a very specific dtype, so generic ones like `np.timedelta64`\n    will return False if passed into this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the timedelta64[ns] dtype.\n\n    Examples\n    --------\n    >>> is_timedelta64_ns_dtype(np.dtype('m8[ns]'))\n    True\n    >>> is_timedelta64_ns_dtype(np.dtype('m8[ps]'))  # Wrong frequency\n    False\n    >>> is_timedelta64_ns_dtype(np.array([1, 2], dtype='m8[ns]'))\n    True\n    >>> is_timedelta64_ns_dtype(np.array([1, 2], dtype=np.timedelta64))\n    False\n    \"\"\"\n    return _is_dtype(arr_or_dtype, lambda dtype: dtype == _TD_DTYPE)",
        "begin_line": 1194,
        "end_line": 1222,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime_or_timedelta_dtype#1225",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime_or_timedelta_dtype(arr_or_dtype)",
        "snippet": "def is_datetime_or_timedelta_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of\n    a timedelta64 or datetime64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a timedelta64,\n        or datetime64 dtype.\n\n    Examples\n    --------\n    >>> is_datetime_or_timedelta_dtype(str)\n    False\n    >>> is_datetime_or_timedelta_dtype(int)\n    False\n    >>> is_datetime_or_timedelta_dtype(np.datetime64)\n    True\n    >>> is_datetime_or_timedelta_dtype(np.timedelta64)\n    True\n    >>> is_datetime_or_timedelta_dtype(np.array(['a', 'b']))\n    False\n    >>> is_datetime_or_timedelta_dtype(pd.Series([1, 2]))\n    False\n    >>> is_datetime_or_timedelta_dtype(np.array([], dtype=np.timedelta64))\n    True\n    >>> is_datetime_or_timedelta_dtype(np.array([], dtype=np.datetime64))\n    True\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes(np.datetime64, np.timedelta64))",
        "begin_line": 1225,
        "end_line": 1261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.needs_i8_conversion#1281",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.needs_i8_conversion(arr_or_dtype)",
        "snippet": "def needs_i8_conversion(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the array or dtype should be converted to int64.\n\n    An array-like or dtype \"needs\" such a conversion if the array-like\n    or dtype is of a datetime-like dtype\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype should be converted to int64.\n\n    Examples\n    --------\n    >>> needs_i8_conversion(str)\n    False\n    >>> needs_i8_conversion(np.int64)\n    False\n    >>> needs_i8_conversion(np.datetime64)\n    True\n    >>> needs_i8_conversion(np.array(['a', 'b']))\n    False\n    >>> needs_i8_conversion(pd.Series([1, 2]))\n    False\n    >>> needs_i8_conversion(pd.Series([], dtype=\"timedelta64[ns]\"))\n    True\n    >>> needs_i8_conversion(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    True\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    return (\n        is_datetime_or_timedelta_dtype(arr_or_dtype)\n        or is_datetime64tz_dtype(arr_or_dtype)\n        or is_period_dtype(arr_or_dtype)\n    )",
        "begin_line": 1281,
        "end_line": 1322,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_string_like_dtype#1368",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_string_like_dtype(arr_or_dtype)",
        "snippet": "def is_string_like_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a string-like dtype.\n\n    Unlike `is_string_dtype`, the object dtype is excluded because it\n    is a mixed dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the string dtype.\n\n    Examples\n    --------\n    >>> is_string_like_dtype(str)\n    True\n    >>> is_string_like_dtype(object)\n    False\n    >>> is_string_like_dtype(np.array(['a', 'b']))\n    True\n    >>> is_string_like_dtype(pd.Series([1, 2]))\n    False\n    \"\"\"\n\n    return _is_dtype(arr_or_dtype, lambda dtype: dtype.kind in (\"S\", \"U\"))",
        "begin_line": 1368,
        "end_line": 1397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_float_dtype#1400",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_float_dtype(arr_or_dtype)",
        "snippet": "def is_float_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a float dtype.\n\n    This function is internal and should not be exposed in the public API.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a float dtype.\n\n    Examples\n    --------\n    >>> is_float_dtype(str)\n    False\n    >>> is_float_dtype(int)\n    False\n    >>> is_float_dtype(float)\n    True\n    >>> is_float_dtype(np.array(['a', 'b']))\n    False\n    >>> is_float_dtype(pd.Series([1, 2]))\n    False\n    >>> is_float_dtype(pd.Index([1, 2.]))\n    True\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.floating))",
        "begin_line": 1400,
        "end_line": 1431,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_bool_dtype#1434",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_bool_dtype(arr_or_dtype)",
        "snippet": "def is_bool_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a boolean dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a boolean dtype.\n\n    Notes\n    -----\n    An ExtensionArray is considered boolean when the ``_is_boolean``\n    attribute is set to True.\n\n    Examples\n    --------\n    >>> is_bool_dtype(str)\n    False\n    >>> is_bool_dtype(int)\n    False\n    >>> is_bool_dtype(bool)\n    True\n    >>> is_bool_dtype(np.bool)\n    True\n    >>> is_bool_dtype(np.array(['a', 'b']))\n    False\n    >>> is_bool_dtype(pd.Series([1, 2]))\n    False\n    >>> is_bool_dtype(np.array([True, False]))\n    True\n    >>> is_bool_dtype(pd.Categorical([True, False]))\n    True\n    >>> is_bool_dtype(pd.SparseArray([True, False]))\n    True\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    try:\n        dtype = _get_dtype(arr_or_dtype)\n    except TypeError:\n        return False\n\n    if isinstance(arr_or_dtype, CategoricalDtype):\n        arr_or_dtype = arr_or_dtype.categories\n        # now we use the special definition for Index\n\n    if isinstance(arr_or_dtype, ABCIndexClass):\n\n        # TODO(jreback)\n        # we don't have a boolean Index class\n        # so its object, we need to infer to\n        # guess this\n        return arr_or_dtype.is_object and arr_or_dtype.inferred_type == \"boolean\"\n    elif is_extension_array_dtype(arr_or_dtype):\n        dtype = getattr(arr_or_dtype, \"dtype\", arr_or_dtype)\n        return dtype._is_boolean\n\n    return issubclass(dtype.type, np.bool_)",
        "begin_line": 1434,
        "end_line": 1496,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_extension_array_dtype#1564",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_extension_array_dtype(arr_or_dtype)",
        "snippet": "def is_extension_array_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check if an object is a pandas extension array type.\n\n    See the :ref:`Use Guide <extending.extension-types>` for more.\n\n    Parameters\n    ----------\n    arr_or_dtype : object\n        For array-like input, the ``.dtype`` attribute will\n        be extracted.\n\n    Returns\n    -------\n    bool\n        Whether the `arr_or_dtype` is an extension array type.\n\n    Notes\n    -----\n    This checks whether an object implements the pandas extension\n    array interface. In pandas, this includes:\n\n    * Categorical\n    * Sparse\n    * Interval\n    * Period\n    * DatetimeArray\n    * TimedeltaArray\n\n    Third-party libraries may implement arrays or types satisfying\n    this interface as well.\n\n    Examples\n    --------\n    >>> from pandas.api.types import is_extension_array_dtype\n    >>> arr = pd.Categorical(['a', 'b'])\n    >>> is_extension_array_dtype(arr)\n    True\n    >>> is_extension_array_dtype(arr.dtype)\n    True\n\n    >>> arr = np.array(['a', 'b'])\n    >>> is_extension_array_dtype(arr.dtype)\n    False\n    \"\"\"\n    dtype = getattr(arr_or_dtype, \"dtype\", arr_or_dtype)\n    return isinstance(dtype, ExtensionDtype) or registry.find(dtype) is not None",
        "begin_line": 1564,
        "end_line": 1610,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_complex_dtype#1613",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_complex_dtype(arr_or_dtype)",
        "snippet": "def is_complex_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a complex dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a complex dtype.\n\n    Examples\n    --------\n    >>> is_complex_dtype(str)\n    False\n    >>> is_complex_dtype(int)\n    False\n    >>> is_complex_dtype(np.complex)\n    True\n    >>> is_complex_dtype(np.array(['a', 'b']))\n    False\n    >>> is_complex_dtype(pd.Series([1, 2]))\n    False\n    >>> is_complex_dtype(np.array([1 + 1j, 5]))\n    True\n    \"\"\"\n\n    return _is_dtype_type(arr_or_dtype, classes(np.complexfloating))",
        "begin_line": 1613,
        "end_line": 1643,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common._is_dtype#1646",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._is_dtype(arr_or_dtype, condition)",
        "snippet": "def _is_dtype(arr_or_dtype, condition) -> bool:\n    \"\"\"\n    Return a boolean if the condition is satisfied for the arr_or_dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like, str, np.dtype, or ExtensionArrayType\n        The array-like or dtype object whose dtype we want to extract.\n    condition : callable[Union[np.dtype, ExtensionDtype]]\n\n    Returns\n    -------\n    bool\n\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return False\n    try:\n        dtype = _get_dtype(arr_or_dtype)\n    except (TypeError, ValueError, UnicodeEncodeError):\n        return False\n    return condition(dtype)",
        "begin_line": 1646,
        "end_line": 1668,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common._get_dtype#1671",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._get_dtype(arr_or_dtype)",
        "snippet": "def _get_dtype(arr_or_dtype):\n    \"\"\"\n    Get the dtype instance associated with an array\n    or dtype object.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype object whose dtype we want to extract.\n\n    Returns\n    -------\n    obj_dtype : The extract dtype instance from the\n                passed in array or dtype object.\n\n    Raises\n    ------\n    TypeError : The passed in object is None.\n    \"\"\"\n\n    if arr_or_dtype is None:\n        raise TypeError(\"Cannot deduce dtype from null object\")\n\n    # fastpath\n    elif isinstance(arr_or_dtype, np.dtype):\n        return arr_or_dtype\n    elif isinstance(arr_or_dtype, type):\n        return np.dtype(arr_or_dtype)\n\n    # if we have an array-like\n    elif hasattr(arr_or_dtype, \"dtype\"):\n        arr_or_dtype = arr_or_dtype.dtype\n\n    return pandas_dtype(arr_or_dtype)",
        "begin_line": 1671,
        "end_line": 1704,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common._is_dtype_type#1707",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._is_dtype_type(arr_or_dtype, condition)",
        "snippet": "def _is_dtype_type(arr_or_dtype, condition) -> bool:\n    \"\"\"\n    Return a boolean if the condition is satisfied for the arr_or_dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype object whose dtype we want to extract.\n    condition : callable[Union[np.dtype, ExtensionDtypeType]]\n\n    Returns\n    -------\n    bool : if the condition is satisfied for the arr_or_dtype\n    \"\"\"\n\n    if arr_or_dtype is None:\n        return condition(type(None))\n\n    # fastpath\n    if isinstance(arr_or_dtype, np.dtype):\n        return condition(arr_or_dtype.type)\n    elif isinstance(arr_or_dtype, type):\n        if issubclass(arr_or_dtype, ExtensionDtype):\n            arr_or_dtype = arr_or_dtype.type\n        return condition(np.dtype(arr_or_dtype).type)\n\n    # if we have an array-like\n    if hasattr(arr_or_dtype, \"dtype\"):\n        arr_or_dtype = arr_or_dtype.dtype\n\n    # we are not possibly a dtype\n    elif is_list_like(arr_or_dtype):\n        return condition(type(None))\n\n    try:\n        tipo = pandas_dtype(arr_or_dtype).type\n    except (TypeError, ValueError, UnicodeEncodeError):\n        if is_scalar(arr_or_dtype):\n            return condition(type(None))\n\n        return False\n\n    return condition(tipo)",
        "begin_line": 1707,
        "end_line": 1749,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.common.pandas_dtype#1841",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.pandas_dtype(dtype)",
        "snippet": "def pandas_dtype(dtype):\n    \"\"\"\n    Convert input into a pandas only dtype object or a numpy dtype object.\n\n    Parameters\n    ----------\n    dtype : object to be converted\n\n    Returns\n    -------\n    np.dtype or a pandas dtype\n\n    Raises\n    ------\n    TypeError if not a dtype\n    \"\"\"\n    # short-circuit\n    if isinstance(dtype, np.ndarray):\n        return dtype.dtype\n    elif isinstance(dtype, (np.dtype, ExtensionDtype)):\n        return dtype\n\n    # registered extension types\n    result = registry.find(dtype)\n    if result is not None:\n        return result\n\n    # try a numpy dtype\n    # raise a consistent TypeError if failed\n    try:\n        npdtype = np.dtype(dtype)\n    except SyntaxError:\n        # np.dtype uses `eval` which can raise SyntaxError\n        raise TypeError(\"data type '{}' not understood\".format(dtype))\n\n    # Any invalid dtype (such as pd.Timestamp) should raise an error.\n    # np.dtype(invalid_type).kind = 0 for such objects. However, this will\n    # also catch some valid dtypes such as object, np.object_ and 'object'\n    # which we safeguard against by catching them earlier and returning\n    # np.dtype(valid_dtype) before this condition is evaluated.\n    if is_hashable(dtype) and dtype in [object, np.object_, \"object\", \"O\"]:\n        # check hashability to avoid errors/DeprecationWarning when we get\n        # here and `dtype` is an array\n        return npdtype\n    elif npdtype.kind == \"O\":\n        raise TypeError(\"dtype '{}' not understood\".format(dtype))\n\n    return npdtype",
        "begin_line": 1841,
        "end_line": 1888,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.missing.isna#48",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing.isna(obj)",
        "snippet": "def isna(obj):\n    \"\"\"\n    Detect missing values for an array-like object.\n\n    This function takes a scalar or array-like object and indicates\n    whether values are missing (``NaN`` in numeric arrays, ``None`` or ``NaN``\n    in object arrays, ``NaT`` in datetimelike).\n\n    Parameters\n    ----------\n    obj : scalar or array-like\n        Object to check for null or missing values.\n\n    Returns\n    -------\n    bool or array-like of bool\n        For scalar input, returns a scalar boolean.\n        For array input, returns an array of boolean indicating whether each\n        corresponding element is missing.\n\n    See Also\n    --------\n    notna : Boolean inverse of pandas.isna.\n    Series.isna : Detect missing values in a Series.\n    DataFrame.isna : Detect missing values in a DataFrame.\n    Index.isna : Detect missing values in an Index.\n\n    Examples\n    --------\n    Scalar arguments (including strings) result in a scalar boolean.\n\n    >>> pd.isna('dog')\n    False\n\n    >>> pd.isna(np.nan)\n    True\n\n    ndarrays result in an ndarray of booleans.\n\n    >>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n    >>> array\n    array([[ 1., nan,  3.],\n           [ 4.,  5., nan]])\n    >>> pd.isna(array)\n    array([[False,  True, False],\n           [False, False,  True]])\n\n    For indexes, an ndarray of booleans is returned.\n\n    >>> index = pd.DatetimeIndex([\"2017-07-05\", \"2017-07-06\", None,\n    ...                           \"2017-07-08\"])\n    >>> index\n    DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],\n                  dtype='datetime64[ns]', freq=None)\n    >>> pd.isna(index)\n    array([False, False,  True, False])\n\n    For Series and DataFrame, the same type is returned, containing booleans.\n\n    >>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])\n    >>> df\n         0     1    2\n    0  ant   bee  cat\n    1  dog  None  fly\n    >>> pd.isna(df)\n           0      1      2\n    0  False  False  False\n    1  False   True  False\n\n    >>> pd.isna(df[1])\n    0    False\n    1     True\n    Name: 1, dtype: bool\n    \"\"\"\n    return _isna(obj)",
        "begin_line": 48,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.missing._isna_new#128",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing._isna_new(obj)",
        "snippet": "def _isna_new(obj):\n\n    if is_scalar(obj):\n        return libmissing.checknull(obj)\n    # hack (for now) because MI registers as ndarray\n    elif isinstance(obj, ABCMultiIndex):\n        raise NotImplementedError(\"isna is not defined for MultiIndex\")\n    elif isinstance(obj, type):\n        return False\n    elif isinstance(\n        obj,\n        (\n            ABCSeries,\n            np.ndarray,\n            ABCIndexClass,\n            ABCExtensionArray,\n            ABCDatetimeArray,\n            ABCTimedeltaArray,\n        ),\n    ):\n        return _isna_ndarraylike(obj)\n    elif isinstance(obj, ABCGeneric):\n        return obj._constructor(obj._data.isna(func=isna))\n    elif isinstance(obj, list):\n        return _isna_ndarraylike(np.asarray(obj, dtype=object))\n    elif hasattr(obj, \"__array__\"):\n        return _isna_ndarraylike(np.asarray(obj))\n    else:\n        return obj is None",
        "begin_line": 128,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.missing._isna_ndarraylike#221",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing._isna_ndarraylike(obj)",
        "snippet": "def _isna_ndarraylike(obj):\n    is_extension = is_extension_array_dtype(obj)\n\n    if not is_extension:\n        # Avoid accessing `.values` on things like\n        # PeriodIndex, which may be expensive.\n        values = getattr(obj, \"values\", obj)\n    else:\n        values = obj\n\n    dtype = values.dtype\n\n    if is_extension:\n        if isinstance(obj, (ABCIndexClass, ABCSeries)):\n            values = obj._values\n        else:\n            values = obj\n        result = values.isna()\n    elif isinstance(obj, ABCDatetimeArray):\n        return obj.isna()\n    elif is_string_dtype(dtype):\n        # Working around NumPy ticket 1542\n        shape = values.shape\n\n        if is_string_like_dtype(dtype):\n            # object array of strings\n            result = np.zeros(values.shape, dtype=bool)\n        else:\n            # object array of non-strings\n            result = np.empty(shape, dtype=bool)\n            vec = libmissing.isnaobj(values.ravel())\n            result[...] = vec.reshape(shape)\n\n    elif needs_i8_conversion(dtype):\n        # this is the NaT pattern\n        result = values.view(\"i8\") == iNaT\n    else:\n        result = np.isnan(values)\n\n    # box\n    if isinstance(obj, ABCSeries):\n        result = obj._constructor(result, index=obj.index, name=obj.name, copy=False)\n\n    return result",
        "begin_line": 221,
        "end_line": 264,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.missing.notna#295",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing.notna(obj)",
        "snippet": "def notna(obj):\n    \"\"\"\n    Detect non-missing values for an array-like object.\n\n    This function takes a scalar or array-like object and indicates\n    whether values are valid (not missing, which is ``NaN`` in numeric\n    arrays, ``None`` or ``NaN`` in object arrays, ``NaT`` in datetimelike).\n\n    Parameters\n    ----------\n    obj : array-like or object value\n        Object to check for *not* null or *non*-missing values.\n\n    Returns\n    -------\n    bool or array-like of bool\n        For scalar input, returns a scalar boolean.\n        For array input, returns an array of boolean indicating whether each\n        corresponding element is valid.\n\n    See Also\n    --------\n    isna : Boolean inverse of pandas.notna.\n    Series.notna : Detect valid values in a Series.\n    DataFrame.notna : Detect valid values in a DataFrame.\n    Index.notna : Detect valid values in an Index.\n\n    Examples\n    --------\n    Scalar arguments (including strings) result in a scalar boolean.\n\n    >>> pd.notna('dog')\n    True\n\n    >>> pd.notna(np.nan)\n    False\n\n    ndarrays result in an ndarray of booleans.\n\n    >>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n    >>> array\n    array([[ 1., nan,  3.],\n           [ 4.,  5., nan]])\n    >>> pd.notna(array)\n    array([[ True, False,  True],\n           [ True,  True, False]])\n\n    For indexes, an ndarray of booleans is returned.\n\n    >>> index = pd.DatetimeIndex([\"2017-07-05\", \"2017-07-06\", None,\n    ...                          \"2017-07-08\"])\n    >>> index\n    DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],\n                  dtype='datetime64[ns]', freq=None)\n    >>> pd.notna(index)\n    array([ True,  True, False,  True])\n\n    For Series and DataFrame, the same type is returned, containing booleans.\n\n    >>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])\n    >>> df\n         0     1    2\n    0  ant   bee  cat\n    1  dog  None  fly\n    >>> pd.notna(df)\n          0      1     2\n    0  True   True  True\n    1  True  False  True\n\n    >>> pd.notna(df[1])\n    0     True\n    1    False\n    Name: 1, dtype: bool\n    \"\"\"\n    res = isna(obj)\n    if is_scalar(res):\n        return not res\n    return ~res",
        "begin_line": 295,
        "end_line": 372,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.missing.array_equivalent#395",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing.array_equivalent(left, right, strict_nan: bool=False)",
        "snippet": "def array_equivalent(left, right, strict_nan: bool = False) -> bool:\n    \"\"\"\n    True if two arrays, left and right, have equal non-NaN elements, and NaNs\n    in corresponding locations.  False otherwise. It is assumed that left and\n    right are NumPy arrays of the same dtype. The behavior of this function\n    (particularly with respect to NaNs) is not defined if the dtypes are\n    different.\n\n    Parameters\n    ----------\n    left, right : ndarrays\n    strict_nan : bool, default False\n        If True, consider NaN and None to be different.\n\n    Returns\n    -------\n    b : bool\n        Returns True if the arrays are equivalent.\n\n    Examples\n    --------\n    >>> array_equivalent(\n    ...     np.array([1, 2, np.nan]),\n    ...     np.array([1, 2, np.nan]))\n    True\n    >>> array_equivalent(\n    ...     np.array([1, np.nan, 2]),\n    ...     np.array([1, 2, np.nan]))\n    False\n    \"\"\"\n\n    left, right = np.asarray(left), np.asarray(right)\n\n    # shape compat\n    if left.shape != right.shape:\n        return False\n\n    # Object arrays can contain None, NaN and NaT.\n    # string dtypes must be come to this path for NumPy 1.7.1 compat\n    if is_string_dtype(left) or is_string_dtype(right):\n\n        if not strict_nan:\n            # isna considers NaN and None to be equivalent.\n            return lib.array_equivalent_object(\n                ensure_object(left.ravel()), ensure_object(right.ravel())\n            )\n\n        for left_value, right_value in zip(left, right):\n            if left_value is NaT and right_value is not NaT:\n                return False\n\n            elif isinstance(left_value, float) and np.isnan(left_value):\n                if not isinstance(right_value, float) or not np.isnan(right_value):\n                    return False\n            else:\n                try:\n                    if np.any(left_value != right_value):\n                        return False\n                except TypeError as err:\n                    if \"Cannot compare tz-naive\" in str(err):\n                        # tzawareness compat failure, see GH#28507\n                        return False\n                    raise\n        return True\n\n    # NaNs can occur in float and complex arrays.\n    if is_float_dtype(left) or is_complex_dtype(left):\n\n        # empty\n        if not (np.prod(left.shape) and np.prod(right.shape)):\n            return True\n        return ((left == right) | (isna(left) & isna(right))).all()\n\n    elif needs_i8_conversion(left) or needs_i8_conversion(right):\n        # datetime64, timedelta64, Period\n        if not is_dtype_equal(left.dtype, right.dtype):\n            return False\n\n        left = left.view(\"i8\")\n        right = right.view(\"i8\")\n\n    # if we have structured dtypes, compare first\n    if left.dtype.type is np.void or right.dtype.type is np.void:\n        if left.dtype != right.dtype:\n            return False\n\n    return np.array_equal(left, right)",
        "begin_line": 395,
        "end_line": 481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.missing.na_value_for_dtype#514",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing.na_value_for_dtype(dtype, compat: bool=True)",
        "snippet": "def na_value_for_dtype(dtype, compat: bool = True):\n    \"\"\"\n    Return a dtype compat na value\n\n    Parameters\n    ----------\n    dtype : string / dtype\n    compat : bool, default True\n\n    Returns\n    -------\n    np.dtype or a pandas dtype\n\n    Examples\n    --------\n    >>> na_value_for_dtype(np.dtype('int64'))\n    0\n    >>> na_value_for_dtype(np.dtype('int64'), compat=False)\n    nan\n    >>> na_value_for_dtype(np.dtype('float64'))\n    nan\n    >>> na_value_for_dtype(np.dtype('bool'))\n    False\n    >>> na_value_for_dtype(np.dtype('datetime64[ns]'))\n    NaT\n    \"\"\"\n    dtype = pandas_dtype(dtype)\n\n    if is_extension_array_dtype(dtype):\n        return dtype.na_value\n    if (\n        is_datetime64_dtype(dtype)\n        or is_datetime64tz_dtype(dtype)\n        or is_timedelta64_dtype(dtype)\n        or is_period_dtype(dtype)\n    ):\n        return NaT\n    elif is_float_dtype(dtype):\n        return np.nan\n    elif is_integer_dtype(dtype):\n        if compat:\n            return 0\n        return np.nan\n    elif is_bool_dtype(dtype):\n        return False\n    return np.nan",
        "begin_line": 514,
        "end_line": 559,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.construction.arrays_to_mgr#52",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction.arrays_to_mgr(arrays, arr_names, index, columns, dtype=None)",
        "snippet": "def arrays_to_mgr(arrays, arr_names, index, columns, dtype=None):\n    \"\"\"\n    Segregate Series based on type and coerce into matrices.\n\n    Needs to handle a lot of exceptional cases.\n    \"\"\"\n    # figure out the index, if necessary\n    if index is None:\n        index = extract_index(arrays)\n    else:\n        index = ensure_index(index)\n\n    # don't force copy because getting jammed in an ndarray anyway\n    arrays = _homogenize(arrays, index, dtype)\n\n    # from BlockManager perspective\n    axes = [ensure_index(columns), index]\n\n    return create_block_manager_from_arrays(arrays, arr_names, axes)",
        "begin_line": 52,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.construction.init_dict#202",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction.init_dict(data, index, columns, dtype=None)",
        "snippet": "def init_dict(data, index, columns, dtype=None):\n    \"\"\"\n    Segregate Series based on type and coerce into matrices.\n    Needs to handle a lot of exceptional cases.\n    \"\"\"\n    if columns is not None:\n        from pandas.core.series import Series\n\n        arrays = Series(data, index=columns, dtype=object)\n        data_names = arrays.index\n\n        missing = arrays.isna()\n        if index is None:\n            # GH10856\n            # raise ValueError if only scalars in dict\n            index = extract_index(arrays[~missing])\n        else:\n            index = ensure_index(index)\n\n        # no obvious \"empty\" int column\n        if missing.any() and not is_integer_dtype(dtype):\n            if dtype is None or np.issubdtype(dtype, np.flexible):\n                # GH#1783\n                nan_dtype = object\n            else:\n                nan_dtype = dtype\n            val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype)\n            arrays.loc[missing] = [val] * missing.sum()\n\n    else:\n        keys = list(data.keys())\n        columns = data_names = Index(keys)\n        arrays = (com.maybe_iterable_to_list(data[k]) for k in keys)\n        # GH#24096 need copy to be deep for datetime64tz case\n        # TODO: See if we can avoid these copies\n        arrays = [\n            arr if not isinstance(arr, ABCIndexClass) else arr._data for arr in arrays\n        ]\n        arrays = [\n            arr if not is_datetime64tz_dtype(arr) else arr.copy() for arr in arrays\n        ]\n    return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)",
        "begin_line": 202,
        "end_line": 243,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.construction._homogenize#286",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction._homogenize(data, index, dtype=None)",
        "snippet": "def _homogenize(data, index, dtype=None):\n    oindex = None\n    homogenized = []\n\n    for val in data:\n        if isinstance(val, ABCSeries):\n            if dtype is not None:\n                val = val.astype(dtype)\n            if val.index is not index:\n                # Forces alignment. No need to copy data since we\n                # are putting it into an ndarray later\n                val = val.reindex(index, copy=False)\n        else:\n            if isinstance(val, dict):\n                if oindex is None:\n                    oindex = index.astype(\"O\")\n\n                if isinstance(index, (ABCDatetimeIndex, ABCTimedeltaIndex)):\n                    val = com.dict_compat(val)\n                else:\n                    val = dict(val)\n                val = lib.fast_multiget(val, oindex.values, default=np.nan)\n            val = sanitize_array(\n                val, index, dtype=dtype, copy=False, raise_cast_failure=False\n            )\n\n        homogenized.append(val)\n\n    return homogenized",
        "begin_line": 286,
        "end_line": 314,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.internals.construction.extract_index#317",
        "src_path": "pandas/core/internals/construction.py",
        "class_name": "pandas.core.internals.construction",
        "signature": "pandas.core.internals.construction.extract_index(data)",
        "snippet": "def extract_index(data):\n    index = None\n    if len(data) == 0:\n        index = Index([])\n    elif len(data) > 0:\n        raw_lengths = []\n        indexes = []\n\n        have_raw_arrays = False\n        have_series = False\n        have_dicts = False\n\n        for val in data:\n            if isinstance(val, ABCSeries):\n                have_series = True\n                indexes.append(val.index)\n            elif isinstance(val, dict):\n                have_dicts = True\n                indexes.append(list(val.keys()))\n            elif is_list_like(val) and getattr(val, \"ndim\", 1) == 1:\n                have_raw_arrays = True\n                raw_lengths.append(len(val))\n\n        if not indexes and not raw_lengths:\n            raise ValueError(\"If using all scalar values, you must pass an index\")\n\n        if have_series:\n            index = union_indexes(indexes)\n        elif have_dicts:\n            index = union_indexes(indexes, sort=False)\n\n        if have_raw_arrays:\n            lengths = list(set(raw_lengths))\n            if len(lengths) > 1:\n                raise ValueError(\"arrays must all be same length\")\n\n            if have_dicts:\n                raise ValueError(\n                    \"Mixing dicts with non-Series may lead to ambiguous ordering.\"\n                )\n\n            if have_series:\n                if lengths[0] != len(index):\n                    msg = (\n                        \"array length {length} does not match index \"\n                        \"length {idx_len}\".format(length=lengths[0], idx_len=len(index))\n                    )\n                    raise ValueError(msg)\n            else:\n                index = ibase.default_index(lengths[0])\n\n    return ensure_index(index)",
        "begin_line": 317,
        "end_line": 368,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.construction.extract_array#316",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction.extract_array(obj, extract_numpy=False)",
        "snippet": "def extract_array(obj, extract_numpy=False):\n    \"\"\"\n    Extract the ndarray or ExtensionArray from a Series or Index.\n\n    For all other types, `obj` is just returned as is.\n\n    Parameters\n    ----------\n    obj : object\n        For Series / Index, the underlying ExtensionArray is unboxed.\n        For Numpy-backed ExtensionArrays, the ndarray is extracted.\n\n    extract_numpy : bool, default False\n        Whether to extract the ndarray from a PandasArray\n\n    Returns\n    -------\n    arr : object\n\n    Examples\n    --------\n    >>> extract_array(pd.Series(['a', 'b', 'c'], dtype='category'))\n    [a, b, c]\n    Categories (3, object): [a, b, c]\n\n    Other objects like lists, arrays, and DataFrames are just passed through.\n\n    >>> extract_array([1, 2, 3])\n    [1, 2, 3]\n\n    For an ndarray-backed Series / Index a PandasArray is returned.\n\n    >>> extract_array(pd.Series([1, 2, 3]))\n    <PandasArray>\n    [1, 2, 3]\n    Length: 3, dtype: int64\n\n    To extract all the way down to the ndarray, pass ``extract_numpy=True``.\n\n    >>> extract_array(pd.Series([1, 2, 3]), extract_numpy=True)\n    array([1, 2, 3])\n    \"\"\"\n    if isinstance(obj, (ABCIndexClass, ABCSeries)):\n        obj = obj.array\n\n    if extract_numpy and isinstance(obj, ABCPandasArray):\n        obj = obj.to_numpy()\n\n    return obj",
        "begin_line": 316,
        "end_line": 364,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.construction.sanitize_array#367",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction.sanitize_array(data, index, dtype=None, copy: bool=False, raise_cast_failure: bool=False)",
        "snippet": "def sanitize_array(\n    data, index, dtype=None, copy: bool = False, raise_cast_failure: bool = False\n):\n    \"\"\"\n    Sanitize input data to an ndarray, copy if specified, coerce to the\n    dtype if specified.\n    \"\"\"\n    if dtype is not None:\n        dtype = pandas_dtype(dtype)\n\n    if isinstance(data, ma.MaskedArray):\n        mask = ma.getmaskarray(data)\n        if mask.any():\n            data, fill_value = maybe_upcast(data, copy=True)\n            data.soften_mask()  # set hardmask False if it was True\n            data[mask] = fill_value\n        else:\n            data = data.copy()\n\n    # extract ndarray or ExtensionArray, ensure we have no PandasArray\n    data = extract_array(data, extract_numpy=True)\n\n    # GH#846\n    if isinstance(data, np.ndarray):\n\n        if dtype is not None and is_float_dtype(data.dtype) and is_integer_dtype(dtype):\n            # possibility of nan -> garbage\n            try:\n                subarr = _try_cast(data, dtype, copy, True)\n            except ValueError:\n                if copy:\n                    subarr = data.copy()\n                else:\n                    subarr = np.array(data, copy=False)\n        else:\n            # we will try to copy be-definition here\n            subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n\n    elif isinstance(data, ABCExtensionArray):\n        # it is already ensured above this is not a PandasArray\n        subarr = data\n\n        if dtype is not None:\n            subarr = subarr.astype(dtype, copy=copy)\n        elif copy:\n            subarr = subarr.copy()\n        return subarr\n\n    elif isinstance(data, (list, tuple)) and len(data) > 0:\n        if dtype is not None:\n            subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n        else:\n            subarr = maybe_convert_platform(data)\n\n        subarr = maybe_cast_to_datetime(subarr, dtype)\n\n    elif isinstance(data, range):\n        # GH#16804\n        arr = np.arange(data.start, data.stop, data.step, dtype=\"int64\")\n        subarr = _try_cast(arr, dtype, copy, raise_cast_failure)\n    else:\n        subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n\n    # scalar like, GH\n    if getattr(subarr, \"ndim\", 0) == 0:\n        if isinstance(data, list):  # pragma: no cover\n            subarr = np.array(data, dtype=object)\n        elif index is not None:\n            value = data\n\n            # figure out the dtype from the value (upcast if necessary)\n            if dtype is None:\n                dtype, value = infer_dtype_from_scalar(value)\n            else:\n                # need to possibly convert the value here\n                value = maybe_cast_to_datetime(value, dtype)\n\n            subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype)\n\n        else:\n            return subarr.item()\n\n    # the result that we want\n    elif subarr.ndim == 1:\n        if index is not None:\n\n            # a 1-element ndarray\n            if len(subarr) != len(index) and len(subarr) == 1:\n                subarr = construct_1d_arraylike_from_scalar(\n                    subarr[0], len(index), subarr.dtype\n                )\n\n    elif subarr.ndim > 1:\n        if isinstance(data, np.ndarray):\n            raise Exception(\"Data must be 1-dimensional\")\n        else:\n            subarr = com.asarray_tuplesafe(data, dtype=dtype)\n\n    if not (is_extension_array_dtype(subarr.dtype) or is_extension_array_dtype(dtype)):\n        # This is to prevent mixed-type Series getting all casted to\n        # NumPy string type, e.g. NaN --> '-1#IND'.\n        if issubclass(subarr.dtype.type, str):\n            # GH#16605\n            # If not empty convert the data to dtype\n            # GH#19853: If data is a scalar, subarr has already the result\n            if not lib.is_scalar(data):\n                if not np.all(isna(data)):\n                    data = np.array(data, dtype=dtype, copy=False)\n                subarr = np.array(data, dtype=object, copy=copy)\n\n        if is_object_dtype(subarr.dtype) and not is_object_dtype(dtype):\n            inferred = lib.infer_dtype(subarr, skipna=False)\n            if inferred == \"period\":\n                from pandas.core.arrays import period_array\n\n                try:\n                    subarr = period_array(subarr)\n                except IncompatibleFrequency:\n                    pass\n\n    return subarr",
        "begin_line": 367,
        "end_line": 487,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.construction._try_cast#490",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction._try_cast(arr, dtype: Optional[Union[np.dtype, 'ExtensionDtype']], copy: bool, raise_cast_failure: bool)",
        "snippet": "def _try_cast(\n    arr,\n    dtype: Optional[Union[np.dtype, \"ExtensionDtype\"]],\n    copy: bool,\n    raise_cast_failure: bool,\n):\n    \"\"\"\n    Convert input to numpy ndarray and optionally cast to a given dtype.\n\n    Parameters\n    ----------\n    arr : ndarray, list, tuple, iterator (catchall)\n        Excludes: ExtensionArray, Series, Index.\n    dtype : np.dtype, ExtensionDtype or None\n    copy : bool\n        If False, don't copy the data if not needed.\n    raise_cast_failure : bool\n        If True, and if a dtype is specified, raise errors during casting.\n        Otherwise an object array is returned.\n    \"\"\"\n    # perf shortcut as this is the most common case\n    if isinstance(arr, np.ndarray):\n        if maybe_castable(arr) and not copy and dtype is None:\n            return arr\n\n    try:\n        # GH#15832: Check if we are requesting a numeric dype and\n        # that we can convert the data to the requested dtype.\n        if is_integer_dtype(dtype):\n            subarr = maybe_cast_to_integer_array(arr, dtype)\n\n        subarr = maybe_cast_to_datetime(arr, dtype)\n        # Take care in creating object arrays (but iterators are not\n        # supported):\n        if is_object_dtype(dtype) and (\n            is_list_like(subarr)\n            and not (is_iterator(subarr) or isinstance(subarr, np.ndarray))\n        ):\n            subarr = construct_1d_object_array_from_listlike(subarr)\n        elif not is_extension_array_dtype(subarr):\n            subarr = construct_1d_ndarray_preserving_na(subarr, dtype, copy=copy)\n    except OutOfBoundsDatetime:\n        # in case of out of bound datetime64 -> always raise\n        raise\n    except (ValueError, TypeError):\n        if is_categorical_dtype(dtype):\n            # We *do* allow casting to categorical, since we know\n            # that Categorical is the only array type for 'category'.\n            dtype = cast(CategoricalDtype, dtype)\n            subarr = dtype.construct_array_type()(\n                arr, dtype.categories, ordered=dtype._ordered\n            )\n        elif is_extension_array_dtype(dtype):\n            # create an extension array from its dtype\n            dtype = cast(ExtensionDtype, dtype)\n            array_type = dtype.construct_array_type()._from_sequence\n            subarr = array_type(arr, dtype=dtype, copy=copy)\n        elif dtype is not None and raise_cast_failure:\n            raise\n        else:\n            subarr = np.array(arr, dtype=object, copy=copy)\n    return subarr",
        "begin_line": 490,
        "end_line": 551,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexers.is_list_like_indexer#13",
        "src_path": "pandas/core/indexers.py",
        "class_name": "pandas.core.indexers",
        "signature": "pandas.core.indexers.is_list_like_indexer(key)",
        "snippet": "def is_list_like_indexer(key) -> bool:\n    \"\"\"\n    Check if we have a list-like indexer that is *not* a NamedTuple.\n\n    Parameters\n    ----------\n    key : object\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    # allow a list_like, but exclude NamedTuples which can be indexers\n    return is_list_like(key) and not (isinstance(key, tuple) and type(key) is not tuple)",
        "begin_line": 13,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexers.is_scalar_indexer#29",
        "src_path": "pandas/core/indexers.py",
        "class_name": "pandas.core.indexers",
        "signature": "pandas.core.indexers.is_scalar_indexer(indexer, arr_value)",
        "snippet": "def is_scalar_indexer(indexer, arr_value) -> bool:\n    # return True if we are all scalar indexers\n\n    if arr_value.ndim == 1:\n        if not isinstance(indexer, tuple):\n            indexer = tuple([indexer])\n            return any(isinstance(idx, np.ndarray) and len(idx) == 0 for idx in indexer)\n    return False",
        "begin_line": 29,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexers.is_empty_indexer#39",
        "src_path": "pandas/core/indexers.py",
        "class_name": "pandas.core.indexers",
        "signature": "pandas.core.indexers.is_empty_indexer(indexer, arr_value: np.ndarray)",
        "snippet": "def is_empty_indexer(indexer, arr_value: np.ndarray) -> bool:\n    \"\"\"\n    Check if we have an empty indexer.\n\n    Parameters\n    ----------\n    indexer : object\n    arr_value : np.ndarray\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    if is_list_like(indexer) and not len(indexer):\n        return True\n    if arr_value.ndim == 1:\n        if not isinstance(indexer, tuple):\n            indexer = tuple([indexer])\n        return any(isinstance(idx, np.ndarray) and len(idx) == 0 for idx in indexer)\n    return False",
        "begin_line": 39,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexers.check_setitem_lengths#65",
        "src_path": "pandas/core/indexers.py",
        "class_name": "pandas.core.indexers",
        "signature": "pandas.core.indexers.check_setitem_lengths(indexer, value, values)",
        "snippet": "def check_setitem_lengths(indexer, value, values) -> None:\n    \"\"\"\n    Validate that value and indexer are the same length.\n\n    An special-case is allowed for when the indexer is a boolean array\n    and the number of true values equals the length of ``value``. In\n    this case, no exception is raised.\n\n    Parameters\n    ----------\n    indexer : sequence\n        The key for the setitem\n    value : array-like\n        The value for the setitem\n    values : array-like\n        The values being set into\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        When the indexer is an ndarray or list and the lengths don't\n        match.\n    \"\"\"\n    # boolean with truth values == len of the value is ok too\n    if isinstance(indexer, (np.ndarray, list)):\n        if is_list_like(value) and len(indexer) != len(value):\n            if not (\n                isinstance(indexer, np.ndarray)\n                and indexer.dtype == np.bool_\n                and len(indexer[indexer]) == len(value)\n            ):\n                raise ValueError(\n                    \"cannot set using a list-like indexer \"\n                    \"with a different length than the value\"\n                )\n\n    elif isinstance(indexer, slice):\n        # slice\n        if is_list_like(value) and len(values):\n            if len(value) != length_of_indexer(indexer, values):\n                raise ValueError(\n                    \"cannot set using a slice indexer with a \"\n                    \"different length than the value\"\n                )",
        "begin_line": 65,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.printing.adjoin#25",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.adjoin(space: int, *lists: List[str], **kwargs)",
        "snippet": "def adjoin(space: int, *lists: List[str], **kwargs) -> str:\n    \"\"\"\n    Glues together two sets of strings using the amount of space requested.\n    The idea is to prettify.\n\n    ----------\n    space : int\n        number of spaces for padding\n    lists : str\n        list of str which being joined\n    strlen : callable\n        function used to calculate the length of each str. Needed for unicode\n        handling.\n    justfunc : callable\n        function used to justify str. Needed for unicode handling.\n    \"\"\"\n    strlen = kwargs.pop(\"strlen\", len)\n    justfunc = kwargs.pop(\"justfunc\", justify)\n\n    out_lines = []\n    newLists = []\n    lengths = [max(map(strlen, x)) + space for x in lists[:-1]]\n    # not the last one\n    lengths.append(max(map(len, lists[-1])))\n    maxLen = max(map(len, lists))\n    for i, lst in enumerate(lists):\n        nl = justfunc(lst, lengths[i], mode=\"left\")\n        nl.extend([\" \" * lengths[i]] * (maxLen - len(lst)))\n        newLists.append(nl)\n    toJoin = zip(*newLists)\n    for lines in toJoin:\n        out_lines.append(\"\".join(lines))\n    return \"\\n\".join(out_lines)",
        "begin_line": 25,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.printing.justify#60",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.justify(texts: Iterable[str], max_len: int, mode: str='right')",
        "snippet": "def justify(texts: Iterable[str], max_len: int, mode: str = \"right\") -> List[str]:\n    \"\"\"\n    Perform ljust, center, rjust against string or list-like\n    \"\"\"\n    if mode == \"left\":\n        return [x.ljust(max_len) for x in texts]\n    elif mode == \"center\":\n        return [x.center(max_len) for x in texts]\n    else:\n        return [x.rjust(max_len) for x in texts]",
        "begin_line": 60,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.printing.pprint_thing#162",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.pprint_thing(thing: Any, _nest_lvl: int=0, escape_chars: Optional[EscapeChars]=None, default_escapes: bool=False, quote_strings: bool=False, max_seq_items: Optional[int]=None)",
        "snippet": "def pprint_thing(\n    thing: Any,\n    _nest_lvl: int = 0,\n    escape_chars: Optional[EscapeChars] = None,\n    default_escapes: bool = False,\n    quote_strings: bool = False,\n    max_seq_items: Optional[int] = None,\n) -> str:\n    \"\"\"\n    This function is the sanctioned way of converting objects\n    to a string representation and properly handles nested sequences.\n\n    Parameters\n    ----------\n    thing : anything to be formatted\n    _nest_lvl : internal use only. pprint_thing() is mutually-recursive\n        with pprint_sequence, this argument is used to keep track of the\n        current nesting level, and limit it.\n    escape_chars : list or dict, optional\n        Characters to escape. If a dict is passed the values are the\n        replacements\n    default_escapes : bool, default False\n        Whether the input escape characters replaces or adds to the defaults\n    max_seq_items : False, int, default None\n        Pass thru to other pretty printers to limit sequence printing\n\n    Returns\n    -------\n    str\n\n    \"\"\"\n\n    def as_escaped_string(\n        thing: Any, escape_chars: Optional[EscapeChars] = escape_chars\n    ) -> str:\n        translate = {\"\\t\": r\"\\t\", \"\\n\": r\"\\n\", \"\\r\": r\"\\r\"}\n        if isinstance(escape_chars, dict):\n            if default_escapes:\n                translate.update(escape_chars)\n            else:\n                translate = escape_chars\n            escape_chars = list(escape_chars.keys())\n        else:\n            escape_chars = escape_chars or tuple()\n\n        result = str(thing)\n        for c in escape_chars:\n            result = result.replace(c, translate[c])\n        return result\n\n    if hasattr(thing, \"__next__\"):\n        return str(thing)\n    elif isinstance(thing, dict) and _nest_lvl < get_option(\n        \"display.pprint_nest_depth\"\n    ):\n        result = _pprint_dict(\n            thing, _nest_lvl, quote_strings=True, max_seq_items=max_seq_items\n        )\n    elif is_sequence(thing) and _nest_lvl < get_option(\"display.pprint_nest_depth\"):\n        result = _pprint_seq(\n            thing,\n            _nest_lvl,\n            escape_chars=escape_chars,\n            quote_strings=quote_strings,\n            max_seq_items=max_seq_items,\n        )\n    elif isinstance(thing, str) and quote_strings:\n        result = \"'{thing}'\".format(thing=as_escaped_string(thing))\n    else:\n        result = as_escaped_string(thing)\n\n    return result",
        "begin_line": 162,
        "end_line": 233,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.io.formats.printing.as_escaped_string#194",
        "src_path": "pandas/io/formats/printing.py",
        "class_name": "pandas.io.formats.printing",
        "signature": "pandas.io.formats.printing.as_escaped_string(thing: Any, escape_chars: Optional[EscapeChars]=escape_chars)",
        "snippet": "    def as_escaped_string(\n        thing: Any, escape_chars: Optional[EscapeChars] = escape_chars\n    ) -> str:\n        translate = {\"\\t\": r\"\\t\", \"\\n\": r\"\\n\", \"\\r\": r\"\\r\"}\n        if isinstance(escape_chars, dict):\n            if default_escapes:\n                translate.update(escape_chars)\n            else:\n                translate = escape_chars\n            escape_chars = list(escape_chars.keys())\n        else:\n            escape_chars = escape_chars or tuple()\n\n        result = str(thing)\n        for c in escape_chars:\n            result = result.replace(c, translate[c])\n        return result",
        "begin_line": 194,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.frame.DataFrame.__init__#403",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame.__init__(self, data=None, index: Optional[Axes]=None, columns: Optional[Axes]=None, dtype: Optional[Dtype]=None, copy: bool=False)",
        "snippet": "    def __init__(\n        self,\n        data=None,\n        index: Optional[Axes] = None,\n        columns: Optional[Axes] = None,\n        dtype: Optional[Dtype] = None,\n        copy: bool = False,\n    ):\n        if data is None:\n            data = {}\n        if dtype is not None:\n            dtype = self._validate_dtype(dtype)\n\n        if isinstance(data, DataFrame):\n            data = data._data\n\n        if isinstance(data, BlockManager):\n            mgr = self._init_mgr(\n                data, axes=dict(index=index, columns=columns), dtype=dtype, copy=copy\n            )\n        elif isinstance(data, dict):\n            mgr = init_dict(data, index, columns, dtype=dtype)\n        elif isinstance(data, ma.MaskedArray):\n            import numpy.ma.mrecords as mrecords\n\n            # masked recarray\n            if isinstance(data, mrecords.MaskedRecords):\n                mgr = masked_rec_array_to_mgr(data, index, columns, dtype, copy)\n\n            # a masked array\n            else:\n                mask = ma.getmaskarray(data)\n                if mask.any():\n                    data, fill_value = maybe_upcast(data, copy=True)\n                    data.soften_mask()  # set hardmask False if it was True\n                    data[mask] = fill_value\n                else:\n                    data = data.copy()\n                mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n\n        elif isinstance(data, (np.ndarray, Series, Index)):\n            if data.dtype.names:\n                data_columns = list(data.dtype.names)\n                data = {k: data[k] for k in data_columns}\n                if columns is None:\n                    columns = data_columns\n                mgr = init_dict(data, index, columns, dtype=dtype)\n            elif getattr(data, \"name\", None) is not None:\n                mgr = init_dict({data.name: data}, index, columns, dtype=dtype)\n            else:\n                mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n\n        # For data is list-like, or Iterable (will consume into list)\n        elif isinstance(data, abc.Iterable) and not isinstance(data, (str, bytes)):\n            if not isinstance(data, abc.Sequence):\n                data = list(data)\n            if len(data) > 0:\n                if is_list_like(data[0]) and getattr(data[0], \"ndim\", 1) == 1:\n                    if is_named_tuple(data[0]) and columns is None:\n                        columns = data[0]._fields\n                    arrays, columns = to_arrays(data, columns, dtype=dtype)\n                    columns = ensure_index(columns)\n\n                    # set the index\n                    if index is None:\n                        if isinstance(data[0], Series):\n                            index = get_names_from_index(data)\n                        elif isinstance(data[0], Categorical):\n                            index = ibase.default_index(len(data[0]))\n                        else:\n                            index = ibase.default_index(len(data))\n\n                    mgr = arrays_to_mgr(arrays, columns, index, columns, dtype=dtype)\n                else:\n                    mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n            else:\n                mgr = init_dict({}, index, columns, dtype=dtype)\n        else:\n            try:\n                arr = np.array(data, dtype=dtype, copy=copy)\n            except (ValueError, TypeError) as e:\n                exc = TypeError(\n                    \"DataFrame constructor called with \"\n                    \"incompatible data and dtype: {e}\".format(e=e)\n                )\n                raise exc from e\n\n            if arr.ndim == 0 and index is not None and columns is not None:\n                values = cast_scalar_to_array(\n                    (len(index), len(columns)), data, dtype=dtype\n                )\n                mgr = init_ndarray(\n                    values, index, columns, dtype=values.dtype, copy=False\n                )\n            else:\n                raise ValueError(\"DataFrame constructor not properly called!\")\n\n        NDFrame.__init__(self, mgr, fastpath=True)",
        "begin_line": 403,
        "end_line": 500,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.frame.DataFrame.axes#505",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame.axes(self)",
        "snippet": "    def axes(self) -> List[Index]:\n        \"\"\"\n        Return a list representing the axes of the DataFrame.\n\n        It has the row axis labels and column axis labels as the only members.\n        They are returned in that order.\n\n        Examples\n        --------\n        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n        >>> df.axes\n        [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\n        dtype='object')]\n        \"\"\"\n        return [self.index, self.columns]",
        "begin_line": 505,
        "end_line": 519,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.frame.DataFrame.shape#522",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame.shape(self)",
        "snippet": "    def shape(self) -> Tuple[int, int]:\n        \"\"\"\n        Return a tuple representing the dimensionality of the DataFrame.\n\n        See Also\n        --------\n        ndarray.shape\n\n        Examples\n        --------\n        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n        >>> df.shape\n        (2, 2)\n\n        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n        ...                    'col3': [5, 6]})\n        >>> df.shape\n        (2, 3)\n        \"\"\"\n        return len(self.index), len(self.columns)",
        "begin_line": 522,
        "end_line": 541,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.frame.DataFrame._ixs#2732",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame._ixs(self, i: int, axis: int=0)",
        "snippet": "    def _ixs(self, i: int, axis: int = 0):\n        \"\"\"\n        Parameters\n        ----------\n        i : int\n        axis : int\n\n        Notes\n        -----\n        If slice passed, the resulting data will be a view.\n        \"\"\"\n        # irow\n        if axis == 0:\n            label = self.index[i]\n            new_values = self._data.fast_xs(i)\n\n            # if we are a copy, mark as such\n            copy = isinstance(new_values, np.ndarray) and new_values.base is None\n            result = self._constructor_sliced(\n                new_values,\n                index=self.columns,\n                name=self.index[i],\n                dtype=new_values.dtype,\n            )\n            result._set_is_copy(self, copy=copy)\n            return result\n\n        # icol\n        else:\n            label = self.columns[i]\n\n            # if the values returned are not the same length\n            # as the index (iow a not found value), iget returns\n            # a 0-len ndarray. This is effectively catching\n            # a numpy error (as numpy should really raise)\n            values = self._data.iget(i)\n\n            if len(self.index) and not len(values):\n                values = np.array([np.nan] * len(self.index), dtype=object)\n            result = self._box_col_values(values, label)\n\n            # this is a cached value, mark it so\n            result._set_as_cached(label, self)\n\n            return result",
        "begin_line": 2732,
        "end_line": 2776,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.frame.DataFrame._box_col_values#3081",
        "src_path": "pandas/core/frame.py",
        "class_name": "pandas.core.frame.DataFrame",
        "signature": "pandas.core.frame.DataFrame._box_col_values(self, values, items)",
        "snippet": "    def _box_col_values(self, values, items):\n        \"\"\"\n        Provide boxed values for a column.\n        \"\"\"\n        klass = self._constructor_sliced\n        return klass(values, index=self.index, name=items, fastpath=True)",
        "begin_line": 3081,
        "end_line": 3086,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.__init__#202",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)",
        "snippet": "    def __init__(\n        self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False\n    ):\n\n        # we are called internally, so short-circuit\n        if fastpath:\n\n            # data is an ndarray, index is defined\n            if not isinstance(data, SingleBlockManager):\n                data = SingleBlockManager(data, index, fastpath=True)\n            if copy:\n                data = data.copy()\n            if index is None:\n                index = data.index\n\n        else:\n\n            if index is not None:\n                index = ensure_index(index)\n\n            if data is None:\n                data = {}\n            if dtype is not None:\n                # GH 26336: explicitly handle 'category' to avoid warning\n                # TODO: Remove after CategoricalDtype defaults to ordered=False\n                if (\n                    isinstance(dtype, str)\n                    and dtype == \"category\"\n                    and is_categorical(data)\n                ):\n                    dtype = data.dtype\n\n                dtype = self._validate_dtype(dtype)\n\n            if isinstance(data, MultiIndex):\n                raise NotImplementedError(\n                    \"initializing a Series from a MultiIndex is not supported\"\n                )\n            elif isinstance(data, Index):\n                if name is None:\n                    name = data.name\n\n                if dtype is not None:\n                    # astype copies\n                    data = data.astype(dtype)\n                else:\n                    # need to copy to avoid aliasing issues\n                    data = data._values.copy()\n                    if isinstance(data, ABCDatetimeIndex) and data.tz is not None:\n                        # GH#24096 need copy to be deep for datetime64tz case\n                        # TODO: See if we can avoid these copies\n                        data = data._values.copy(deep=True)\n                copy = False\n\n            elif isinstance(data, np.ndarray):\n                pass\n            elif isinstance(data, ABCSeries):\n                if name is None:\n                    name = data.name\n                if index is None:\n                    index = data.index\n                else:\n                    data = data.reindex(index, copy=copy)\n                data = data._data\n            elif isinstance(data, dict):\n                data, index = self._init_dict(data, index, dtype)\n                dtype = None\n                copy = False\n            elif isinstance(data, SingleBlockManager):\n                if index is None:\n                    index = data.index\n                elif not data.index.equals(index) or copy:\n                    # GH#19275 SingleBlockManager input should only be called\n                    # internally\n                    raise AssertionError(\n                        \"Cannot pass both SingleBlockManager \"\n                        \"`data` argument and a different \"\n                        \"`index` argument.  `copy` must \"\n                        \"be False.\"\n                    )\n\n            elif is_extension_array_dtype(data):\n                pass\n            elif isinstance(data, (set, frozenset)):\n                raise TypeError(\n                    \"{0!r} type is unordered\".format(data.__class__.__name__)\n                )\n            elif isinstance(data, ABCSparseArray):\n                # handle sparse passed here (and force conversion)\n                data = data.to_dense()\n            else:\n                data = com.maybe_iterable_to_list(data)\n\n            if index is None:\n                if not is_list_like(data):\n                    data = [data]\n                index = ibase.default_index(len(data))\n            elif is_list_like(data):\n\n                # a scalar numpy array is list-like but doesn't\n                # have a proper length\n                try:\n                    if len(index) != len(data):\n                        raise ValueError(\n                            \"Length of passed values is {val}, \"\n                            \"index implies {ind}\".format(val=len(data), ind=len(index))\n                        )\n                except TypeError:\n                    pass\n\n            # create/copy the manager\n            if isinstance(data, SingleBlockManager):\n                if dtype is not None:\n                    data = data.astype(dtype=dtype, errors=\"ignore\", copy=copy)\n                elif copy:\n                    data = data.copy()\n            else:\n                data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)\n\n                data = SingleBlockManager(data, index, fastpath=True)\n\n        generic.NDFrame.__init__(self, data, fastpath=True)\n        self.name = name\n        self._set_axis(0, index, fastpath=True)",
        "begin_line": 202,
        "end_line": 325,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._init_dict#327",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._init_dict(self, data, index=None, dtype=None)",
        "snippet": "    def _init_dict(self, data, index=None, dtype=None):\n        \"\"\"\n        Derive the \"_data\" and \"index\" attributes of a new Series from a\n        dictionary input.\n\n        Parameters\n        ----------\n        data : dict or dict-like\n            Data used to populate the new Series.\n        index : Index or index-like, default None\n            Index for the new Series: if None, use dict keys.\n        dtype : dtype, default None\n            The dtype for the new Series: if None, infer from data.\n\n        Returns\n        -------\n        _data : BlockManager for the new Series\n        index : index for the new Series\n        \"\"\"\n        # Looking for NaN in dict doesn't work ({np.nan : 1}[float('nan')]\n        # raises KeyError), so we iterate the entire dict, and align\n        if data:\n            keys, values = zip(*data.items())\n            values = list(values)\n        elif index is not None:\n            # fastpath for Series(data=None). Just use broadcasting a scalar\n            # instead of reindexing.\n            values = na_value_for_dtype(dtype)\n            keys = index\n        else:\n            keys, values = [], []\n\n        # Input is now list-like, so rely on \"standard\" construction:\n        s = Series(values, index=keys, dtype=dtype)\n\n        # Now we just make sure the order is respected, if any\n        if data and index is not None:\n            s = s.reindex(index, copy=False)\n        return s._data, s.index",
        "begin_line": 327,
        "end_line": 365,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._constructor#396",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._constructor(self)",
        "snippet": "    def _constructor(self):\n        return Series",
        "begin_line": 396,
        "end_line": 397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._constructor_expanddim#400",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._constructor_expanddim(self)",
        "snippet": "    def _constructor_expanddim(self):\n        from pandas.core.frame import DataFrame\n\n        return DataFrame",
        "begin_line": 400,
        "end_line": 403,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._set_axis#412",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._set_axis(self, axis, labels, fastpath=False)",
        "snippet": "    def _set_axis(self, axis, labels, fastpath=False):\n        \"\"\"\n        Override generic, we want to set the _typ here.\n        \"\"\"\n\n        if not fastpath:\n            labels = ensure_index(labels)\n\n        is_all_dates = labels.is_all_dates\n        if is_all_dates:\n            if not isinstance(labels, (DatetimeIndex, PeriodIndex, TimedeltaIndex)):\n                try:\n                    labels = DatetimeIndex(labels)\n                    # need to set here because we changed the index\n                    if fastpath:\n                        self._data.set_axis(axis, labels)\n                except (tslibs.OutOfBoundsDatetime, ValueError):\n                    # labels may exceeds datetime bounds,\n                    # or not be a DatetimeIndex\n                    pass\n\n        self._set_subtyp(is_all_dates)\n\n        object.__setattr__(self, \"_index\", labels)\n        if not fastpath:\n            self._data.set_axis(axis, labels)",
        "begin_line": 412,
        "end_line": 437,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._set_subtyp#439",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._set_subtyp(self, is_all_dates)",
        "snippet": "    def _set_subtyp(self, is_all_dates):\n        if is_all_dates:\n            object.__setattr__(self, \"_subtyp\", \"time_series\")\n        else:\n            object.__setattr__(self, \"_subtyp\", \"series\")",
        "begin_line": 439,
        "end_line": 443,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.dtype#451",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.dtype(self)",
        "snippet": "    def dtype(self):\n        \"\"\"\n        Return the dtype object of the underlying data.\n        \"\"\"\n        return self._data.dtype",
        "begin_line": 451,
        "end_line": 455,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.name#465",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.name(self)",
        "snippet": "    def name(self) -> Optional[Hashable]:\n        return self.attrs.get(\"name\", None)",
        "begin_line": 465,
        "end_line": 466,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.name#469",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.name(self, value: Optional[Hashable])",
        "snippet": "    def name(self, value: Optional[Hashable]) -> None:\n        if not is_hashable(value):\n            raise TypeError(\"Series.name must be a hashable type\")\n        self.attrs[\"name\"] = value",
        "begin_line": 469,
        "end_line": 472,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.values#511",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.values(self)",
        "snippet": "    def values(self):\n        \"\"\"\n        Return Series as ndarray or ndarray-like depending on the dtype.\n\n        .. warning::\n\n           We recommend using :attr:`Series.array` or\n           :meth:`Series.to_numpy`, depending on whether you need\n           a reference to the underlying data or a NumPy array.\n\n        Returns\n        -------\n        numpy.ndarray or ndarray-like\n\n        See Also\n        --------\n        Series.array : Reference to the underlying data.\n        Series.to_numpy : A NumPy array representing the underlying data.\n\n        Examples\n        --------\n        >>> pd.Series([1, 2, 3]).values\n        array([1, 2, 3])\n\n        >>> pd.Series(list('aabc')).values\n        array(['a', 'a', 'b', 'c'], dtype=object)\n\n        >>> pd.Series(list('aabc')).astype('category').values\n        [a, a, b, c]\n        Categories (3, object): [a, b, c]\n\n        Timezone aware datetime data is converted to UTC:\n\n        >>> pd.Series(pd.date_range('20130101', periods=3,\n        ...                         tz='US/Eastern')).values\n        array(['2013-01-01T05:00:00.000000000',\n               '2013-01-02T05:00:00.000000000',\n               '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n        \"\"\"\n        return self._data.external_values()",
        "begin_line": 511,
        "end_line": 550,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._values#553",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._values(self)",
        "snippet": "    def _values(self):\n        \"\"\"\n        Return the internal repr of this data.\n        \"\"\"\n        return self._data.internal_values()",
        "begin_line": 553,
        "end_line": 557,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._internal_get_values#579",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._internal_get_values(self)",
        "snippet": "    def _internal_get_values(self):\n        return self._data.get_values()",
        "begin_line": 579,
        "end_line": 580,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.__len__#706",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__len__(self)",
        "snippet": "    def __len__(self) -> int:\n        \"\"\"\n        Return the length of the Series.\n        \"\"\"\n        return len(self._data)",
        "begin_line": 706,
        "end_line": 710,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.__array__#870",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__array__(self, dtype=None)",
        "snippet": "    def __array__(self, dtype=None):\n        \"\"\"\n        Return the values as a NumPy array.\n\n        Users should not call this directly. Rather, it is invoked by\n        :func:`numpy.array` and :func:`numpy.asarray`.\n\n        Parameters\n        ----------\n        dtype : str or numpy.dtype, optional\n            The dtype to use for the resulting NumPy array. By default,\n            the dtype is inferred from the data.\n\n        Returns\n        -------\n        numpy.ndarray\n            The values in the series converted to a :class:`numpy.ndarary`\n            with the specified `dtype`.\n\n        See Also\n        --------\n        array : Create a new array from data.\n        Series.array : Zero-copy view to the array backing the Series.\n        Series.to_numpy : Series method for similar behavior.\n\n        Examples\n        --------\n        >>> ser = pd.Series([1, 2, 3])\n        >>> np.asarray(ser)\n        array([1, 2, 3])\n\n        For timezone-aware data, the timezones may be retained with\n        ``dtype='object'``\n\n        >>> tzser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n        >>> np.asarray(tzser, dtype=\"object\")\n        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET', freq='D'),\n               Timestamp('2000-01-02 00:00:00+0100', tz='CET', freq='D')],\n              dtype=object)\n\n        Or the values may be localized to UTC and the tzinfo discared with\n        ``dtype='datetime64[ns]'``\n\n        >>> np.asarray(tzser, dtype=\"datetime64[ns]\")  # doctest: +ELLIPSIS\n        array(['1999-12-31T23:00:00.000000000', ...],\n              dtype='datetime64[ns]')\n        \"\"\"\n        if (\n            dtype is None\n            and isinstance(self.array, ABCDatetimeArray)\n            and getattr(self.dtype, \"tz\", None)\n        ):\n            msg = (\n                \"Converting timezone-aware DatetimeArray to timezone-naive \"\n                \"ndarray with 'datetime64[ns]' dtype. In the future, this \"\n                \"will return an ndarray with 'object' dtype where each \"\n                \"element is a 'pandas.Timestamp' with the correct 'tz'.\\n\\t\"\n                \"To accept the future behavior, pass 'dtype=object'.\\n\\t\"\n                \"To keep the old behavior, pass 'dtype=\\\"datetime64[ns]\\\"'.\"\n            )\n            warnings.warn(msg, FutureWarning, stacklevel=3)\n            dtype = \"M8[ns]\"\n        return np.asarray(self.array, dtype)",
        "begin_line": 870,
        "end_line": 932,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.__getitem__#1075",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        key = com.apply_if_callable(key, self)\n        try:\n            result = self.index.get_value(self, key)\n\n            if not is_scalar(result):\n                if is_list_like(result) and not isinstance(result, Series):\n\n                    # we need to box if loc of the key isn't scalar here\n                    # otherwise have inline ndarray/lists\n                    try:\n                        if not is_scalar(self.index.get_loc(key)):\n                            result = self._constructor(\n                                result, index=[key] * len(result), dtype=self.dtype\n                            ).__finalize__(self)\n                    except KeyError:\n                        pass\n            return result\n        except InvalidIndexError:\n            pass\n        except (KeyError, ValueError):\n            if isinstance(key, tuple) and isinstance(self.index, MultiIndex):\n                # kludge\n                pass\n            elif key is Ellipsis:\n                return self\n            elif com.is_bool_indexer(key):\n                pass\n            else:\n\n                # we can try to coerce the indexer (or this will raise)\n                new_key = self.index._convert_scalar_indexer(key, kind=\"getitem\")\n                if type(new_key) != type(key):\n                    return self.__getitem__(new_key)\n                raise\n\n        if is_iterator(key):\n            key = list(key)\n\n        if com.is_bool_indexer(key):\n            key = check_bool_indexer(self.index, key)\n\n        return self._get_with(key)",
        "begin_line": 1075,
        "end_line": 1117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._get_with#1119",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._get_with(self, key)",
        "snippet": "    def _get_with(self, key):\n        # other: fancy integer or otherwise\n        if isinstance(key, slice):\n            return self._slice(key)\n        elif isinstance(key, ABCDataFrame):\n            raise TypeError(\n                \"Indexing a Series with DataFrame is not \"\n                \"supported, use the appropriate DataFrame column\"\n            )\n        elif isinstance(key, tuple):\n            try:\n                return self._get_values_tuple(key)\n            except ValueError:\n                # if we don't have a MultiIndex, we may still be able to handle\n                #  a 1-tuple.  see test_1tuple_without_multiindex\n                if len(key) == 1:\n                    key = key[0]\n                    if isinstance(key, slice):\n                        return self._get_values(key)\n                raise\n\n        if not isinstance(key, (list, np.ndarray, Series, Index)):\n            key = list(key)\n\n        if isinstance(key, Index):\n            key_type = key.inferred_type\n        else:\n            key_type = lib.infer_dtype(key, skipna=False)\n\n        if key_type == \"integer\":\n            if self.index.is_integer() or self.index.is_floating():\n                return self.loc[key]\n            else:\n                return self._get_values(key)\n        elif key_type == \"boolean\":\n            return self._get_values(key)\n\n        if isinstance(key, (list, tuple)):\n            # TODO: de-dup with tuple case handled above?\n            # handle the dup indexing case GH#4246\n            if len(key) == 1 and isinstance(key[0], slice):\n                # [slice(0, 5, None)] will break if you convert to ndarray,\n                # e.g. as requested by np.median\n                # FIXME: hack\n                return self._get_values(key)\n\n            return self.loc[key]\n\n        return self.reindex(key)",
        "begin_line": 1119,
        "end_line": 1167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._get_values#1183",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._get_values(self, indexer)",
        "snippet": "    def _get_values(self, indexer):\n        try:\n            return self._constructor(\n                self._data.get_slice(indexer), fastpath=True\n            ).__finalize__(self)\n        except ValueError:\n            # mpl compat if we look up e.g. ser[:, np.newaxis];\n            #  see tests.series.timeseries.test_mpl_compat_hack\n            return self._values[indexer]",
        "begin_line": 1183,
        "end_line": 1191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._is_mixed_type#1352",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._is_mixed_type(self)",
        "snippet": "    def _is_mixed_type(self):\n        return False",
        "begin_line": 1352,
        "end_line": 1353,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.__repr__#1549",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__repr__(self)",
        "snippet": "    def __repr__(self) -> str:\n        \"\"\"\n        Return a string representation for a particular Series.\n        \"\"\"\n        buf = StringIO(\"\")\n        width, height = get_terminal_size()\n        max_rows = (\n            height\n            if get_option(\"display.max_rows\") == 0\n            else get_option(\"display.max_rows\")\n        )\n        min_rows = (\n            height\n            if get_option(\"display.max_rows\") == 0\n            else get_option(\"display.min_rows\")\n        )\n        show_dimensions = get_option(\"display.show_dimensions\")\n\n        self.to_string(\n            buf=buf,\n            name=self.name,\n            dtype=self.dtype,\n            min_rows=min_rows,\n            max_rows=max_rows,\n            length=show_dimensions,\n        )\n        result = buf.getvalue()\n\n        return result",
        "begin_line": 1549,
        "end_line": 1577,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.to_string#1579",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None, min_rows=None)",
        "snippet": "    def to_string(\n        self,\n        buf=None,\n        na_rep=\"NaN\",\n        float_format=None,\n        header=True,\n        index=True,\n        length=False,\n        dtype=False,\n        name=False,\n        max_rows=None,\n        min_rows=None,\n    ):\n        \"\"\"\n        Render a string representation of the Series.\n\n        Parameters\n        ----------\n        buf : StringIO-like, optional\n            Buffer to write to.\n        na_rep : str, optional\n            String representation of NaN to use, default 'NaN'.\n        float_format : one-parameter function, optional\n            Formatter function to apply to columns' elements if they are\n            floats, default None.\n        header : bool, default True\n            Add the Series header (index name).\n        index : bool, optional\n            Add index (row) labels, default True.\n        length : bool, default False\n            Add the Series length.\n        dtype : bool, default False\n            Add the Series dtype.\n        name : bool, default False\n            Add the Series name if not None.\n        max_rows : int, optional\n            Maximum number of rows to show before truncating. If None, show\n            all.\n        min_rows : int, optional\n            The number of rows to display in a truncated repr (when number\n            of rows is above `max_rows`).\n\n        Returns\n        -------\n        str or None\n            String representation of Series if ``buf=None``, otherwise None.\n        \"\"\"\n\n        formatter = fmt.SeriesFormatter(\n            self,\n            name=name,\n            length=length,\n            header=header,\n            index=index,\n            dtype=dtype,\n            na_rep=na_rep,\n            float_format=float_format,\n            min_rows=min_rows,\n            max_rows=max_rows,\n        )\n        result = formatter.to_string()\n\n        # catch contract violations\n        if not isinstance(result, str):\n            raise AssertionError(\n                \"result must be of type unicode, type\"\n                \" of result is {0!r}\"\n                \"\".format(result.__class__.__name__)\n            )\n\n        if buf is None:\n            return result\n        else:\n            try:\n                buf.write(result)\n            except AttributeError:\n                with open(buf, \"w\") as f:\n                    f.write(result)",
        "begin_line": 1579,
        "end_line": 1656,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series._reduce#3966",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._reduce(self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds)",
        "snippet": "    def _reduce(\n        self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds\n    ):\n        \"\"\"\n        Perform a reduction operation.\n\n        If we have an ndarray as a value, then simply perform the operation,\n        otherwise delegate to the object.\n        \"\"\"\n\n        delegate = self._values\n\n        if axis is not None:\n            self._get_axis_number(axis)\n\n        if isinstance(delegate, Categorical):\n            # TODO deprecate numeric_only argument for Categorical and use\n            # skipna as well, see GH25303\n            return delegate._reduce(name, numeric_only=numeric_only, **kwds)\n        elif isinstance(delegate, ExtensionArray):\n            # dispatch to ExtensionArray interface\n            return delegate._reduce(name, skipna=skipna, **kwds)\n        elif is_datetime64_dtype(delegate):\n            # use DatetimeIndex implementation to handle skipna correctly\n            delegate = DatetimeIndex(delegate)\n        elif is_timedelta64_dtype(delegate) and hasattr(TimedeltaIndex, name):\n            # use TimedeltaIndex to handle skipna correctly\n            # TODO: remove hasattr check after TimedeltaIndex has `std` method\n            delegate = TimedeltaIndex(delegate)\n\n        # dispatch to numpy arrays\n        elif isinstance(delegate, np.ndarray):\n            if numeric_only:\n                raise NotImplementedError(\n                    \"Series.{0} does not implement numeric_only.\".format(name)\n                )\n            with np.errstate(all=\"ignore\"):\n                return op(delegate, skipna=skipna, **kwds)\n\n        # TODO(EA) dispatch to Index\n        # remove once all internals extension types are\n        # moved to ExtensionArrays\n        return delegate._reduce(\n            op=op,\n            name=name,\n            axis=axis,\n            skipna=skipna,\n            numeric_only=numeric_only,\n            filter_type=filter_type,\n            **kwds,\n        )",
        "begin_line": 3966,
        "end_line": 4016,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.fillna#4244",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)",
        "snippet": "    def fillna(\n        self,\n        value=None,\n        method=None,\n        axis=None,\n        inplace=False,\n        limit=None,\n        downcast=None,\n        **kwargs,\n    ):\n        return super().fillna(\n            value=value,\n            method=method,\n            axis=axis,\n            inplace=inplace,\n            limit=limit,\n            downcast=downcast,\n            **kwargs,\n        )",
        "begin_line": 4244,
        "end_line": 4262,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.series.Series.isna#4570",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.isna(self)",
        "snippet": "    def isna(self):\n        return super().isna()",
        "begin_line": 4570,
        "end_line": 4571,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__new__#261",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__new__(cls, data=None, dtype=None, copy=False, name=None, fastpath=None, tupleize_cols=True, **kwargs)",
        "snippet": "    def __new__(\n        cls,\n        data=None,\n        dtype=None,\n        copy=False,\n        name=None,\n        fastpath=None,\n        tupleize_cols=True,\n        **kwargs,\n    ) -> \"Index\":\n\n        from .range import RangeIndex\n        from pandas import PeriodIndex, DatetimeIndex, TimedeltaIndex\n        from .numeric import Float64Index, Int64Index, UInt64Index\n        from .interval import IntervalIndex\n        from .category import CategoricalIndex\n\n        if name is None and hasattr(data, \"name\"):\n            name = data.name\n\n        if fastpath is not None:\n            warnings.warn(\n                \"The 'fastpath' keyword is deprecated, and will be \"\n                \"removed in a future version.\",\n                FutureWarning,\n                stacklevel=2,\n            )\n            if fastpath:\n                return cls._simple_new(data, name)\n\n        if isinstance(data, ABCPandasArray):\n            # ensure users don't accidentally put a PandasArray in an index.\n            data = data.to_numpy()\n\n        # range\n        if isinstance(data, RangeIndex):\n            return RangeIndex(start=data, copy=copy, dtype=dtype, name=name)\n        elif isinstance(data, range):\n            return RangeIndex.from_range(data, dtype=dtype, name=name)\n\n        # categorical\n        elif is_categorical_dtype(data) or is_categorical_dtype(dtype):\n            return CategoricalIndex(data, dtype=dtype, copy=copy, name=name, **kwargs)\n\n        # interval\n        elif (\n            is_interval_dtype(data) or is_interval_dtype(dtype)\n        ) and not is_object_dtype(dtype):\n            closed = kwargs.get(\"closed\", None)\n            return IntervalIndex(data, dtype=dtype, name=name, copy=copy, closed=closed)\n\n        elif (\n            is_datetime64_any_dtype(data)\n            or is_datetime64_any_dtype(dtype)\n            or \"tz\" in kwargs\n        ):\n            if is_dtype_equal(_o_dtype, dtype):\n                # GH#23524 passing `dtype=object` to DatetimeIndex is invalid,\n                #  will raise in the where `data` is already tz-aware.  So\n                #  we leave it out of this step and cast to object-dtype after\n                #  the DatetimeIndex construction.\n                # Note we can pass copy=False because the .astype below\n                #  will always make a copy\n                result = DatetimeIndex(\n                    data, copy=False, name=name, **kwargs\n                )  # type: \"Index\"\n                return result.astype(object)\n            else:\n                return DatetimeIndex(data, copy=copy, name=name, dtype=dtype, **kwargs)\n\n        elif is_timedelta64_dtype(data) or is_timedelta64_dtype(dtype):\n            if is_dtype_equal(_o_dtype, dtype):\n                # Note we can pass copy=False because the .astype below\n                #  will always make a copy\n                result = TimedeltaIndex(data, copy=False, name=name, **kwargs)\n                return result.astype(object)\n            else:\n                return TimedeltaIndex(data, copy=copy, name=name, dtype=dtype, **kwargs)\n\n        elif is_period_dtype(data) and not is_object_dtype(dtype):\n            return PeriodIndex(data, copy=copy, name=name, **kwargs)\n\n        # extension dtype\n        elif is_extension_array_dtype(data) or is_extension_array_dtype(dtype):\n            data = np.asarray(data)\n            if not (dtype is None or is_object_dtype(dtype)):\n                # coerce to the provided dtype\n                ea_cls = dtype.construct_array_type()\n                data = ea_cls._from_sequence(data, dtype=dtype, copy=False)\n\n            # coerce to the object dtype\n            data = data.astype(object)\n            return Index(data, dtype=object, copy=copy, name=name, **kwargs)\n\n        # index-like\n        elif isinstance(data, (np.ndarray, Index, ABCSeries)):\n            if dtype is not None:\n                # we need to avoid having numpy coerce\n                # things that look like ints/floats to ints unless\n                # they are actually ints, e.g. '0' and 0.0\n                # should not be coerced\n                # GH 11836\n                if is_integer_dtype(dtype):\n                    inferred = lib.infer_dtype(data, skipna=False)\n                    if inferred == \"integer\":\n                        data = maybe_cast_to_integer_array(data, dtype, copy=copy)\n                    elif inferred in [\"floating\", \"mixed-integer-float\"]:\n                        if isna(data).any():\n                            raise ValueError(\"cannot convert float NaN to integer\")\n\n                        if inferred == \"mixed-integer-float\":\n                            data = maybe_cast_to_integer_array(data, dtype)\n\n                        # If we are actually all equal to integers,\n                        # then coerce to integer.\n                        try:\n                            return cls._try_convert_to_int_index(\n                                data, copy, name, dtype\n                            )\n                        except ValueError:\n                            pass\n\n                        # Return an actual float index.\n                        return Float64Index(data, copy=copy, dtype=dtype, name=name)\n\n                    elif inferred == \"string\":\n                        pass\n                    else:\n                        data = data.astype(dtype)\n                elif is_float_dtype(dtype):\n                    inferred = lib.infer_dtype(data, skipna=False)\n                    if inferred == \"string\":\n                        pass\n                    else:\n                        data = data.astype(dtype)\n                else:\n                    data = np.array(data, dtype=dtype, copy=copy)\n\n            # maybe coerce to a sub-class\n            if is_signed_integer_dtype(data.dtype):\n                return Int64Index(data, copy=copy, dtype=dtype, name=name)\n            elif is_unsigned_integer_dtype(data.dtype):\n                return UInt64Index(data, copy=copy, dtype=dtype, name=name)\n            elif is_float_dtype(data.dtype):\n                return Float64Index(data, copy=copy, dtype=dtype, name=name)\n            elif issubclass(data.dtype.type, np.bool) or is_bool_dtype(data):\n                subarr = data.astype(\"object\")\n            else:\n                subarr = com.asarray_tuplesafe(data, dtype=object)\n\n            # asarray_tuplesafe does not always copy underlying data,\n            # so need to make sure that this happens\n            if copy:\n                subarr = subarr.copy()\n\n            if dtype is None:\n                inferred = lib.infer_dtype(subarr, skipna=False)\n                if inferred == \"integer\":\n                    try:\n                        return cls._try_convert_to_int_index(subarr, copy, name, dtype)\n                    except ValueError:\n                        pass\n\n                    return Index(subarr, copy=copy, dtype=object, name=name)\n                elif inferred in [\"floating\", \"mixed-integer-float\", \"integer-na\"]:\n                    # TODO: Returns IntegerArray for integer-na case in the future\n                    return Float64Index(subarr, copy=copy, name=name)\n                elif inferred == \"interval\":\n                    try:\n                        return IntervalIndex(subarr, name=name, copy=copy)\n                    except ValueError:\n                        # GH27172: mixed closed Intervals --> object dtype\n                        pass\n                elif inferred == \"boolean\":\n                    # don't support boolean explicitly ATM\n                    pass\n                elif inferred != \"string\":\n                    if inferred.startswith(\"datetime\"):\n                        try:\n                            return DatetimeIndex(subarr, copy=copy, name=name, **kwargs)\n                        except (ValueError, OutOfBoundsDatetime):\n                            # GH 27011\n                            # If we have mixed timezones, just send it\n                            # down the base constructor\n                            pass\n\n                    elif inferred.startswith(\"timedelta\"):\n                        return TimedeltaIndex(subarr, copy=copy, name=name, **kwargs)\n                    elif inferred == \"period\":\n                        try:\n                            return PeriodIndex(subarr, name=name, **kwargs)\n                        except IncompatibleFrequency:\n                            pass\n            if kwargs:\n                raise TypeError(f\"Unexpected keyword arguments {set(kwargs)!r}\")\n            return cls._simple_new(subarr, name, **kwargs)\n\n        elif hasattr(data, \"__array__\"):\n            return Index(np.asarray(data), dtype=dtype, copy=copy, name=name, **kwargs)\n        elif data is None or is_scalar(data):\n            raise cls._scalar_data_error(data)\n        else:\n            if tupleize_cols and is_list_like(data):\n                # GH21470: convert iterable to list before determining if empty\n                if is_iterator(data):\n                    data = list(data)\n\n                if data and all(isinstance(e, tuple) for e in data):\n                    # we must be all tuples, otherwise don't construct\n                    # 10697\n                    from .multi import MultiIndex\n\n                    return MultiIndex.from_tuples(\n                        data, names=name or kwargs.get(\"names\")\n                    )\n            # other iterable of some kind\n            subarr = com.asarray_tuplesafe(data, dtype=object)\n            return Index(subarr, dtype=dtype, copy=copy, name=name, **kwargs)",
        "begin_line": 261,
        "end_line": 478,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._simple_new#512",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._simple_new(cls, values, name=None, dtype=None)",
        "snippet": "    def _simple_new(cls, values, name=None, dtype=None):\n        \"\"\"\n        We require that we have a dtype compat for the values. If we are passed\n        a non-dtype compat, then coerce using the constructor.\n\n        Must be careful not to recurse.\n        \"\"\"\n        if isinstance(values, (ABCSeries, ABCIndexClass)):\n            # Index._data must always be an ndarray.\n            # This is no-copy for when _values is an ndarray,\n            # which should be always at this point.\n            values = np.asarray(values._values)\n\n        result = object.__new__(cls)\n        result._data = values\n        # _index_data is a (temporary?) fix to ensure that the direct data\n        # manipulation we do in `_libs/reduction.pyx` continues to work.\n        # We need access to the actual ndarray, since we're messing with\n        # data buffers and strides. We don't re-use `_ndarray_values`, since\n        # we actually set this value too.\n        result._index_data = values\n        result.name = name\n\n        return result._reset_identity()",
        "begin_line": 512,
        "end_line": 535,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._get_attributes_dict#544",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._get_attributes_dict(self)",
        "snippet": "    def _get_attributes_dict(self):\n        \"\"\"\n        Return an attributes dict for my class.\n        \"\"\"\n        return {k: getattr(self, k, None) for k in self._attributes}",
        "begin_line": 544,
        "end_line": 548,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._shallow_copy_with_infer#583",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._shallow_copy_with_infer(self, values, **kwargs)",
        "snippet": "    def _shallow_copy_with_infer(self, values, **kwargs):\n        \"\"\"\n        Create a new Index inferring the class with passed value, don't copy\n        the data, use the same object attributes with passed in attributes\n        taking precedence.\n\n        *this is an internal non-public method*\n\n        Parameters\n        ----------\n        values : the values to create the new Index, optional\n        kwargs : updates the default attributes for this Index\n        \"\"\"\n        attributes = self._get_attributes_dict()\n        attributes.update(kwargs)\n        attributes[\"copy\"] = False\n        if not len(values) and \"dtype\" not in kwargs:\n            attributes[\"dtype\"] = self.dtype\n        if self._infer_as_myclass:\n            try:\n                return self._constructor(values, **attributes)\n            except (TypeError, ValueError):\n                pass\n        return Index(values, **attributes)",
        "begin_line": 583,
        "end_line": 606,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_#612",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_(self, other)",
        "snippet": "    def is_(self, other) -> bool:\n        \"\"\"\n        More flexible, faster check like ``is`` but that works through views.\n\n        Note: this is *not* the same as ``Index.identical()``, which checks\n        that metadata is also the same.\n\n        Parameters\n        ----------\n        other : object\n            other object to compare against.\n\n        Returns\n        -------\n        True if both have same underlying data, False otherwise : bool\n        \"\"\"\n        # use something other than None to be clearer\n        return self._id is getattr(other, \"_id\", Ellipsis) and self._id is not None",
        "begin_line": 612,
        "end_line": 629,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._reset_identity#631",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._reset_identity(self)",
        "snippet": "    def _reset_identity(self):\n        \"\"\"\n        Initializes or resets ``_id`` attribute with new object.\n        \"\"\"\n        self._id = _Identity()\n        return self",
        "begin_line": 631,
        "end_line": 636,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._engine#642",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._engine(self)",
        "snippet": "    def _engine(self):\n        # property, for now, slow to look up\n\n        # to avoid a reference cycle, bind `_ndarray_values` to a local variable, so\n        # `self` is not passed into the lambda.\n        _ndarray_values = self._ndarray_values\n        return self._engine_type(lambda: _ndarray_values, len(self))",
        "begin_line": 642,
        "end_line": 648,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__len__#654",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__len__(self)",
        "snippet": "    def __len__(self) -> int:\n        \"\"\"\n        Return the length of the Index.\n        \"\"\"\n        return len(self._data)",
        "begin_line": 654,
        "end_line": 658,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.dtype#678",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.dtype(self)",
        "snippet": "    def dtype(self):\n        \"\"\"\n        Return the dtype object of the underlying data.\n        \"\"\"\n        return self._data.dtype",
        "begin_line": 678,
        "end_line": 682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.format#1021",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.format(self, name=False, formatter=None, **kwargs)",
        "snippet": "    def format(self, name=False, formatter=None, **kwargs):\n        \"\"\"\n        Render a string representation of the Index.\n        \"\"\"\n        header = []\n        if name:\n            header.append(\n                pprint_thing(self.name, escape_chars=(\"\\t\", \"\\r\", \"\\n\"))\n                if self.name is not None\n                else \"\"\n            )\n\n        if formatter is not None:\n            return header + list(self.map(formatter))\n\n        return self._format_with_header(header, **kwargs)",
        "begin_line": 1021,
        "end_line": 1036,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._format_with_header#1038",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._format_with_header(self, header, na_rep='NaN', **kwargs)",
        "snippet": "    def _format_with_header(self, header, na_rep=\"NaN\", **kwargs):\n        values = self.values\n\n        from pandas.io.formats.format import format_array\n\n        if is_categorical_dtype(values.dtype):\n            values = np.array(values)\n\n        elif is_object_dtype(values.dtype):\n            values = lib.maybe_convert_objects(values, safe=1)\n\n        if is_object_dtype(values.dtype):\n            result = [pprint_thing(x, escape_chars=(\"\\t\", \"\\r\", \"\\n\")) for x in values]\n\n            # could have nans\n            mask = isna(values)\n            if mask.any():\n                result = np.array(result)\n                result[mask] = na_rep\n                result = result.tolist()\n\n        else:\n            result = _trim_front(format_array(values, None, justify=\"left\"))\n        return header + result",
        "begin_line": 1038,
        "end_line": 1061,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._get_names#1285",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._get_names(self)",
        "snippet": "    def _get_names(self):\n        return FrozenList((self.name,))",
        "begin_line": 1285,
        "end_line": 1286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.nlevels#1455",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.nlevels(self)",
        "snippet": "    def nlevels(self) -> int:\n        \"\"\"\n        Number of levels.\n        \"\"\"\n        return 1",
        "begin_line": 1455,
        "end_line": 1459,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_integer#1744",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_integer(self)",
        "snippet": "    def is_integer(self) -> bool:\n        return self.inferred_type in [\"integer\"]",
        "begin_line": 1744,
        "end_line": 1745,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_object#1753",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_object(self)",
        "snippet": "    def is_object(self) -> bool:\n        return is_object_dtype(self.dtype)",
        "begin_line": 1753,
        "end_line": 1754,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_categorical#1756",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_categorical(self)",
        "snippet": "    def is_categorical(self) -> bool:\n        \"\"\"\n        Check if the Index holds categorical data.\n\n        Returns\n        -------\n        boolean\n            True if the Index is categorical.\n\n        See Also\n        --------\n        CategoricalIndex : Index for categorical data.\n\n        Examples\n        --------\n        >>> idx = pd.Index([\"Watermelon\", \"Orange\", \"Apple\",\n        ...                 \"Watermelon\"]).astype(\"category\")\n        >>> idx.is_categorical()\n        True\n\n        >>> idx = pd.Index([1, 3, 5, 7])\n        >>> idx.is_categorical()\n        False\n\n        >>> s = pd.Series([\"Peter\", \"Victor\", \"Elisabeth\", \"Mar\"])\n        >>> s\n        0        Peter\n        1       Victor\n        2    Elisabeth\n        3          Mar\n        dtype: object\n        >>> s.index.is_categorical()\n        False\n        \"\"\"\n        return self.inferred_type in [\"categorical\"]",
        "begin_line": 1756,
        "end_line": 1790,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.inferred_type#1805",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.inferred_type(self)",
        "snippet": "    def inferred_type(self):\n        \"\"\"\n        Return a string of the type inferred from the values.\n        \"\"\"\n        return lib.infer_dtype(self, skipna=False)",
        "begin_line": 1805,
        "end_line": 1809,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.is_all_dates#1812",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.is_all_dates(self)",
        "snippet": "    def is_all_dates(self) -> bool:\n        return is_datetime_array(ensure_object(self.values))",
        "begin_line": 1812,
        "end_line": 1813,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.get_loc#2817",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.get_loc(self, key, method=None, tolerance=None)",
        "snippet": "    def get_loc(self, key, method=None, tolerance=None):\n        if method is None:\n            if tolerance is not None:\n                raise ValueError(\n                    \"tolerance argument only valid if using pad, \"\n                    \"backfill or nearest lookups\"\n                )\n            try:\n                return self._engine.get_loc(key)\n            except KeyError:\n                return self._engine.get_loc(self._maybe_cast_indexer(key))\n        indexer = self.get_indexer([key], method=method, tolerance=tolerance)\n        if indexer.ndim > 1 or indexer.size > 1:\n            raise TypeError(\"get_loc requires scalar valued input\")\n        loc = indexer.item()\n        if loc == -1:\n            raise KeyError(key)\n        return loc",
        "begin_line": 2817,
        "end_line": 2834,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._convert_scalar_indexer#3033",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._convert_scalar_indexer(self, key, kind=None)",
        "snippet": "    def _convert_scalar_indexer(self, key, kind=None):\n        assert kind in [\"ix\", \"loc\", \"getitem\", \"iloc\", None]\n\n        if kind == \"iloc\":\n            return self._validate_indexer(\"positional\", key, kind)\n\n        if len(self) and not isinstance(self, ABCMultiIndex):\n\n            # we can raise here if we are definitive that this\n            # is positional indexing (eg. .ix on with a float)\n            # or label indexing if we are using a type able\n            # to be represented in the index\n\n            if kind in [\"getitem\", \"ix\"] and is_float(key):\n                if not self.is_floating():\n                    return self._invalid_indexer(\"label\", key)\n\n            elif kind in [\"loc\"] and is_float(key):\n\n                # we want to raise KeyError on string/mixed here\n                # technically we *could* raise a TypeError\n                # on anything but mixed though\n                if self.inferred_type not in [\n                    \"floating\",\n                    \"mixed-integer-float\",\n                    \"integer-na\",\n                    \"string\",\n                    \"unicode\",\n                    \"mixed\",\n                ]:\n                    return self._invalid_indexer(\"label\", key)\n\n            elif kind in [\"loc\"] and is_integer(key):\n                if not self.holds_integer():\n                    return self._invalid_indexer(\"label\", key)\n\n        return key",
        "begin_line": 3033,
        "end_line": 3069,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.values#3814",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.values(self)",
        "snippet": "    def values(self):\n        \"\"\"\n        Return an array representing the data in the Index.\n\n        .. warning::\n\n           We recommend using :attr:`Index.array` or\n           :meth:`Index.to_numpy`, depending on whether you need\n           a reference to the underlying data or a NumPy array.\n\n        Returns\n        -------\n        array: numpy.ndarray or ExtensionArray\n\n        See Also\n        --------\n        Index.array : Reference to the underlying data.\n        Index.to_numpy : A NumPy array representing the underlying data.\n        \"\"\"\n        return self._data.view(np.ndarray)",
        "begin_line": 3814,
        "end_line": 3833,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._values#3836",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._values(self)",
        "snippet": "    def _values(self) -> Union[ExtensionArray, ABCIndexClass, np.ndarray]:\n        # TODO(EA): remove index types as they become extension arrays\n        \"\"\"\n        The best array representation.\n\n        This is an ndarray, ExtensionArray, or Index subclass. This differs\n        from ``_ndarray_values``, which always returns an ndarray.\n\n        Both ``_values`` and ``_ndarray_values`` are consistent between\n        ``Series`` and ``Index``.\n\n        It may differ from the public '.values' method.\n\n        index             | values          | _values       | _ndarray_values |\n        ----------------- | --------------- | ------------- | --------------- |\n        Index             | ndarray         | ndarray       | ndarray         |\n        CategoricalIndex  | Categorical     | Categorical   | ndarray[int]    |\n        DatetimeIndex     | ndarray[M8ns]   | ndarray[M8ns] | ndarray[M8ns]   |\n        DatetimeIndex[tz] | ndarray[M8ns]   | DTI[tz]       | ndarray[M8ns]   |\n        PeriodIndex       | ndarray[object] | PeriodArray   | ndarray[int]    |\n        IntervalIndex     | IntervalArray   | IntervalArray | ndarray[object] |\n\n        See Also\n        --------\n        values\n        _ndarray_values\n        \"\"\"\n        return self._data",
        "begin_line": 3836,
        "end_line": 3863,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._internal_get_values#3918",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._internal_get_values(self)",
        "snippet": "    def _internal_get_values(self):\n        return self.values",
        "begin_line": 3918,
        "end_line": 3919,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.__getitem__#4145",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        \"\"\"\n        Override numpy.ndarray's __getitem__ method to work as desired.\n\n        This function adds lists and Series as valid boolean indexers\n        (ndarrays only supports ndarray with dtype=bool).\n\n        If resulting ndim != 1, plain ndarray is returned instead of\n        corresponding `Index` subclass.\n\n        \"\"\"\n        # There's no custom logic to be implemented in __getslice__, so it's\n        # not overloaded intentionally.\n        getitem = self._data.__getitem__\n        promote = self._shallow_copy\n\n        if is_scalar(key):\n            key = com.cast_scalar_indexer(key)\n            return getitem(key)\n\n        if isinstance(key, slice):\n            # This case is separated from the conditional above to avoid\n            # pessimization of basic indexing.\n            return promote(getitem(key))\n\n        if com.is_bool_indexer(key):\n            key = np.asarray(key, dtype=bool)\n\n        key = com.values_from_object(key)\n        result = getitem(key)\n        if not is_scalar(result):\n            return promote(result)\n        else:\n            return result",
        "begin_line": 4145,
        "end_line": 4178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._can_hold_identifiers_and_holds_name#4180",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._can_hold_identifiers_and_holds_name(self, name)",
        "snippet": "    def _can_hold_identifiers_and_holds_name(self, name) -> bool:\n        \"\"\"\n        Faster check for ``name in self`` when we know `name` is a Python\n        identifier (e.g. in NDFrame.__getattr__, which hits this to support\n        . key lookup). For indexes that can't hold identifiers (everything\n        but object & categorical) we just return False.\n\n        https://github.com/pandas-dev/pandas/issues/19764\n        \"\"\"\n        if self.is_object() or self.is_categorical():\n            return name in self\n        return False",
        "begin_line": 4180,
        "end_line": 4191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.equals#4277",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.equals(self, other)",
        "snippet": "    def equals(self, other) -> bool:\n        \"\"\"\n        Determine if two Index objects contain the same elements.\n\n        Returns\n        -------\n        bool\n            True if \"other\" is an Index and it has the same elements as calling\n            index; False otherwise.\n        \"\"\"\n        if self.is_(other):\n            return True\n\n        if not isinstance(other, Index):\n            return False\n\n        if is_object_dtype(self) and not is_object_dtype(other):\n            # if other is not object, use other's logic for coercion\n            return other.equals(self)\n\n        return array_equivalent(\n            com.values_from_object(self), com.values_from_object(other)\n        )",
        "begin_line": 4277,
        "end_line": 4299,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.get_value#4598",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.get_value(self, series, key)",
        "snippet": "    def get_value(self, series, key):\n\n        # if we have something that is Index-like, then\n        # use this, e.g. DatetimeIndex\n        # Things like `Series._get_value` (via .at) pass the EA directly here.\n        s = getattr(series, \"_values\", series)\n        if isinstance(s, (ExtensionArray, Index)) and is_scalar(key):\n            # GH 20882, 21257\n            # Unify Index and ExtensionArray treatment\n            # First try to convert the key to a location\n            # If that fails, raise a KeyError if an integer\n            # index, otherwise, see if key is an integer, and\n            # try that\n            try:\n                iloc = self.get_loc(key)\n                return s[iloc]\n            except KeyError:\n                if len(self) > 0 and (self.holds_integer() or self.is_boolean()):\n                    raise\n                elif is_integer(key):\n                    return s[key]\n\n        s = com.values_from_object(series)\n        k = com.values_from_object(key)\n\n        k = self._convert_scalar_indexer(k, kind=\"getitem\")\n        try:\n            return self._engine.get_value(s, k, tz=getattr(series.dtype, \"tz\", None))\n        except KeyError as e1:\n            if len(self) > 0 and (self.holds_integer() or self.is_boolean()):\n                raise\n\n            try:\n                return libindex.get_value_at(s, key)\n            except IndexError:\n                raise\n            except TypeError:\n                # generator/iterator-like\n                if is_iterator(key):\n                    raise InvalidIndexError(key)\n                else:\n                    raise e1\n            except Exception:\n                raise e1\n        except TypeError:\n            # e.g. \"[False] is an invalid key\"\n            if is_scalar(key):\n                raise IndexError(key)\n            raise InvalidIndexError(key)",
        "begin_line": 4598,
        "end_line": 4646,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._maybe_cast_indexer#4943",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._maybe_cast_indexer(self, key)",
        "snippet": "    def _maybe_cast_indexer(self, key):\n        \"\"\"\n        If we have a float key and are not a floating index, then try to cast\n        to an int if equivalent.\n        \"\"\"\n\n        if is_float(key) and not self.is_floating():\n            try:\n                ckey = int(key)\n                if ckey == key:\n                    key = ckey\n            except (OverflowError, ValueError, TypeError):\n                pass\n        return key",
        "begin_line": 4943,
        "end_line": 4956,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base.ensure_index#5514",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base.ensure_index(index_like, copy=False)",
        "snippet": "def ensure_index(index_like, copy=False):\n    \"\"\"\n    Ensure that we have an index from some index-like object.\n\n    Parameters\n    ----------\n    index : sequence\n        An Index or other sequence\n    copy : bool\n\n    Returns\n    -------\n    index : Index or MultiIndex\n\n    Examples\n    --------\n    >>> ensure_index(['a', 'b'])\n    Index(['a', 'b'], dtype='object')\n\n    >>> ensure_index([('a', 'a'),  ('b', 'c')])\n    Index([('a', 'a'), ('b', 'c')], dtype='object')\n\n    >>> ensure_index([['a', 'a'], ['b', 'c']])\n    MultiIndex([('a', 'b'),\n                ('a', 'c')],\n               dtype='object')\n               )\n\n    See Also\n    --------\n    ensure_index_from_sequences\n    \"\"\"\n    if isinstance(index_like, Index):\n        if copy:\n            index_like = index_like.copy()\n        return index_like\n    if hasattr(index_like, \"name\"):\n        return Index(index_like, name=index_like.name, copy=copy)\n\n    if is_iterator(index_like):\n        index_like = list(index_like)\n\n    # must check for exactly list here because of strict type\n    # check in clean_index_list\n    if isinstance(index_like, list):\n        if type(index_like) != list:\n            index_like = list(index_like)\n\n        converted, all_arrays = lib.clean_index_list(index_like)\n\n        if len(converted) > 0 and all_arrays:\n            from .multi import MultiIndex\n\n            return MultiIndex.from_arrays(converted)\n        else:\n            index_like = converted\n    else:\n        # clean_index_list does the equivalent of copying\n        # so only need to do this if not list instance\n        if copy:\n            from copy import copy\n\n            index_like = copy(index_like)\n\n    return Index(index_like)",
        "begin_line": 5514,
        "end_line": 5578,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexes.base._trim_front#5593",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base._trim_front(strings)",
        "snippet": "def _trim_front(strings):\n    \"\"\"\n    Trims zeros and decimal points.\n    \"\"\"\n    trimmed = strings\n    while len(strings) > 0 and all(x[0] == \" \" for x in trimmed):\n        trimmed = [x[1:] for x in trimmed]\n    return trimmed",
        "begin_line": 5593,
        "end_line": 5600,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.generic.create_pandas_abc_type#6",
        "src_path": "pandas/core/dtypes/generic.py",
        "class_name": "pandas.core.dtypes.generic",
        "signature": "pandas.core.dtypes.generic.create_pandas_abc_type(name, attr, comp)",
        "snippet": "def create_pandas_abc_type(name, attr, comp):\n    @classmethod\n    def _check(cls, inst) -> bool:\n        return getattr(inst, attr, \"_typ\") in comp\n\n    dct = dict(__instancecheck__=_check, __subclasscheck__=_check)\n    meta = type(\"ABCBase\", (type,), dct)\n    return meta(name, tuple(), dct)",
        "begin_line": 6,
        "end_line": 13,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.dtypes.generic._check#8",
        "src_path": "pandas/core/dtypes/generic.py",
        "class_name": "pandas.core.dtypes.generic",
        "signature": "pandas.core.dtypes.generic._check(cls, inst)",
        "snippet": "    def _check(cls, inst) -> bool:\n        return getattr(inst, attr, \"_typ\") in comp",
        "begin_line": 8,
        "end_line": 9,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._get_loc#162",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._get_loc(self, key: int, axis: int)",
        "snippet": "    def _get_loc(self, key: int, axis: int):\n        return self.obj._ixs(key, axis=axis)",
        "begin_line": 162,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._get_setitem_indexer#168",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._get_setitem_indexer(self, key)",
        "snippet": "    def _get_setitem_indexer(self, key):\n        if self.axis is not None:\n            return self._convert_tuple(key)\n\n        ax = self.obj._get_axis(0)\n\n        if isinstance(ax, ABCMultiIndex) and self.name != \"iloc\":\n            try:\n                return ax.get_loc(key)\n            except (TypeError, KeyError):\n                # TypeError e.g. passed a bool\n                pass\n\n        if isinstance(key, tuple):\n            try:\n                return self._convert_tuple(key)\n            except IndexingError:\n                pass\n\n        if isinstance(key, range):\n            return list(key)\n\n        axis = self.axis or 0\n        try:\n            return self._convert_to_indexer(key, axis=axis)\n        except TypeError as e:\n\n            # invalid indexer type vs 'other' indexing errors\n            if \"cannot do\" in str(e):\n                raise\n            raise IndexingError(key)",
        "begin_line": 168,
        "end_line": 198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer.__setitem__#200",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer.__setitem__(self, key, value)",
        "snippet": "    def __setitem__(self, key, value):\n        if isinstance(key, tuple):\n            key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n        else:\n            key = com.apply_if_callable(key, self.obj)\n        indexer = self._get_setitem_indexer(key)\n        self._setitem_with_indexer(indexer, value)",
        "begin_line": 200,
        "end_line": 206,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._has_valid_tuple#230",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._has_valid_tuple(self, key: Tuple)",
        "snippet": "    def _has_valid_tuple(self, key: Tuple):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.ndim:\n                raise IndexingError(\"Too many indexers\")\n            try:\n                self._validate_key(k, i)\n            except ValueError:\n                raise ValueError(\n                    \"Location based indexing can only have \"\n                    \"[{types}] types\".format(types=self._valid_types)\n                )",
        "begin_line": 230,
        "end_line": 241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._is_nested_tuple_indexer#243",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._is_nested_tuple_indexer(self, tup: Tuple)",
        "snippet": "    def _is_nested_tuple_indexer(self, tup: Tuple):\n        if any(isinstance(ax, ABCMultiIndex) for ax in self.obj.axes):\n            return any(is_nested_tuple(tup, ax) for ax in self.obj.axes)\n        return False",
        "begin_line": 243,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._convert_scalar_indexer#265",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._convert_scalar_indexer(self, key, axis: int)",
        "snippet": "    def _convert_scalar_indexer(self, key, axis: int):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, kind=self.name)",
        "begin_line": 265,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._has_valid_setitem_indexer#276",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._has_valid_setitem_indexer(self, indexer)",
        "snippet": "    def _has_valid_setitem_indexer(self, indexer):\n        return True",
        "begin_line": 276,
        "end_line": 277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._setitem_with_indexer#308",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._setitem_with_indexer(self, indexer, value)",
        "snippet": "    def _setitem_with_indexer(self, indexer, value):\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        from pandas import Series\n\n        info_axis = self.obj._info_axis_number\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n\n        # if there is only one block/type, still have to take split path\n        # unless the block is one-dimensional or it can hold the value\n        if not take_split_path and self.obj._data.blocks:\n            (blk,) = self.obj._data.blocks\n            if 1 < blk.ndim:  # in case of dict, keys are indices\n                val = list(value.values()) if isinstance(value, dict) else value\n                take_split_path = not blk._can_hold_element(val)\n\n        # if we have any multi-indexes that have non-trivial slices\n        # (not null slices) then we must take the split path, xref\n        # GH 10360, GH 27841\n        if isinstance(indexer, tuple) and len(indexer) == len(self.obj.axes):\n            for i, ax in zip(indexer, self.obj.axes):\n                if isinstance(ax, ABCMultiIndex) and not (\n                    is_integer(i) or com.is_null_slice(i)\n                ):\n                    take_split_path = True\n                    break\n\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = (\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes) if _i != i\n                        )\n                        if any(not l for l in len_non_info_axes):\n                            if not is_list_like_indexer(value):\n                                raise ValueError(\n                                    \"cannot set a frame with no \"\n                                    \"defined index and a scalar\"\n                                )\n                            self.obj[key] = value\n                            return self.obj\n\n                        # add a new item with the dtype setup\n                        self.obj[key] = _infer_fill_value(value)\n\n                        new_indexer = convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes\n                        )\n                        self._setitem_with_indexer(new_indexer, value)\n\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = index.insert(len(index), key)\n                    self.obj._data = self.obj.reindex(labels, axis=i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj._is_copy = None\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = convert_missing_indexer(indexer)\n\n            if missing:\n                return self._setitem_with_indexer_missing(indexer, value)\n\n        # set\n        item_labels = self.obj._get_axis(info_axis)\n\n        # align and set the values\n        if take_split_path:\n            # Above we only set take_split_path to True for 2D cases\n            assert self.ndim == 2\n            assert info_axis == 1\n\n            if not isinstance(indexer, tuple):\n                indexer = _tuplify(self.ndim, indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if len(labels) == 1 and isinstance(\n                self.obj[labels[0]].axes[0], ABCMultiIndex\n            ):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1 :]\n                lplane_indexer = length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if (\n                    is_list_like_indexer(value)\n                    and np.iterable(value)\n                    and lplane_indexer != len(value)\n                ):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\n                            \"cannot set using a multi-index \"\n                            \"selection indexer with a different \"\n                            \"length than the value\"\n                        )\n\n                    # make sure we have an ndarray\n                    value = getattr(value, \"values\", value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj._consolidate_inplace()\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1 :]\n                plane_axis = self.obj.axes[:info_axis][0]\n                lplane_indexer = length_of_indexer(plane_indexer[0], plane_axis)\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice or a slice with full bounds\n                # which means essentially reassign to the columns of a\n                # multi-dim object\n                # GH6149 (null slice), GH10408 (full bounds)\n                if isinstance(pi, tuple) and all(\n                    com.is_null_slice(idx) or com.is_full_slice(idx, len(self.obj))\n                    for idx in pi\n                ):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s._consolidate_inplace()\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            # we need an iterable, with a ndim of at least 1\n            # eg. don't pass through np.array(0)\n            if is_list_like_indexer(value) and getattr(value, \"ndim\", 1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame):\n                    sub_indexer = list(indexer)\n                    multiindex_indexer = isinstance(labels, ABCMultiIndex)\n\n                    for item in labels:\n                        if item in value:\n                            sub_indexer[info_axis] = item\n                            v = self._align_series(\n                                tuple(sub_indexer), value[item], multiindex_indexer\n                            )\n                        else:\n                            v = np.nan\n\n                        setter(item, v)\n\n                # we have an equal len ndarray/convertible to our labels\n                # hasattr first, to avoid coercing to ndarray without reason.\n                # But we may be relying on the ndarray coercion to check ndim.\n                # Why not just convert to an ndarray earlier on if needed?\n                elif np.ndim(value) == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value, dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError(\n                            \"Must have equal len keys and value \"\n                            \"when setting with an ndarray\"\n                        )\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif _can_do_equal_len(\n                    labels, value, plane_indexer, lplane_indexer, self.obj\n                ):\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError(\n                            \"Must have equal len keys and value \"\n                            \"when setting with an iterable\"\n                        )\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = maybe_convert_ix(*indexer)\n\n                # if we are setting on the info axis ONLY\n                # set using those methods to avoid block-splitting\n                # logic here\n                if (\n                    len(indexer) > info_axis\n                    and is_integer(indexer[info_axis])\n                    and all(\n                        com.is_null_slice(idx)\n                        for i, idx in enumerate(indexer)\n                        if i != info_axis\n                    )\n                    and item_labels.is_unique\n                ):\n                    self.obj[item_labels[indexer[info_axis]]] = value\n                    return\n\n            if isinstance(value, (ABCSeries, dict)):\n                # TODO(EA): ExtensionBlock.setitem this causes issues with\n                # setting for extensionarrays that store dicts. Need to decide\n                # if it's worth supporting that.\n                value = self._align_series(indexer, Series(value))\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._consolidate_inplace()\n            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n            self.obj._maybe_update_cacher(clear=True)",
        "begin_line": 308,
        "end_line": 591,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._getitem_lowerdim#886",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._getitem_lowerdim(self, tup: Tuple)",
        "snippet": "    def _getitem_lowerdim(self, tup: Tuple):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        # ...but iloc should handle the tuple as simple integer-location\n        # instead of checking it as multiindex representation (GH 13797)\n        if isinstance(ax0, ABCMultiIndex) and self.name != \"iloc\":\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not is_list_like_indexer(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1 :]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1 :]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (\n                        isinstance(section, ABCDataFrame)\n                        and i > 0\n                        and len(new_key) == 2\n                    ):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key = new_key[0]\n\n                # Slices should return views, but calling iloc/loc with a null\n                # slice returns a new object.\n                if com.is_null_slice(new_key):\n                    return section\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError(\"not applicable\")",
        "begin_line": 886,
        "end_line": 948,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._NDFrameIndexer._convert_to_indexer#1190",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._NDFrameIndexer",
        "signature": "pandas.core.indexing._NDFrameIndexer._convert_to_indexer(self, obj, axis: int, raise_missing: bool=False)",
        "snippet": "    def _convert_to_indexer(self, obj, axis: int, raise_missing: bool = False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        'In the face of ambiguity, refuse the temptation to guess.'\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        # try to find out correct indexer, if not type correct raise\n        try:\n            obj = self._convert_scalar_indexer(obj, axis)\n        except TypeError:\n            # but we will allow setting\n            pass\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except LookupError:\n            if isinstance(obj, tuple) and isinstance(labels, ABCMultiIndex):\n                if len(obj) == labels.nlevels:\n                    return {\"key\": obj}\n                raise\n        except TypeError:\n            pass\n        except ValueError:\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n\n            if self.name == \"loc\":\n                # always valid\n                return {\"key\": obj}\n\n            if obj >= self.obj.shape[axis] and not isinstance(labels, ABCMultiIndex):\n                # a positional\n                raise ValueError(\"cannot set by positional indexing with enlargement\")\n\n            return obj\n\n        if is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n\n        elif is_list_like_indexer(obj):\n\n            if com.is_bool_indexer(obj):\n                obj = check_bool_indexer(labels, obj)\n                (inds,) = obj.nonzero()\n                return inds\n            else:\n                # When setting, missing keys are not allowed, even with .loc:\n                return self._get_listlike_indexer(obj, axis, raise_missing=True)[1]\n        else:\n            try:\n                return labels.get_loc(obj)\n            except LookupError:\n                # allow a not found key only if we are a setter\n                if not is_list_like_indexer(obj):\n                    return {\"key\": obj}\n                raise",
        "begin_line": 1190,
        "end_line": 1270,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._LocationIndexer.__getitem__#1379",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._LocationIndexer",
        "signature": "pandas.core.indexing._LocationIndexer.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        if type(key) is tuple:\n            key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n            if self._is_scalar_access(key):\n                try:\n                    return self._getitem_scalar(key)\n                except (KeyError, IndexError, AttributeError):\n                    pass\n            return self._getitem_tuple(key)\n        else:\n            # we by definition only have the 0th axis\n            axis = self.axis or 0\n\n            maybe_callable = com.apply_if_callable(key, self.obj)\n            return self._getitem_axis(maybe_callable, axis=axis)",
        "begin_line": 1379,
        "end_line": 1393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._iLocIndexer._validate_key#1960",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._iLocIndexer",
        "signature": "pandas.core.indexing._iLocIndexer._validate_key(self, key, axis: int)",
        "snippet": "    def _validate_key(self, key, axis: int):\n        if com.is_bool_indexer(key):\n            if hasattr(key, \"index\") and isinstance(key.index, Index):\n                if key.index.inferred_type == \"integer\":\n                    raise NotImplementedError(\n                        \"iLocation based boolean \"\n                        \"indexing on an integer type \"\n                        \"is not available\"\n                    )\n                raise ValueError(\n                    \"iLocation based boolean indexing cannot use \"\n                    \"an indexable as a mask\"\n                )\n            return\n\n        if isinstance(key, slice):\n            return\n        elif is_integer(key):\n            self._validate_integer(key, axis)\n        elif isinstance(key, tuple):\n            # a tuple should already have been caught by this point\n            # so don't treat a tuple as a valid indexer\n            raise IndexingError(\"Too many indexers\")\n        elif is_list_like_indexer(key):\n            arr = np.array(key)\n            len_axis = len(self.obj._get_axis(axis))\n\n            # check that the key has a numeric dtype\n            if not is_numeric_dtype(arr.dtype):\n                raise IndexError(\n                    \".iloc requires numeric indexers, got {arr}\".format(arr=arr)\n                )\n\n            # check that the key does not exceed the maximum size of the index\n            if len(arr) and (arr.max() >= len_axis or arr.min() < -len_axis):\n                raise IndexError(\"positional indexers are out-of-bounds\")\n        else:\n            raise ValueError(\n                \"Can only index by location with \"\n                \"a [{types}]\".format(types=self._valid_types)\n            )",
        "begin_line": 1960,
        "end_line": 2000,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._iLocIndexer._is_scalar_access#2005",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._iLocIndexer",
        "signature": "pandas.core.indexing._iLocIndexer._is_scalar_access(self, key: Tuple)",
        "snippet": "    def _is_scalar_access(self, key: Tuple):\n        # this is a shortcut accessor to both .loc and .iloc\n        # that provide the equivalent access of .at and .iat\n        # a) avoid getting things via sections and (to minimize dtype changes)\n        # b) provide a performant path\n        if len(key) != self.ndim:\n            return False\n\n        for i, k in enumerate(key):\n            if not is_integer(k):\n                return False\n\n            ax = self.obj.axes[i]\n            if not ax.is_unique:\n                return False\n\n        return True",
        "begin_line": 2005,
        "end_line": 2021,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._iLocIndexer._validate_integer#2029",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._iLocIndexer",
        "signature": "pandas.core.indexing._iLocIndexer._validate_integer(self, key: int, axis: int)",
        "snippet": "    def _validate_integer(self, key: int, axis: int):\n        \"\"\"\n        Check that 'key' is a valid position in the desired axis.\n\n        Parameters\n        ----------\n        key : int\n            Requested position\n        axis : int\n            Desired axis\n\n        Returns\n        -------\n        None\n\n        Raises\n        ------\n        IndexError\n            If 'key' is not a valid position in axis 'axis'\n        \"\"\"\n\n        len_axis = len(self.obj._get_axis(axis))\n        if key >= len_axis or key < -len_axis:\n            raise IndexError(\"single positional indexer is out-of-bounds\")",
        "begin_line": 2029,
        "end_line": 2052,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._iLocIndexer._getitem_tuple#2054",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._iLocIndexer",
        "signature": "pandas.core.indexing._iLocIndexer._getitem_tuple(self, tup: Tuple)",
        "snippet": "    def _getitem_tuple(self, tup: Tuple):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        retval = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n            if com.is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim < self.ndim:\n                # TODO: this is never reached in tests; can we confirm that\n                #  it is impossible?\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval",
        "begin_line": 2054,
        "end_line": 2080,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing._iLocIndexer._getitem_axis#2101",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing._iLocIndexer",
        "signature": "pandas.core.indexing._iLocIndexer._getitem_axis(self, key, axis: int)",
        "snippet": "    def _getitem_axis(self, key, axis: int):\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n\n        if isinstance(key, list):\n            key = np.asarray(key)\n\n        if com.is_bool_indexer(key):\n            self._validate_key(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a list of integers\n        elif is_list_like_indexer(key):\n            return self._get_list_axis(key, axis=axis)\n\n        # a single integer\n        else:\n            key = item_from_zerodim(key)\n            if not is_integer(key):\n                raise TypeError(\"Cannot index by location index with a non-integer key\")\n\n            # validate the location\n            self._validate_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)",
        "begin_line": 2101,
        "end_line": 2125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing.check_bool_indexer#2357",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing",
        "signature": "pandas.core.indexing.check_bool_indexer(index: Index, key)",
        "snippet": "def check_bool_indexer(index: Index, key) -> np.ndarray:\n    \"\"\"\n    Check if key is a valid boolean indexer for an object with such index and\n    perform reindexing or conversion if needed.\n\n    This function assumes that is_bool_indexer(key) == True.\n\n    Parameters\n    ----------\n    index : Index\n        Index of the object on which the indexing is done\n    key : list-like\n        Boolean indexer to check\n\n    Returns\n    -------\n    result: np.array\n        Resulting key\n\n    Raises\n    ------\n    IndexError\n        If the key does not have the same length as index\n\n    IndexingError\n        If the index of the key is unalignable to index\n\n    \"\"\"\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(index):\n        result = result.reindex(index)\n        mask = isna(result._values)\n        if mask.any():\n            raise IndexingError(\n                \"Unalignable boolean Series provided as \"\n                \"indexer (index of the boolean Series and of \"\n                \"the indexed object do not match).\"\n            )\n        result = result.astype(bool)._values\n    else:\n        if is_sparse(result):\n            result = result.to_dense()\n        result = np.asarray(result, dtype=bool)\n\n        # GH26658\n        if len(result) != len(index):\n            raise IndexError(\n                \"Item wrong length {} instead of {}.\".format(len(result), len(index))\n            )\n\n    return result",
        "begin_line": 2357,
        "end_line": 2407,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing.convert_missing_indexer#2410",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing",
        "signature": "pandas.core.indexing.convert_missing_indexer(indexer)",
        "snippet": "def convert_missing_indexer(indexer):\n    \"\"\"\n    reverse convert a missing indexer, which is a dict\n    return the scalar indexer and a boolean indicating if we converted\n    \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer[\"key\"]\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False",
        "begin_line": 2410,
        "end_line": 2425,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing.is_nested_tuple#2455",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing",
        "signature": "pandas.core.indexing.is_nested_tuple(tup, labels)",
        "snippet": "def is_nested_tuple(tup, labels):\n    # check for a compatible nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    for i, k in enumerate(tup):\n\n        if is_list_like(k) or isinstance(k, slice):\n            return isinstance(labels, ABCMultiIndex)\n\n    return False",
        "begin_line": 2455,
        "end_line": 2465,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.indexing.is_label_like#2468",
        "src_path": "pandas/core/indexing.py",
        "class_name": "pandas.core.indexing",
        "signature": "pandas.core.indexing.is_label_like(key)",
        "snippet": "def is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not is_list_like_indexer(key)",
        "begin_line": 2468,
        "end_line": 2470,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops.disallow.check#55",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops.disallow",
        "signature": "pandas.core.nanops.disallow.check(self, obj)",
        "snippet": "    def check(self, obj) -> bool:\n        return hasattr(obj, \"dtype\") and issubclass(obj.dtype.type, self.dtypes)",
        "begin_line": 55,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops.disallow.__call__#58",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops.disallow",
        "signature": "pandas.core.nanops.disallow.__call__(self, f)",
        "snippet": "    def __call__(self, f):\n        @functools.wraps(f)\n        def _f(*args, **kwargs):\n            obj_iter = itertools.chain(args, kwargs.values())\n            if any(self.check(obj) for obj in obj_iter):\n                msg = \"reduction operation {name!r} not allowed for this dtype\"\n                raise TypeError(msg.format(name=f.__name__.replace(\"nan\", \"\")))\n            try:\n                with np.errstate(invalid=\"ignore\"):\n                    return f(*args, **kwargs)\n            except ValueError as e:\n                # we want to transform an object array\n                # ValueError message to the more typical TypeError\n                # e.g. this is normally a disallowed function on\n                # object arrays that contain strings\n                if is_object_dtype(args[0]):\n                    raise TypeError(e)\n                raise\n\n        return _f",
        "begin_line": 58,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops.disallow._f#60",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops.disallow",
        "signature": "pandas.core.nanops.disallow._f(*args, **kwargs)",
        "snippet": "        def _f(*args, **kwargs):\n            obj_iter = itertools.chain(args, kwargs.values())\n            if any(self.check(obj) for obj in obj_iter):\n                msg = \"reduction operation {name!r} not allowed for this dtype\"\n                raise TypeError(msg.format(name=f.__name__.replace(\"nan\", \"\")))\n            try:\n                with np.errstate(invalid=\"ignore\"):\n                    return f(*args, **kwargs)\n            except ValueError as e:\n                # we want to transform an object array\n                # ValueError message to the more typical TypeError\n                # e.g. this is normally a disallowed function on\n                # object arrays that contain strings\n                if is_object_dtype(args[0]):\n                    raise TypeError(e)\n                raise",
        "begin_line": 60,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops._get_fill_value#164",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops",
        "signature": "pandas.core.nanops._get_fill_value(dtype, fill_value=None, fill_value_typ=None)",
        "snippet": "def _get_fill_value(dtype, fill_value=None, fill_value_typ=None):\n    \"\"\" return the correct fill value for the dtype of the values \"\"\"\n    if fill_value is not None:\n        return fill_value\n    if _na_ok_dtype(dtype):\n        if fill_value_typ is None:\n            return np.nan\n        else:\n            if fill_value_typ == \"+inf\":\n                return np.inf\n            else:\n                return -np.inf\n    else:\n        if fill_value_typ is None:\n            return iNaT\n        else:\n            if fill_value_typ == \"+inf\":\n                # need the max int here\n                return _int64_max\n            else:\n                return iNaT",
        "begin_line": 164,
        "end_line": 184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops._maybe_get_mask#187",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops",
        "signature": "pandas.core.nanops._maybe_get_mask(values: np.ndarray, skipna: bool, mask: Optional[np.ndarray])",
        "snippet": "def _maybe_get_mask(\n    values: np.ndarray, skipna: bool, mask: Optional[np.ndarray]\n) -> Optional[np.ndarray]:\n    \"\"\"\n    Compute a mask if and only if necessary.\n\n    This function will compute a mask iff it is necessary. Otherwise,\n    return the provided mask (potentially None) when a mask does not need to be\n    computed.\n\n    A mask is never necessary if the values array is of boolean or integer\n    dtypes, as these are incapable of storing NaNs. If passing a NaN-capable\n    dtype that is interpretable as either boolean or integer data (eg,\n    timedelta64), a mask must be provided.\n\n    If the skipna parameter is False, a new mask will not be computed.\n\n    The mask is computed using isna() by default. Setting invert=True selects\n    notna() as the masking function.\n\n    Parameters\n    ----------\n    values : ndarray\n        input array to potentially compute mask for\n    skipna : bool\n        boolean for whether NaNs should be skipped\n    mask : Optional[ndarray]\n        nan-mask if known\n\n    Returns\n    -------\n    Optional[np.ndarray]\n    \"\"\"\n\n    if mask is None:\n        if is_bool_dtype(values.dtype) or is_integer_dtype(values.dtype):\n            # Boolean data cannot contain nulls, so signal via mask being None\n            return None\n\n        if skipna:\n            mask = isna(values)\n\n    return mask",
        "begin_line": 187,
        "end_line": 229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops._get_values#232",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops",
        "signature": "pandas.core.nanops._get_values(values: np.ndarray, skipna: bool, fill_value: Any=None, fill_value_typ: Optional[str]=None, mask: Optional[np.ndarray]=None)",
        "snippet": "def _get_values(\n    values: np.ndarray,\n    skipna: bool,\n    fill_value: Any = None,\n    fill_value_typ: Optional[str] = None,\n    mask: Optional[np.ndarray] = None,\n) -> Tuple[np.ndarray, Optional[np.ndarray], np.dtype, np.dtype, Any]:\n    \"\"\"\n    Utility to get the values view, mask, dtype, dtype_max, and fill_value.\n\n    If both mask and fill_value/fill_value_typ are not None and skipna is True,\n    the values array will be copied.\n\n    For input arrays of boolean or integer dtypes, copies will only occur if a\n    precomputed mask, a fill_value/fill_value_typ, and skipna=True are\n    provided.\n\n    Parameters\n    ----------\n    values : ndarray\n        input array to potentially compute mask for\n    skipna : bool\n        boolean for whether NaNs should be skipped\n    fill_value : Any\n        value to fill NaNs with\n    fill_value_typ : str\n        Set to '+inf' or '-inf' to handle dtype-specific infinities\n    mask : Optional[np.ndarray]\n        nan-mask if known\n\n    Returns\n    -------\n    values : ndarray\n        Potential copy of input value array\n    mask : Optional[ndarray[bool]]\n        Mask for values, if deemed necessary to compute\n    dtype : dtype\n        dtype for values\n    dtype_max : dtype\n        platform independent dtype\n    fill_value : Any\n        fill value used\n    \"\"\"\n\n    # In _get_values is only called from within nanops, and in all cases\n    #  with scalar fill_value.  This guarantee is important for the\n    #  maybe_upcast_putmask call below\n    assert is_scalar(fill_value)\n\n    mask = _maybe_get_mask(values, skipna, mask)\n\n    if is_datetime64tz_dtype(values):\n        # lib.values_from_object returns M8[ns] dtype instead of tz-aware,\n        #  so this case must be handled separately from the rest\n        dtype = values.dtype\n        values = getattr(values, \"_values\", values)\n    else:\n        values = lib.values_from_object(values)\n        dtype = values.dtype\n\n    if is_datetime_or_timedelta_dtype(values) or is_datetime64tz_dtype(values):\n        # changing timedelta64/datetime64 to int64 needs to happen after\n        #  finding `mask` above\n        values = getattr(values, \"asi8\", values)\n        values = values.view(np.int64)\n\n    dtype_ok = _na_ok_dtype(dtype)\n\n    # get our fill value (in case we need to provide an alternative\n    # dtype for it)\n    fill_value = _get_fill_value(\n        dtype, fill_value=fill_value, fill_value_typ=fill_value_typ\n    )\n\n    copy = (mask is not None) and (fill_value is not None)\n\n    if skipna and copy:\n        values = values.copy()\n        if dtype_ok:\n            np.putmask(values, mask, fill_value)\n\n        # promote if needed\n        else:\n            values, changed = maybe_upcast_putmask(values, mask, fill_value)\n\n    # return a platform independent precision dtype\n    dtype_max = dtype\n    if is_integer_dtype(dtype) or is_bool_dtype(dtype):\n        dtype_max = np.int64\n    elif is_float_dtype(dtype):\n        dtype_max = np.float64\n\n    return values, mask, dtype, dtype_max, fill_value",
        "begin_line": 232,
        "end_line": 324,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops._na_ok_dtype#327",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops",
        "signature": "pandas.core.nanops._na_ok_dtype(dtype)",
        "snippet": "def _na_ok_dtype(dtype):\n    # TODO: what about datetime64tz?  PeriodDtype?\n    return not issubclass(dtype.type, (np.integer, np.timedelta64, np.datetime64))",
        "begin_line": 327,
        "end_line": 329,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops._wrap_results#332",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops",
        "signature": "pandas.core.nanops._wrap_results(result, dtype, fill_value=None)",
        "snippet": "def _wrap_results(result, dtype, fill_value=None):\n    \"\"\" wrap our results if needed \"\"\"\n\n    if is_datetime64_dtype(dtype) or is_datetime64tz_dtype(dtype):\n        if fill_value is None:\n            # GH#24293\n            fill_value = iNaT\n        if not isinstance(result, np.ndarray):\n            tz = getattr(dtype, \"tz\", None)\n            assert not isna(fill_value), \"Expected non-null fill_value\"\n            if result == fill_value:\n                result = np.nan\n            result = Timestamp(result, tz=tz)\n        else:\n            result = result.view(dtype)\n    elif is_timedelta64_dtype(dtype):\n        if not isinstance(result, np.ndarray):\n            if result == fill_value:\n                result = np.nan\n\n            # raise if we have a timedelta64[ns] which is too large\n            if np.fabs(result) > _int64_max:\n                raise ValueError(\"overflow in timedelta operation\")\n\n            result = Timedelta(result, unit=\"ns\")\n        else:\n            result = result.astype(\"m8[ns]\").view(dtype)\n\n    return result",
        "begin_line": 332,
        "end_line": 360,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops.nanany#394",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops",
        "signature": "pandas.core.nanops.nanany(values, axis=None, skipna: bool=True, mask=None)",
        "snippet": "def nanany(values, axis=None, skipna: bool = True, mask=None):\n    \"\"\"\n    Check if any elements along an axis evaluate to True.\n\n    Parameters\n    ----------\n    values : ndarray\n    axis : int, optional\n    skipna : bool, default True\n    mask : ndarray[bool], optional\n        nan-mask if known\n\n    Returns\n    -------\n    result : bool\n\n    Examples\n    --------\n    >>> import pandas.core.nanops as nanops\n    >>> s = pd.Series([1, 2])\n    >>> nanops.nanany(s)\n    True\n\n    >>> import pandas.core.nanops as nanops\n    >>> s = pd.Series([np.nan])\n    >>> nanops.nanany(s)\n    False\n    \"\"\"\n    values, _, _, _, _ = _get_values(values, skipna, fill_value=False, mask=mask)\n    return values.any(axis)",
        "begin_line": 394,
        "end_line": 423,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops.nansum#459",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops",
        "signature": "pandas.core.nanops.nansum(values, axis=None, skipna=True, min_count=0, mask=None)",
        "snippet": "def nansum(values, axis=None, skipna=True, min_count=0, mask=None):\n    \"\"\"\n    Sum the elements along an axis ignoring NaNs\n\n    Parameters\n    ----------\n    values : ndarray[dtype]\n    axis: int, optional\n    skipna : bool, default True\n    min_count: int, default 0\n    mask : ndarray[bool], optional\n        nan-mask if known\n\n    Returns\n    -------\n    result : dtype\n\n    Examples\n    --------\n    >>> import pandas.core.nanops as nanops\n    >>> s = pd.Series([1, 2, np.nan])\n    >>> nanops.nansum(s)\n    3.0\n    \"\"\"\n    values, mask, dtype, dtype_max, _ = _get_values(\n        values, skipna, fill_value=0, mask=mask\n    )\n    dtype_sum = dtype_max\n    if is_float_dtype(dtype):\n        dtype_sum = dtype\n    elif is_timedelta64_dtype(dtype):\n        dtype_sum = np.float64\n    the_sum = values.sum(axis, dtype=dtype_sum)\n    the_sum = _maybe_null_out(the_sum, axis, mask, values.shape, min_count=min_count)\n\n    return _wrap_results(the_sum, dtype)",
        "begin_line": 459,
        "end_line": 494,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.nanops._maybe_null_out#1179",
        "src_path": "pandas/core/nanops.py",
        "class_name": "pandas.core.nanops",
        "signature": "pandas.core.nanops._maybe_null_out(result: np.ndarray, axis: Optional[int], mask: Optional[np.ndarray], shape: Tuple, min_count: int=1)",
        "snippet": "def _maybe_null_out(\n    result: np.ndarray,\n    axis: Optional[int],\n    mask: Optional[np.ndarray],\n    shape: Tuple,\n    min_count: int = 1,\n) -> np.ndarray:\n    if mask is not None and axis is not None and getattr(result, \"ndim\", False):\n        null_mask = (mask.shape[axis] - mask.sum(axis) - min_count) < 0\n        if np.any(null_mask):\n            if is_numeric_dtype(result):\n                if np.iscomplexobj(result):\n                    result = result.astype(\"c16\")\n                else:\n                    result = result.astype(\"f8\")\n                result[null_mask] = np.nan\n            else:\n                # GH12941, use None to auto cast null\n                result[null_mask] = None\n    elif result is not NaT:\n        if mask is not None:\n            null_mask = mask.size - mask.sum()\n        else:\n            null_mask = np.prod(shape)\n        if null_mask < min_count:\n            result = np.nan\n\n    return result",
        "begin_line": 1179,
        "end_line": 1206,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util.testing._check_isinstance#366",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing._check_isinstance(left, right, cls)",
        "snippet": "def _check_isinstance(left, right, cls):\n    \"\"\"\n    Helper method for our assert_* methods that ensures that\n    the two objects being compared have the right type before\n    proceeding with the comparison.\n\n    Parameters\n    ----------\n    left : The first object being compared.\n    right : The second object being compared.\n    cls : The class type to check against.\n\n    Raises\n    ------\n    AssertionError : Either `left` or `right` is not an instance of `cls`.\n    \"\"\"\n\n    err_msg = \"{name} Expected type {exp_type}, found {act_type} instead\"\n    cls_name = cls.__name__\n\n    if not isinstance(left, cls):\n        raise AssertionError(\n            err_msg.format(name=cls_name, exp_type=cls, act_type=type(left))\n        )\n    if not isinstance(right, cls):\n        raise AssertionError(\n            err_msg.format(name=cls_name, exp_type=cls, act_type=type(right))\n        )",
        "begin_line": 366,
        "end_line": 393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util.testing.assert_index_equal#570",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.assert_index_equal(left: Index, right: Index, exact: Union[bool, str]='equiv', check_names: bool=True, check_less_precise: Union[bool, int]=False, check_exact: bool=True, check_categorical: bool=True, obj: str='Index')",
        "snippet": "def assert_index_equal(\n    left: Index,\n    right: Index,\n    exact: Union[bool, str] = \"equiv\",\n    check_names: bool = True,\n    check_less_precise: Union[bool, int] = False,\n    check_exact: bool = True,\n    check_categorical: bool = True,\n    obj: str = \"Index\",\n) -> None:\n    \"\"\"\n    Check that left and right Index are equal.\n\n    Parameters\n    ----------\n    left : Index\n    right : Index\n    exact : bool or {'equiv'}, default 'equiv'\n        Whether to check the Index class, dtype and inferred_type\n        are identical. If 'equiv', then RangeIndex can be substituted for\n        Int64Index as well.\n    check_names : bool, default True\n        Whether to check the names attribute.\n    check_less_precise : bool or int, default False\n        Specify comparison precision. Only used when check_exact is False.\n        5 digits (False) or 3 digits (True) after decimal points are compared.\n        If int, then specify the digits to compare.\n    check_exact : bool, default True\n        Whether to compare number exactly.\n    check_categorical : bool, default True\n        Whether to compare internal Categorical exactly.\n    obj : str, default 'Index'\n        Specify object name being compared, internally used to show appropriate\n        assertion message.\n    \"\"\"\n    __tracebackhide__ = True\n\n    def _check_types(l, r, obj=\"Index\"):\n        if exact:\n            assert_class_equal(l, r, exact=exact, obj=obj)\n\n            # Skip exact dtype checking when `check_categorical` is False\n            if check_categorical:\n                assert_attr_equal(\"dtype\", l, r, obj=obj)\n\n            # allow string-like to have different inferred_types\n            if l.inferred_type in (\"string\", \"unicode\"):\n                assert r.inferred_type in (\"string\", \"unicode\")\n            else:\n                assert_attr_equal(\"inferred_type\", l, r, obj=obj)\n\n    def _get_ilevel_values(index, level):\n        # accept level number only\n        unique = index.levels[level]\n        level_codes = index.codes[level]\n        filled = take_1d(unique.values, level_codes, fill_value=unique._na_value)\n        values = unique._shallow_copy(filled, name=index.names[level])\n        return values\n\n    # instance validation\n    _check_isinstance(left, right, Index)\n\n    # class / dtype comparison\n    _check_types(left, right, obj=obj)\n\n    # level comparison\n    if left.nlevels != right.nlevels:\n        msg1 = \"{obj} levels are different\".format(obj=obj)\n        msg2 = \"{nlevels}, {left}\".format(nlevels=left.nlevels, left=left)\n        msg3 = \"{nlevels}, {right}\".format(nlevels=right.nlevels, right=right)\n        raise_assert_detail(obj, msg1, msg2, msg3)\n\n    # length comparison\n    if len(left) != len(right):\n        msg1 = \"{obj} length are different\".format(obj=obj)\n        msg2 = \"{length}, {left}\".format(length=len(left), left=left)\n        msg3 = \"{length}, {right}\".format(length=len(right), right=right)\n        raise_assert_detail(obj, msg1, msg2, msg3)\n\n    # MultiIndex special comparison for little-friendly error messages\n    if left.nlevels > 1:\n        left = cast(MultiIndex, left)\n        right = cast(MultiIndex, right)\n\n        for level in range(left.nlevels):\n            # cannot use get_level_values here because it can change dtype\n            llevel = _get_ilevel_values(left, level)\n            rlevel = _get_ilevel_values(right, level)\n\n            lobj = \"MultiIndex level [{level}]\".format(level=level)\n            assert_index_equal(\n                llevel,\n                rlevel,\n                exact=exact,\n                check_names=check_names,\n                check_less_precise=check_less_precise,\n                check_exact=check_exact,\n                obj=lobj,\n            )\n            # get_level_values may change dtype\n            _check_types(left.levels[level], right.levels[level], obj=obj)\n\n    # skip exact index checking when `check_categorical` is False\n    if check_exact and check_categorical:\n        if not left.equals(right):\n            diff = np.sum((left.values != right.values).astype(int)) * 100.0 / len(left)\n            msg = \"{obj} values are different ({pct} %)\".format(\n                obj=obj, pct=np.round(diff, 5)\n            )\n            raise_assert_detail(obj, msg, left, right)\n    else:\n        _testing.assert_almost_equal(\n            left.values,\n            right.values,\n            check_less_precise=check_less_precise,\n            check_dtype=exact,\n            obj=obj,\n            lobj=left,\n            robj=right,\n        )\n\n    # metadata comparison\n    if check_names:\n        assert_attr_equal(\"names\", left, right, obj=obj)\n    if isinstance(left, pd.PeriodIndex) or isinstance(right, pd.PeriodIndex):\n        assert_attr_equal(\"freq\", left, right, obj=obj)\n    if isinstance(left, pd.IntervalIndex) or isinstance(right, pd.IntervalIndex):\n        assert_interval_array_equal(left.values, right.values)\n\n    if check_categorical:\n        if is_categorical_dtype(left) or is_categorical_dtype(right):\n            assert_categorical_equal(\n                left.values, right.values, obj=\"{obj} category\".format(obj=obj)\n            )",
        "begin_line": 570,
        "end_line": 703,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util.testing._check_types#607",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing._check_types(l, r, obj='Index')",
        "snippet": "    def _check_types(l, r, obj=\"Index\"):\n        if exact:\n            assert_class_equal(l, r, exact=exact, obj=obj)\n\n            # Skip exact dtype checking when `check_categorical` is False\n            if check_categorical:\n                assert_attr_equal(\"dtype\", l, r, obj=obj)\n\n            # allow string-like to have different inferred_types\n            if l.inferred_type in (\"string\", \"unicode\"):\n                assert r.inferred_type in (\"string\", \"unicode\")\n            else:\n                assert_attr_equal(\"inferred_type\", l, r, obj=obj)",
        "begin_line": 607,
        "end_line": 619,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util.testing._get_ilevel_values#621",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing._get_ilevel_values(index, level)",
        "snippet": "    def _get_ilevel_values(index, level):\n        # accept level number only\n        unique = index.levels[level]\n        level_codes = index.codes[level]\n        filled = take_1d(unique.values, level_codes, fill_value=unique._na_value)\n        values = unique._shallow_copy(filled, name=index.names[level])\n        return values",
        "begin_line": 621,
        "end_line": 627,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util.testing.assert_class_equal#706",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.assert_class_equal(left, right, exact=True, obj='Input')",
        "snippet": "def assert_class_equal(left, right, exact=True, obj=\"Input\"):\n    \"\"\"checks classes are equal.\"\"\"\n    __tracebackhide__ = True\n\n    def repr_class(x):\n        if isinstance(x, Index):\n            # return Index as it is to include values in the error message\n            return x\n\n        try:\n            return x.__class__.__name__\n        except AttributeError:\n            return repr(type(x))\n\n    if exact == \"equiv\":\n        if type(left) != type(right):\n            # allow equivalence of Int64Index/RangeIndex\n            types = {type(left).__name__, type(right).__name__}\n            if len(types - {\"Int64Index\", \"RangeIndex\"}):\n                msg = \"{obj} classes are not equivalent\".format(obj=obj)\n                raise_assert_detail(obj, msg, repr_class(left), repr_class(right))\n    elif exact:\n        if type(left) != type(right):\n            msg = \"{obj} classes are different\".format(obj=obj)\n            raise_assert_detail(obj, msg, repr_class(left), repr_class(right))",
        "begin_line": 706,
        "end_line": 730,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util.testing.repr_class#710",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.repr_class(x)",
        "snippet": "    def repr_class(x):\n        if isinstance(x, Index):\n            # return Index as it is to include values in the error message\n            return x\n\n        try:\n            return x.__class__.__name__\n        except AttributeError:\n            return repr(type(x))",
        "begin_line": 710,
        "end_line": 718,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util.testing.assert_attr_equal#733",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.assert_attr_equal(attr, left, right, obj='Attributes')",
        "snippet": "def assert_attr_equal(attr, left, right, obj=\"Attributes\"):\n    \"\"\"checks attributes are equal. Both objects must have attribute.\n\n    Parameters\n    ----------\n    attr : str\n        Attribute name being compared.\n    left : object\n    right : object\n    obj : str, default 'Attributes'\n        Specify object name being compared, internally used to show appropriate\n        assertion message\n    \"\"\"\n    __tracebackhide__ = True\n\n    left_attr = getattr(left, attr)\n    right_attr = getattr(right, attr)\n\n    if left_attr is right_attr:\n        return True\n    elif (\n        is_number(left_attr)\n        and np.isnan(left_attr)\n        and is_number(right_attr)\n        and np.isnan(right_attr)\n    ):\n        # np.nan\n        return True\n\n    try:\n        result = left_attr == right_attr\n    except TypeError:\n        # datetimetz on rhs may raise TypeError\n        result = False\n    if not isinstance(result, bool):\n        result = result.all()\n\n    if result:\n        return True\n    else:\n        msg = 'Attribute \"{attr}\" are different'.format(attr=attr)\n        raise_assert_detail(obj, msg, left_attr, right_attr)",
        "begin_line": 733,
        "end_line": 774,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util.testing.raise_assert_detail#906",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.raise_assert_detail(obj, message, left, right, diff=None)",
        "snippet": "def raise_assert_detail(obj, message, left, right, diff=None):\n    __tracebackhide__ = True\n\n    if isinstance(left, np.ndarray):\n        left = pprint_thing(left)\n    elif is_categorical_dtype(left):\n        left = repr(left)\n\n    if isinstance(right, np.ndarray):\n        right = pprint_thing(right)\n    elif is_categorical_dtype(right):\n        right = repr(right)\n\n    msg = \"\"\"{obj} are different\n\n{message}\n[left]:  {left}\n[right]: {right}\"\"\".format(\n        obj=obj, message=message, left=left, right=right\n    )\n\n    if diff is not None:\n        msg += \"\\n[diff]: {diff}\".format(diff=diff)\n\n    raise AssertionError(msg)",
        "begin_line": 906,
        "end_line": 930,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util.testing.assert_series_equal#1069",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.assert_series_equal(left, right, check_dtype=True, check_index_type='equiv', check_series_type=True, check_less_precise=False, check_names=True, check_exact=False, check_datetimelike_compat=False, check_categorical=True, obj='Series')",
        "snippet": "def assert_series_equal(\n    left,\n    right,\n    check_dtype=True,\n    check_index_type=\"equiv\",\n    check_series_type=True,\n    check_less_precise=False,\n    check_names=True,\n    check_exact=False,\n    check_datetimelike_compat=False,\n    check_categorical=True,\n    obj=\"Series\",\n):\n    \"\"\"\n    Check that left and right Series are equal.\n\n    Parameters\n    ----------\n    left : Series\n    right : Series\n    check_dtype : bool, default True\n        Whether to check the Series dtype is identical.\n    check_index_type : bool or {'equiv'}, default 'equiv'\n        Whether to check the Index class, dtype and inferred_type\n        are identical.\n    check_series_type : bool, default True\n        Whether to check the Series class is identical.\n    check_less_precise : bool or int, default False\n        Specify comparison precision. Only used when check_exact is False.\n        5 digits (False) or 3 digits (True) after decimal points are compared.\n        If int, then specify the digits to compare.\n\n        When comparing two numbers, if the first number has magnitude less\n        than 1e-5, we compare the two numbers directly and check whether\n        they are equivalent within the specified precision. Otherwise, we\n        compare the **ratio** of the second number to the first number and\n        check whether it is equivalent to 1 within the specified precision.\n    check_names : bool, default True\n        Whether to check the Series and Index names attribute.\n    check_exact : bool, default False\n        Whether to compare number exactly.\n    check_datetimelike_compat : bool, default False\n        Compare datetime-like which is comparable ignoring dtype.\n    check_categorical : bool, default True\n        Whether to compare internal Categorical exactly.\n    obj : str, default 'Series'\n        Specify object name being compared, internally used to show appropriate\n        assertion message.\n    \"\"\"\n    __tracebackhide__ = True\n\n    # instance validation\n    _check_isinstance(left, right, Series)\n\n    if check_series_type:\n        # ToDo: There are some tests using rhs is sparse\n        # lhs is dense. Should use assert_class_equal in future\n        assert isinstance(left, type(right))\n        # assert_class_equal(left, right, obj=obj)\n\n    # length comparison\n    if len(left) != len(right):\n        msg1 = \"{len}, {left}\".format(len=len(left), left=left.index)\n        msg2 = \"{len}, {right}\".format(len=len(right), right=right.index)\n        raise_assert_detail(obj, \"Series length are different\", msg1, msg2)\n\n    # index comparison\n    assert_index_equal(\n        left.index,\n        right.index,\n        exact=check_index_type,\n        check_names=check_names,\n        check_less_precise=check_less_precise,\n        check_exact=check_exact,\n        check_categorical=check_categorical,\n        obj=\"{obj}.index\".format(obj=obj),\n    )\n\n    if check_dtype:\n        # We want to skip exact dtype checking when `check_categorical`\n        # is False. We'll still raise if only one is a `Categorical`,\n        # regardless of `check_categorical`\n        if (\n            is_categorical_dtype(left)\n            and is_categorical_dtype(right)\n            and not check_categorical\n        ):\n            pass\n        else:\n            assert_attr_equal(\n                \"dtype\", left, right, obj=\"Attributes of {obj}\".format(obj=obj)\n            )\n\n    if check_exact:\n        assert_numpy_array_equal(\n            left._internal_get_values(),\n            right._internal_get_values(),\n            check_dtype=check_dtype,\n            obj=\"{obj}\".format(obj=obj),\n        )\n    elif check_datetimelike_compat:\n        # we want to check only if we have compat dtypes\n        # e.g. integer and M|m are NOT compat, but we can simply check\n        # the values in that case\n        if needs_i8_conversion(left) or needs_i8_conversion(right):\n\n            # datetimelike may have different objects (e.g. datetime.datetime\n            # vs Timestamp) but will compare equal\n            if not Index(left.values).equals(Index(right.values)):\n                msg = (\n                    \"[datetimelike_compat=True] {left} is not equal to {right}.\"\n                ).format(left=left.values, right=right.values)\n                raise AssertionError(msg)\n        else:\n            assert_numpy_array_equal(\n                left._internal_get_values(),\n                right._internal_get_values(),\n                check_dtype=check_dtype,\n            )\n    elif is_interval_dtype(left) or is_interval_dtype(right):\n        assert_interval_array_equal(left.array, right.array)\n    elif is_extension_array_dtype(left.dtype) and is_datetime64tz_dtype(left.dtype):\n        # .values is an ndarray, but ._values is the ExtensionArray.\n        # TODO: Use .array\n        assert is_extension_array_dtype(right.dtype)\n        assert_extension_array_equal(left._values, right._values)\n    elif (\n        is_extension_array_dtype(left)\n        and not is_categorical_dtype(left)\n        and is_extension_array_dtype(right)\n        and not is_categorical_dtype(right)\n    ):\n        assert_extension_array_equal(left.array, right.array)\n    else:\n        _testing.assert_almost_equal(\n            left._internal_get_values(),\n            right._internal_get_values(),\n            check_less_precise=check_less_precise,\n            check_dtype=check_dtype,\n            obj=\"{obj}\".format(obj=obj),\n        )\n\n    # metadata comparison\n    if check_names:\n        assert_attr_equal(\"name\", left, right, obj=obj)\n\n    if check_categorical:\n        if is_categorical_dtype(left) or is_categorical_dtype(right):\n            assert_categorical_equal(\n                left.values, right.values, obj=\"{obj} category\".format(obj=obj)\n            )",
        "begin_line": 1069,
        "end_line": 1219,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util.testing.assert_frame_equal#1223",
        "src_path": "pandas/util/testing.py",
        "class_name": "pandas.util.testing",
        "signature": "pandas.util.testing.assert_frame_equal(left, right, check_dtype=True, check_index_type='equiv', check_column_type='equiv', check_frame_type=True, check_less_precise=False, check_names=True, by_blocks=False, check_exact=False, check_datetimelike_compat=False, check_categorical=True, check_like=False, obj='DataFrame')",
        "snippet": "def assert_frame_equal(\n    left,\n    right,\n    check_dtype=True,\n    check_index_type=\"equiv\",\n    check_column_type=\"equiv\",\n    check_frame_type=True,\n    check_less_precise=False,\n    check_names=True,\n    by_blocks=False,\n    check_exact=False,\n    check_datetimelike_compat=False,\n    check_categorical=True,\n    check_like=False,\n    obj=\"DataFrame\",\n):\n    \"\"\"\n    Check that left and right DataFrame are equal.\n\n    This function is intended to compare two DataFrames and output any\n    differences. Is is mostly intended for use in unit tests.\n    Additional parameters allow varying the strictness of the\n    equality checks performed.\n\n    Parameters\n    ----------\n    left : DataFrame\n        First DataFrame to compare.\n    right : DataFrame\n        Second DataFrame to compare.\n    check_dtype : bool, default True\n        Whether to check the DataFrame dtype is identical.\n    check_index_type : bool or {'equiv'}, default 'equiv'\n        Whether to check the Index class, dtype and inferred_type\n        are identical.\n    check_column_type : bool or {'equiv'}, default 'equiv'\n        Whether to check the columns class, dtype and inferred_type\n        are identical. Is passed as the ``exact`` argument of\n        :func:`assert_index_equal`.\n    check_frame_type : bool, default True\n        Whether to check the DataFrame class is identical.\n    check_less_precise : bool or int, default False\n        Specify comparison precision. Only used when check_exact is False.\n        5 digits (False) or 3 digits (True) after decimal points are compared.\n        If int, then specify the digits to compare.\n\n        When comparing two numbers, if the first number has magnitude less\n        than 1e-5, we compare the two numbers directly and check whether\n        they are equivalent within the specified precision. Otherwise, we\n        compare the **ratio** of the second number to the first number and\n        check whether it is equivalent to 1 within the specified precision.\n    check_names : bool, default True\n        Whether to check that the `names` attribute for both the `index`\n        and `column` attributes of the DataFrame is identical.\n    by_blocks : bool, default False\n        Specify how to compare internal data. If False, compare by columns.\n        If True, compare by blocks.\n    check_exact : bool, default False\n        Whether to compare number exactly.\n    check_datetimelike_compat : bool, default False\n        Compare datetime-like which is comparable ignoring dtype.\n    check_categorical : bool, default True\n        Whether to compare internal Categorical exactly.\n    check_like : bool, default False\n        If True, ignore the order of index & columns.\n        Note: index labels must match their respective rows\n        (same as in columns) - same labels must be with the same data.\n    obj : str, default 'DataFrame'\n        Specify object name being compared, internally used to show appropriate\n        assertion message.\n\n    See Also\n    --------\n    assert_series_equal : Equivalent method for asserting Series equality.\n    DataFrame.equals : Check DataFrame equality.\n\n    Examples\n    --------\n    This example shows comparing two DataFrames that are equal\n    but with columns of differing dtypes.\n\n    >>> from pandas.util.testing import assert_frame_equal\n    >>> df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n    >>> df2 = pd.DataFrame({'a': [1, 2], 'b': [3.0, 4.0]})\n\n    df1 equals itself.\n\n    >>> assert_frame_equal(df1, df1)\n\n    df1 differs from df2 as column 'b' is of a different type.\n\n    >>> assert_frame_equal(df1, df2)\n    Traceback (most recent call last):\n    ...\n    AssertionError: Attributes of DataFrame.iloc[:, 1] are different\n\n    Attribute \"dtype\" are different\n    [left]:  int64\n    [right]: float64\n\n    Ignore differing dtypes in columns with check_dtype.\n\n    >>> assert_frame_equal(df1, df2, check_dtype=False)\n    \"\"\"\n    __tracebackhide__ = True\n\n    # instance validation\n    _check_isinstance(left, right, DataFrame)\n\n    if check_frame_type:\n        assert isinstance(left, type(right))\n        # assert_class_equal(left, right, obj=obj)\n\n    # shape comparison\n    if left.shape != right.shape:\n        raise_assert_detail(\n            obj,\n            \"{obj} shape mismatch\".format(obj=obj),\n            \"{shape!r}\".format(shape=left.shape),\n            \"{shape!r}\".format(shape=right.shape),\n        )\n\n    if check_like:\n        left, right = left.reindex_like(right), right\n\n    # index comparison\n    assert_index_equal(\n        left.index,\n        right.index,\n        exact=check_index_type,\n        check_names=check_names,\n        check_less_precise=check_less_precise,\n        check_exact=check_exact,\n        check_categorical=check_categorical,\n        obj=\"{obj}.index\".format(obj=obj),\n    )\n\n    # column comparison\n    assert_index_equal(\n        left.columns,\n        right.columns,\n        exact=check_column_type,\n        check_names=check_names,\n        check_less_precise=check_less_precise,\n        check_exact=check_exact,\n        check_categorical=check_categorical,\n        obj=\"{obj}.columns\".format(obj=obj),\n    )\n\n    # compare by blocks\n    if by_blocks:\n        rblocks = right._to_dict_of_blocks()\n        lblocks = left._to_dict_of_blocks()\n        for dtype in list(set(list(lblocks.keys()) + list(rblocks.keys()))):\n            assert dtype in lblocks\n            assert dtype in rblocks\n            assert_frame_equal(\n                lblocks[dtype], rblocks[dtype], check_dtype=check_dtype, obj=obj\n            )\n\n    # compare by columns\n    else:\n        for i, col in enumerate(left.columns):\n            assert col in right\n            lcol = left.iloc[:, i]\n            rcol = right.iloc[:, i]\n            assert_series_equal(\n                lcol,\n                rcol,\n                check_dtype=check_dtype,\n                check_index_type=check_index_type,\n                check_less_precise=check_less_precise,\n                check_exact=check_exact,\n                check_names=check_names,\n                check_datetimelike_compat=check_datetimelike_compat,\n                check_categorical=check_categorical,\n                obj=\"{obj}.iloc[:, {idx}]\".format(obj=obj, idx=i),\n            )",
        "begin_line": 1223,
        "end_line": 1400,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.computation.expressions._evaluate_standard#65",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions._evaluate_standard(op, op_str, a, b)",
        "snippet": "def _evaluate_standard(op, op_str, a, b):\n    \"\"\" standard evaluation \"\"\"\n    if _TEST_MODE:\n        _store_test_result(False)\n    with np.errstate(all=\"ignore\"):\n        return op(a, b)",
        "begin_line": 65,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.computation.expressions._has_bool_dtype#160",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions._has_bool_dtype(x)",
        "snippet": "def _has_bool_dtype(x):\n    if isinstance(x, ABCDataFrame):\n        return \"bool\" in x.dtypes\n    try:\n        return x.dtype == bool\n    except AttributeError:\n        return isinstance(x, (bool, np.bool_))",
        "begin_line": 160,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.computation.expressions._bool_arith_check#169",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions._bool_arith_check(op_str, a, b, not_allowed=frozenset(('/', '//', '**')), unsupported=None)",
        "snippet": "def _bool_arith_check(\n    op_str, a, b, not_allowed=frozenset((\"/\", \"//\", \"**\")), unsupported=None\n):\n    if unsupported is None:\n        unsupported = {\"+\": \"|\", \"*\": \"&\", \"-\": \"^\"}\n\n    if _has_bool_dtype(a) and _has_bool_dtype(b):\n        if op_str in unsupported:\n            warnings.warn(\n                \"evaluating in Python space because the {op!r} \"\n                \"operator is not supported by numexpr for \"\n                \"the bool dtype, use {alt_op!r} instead\".format(\n                    op=op_str, alt_op=unsupported[op_str]\n                )\n            )\n            return False\n\n        if op_str in not_allowed:\n            raise NotImplementedError(\n                \"operator {op!r} not implemented for bool dtypes\".format(op=op_str)\n            )\n    return True",
        "begin_line": 169,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.computation.expressions.evaluate#193",
        "src_path": "pandas/core/computation/expressions.py",
        "class_name": "pandas.core.computation.expressions",
        "signature": "pandas.core.computation.expressions.evaluate(op, op_str, a, b, use_numexpr=True)",
        "snippet": "def evaluate(op, op_str, a, b, use_numexpr=True):\n    \"\"\"\n    Evaluate and return the expression of the op on a and b.\n\n    Parameters\n    ----------\n    op : the actual operand\n    op_str : str\n        The string version of the op.\n    a : left operand\n    b : right operand\n    use_numexpr : bool, default True\n        Whether to try to use numexpr.\n    \"\"\"\n\n    use_numexpr = use_numexpr and _bool_arith_check(op_str, a, b)\n    if use_numexpr:\n        return _evaluate(op, op_str, a, b)\n    return _evaluate_standard(op, op_str, a, b)",
        "begin_line": 193,
        "end_line": 211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util._validators.validate_bool_kwarg#234",
        "src_path": "pandas/util/_validators.py",
        "class_name": "pandas.util._validators",
        "signature": "pandas.util._validators.validate_bool_kwarg(value, arg_name)",
        "snippet": "def validate_bool_kwarg(value, arg_name):\n    \"\"\" Ensures that argument passed in arg_name is of type bool. \"\"\"\n    if not (is_bool(value) or value is None):\n        raise ValueError(\n            'For argument \"{arg}\" expected type bool, received '\n            \"type {typ}.\".format(arg=arg_name, typ=type(value).__name__)\n        )\n    return value",
        "begin_line": 234,
        "end_line": 241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.util._validators.validate_fillna_kwargs#340",
        "src_path": "pandas/util/_validators.py",
        "class_name": "pandas.util._validators",
        "signature": "pandas.util._validators.validate_fillna_kwargs(value, method, validate_scalar_dict_value=True)",
        "snippet": "def validate_fillna_kwargs(value, method, validate_scalar_dict_value=True):\n    \"\"\"Validate the keyword arguments to 'fillna'.\n\n    This checks that exactly one of 'value' and 'method' is specified.\n    If 'method' is specified, this validates that it's a valid method.\n\n    Parameters\n    ----------\n    value, method : object\n        The 'value' and 'method' keyword arguments for 'fillna'.\n    validate_scalar_dict_value : bool, default True\n        Whether to validate that 'value' is a scalar or dict. Specifically,\n        validate that it is not a list or tuple.\n\n    Returns\n    -------\n    value, method : object\n    \"\"\"\n    from pandas.core.missing import clean_fill_method\n\n    if value is None and method is None:\n        raise ValueError(\"Must specify a fill 'value' or 'method'.\")\n    elif value is None and method is not None:\n        method = clean_fill_method(method)\n\n    elif value is not None and method is None:\n        if validate_scalar_dict_value and isinstance(value, (list, tuple)):\n            raise TypeError(\n                '\"value\" parameter must be a scalar or dict, but '\n                'you passed a \"{0}\"'.format(type(value).__name__)\n            )\n\n    elif value is not None and method is not None:\n        raise ValueError(\"Cannot specify both 'value' and 'method'.\")\n\n    return value, method",
        "begin_line": 340,
        "end_line": 375,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__init__#197",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__init__(self, data: BlockManager, axes: Optional[List[Index]]=None, copy: bool=False, dtype: Optional[Dtype]=None, attrs: Optional[Mapping[Optional[Hashable], Any]]=None, fastpath: bool=False)",
        "snippet": "    def __init__(\n        self,\n        data: BlockManager,\n        axes: Optional[List[Index]] = None,\n        copy: bool = False,\n        dtype: Optional[Dtype] = None,\n        attrs: Optional[Mapping[Optional[Hashable], Any]] = None,\n        fastpath: bool = False,\n    ):\n\n        if not fastpath:\n            if dtype is not None:\n                data = data.astype(dtype)\n            elif copy:\n                data = data.copy()\n\n            if axes is not None:\n                for i, ax in enumerate(axes):\n                    data = data.reindex_axis(ax, axis=i)\n\n        object.__setattr__(self, \"_is_copy\", None)\n        object.__setattr__(self, \"_data\", data)\n        object.__setattr__(self, \"_item_cache\", {})\n        if attrs is None:\n            attrs = {}\n        else:\n            attrs = dict(attrs)\n        object.__setattr__(self, \"_attrs\", attrs)",
        "begin_line": 197,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.attrs#246",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.attrs(self)",
        "snippet": "    def attrs(self) -> Dict[Optional[Hashable], Any]:\n        \"\"\"\n        Dictionary of global attributes on this object.\n        \"\"\"\n        if self._attrs is None:\n            self._attrs = {}\n        return self._attrs",
        "begin_line": 246,
        "end_line": 252,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._validate_dtype#281",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._validate_dtype(self, dtype)",
        "snippet": "    def _validate_dtype(self, dtype):\n        \"\"\" validate the passed dtype \"\"\"\n\n        if dtype is not None:\n            dtype = pandas_dtype(dtype)\n\n            # a compound dtype\n            if dtype.kind == \"V\":\n                raise NotImplementedError(\n                    \"compound dtypes are not implemented\"\n                    \" in the {0} constructor\".format(self.__class__.__name__)\n                )\n\n        return dtype",
        "begin_line": 281,
        "end_line": 294,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._construct_axes_dict#388",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._construct_axes_dict(self, axes=None, **kwargs)",
        "snippet": "    def _construct_axes_dict(self, axes=None, **kwargs):\n        \"\"\"Return an axes dictionary for myself.\"\"\"\n        d = {a: self._get_axis(a) for a in (axes or self._AXIS_ORDERS)}\n        d.update(kwargs)\n        return d",
        "begin_line": 388,
        "end_line": 392,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_axis_number#456",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_axis_number(cls, axis)",
        "snippet": "    def _get_axis_number(cls, axis):\n        axis = cls._AXIS_ALIASES.get(axis, axis)\n        if is_integer(axis):\n            if axis in cls._AXIS_NAMES:\n                return axis\n        else:\n            try:\n                return cls._AXIS_NUMBERS[axis]\n            except KeyError:\n                pass\n        raise ValueError(\"No axis named {0} for object type {1}\".format(axis, cls))",
        "begin_line": 456,
        "end_line": 466,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_axis_name#469",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_axis_name(cls, axis)",
        "snippet": "    def _get_axis_name(cls, axis):\n        axis = cls._AXIS_ALIASES.get(axis, axis)\n        if isinstance(axis, str):\n            if axis in cls._AXIS_NUMBERS:\n                return axis\n        else:\n            try:\n                return cls._AXIS_NAMES[axis]\n            except KeyError:\n                pass\n        raise ValueError(\"No axis named {0} for object type {1}\".format(axis, cls))",
        "begin_line": 469,
        "end_line": 479,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._get_axis#481",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._get_axis(self, axis)",
        "snippet": "    def _get_axis(self, axis):\n        name = self._get_axis_name(axis)\n        return getattr(self, name)",
        "begin_line": 481,
        "end_line": 483,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._info_axis#542",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._info_axis(self)",
        "snippet": "    def _info_axis(self):\n        return getattr(self, self._info_axis_name)",
        "begin_line": 542,
        "end_line": 543,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.ndim#566",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.ndim(self)",
        "snippet": "    def ndim(self) -> int:\n        \"\"\"\n        Return an int representing the number of axes / array dimensions.\n\n        Return 1 if Series. Otherwise return 2 if DataFrame.\n\n        See Also\n        --------\n        ndarray.ndim : Number of array dimensions.\n\n        Examples\n        --------\n        >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n        >>> s.ndim\n        1\n\n        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n        >>> df.ndim\n        2\n        \"\"\"\n        return self._data.ndim",
        "begin_line": 566,
        "end_line": 586,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__invert__#1562",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__invert__(self)",
        "snippet": "    def __invert__(self):\n        if not self.size:\n            # inv fails with 0 len\n            return self\n\n        arr = operator.inv(com.values_from_object(self))\n        return self.__array_wrap__(arr)",
        "begin_line": 1562,
        "end_line": 1568,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__contains__#1953",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__contains__(self, key)",
        "snippet": "    def __contains__(self, key):\n        \"\"\"True if the key is in the info axis\"\"\"\n        return key in self._info_axis",
        "begin_line": 1953,
        "end_line": 1955,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__array_wrap__#2016",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__array_wrap__(self, result, context=None)",
        "snippet": "    def __array_wrap__(self, result, context=None):\n        d = self._construct_axes_dict(self._AXIS_ORDERS, copy=False)\n        return self._constructor(result, **d).__finalize__(self)",
        "begin_line": 2016,
        "end_line": 2018,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._set_as_cached#3314",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._set_as_cached(self, item, cacher)",
        "snippet": "    def _set_as_cached(self, item, cacher):\n        \"\"\"Set the _cacher attribute on the calling object with a weakref to\n        cacher.\n        \"\"\"\n        self._cacher = (item, weakref.ref(cacher))",
        "begin_line": 3314,
        "end_line": 3318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._maybe_update_cacher#3342",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._maybe_update_cacher(self, clear=False, verify_is_copy=True)",
        "snippet": "    def _maybe_update_cacher(self, clear=False, verify_is_copy=True):\n        \"\"\"\n        See if we need to update our parent cacher if clear, then clear our\n        cache.\n\n        Parameters\n        ----------\n        clear : bool, default False\n            Clear the item cache.\n        verify_is_copy : bool, default True\n            Provide is_copy checks.\n        \"\"\"\n\n        cacher = getattr(self, \"_cacher\", None)\n        if cacher is not None:\n            ref = cacher[1]()\n\n            # we are trying to reference a dead referant, hence\n            # a copy\n            if ref is None:\n                del self._cacher\n            else:\n                # Note: we need to call ref._maybe_cache_changed even in the\n                #  case where it will raise.  (Uh, not clear why)\n                try:\n                    ref._maybe_cache_changed(cacher[0], self)\n                except AssertionError:\n                    # ref._data.setitem can raise\n                    #  AssertionError because of shape mismatch\n                    pass\n\n        if verify_is_copy:\n            self._check_setitem_copy(stacklevel=5, t=\"referant\")\n\n        if clear:\n            self._clear_item_cache()",
        "begin_line": 3342,
        "end_line": 3377,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._clear_item_cache#3379",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._clear_item_cache(self)",
        "snippet": "    def _clear_item_cache(self):\n        self._item_cache.clear()",
        "begin_line": 3379,
        "end_line": 3380,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._check_is_chained_assignment_possible#3697",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._check_is_chained_assignment_possible(self)",
        "snippet": "    def _check_is_chained_assignment_possible(self):\n        \"\"\"\n        Check if we are a view, have a cacher, and are of mixed type.\n        If so, then force a setitem_copy check.\n\n        Should be called just near setting a value\n\n        Will return a boolean if it we are a view and are cached, but a\n        single-dtype meaning that the cacher should be updated following\n        setting.\n        \"\"\"\n        if self._is_view and self._is_cached:\n            ref = self._get_cacher()\n            if ref is not None and ref._is_mixed_type:\n                self._check_setitem_copy(stacklevel=4, t=\"referant\", force=True)\n            return True\n        elif self._is_copy:\n            self._check_setitem_copy(stacklevel=4, t=\"referant\")\n        return False",
        "begin_line": 3697,
        "end_line": 3715,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._check_setitem_copy#3717",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._check_setitem_copy(self, stacklevel=4, t='setting', force=False)",
        "snippet": "    def _check_setitem_copy(self, stacklevel=4, t=\"setting\", force=False):\n        \"\"\"\n\n        Parameters\n        ----------\n        stacklevel : int, default 4\n           the level to show of the stack when the error is output\n        t : str, the type of setting error\n        force : bool, default False\n           If True, then force showing an error.\n\n        validate if we are doing a setitem on a chained copy.\n\n        If you call this function, be sure to set the stacklevel such that the\n        user will see the error *at the level of setting*\n\n        It is technically possible to figure out that we are setting on\n        a copy even WITH a multi-dtyped pandas object. In other words, some\n        blocks may be views while other are not. Currently _is_view will ALWAYS\n        return False for multi-blocks to avoid having to handle this case.\n\n        df = DataFrame(np.arange(0,9), columns=['count'])\n        df['group'] = 'b'\n\n        # This technically need not raise SettingWithCopy if both are view\n        # (which is not # generally guaranteed but is usually True.  However,\n        # this is in general not a good practice and we recommend using .loc.\n        df.iloc[0:5]['group'] = 'a'\n\n        \"\"\"\n\n        # return early if the check is not needed\n        if not (force or self._is_copy):\n            return\n\n        value = config.get_option(\"mode.chained_assignment\")\n        if value is None:\n            return\n\n        # see if the copy is not actually referred; if so, then dissolve\n        # the copy weakref\n        if self._is_copy is not None and not isinstance(self._is_copy, str):\n            r = self._is_copy()\n            if not gc.get_referents(r) or r.shape == self.shape:\n                self._is_copy = None\n                return\n\n        # a custom message\n        if isinstance(self._is_copy, str):\n            t = self._is_copy\n\n        elif t == \"referant\":\n            t = (\n                \"\\n\"\n                \"A value is trying to be set on a copy of a slice from a \"\n                \"DataFrame\\n\\n\"\n                \"See the caveats in the documentation: \"\n                \"http://pandas.pydata.org/pandas-docs/stable/user_guide/\"\n                \"indexing.html#returning-a-view-versus-a-copy\"\n            )\n\n        else:\n            t = (\n                \"\\n\"\n                \"A value is trying to be set on a copy of a slice from a \"\n                \"DataFrame.\\n\"\n                \"Try using .loc[row_indexer,col_indexer] = value \"\n                \"instead\\n\\nSee the caveats in the documentation: \"\n                \"http://pandas.pydata.org/pandas-docs/stable/user_guide/\"\n                \"indexing.html#returning-a-view-versus-a-copy\"\n            )\n\n        if value == \"raise\":\n            raise com.SettingWithCopyError(t)\n        elif value == \"warn\":\n            warnings.warn(t, com.SettingWithCopyWarning, stacklevel=stacklevel)",
        "begin_line": 3717,
        "end_line": 3792,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._is_view#3851",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._is_view(self)",
        "snippet": "    def _is_view(self):\n        \"\"\"Return boolean indicating if self is view of another array \"\"\"\n        return self._data.is_view",
        "begin_line": 3851,
        "end_line": 3853,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__finalize__#5237",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__finalize__(self, other, method=None, **kwargs)",
        "snippet": "    def __finalize__(self, other, method=None, **kwargs):\n        \"\"\"\n        Propagate metadata from other to self.\n\n        Parameters\n        ----------\n        other : the object from which to get the attributes that we are going\n            to propagate\n        method : optional, a passed method name ; possibly to take different\n            types of propagation actions based on this\n\n        \"\"\"\n        if isinstance(other, NDFrame):\n            for name in other.attrs:\n                self.attrs[name] = other.attrs[name]\n            # For subclasses using _metadata.\n            for name in self._metadata:\n                object.__setattr__(self, name, getattr(other, name, None))\n        return self",
        "begin_line": 5237,
        "end_line": 5255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__getattr__#5257",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__getattr__(self, name)",
        "snippet": "    def __getattr__(self, name):\n        \"\"\"After regular attribute access, try looking up the name\n        This allows simpler access to columns for interactive use.\n        \"\"\"\n\n        # Note: obj.x will always call obj.__getattribute__('x') prior to\n        # calling obj.__getattr__('x').\n\n        if (\n            name in self._internal_names_set\n            or name in self._metadata\n            or name in self._accessors\n        ):\n            return object.__getattribute__(self, name)\n        else:\n            if self._info_axis._can_hold_identifiers_and_holds_name(name):\n                return self[name]\n            return object.__getattribute__(self, name)",
        "begin_line": 5257,
        "end_line": 5274,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__setattr__#5276",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__setattr__(self, name, value)",
        "snippet": "    def __setattr__(self, name, value):\n        \"\"\"After regular attribute access, try setting the name\n        This allows simpler access to columns for interactive use.\n        \"\"\"\n\n        # first try regular attribute access via __getattribute__, so that\n        # e.g. ``obj.x`` and ``obj.x = 4`` will always reference/modify\n        # the same attribute.\n\n        try:\n            object.__getattribute__(self, name)\n            return object.__setattr__(self, name, value)\n        except AttributeError:\n            pass\n\n        # if this fails, go on to more involved attribute setting\n        # (note that this matches __getattr__, above).\n        if name in self._internal_names_set:\n            object.__setattr__(self, name, value)\n        elif name in self._metadata:\n            object.__setattr__(self, name, value)\n        else:\n            try:\n                existing = getattr(self, name)\n                if isinstance(existing, Index):\n                    object.__setattr__(self, name, value)\n                elif name in self._info_axis:\n                    self[name] = value\n                else:\n                    object.__setattr__(self, name, value)\n            except (AttributeError, TypeError):\n                if isinstance(self, ABCDataFrame) and (is_list_like(value)):\n                    warnings.warn(\n                        \"Pandas doesn't allow columns to be \"\n                        \"created via a new attribute name - see \"\n                        \"https://pandas.pydata.org/pandas-docs/\"\n                        \"stable/indexing.html#attribute-access\",\n                        stacklevel=2,\n                    )\n                object.__setattr__(self, name, value)",
        "begin_line": 5276,
        "end_line": 5315,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._protect_consolidate#5331",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._protect_consolidate(self, f)",
        "snippet": "    def _protect_consolidate(self, f):\n        \"\"\"Consolidate _data -- if the blocks have changed, then clear the\n        cache\n        \"\"\"\n        blocks_before = len(self._data.blocks)\n        result = f()\n        if len(self._data.blocks) != blocks_before:\n            self._clear_item_cache()\n        return result",
        "begin_line": 5331,
        "end_line": 5339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._consolidate_inplace#5341",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._consolidate_inplace(self)",
        "snippet": "    def _consolidate_inplace(self):\n        \"\"\"Consolidate data in place and return None\"\"\"\n\n        def f():\n            self._data = self._data.consolidate()\n\n        self._protect_consolidate(f)",
        "begin_line": 5341,
        "end_line": 5347,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.f#5344",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.f()",
        "snippet": "        def f():\n            self._data = self._data.consolidate()",
        "begin_line": 5344,
        "end_line": 5345,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.fillna#6179",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)",
        "snippet": "    def fillna(\n        self,\n        value=None,\n        method=None,\n        axis=None,\n        inplace=False,\n        limit=None,\n        downcast=None,\n    ):\n        \"\"\"\n        Fill NA/NaN values using the specified method.\n\n        Parameters\n        ----------\n        value : scalar, dict, Series, or DataFrame\n            Value to use to fill holes (e.g. 0), alternately a\n            dict/Series/DataFrame of values specifying which value to use for\n            each index (for a Series) or column (for a DataFrame).  Values not\n            in the dict/Series/DataFrame will not be filled. This value cannot\n            be a list.\n        method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n            Method to use for filling holes in reindexed Series\n            pad / ffill: propagate last valid observation forward to next valid\n            backfill / bfill: use next valid observation to fill gap.\n        axis : %(axes_single_arg)s\n            Axis along which to fill missing values.\n        inplace : bool, default False\n            If True, fill in-place. Note: this will modify any\n            other views on this object (e.g., a no-copy slice for a column in a\n            DataFrame).\n        limit : int, default None\n            If method is specified, this is the maximum number of consecutive\n            NaN values to forward/backward fill. In other words, if there is\n            a gap with more than this number of consecutive NaNs, it will only\n            be partially filled. If method is not specified, this is the\n            maximum number of entries along the entire axis where NaNs will be\n            filled. Must be greater than 0 if not None.\n        downcast : dict, default is None\n            A dict of item->dtype of what to downcast if possible,\n            or the string 'infer' which will try to downcast to an appropriate\n            equal type (e.g. float64 to int64 if possible).\n\n        Returns\n        -------\n        %(klass)s\n            Object with missing values filled.\n\n        See Also\n        --------\n        interpolate : Fill NaN values using interpolation.\n        reindex : Conform object to new index.\n        asfreq : Convert TimeSeries to specified frequency.\n\n        Examples\n        --------\n        >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n        ...                    [3, 4, np.nan, 1],\n        ...                    [np.nan, np.nan, np.nan, 5],\n        ...                    [np.nan, 3, np.nan, 4]],\n        ...                   columns=list('ABCD'))\n        >>> df\n             A    B   C  D\n        0  NaN  2.0 NaN  0\n        1  3.0  4.0 NaN  1\n        2  NaN  NaN NaN  5\n        3  NaN  3.0 NaN  4\n\n        Replace all NaN elements with 0s.\n\n        >>> df.fillna(0)\n            A   B   C   D\n        0   0.0 2.0 0.0 0\n        1   3.0 4.0 0.0 1\n        2   0.0 0.0 0.0 5\n        3   0.0 3.0 0.0 4\n\n        We can also propagate non-null values forward or backward.\n\n        >>> df.fillna(method='ffill')\n            A   B   C   D\n        0   NaN 2.0 NaN 0\n        1   3.0 4.0 NaN 1\n        2   3.0 4.0 NaN 5\n        3   3.0 3.0 NaN 4\n\n        Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n        2, and 3 respectively.\n\n        >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n        >>> df.fillna(value=values)\n            A   B   C   D\n        0   0.0 2.0 2.0 0\n        1   3.0 4.0 2.0 1\n        2   0.0 1.0 2.0 5\n        3   0.0 3.0 2.0 4\n\n        Only replace the first NaN element.\n\n        >>> df.fillna(value=values, limit=1)\n            A   B   C   D\n        0   0.0 2.0 2.0 0\n        1   3.0 4.0 NaN 1\n        2   NaN 1.0 NaN 5\n        3   NaN 3.0 NaN 4\n        \"\"\"\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\n        value, method = validate_fillna_kwargs(value, method)\n\n        self._consolidate_inplace()\n\n        # set the default here, so functions examining the signaure\n        # can detect if something was set (e.g. in groupby) (GH9221)\n        if axis is None:\n            axis = 0\n        axis = self._get_axis_number(axis)\n\n        if value is None:\n\n            if self._is_mixed_type and axis == 1:\n                if inplace:\n                    raise NotImplementedError()\n                result = self.T.fillna(method=method, limit=limit).T\n\n                # need to downcast here because of all of the transposes\n                result._data = result._data.downcast()\n\n                return result\n\n            new_data = self._data.interpolate(\n                method=method,\n                axis=axis,\n                limit=limit,\n                inplace=inplace,\n                coerce=True,\n                downcast=downcast,\n            )\n        else:\n            if len(self._get_axis(axis)) == 0:\n                return self\n\n            if self.ndim == 1:\n                if isinstance(value, (dict, ABCSeries)):\n                    from pandas import Series\n\n                    value = Series(value)\n                elif not is_list_like(value):\n                    pass\n                else:\n                    raise TypeError(\n                        '\"value\" parameter must be a scalar, dict '\n                        \"or Series, but you passed a \"\n                        '\"{0}\"'.format(type(value).__name__)\n                    )\n\n                new_data = self._data.fillna(\n                    value=value, limit=limit, inplace=inplace, downcast=downcast\n                )\n\n            elif isinstance(value, (dict, ABCSeries)):\n                if axis == 1:\n                    raise NotImplementedError(\n                        \"Currently only can fill \"\n                        \"with dict/Series column \"\n                        \"by column\"\n                    )\n\n                result = self if inplace else self.copy()\n                for k, v in value.items():\n                    if k not in result:\n                        continue\n                    obj = result[k]\n                    obj.fillna(v, limit=limit, inplace=True, downcast=downcast)\n                return result if not inplace else None\n\n            elif not is_list_like(value):\n                new_data = self._data.fillna(\n                    value=value, limit=limit, inplace=inplace, downcast=downcast\n                )\n            elif isinstance(value, ABCDataFrame) and self.ndim == 2:\n                new_data = self.where(self.notna(), value)\n            else:\n                raise ValueError(\"invalid fill value with a %s\" % type(value))\n\n        if inplace:\n            self._update_inplace(new_data)\n        else:\n            return self._constructor(new_data).__finalize__(self)",
        "begin_line": 6179,
        "end_line": 6365,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.isna#7376",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.isna(self)",
        "snippet": "    def isna(self):\n        return isna(self).__finalize__(self)",
        "begin_line": 7376,
        "end_line": 7377,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic._make_min_count_stat_function#11556",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic",
        "signature": "pandas.core.generic._make_min_count_stat_function(cls, name, name1, name2, axis_descr, desc, f, see_also='', examples='')",
        "snippet": "def _make_min_count_stat_function(\n    cls, name, name1, name2, axis_descr, desc, f, see_also=\"\", examples=\"\"\n):\n    @Substitution(\n        desc=desc,\n        name1=name1,\n        name2=name2,\n        axis_descr=axis_descr,\n        min_count=_min_count_stub,\n        see_also=see_also,\n        examples=examples,\n    )\n    @Appender(_num_doc)\n    def stat_func(\n        self,\n        axis=None,\n        skipna=None,\n        level=None,\n        numeric_only=None,\n        min_count=0,\n        **kwargs,\n    ):\n        if name == \"sum\":\n            nv.validate_sum(tuple(), kwargs)\n        elif name == \"prod\":\n            nv.validate_prod(tuple(), kwargs)\n        else:\n            nv.validate_stat_func(tuple(), kwargs, fname=name)\n        if skipna is None:\n            skipna = True\n        if axis is None:\n            axis = self._stat_axis_number\n        if level is not None:\n            return self._agg_by_level(\n                name, axis=axis, level=level, skipna=skipna, min_count=min_count\n            )\n        return self._reduce(\n            f,\n            name,\n            axis=axis,\n            skipna=skipna,\n            numeric_only=numeric_only,\n            min_count=min_count,\n        )\n\n    return set_function_name(stat_func, name, cls)",
        "begin_line": 11556,
        "end_line": 11601,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.stat_func#11569",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic",
        "signature": "pandas.core.generic.stat_func(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)",
        "snippet": "    def stat_func(\n        self,\n        axis=None,\n        skipna=None,\n        level=None,\n        numeric_only=None,\n        min_count=0,\n        **kwargs,\n    ):\n        if name == \"sum\":\n            nv.validate_sum(tuple(), kwargs)\n        elif name == \"prod\":\n            nv.validate_prod(tuple(), kwargs)\n        else:\n            nv.validate_stat_func(tuple(), kwargs, fname=name)\n        if skipna is None:\n            skipna = True\n        if axis is None:\n            axis = self._stat_axis_number\n        if level is not None:\n            return self._agg_by_level(\n                name, axis=axis, level=level, skipna=skipna, min_count=min_count\n            )\n        return self._reduce(\n            f,\n            name,\n            axis=axis,\n            skipna=skipna,\n            numeric_only=numeric_only,\n            min_count=min_count,\n        )",
        "begin_line": 11569,
        "end_line": 11599,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic._make_logical_function#11709",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic",
        "signature": "pandas.core.generic._make_logical_function(cls, name, name1, name2, axis_descr, desc, f, see_also, examples, empty_value)",
        "snippet": "def _make_logical_function(\n    cls, name, name1, name2, axis_descr, desc, f, see_also, examples, empty_value\n):\n    @Substitution(\n        desc=desc,\n        name1=name1,\n        name2=name2,\n        axis_descr=axis_descr,\n        see_also=see_also,\n        examples=examples,\n        empty_value=empty_value,\n    )\n    @Appender(_bool_doc)\n    def logical_func(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs):\n        nv.validate_logical_func(tuple(), kwargs, fname=name)\n        if level is not None:\n            if bool_only is not None:\n                raise NotImplementedError(\n                    \"Option bool_only is not implemented with option level.\"\n                )\n            return self._agg_by_level(name, axis=axis, level=level, skipna=skipna)\n        return self._reduce(\n            f,\n            name,\n            axis=axis,\n            skipna=skipna,\n            numeric_only=bool_only,\n            filter_type=\"bool\",\n        )\n\n    return set_function_name(logical_func, name, cls)",
        "begin_line": 11709,
        "end_line": 11739,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas.core.generic.logical_func#11722",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic",
        "signature": "pandas.core.generic.logical_func(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)",
        "snippet": "    def logical_func(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs):\n        nv.validate_logical_func(tuple(), kwargs, fname=name)\n        if level is not None:\n            if bool_only is not None:\n                raise NotImplementedError(\n                    \"Option bool_only is not implemented with option level.\"\n                )\n            return self._agg_by_level(name, axis=axis, level=level, skipna=skipna)\n        return self._reduce(\n            f,\n            name,\n            axis=axis,\n            skipna=skipna,\n            numeric_only=bool_only,\n            filter_type=\"bool\",\n        )",
        "begin_line": 11722,
        "end_line": 11737,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config._get_single_key#83",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_single_key(pat, silent)",
        "snippet": "def _get_single_key(pat, silent):\n    keys = _select_options(pat)\n    if len(keys) == 0:\n        if not silent:\n            _warn_if_deprecated(pat)\n        raise OptionError(\"No such keys(s): {pat!r}\".format(pat=pat))\n    if len(keys) > 1:\n        raise OptionError(\"Pattern matched multiple keys\")\n    key = keys[0]\n\n    if not silent:\n        _warn_if_deprecated(key)\n\n    key = _translate_key(key)\n\n    return key",
        "begin_line": 83,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config._get_option#101",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_option(pat, silent=False)",
        "snippet": "def _get_option(pat, silent=False):\n    key = _get_single_key(pat, silent)\n\n    # walk the nested dict\n    root, k = _get_root(key)\n    return root[k]",
        "begin_line": 101,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config._set_option#109",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._set_option(*args, **kwargs)",
        "snippet": "def _set_option(*args, **kwargs):\n    # must at least 1 arg deal with constraints later\n    nargs = len(args)\n    if not nargs or nargs % 2 != 0:\n        raise ValueError(\"Must provide an even number of non-keyword arguments\")\n\n    # default to false\n    silent = kwargs.pop(\"silent\", False)\n\n    if kwargs:\n        msg = '_set_option() got an unexpected keyword argument \"{kwarg}\"'\n        raise TypeError(msg.format(list(kwargs.keys())[0]))\n\n    for k, v in zip(args[::2], args[1::2]):\n        key = _get_single_key(k, silent)\n\n        o = _get_registered_option(key)\n        if o and o.validator:\n            o.validator(v)\n\n        # walk the nested dict\n        root, k = _get_root(key)\n        root[k] = v\n\n        if o.cb:\n            if silent:\n                with warnings.catch_warnings(record=True):\n                    o.cb(key)\n            else:\n                o.cb(key)",
        "begin_line": 109,
        "end_line": 138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config.CallableDynamicDoc.__call__#232",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config.CallableDynamicDoc",
        "signature": "pandas._config.config.CallableDynamicDoc.__call__(self, *args, **kwds)",
        "snippet": "    def __call__(self, *args, **kwds):\n        return self.__func__(*args, **kwds)",
        "begin_line": 232,
        "end_line": 233,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config._select_options#535",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._select_options(pat)",
        "snippet": "def _select_options(pat):\n    \"\"\"returns a list of keys matching `pat`\n\n    if pat==\"all\", returns all registered options\n    \"\"\"\n\n    # short-circuit for exact key\n    if pat in _registered_options:\n        return [pat]\n\n    # else look through all of them\n    keys = sorted(_registered_options.keys())\n    if pat == \"all\":  # reserved key\n        return keys\n\n    return [k for k in keys if re.search(pat, k, re.I)]",
        "begin_line": 535,
        "end_line": 550,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config._get_root#553",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_root(key)",
        "snippet": "def _get_root(key):\n    path = key.split(\".\")\n    cursor = _global_config\n    for p in path[:-1]:\n        cursor = cursor[p]\n    return cursor, path[-1]",
        "begin_line": 553,
        "end_line": 558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config._get_deprecated_option#568",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_deprecated_option(key)",
        "snippet": "def _get_deprecated_option(key):\n    \"\"\"\n    Retrieves the metadata for a deprecated option, if `key` is deprecated.\n\n    Returns\n    -------\n    DeprecatedOption (namedtuple) if key is deprecated, None otherwise\n    \"\"\"\n\n    try:\n        d = _deprecated_options[key]\n    except KeyError:\n        return None\n    else:\n        return d",
        "begin_line": 568,
        "end_line": 582,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config._get_registered_option#585",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_registered_option(key)",
        "snippet": "def _get_registered_option(key):\n    \"\"\"\n    Retrieves the option metadata if `key` is a registered option.\n\n    Returns\n    -------\n    RegisteredOption (namedtuple) if key is deprecated, None otherwise\n    \"\"\"\n    return _registered_options.get(key)",
        "begin_line": 585,
        "end_line": 593,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config._translate_key#596",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._translate_key(key)",
        "snippet": "def _translate_key(key):\n    \"\"\"\n    if key id deprecated and a replacement key defined, will return the\n    replacement key, otherwise returns `key` as - is\n    \"\"\"\n\n    d = _get_deprecated_option(key)\n    if d:\n        return d.rkey or key\n    else:\n        return key",
        "begin_line": 596,
        "end_line": 606,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config._warn_if_deprecated#609",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._warn_if_deprecated(key)",
        "snippet": "def _warn_if_deprecated(key):\n    \"\"\"\n    Checks if `key` is a deprecated option and if so, prints a warning.\n\n    Returns\n    -------\n    bool - True if `key` is deprecated, False otherwise.\n    \"\"\"\n\n    d = _get_deprecated_option(key)\n    if d:\n        if d.msg:\n            print(d.msg)\n            warnings.warn(d.msg, FutureWarning)\n        else:\n            msg = \"'{key}' is deprecated\".format(key=key)\n            if d.removal_ver:\n                msg += \" and will be removed in {version}\".format(version=d.removal_ver)\n            if d.rkey:\n                msg += \", please use '{rkey}' instead.\".format(rkey=d.rkey)\n            else:\n                msg += \", please refrain from using it.\"\n\n            warnings.warn(msg, FutureWarning)\n        return True\n    return False",
        "begin_line": 609,
        "end_line": 634,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02631578947368421,
            "pseudo_dstar_susp": 0.02631578947368421,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.02631578947368421,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    },
    {
        "name": "pandas._config.config.inner#810",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config.inner(x)",
        "snippet": "    def inner(x):\n        if x not in legal_values:\n\n            if not any(c(x) for c in callables):\n                uvals = [str(lval) for lval in legal_values]\n                pp_values = \"|\".join(uvals)\n                msg = \"Value must be one of {pp_values}\"\n                if len(callables):\n                    msg += \" or a callable\"\n                raise ValueError(msg.format(pp_values=pp_values))",
        "begin_line": 810,
        "end_line": 819,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008163265306122449,
            "pseudo_dstar_susp": 0.0008163265306122449,
            "pseudo_tarantula_susp": 0.0008424599831508003,
            "pseudo_op2_susp": 0.0008163265306122449,
            "pseudo_barinel_susp": 0.0008424599831508003
        }
    }
]