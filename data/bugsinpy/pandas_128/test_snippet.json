[
    {
        "name": "pandas.tests.io.json.test_readlines.lines_json_df#13",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.lines_json_df()",
        "snippet": "def lines_json_df():\n    df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n    return df.to_json(lines=True, orient=\"records\")",
        "begin_line": 13,
        "end_line": 15,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_read_jsonl#18",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_read_jsonl()",
        "snippet": "def test_read_jsonl():\n    # GH9180\n    result = read_json('{\"a\": 1, \"b\": 2}\\n{\"b\":2, \"a\" :1}\\n', lines=True)\n    expected = DataFrame([[1, 2], [1, 2]], columns=[\"a\", \"b\"])\n    tm.assert_frame_equal(result, expected)",
        "begin_line": 18,
        "end_line": 22,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_read_jsonl_unicode_chars#25",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_read_jsonl_unicode_chars()",
        "snippet": "def test_read_jsonl_unicode_chars():\n    # GH15132: non-ascii unicode characters\n    # \\u201d == RIGHT DOUBLE QUOTATION MARK\n\n    # simulate file handle\n    json = '{\"a\": \"foo\u201d\", \"b\": \"bar\"}\\n{\"a\": \"foo\", \"b\": \"bar\"}\\n'\n    json = StringIO(json)\n    result = read_json(json, lines=True)\n    expected = DataFrame([[\"foo\\u201d\", \"bar\"], [\"foo\", \"bar\"]], columns=[\"a\", \"b\"])\n    tm.assert_frame_equal(result, expected)\n\n    # simulate string\n    json = '{\"a\": \"foo\u201d\", \"b\": \"bar\"}\\n{\"a\": \"foo\", \"b\": \"bar\"}\\n'\n    result = read_json(json, lines=True)\n    expected = DataFrame([[\"foo\\u201d\", \"bar\"], [\"foo\", \"bar\"]], columns=[\"a\", \"b\"])\n    tm.assert_frame_equal(result, expected)",
        "begin_line": 25,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_to_jsonl#43",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_to_jsonl()",
        "snippet": "def test_to_jsonl():\n    # GH9180\n    df = DataFrame([[1, 2], [1, 2]], columns=[\"a\", \"b\"])\n    result = df.to_json(orient=\"records\", lines=True)\n    expected = '{\"a\":1,\"b\":2}\\n{\"a\":1,\"b\":2}'\n    assert result == expected\n\n    df = DataFrame([[\"foo}\", \"bar\"], ['foo\"', \"bar\"]], columns=[\"a\", \"b\"])\n    result = df.to_json(orient=\"records\", lines=True)\n    expected = '{\"a\":\"foo}\",\"b\":\"bar\"}\\n{\"a\":\"foo\\\\\"\",\"b\":\"bar\"}'\n    assert result == expected\n    tm.assert_frame_equal(read_json(result, lines=True), df)\n\n    # GH15096: escaped characters in columns and data\n    df = DataFrame([[\"foo\\\\\", \"bar\"], ['foo\"', \"bar\"]], columns=[\"a\\\\\", \"b\"])\n    result = df.to_json(orient=\"records\", lines=True)\n    expected = '{\"a\\\\\\\\\":\"foo\\\\\\\\\",\"b\":\"bar\"}\\n' '{\"a\\\\\\\\\":\"foo\\\\\"\",\"b\":\"bar\"}'\n    assert result == expected\n    tm.assert_frame_equal(read_json(result, lines=True), df)",
        "begin_line": 43,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_readjson_chunks#65",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_readjson_chunks(lines_json_df, chunksize)",
        "snippet": "def test_readjson_chunks(lines_json_df, chunksize):\n    # Basic test that read_json(chunks=True) gives the same result as\n    # read_json(chunks=False)\n    # GH17048: memory usage when lines=True\n\n    unchunked = read_json(StringIO(lines_json_df), lines=True)\n    reader = read_json(StringIO(lines_json_df), lines=True, chunksize=chunksize)\n    chunked = pd.concat(reader)\n\n    tm.assert_frame_equal(chunked, unchunked)",
        "begin_line": 65,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_readjson_chunksize_requires_lines#77",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_readjson_chunksize_requires_lines(lines_json_df)",
        "snippet": "def test_readjson_chunksize_requires_lines(lines_json_df):\n    msg = \"chunksize can only be passed if lines=True\"\n    with pytest.raises(ValueError, match=msg):\n        pd.read_json(StringIO(lines_json_df), lines=False, chunksize=2)",
        "begin_line": 77,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_readjson_chunks_series#83",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_readjson_chunks_series()",
        "snippet": "def test_readjson_chunks_series():\n    # Test reading line-format JSON to Series with chunksize param\n    s = pd.Series({\"A\": 1, \"B\": 2})\n\n    strio = StringIO(s.to_json(lines=True, orient=\"records\"))\n    unchunked = pd.read_json(strio, lines=True, typ=\"Series\")\n\n    strio = StringIO(s.to_json(lines=True, orient=\"records\"))\n    chunked = pd.concat(pd.read_json(strio, lines=True, typ=\"Series\", chunksize=1))\n\n    tm.assert_series_equal(chunked, unchunked)",
        "begin_line": 83,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_readjson_each_chunk#96",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_readjson_each_chunk(lines_json_df)",
        "snippet": "def test_readjson_each_chunk(lines_json_df):\n    # Other tests check that the final result of read_json(chunksize=True)\n    # is correct. This checks the intermediate chunks.\n    chunks = list(pd.read_json(StringIO(lines_json_df), lines=True, chunksize=2))\n    assert chunks[0].shape == (2, 2)\n    assert chunks[1].shape == (1, 2)",
        "begin_line": 96,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_readjson_chunks_from_file#104",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_readjson_chunks_from_file()",
        "snippet": "def test_readjson_chunks_from_file():\n    with tm.ensure_clean(\"test.json\") as path:\n        df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n        df.to_json(path, lines=True, orient=\"records\")\n        chunked = pd.concat(pd.read_json(path, lines=True, chunksize=1))\n        unchunked = pd.read_json(path, lines=True)\n        tm.assert_frame_equal(unchunked, chunked)",
        "begin_line": 104,
        "end_line": 110,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_readjson_chunks_closes#114",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_readjson_chunks_closes(chunksize)",
        "snippet": "def test_readjson_chunks_closes(chunksize):\n    with tm.ensure_clean(\"test.json\") as path:\n        df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n        df.to_json(path, lines=True, orient=\"records\")\n        reader = JsonReader(\n            path,\n            orient=None,\n            typ=\"frame\",\n            dtype=True,\n            convert_axes=True,\n            convert_dates=True,\n            keep_default_dates=True,\n            numpy=False,\n            precise_float=False,\n            date_unit=None,\n            encoding=None,\n            lines=True,\n            chunksize=chunksize,\n            compression=None,\n        )\n        reader.read()\n        assert (\n            reader.open_stream.closed\n        ), \"didn't close stream with \\\n            chunksize = {chunksize}\".format(\n            chunksize=chunksize\n        )",
        "begin_line": 114,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_readjson_invalid_chunksize#144",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_readjson_invalid_chunksize(lines_json_df, chunksize)",
        "snippet": "def test_readjson_invalid_chunksize(lines_json_df, chunksize):\n    msg = r\"'chunksize' must be an integer >=1\"\n\n    with pytest.raises(ValueError, match=msg):\n        pd.read_json(StringIO(lines_json_df), lines=True, chunksize=chunksize)",
        "begin_line": 144,
        "end_line": 148,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_readjson_chunks_multiple_empty_lines#152",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_readjson_chunks_multiple_empty_lines(chunksize)",
        "snippet": "def test_readjson_chunks_multiple_empty_lines(chunksize):\n    j = \"\"\"\n\n    {\"A\":1,\"B\":4}\n\n\n\n    {\"A\":2,\"B\":5}\n\n\n\n\n\n\n\n    {\"A\":3,\"B\":6}\n    \"\"\"\n    orig = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n    test = pd.read_json(j, lines=True, chunksize=chunksize)\n    if chunksize is not None:\n        test = pd.concat(test)\n    tm.assert_frame_equal(\n        orig, test, obj=\"chunksize: {chunksize}\".format(chunksize=chunksize)\n    )",
        "begin_line": 152,
        "end_line": 175,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.test_readlines.test_readjson_unicode#178",
        "src_path": "pandas/tests/io/json/test_readlines.py",
        "class_name": "pandas.tests.io.json.test_readlines",
        "signature": "pandas.tests.io.json.test_readlines.test_readjson_unicode(monkeypatch)",
        "snippet": "def test_readjson_unicode(monkeypatch):\n    with tm.ensure_clean(\"test.json\") as path:\n        monkeypatch.setattr(\"_bootlocale.getpreferredencoding\", lambda l: \"cp949\")\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            f.write('{\"\u00a3\u00a9\u00b5\u00c0\u00c6\u00d6\u00de\u00df\u00e9\u00f6\u00ff\":[\"\u0410\u0411\u0412\u0413\u0414\u0430\u0431\u0432\u0433\u0434\uac00\"]}')\n\n        result = read_json(path)\n        expected = pd.DataFrame({\"\u00a3\u00a9\u00b5\u00c0\u00c6\u00d6\u00de\u00df\u00e9\u00f6\u00ff\": [\"\u0410\u0411\u0412\u0413\u0414\u0430\u0431\u0432\u0433\u0434\uac00\"]})\n        tm.assert_frame_equal(result, expected)",
        "begin_line": 178,
        "end_line": 186,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.frame#9",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.frame(float_frame)",
        "snippet": "def frame(float_frame):\n    \"\"\"\n    Returns the first ten items in fixture \"float_frame\".\n    \"\"\"\n    return float_frame[:10]",
        "begin_line": 9,
        "end_line": 13,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.tsframe#17",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.tsframe()",
        "snippet": "def tsframe():\n    return tm.makeTimeDataFrame()[:5]",
        "begin_line": 17,
        "end_line": 18,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.merge_cells#22",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.merge_cells(request)",
        "snippet": "def merge_cells(request):\n    return request.param",
        "begin_line": 22,
        "end_line": 23,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.df_ref#27",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.df_ref()",
        "snippet": "def df_ref():\n    \"\"\"\n    Obtain the reference data from read_csv with the Python engine.\n    \"\"\"\n    df_ref = read_csv(\"test1.csv\", index_col=0, parse_dates=True, engine=\"python\")\n    return df_ref",
        "begin_line": 27,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.read_ext#36",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.read_ext(request)",
        "snippet": "def read_ext(request):\n    \"\"\"\n    Valid extensions for reading Excel files.\n    \"\"\"\n    return request.param",
        "begin_line": 36,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.pytables.conftest.setup_mode#13",
        "src_path": "pandas/tests/io/pytables/conftest.py",
        "class_name": "pandas.tests.io.pytables.conftest",
        "signature": "pandas.tests.io.pytables.conftest.setup_mode()",
        "snippet": "def setup_mode():\n    \"\"\" Reset testing mode fixture\"\"\"\n    tm.reset_testing_mode()\n    yield\n    tm.set_testing_mode()",
        "begin_line": 13,
        "end_line": 17,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.conftest.salaries_table#23",
        "src_path": "pandas/tests/io/conftest.py",
        "class_name": "pandas.tests.io.conftest",
        "signature": "pandas.tests.io.conftest.salaries_table(datapath)",
        "snippet": "def salaries_table(datapath):\n    \"\"\"DataFrame with the salaries dataset\"\"\"\n    return read_csv(datapath(\"io\", \"parser\", \"data\", \"salaries.csv\"), sep=\"\\t\")",
        "begin_line": 23,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.update_kwargs#14",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.update_kwargs(self, kwargs)",
        "snippet": "    def update_kwargs(self, kwargs):\n        kwargs = kwargs.copy()\n        kwargs.update(dict(engine=self.engine, low_memory=self.low_memory))\n\n        return kwargs",
        "begin_line": 14,
        "end_line": 18,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.read_csv#20",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.read_csv(self, *args, **kwargs)",
        "snippet": "    def read_csv(self, *args, **kwargs):\n        kwargs = self.update_kwargs(kwargs)\n        return read_csv(*args, **kwargs)",
        "begin_line": 20,
        "end_line": 22,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.read_table#24",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.read_table(self, *args, **kwargs)",
        "snippet": "    def read_table(self, *args, **kwargs):\n        kwargs = self.update_kwargs(kwargs)\n        return read_table(*args, **kwargs)",
        "begin_line": 24,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.csv_dir_path#48",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.csv_dir_path(datapath)",
        "snippet": "def csv_dir_path(datapath):\n    return datapath(\"io\", \"parser\", \"data\")",
        "begin_line": 48,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.csv1#53",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.csv1(csv_dir_path)",
        "snippet": "def csv1(csv_dir_path):\n    return os.path.join(csv_dir_path, \"test1.csv\")",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.all_parsers#71",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.all_parsers(request)",
        "snippet": "def all_parsers(request):\n    return request.param",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.c_parser_only#76",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.c_parser_only(request)",
        "snippet": "def c_parser_only(request):\n    return request.param",
        "begin_line": 76,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.python_parser_only#81",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.python_parser_only(request)",
        "snippet": "def python_parser_only(request):\n    return request.param",
        "begin_line": 81,
        "end_line": 82,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.conftest.orient#5",
        "src_path": "pandas/tests/io/json/conftest.py",
        "class_name": "pandas.tests.io.json.conftest",
        "signature": "pandas.tests.io.json.conftest.orient(request)",
        "snippet": "def orient(request):\n    \"\"\"\n    Fixture for orients excluding the table format.\n    \"\"\"\n    return request.param",
        "begin_line": 5,
        "end_line": 9,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_series#97",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_series()",
        "snippet": "def _create_sp_series():\n    nan = np.nan\n\n    # nan-based\n    arr = np.arange(15, dtype=np.float64)\n    arr[7:12] = nan\n    arr[-1:] = nan\n\n    bseries = Series(SparseArray(arr, kind=\"block\"))\n    bseries.name = \"bseries\"\n    return bseries",
        "begin_line": 97,
        "end_line": 107,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_tsseries#110",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_tsseries()",
        "snippet": "def _create_sp_tsseries():\n    nan = np.nan\n\n    # nan-based\n    arr = np.arange(15, dtype=np.float64)\n    arr[7:12] = nan\n    arr[-1:] = nan\n\n    date_index = bdate_range(\"1/1/2011\", periods=len(arr))\n    bseries = Series(SparseArray(arr, kind=\"block\"), index=date_index)\n    bseries.name = \"btsseries\"\n    return bseries",
        "begin_line": 110,
        "end_line": 121,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_frame#124",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_frame()",
        "snippet": "def _create_sp_frame():\n    nan = np.nan\n\n    data = {\n        \"A\": [nan, nan, nan, 0, 1, 2, 3, 4, 5, 6],\n        \"B\": [0, 1, 2, nan, nan, nan, 3, 4, 5, 6],\n        \"C\": np.arange(10).astype(np.int64),\n        \"D\": [0, 1, 2, 3, 4, 5, nan, nan, nan, nan],\n    }\n\n    dates = bdate_range(\"1/1/2011\", periods=10)\n    return DataFrame(data, index=dates).apply(SparseArray)",
        "begin_line": 124,
        "end_line": 135,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.create_data#138",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.create_data()",
        "snippet": "def create_data():\n    \"\"\" create the pickle/msgpack data \"\"\"\n\n    data = {\n        \"A\": [0.0, 1.0, 2.0, 3.0, np.nan],\n        \"B\": [0, 1, 0, 1, 0],\n        \"C\": [\"foo1\", \"foo2\", \"foo3\", \"foo4\", \"foo5\"],\n        \"D\": date_range(\"1/1/2009\", periods=5),\n        \"E\": [0.0, 1, Timestamp(\"20100101\"), \"foo\", 2.0],\n    }\n\n    scalars = dict(timestamp=Timestamp(\"20130101\"), period=Period(\"2012\", \"M\"))\n\n    index = dict(\n        int=Index(np.arange(10)),\n        date=date_range(\"20130101\", periods=10),\n        period=period_range(\"2013-01-01\", freq=\"M\", periods=10),\n        float=Index(np.arange(10, dtype=np.float64)),\n        uint=Index(np.arange(10, dtype=np.uint64)),\n        timedelta=timedelta_range(\"00:00:00\", freq=\"30T\", periods=10),\n    )\n\n    index[\"range\"] = RangeIndex(10)\n\n    if _loose_version >= LooseVersion(\"0.21\"):\n        from pandas import interval_range\n\n        index[\"interval\"] = interval_range(0, periods=10)\n\n    mi = dict(\n        reg2=MultiIndex.from_tuples(\n            tuple(\n                zip(\n                    *[\n                        [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n                        [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n                    ]\n                )\n            ),\n            names=[\"first\", \"second\"],\n        )\n    )\n\n    series = dict(\n        float=Series(data[\"A\"]),\n        int=Series(data[\"B\"]),\n        mixed=Series(data[\"E\"]),\n        ts=Series(\n            np.arange(10).astype(np.int64), index=date_range(\"20130101\", periods=10)\n        ),\n        mi=Series(\n            np.arange(5).astype(np.float64),\n            index=MultiIndex.from_tuples(\n                tuple(zip(*[[1, 1, 2, 2, 2], [3, 4, 3, 4, 5]])), names=[\"one\", \"two\"]\n            ),\n        ),\n        dup=Series(np.arange(5).astype(np.float64), index=[\"A\", \"B\", \"C\", \"D\", \"A\"]),\n        cat=Series(Categorical([\"foo\", \"bar\", \"baz\"])),\n        dt=Series(date_range(\"20130101\", periods=5)),\n        dt_tz=Series(date_range(\"20130101\", periods=5, tz=\"US/Eastern\")),\n        period=Series([Period(\"2000Q1\")] * 5),\n    )\n\n    mixed_dup_df = DataFrame(data)\n    mixed_dup_df.columns = list(\"ABCDA\")\n    frame = dict(\n        float=DataFrame({\"A\": series[\"float\"], \"B\": series[\"float\"] + 1}),\n        int=DataFrame({\"A\": series[\"int\"], \"B\": series[\"int\"] + 1}),\n        mixed=DataFrame({k: data[k] for k in [\"A\", \"B\", \"C\", \"D\"]}),\n        mi=DataFrame(\n            {\"A\": np.arange(5).astype(np.float64), \"B\": np.arange(5).astype(np.int64)},\n            index=MultiIndex.from_tuples(\n                tuple(\n                    zip(\n                        *[\n                            [\"bar\", \"bar\", \"baz\", \"baz\", \"baz\"],\n                            [\"one\", \"two\", \"one\", \"two\", \"three\"],\n                        ]\n                    )\n                ),\n                names=[\"first\", \"second\"],\n            ),\n        ),\n        dup=DataFrame(\n            np.arange(15).reshape(5, 3).astype(np.float64), columns=[\"A\", \"B\", \"A\"]\n        ),\n        cat_onecol=DataFrame({\"A\": Categorical([\"foo\", \"bar\"])}),\n        cat_and_float=DataFrame(\n            {\n                \"A\": Categorical([\"foo\", \"bar\", \"baz\"]),\n                \"B\": np.arange(3).astype(np.int64),\n            }\n        ),\n        mixed_dup=mixed_dup_df,\n        dt_mixed_tzs=DataFrame(\n            {\n                \"A\": Timestamp(\"20130102\", tz=\"US/Eastern\"),\n                \"B\": Timestamp(\"20130603\", tz=\"CET\"),\n            },\n            index=range(5),\n        ),\n        dt_mixed2_tzs=DataFrame(\n            {\n                \"A\": Timestamp(\"20130102\", tz=\"US/Eastern\"),\n                \"B\": Timestamp(\"20130603\", tz=\"CET\"),\n                \"C\": Timestamp(\"20130603\", tz=\"UTC\"),\n            },\n            index=range(5),\n        ),\n    )\n\n    cat = dict(\n        int8=Categorical(list(\"abcdefg\")),\n        int16=Categorical(np.arange(1000)),\n        int32=Categorical(np.arange(10000)),\n    )\n\n    timestamp = dict(\n        normal=Timestamp(\"2011-01-01\"),\n        nat=NaT,\n        tz=Timestamp(\"2011-01-01\", tz=\"US/Eastern\"),\n    )\n\n    timestamp[\"freq\"] = Timestamp(\"2011-01-01\", freq=\"D\")\n    timestamp[\"both\"] = Timestamp(\"2011-01-01\", tz=\"Asia/Tokyo\", freq=\"M\")\n\n    off = {\n        \"DateOffset\": DateOffset(years=1),\n        \"DateOffset_h_ns\": DateOffset(hour=6, nanoseconds=5824),\n        \"BusinessDay\": BusinessDay(offset=timedelta(seconds=9)),\n        \"BusinessHour\": BusinessHour(normalize=True, n=6, end=\"15:14\"),\n        \"CustomBusinessDay\": CustomBusinessDay(weekmask=\"Mon Fri\"),\n        \"SemiMonthBegin\": SemiMonthBegin(day_of_month=9),\n        \"SemiMonthEnd\": SemiMonthEnd(day_of_month=24),\n        \"MonthBegin\": MonthBegin(1),\n        \"MonthEnd\": MonthEnd(1),\n        \"QuarterBegin\": QuarterBegin(1),\n        \"QuarterEnd\": QuarterEnd(1),\n        \"Day\": Day(1),\n        \"YearBegin\": YearBegin(1),\n        \"YearEnd\": YearEnd(1),\n        \"Week\": Week(1),\n        \"Week_Tues\": Week(2, normalize=False, weekday=1),\n        \"WeekOfMonth\": WeekOfMonth(week=3, weekday=4),\n        \"LastWeekOfMonth\": LastWeekOfMonth(n=1, weekday=3),\n        \"FY5253\": FY5253(n=2, weekday=6, startingMonth=7, variation=\"last\"),\n        \"Easter\": Easter(),\n        \"Hour\": Hour(1),\n        \"Minute\": Minute(1),\n    }\n\n    return dict(\n        series=series,\n        frame=frame,\n        index=index,\n        scalars=scalars,\n        mi=mi,\n        sp_series=dict(float=_create_sp_series(), ts=_create_sp_tsseries()),\n        sp_frame=dict(float=_create_sp_frame()),\n        cat=cat,\n        timestamp=timestamp,\n        offsets=off,\n    )",
        "begin_line": 138,
        "end_line": 300,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.create_pickle_data#303",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.create_pickle_data()",
        "snippet": "def create_pickle_data():\n    data = create_data()\n\n    return data",
        "begin_line": 303,
        "end_line": 306,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._u#309",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._u(x)",
        "snippet": "def _u(x):\n    return {k: _u(x[k]) for k in x} if isinstance(x, dict) else x",
        "begin_line": 309,
        "end_line": 310,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.create_msgpack_data#313",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.create_msgpack_data()",
        "snippet": "def create_msgpack_data():\n    data = create_data()\n    # Not supported\n    del data[\"sp_series\"]\n    del data[\"sp_frame\"]\n    del data[\"series\"][\"cat\"]\n    del data[\"series\"][\"period\"]\n    del data[\"frame\"][\"cat_onecol\"]\n    del data[\"frame\"][\"cat_and_float\"]\n    del data[\"scalars\"][\"period\"]\n    if _loose_version >= LooseVersion(\"0.21\") and (\n        _loose_version < LooseVersion(\"0.23.0\")\n    ):\n        del data[\"index\"][\"interval\"]\n    del data[\"offsets\"]\n    return _u(data)",
        "begin_line": 313,
        "end_line": 328,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.platform_name#331",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.platform_name()",
        "snippet": "def platform_name():\n    return \"_\".join(\n        [\n            str(pandas.__version__),\n            str(pl.machine()),\n            str(pl.system().lower()),\n            str(pl.python_version()),\n        ]\n    )",
        "begin_line": 331,
        "end_line": 339,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.write_legacy_pickles#342",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.write_legacy_pickles(output_dir)",
        "snippet": "def write_legacy_pickles(output_dir):\n\n    version = pandas.__version__\n\n    print(\n        \"This script generates a storage file for the current arch, system, \"\n        \"and python version\"\n    )\n    print(\"  pandas version: {0}\".format(version))\n    print(\"  output dir    : {0}\".format(output_dir))\n    print(\"  storage format: pickle\")\n\n    pth = \"{0}.pickle\".format(platform_name())\n\n    fh = open(os.path.join(output_dir, pth), \"wb\")\n    pickle.dump(create_pickle_data(), fh, pickle.HIGHEST_PROTOCOL)\n    fh.close()\n\n    print(\"created pickle file: {pth}\".format(pth=pth))",
        "begin_line": 342,
        "end_line": 360,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.write_legacy_msgpack#363",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.write_legacy_msgpack(output_dir, compress)",
        "snippet": "def write_legacy_msgpack(output_dir, compress):\n\n    version = pandas.__version__\n\n    print(\n        \"This script generates a storage file for the current arch, \"\n        \"system, and python version\"\n    )\n    print(\"  pandas version: {0}\".format(version))\n    print(\"  output dir    : {0}\".format(output_dir))\n    print(\"  storage format: msgpack\")\n    pth = \"{0}.msgpack\".format(platform_name())\n    to_msgpack(os.path.join(output_dir, pth), create_msgpack_data(), compress=compress)\n\n    print(\"created msgpack file: {pth}\".format(pth=pth))",
        "begin_line": 363,
        "end_line": 377,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.write_legacy_file#380",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.write_legacy_file()",
        "snippet": "def write_legacy_file():\n    # force our cwd to be the first searched\n    sys.path.insert(0, \".\")\n\n    if not (3 <= len(sys.argv) <= 4):\n        exit(\n            \"Specify output directory and storage type: generate_legacy_\"\n            \"storage_files.py <output_dir> <storage_type> \"\n            \"<msgpack_compress_type>\"\n        )\n\n    output_dir = str(sys.argv[1])\n    storage_type = str(sys.argv[2])\n    try:\n        compress_type = str(sys.argv[3])\n    except IndexError:\n        compress_type = None\n\n    if storage_type == \"pickle\":\n        write_legacy_pickles(output_dir=output_dir)\n    elif storage_type == \"msgpack\":\n        write_legacy_msgpack(output_dir=output_dir, compress=compress_type)\n    else:\n        exit(\"storage_type must be one of {'pickle', 'msgpack'}\")",
        "begin_line": 380,
        "end_line": 403,
        "comment": "",
        "is_bug": false
    }
]